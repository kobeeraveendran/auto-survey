l u j l c s c v v x r discovering topics text datasets visualizing relevant words franziska leila grgoire klaus robert wojciech learning group technische universitt berlin berlin germany learning group fraunhofer heinrich hertz institute berlin germany brain cognitive engineering korea university seoul korea franziska tu berlin abstract related work dealing large collections uments imperative quickly overview texts contents achieved clustering algorithm identify ics dataset selecting visualizing relevant words guish group documents rest texts summarize contents documents belonging topic demonstrate approach discovering trending topics collection new york times article snippets introduction large unstructured text datasets e form data dumps leaked journalists ing frequent quickly overview contents datasets tools exploratory analysis essential propose method extracting set texts relevant words distinguish documents dataset dbscan clustering algorithm documents dataset grouped reveal salient topics summarize texts belonging topic visualizing extracted relevant words word clouds enabling grasp contents documents glance identifying relevant words clusters cent new york times article snippets strate approach reveal trending topics tools discussed paper code replicate experiments available open source python library com textcatvis identifying relevant words text documents traditionally limited area feature selection different approaches discard irrelevant features attempt improve classication performance reducing noise save computational resources primary objective identify words best describe documents belonging certain clusters identify features particularly uninformative classication task disregarded work focused selecting keywords individual documents e based tf idf variants ers keywords vide adequate summaries single documents necessarily overlap keywords found documents topic difcult aggregate overview contents group texts current tools available creating word clouds means ing collection rely term frequencies ignoring stopwords sibly combined speech tagging named entity recognition identify words est approach based tf idf tures selects words occurring frequently group documents words reliably guish documents texts belonging clusters recent work relevant features selected layerwise relevance tion lrp trace classier s decision samples input features fully understand classication decisions convolutional neural network trained text categorization task subsequently termine relevant features individual classes aggregating lrp scores computed test samples classication settings lrp works great identify relevant words describing different classes documents method suited case dealing unlabeled data methods quick overview text dataset want identify visualize relevant words ring collection texts dene relevant words characteristic features uments distinguish ments rst step process texts preprocessed transformed feature vectors section relevant words supposed occur documents interest distinguish documents analyzing dataset revealing look individual clusters obtain relevant words ter e nd features distinguish cluster e topic cluster documents dataset use dbscan algorithm tion relevant words cluster c identied computing relevancy score rc word ti t t number unique terms given vocabulary word clouds created ranking words easiest way compute relevancy scores simply check frequent features selection documents necessarily duce features additionally occur infrequently clusters instead compute score word indicating uments cluster occurs compared clusters section preprocessing feature extraction n texts dataset preprocessed casing removing non alphanumeric characters text transformed bag words bow feature vector xk rt k n rst computing normalized count term frequency tf word text weighting word s inverse document frequency idf reduce inuence frequent pressive words occur documents idf term ti calculated logarithm total number documents divided number documents contain term ti e idf ti log n ti entry corresponding term ti tf idf feature vector xk document k xki idf ti addition single terms ing meaningful combinations words e grams features inate ture space later relevancy scores computed feature tinctive bigrams selected achieved computing bigram score combination words occurring corpus similar selecting score signicantly higher random word combinations ther details found appendix clustering identify relevant words summarizing ent topics dataset texts rst clustered use density based spatial clustering applications noise dbscan clustering algorithm identies clusters areas high density feature space separated areas low density algorithm chosen assume clusters certain shape unlike e k means algorithm assumes spherical clusters allows noise dataset e enforce samples belong certain cluster dbscan based pairwise distances tween samples rst identies core samples areas high density iteratively expands cluster joining samples distance user dened threshold cosine similarity reliable measure larity text documents compute pairwise distances dbscan algorithm rst reducing documents tf idf feature vectors linear kernel pca components remove noise create overlap feature tors compute cosine similarity vectors subtract transform distance measure clustering unsupervised process value distance threshold chosen obtained clusters reasonable experiments scribed found minimum cosine similarity samples cluster e distance threshold leads texts topic grouped denote yk cluster document k assigned clustering procedure identifying relevant words relevant words cluster identied computing relevancy score rc word ti selecting highest scoring words compute score word depending number documents occurs cluster compared documents clusters fraction documents target cluster c contain word ti word s true positive rate yk c yk correspondingly compute word s false positive rate mean plus standard deviation tprs word c c objective nd words occur documents target cluster e large occur documents clusteres e low way identify words compute difference rates e ti similar traditional feature selection proaches score yields words occur target cluster clusters account relative differences example able detect emerging topics newspaper articles necessarily interested words occur today s articles infrequently terday instead acknowledge articles published today written new event signicantly articles pared yesterday propose instead rate quotient gives score word tpr times higher fpr ti rate quotient extracts relevant words unnoticed given fpr assigns score words tpr tpr create proper ranking relevant words mean scores compute nal score rc ti ti ti results tpr fpr relation shown fig figure relevancy score depending word s tpr fpr cluster experiments results illustrate identied relevant words help exploring new datasets test ously described methods recent article snippets new york times code replicate experiments available online includes functions cluster documents extract relevant words visualize word clouds highlight relevant words individual documents approach discover trending topics newspaper article snippets week president trump s guration jan weeks prior including week downloaded archive api new york times cluster texts ally split articles published week inauguration identied relevant words reveals clear taking maximum clusters tprs word avoid large inuence cluster maybe samples json com textcatvis nytimes com week inauguration clustered scan enforcing minimum cosine larity samples cluster articles cluster obtain clusters week ticles considered noise clusters correspond specic sections newspaper e corrections articles published days fore refer meaningful events happened week e nomination betsy devos avalanche italy fig conclusion examining relevant words summarize ferent groups documents dataset helpful step exploratory analysis tion texts allows quickly grasp contents documents belonging certain clusters help identify salient topics important faced large dataset quickly needs nd documents interest explained compute relevancy score individual words depending ber documents target cluster word occurs compared clusters method fast robust respect small ing numbers samples cluster usefulness approach demonstrated obtained word clouds identify trending topics recent new york times article snippets hope provided code encourage people faced large collections texts quickly dive analysis thoroughly explore new datasets acknowledgments like thank christoph hartmann helpful comments earlier version manuscript franziska horn acknowledges funding elsa neumann scholarship tu berlin references leila arras franziska horn grgoire montavon klaus robert mller wojciech samek plaining predictions non linear classiers nlp proceedings workshop resentation learning nlp pages ation computational linguistics leila arras franziska horn grgoire tavon klaus robert mller wojciech samek figure relevant words ny times article pets week president trump s ration green weeks prior red figure frequencies selected words ny times article snippets different days trends fig obviously main focus week inauguration ready apparent followed protest marches australian open happening time looking currence frequencies different words time fig spike trump day inauguration stopwords occur equally frequent days meaningless words tuesday clear spikes tuesdays care taken contrasting articles different times computing relevant words easily happen meaningless words picked simply e month contains tuesdays month comparison identify trending topics articles figure word clouds created relevant words identied clusters week jan corresponding headlines christopher d manning prabhakar raghavan introduction hinrich schtze mation retrieval cambridge university press new york ny usa isbn carmel mcnaught paul lam wordle supplementary research tool qualitative report tomas mikolov ilya sutskever kai chen greg s corrado jeff dean distributed tions words phrases ity advances neural information processing systems pages grgoire montavon wojciech samek robert mller methods interpreting derstanding deep neural networks arxiv preprint bernhard schlkopf alexander smola robert mller nonlinear component analysis kernel eigenvalue problem neural computation yiming yang jan o pedersen comparative study feature selection text categorization proceedings fourteenth international ference machine learning icml pages san francisco usa morgan kaufmann publishers inc isbn kuo zhang hui xu jie tang juanzi li word extraction support vector machine pages springer berlin heidelberg berlin heidelberg relevant text document terpretable machine learning approach arxiv preprint sebastian bach alexander binder grgoire tavon frederick klauschen klaus robert mller wojciech samek pixel wise explanations non linear classier decisions layer wise evance propagation plos martin ester hans peter kriegel jrg sander aowei xu al density based algorithm discovering clusters large spatial databases noise kdd volume pages george forman extensive empirical study feature selection metrics text classication journal machine learning research florian heimerl steffen lohmann simon lange thomas ertl word cloud explorer text lytics based word clouds system sciences hicss hawaii international ence pages ieee franziska horn leila arras grgoire montavon klaus robert mller wojciech samek ploring text datasets visualizing relevant words arxiv preprint anette hulth improved automatic keyword traction given linguistic knowledge ceedings conference empirical methods natural language processing pages association computational tics sungjick lee han joon kim news keyword extraction topic tracking networked puting advanced information management fourth international conference volume pages ieee issues surrounding betsy devos education nominee profit law school cut federal student loans betsy devos s education hearing erupts partisan debate nominee betsy devos s knowledge education basics open criticism donald trump s education nominee betsy devos avalanche death toll italy reaches search hotel rubble continues avalanche italy buries hotel leaving missing italy cheers boy pulled rubble avalanche search survivors avalanche italy
