cx queryable extractive summarizer semantic search engine allen roush university oregon usa abstract competitive debate s increasingly technical nature left competitors looking tools accelerate evidence production find unique type extractive summarization performed competitive debaters summarization bias particular target meaning performed latest innovations unsupervised pre trained text vectorization models introduce queryable word level extractive summarizer evidence creation framework allows summarization rapid biasable arbitrarily sized texts usage embedding framework flair means underlying models improve improve observe functions semantic search engine application supplement traditional find programs webpages currently competitive debaters available public com hellis otherpeople functionality introduction summarization extractive task automatically producing summary text deleting uninformative tokens contrast abstractive summarization allows deletion replacement insertion tokens way characterizing difference highlighter vs pen analogy extractive summarization process highlighting document include important figure example document competitive debate community bolded highlighted sentences abstract document extract document highlighting important text author date salient parts document abstractive summarization writes completely new abstract based document abstract include tokens found document extractive summarization system prior work extractive summarization systems includes recent advances nlp jadhav rajan zhao al unfortunately systems suffer key limitations utilize latest pre trained word character embeddings focus maximizing grammatical correctness populate summaries candidate text sentence level focus creating faithful summaries e usually select sentences goal taking similar sentences document find documents summarized reader wants confidential review copy distribute inspired s algorithm competitive debaters abstractively summarize documents presents accounting evidence says supports argument presenting summarization recite extractive summarization evidence imitates process related work summarization queryable new development yulianti al describe system concatenates tweets document alongside document summarizing users found summaries system preferable unbiased summaries azar et al describes query based summarizer ensemble noisy auto encoders select sentences test system emails email subject lines query lierde chow describes hypergraph based system summarization based query tries maximize coverage query selecting semantically meaningful sentences graph traversal chaudhari mattukoyya describes tf idf based document summarization model biases specific words incorporating secondary polarity measuring model selects sentences based sentiment notably anticipate possibility applications businesses biased summaries create positive sounding testimonials product buyers anticipate possibility users content graceful manner barve desai describes query based extractive models summarizing sanskrit documents sanskrit chosen known sanskrit texts existence digitized contemporary extractive summarizers focus sentence level document summarization nallapati et al narayan et al shi et al current word embedding based techniques extractive summarization work sentence level liu word level extractive summarization systems exist called sentence compression systems filippova al klerke al knowledge systems queryable utilize pre trained word embeddings point training process algorithm similar existing text rank algorithm mihalcea tarau textrank find keywords select sentences form summary blends sliding word window approach computing word importances ranking mechanism described mihalcea tarau generate summaries finally observe parallels work semantic search engines chrome extension called fuzbal ilchenk utilizes glove embeddings perform semantic searches webpages performs similar process document customizable set embeddings fuzbal utilizes small pre trained models interests impacting page render speed backend architecture underlying architecture unsupervised pre trained text vectorization models text vectorization process converting text n dimensional vector vector properties magnitude direction allow comparison words cosine distance text vectorization models trained predict word given previous context designed predict context words given candidate word mikolov al recent methods utilize newer neural network architectures like transformer introduce bidirectionality devlin et al improved contextual disambiguation like masking techniques work field text embeddings rapidly progressing reason powered text embedding framework flair akbik blythe flair chosen simple interface allows user combine word document embeddings arbitrarily authors flair point quickly incorporate new text embedding models meaning s summarization capabilities improve state art models power improve techniques summarization utilize supervised techniques consciously avoided desired stronger generalization performance available unsupervised models unsupervised models usually trained massive corpuses like wikipedia common crawl penninglon et al overfit particular topic domain furthermore offer user ability tune embedding models domain specific confidential review copy distribute figure comparison different lengths word window length middle length length embeddings fasttext trained wikipedia data underlined highlighted bias query economic decline causes unending war figure scaling word windows beginning end document word window size window word words summary window second word stand adds word word window appends additional words list slides window text eventually creating word bidirectional word windows middle text reducing final word true unlabeled corpus requiring labeled text data algorithm overview word windows similarity generate user specified length summary document computing cosine vectorized representation user inputted query words corresponding word window document produces scaler word corresponds similarity word context query figure displays difference summarization word window lengthened observe word window increases summaries tend include longer runs words roughly proportional size word window compared sentence level summarization assigns scalers sentences words technique trades significant grammatical correctness purposes competitive debate community tradeoffs worth benefits scalable summarization furthermore improves capacity biased summary piece confidential review copy distribute figure unbiased summary vs biased summary hyperparamaters chosen fasttext trained wikipedia data underlined highlighted bias query moderns seek enjoyment life staying alive meaning intended original documents authors extremely useful tool guiding algorithm s summary creation scaling word window described figure chosen perceived natural correspondence human read text usage pretraining models uses bias query executing asks user input bias query single word semantic search sentence tagline debaters different document users wish generate unbiased summary enter set query document summarized word vectorized bias vector computed mean pooling word vector query differences figure highlights summarization unbiased biased summaries theory summary generated says user wants practice nature word embeddings makes challenging word embeddings predict context sentences love ice cream hate ice cream rank extremely similar query looking ills ice cream accidentally end including information good ice cream observe queryability feature summarization main execution loop user enters documents wish summarize takes input system s standard input stream user indicates entering document pressing d user entered document works follows word source document vectorized representation word window computed computes cosine similarity query vector word window vector prompts user specify percentage document want underlined highlighted ahead time words highest similarity selected included summary allows user underline highlight document want different sized summary summary different settings pooling inherits hyperparamaters available flair s documentpoolembeddings class set word vectors available flair confidential review copy distribute custom user trained models selected power instance user leverage fine tuned glove fasttext bert models summarize document flair concatenates embeddings seamlessly computing vector representation word string usually averaging word character vector flair makes possible maximum minimum vector utilize average word pooling default written originally competitive debate community asks user summaries produced user indicates finished produces word document similar format evidence shown figure outputs summary standard output sty dynamic highlighting terminal use cases section describes current domains successfully proposes use cases extensions competitive speech debate original idea raison detre tool assist creation evidence users compete american style cross examination debate style debate characterized length extreme technical style heavy reliance topic evidence competitors painstakingly spend hundreds hours researching preparing evidence format shown figure s pays homage community annual tool introduced competitive debate community caused positive reactions impressed customizability speed summarization believe automation evidence production risks incentivizing competitors properly read research include core debate case ideal use case tool quickly summarize documents found immediately prior important speech extremely limited preparation time competitor utilizes significant advantage competition com feluxe sty semantic search users noted similarity model semantic powered find search tool typing query like policies politician s web page easily guide user list policies webpage chooses different semantically similar words describe policy page fuzbal proved significant group users find feature useful built web browser especially interesting use case information retrieval user mentioned trying use tandem embeddings trained pubmed abstracts process medical documents cancer search experimental novel treatments family strongly support kind efforts hope tools like useful need quickly parse large semantic amounts understanding information future work sentence requested debate community satisfied grammatically incorrect summaries users level summarization mode plan add feature future update furthermore exciting possibilities related trying incorporate context ranking mechanism concatenating sparse wide embedding models like tf idf alongside current deep embedding models fine tuning text vector models debate corpuses conclusion presented queryable word level extractive summarization system designed specific domain tool leverages state art pre trained language models generate summaries explain underlying architecture muse potential use cases serve action work field semantic search system utilized extensively competitive speech debate community available public github confidential review copy distribute references summarization retrieved org akbik alanand blythe d v r contextual string embeddings sequence labeling proceedings international conference computational linguistics retrieved org anthology mihalcea r tarau p textrank bringing order texts proceedings conference empirical methods natural language processing azar m y sirts k moll d mikolov t chen k corrado g dean j distributed representations words phrasesand compositionality advances neural information processing systems jmlr nallapati r zhai f zhou b summarunner recurrent neural network based sequence model extractive summarization documents proceedings thirty aaai conference artificial intelligence retrieved org narayan s cohen s b lapata m ranking sentences extractive summarization reinforcement learning retrieved org penninglon j socher r manning c d m glove global vectors word representation proceedings conference empirical methods natural language processing emnlp nq iv c shi j liang c hou l li j liu z zhang h deepchannel salience estimation contrastive learning extractive document summarization retrieved org yulianti e huspi s sanderson m tweet biased summarization journal association information science technology asi zhao y luo z aizawa language model based evaluator sentence compression proceedings annual meeting association computational linguistics volume short papers retrieved org anthology based single document summarization ensemble noisy proceedings australasian language technology association workshop barve s desai s s r query based extractive text summarization sanskrit advances intelligent systems computing retrieved springer com chaudhari m mattukoyya n tone biased mmr text summarization retrieved org devlin j chang m lee k toutanova k bert pre training deep bidirectional transformers language understanding mlm retrieved org filippova k alfonseca e colmenares c kaiser l vinyals o sentence compression deletion lstms proceedings conference empirical methods natural language processing ilchenk fuzbal gives ctrl f like find results retrieved com ijkilchenko fuzbal jadhav rajan v extractive summarization swap net sentences words alternating pointer networks association computational linguistics bjr klerke s goldberg y sgaard improving sentence compression learning predict gaze proceedings naacl hlt retrieved org lierde h van chow t w s oriented text summarization based hypergraph transversals hadrien liu y fine tune bert extractive
