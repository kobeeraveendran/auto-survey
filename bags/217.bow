clustering deep contextualized representations summarization biomedical texts milad moradi matthias samwald institute artificial intelligence decision support center medical statistics informatics intelligent systems medical university vienna vienna austria milad moradivastegani matthias abstract summarizers contextualized recent years incorporate domain knowledge process text summarization outperformed generic methods especially summarization biomedical texts construction maintenance domain knowledge bases intense tasks requiring significant manual annotation paper demonstrate representations extracted pre trained deep language model bert effectively measure similarity sentences quantify informative content results based performance biomedical summarization summarizer use sources domain knowledge capture context sentences accurately comparison methods source code data available com biotextsu bert based summ summarizer improve introduction text summarization process identifying important contents document producing shorter version text conveys important ideas publicly available summarizers use generic features position length sentences term frequency presence cue phrases assess importance sentences specifically biomedical domain shown generic measures efficient domain specific methods incorporate sources domain knowledge knowledge represent text concept based level effort invested sources domain ontologies taxonomies controlled vocabularies capture context input text appears methods improved performance biomedical summarization quantify informative content considering semantics sentences considering generic features building maintaining utilizing sources domain knowledge challenging time consuming tasks leading research community develop new generation context aware methods use neural network based language models recent years usage pre trained deep language models received significant attention wide variety natural language processing nlp tasks approach unsupervised training conducted large corpus text resulting model fine tuned supervised task directly extract numeric features input text usage deep pre trained language models recently obtained state art results wide variety nlp tasks transformers paper propose novel biomedical text summarizer uses bidirectional encoder representations bert language model capture context sentences appear input document bert pre trained large text corpora wikipedia bookcorpus tuning step achieve state art results wide variety nlp tasks possible directly extract use contextualized embeddings learnt bert training fine tuning steps paper sentences accurately summarizers use domain knowledge showing clustering deep representations contextualized improve performance biomedical text summarization summarization method summarization method consists main steps figure illustrates overall architecture summarizer preprocessing summarizer performs preprocessing step order prepare input text subsequent steps parts text unimportant appearing summary discarded parts vary based input document user structure requirements case evaluations performed biomedical scientific articles main text input article retained parts headers sections subsections figures tables discarded information added final summary needed text split sentences sentence split tokens purpose use natural language tool kit nltk library mapping text representations contextualized second step utilize bert extract contextualized embeddings tokens input feature extraction script output json file containing activation values hidden layers different versions bert different model sizes currently available bert base contains layers hidden units layer attention heads unit total number million parameters bert large contains layers hidden units layer attention heads unit total number million parameters use bert base bert large experiments assess impact different model sizes quality summaries feature extraction step token represented contextualized embedding size based size bert model contextualized representation computed sentence figure overall architecture based biomedical text summarizer summarizer uses quantify utilizing bert language model summarizer computes contextual representation dimensional vector sentence applies hierarchical clustering algorithm find multiple groups sentences sentences nearby vector space fall cluster contextualized embeddings informative content sentences assess similarity idea sentences cluster share similar context subsequently summarizer selects informative sentences cluster generate final summary evaluate performance bert based summarizer corpus biomedical scientific articles results summarizer improve performance biomedical text summarization compared generic methods biomedical summarizers utilize domain knowledge main contributions paper summarized follows utilizing pre trained bidirectional unsupervised language model biomedical text summarization demonstrating bert based summarizer capture context averaging representations tokens belonging sentence sentence clustering contextualized embedding sentence represents context sentence appears nearby sentences vector space share similar context summarizer uses clustering step group sentences number clusters cluster similar terms representations vector space use agglomerative hierarchical clustering algorithm step clustering algorithm starts specifying number final clusters parameter iteration clusters similar nearest merged number clusters reduces similarity distance clusters computed averaging similarity distance values sentence cluster sentence second clustering algorithm proceeds number clusters reaches similarity distance sentences computed different measures run clustering step widely measures separately cosine similarity euclidean distance let contextualized representations given sentences cosine similarity euclidean distance vectors computed follows end step set clusters containing set related sentences summary generation summarizer needs decide sentences relevant informative included summary sentences cluster share important content input text summarizer selects sentences clusters cover important ideas possible cluster contributes summary proportion size follows number sentences selected ith cluster size summary specified compression rate size ith cluster size input document order select informative related sentences cluster cluster score computed sentence follows wcsi cluster score ith sentences belonging jth cluster size jth cluster similarity sentences sisq note value computed measures cosine similarity euclidean distance measure clustering algorithm summarizer ranks sentences cluster based cluster scores cluster ranked sentences extracted according summarizer arranges selected sentences order appear input text produces final summary experiments results evaluation corpora metrics randomly retrieve articles biomed central construct development evaluation corpora respectively abstract article model summary approach creating corpora widely adopted biomedical text summarization according size corpora large allow results statistically significant use rouge toolkit assess quality summaries produced automatic methods higher scores returned rouge metrics refer higher content overlap system model summaries evaluations use metrics quantify content overlap terms shared unigrams bigrams respectively parameterization parameter specifies number final clusters clustering algorithm similarity measure sentence clustering summary generation steps assess performance summarization method comparison summarizers evaluate performance summarization method comparison methods cibs bayesian biomedical summarizer summa cibs uses umls concepts combination itemset mining clustering identify extract important sentences bayesian summarizer applies probabilistic heuristic concepts produce informative summary summa texlexan employ generic features length position sentences frequency terms presence cue terms table presents rouge scores obtained methods bert based summarizer reports highest scores compared scores obtained comparison methods bert based summarizer performance biomedical text summarization according wilcoxon signed rank text confidence interval significantly improve conclusion results contextualized embeddings learnt bert effectively biomedical text summarization shown type contextual representations convey context sentences accurately comparison methods utilize sources domain knowledge study initial step employing type language models developing domain specific nlp systems text summarization extend research plan utilize type language models trained biomedical text corpora investigate usefulness biomedical text summarization future work include usage contextual representations address problems biomedical named entity recognition question answering information extraction need accurately capture context text biomedical especially references gambhir gupta recent automatic text summarization techniques survey artificial intelligence review vol cosine similarity euclidean distance table rouge scores obtained based summarizer parameterization experiments bert based summarizer cibs bayesian summarizer summa texlexan table rouge scores obtained based summarizer comparison methods different settings varying number clusters range measures cosine similarity euclidean distance separately brevity reasons report results obtained summarizer utilizes bert large scores higher bert base experiments compression rate set table presents rouge scores obtained summarizer different settings scores presented cosine similarity euclidean distance summarizer obtains highest scores smaller values important sentences merged sentences larger clusters lose chance inclusion summary case informative sentences excluded summaries leading decrease quality summarization hand higher values assigned unimportant sentences leave large clusters construct new cluster contribute summary case number non informative sentences appear summary decreasing scores sourceforge arxiv transformers language preprint bidirectional understanding lin looking good metrics automatic summarization evaluation samples ntcir saggion summa robust adaptable summarization tool traitement automatique langues vol recent journal approach identifying review topic based intelligence text moradi cibs biomedical sentence summarizer clustering biomedical informatics vol moradi ghadiri different approaches important concepts probabilistic biomedical text summarization artificial intelligence medicine vol mishra bian fiszman weir jonnalagadda mostafa text summarization biomedical domain research systematic journal biomedical informatics vol plaza daz gervs semantic biomedical graph based summarisation artificial medicine vol moradi ghadiri quantifying informativeness biomedical literature summarization itemset mining method computer methods programs biomedicine vol moradi frequent itemsets meaningful summarizing events biomedical texts international conference computer knowledge engineering iccke moradi concept based text multi document summarization isfahan university technology fleuren alkema application text mining biomedical domain methods vol turian ratinov bengio word representations simple general method semi supervised learning presented proceedings annual meeting computational linguistics uppsala sweden peters ammar bhagavatula sequence power tagging bidirectional language models arxiv preprint radford narasimhan salimans language understanding generative pre training url amazonaws com openai assets covers languageunsupervised language understanding paper pdf semi supervised association graphs improving biomedical sutskever peters neumann iyyer gardner clark lee deep contextualized word representations arxiv preprint devlin chang lee toutanova bert pre training deep
