survey taxonomy adversarial neural networks text image synthesis jorge jonathan haicheng xingquan computer electrical engineering computer science florida atlantic university boca raton usa email edu edu edu provincial key laboratory business nanjing university finance economics nanjing china email ustc edu abstract text image synthesis refers computational methods translate human written textual tions form keywords sentences images similar semantic meaning text earlier research image synthesis relied mainly word image correlation analysis combined supervised methods best alignment visual content matching text recent progress deep learning brought new set unsupervised deep learning methods particularly deep erative models able generate realistic visual images suitably trained neural network models change direction computer vision based approaches articial intelligence driven methods ignited intense interest industry virtual reality recreational professional esports gaming computer aided design automatically generate compelling images text based natural language descriptions paper review recent development text image synthesis research domain goal provide value delivering comparative review state art models terms architecture design survey rst introduces image synthesis challenges reviews key concepts generative adversarial networks gans deep convolutional decoder neural networks dcnn propose taxonomy summarize gan based text image synthesis major categories semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gans elaborate main tive group review typical gan architectures group taxonomy review outline techniques evolution different approaches eventually provide clear roadmap summarize list contemporaneous solutions utilize gans dcnns generate enthralling results categories human faces birds owers room interiors object tion edge maps games survey conclude comparison proposed solutions challenges remain unresolved future developments text image synthesis domain text image synthesis generative adversarial network gan deep learning machine keywords learning introduction gans variations proposed interesting idea years opinion yann lecun picture worth thousand words written text provide efcient effective concise ways communication visual content images comprehensive accurate wiley interdisciplinary reviews data mining knowledge discovery equally contributing authors figure early research text image synthesis zhu system uses correlation keywords keyphrase images identies informative picturable text units searches likely image parts conditioned text eventually optimizes picture layout conditioned text image parts ligible method information sharing understanding generation images text descriptions text image synthesis complex computer vision machine learning problem seen great progress recent years automatic image generation natural language allow users describe visual elements visually rich text descriptions ability effectively highly desirable articial intelligence applications computer aided design image editing chen yan game engines development generation video pictorial art generation elgammal traditional learning based text image synthesis early stages research text image synthesis mainly carried search order connect supervised learning combined process zhu shown figure text descriptions images use correlation keywords keyphrase images identies informative picturable text units units search likely image parts conditioned text eventually optimizing picture layout conditioned text image parts methods integrated multiple articial intelligence key components including natural language processing computer vision computer graphics machine learning major limitation traditional learning based text image synthesis approaches lack ability generate new image content change characteristics given training images alternatively research generative models advanced signicantly delivers solutions learn training images produce new visual content example yan models image composite foreground background addition layered generative model disentangled latent variables learned variational encoder generate visual content learning customized conditioned given attributes generative models generate images respect different attributes gender hair color age shown figure gan based text image synthesis generative model based text image synthesis provides realistic image synthesis results image generation conditioned limited attributes recent years papers published subject text image synthesis contributions papers rely multimodal learning approaches include generative adversarial networks deep figure supervised learning based text image synthesis yan supervised ing process aims learn layered generative models generate visual content learning customized conditioned given attributes generative models generative images respect different attributes hair color age figure generative adversarial neural network gan based text image synthesis huang gan based text image synthesis combines discriminative generative learning train neural networks resulting generated images semantically resemble training samples lored subset training images conditioned outputs feature embedding function converts text feature vector latent vector following normal distributions zero mean denotes synthetic image generated generator latent vector text features input denotes prediction discriminator based input generated image text information generated image explanations generators discriminators detailed section figure visual summary gan based text image synthesis process summary gan based frameworks methods reviewed survey convolutional decoder networks main drivers generate entrancing images text reed goodfellow odena introduced ian goodfellow goodfellow generative adversarial networks gans consist neural networks paired discriminator generator models compete generator attempting produce synthetic fake samples fool discriminator discriminator attempting differentiate real genuine synthetic samples gans adversarial training aims cause generators produce images similar real training images gans naturally generate synthetic images image synthesis process customized text descriptions specify types images generate shown figure like text speech speech text conversion exists wide variety problems text image synthesis solve computer vision eld specically reed haynes nowadays researchers attempting solve plethora computer vision lems aid deep convolutional networks generative adversarial networks combination multiple methods called multimodal learning methods reed simplicity multiple learning methods referred multimodal learning ngiam searchers describe multimodal learning method incorporates characteristics methods algorithms ideas include ideas learning approaches order create robust implementation solve uncommon problem improve solution reed yang dash baltrusaitis survey focus primarily reviewing recent works aim solve challenge text image synthesis generative adversarial networks gans order provide clear roadmap propose taxonomy summarize reviewed gans major categories review elaborate motivations methods category analyze typical models network architectures possible drawbacks improvement visual abstract survey list reviewed gan frameworks shown figure remainder survey organized follows section presents brief summary existing works subjects similar paper highlights key distinctions making unique section gives short introduction gans preliminary concepts related image generation engines text image synthesis possible essential building blocks achieve photo realistic images text descriptions section proposes taxonomy summarize gan based text image synthesis discusses models architectures novel works focused solely text image synthesis section draw key contributions works relation applications section reviews gan based text image synthesis benchmarks performance metrics comparisons including simple review gans applications section conclude brief summary outline ideas future interesting developments eld image synthesis related work growth success gans deep convolutional decoder networks multimodal ing methods techniques rst procedures aimed solve challenge image synthesis engineers scientists computer vision contributed tensive studies experiments numerous proposals publications detailing contributions gans introduced goodfellow emerging research topics practical applications image synthesis infancy recently new gan architectures signs proposed use gans different applications gans generate tal texts wang wan gans transform natural images cartoons chen gans increasingly popular survey papers currently exist marize outline contemporaneous technical innovations contributions different gan tures hong creswell survey papers specically attuned analyzing different contributions text image synthesis gans scarce found surveys huang image synthesis gans closely related publications survey objective following paragraphs briey summarize surveys point objectives differ theirs huang authors provide overview image synthesis gans survey authors discuss motivations research image synthesis introduce ground information history gans including section dedicated core concepts gans generators discriminators min max game analogy enhancements inal gan model conditional gans addition variational auto encoders survey carry similar review background knowledge understanding preliminary concepts paramount rest paper types approaches image ation reviewed including direct methods single generator discriminator hierarchical methods generator discriminator pairs different goal iterative methods generator discriminator pair generates gradually higher resolution image following introduction huang discusses methods text image image image synthesis respectively describes evaluation metrics synthetic images including inception scores frechet inception distance fid explains signicance discriminators acting learned loss tions opposed xed loss functions different survey relatively broad scope gans objective heavily focused text image synthesis topic text image synthesis ered huang detailed fashion listing different works time sequential order comparison review representative methods eld outline models contributions detail similarly huang second survey paper begins standard introduction addressing motivation image synthesis challenges presents followed section dedicated core concepts gans enhancements original gan model addition paper covers review types applications unconstrained applications image thesis super resolution image inpainting constrained image synthesis applications image image text image sketch image discusses image video editing gans scope paper intrinsically comprehensive focus specically text image detail contributions novel state art models surveys published related matters mainly related advancements plications gans zhang found prior works focus specically text image synthesis gans knowledge rst paper preliminaries frameworks section rst introduce preliminary knowledge gans commonly variants conditional gan cgan building block gan based text image synthesis models briey separate gan based text image synthesis types simple gan frameworks advanced gan frameworks discuss advanced gan architecture image synthesis notice simple advanced gan framework separation brief taxonomy section propose taxonomy summarize advanced gan frameworks categories based objective designs generative adversarial neural network moving discussion analysis works applying gans text image synthesis preliminary concepts enhancements gans datasets evaluation metrics present works described section worth introducing stated previously gans introduced ian goodfellow goodfellow consist deep neural networks generator discriminator trained pendently conicting goals generator aims generate samples closely related original data distribution fool discriminator discriminator aims distinguish samples generator model samples true data distribution calculating probability sample coming source conceptual view generative adversarial network gan architecture shown figure training gans iterative process iteration updates generator discriminator goal defeating leading model increasingly adept specic task threshold reached analogous min max game models according following equation min max denotes multi dimensional sample image denotes multi dimensional latent space vector multidimensional data point following predened distribution function normal distributions denotes discriminator function controlled parameters aims classify sample binary space denotes generator function controlled parameters aims generate sample latent space vector example means latent vector generate synthetic fake image means classify image binary output true false gan setting discriminator learned distinguish genuine true image labeled fake images labeled given true image ideal output discriminator given fake image generated generator ideal prediction discriminator indicating sample fake image following denition min max objective function aims learn parameters discriminator generator reach optimization goal discriminator intends differentiate true fake images maximum capability maxd generator intends minimize difference fake image true image ming words discriminator sets characteristics generator produces elements images iteratively meets attributes set forth discriminator gans images visual elements notoriously efcient generating compelling convincing photorealistic images recently gans generate original painting unsupervised fashion radford following sections detail generator discriminator trained gans generator image synthesis generator network thought mapping representation space latent space actual data creswell comes image synthesis images data space fall distribution complex dimensional feature space sampling complex space difcult gans instead train generator create synthetic images simple feature space usually random noise called latent space generator network performs sampling latent space usually real data sample real data sigmoid function real fake random noise vector fake sample generator figure conceptual view generative adversarial network gan architecture generator trained generate synthetic fake resemble real samples random noise distribution fake samples fed discriminator real samples discriminator trained differentiate fake samples real samples iterative training generator discriminator helps gan deliver good generator generating samples close underlying training samples deep neural network consisting convolutional fully connected layers creswell generator trained gradient descent update weights generator network aim producing data case images discriminator classies real discriminator discriminator network thought mapping image data probability image coming real data space generally deep neural network consisting convolution fully connected layers discriminator performs sampling opposed sampling like generator trained gradient descent goal update weights likely correctly classify images real fake gans ideal outcome generator discriminator cost functions converge generator produces photo realistic images indistinguishable real data discriminator time expert differentiating real synthetic data possible reduction cost model generally leads increase cost phenomenon makes training gans difcult training simultaneously models performing gradient descent parallel leads stable orbit model able converge combat generator discriminator trained independently case gan remains different training stages stage weights generator kept constant gradient descent updates weights discriminator stage weights discriminator kept constant gradient descent updates weights generator repeated number epochs desired low cost model reached salimans cgan conditional gan conditional generative adversarial networks cgan enhancement gans proposed mirza osindero shortly introduction gans goodfellow objective function cgan dened similar gan objective function inputs discriminator generator conditioned class label min max main technical innovation cgan introduces additional input inputs original gan model allowing model trained information class labels conditioning variables samples concurrently original gan trained samples data distribution resulting generated sample reecting general data distribution cgan enables directing model generate tailored outputs sample real data real bird images sigmoid function real fake random noise vector fake sample generator condition vector bird figure conceptual view conditional gan architecture generator generates samples random noise distribution condition vector case text fake samples fed discriminator real samples condition vector discriminator calculates probability fake sample came real data distribution figure condition vector class label text string red bird fed generator discriminator important condition vector related real data model figure trained set real data red birds condition text yellow generator learn create images red birds conditioned text yellow note condition vector cgan come forms texts limited class label unique design provides direct solution generate images conditioned predened specications result cgan text image synthesis rst day invention modern approaches deliver better text image synthesis results simple gan frameworks text image synthesis order generate images text simple solution employ conditional gan cgan designs add conditions training samples gan trained respect underlying conditions pioneer works followed similar designs text image synthesis essential disadvantage cgan text image synthesis handle complicated textual descriptions image generation cgan uses labels conditions strict gan inputs text inputs multiple keywords long text descriptions simultaneously restrict input instead text conditions proaches reed dash use text input features concatenate features features train discriminator generator shown figure ensure text gan input feature embedding feature representation learning bengio zhang function introduced convert input text numeric features concatenated features train gans advanced gan frameworks text image synthesis motivated gan conditional gan cgan design gan based frameworks proposed generate images different designs architectures multiple tors progressively trained discriminators hierarchical discriminators figure outlines advanced gan frameworks literature addition frameworks news figure simple architecture comparisons gan networks text image synthesis gure explains texts fed input train gan generate images conditional gan cgan mirza osindero use labels condition input generator inator nal output discriminator similar generic gan manifold interpolation aware discriminator gan gan int cls reed feeds text input generator discriminator texts preprocessed embedding features function concatenated input feeding generator discriminator nal output discriminator similar generic gan auxiliary classier gan gan odena uses auxiliary sier layer predict class image ensure output consists images different classes resulting diversied synthesis images text conditioned auxiliary classier gan gan dash share similar design gan int cls output include discriminator classier classication text conditioned semantic classier gan text segan cha uses regression layer estimate semantic vance image generated images limited certain classes semantically matching text input figure high level comparison advanced gans framework text image synthesis frameworks text red triangle input generate output images left right uses multiple discriminators generator durugkar nguyen uses multiple stage gans output gan fed gan input zhang denton progressively trains symmetric discriminators generators huang uses single stream generator hierarchically nested discriminator trained end end zhang signs proposed advance eld sophisticated designs example recent work gao proposes use pyramid generator independent discriminators focusing different aspect images lead generator creating images photo realistic multiple levels recent publication cha proposes use criminator measure semantic relevance image text instead class prediction like discriminator gans resulting new gan structure outperforming text conditioned auxiliary classier tac gan dash generating diverse realistic relevant input text regardless class following section rst propose taxonomy summarizes advanced gan works text image synthesis review recent proposed solutions challenge ing photo realistic images conditioned natural language text descriptions gans solutions discuss selected based relevance quality contributions publications exist subject image generation gans paper focus specically models text image synthesis review emphasizing model contributions text image thesis end section briey review methods gans image synthesis applications text image synthesis taxonomy categorization section propose taxonomy summarize advanced gan based text image synthesis frameworks shown figure taxonomy organizes gan frameworks categories cluding semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gags following proposed taxonomy subsection introduce typical frameworks address techniques gans solve certain aspects text mage synthesis challenges gan based text image synthesis taxonomy ultimate goal text image synthesis generate images closely related textual descriptions relevance images texts validated different perspectives inherent diversity human perceptions example generating images matching description rose owers users know exact type owers like intend generate rose owers similar colors users seek generate high quality rose owers nice background garden group users interested generating owers similar rose different colors visual appearance roses begonia peony fourth group users want generate ower images use form meaningful action video clip showing ower growth performing magic owers telling love story owers text image synthesis point view rst group users intend precisely control semantic generated images goal match texts images semantic level second group users focused resolutions qualify images addition requirement images texts semantically related group users goal diversify output images images carry diversied visual appearances semantically related fourth user group adds new dimension image synthesis aims generate sequences images coherent temporal order capture motion information based descriptions categorize gan based text image synthesis taxonomy major categories shown fig semantic enhancement gans semantic enhancement gans represent pioneer works gan frameworks text image synthesis main focus gan frameworks ensure generated images semantically related input texts objective mainly achieved neural network encode texts dense features fed second network generate images matching texts resolution enhancement gans resolution enhancement gans mainly focus generating high qualify images semantically matched texts mainly achieved multi stage gan framework outputs earlier stage gans fed second later stage gan generate better qualify images diversity enhancement gans diversity enhancement gans intend diversify output ages generated images semantically related different types visual appearance objective mainly achieved additional component timate semantic relevance generated images texts order maximize output diversity motion enhancement gans motion enhancement gans intend add temporal dimension output images form meaningful actions respect text descriptions goal mainly achieved step process rst generates images matching actions texts followed mapping alignment procedure ensure images coherent temporal order following introduce gan frameworks evolve text image synthesis review typical methods category semantic enhancement gans semantic relevance important criteria text image synthesis gnas discussed survey required generate images semantically related text tions semantic relevance subjective measure images inherently rich terms semantics interpretations gans proposed enhance text image synthesis different perspectives subsection review classical approaches commonly served text image synthesis baseline gan deep convolution generative adversarial network gan reed represents pioneer work text image synthesis gans main goal train deep convolutional generative adversarial network gan text features process text features encoded neural network neural network hybrid convolutional recurrent network character level concurrently neural networks feed forward inference way condition text features generating realistic images automatically natural language text motivation works proposed computer vision eld actual articial intelligence figure taxonomy categorization advanced gan frameworks text image synthesis categorize advanced gan frameworks major categories semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gags relationship relevant frameworks publication date outlined reference systems far achieving task reed liu yang wang gupta zhang mirza osindero lately recurrent ral networks led way develop frameworks learn discriminatively text features time generative adversarial networks gans began recently promise generating compelling images host elements including limited faces birds owers common images room gan multimodal learning model attempts bridge mentioned unsupervised machine learning algorithms recurrent neural networks rnn generative adversarial networks gans sole purpose speeding generation text image synthesis deep learning shed light sophisticated advances natural language resentation image synthesis reed wang huang classication generic data han bulk latest breakthroughs deep learning computer vision related supervised learning reed natural language image synthesis contributions supervised deep learning unsupervised learning saw recently tremendous rise input research community specially subproblems text based natural language image synthesis dong yang reed cha zhang subproblems typically subdivided focused research areas gan contributions mainly driven research areas order generate plausible images natural language gan contributions revolve developing straightforward effective gan architecture training strategy allows natural text image synthesis contributions primarily tested caltech ucsd birds flowers datasets image datasets carry text descriptions text descriptions created research team setting evaluation environment gans model subsequently trained subcategories subcategories research represent training testing sub datasets performance shown experiments display promising effective way generate images textual natural language descriptions reed gan extensions following pioneer gan framework reed researches propose revised work structures different discriminaotrs order improve images better semantic relevance texts based deep convolutional adversarial network gan network architecture gan cls image text matching discriminator gan int learned text manifold interpolation gan int cls combines proposed semantic match text age similar gan architecture adaptive loss function perceptual loss johnson proposed semantic image synthesis synthesize realistic image matches target text description irrelavant background source images dong perceptual losses loss functions pixel struction loss activation reconstruction loss texture reconstruction loss proposed cha construct network architectures based gan gan int dong pixel gan int cls vgg gan int cls gram respect losses residual transformation unit added network retain similar structure source image following dong considering features early layers address background foreground obtained layers cnn pair discriminators different architectures paired gan proposed synthesize background foreground source image ately sugimoto skip connection generator employed precisely retain background information source image gan synthesising images text image synthesis methods consider output image single unit characterize semantic relevance texts likely problematic images naturally consist crucial components foreground background properly separating components hard characterize semantics image image treated single unit proper separation order enhance semantic relevance images multi conditional gan gan park proposed synthesize target image combining background source image text described foreground object exist source image unique feature gan proposes synthesis block background feature extracted given image non linear function convolution batch normalization foreground feature feature map previous layer gan able properly model background foreground generated images unique strength gan users able provide base image gan able preserve background information base image generate new images resolution enhancement gans fact training gans difcult generating high resolution images stage gan proposed rough low resolution images generated stage rened stage improve quality generated images second version stackgan proposed use multi stage gans generate multi scale images color consistency regularization term added loss consistency images different scales stackgan built global sentence vector posed use attention mechanism deep attentional multimodal similarity model damsm model multi level information word level sentence level gans following stackgan explained detail recently dynamic memory generative adversarial network uses dynamic memory component proposed focus reningthe initial generated image key success generating high quality images stackgan zhang proposed model generating photo realistic images text descriptions called stackgan stacked generative adversarial network zhang work dene stage model uses cascaded gans corresponding stages stage gan takes text description input converts text description text embedding containing conditioning variables generates low quality image rough shapes colors based computed conditioning variables stage gan takes low quality stage image text embedding uses conditioning variables correct add detail stage result output stage photorealistic image resembles text description compelling accuracy major contribution stackgan use cascaded gans text image synthesis sketch renement process conditioning stage gan image produced stage gan text description stage gan able correct defects stage output resulting high quality images prior works utilized stacked gans separate age generation process structure style wang gupta multiple stages generating lower level representations higher level representations previous stage huang multiple stages combined laplacian pyramid approach denton troduced image compression burt adelson uses differences consecutive samples original image reconstruct original image sampled version burt adelson works use text descriptions condition generator models conditioning augmentation major contribution stackgan prior works transformed natural language text description xed text embedding containing static conditioning variables fed generator reed stackgan creates gaussian distribution text embedding randomly selects variables gaussian distribution add set conditioning variables training encourages robustness introducing small variations original text embedding particular training image keeping training image generated output compared result trained model produces diverse images distribution conditioning augmentation model xed text embedding zhang proposed users stackgan stacked gan model organizes generators discriminators tree like structure zhang multiple stages rst stage combines noise vector conditioning variables conditional augmentation introduced zhang input rst generator generates low resolution image default changed depending desired number stages lowing stage uses result previous stage conditioning variables produce gradually higher resolution images stages use noise vector creators assume randomness introduces preserved output rst stage nal stage produces high quality image introduces joint conditional unconditional approximation designs zhang discriminators trained calculate loss image produced generator conditioning variables measuring accurately image represents scription loss image real images probability image real fake generators aim minimize sum losses improving nal result attentional generative adversarial network similar terms structure zhang discussed previous section novel ponents added like previous works reed zhang text encoder generates text embedding conditioning variables based overall sentence additionally text encoder generates separate text embedding conditioning variables based individual words process optimized produce meaningful variables bidirectional recurrent neural work brnn specically bidirectional long short term memory lstm schuster paliwal word description generates conditions based previous word word bidirectional rst stage generates low resolution image based sentence level text embedding random noise vector output fed level text embedding attention model matches word level conditioning variables regions stage image producing word context matrix fed stage model raw previous stage output consecutive stage works manner produces gradually higher resolution images conditioned previous stage major contributions introduced attngan attentional generative network deep attentional multimodal similarity model damsm zhang attentional ative network matches specic regions stage output image conditioning variables word level text embedding worthy contribution allowing consecutive stage focus specic regions image independently adding attentional details region region opposed image damsm key feature introduced result nal stage calculate similarity generated image text embedding sentence level grained word level table shows scores different metrics stackgan attngan hdgan cub oxford coco datasets table shows outperforms models terms cub dataset small greatly outperforms coco dataset hdgan hierarchically nested adversarial network hdgan method proposed zhang main objective tackle difcult problem dealing photographic images semantic text descriptions semantic text descriptions applied images diverse datasets method introduces adversarial objectives nested inside hierarchically oriented networks zhang hierarchical networks helps regularize mid level manifestations addition regularize level manifestations assists training generator order capture highly complex media elements elements captured statistical order train generator based settings tracted directly image ideal scenario paper aims incorporate single stream architecture single stream architecture functions generator form optimum adaptability jointed discriminators jointed discriminators setup optimum manner single stream architecture advance generated images achieve higher resolution zhang main contributions hdgans include introduction visual semantic similarity sure zhang feature aid evaluation consistency generated images addition checking consistency generated images key objectives step test logical consistency end product zhang end product case images semantically mapped text based natural language descriptions area picture wing bird petal ower deep learning created multitude opportunities challenges researchers computer vision eld coupled gan multimodal ing architectures eld seen tremendous growth reed liu yang wang gupta zhang mirza osindero based advancements hdgans attempt extend desirable common features generating images textual natural language zhang words takes sentences treats hierarchical structure positive negative implications cases starters makes complex generate compelling images key benets elaborate process realism obtained processes completed addition common feature added process ability identify parts sentences bounding boxes sentence includes common characteristics bird surround attributes bird bounding boxes practice happen desired image ements human faces eyes hair owers petal size color inanimate object table mug finally hdgans evaluated claims common ideal text image datasets cub coco reed zhang liu yang wang gupta zhang mirza osindero datasets rst utilized earlier works reed sport modied features image annotations labels descriptions qualitative quantitative results reported researchers study far superior earlier works eld computer vision diversity enhancement gans subsection introduce text image synthesis methods try maximize diversity output images based text descriptions gan issues arise traditional gans mirza osindero image synthesis bilirty problem traditional gans predict large number image categories diversity problem images subject mapping image labeled different tags described different texts address problems gan conditioned additional information cgan alternative solution cgan previously troduced approaches able generate images respect text descriptions output images similar types visual appearance slightly different cgan auxiliary classier gans gan odena poses improve diversity output images auxiliary classier control output images overall structure gan shown fig gan generated image ated class label addition true fake label commonly gan cgan discriminator gan outputs probability distribution sources image true fake output probability distribution class label predict class image belong auxiliary classier layer predict class image gan able use predicted class labels images ensure output consists images different classes resulting diversied synthesis images results gan generate images high diversity tac gan building gan tac gan dash proposed replace class information textual descriptions input perform task text image synthesis architecture tac gan shown fig similar gan overall major difference tac gan gan tac gan conditions generated images text descriptions instead class label design makes tac gan generic image synthesis tac gan imposes restrictions generated images texts class labels input vector tac gan generative network built based noise vector embedded vector tation textual descriptions discriminator tac gan similar gan predicts image fake predicts label images minor difference tac gan discriminator compared gan receives text information input performing classication experiments validations owers dataset results produced tac gan slightly better approaches including gan int cls stackgan text segan order improve diversity output images gan tac gan discriminators predict class labels synthesised images process likely enforces semantic diversity images class labels inherently restrictive describing image semantics images described text matched multiple labels instead predicting images class labels alternative solution directly quantify semantic relevance architecture text segan shown fig order directly quantify semantic evance text segan cha adds regression layer estimate semantic relevance image text instead classier layer predicting labels estimated semantic reference fractional value ranging higher value reecting better semantic relevance image text unique design inherent advantage text segan generated images limited certain classes semantically matching text input experiments validations ower dataset text segan generate diverse images semantically relevant input text addition results text segan improved inception score compared approaches including gan int cls stackgan tac gan hdgan mirrorgan scene graph gan inherent complexity visual images diversity text descriptions words imply different meanings difculty precisely match texts visual images semantic levels methods discussed far employ direct text image generation process validation generated images comply text reverse fashion ensure semantic consistency diversity mirrorgan qiao employs ror structure reversely learns generated images output texts image text process validate generated consistent input texts mirrowgan includes modules semantic text embedding module stem global local collaborative attentive ule cascaded image generation glam semantic text regeneration alignment module stream text image image text combined sively enhance diversity semantic consistency generated images order enhance diversity output image scene graph gan johnson poses use visual scene graphs describe layout objects allowing users precisely specic relationships objects images order convert visual scene graph input gan generate images method uses graph convolution process input graphs computes scene layout predicting bounding boxes segmentation masks objects converts computed layout image cascaded renement network motion enhancement gans instead focusing generating static images line text image synthesis research focuses generating videos sequences images texts context synthesised videos useful resources automated assistance story telling obamanet early interesting work motion enhancement gans generate spoofed speech lip sync videos talking face barack obama obamanet based text input kumar framework consisted parts text speech mouth shape representation synced audio time delayed lstm video generation conditioned mouth shape net architecture results promising obamanet models mouth region videos generated noise regarded video prediction video generation meaningful trial synthesised videos automated assistance translate spoken language text sign language video sequences stoll achieved step process converting texts meaningful units generate images followed learning component arrange images sequential order best representation ically rnn based machine translation methods texts translated sign language gloss quences glosses mapped skeletal pose sequences lookup table generate videos conditional dcgan input concatenation latent representation image base pose skeletal pose information built text video model proposed based cgan input isometric gaussian noise text gist vector served generator key component generating videos text train conditional generative model extract static dynamic information text followed hybrid framework combining variational autoencoder vae generative adversarial network gan specically relies types features static features dynamic features erate videos static features called gist sketch text conditioned background color object layout structure dynamic features hand considered transforming input text image lter eventually forms video generator consists entangled neural networks text gist vector generated gist generator maintains static information background captures dynamic information actions text generate videos demonstrated paper generated videos semantically related texts low quality resolution storygan different generates videos single text storygan aims produce dynamic scenes consistent specied texts story written multi sentence paragraph sequential gan model story encoder context encoder discriminators main nents model stochastic sampling story encoder intends learn low dimensional embedding vector story continuity story context encoder posed capture contextual information sequential image generation based deep rnn discriminators storygan image discriminator evaluates generated images story discriminator ensures global consistency experiments comparisons clevr dataset pororo cartoon dataset inally visual question answering storygan improves generated video qualify terms structural similarity index ssim visual qualify consistence relevance measure based human evaluation table summary different gans datasets validation symbol indicates model evaluated corresponding dataset method names cgan mirza osindero gan odena tac gan dash text segan cha gan int cls reed stackgan zhang zhang gan reed hdgan zhang mirrorgan qiao evaluation datasets mnist coco cub gan based text image synthesis applications mark evaluation comparisons text image synthesis applications computer vision applications strong potential industries including limited cal government military entertainment online social media elds nie hong mansimov asmuth fang text image sis application computer vision main focus recent years potential providing benecial properties opportunities wide range applicable areas text image synthesis application byproduct deep convolutional decoder networks bination gans reed deep convolutional networks contributed breakthroughs image video speech audio processing learning method intends possibilities help translate sequential text descriptions images mented additional methods algorithms methods developed computer vision eld allowed researchers recent years create realistic images plain sentences advances computer vision deep convolutional nets semantic units shined light redirected cus research area text image synthesis having prime directive aid generation compelling images delity text descriptions possible date models generating synthetic images textual natural language research ratories universities private companies yielded compelling images owers birds reed owers birds common objects studied far research applied classes example studies focused solely human faces reed wang yin fascinating time computer vision deep learning researchers enthusiasts consistent advancement hardware software contemporaneous development computer vision research disrupts multiple industries advances technology allow extraction data types variety sources example image data captured variety photo ready devices smart phones online social media services opened door analysis large amounts media datasets fang availability large media datasets allow new frameworks algorithms proposed tested real world data text image synthesis benchmark datasets summary reviewed methods benchmark datasets validation reported table addition performance different gans respect benchmark datasets performance metrics reported table order synthesize images text descriptions frameworks taken minimalistic proach creating small background images mao cases experiments conducted simple datasets initially containing images birds owers reed contributed data sets adding corresponding natural language text descriptions subsets cub mscoco datasets facilitated work text image synthesis papers released recently deep learning algorithms use mnist lecun cortes dataset mark main datasets commonly evaluation proposed gan models text image synthesis cub wang oxford nilsback zisserman coco lin krizhevsky cub wang contains birds matching text descriptions oxford nilsback zisserman contains categories ers images matching text descriptions datasets contain individual jects text description corresponding object making relatively simple coco lin complex containing images different object types krizhevsky dataset consists colour images classes ages class contrast cub oxford images contain individual object coco images contain multiple objects label labels image total number labels images million lin text image synthesis benchmark evaluation metrics evaluation metrics judging images produced text image gans proposed salimans inception scores calculates entropy randomness conditional distribution obtained applying inception model introduced szegedy marginal distribution large set generated images low high respectively ful images low entropy conditional distribution means evaluator condent images came data distribution high entropy marginal distribution means set generated images diverse desired features score computed divergence entropies fcn scores isola computed similar manner relying intuition realistic images generated gan able classied correctly classier trained real images distribution fcn classier classies set synthetic images accurately image probably realistic corresponding gan gets high fcn score frechet inception distance fid heusel commonly uation metric takes different approach actually comparing generated images real images distribution high fid means little relationship statistics synthetic real images vice versa lower fids better performance different gans respect benchmark datasets performance metrics reported table addition figure lists performance gans respect inception scores table summary performance different methods respect benchmark datasets performance metrics inception score frechet inception distance fid human classier ssim scores generative adversarial networks inlcude dcgan gan int cls gan paired gan stackgan attngan objgan hdgan gan tac gan text segan scene graph gan mirrorgan benchmark datasets include cub oxford coco datasets dash indicates data found methods dcgan gan int cls dong gan paired gan stackgan obj gan hdgan gan tac gan text segan scene graph gan mirrorgan cub datasets metrics coco oxford fid ssim fid ssim fid ssim gan based text image synthesis results comparison gathered data scores model cub oxford coco datasets fid fcn human classiers unfortunately unable certain data hdgan missing table best evaluation missing data opinions looking examples generated images provided papers regard observed hdgan produced relatively better visual results cub oxford datasets attngan produced far impressive results rest complex coco dataset evidence attentional model damsm introduced attngan effective producing high quality images examples best results birds plates vegetables generated model presented figures respectively terms inception score metric applied majority models gan results table showed slight improvement decessor stackgan text image synthesis introduce worthy enhancement unconditional image generation organizing generators discriminators tree like structure indicates revising structures discriminators generators bring moderate level improvement text image synthesis addition results table gan zhu best mance followed obj gan notice gan obj gan recently developed methods eld published indicating research text image synthesis continuously improving results better visual perception interception nical wise gan zhu model dynamic memory rene fuzzy image contents initially generated gan networks memory writing gate gan select portant text information generate images based selected text accordingly hand obj gan focuses object centered text image synthesis proposed framework obj gan consists layout generation including bounding box generator shape generator object driven attentive image generator designs advancement gan gan indicate research text image synthesis advancing emphasis image details text semantics better understanding perception notable mentions worth noting survey mainly focuses text image synthesis applications gans broader image synthesis eld found fascinating worth cub coco oxford ong paired stack stack attn scene raph irror text figure performance comparison gans respect inception scores figure examples best images birds generated gan int cls stackgan hdgan images reprinted zhang zhang respectively ing small section example yin sem latent gans generate images faces based facial attributes producing impressive results glance mistaken real faces fang karpathy fei fei demonstrated great success erating text descriptions images image captioning great accuracy attention based model automatically learns focus salient objects karpathy fei fei deep visual semantic alignments finally contribution mentioned dedicated section relation unconditional image generation opposed conditional color regularization term zhang additional term aims samples generated input different stages consistent color resulted signicantly better results unconditional model conclusion recent advancement text image synthesis research opens door compelling ods architectures main objective text image synthesis initially create images figure examples best images plate vegetables generated gan int cls stackgan hdgan images reprinted zhang zhang respectively simple labels objective later scaled natural languages paper reviewed novel methods generate opinion visually rich photo realistic images text based natural language generated images rely generative adversarial networks gans deep convolutional decoder networks multimodal learning methods paper rst proposed taxonomy organize gan based text image synthesis works major groups semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gans taxonomy provides clear roadmap motivations architectures difference different methods outlines evolution timeline relationships following proposed taxonomy reviewed important features method architectures indicated model denition key contributions advanced gan framworks including stackgan attngan gan gan gan hdgan text segan storygan solutions surveyed paper tackled highly complex challenge generating photo realistic images swatch size samples words work reed images generated text tiny swatches lastly methods evaluated datasets included birds owers humans miscellaneous elements able allocate important papers impressive papers nally surveyed notable papers contribute directly indirectly expansion vast computer vision eld looking future excellent extension works surveyed paper independence learning ods human intervention involved studies increasing size output images acknowledgements conflict interest references authors declare conict interest publication article asmuth dixon hanna hsu kumar paragano pope samarasekera sawhney multimedia applications computer vision proceedings fourth ieee workshop applications computer vision cat princeton usa volume doi acv pages baltrusaitis ahuja morency multimodal machine learning survey omy corr arxiv bengio courville vincent representation learning review new tives ieee transactions pattern analysis machine intelligence burt adelson laplacian pyramid compact image code ieee transactions cha gown kung adversarial learning semantic relevance text communications image synthesis aaai cha gwon kung adversarial nets perceptual losses text image synthesis ieee international workshop machine learning signal processing mlsp pages ieee cha gwon kung adversarial nets perceptual losses text image synthesis ieee international workshop machine learning signal processing mlsp tokyo japan pages cha gwon kung adversarial learning semantic relevance text image synthesis proceedings association advancement articial intelligence aaai chen shen gao liu liu language based image editing recurrent attentive models proc eee cvf conference computer vision pattern recognition chen lai liu cartoongan generative adversarial networks photo cartoonization ieee cvf conference computer vision pattern recognition cvpr lake salt city usa creswell white dumoulin arulkumaran sengupta bharath tive adversarial networks overview ieee signal processing magazine pages dash gamboa ahmed afzal liwicki tac gan text conditioned auxiliary classier generative adversarial network corr arxiv dash gamboa ahmed liwicki afzal tac gan text conditioned auxiliary classier generative adversarial network arxiv preprint denton chintala szlam fergus deep generative image models laplacian pyramid adversarial networks corr arxiv denton chintala szlam fergus deep generative image models laplacian pyramid adversarial networks cortes lawrence lee sugiyama garnett editors advances neural information processing systems pages curran associates inc dong guo semantic image synthesis adversarial learning proceedings ieee international conference computer vision pages dong zhang mcilwraith guo learning text image synthesis textual data augmentation ieee international conference image processing icip beijing china pages durugkar gemp mahadevan generative multi adversarial networks elgammal liu elhoseiny mazzone creative adversarial networks generating art learning styles deviating style norms corr arxiv ieee international conference image processing icip athens greece volume doi icip pages image captioning word level attention fang wang tang gao chen song zhang shen perceptual pyramid ial networks text image synthesis proceedings association advancement articial intelligence aaai goodfellow pouget abadie mirza warde farley ozair courville bengio generative adversarial networks proceedings nips han zhu convolutional neural network learning generic data classication information sciences haynes norton mcparland cooper speech text broadcasters research implementation smpte motion imaging journal heusel ramsauer unterthiner nessler hochreiter gans trained time scale update rule converge local nash equilibrium corr arxiv hong yang choi lee inferring semantic layout hierarchical text image synthesis corr arxiv hong hwang yoo yoon generative adversarial networks variants work overview acm computing surveys csur huang wang introduction image synthesis generative adversarial nets corr arxiv huang poursaeed hopcroft belongie stacked generative adversarial networks ieee conference computer vision pattern recognition pages isola zhu zhou efros image image translation conditional adversarial networks corr arxiv johnson alahi fei fei perceptual losses real time style transfer resolution european conference computer vision pages springer johnson gupta fei fei image generation scene graphs proceedings cvpr karpathy fei fei deep visual semantic alignments generating image descriptions ieee transactions pattern analysis machine intelligence krizhevsky master thesis dept computer science univ toronto kumar sotelo kumar brebisson bengio obamanet photo realistic lip sync text arxiv preprint lecun cortes mnist handwritten digit database liu text text generative adversarial networks international joint conference neural networks ijcnn rio janeiro pages wang fast converging conditional generative adversarial networks ieee international conference image processing icip athens greece image synthesis pages zhang zhang huang lyu gao object driven text image synthesis adversarial training corr gan shen liu cheng carin carlson gao gan sequential conditional gan story visualization proceedings ieee conference computer vision pattern recognition pages min shen carlson carin video generation text second aaai conference articial intelligence lin maire belongie bourdev girshick hays perona ramanan zitnick dollar microsoft coco common objects context corr arxiv liu meng xiang pan semantic image synthesis conditional international conference pattern recognition icpr generative adversarial networks beijing china pages mansimov parisotto salakhutdinov generating images captions attention corr arxiv mao xie lau wang smolley squares generative adversarial networks ieee international conference computer vision iccv venice pages mirza osindero conditional generative adversarial nets corr arxiv arxiv preprint mirza osindero conditional generative adversarial nets ngiam khosla kim nam lee multimodal deep learning proceedings international conference international conference machine learning omnipress usa pages nguyen phung dual discriminator generative adversarial nets proc nips nie trullo petitjean ruan shen medical image synthesis aware generative adversarial networks corr arxiv nilsback zisserman automated ower classication large number classes proceedings indian conference computer vision graphics image processing odena olah shlens conditional image synthesis auxiliary classier gans corr arxiv odena olah shlens conditional image synthesis auxiliary classier gans proceedings international conference machine learning volume pages jmlr org park yoo kwak gan multi conditional generative adversarial network image synthesis arxiv preprint qiao zhang tao mirrorgan learning text image generation redescription corr radford metz chintala unsupervised representation learning deep lutional generative adversarial networks corr arxiv reed akata mohan tenka schiele lee learning draw proc nips international conference reed akata yan logeswaran schiele lee generative adversarial text image synthesis proceedings international conference machine learning icml salimans goodfellow zaremba cheung radford chen improved techniques training gans corr arxiv schuster paliwal bidirectional recurrent neural networks ieee transactions signal processing stoll camgoz hadeld bowden sign language production neural machine translation generative adversarial networks bmvc page szegedy vanhoucke ioffe shlens rethinking inception architecture computer vision ieee conference computer vision pattern recognition pages sugimoto paired gan semantic image synthesis asian conference computer vision pages springer wang gou duan lin zheng wang caltech ucsd dataset computation neural systems technical report cns wang gou duan lin zheng wang generative adversarial networks introduction outlook ieee caa journal automatica sinica wang wan sentigan generating sentimental texts mixture adversarial networks proceedings seventh international joint conference articial intelligence wang gupta generative image modeling style structure adversarial works corr arxiv wang chang cheng jin cheng learning face sketch facial attribute text ieee international conference image processing icip athens greece pages hall survey image synthesis editing generative adversarial networks tsinghua science technology kiros cho courville salakhutdinov zemel bengio attend tell neural image caption generation visual attention corr arxiv zhang huang zhang gan huang attngan fine grained text image generation attentional generative adversarial networks corr arxiv yan yang sohn lee conditional image generation visual attributes leibe matas sebe welling eds computer vision eccv eccv lecture notes computer science springer cham volume yan zhang wang paris automatic photo adjustment deep neural networks acm transactions graphics tog yang kannan batra parikh gan layered recursive generative adversarial networks image generation corr arxiv yang zhao feng zhao chen lei multitask learning cross domain image captioning ieee transactions multimedia yin sigaly xue semi latent gan learning generate modify facial images attributes corr arxiv zhang yin zhu zhang network representation learning survey ieee transactions big data doi tbdata zhang cui stable improved generative adversarial nets gans proceedings international conference image processing pages constructive survey zhang zhang wang huang metaxas realistic image synthesis stacked generative adversarial networks ieee transactions pattern analysis machine intelligence zhang zhang wang huang metaxas stackgan text photo realistic image synthesis stacked generative adversarial networks ieee international conference computer vision iccv venice pages zhang zhai luo zhan chen recent advance generative adversarial networks proceedings international conference machine learning cybernetics pages zhang xie yang photographic text image synthesis nested adversarial network corr arxiv zhu pan chen yang gan dynamic memory generative adversarial networks text image synthesis proceedings ieee conference computer vision pattern recognition pages zhu goldberg eldawy dyer strock text picture synthesis system augmenting communication prof aaai international conference pages
