t c o v c s c v v x r survey taxonomy adversarial neural networks text image synthesis jorge jonathan haicheng xingquan computer electrical engineering computer science florida atlantic university boca raton fl usa email edu edu edu provincial key laboratory e business nanjing university finance economics nanjing china email ustc edu abstract text image synthesis refers computational methods translate human written textual tions form keywords sentences images similar semantic meaning text earlier research image synthesis relied mainly word image correlation analysis combined supervised methods nd best alignment visual content matching text recent progress deep learning dl brought new set unsupervised deep learning methods particularly deep erative models able generate realistic visual images suitably trained neural network models change direction computer vision based approaches articial intelligence ai driven methods ignited intense interest industry virtual reality recreational professional esports gaming computer aided design automatically generate compelling images text based natural language descriptions paper review recent development text image synthesis research domain goal provide value delivering comparative review state art models terms architecture design survey rst introduces image synthesis challenges reviews key concepts generative adversarial networks gans deep convolutional decoder neural networks dcnn propose taxonomy summarize gan based text image synthesis major categories semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gans elaborate main tive group review typical gan architectures group taxonomy review outline techniques evolution different approaches eventually provide clear roadmap summarize list contemporaneous solutions utilize gans dcnns generate enthralling results categories human faces birds owers room interiors object tion edge maps games survey conclude comparison proposed solutions challenges remain unresolved future developments text image synthesis domain text image synthesis generative adversarial network gan deep learning machine keywords learning introduction gans variations proposed interesting idea years ml opinion yann lecun picture worth thousand words written text provide efcient effective concise ways communication visual content images comprehensive accurate wiley interdisciplinary reviews data mining knowledge discovery equally contributing authors figure early research text image synthesis zhu et al system uses correlation keywords keyphrase images identies informative picturable text units searches likely image parts conditioned text eventually optimizes picture layout conditioned text image parts ligible method information sharing understanding generation images text descriptions e text image synthesis complex computer vision machine learning problem seen great progress recent years automatic image generation natural language allow users describe visual elements visually rich text descriptions ability effectively highly desirable articial intelligence applications computer aided design image editing chen et al yan et al game engines development generation video et al pictorial art generation elgammal et al traditional learning based text image synthesis early stages research text image synthesis mainly carried search order connect supervised learning combined process zhu et al shown figure text descriptions images use correlation keywords keyphrase images identies informative picturable text units units search likely image parts conditioned text eventually optimizing picture layout conditioned text image parts methods integrated multiple articial intelligence key components including natural language processing computer vision computer graphics machine learning major limitation traditional learning based text image synthesis approaches lack ability generate new image content change characteristics given training images alternatively research generative models advanced signicantly delivers solutions learn training images produce new visual content example yan et al models image composite foreground background addition layered generative model disentangled latent variables learned variational encoder generate visual content learning customized conditioned given attributes generative models generate images respect different attributes gender hair color age shown figure gan based text image synthesis generative model based text image synthesis provides realistic image synthesis results image generation conditioned limited attributes recent years papers published subject text image synthesis contributions papers rely multimodal learning approaches include generative adversarial networks deep figure supervised learning based text image synthesis yan et al supervised ing process aims learn layered generative models generate visual content learning customized conditioned given attributes generative models generative images respect different attributes hair color age figure generative adversarial neural network gan based text image synthesis huang et al gan based text image synthesis combines discriminative generative learning train neural networks resulting generated images semantically resemble training samples lored subset training images e conditioned outputs feature embedding function converts text feature vector z latent vector following normal distributions zero mean denotes synthetic image generated generator latent vector z text features input d denotes prediction discriminator based input x generated image text information generated image explanations generators discriminators detailed section figure visual summary gan based text image synthesis process summary gan based frameworks methods reviewed survey convolutional decoder networks main drivers generate entrancing images text wu et al reed et al goodfellow et al xu et al odena et al introduced ian goodfellow et al goodfellow et al generative adversarial networks gans consist neural networks paired discriminator generator models compete generator attempting produce synthetic fake samples fool discriminator discriminator attempting differentiate real genuine synthetic samples gans adversarial training aims cause generators produce images similar real training images gans naturally generate synthetic images image synthesis process customized text descriptions specify types images generate shown figure like text speech speech text conversion exists wide variety problems text image synthesis solve computer vision eld specically reed et al haynes et al nowadays researchers attempting solve plethora computer vision lems aid deep convolutional networks generative adversarial networks combination multiple methods called multimodal learning methods reed et al simplicity multiple learning methods referred multimodal learning ngiam et al searchers describe multimodal learning method incorporates characteristics methods algorithms ideas include ideas learning approaches order create robust implementation solve uncommon problem improve solution reed et al yang et al li et al dash et al baltrusaitis et al survey focus primarily reviewing recent works aim solve challenge text image synthesis generative adversarial networks gans order provide clear roadmap propose taxonomy summarize reviewed gans major categories review elaborate motivations methods category analyze typical models network architectures possible drawbacks improvement visual abstract survey list reviewed gan frameworks shown figure remainder survey organized follows section presents brief summary existing works subjects similar paper highlights key distinctions making unique section gives short introduction gans preliminary concepts related image generation engines text image synthesis possible essential building blocks achieve photo realistic images text descriptions section proposes taxonomy summarize gan based text image synthesis discusses models architectures novel works focused solely text image synthesis section draw key contributions works relation applications section reviews gan based text image synthesis benchmarks performance metrics comparisons including simple review gans applications section conclude brief summary outline ideas future interesting developments eld image synthesis related work growth success gans deep convolutional decoder networks multimodal ing methods techniques rst procedures aimed solve challenge image synthesis engineers scientists computer vision ai contributed tensive studies experiments numerous proposals publications detailing contributions gans introduced goodfellow et al emerging research topics practical applications image synthesis infancy recently new gan architectures signs proposed use gans different applications e gans generate tal texts wang wan gans transform natural images cartoons chen et al gans increasingly popular survey papers currently exist marize outline contemporaneous technical innovations contributions different gan tures hong et al creswell et al survey papers specically attuned analyzing different contributions text image synthesis gans scarce found surveys huang et al wu et al image synthesis gans closely related publications survey objective following paragraphs briey summarize surveys point objectives differ theirs huang et al authors provide overview image synthesis gans survey authors discuss motivations research image synthesis introduce ground information history gans including section dedicated core concepts gans generators discriminators min max game analogy enhancements inal gan model conditional gans addition variational auto encoders survey carry similar review background knowledge understanding preliminary concepts paramount rest paper types approaches image ation reviewed including direct methods single generator discriminator hierarchical methods generator discriminator pairs different goal iterative methods generator discriminator pair generates gradually higher resolution image following introduction huang et al discusses methods text image image image synthesis respectively describes evaluation metrics synthetic images including inception scores frechet inception distance fid explains signicance discriminators acting learned loss tions opposed xed loss functions different survey relatively broad scope gans objective heavily focused text image synthesis topic text image synthesis ered huang et al detailed fashion listing different works time sequential order comparison review representative methods eld outline models contributions detail similarly huang et al second survey paper wu et al begins standard introduction addressing motivation image synthesis challenges presents followed section dedicated core concepts gans enhancements original gan model addition paper covers review types applications unconstrained applications image thesis super resolution image inpainting constrained image synthesis applications image image text image sketch image discusses image video editing gans scope paper intrinsically comprehensive focus specically text image detail contributions novel state art models surveys published related matters mainly related advancements plications gans zhang et al found prior works focus specically text image synthesis gans knowledge rst paper preliminaries frameworks section rst introduce preliminary knowledge gans commonly variants conditional gan e cgan building block gan based text image synthesis models briey separate gan based text image synthesis types simple gan frameworks vs advanced gan frameworks discuss advanced gan architecture image synthesis notice simple vs advanced gan framework separation brief taxonomy section propose taxonomy summarize advanced gan frameworks categories based objective designs generative adversarial neural network moving discussion analysis works applying gans text image synthesis preliminary concepts enhancements gans datasets evaluation metrics present works described section worth introducing stated previously gans introduced ian goodfellow et al goodfellow et al consist deep neural networks generator discriminator trained pendently conicting goals generator aims generate samples closely related original data distribution fool discriminator discriminator aims distinguish samples generator model samples true data distribution calculating probability sample coming source conceptual view generative adversarial network gan architecture shown figure training gans iterative process iteration updates generator discriminator goal defeating leading model increasingly adept specic task threshold reached analogous min max game models according following equation min g max d v dd gg dd eq denotes multi dimensional sample e image z denotes multi dimensional latent space vector e multidimensional data point following predened distribution function normal distributions dd denotes discriminator function controlled parameters d aims classify sample binary space gg denotes generator function controlled parameters g aims generate sample latent space vector example means latent vector z generate synthetic fake image dd means classify image binary output e true false gan setting discriminator dd learned distinguish genuine true image labeled fake images labeled given true image ideal output discriminator dd given fake image generated generator ideal prediction discriminator dd gg z indicating sample fake image following denition min max objective function eq aims learn parameters discriminator generator g reach optimization goal discriminator intends differentiate true vs fake images maximum capability maxd generator intends minimize difference fake image vs true image ming words discriminator sets characteristics generator produces elements images iteratively meets attributes set forth discriminator gans images visual elements notoriously efcient generating compelling convincing photorealistic images recently gans generate original painting unsupervised fashion radford et al following sections detail generator discriminator trained gans generator image synthesis generator network thought mapping representation space latent space actual data creswell et al comes image synthesis images data space fall distribution complex dimensional feature space sampling complex space difcult gans instead train generator create synthetic images simple feature space usually random noise called latent space generator network performs sampling latent space usually real data sample real data sigmoid function real fake random noise vector z fake sample generator figure conceptual view generative adversarial network gan architecture generator trained generate synthetic fake resemble real samples random noise distribution fake samples fed discriminator real samples discriminator trained differentiate fake samples real samples iterative training generator discriminator helps gan deliver good generator generating samples close underlying training samples deep neural network consisting convolutional fully connected layers creswell et al generator trained gradient descent update weights generator network aim producing data case images discriminator classies real discriminator discriminator network thought mapping image data probability image coming real data space generally deep neural network consisting convolution fully connected layers discriminator performs sampling opposed sampling like generator trained gradient descent goal update weights likely correctly classify images real fake gans ideal outcome generator s discriminator s cost functions converge generator produces photo realistic images indistinguishable real data discriminator time expert differentiating real synthetic data possible reduction cost model generally leads increase cost phenomenon makes training gans difcult training simultaneously models performing gradient descent parallel leads stable orbit model able converge combat generator discriminator trained independently case gan remains different training stages stage weights generator kept constant gradient descent updates weights discriminator stage weights discriminator kept constant gradient descent updates weights generator repeated number epochs desired low cost model reached salimans al cgan conditional gan conditional generative adversarial networks cgan enhancement gans proposed mirza osindero shortly introduction gans goodfellow et al objective function cgan dened eq similar gan objective function eq inputs discriminator generator conditioned class label min g max d v dd gg e e dd main technical innovation cgan introduces additional input inputs original gan model allowing model trained information class labels conditioning variables samples concurrently original gan trained samples data distribution resulting generated sample reecting general data distribution cgan enables directing model generate tailored outputs sample real data real bird images sigmoid function real fake random noise vector z fake sample generator condition vector y bird figure conceptual view conditional gan architecture generator generates samples random noise distribution condition vector case text fake samples fed discriminator real samples condition vector discriminator calculates probability fake sample came real data distribution figure condition vector class label text string red bird fed generator discriminator important condition vector related real data model figure trained set real data red birds condition text yellow sh generator learn create images red birds conditioned text yellow sh note condition vector cgan come forms texts limited class label unique design provides direct solution generate images conditioned predened specications result cgan text image synthesis rst day invention modern approaches deliver better text image synthesis results simple gan frameworks text image synthesis order generate images text simple solution employ conditional gan cgan designs add conditions training samples gan trained respect underlying conditions pioneer works followed similar designs text image synthesis essential disadvantage cgan text image synthesis handle complicated textual descriptions image generation cgan uses labels conditions strict gan inputs text inputs multiple keywords long text descriptions simultaneously restrict input instead text conditions proaches reed et al dash et al use text input features concatenate features features train discriminator generator shown figure c ensure text gan input feature embedding feature representation learning bengio et al zhang et al function introduced convert input text numeric features concatenated features train gans advanced gan frameworks text image synthesis motivated gan conditional gan cgan design gan based frameworks proposed generate images different designs architectures multiple tors progressively trained discriminators hierarchical discriminators figure outlines advanced gan frameworks literature addition frameworks news figure simple architecture comparisons ve gan networks text image synthesis gure explains texts fed input train gan generate images conditional gan cgan mirza osindero use labels condition input generator inator nal output discriminator similar generic gan manifold interpolation aware discriminator gan gan int cls reed et al feeds text input generator discriminator texts preprocessed embedding features function concatenated input feeding generator discriminator nal output discriminator similar generic gan auxiliary classier gan ac gan odena et al uses auxiliary sier layer predict class image ensure output consists images different classes resulting diversied synthesis images text conditioned auxiliary classier gan gan dash et al share similar design gan int cls output include discriminator classier classication e text conditioned semantic classier gan text segan cha et al uses regression layer estimate semantic vance image generated images limited certain classes semantically matching text input figure high level comparison advanced gans framework text image synthesis frameworks text red triangle input generate output images left right uses multiple discriminators generator durugkar et al nguyen et al b uses multiple stage gans output gan fed gan input zhang et al denton et al c progressively trains symmetric discriminators generators huang et al d uses single stream generator hierarchically nested discriminator trained end end zhang et al signs proposed advance eld sophisticated designs example recent work gao et al proposes use pyramid generator independent discriminators focusing different aspect images lead generator creating images photo realistic multiple levels recent publication cha et al proposes use criminator measure semantic relevance image text instead class prediction like discriminator gans resulting new gan structure outperforming text conditioned auxiliary classier tac gan dash et al generating diverse realistic relevant input text regardless class following section rst propose taxonomy summarizes advanced gan works text image synthesis review recent proposed solutions challenge ing photo realistic images conditioned natural language text descriptions gans solutions discuss selected based relevance quality contributions publications exist subject image generation gans paper focus specically models text image synthesis review emphasizing model contributions text image thesis end section briey review methods gans image synthesis applications text image synthesis taxonomy categorization section propose taxonomy summarize advanced gan based text image synthesis frameworks shown figure taxonomy organizes gan frameworks categories cluding semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gags following proposed taxonomy subsection introduce typical frameworks address techniques gans solve certain aspects text mage synthesis challenges gan based text image synthesis taxonomy ultimate goal text image synthesis generate images closely related textual descriptions relevance images texts validated different perspectives inherent diversity human perceptions example generating images matching description rose owers users know exact type owers like intend generate rose owers similar colors users seek generate high quality rose owers nice background e garden group users interested generating owers similar rose different colors visual appearance e roses begonia peony fourth group users want generate ower images use form meaningful action e video clip showing ower growth performing magic owers telling love story owers text image synthesis point view rst group users intend precisely control semantic generated images goal match texts images semantic level second group users focused resolutions qualify images addition requirement images texts semantically related group users goal diversify output images images carry diversied visual appearances semantically related fourth user group adds new dimension image synthesis aims generate sequences images coherent temporal order e capture motion information based descriptions categorize gan based text image synthesis taxonomy major categories shown fig semantic enhancement gans semantic enhancement gans represent pioneer works gan frameworks text image synthesis main focus gan frameworks ensure generated images semantically related input texts objective mainly achieved neural network encode texts dense features fed second network generate images matching texts resolution enhancement gans resolution enhancement gans mainly focus generating high qualify images semantically matched texts mainly achieved multi stage gan framework outputs earlier stage gans fed second later stage gan generate better qualify images diversity enhancement gans diversity enhancement gans intend diversify output ages generated images semantically related different types visual appearance objective mainly achieved additional component timate semantic relevance generated images texts order maximize output diversity motion enhancement gans motion enhancement gans intend add temporal dimension output images form meaningful actions respect text descriptions goal mainly achieved step process rst generates images matching actions texts followed mapping alignment procedure ensure images coherent temporal order following introduce gan frameworks evolve text image synthesis review typical methods category semantic enhancement gans semantic relevance important criteria text image synthesis gnas discussed survey required generate images semantically related text tions semantic relevance subjective measure images inherently rich terms semantics interpretations gans proposed enhance text image synthesis different perspectives subsection review classical approaches commonly served text image synthesis baseline dc gan deep convolution generative adversarial network dc gan reed et al represents pioneer work text image synthesis gans main goal train deep convolutional generative adversarial network dc gan text features process text features encoded neural network neural network hybrid convolutional recurrent network character level concurrently neural networks feed forward inference way condition text features generating realistic images automatically natural language text motivation works proposed computer vision eld actual articial intelligence ai figure taxonomy categorization advanced gan frameworks text image synthesis categorize advanced gan frameworks major categories semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gags relationship relevant frameworks publication date outlined reference systems far achieving task reed et al liu et al yang et al li et al wang gupta zhang et al mirza osindero lately recurrent ral networks led way develop frameworks learn discriminatively text features time generative adversarial networks gans began recently promise generating compelling images host elements including limited faces birds owers common images room et al dc gan multimodal learning model attempts bridge mentioned unsupervised machine learning algorithms recurrent neural networks rnn generative adversarial networks gans sole purpose speeding generation text image synthesis deep learning shed light sophisticated advances natural language resentation image synthesis wu et al reed et al wang et al huang et al classication generic data han et al bulk latest breakthroughs deep learning computer vision related supervised learning reed et al natural language image synthesis contributions supervised deep learning unsupervised learning saw recently tremendous rise input research community specially subproblems text based natural language image synthesis dong et al yang et al reed et al cha et al zhang et al subproblems typically subdivided focused research areas dc gan s contributions mainly driven research areas order generate plausible images natural language dc gan contributions revolve developing straightforward effective gan architecture training strategy allows natural text image synthesis contributions primarily tested caltech ucsd birds flowers datasets image datasets carry ve text descriptions text descriptions created research team setting evaluation environment gans model subsequently trained subcategories subcategories research represent training testing sub datasets performance shown experiments display promising effective way generate images textual natural language descriptions reed et al dc gan extensions following pioneer dc gan framework reed et al researches propose revised work structures e different discriminaotrs order improve images better semantic relevance texts based deep convolutional adversarial network dc gan network architecture gan cls image text matching discriminator gan int learned text manifold interpolation gan int cls combines proposed nd semantic match text age similar dc gan architecture adaptive loss function e perceptual loss johnson et al proposed semantic image synthesis synthesize realistic image matches target text description irrelavant background source images dong et al perceptual losses loss functions e pixel struction loss activation reconstruction loss texture reconstruction loss proposed cha et al construct network architectures based dc gan e gan int dong et al pixel gan int cls vgg gan int cls gram respect losses residual transformation unit added network retain similar structure source image following dong et al considering features early layers address background foreground obtained layers cnn pair discriminators different architectures e paired d gan proposed synthesize background foreground source image ately vo sugimoto skip connection generator employed precisely retain background information source image mc gan synthesising images text image synthesis methods consider output image single unit characterize semantic relevance texts likely problematic images naturally consist crucial components foreground background properly separating components s hard characterize semantics image image treated single unit proper separation order enhance semantic relevance images multi conditional gan gan park et al proposed synthesize target image combining background source image text described foreground object exist source image unique feature mc gan proposes synthesis block background feature extracted given image non linear function e convolution batch normalization foreground feature feature map previous layer mc gan able properly model background foreground generated images unique strength mc gan users able provide base image mc gan able preserve background information base image generate new images resolution enhancement gans fact training gans difcult generating high resolution images stage gan e proposed rough e low resolution images generated stage rened stage ii improve quality generated images second version stackgan e proposed use multi stage gans generate multi scale images color consistency regularization term added loss consistency images different scales stackgan built global sentence vector posed use attention mechanism e deep attentional multimodal similarity model damsm model multi level information e word level sentence level gans following stackgan explained detail recently dynamic memory generative adversarial network e dm et al uses dynamic memory component proposed focus reningthe initial generated image key success generating high quality images stackgan zhang et al proposed model generating photo realistic images text descriptions called stackgan stacked generative adversarial network zhang et al work dene stage model uses cascaded gans corresponding stages stage gan takes text description input converts text description text embedding containing conditioning variables generates low quality image rough shapes colors based computed conditioning variables stage ii gan takes low quality stage image text embedding uses conditioning variables correct add detail stage result output stage ii photorealistic image resembles text description compelling accuracy major contribution stackgan use cascaded gans text image synthesis sketch renement process conditioning stage ii gan image produced stage gan text description stage ii gan able correct defects stage output resulting high quality images prior works utilized stacked gans separate age generation process structure style wang gupta multiple stages generating lower level representations higher level representations previous stage huang et al multiple stages combined laplacian pyramid approach denton et al troduced image compression p burt e adelson uses differences consecutive samples original image reconstruct original image sampled version burt adelson works use text descriptions condition generator models conditioning augmentation major contribution stackgan prior works transformed natural language text description xed text embedding containing static conditioning variables fed generator reed et al stackgan creates gaussian distribution text embedding randomly selects variables gaussian distribution add set conditioning variables training encourages robustness introducing small variations original text embedding particular training image keeping training image generated output compared result trained model produces diverse images distribution conditioning augmentation model xed text embedding zhang et al proposed users stackgan stacked gan model organizes generators discriminators tree like structure zhang et al multiple stages rst stage combines noise vector conditioning variables conditional augmentation introduced zhang et al input rst generator generates low resolution image default changed depending desired number stages lowing stage uses result previous stage conditioning variables produce gradually higher resolution images stages use noise vector creators assume randomness introduces preserved output rst stage nal stage produces high quality image introduces joint conditional unconditional approximation designs zhang et al discriminators trained calculate loss image produced generator conditioning variables measuring accurately image represents scription loss image real images probability image real fake generators aim minimize sum losses improving nal result attentional generative adversarial network xu et al similar terms structure zhang et al discussed previous section novel ponents added like previous works reed et al zhang et al text encoder generates text embedding conditioning variables based overall sentence additionally text encoder generates separate text embedding conditioning variables based individual words process optimized produce meaningful variables bidirectional recurrent neural work brnn specically bidirectional long short term memory lstm schuster paliwal word description generates conditions based previous word word bidirectional rst stage generates low resolution image based sentence level text embedding random noise vector output fed level text embedding attention model matches word level conditioning variables regions stage image producing word context matrix fed stage model raw previous stage output consecutive stage works manner produces gradually higher resolution images conditioned previous stage major contributions introduced attngan attentional generative network deep attentional multimodal similarity model damsm zhang et al attentional ative network matches specic regions stage s output image conditioning variables word level text embedding worthy contribution allowing consecutive stage focus specic regions image independently adding attentional details region region opposed image damsm key feature introduced result nal stage calculate similarity generated image text embedding sentence level ne grained word level table shows scores different metrics stackgan attngan hdgan cub oxford coco datasets table shows outperforms models terms cub dataset small greatly outperforms coco dataset hdgan hierarchically nested adversarial network hdgan method proposed zhang et al main objective tackle difcult problem dealing photographic images semantic text descriptions semantic text descriptions applied images diverse datasets method introduces adversarial objectives nested inside hierarchically oriented networks zhang et al hierarchical networks helps regularize mid level manifestations addition regularize level manifestations assists training generator order capture highly complex media elements elements captured statistical order train generator based settings tracted directly image ideal scenario paper aims incorporate single stream architecture single stream architecture functions generator form optimum adaptability jointed discriminators jointed discriminators setup optimum manner single stream architecture advance generated images achieve higher resolution zhang et al main contributions hdgans include introduction visual semantic similarity sure zhang et al feature aid evaluation consistency generated images addition checking consistency generated images key objectives step test logical consistency end product zhang et al end product case images semantically mapped text based natural language descriptions area picture e wing bird petal ower deep learning created multitude opportunities challenges researchers computer vision ai eld coupled gan multimodal ing architectures eld seen tremendous growth reed et al liu et al yang et al li et al wang gupta zhang et al mirza osindero based advancements hdgans attempt extend desirable common features generating images textual natural language zhang et al words takes sentences treats hierarchical structure positive negative implications cases starters makes complex generate compelling images key benets elaborate process realism obtained processes completed addition common feature added process ability identify parts sentences bounding boxes sentence includes common characteristics bird surround attributes bird bounding boxes practice happen desired image ements human faces e eyes hair owers e petal size color inanimate object e table mug finally hdgans evaluated claims common ideal text image datasets cub coco reed et al zhang et al liu et al yang et al li et al wang gupta zhang et al mirza osindero datasets rst utilized earlier works reed et al sport modied features image annotations labels descriptions qualitative quantitative results reported researchers study far superior earlier works eld computer vision ai diversity enhancement gans subsection introduce text image synthesis methods try maximize diversity output images based text descriptions ac gan issues arise traditional gans mirza osindero image synthesis bilirty problem traditional gans predict large number image categories diversity problem images subject mapping image labeled different tags described different texts address problems gan conditioned additional information e cgan alternative solution cgan previously troduced approaches able generate images respect text descriptions output images similar types visual appearance slightly different cgan auxiliary classier gans ac gan odena et al poses improve diversity output images auxiliary classier control output images overall structure ac gan shown fig ac gan generated image ated class label addition true fake label commonly gan cgan discriminator ac gan outputs probability distribution sources e image true fake output probability distribution class label e predict class image belong auxiliary classier layer predict class image ac gan able use predicted class labels images ensure output consists images different classes resulting diversied synthesis images results ac gan generate images high diversity tac gan building ac gan tac gan dash et al proposed replace class information textual descriptions input perform task text image synthesis architecture tac gan shown fig similar ac gan overall major difference tac gan ac gan tac gan conditions generated images text descriptions instead class label design makes tac gan generic image synthesis tac gan imposes restrictions generated images texts class labels input vector tac gan s generative network built based noise vector embedded vector tation textual descriptions discriminator tac gan similar ac gan predicts image fake predicts label images minor difference tac gan s discriminator compared ac gan receives text information input performing classication experiments validations owers dataset results produced tac gan slightly better approaches including gan int cls stackgan text segan order improve diversity output images ac gan tac gan s discriminators predict class labels synthesised images process likely enforces semantic diversity images class labels inherently restrictive describing image semantics images described text matched multiple labels instead predicting images class labels alternative solution directly quantify semantic relevance architecture text segan shown fig order directly quantify semantic evance text segan cha et al adds regression layer estimate semantic relevance image text instead classier layer predicting labels estimated semantic reference fractional value ranging higher value reecting better semantic relevance image text unique design inherent advantage text segan generated images limited certain classes semantically matching text input experiments validations ower dataset text segan generate diverse images semantically relevant input text addition results text segan improved inception score compared approaches including gan int cls stackgan tac gan hdgan mirrorgan scene graph gan inherent complexity visual images diversity text descriptions e words imply different meanings difculty precisely match texts visual images semantic levels methods discussed far employ direct text image generation process validation generated images comply text reverse fashion ensure semantic consistency diversity mirrorgan qiao et al employs ror structure reversely learns generated images output texts image text process validate generated consistent input texts mirrowgan includes modules semantic text embedding module stem global local collaborative attentive ule cascaded image generation glam semantic text regeneration alignment module stream text image image text t combined sively enhance diversity semantic consistency generated images order enhance diversity output image scene graph gan johnson et al poses use visual scene graphs describe layout objects allowing users precisely specic relationships objects images order convert visual scene graph input gan generate images method uses graph convolution process input graphs computes scene layout predicting bounding boxes segmentation masks objects converts computed layout image cascaded renement network motion enhancement gans instead focusing generating static images line text image synthesis research focuses generating videos e sequences images texts context synthesised videos useful resources automated assistance story telling obamanet early interesting work motion enhancement gans generate spoofed speech lip sync videos talking face barack obama e obamanet based text input kumar et al framework consisted parts e text speech mouth shape representation synced audio time delayed lstm video generation conditioned mouth shape u net architecture results promising obamanet models mouth region videos generated noise regarded video prediction video generation meaningful trial synthesised videos automated assistance translate spoken language e text sign language video sequences e stoll et al achieved step process converting texts meaningful units generate images followed learning component arrange images sequential order best representation ically rnn based machine translation methods texts translated sign language gloss quences glosses mapped skeletal pose sequences lookup table generate videos conditional dcgan input concatenation latent representation image base pose skeletal pose information built li et al text video model proposed based cgan input isometric gaussian noise text gist vector served generator key component generating videos text train conditional generative model extract static dynamic information text followed hybrid framework combining variational autoencoder vae generative adversarial network gan specically relies types features static features dynamic features erate videos static features called gist sketch text conditioned background color object layout structure dynamic features hand considered transforming input text image lter eventually forms video generator consists entangled neural networks text gist vector generated gist generator maintains static information e background captures dynamic information e actions text generate videos demonstrated paper li et al generated videos semantically related texts low quality e resolution storygan different generates videos single text storygan aims produce dynamic scenes consistent specied texts e story written multi sentence paragraph sequential gan model li et al story encoder context encoder discriminators main nents model stochastic sampling story encoder intends learn low dimensional embedding vector story continuity story context encoder posed capture contextual information sequential image generation based deep rnn discriminators storygan image discriminator evaluates generated images story discriminator ensures global consistency experiments comparisons clevr dataset pororo cartoon dataset inally visual question answering storygan improves generated video qualify terms structural similarity index ssim visual qualify consistence relevance measure based human evaluation table summary different gans datasets validation x symbol indicates model evaluated corresponding dataset method names cgan mirza osindero ac gan odena et al tac gan dash et al text segan cha et al gan int cls reed et al stackgan zhang et al zhang et al xu et al dc gan reed et al hdgan zhang et al mirrorgan qiao et al evaluation datasets mnist coco cub x x x x x x x x x x x x x x x x x x x x x x x x gan based text image synthesis applications mark evaluation comparisons text image synthesis applications computer vision applications strong potential industries including limited cal government military entertainment online social media elds wu et al nie et al hong et al mansimov et al asmuth et al fang et al text image sis application computer vision ai main focus recent years potential providing benecial properties opportunities wide range applicable areas text image synthesis application byproduct deep convolutional decoder networks bination gans wu et al reed et al xu et al deep convolutional networks contributed breakthroughs image video speech audio processing learning method intends possibilities help translate sequential text descriptions images mented additional methods algorithms methods developed computer vision eld allowed researchers recent years create realistic images plain sentences advances computer vision deep convolutional nets semantic units shined light redirected cus research area text image synthesis having prime directive aid generation compelling images delity text descriptions possible date models generating synthetic images textual natural language research ratories universities private companies yielded compelling images owers birds reed et al owers birds common objects studied far research applied classes example studies focused solely human faces wu et al reed et al wang et al yin et al s fascinating time computer vision ai deep learning researchers enthusiasts consistent advancement hardware software contemporaneous development computer vision ai research disrupts multiple industries advances technology allow extraction data types variety sources example image data captured variety photo ready devices smart phones online social media services opened door analysis large amounts media datasets fang et al availability large media datasets allow new frameworks algorithms proposed tested real world data text image synthesis benchmark datasets summary reviewed methods benchmark datasets validation reported table addition performance different gans respect benchmark datasets performance metrics reported table order synthesize images text descriptions frameworks taken minimalistic proach creating small background images mao et al cases experiments conducted simple datasets initially containing images birds owers reed et al contributed data sets adding corresponding natural language text descriptions subsets cub mscoco datasets facilitated work text image synthesis papers released recently deep learning algorithms use mnist lecun cortes dataset mark main datasets commonly evaluation proposed gan models text image synthesis cub wang et al oxford nilsback zisserman coco lin et al krizhevsky cub wang et al contains birds matching text descriptions oxford nilsback zisserman contains categories ers images matching text descriptions datasets contain individual jects text description corresponding object making relatively simple coco lin et al complex containing images different object types krizhevsky dataset consists colour images classes ages class contrast cub oxford images contain individual object coco s images contain multiple objects label labels image total number labels images million lin et al text image synthesis benchmark evaluation metrics evaluation metrics judging images produced text image gans proposed salimans et al inception scores calculates entropy randomness conditional distribution obtained applying inception model introduced szegedy et al marginal distribution large set generated images low high respectively ful images low entropy conditional distribution means evaluator condent images came data distribution high entropy marginal distribution means set generated images diverse desired features score computed divergence entropies fcn scores isola et al computed similar manner relying intuition realistic images generated gan able classied correctly classier trained real images distribution fcn classier classies set synthetic images accurately image probably realistic corresponding gan gets high fcn score frechet inception distance fid heusel et al commonly uation metric takes different approach actually comparing generated images real images distribution high fid means little relationship statistics synthetic real images vice versa lower fids better performance different gans respect benchmark datasets performance metrics reported table addition figure lists performance gans respect inception scores table summary performance different methods respect benchmark datasets performance metrics inception score frechet inception distance fid human classier hc ssim scores generative adversarial networks inlcude dcgan gan int cls gan paired d gan stackgan attngan objgan hdgan dm gan tac gan text segan scene graph gan mirrorgan benchmark datasets include cub oxford coco datasets dash indicates data found methods dcgan gan int cls dong gan paired d gan stackgan obj gan hdgan dm gan tac gan text segan scene graph gan mirrorgan cub datasets metrics coco oxford fid hc ssim fid hc ssim fid hc ssim gan based text image synthesis results comparison gathered data nd scores model cub oxford coco datasets fid fcn human classiers unfortunately unable nd certain data hdgan missing table best evaluation missing data opinions looking examples generated images provided papers regard observed hdgan produced relatively better visual results cub oxford datasets attngan produced far impressive results rest complex coco dataset evidence attentional model damsm introduced attngan effective producing high quality images examples best results birds plates vegetables generated model presented figures respectively terms inception score metric applied majority models dc gan results table showed slight improvement decessor stackgan text image synthesis introduce worthy enhancement unconditional image generation organizing generators discriminators tree like structure indicates revising structures discriminators generators bring moderate level improvement text image synthesis addition results table dm gan zhu et al best mance followed obj gan li et al notice dm gan obj gan recently developed methods eld published indicating research text image synthesis continuously improving results better visual perception interception nical wise dm gan zhu et al model dynamic memory rene fuzzy image contents initially generated gan networks memory writing gate dm gan select portant text information generate images based selected text accordingly hand obj gan li et al focuses object centered text image synthesis proposed framework obj gan consists layout generation including bounding box generator shape generator object driven attentive image generator designs advancement dm gan gan indicate research text image synthesis advancing emphasis image details text semantics better understanding perception notable mentions worth noting survey mainly focuses text image synthesis applications gans broader image synthesis eld found fascinating worth cub coco oxford s g n t c l s d c g n d ong g n paired d g n stack g n stack g n attn g n o bj g n h d g n m n t c g n d scene g raph g n m irror g n text se g n figure performance comparison gans respect inception scores figure examples best images birds generated gan int cls stackgan hdgan images reprinted zhang et al b xu et al zhang et al respectively ing small section example yin et al sem latent gans generate images faces based facial attributes producing impressive results glance mistaken real faces xu et al fang et al karpathy fei fei demonstrated great success erating text descriptions images image captioning great accuracy xu et al attention based model automatically learns focus salient objects karpathy fei fei deep visual semantic alignments finally contribution mentioned dedicated section relation unconditional image generation opposed conditional color regularization term zhang et al additional term aims samples generated input different stages consistent color resulted signicantly better results unconditional model conclusion recent advancement text image synthesis research opens door compelling ods architectures main objective text image synthesis initially create images figure examples best images plate vegetables generated gan int cls stackgan hdgan images reprinted zhang et al b xu et al zhang et al respectively simple labels objective later scaled natural languages paper reviewed novel methods generate opinion visually rich photo realistic images text based natural language generated images rely generative adversarial networks gans deep convolutional decoder networks multimodal learning methods paper rst proposed taxonomy organize gan based text image synthesis works major groups semantic enhancement gans resolution enhancement gans diversity enhancement gans motion enhancement gans taxonomy provides clear roadmap motivations architectures difference different methods outlines evolution timeline relationships following proposed taxonomy reviewed important features method architectures indicated model denition key contributions advanced gan framworks including stackgan attngan dc gan ac gan gan hdgan text segan storygan solutions surveyed paper tackled highly complex challenge generating photo realistic images swatch size samples words work reed et al images generated text tiny swatches lastly methods evaluated datasets included birds owers humans miscellaneous elements able allocate important papers impressive papers nally surveyed notable papers contribute directly indirectly expansion vast computer vision ai eld looking future excellent extension works surveyed paper independence learning ods e human intervention involved studies increasing size output images acknowledgements conflict interest references authors declare conict interest publication article asmuth j dixon d hanna k hsu s c kumar r paragano v pope samarasekera s sawhney h multimedia applications computer vision proceedings fourth ieee workshop applications computer vision cat princeton nj usa volume doi acv pages baltrusaitis t ahuja c morency l multimodal machine learning survey omy corr arxiv bengio y courville vincent p representation learning review new tives ieee transactions pattern analysis machine intelligence burt p adelson e laplacian pyramid compact image code ieee transactions cha m gown y l kung h t adversarial learning semantic relevance text communications image synthesis aaai cha m gwon y kung h adversarial nets perceptual losses text image synthesis ieee international workshop machine learning signal processing mlsp pages ieee cha m gwon y kung h t adversarial nets perceptual losses text image synthesis ieee international workshop machine learning signal processing mlsp tokyo japan pages cha m gwon y l kung h t adversarial learning semantic relevance text image synthesis proceedings association advancement articial intelligence aaai chen j shen y gao j liu j liu x language based image editing recurrent attentive models proc eee cvf conference computer vision pattern recognition chen y lai y liu y cartoongan generative adversarial networks photo cartoonization ieee cvf conference computer vision pattern recognition cvpr lake salt city usa creswell white t dumoulin v arulkumaran k sengupta b bharath tive adversarial networks overview ieee signal processing magazine pages dash gamboa j c b ahmed s afzal m z liwicki m tac gan text conditioned auxiliary classier generative adversarial network corr arxiv dash gamboa j c b ahmed s liwicki m afzal m z tac gan text conditioned auxiliary classier generative adversarial network arxiv preprint denton e chintala s szlam fergus r deep generative image models laplacian pyramid adversarial networks corr arxiv denton e l chintala s szlam fergus r deep generative image models laplacian pyramid adversarial networks cortes c lawrence n d lee d d sugiyama m garnett r editors advances neural information processing systems pages curran associates inc dong h yu s wu c guo y semantic image synthesis adversarial learning proceedings ieee international conference computer vision pages dong h zhang j mcilwraith d guo y learning text image synthesis textual data augmentation ieee international conference image processing icip beijing china pages durugkar gemp mahadevan s generative multi adversarial networks elgammal liu b elhoseiny m mazzone m creative adversarial networks generating art learning styles deviating style norms corr arxiv ieee international conference image processing icip athens greece volume doi icip pages image captioning word level attention fang f wang h tang p gao l chen d song j xu x zhang d shen h t perceptual pyramid ial networks text image synthesis proceedings association advancement articial intelligence aaai goodfellow j pouget abadie j mirza m xu b d warde farley ozair s courville bengio y generative adversarial networks proceedings nips han h li y zhu x convolutional neural network learning generic data classication information sciences haynes m norton mcparland cooper r speech text broadcasters research implementation smpte motion imaging journal heusel m ramsauer h unterthiner t nessler b hochreiter s gans trained time scale update rule converge local nash equilibrium corr arxiv hong s yang d choi j lee h inferring semantic layout hierarchical text image synthesis corr arxiv hong y hwang u yoo j yoon s generative adversarial networks variants work overview acm computing surveys csur huang h yu p wang c introduction image synthesis generative adversarial nets corr arxiv huang x li y poursaeed o hopcroft j belongie s stacked generative adversarial networks ieee conference computer vision pattern recognition pages isola p zhu j zhou t efros image image translation conditional adversarial networks corr arxiv johnson j alahi fei fei l perceptual losses real time style transfer resolution european conference computer vision pages springer johnson j gupta fei fei l image generation scene graphs proceedings cvpr karpathy fei fei l deep visual semantic alignments generating image descriptions ieee transactions pattern analysis machine intelligence krizhevsky master s thesis dept computer science univ toronto kumar r sotelo j kumar k brebisson bengio y obamanet photo realistic lip sync text arxiv preprint lecun y cortes c mnist handwritten digit database li c su y liu w text text generative adversarial networks international joint conference neural networks ijcnn rio de janeiro pages li c wang z qi h fast converging conditional generative adversarial networks ieee international conference image processing icip athens greece image synthesis pages li w zhang p zhang l huang q x lyu s gao j object driven text image synthesis adversarial training corr li y gan z shen y liu j cheng y wu y carin l carlson d gao j gan sequential conditional gan story visualization proceedings ieee conference computer vision pattern recognition pages li y min m r shen d carlson d carin l video generation text second aaai conference articial intelligence lin t maire m belongie s bourdev l girshick r hays j perona p ramanan d zitnick c dollar p microsoft coco common objects context corr arxiv liu x meng g xiang s pan c semantic image synthesis conditional international conference pattern recognition icpr generative adversarial networks beijing china pages mansimov e parisotto e ba j l salakhutdinov r generating images captions attention corr arxiv mao x li q xie h lau r y k wang z smolley s p squares generative adversarial networks ieee international conference computer vision iccv venice pages mirza m osindero s conditional generative adversarial nets corr arxiv arxiv preprint mirza m osindero s conditional generative adversarial nets ngiam j khosla kim m nam j lee h ng y multimodal deep learning proceedings international conference international conference machine learning omnipress usa pages nguyen t d le t vu h phung d dual discriminator generative adversarial nets proc nips nie d trullo r petitjean c ruan s shen d medical image synthesis aware generative adversarial networks corr arxiv nilsback m zisserman automated ower classication large number classes proceedings indian conference computer vision graphics image processing odena olah c shlens j conditional image synthesis auxiliary classier gans corr arxiv odena olah c shlens j conditional image synthesis auxiliary classier gans proceedings international conference machine learning volume pages jmlr org park h yoo y kwak n mc gan multi conditional generative adversarial network image synthesis arxiv preprint qiao t zhang j xu d tao d mirrorgan learning text image generation redescription corr radford metz l chintala s unsupervised representation learning deep lutional generative adversarial networks corr arxiv reed s akata z mohan s tenka s schiele b lee h learning draw proc nips international conference reed s akata z yan x logeswaran l schiele b lee h generative adversarial text image synthesis proceedings international conference machine learning icml salimans t goodfellow zaremba w cheung v radford chen x improved techniques training gans corr arxiv schuster m paliwal k bidirectional recurrent neural networks ieee transactions signal processing stoll s camgoz n c hadeld s bowden r sign language production neural machine translation generative adversarial networks bmvc page szegedy c vanhoucke v ioffe s shlens j rethinking inception architecture computer vision ieee conference computer vision pattern recognition pages vo d m sugimoto paired d gan semantic image synthesis asian conference computer vision pages springer wang k gou c duan y lin y zheng x wang f caltech ucsd dataset computation neural systems technical report cns wang k gou c duan y lin y zheng x wang f generative adversarial networks introduction outlook ieee caa journal automatica sinica wang k wan x sentigan generating sentimental texts mixture adversarial networks proceedings seventh international joint conference articial intelligence wang x gupta generative image modeling style structure adversarial works corr arxiv wang y chang l cheng y jin l cheng z learning face sketch facial attribute text ieee international conference image processing icip athens greece pages wu x xu k hall p survey image synthesis editing generative adversarial networks tsinghua science technology xu k ba j kiros r cho k courville salakhutdinov r zemel r bengio y attend tell neural image caption generation visual attention corr arxiv xu t zhang p huang q zhang h gan z huang x x attngan fine grained text image generation attentional generative adversarial networks corr arxiv yan c yang j sohn k lee h conditional image generation visual attributes leibe b matas j sebe n welling m eds computer vision eccv eccv lecture notes computer science springer cham volume yan z zhang h wang b paris s yu y automatic photo adjustment deep neural networks acm transactions graphics tog yang j kannan batra d parikh d lr gan layered recursive generative adversarial networks image generation corr arxiv yang m zhao w xu w feng y zhao z chen x lei k multitask learning cross domain image captioning ieee transactions multimedia yin w fu y sigaly l xue x semi latent gan learning generate modify facial images attributes corr arxiv zhang d yin j zhu x zhang c network representation learning survey ieee transactions big data doi tbdata zhang g tu e cui d stable improved generative adversarial nets gans proceedings international conference image processing pages constructive survey zhang h xu t li h zhang s wang x huang x metaxas d realistic image synthesis stacked generative adversarial networks ieee transactions pattern analysis machine intelligence zhang h xu t li h zhang s wang z huang x metaxas d stackgan text photo realistic image synthesis stacked generative adversarial networks ieee international conference computer vision iccv venice pages zhang s zhai j luo d zhan y chen j recent advance generative adversarial networks proceedings international conference machine learning cybernetics pages zhang z xie y yang l photographic text image synthesis nested adversarial network corr arxiv zhu m pan p chen w yang y dm gan dynamic memory generative adversarial networks text image synthesis proceedings ieee conference computer vision pattern recognition pages zhu x goldberg eldawy m dyer c strock b text picture synthesis system augmenting communication prof aaai international conference pages
