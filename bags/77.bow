g u a l c s c v v i x r a tsinghuauniversity beijing chinaabstractneuralmodelshaverecentlybeenusedintextsummarizationincludingheadlinegener ation themodelcanbetrainedusingasetofdocument headlinepairs however themodeldoesnotexplicitlyconsidertopicalsimilaritiesanddifferencesofdocuments wesuggesttocategorizingdocumentsintovarioustopicssothatdocumentswithinthesametopicaresim ilarincontentandsharesimilarsummariza tionpatterns takingadvantageoftopicinfor mationofdocuments weproposetopicsen sitiveneuralheadlinegenerationmodel ourmodelcangeneratemoreaccuratesummariesguidedbydocumenttopics wetestourmodelonlcstsdataset andexperimentsshowthatourmethodoutperformsotherbaselinesoneachtopicandachievesthestate of artperfor includingheadlinegeneration isanimportanttaskinnaturallanguageprocessing itistypicallychallengingtocapturethecoreinfor mationofadocumentandcreateaninformativebutbriefsummaryofthedocument mostexistingtextsummarizationapproachescanbedividedintotwocategories extractiveandgener ative umentandreorderthemintoacompactsummary itisextremelydifcultforextractivemod elstogeneratecoherentandconcisesummaries generativemodels ontheotherhand aimatcom prehendingadocumentandgeneratingthesummarynotnecessarilyhavingappearedintheoriginaldoc ument recentyearshavewitnessedthedevelopmentofsequence to andthengenerateanoutputsequenceaccordingly theadvantageofneu ralmodelsisthatthesemodelslearnasemanticmappingdirectlyaccordingtopairsofdocument headlinesequenceswithoutdesigninghand craftedfeatures becausethesemodelscanexiblymodeldocumentsemanticsfrominternalwordsequenceswithinthedocument nevertheless muchexternalinformationaboutdocumentsmayalsoplayimpor tantrolesfortextsummarization forexample doc umentsusuallygroupintovarioustopics andthedocumentswithinacertaintopicmayexhibitspe cicsummarizationpatterns forexample adocu mentabouteconomyisusuallysummarizedinclud locationandplaceoftheevent inthispaper weproposetoincorporatetopicin formationofdocumentsintoneuralmodelsfortextsummarizationandproposetopic andintroducethetopiclabelsinneuralmodelstobuilduniqueencodersanddecodersforeachtopicrespec tively inthisway topicnhgcaneffectivelyiden tifythecorrespondingcrucialpartsinadocumentguidedbyitstopicinformation andareexpectedtogeneratewell focusedheadlines inthispaper weevaluateourmodelonalarge moreover itconsistentlyperformsthebestoneachindividualtopic whencalculatinght itusesupdategateztandresetgaterttoimprovetheperformanceonlongsequences thegatesarecom putedaszt thenitcomputescandidateoutputhtandnaloutputhtasht decodernhgincludesanencodertoencodeinputtextxintoafeaturevectorvandadecodertogeneratehead lineybasedonv theattentionmechanismcanim nhgwithattentionmechanism t natedtogethasht thefeaturevectorvistheaverageofoutputh for mally fort thunit attentionthefeaturevectorvremainsidenti theattentionmechanismdeter minesdifferentfeaturevtfort forshorttextx summaryyandtopiclabell l tionfeatureforadocument arethedirichletpriorsontheper documenttopicdistributionandper topicworddis tributionrespectively forsimplicity weassigneachinputsequencewithexactlyonetopicasl thetopiclabeloftheinputshorttextwillaf fectweightmatricesinencoder decoderandatten tionlayer forktopics kdifferentencoders decodersandattentionlay ers withkdifferentencoder wegeneratekrepre thetrainingofourmodelistime consuming foreachtopic soweusetheparameterstrainedintheconven tionalnhgmodeltoinitializeourmodel specic usinginitializationalsomakesourmodelmoregeneralthateachpartofourmodelwillrstlybetrainedbyalargesetofgeneraltextsum mariesandlaterbetrainedtogeneratetopic dia anteethequalityofdata iiandpart iiihasahuman labeledscore reectingtherelevanceofthesummary datainpart anddatainpart inourexperiment weusepart iasourtrainingdata andweusepart wemanuallymarkthesetopicsasjob economy accident politicsandtechnology topickeywordsjobundergraduate graduate pho tographer researchereconomyrmb usd realty investor company manager ipoaccidentsuspect police court idcard bus taxi highwaypoliticsstatedepartment authority civilservants urbanizationtechnologyinternet consumer smartphone e business topicandkeywords topicpart ipart iipart samplesintopic fevaluationonthesemod els byintroducingtopics oneachtopic wecompareourmodelagainstthebaseline rouge rouge inthisexample topic nhgperformsmuchbetterthanthebaseline thebaselineconsiderstherstsentenceoftheinputasitsmainpoint inmostcases thisassumptionisprobablytrue sothebaselinelearnsageneralreg ularityinsummarizationthattherstsentenceisimportant however therstsentenceofaweiboconcerningpoliticsusuallytalksaboutaconference whilethecontentoftheconferenceinthefollowingsentencesismoreimportant topicnhgcangureoutthisregularityandgiveaninformativesummary weibo text this afternoon the meeting of beijing s session of the national people s congress held the first press conference focusing on people s house problem beijing s economical departments with an average of per square meter will become history after solving all the waiting families no new economical departments will be built human notation economical departments will become history this year baseline the meeting of beijing s session of the national people s congress held a press conference topicnhg the economical department in beijing will become history comparingtopicnhgwithbaseline weproposetopic sensitiveneuralheadlinegeneration theexperimentsprovethattopicisanimportantfeatureinheadlinegenerationtasks however ourmodelisrelativelysimple itshighcostintrainingpreventsitfromhandlingmoretopics inthefuture referencesdzmitrybahdanau kyunghyuncho andyoshuaben andrewyng caglargulcehre kyunghyuncho zhengdonglu hangli to martinkaraat lukasburget jancer ininter speech sumitchopra andjasonwe oriolvinyals inadvancesinneuralinformationprocessingsystems
