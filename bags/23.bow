relabeling summarizing posterior distributions signal decomposition problems number components unknown alireza roodaki julien bect gilles fleury abstract paper addresses problems relabeling summarizing posterior distributions typically arise bayesian framework dealing signal tion problems unknown number components posterior distributions dened union subspaces differing dimensionality sampled modern monte carlo techniques instance increasingly popular mcmc method generic approach available summarize resulting variable dimensional samples extract component specic parameters propose novel approach named variable dimensional approximate posterior relabeling summarizing vapors problem consists approximating rior distribution interest simplebut dimensional parametric distribution distance distributions measured kullback leibler vergence stochastic type algorithm driven mcmc sampler proposed estimate parameters signal decomposition problems considered capability vapors relabeling summarizing variable dimensional posterior distributions classical lem detecting estimating sinusoids white gaussian noise hand particle counting problem motivated pierre auger project astrophysics hand index terms bayesian inference signal decomposition trans dimensional mcmc label switching stochastic introduction nowadays owing advent markov chain monte carlo mcmc sampling methods bayesian data ysis considered conventional approach machine ing signal image processing data mining problems applications tical challenges remain process extracting generated samples quantities interest summarize posterior distribution summarization consists loosely speaking providing simple interpretable parameters graphics end user statistical method instance case scalar parameter unimodal posterior distribution measures location dispersion empirical mean standard deviation median tile range typically provided addition graphical alireza roodaki ltci cnrs tlcom paristech paris france email com julien bect gilles fleury supelec systems sciences department signal processing electronic systems supelec gif yvette france email rstname results presented thesis rst author summary distribution histogram kernel density estimate case multimodal distributions summarization difcult carried instance approximation posterior gaussian mixture model gmm summarizing approximating posterior distributions designing proposal distributions metropolis hastings samplers adaptive mcmc framework paper addresses problem summarizing posterior distributions case trans dimensional problems problems number things know things know specically concentrate problem signal position number components unknown important case trans dimensional problem examples problems include detection estimation sinusoids white gaussian noise related problem estimating directions arrival array processing detection objects images detection physical particles neutrons muons noisy data types sensors instance spectroscopy astrophysics let vector observations superscript stands vector transposition signal decomposition problems model space nite countable set models denotes number components set possible values assumed components vectors component specic parameters qqq qqq qqq feature problems considering common invariance likelihood qqq respect permutations relabeling components called label switching issue literature discuss issue section bayesian framework joint posterior density qqq qqq obtained bayes formula number components vector specic parameters assigning prior distributions qqq qqq qqq variable dimensional space differing dimensionality indicates proportionality density dened union subspaces posterior density completely describes tion associated uncertainty provided data psfrag replacements candidate models vector unknown rameters known normalizing constant cases monte carlo simulation methods reversible jump mcmc mcmc sampler widely approximate label switching issue challenging issues attempting summarizing posterior distributions occurs dimensional situations label switching phenomenon caused invariance likelihood prior distribution permutations components consequence component specic marginal posterior distributions equal useless purpose summarizing information tained posterior distribution individual nents simplest way dealing label switching issue introduce identiability constraint sorting components respect parameters discussion concerning use ics problem bayesian analysis gmm practical examples choosing appropriate manually feasible relabeling algorithms developed undo label switching effect automatically restricted case xed dimensional posterior distributions recent advances references variable dimensional posterior distributions extra uncertainty presence components dition location challenging problem hindered previous attempts undo label switching dimensional scenario according meaning individual components vacuous argument claried following illustrative example illustrative example joint bayesian detection tion sinusoids white gaussian noise example assumed observed signal composed sinusoidal components observed white gaussian noise cosine sine amplitudes radial frequency jth sinusoidal component white gaussian noise variance unknown parameters number sinusoidal components vectors qqq specic parameters noise variance use hierarchical model prior distributions mcmc sampler proposed problem interested reader referred fact birth death moves acceptance ratio provided seminal paper erroneous chapter justication true expression acceptance ratio paper figure posterior distributions left sorted radial cies www given right output mcmc samples true number components vertical dashed lines right gure locate true radial frequencies figure represents posterior distributions number components sorted radial cies www given obtained ples generated mcmc sampler note sorting mitigate effect label switching ization row dedicated value observe models negligible posterior ties experiment served signal length consists sinusoids energies phases fff true radial frequencies www snr design matrix sines cosines associated www set moderate value roughly speaking approaches exist literature summarizing variable dimensional posterior distributions bayesian model selection bms bayesian model aging bma bms approach ranks models according posterior probabilities selects model denoted map map stands maximum riori summarizes posterior distribution component specic parameters xed dimensional selected model price losing valuable tion provided discarded models instance example figure information small harder detect middle component lost selecting posteriori probable model hand bma approach consists reporting results averaged possible models bma approach suitable signal reconstruction prediction purposes references appropriate studying component specic parameters number changes information concerning approaches found references best knowledge generic method currently available allow summarize information easily read figure simple example sinusoidal components observed noisy signal middle having smaller probability presence outline paper paper propose novel approach named dimensional approximate posterior relabeling marizing vapors relabeling summarizing posterior distributions dened variable dimensional subspaces typically arise signal decomposition problems number components unknown consists mating true posterior distribution parametric model varying dimensionality minimization leibler divergence distributions stochastic expectation maximization algorithm driven output mcmc sampler estimate parameters approximate model vapors shares similarities relabeling rithms proposed solve label switching problem type algorithm context adaptive mcmc algorithms dimensional setting main contribution paper introduction original variable dimensional parametric model allows tackle directly difcult problem approximating distribution dened union subspaces differing dimensionality provides rst solution trans dimensional label switching problem speak algorithm propose seen realization idea stephens mind stated page raises question able obtain alternative view variable dimensional rior combining results different grouping components similar similar predictive density estimates attempts failed produce easily interpretable results paper organized follows section introduces proposed model stochastic algorithm relabeling summarizing variable dimensional posterior distributions section iii illustrates performance vapors signal decomposition examples problem joint bayesian detection estimation sinusoids white sian noise problem joint bayesian detection estimation particles auger project astrophysics section conrms performances vapors monte carlo experiment finally section concludes paper gives directions future work vapors assume target posterior distribution dened variable dimensional space admits probability density function pdf respect dimensional lebesgue measure objective approximate true posterior density simple parametric model qhhh hhh vector parameters dening model pdf qhhh dened variable dimensional space xed dimensional approximation bms approach assume monte carlo sampling method mcmc sampler available generate ples denote qqq qqq variable dimensional parametric model instead trying describe proposed parametric family densities directly let adopt generative point view valued random variable qqq qqq corresponding probability distribution assume positive integer given represents number components present posterior let describe sample generate independently ponents binary indicator variable drawn bernoulli distribution indicates corresponding component present absent qqq actual number components parameter erated samples dened called probability presence lth component second given vector indicator variables xxx random vector generated component present random vector generated according probability distribution associated component assumed dimensional gaussian distribution mean mmm covariance matrix order achieve required invariance respect component relabeling generated vectors arranged vector qqq qqq qqq contemplating posterior distributions sorted radial frequencies depicted right panel figure particularly plots related models sinusoidal components observed diffuse parts mcmc output samples resulting heavy metric tails components clear model gaussian components capable describing diffuse samples parsimonious way abnormal observations respect bulk observed data simply outliers adversely inuence dimensional parametric family distributions point literature gaussian distribution chosen convenient mean describing compact unimodal dimensional distribution intensity plot provided section iii figure precisely permutation components present example bma summary related component specic parameter drawn uniformly set permutations mmm qqq figure proposed variable dimensional parametric model generative viewpoint process tting approximate posterior true posterior distribution interest consequently lead meaningless parameter estimates overcome robustness issue propose include model noise like poisson point process ppp account presence outliers observed samples assume ppp intensity number components generated ppp follows poisson distribution mean consistent previous notations denote number note values extended vector xxx follows probability distribution xxx ppp given xxx random samples generated uniformly inserted randomly samples drawn gaussian components denote qhhh pdf random variable qqq qqq generated mmm hhh hhh hhh figure provides directed acyclic graph model hhh distribution labeled samples random variable qqq qqq qqq drawn density qhhh thought unlabeled sample component label qqq originates recovered qqq let introduce variable dimensional allocation vector provides missing piece information indicates qqq originates lth gaussian component indicates qqq originates point process component refer pair qqq labeled sample following derive joint distribution qhhh qqq qhhh qqq distribution allocation vector qhhh xxx xxx qhhh xxx given note xxx deterministic function compute rst term remember points generated components parametric model randomly arranged qqq qhhh xxx arrangements differ position points corresponding ppp rise allocation vector conditional distribution qhhh qqq reads qhhh qqq qhhh qqq qhhh qqq mmm qqq equations qhhh qqq qqq mmm set allocation vectors set estimating model parameters propose parametric distribution qhhh posterior interest minimizing divergence measure qhhh use divergence divergence measure paper divergence measures denoting divergence dkl qqq kqhhh qqq dene criterion minimized qhhh hhh dkl qqq qhhh qqq qqq log qqq qqq dqqq samples generated mcmc sampler criterion approximated hhh log qhhh qqq assumed sake simplicity elaborate non homogeneous models easily accommodated approach needed chapter divergence measure proposed problem robustness reasons iteration step draw allocation vectors imh step target hhh qqq step construct pseudo completed log likelihood qhhh qqq log step estimate hhh hhh argminhhh figure proposed sem type algorithm constant depend hhh note minimizing hhh amounts choosing hhh argmaxhhh log qhhh qqq estimate model parameters hhh extensively algorithms maximum likelihood parameter estimation latent variable models algorithm proposed turns algorithm similar works appropriate solving problem computing expectation step intricate explicitly problem computational burden summation step set possible allocation vectors increases rapidly fact moderate values summation far expensive compute involves terms paper propose use sem algorithm variation algorithm step substituted stochastic simulation latent variables conditional posterior distributions given vious estimates unknown parameters words iteration sem algorithm denoting estimated parameters iteration hhh allocation vectors drawn hhh qqq step called stochastic random samples construct called pseudo completed log likelihood exact sampling hhh qqq required step sem type algorithm unfortunately feasible accept reject algorithm heavily binatorial expression normalizing constant hhh qqq instead hhh qqq hhh qqq possible assign prior remark tributions unknown parameters hhh study posterior distributions example mcmc sampler latent variable added state chain spirit data augmentation algorithm leave label switching issue unsolved invariance qhhh permutations components remark convergence results sem algorithm general form provided particular example mixture analysis problems unfortunately assumptions hold problem dealing observed samples qqq correlated owing fact generated true posterior distribution mcmc methods mcmc sampler sampler draw conditional posterior distribution empirical evidence good convergence properties type algorithm proposed provided sections robustied algorithm preliminary experiments sem type algorithm scribed figure satisfactory sample mean estimates step obtained minimizing divergence posterior tion parametric model qhhh suffer sensitivity outliers observed samples including poisson point process component workaround propose use robust estimates means gaussian distributions instead empirical means step example case univariate gaussian distributions use median interquartile range robust estimators mean variance respectively section discussion robustness issue including alternative solution robust divergence remark similar robustness concerns widespread clustering literature references iii illustrative examples section investigate capability vapors summarizing variable dimensional posterior distributions signal decomposition examples joint bayesian detection estimation sinusoids white gaussian noise joint bayesian detection estimation astrophysical particles auger project chapters results discussion phasize output trans dimensional monte carlo sampler mcmc sampler paper considered observed data vapors computed normalizing constant choose use independent metropolis hasting imh step hhh qqq stationary distribution rithm details proposed sem type algorithm summarized figure joint bayesian detection estimation sinusoids white gaussian noise let consider problem detection estimation sinusoidal components introduced section psfrag replacements psfrag replacements gaussian comp gaussian comp gaussian comp point process comp sem iteration figure evolution model parameters dened iterations vapors rion mcmc output samples shown figure unknown parameters number components component specic parameters noise variance amplitudes noise variance analytically integrated focus summarizing joint posterior distribution www form illustrated figure assume proposed parametric model introduced section consists univariate gaussian components means probabilities presence variances estimated space component specic parameters launching vapors need rst initialize parametric model natural deduce number gaussian components posterior distribution set percentile probable models play initialize gaussian nents parameters robust estimates means variances marginal posterior distributions sorted radial frequencies given finally set ran robustied stochastic algorithm introduced section specic example shown figure iterations gaussian components note posterior probability approximately assess convergence vapors figure illustrates evolution model parameters hhh criterion substantial facts showing convergence vapors deduced gure rst decreasing constant behavior criterion iteration convergence parameters parametric model particularly means bilities presence naive initialization procedure iteration signicant parameter estimates figure histogram labeled samples samples allocated gaussian poisson point process components pdf estimated gaussian components model black solid line vapors sinusoid detection example estimated parameters component presented corresponding panel trans dimensional setting figures shows histograms labeled samples qqq pdf estimated gaussian components black solid line summaries provided vapors component presented corresponding panel average sem iterations parameter estimates recommended sem literature example comparing distributions labeled samples ones posterior distributions sorted radial frequencies given shown figure highly multimodal reveals capability vapors solving label switching variable dimensional setting looking right panel figure role point process component capturing outliers observed samples described gaussian components clearer note point process component outliers allocated gaussian components consequently induce signicant deterioration parameter estimates table presents summaries provided vapors ones obtained bms approach trary bms approach vapors enabled benet information probable models summaries middle harder detect component turning results vapors seen estimated means compatible true radial frequencies furthermore estimated probabilities presence consistent certainty variable dimensional posterior shown figure discussed section main objectives algorithm proposed solve label switching issue observe better goodness estimated gaussian components panel figure depicts psfrag replacements psfrag replacements comp bms sbms psfrag replacements table summaries variable dimensional posterior distribution shown figure bms approach figure posterior distribution sorted radial frequencies www given normalized pdf tted gaussian components normalized posterior distributions sorted radial frequencies given gure validate coherency estimated summaries information variable dimensional posterior distribution seen gures shape pdf estimated gaussian components coherent location dispersion ones posterior sorted radial frequencies useful validating estimated summaries compare intensity estimated parametric model qhhh dened general mmm ignore point process component histogram intensity radial frequencies obtained bma approach chapter information figure shows gure specic example section solid black line indicates intensity estimated parametric model gures indicate goodness tted approximate posterior true finally validate estimated probabilities ence gaussian components mean parameter poisson point process component figure illustrates posterior distribution number components approximated versions vapors seen gure vapors captured information provided true posterior number components obtain normalized densities rst normalized estimated pdf maximum equal multiplied estimated probability presence gaussian component corresponding normalized estimated pdf maximum normalized density equal corresponding estimated probability presence figure histogram intensity radial frequencies samples bma approach intensity tted parametric model obtained vapors figure posterior distribution number number components black approximated version gray obtained tted model joint bayesian detection estimation astrophysical particles auger project second illustrative example results signal decomposition problem encountered international astrophysics collaboration called auger auger project aimed studying ultra high energy cosmic rays energies order energetic particles found far universe long term objective project study nature ultra high energy cles determine origin universe observed directly fact collide earth atmosphere host secondary particles generated muons nally reach ground detect pierre auger cosmic ray observatory built consists independent detectors array surface detectors number fluorescence detectors number muons arrival times indications chemical composition origin primary particles information concentrate signal decomposition problem goal count number muons estimate individual parameters signals observed detectors results use bayesian algorithm mcmc sampler developed trans dimensional problem joint detection estimation figure observed signal intensity model aaam ttt dened muons signal true arrival times ttt indicated vertical dashed lines psfrag replacements psfrag replacements muons section rst briey describe problem use vapors relabel summarize dimensional output samples mcmc sampler oped muon crosses tank generates photoelectrons track captured detectors create discrete observed signal denote vector observed signal element indicates number deposited muons time interval itd absolute starting time signal signal resolution length bin muon component specic parameters arrival time signal amplitude absorption process photons generated muon modeled non homogeneous poisson point process intensity section time response distribution time exponential decay measured figure exponential shape intensities expected number bin obtained integrating intensity corresponding bin conditioning number muons vector parameters ttt aaam assuming number bin independent likelihood written ttt aaam aaam ttt aaam ttt poisson distribution mean aaam ttt assuming independence expected number ith bin muons aaam ttt given ttt aaam nnn figure posterior distributions number muons left sorted arrival times ttt given right constructed mcmc output samples discarding burn period true number components vertical dashed lines right gure locate arrival times aaam ttt illustrate performance vapors simulated counting signal chapter results simulated experiments observed signal illustrative example considered consists muons located ttt figure posterior distributions number muons sorted arrival times shown figure note example muons equal arrival times fourth muons bms approach model muons selected similar posterior probability observe marginal posterior arrival time component bimodal signicantly ran vapors gaussian components mcmc output samples shown figure note figure shows histogram labeled samples estimated parameters components gure seen bimodality effects caused label switching exhibited figure removed completely estimated gaussian components enjoy reasonable variances presented summary muons high probabilities presence corresponding ones shown row figure muons comparatively low probabilities presence fact samples allocated point process component shown row figure regarded residuals tted model observed samples gaussian components qhhh able psfrag replacements psfrag replacements psfrag replacements gaussian comp gaussian comp gaussian comp gaussian comp gaussian comp gaussian comp figure histograms residuals tted model vapors different values point process comp figure histogram labeled samples pdf estimated gaussian components model black solid line vapors variable dimensional postrior shown figure estimated parameters component presented corresponding panel figure normalized pdf tted gaussian components vapors different values describe residuals usual statistics tool goodness diagnostics model choice figure illustrates histograms residuals tted model different values seen left panel figure distribution residuals corresponding case contains signicant peaks peaks gradually removed adding gaussian components component added captures samples distributed signicant peak left panel figure exist peaks particularly captured distribution residuals case differ signicantly note decrease value increasing figure compares normalized intensities mated gaussian components seen gure changing reasonable range inuence signicantly nal inference cases gaussian components estimated case exist moving additional gaussian components added obtained summary low probabilities presence improve change nal inference monte carlo experiment examples section iii illustrated capability vapors relabel summarize variable dimensional posterior distributions encountered signal sition problems order conrm ndings investigate systematically means monte carlo simulation experiment faithfully approximate posterior distribution preserves certain features true posterior distribution realizations sinusoid detection ment described section figure simulated analyzed mcmc sampler number mcmc iterations set rst samples discarded burn period samples thinned fth initialize systematic fashion set parametric model qhhh largest posterior probability process sem type algorithms sufcient number samples allocated gaussian component equivalently probability presence fades zero remove parametric model decrease approach generally results approximate posterior distributions richer provided bms sense map map argmaxk initialize gaussian components parameters means variances previously robust estimates mean variances posterior distributions sorted radial frequencies given figure compares features tted mate posterior distribution hhh obtained iterations vapors corresponding features true variable dimensional posterior distribution features described rest section scatter plots shown panels compare posterior distribution number components approximated version denoted runs posterior probabilities comparison probabilities close zero digits situated right points panel indicate number occurrence corresponding event runs map argmaxk seen panels information preserved approximated posterior distributions compare performance vapors direct bma reconstructing noiseless signal end estimated reconstructed noiseless signal dened qqq qqq dqqq direct bma approach samples generated mcmc sampler integral approximated ybma design matrix ith vector sampled radial frequencies www posterior mean amplitudes given www hyperparameters reconstruct noiseless signal tted approximate posterior hhh vapors generate pairs samples www explained section set yvapors panel compares normalized reconstruction errors vapors ones direct bma approach dened post processing step gaussian component endowed probability presence decide discard ones smaller certain threshold section discussion idea direct mean posterior means approximated mcmc samples directly vapors posterior norm set ybma yvapors bma approach vapors spectively seen gure normalized errors reconstructed noiseless signals compact summary obtained vapors comparable ones obtained bma approach finally scatter plots panels compare expected number components intervals vapors ones obtained direct bma approach bma approach expected number components interval given number radial frequencies observed ith sample hand summary provided vapors expected number components interval hhh hhh hhh denotes probability sian distribution parameters hhh gures conrm expected number components chosen intervals computed approaches similar results shown section conrmed proximate posterior distribution hhh obtained vapors preserves faithfully important features true posterior distribution section results vein including numerical investigation comparison properties estimators derived vapors conclusion paper proposed novel algorithm relabel summarize variable dimensional posterior butions encountered signal decomposition problems number component unknown purpose variable dimensional parametric model designed approximate posterior interest parameters approximate model estimated means sem type algorithm samples true posterior distribution generated trans dimensional monte carlo sampler mcmc sampler modications initial sem type algorithm proposed order cope lack robustness maximum likelihood type estimates relevance proposed algorithm marizing relabeling variable dimensional posterior distributions illustrated signal decomposition examples problem detection estimation sinusoids gaussian white noise particle counting problem motivated astrophysics project auger notably vapors shown rst approach literature capable solving label switching issue trans dimensional problems shown proposed psfrag replacements psfrag replacements map map estimator posterior probability psfrag replacements psfrag replacements direct bma posterior probability reconstruction error psfrag replacements psfrag replacements direct bma direct bma figure comparison features true posterior distribution vapors approximation parametric model provides good approximation teriors encountered applications vapors provide user insight concerning component specic parameters uncertainties presence believe algorithm useful vast domain signal decomposition mixture model analysis enhance inference trans dimensional problems theoretical investigations required order extend available existing convergence results sem algorithm sem type algorithm paper correlated input data metropolis hastings updates future work focus vapors design efcient adaptive trans dimensional mcmc methods continuation ideas presented acknowledgment authors like express gratitude kgl collaboration providing data auger example references roodaki signal decompositions trans dimensional bayesian methods thesis cole suprieure dlectricit suplec gif sur yvette france metropolis rosenbluth rosenbluth teller teller equation state calculations fast computing machines journal chemical physics vol hastings monte carlo sampling methods markov chains stephens dealing label switching mixture models journal royal statistical society series statistical methodology jasra holmes stephens markov chain monte carlo methods label switching problem bayesian mixture modeling statistical science vol celeux hurn robert computational inferential difculties mixture posterior distributions journal american statistical tion frhwirth schnatter dealing label switching model uncertainty mixtures estimation applications mengersen robert terington eds wiley online library sperrin jaki wit probabilistic relabelling strategies label switching problem bayesian mixture models statistics computing vol yao model based labeling mixture models statistics computing robert discussion bayesian analysis mixtures unknown number components richardson green journal royal statistical society series statistical methodology vol roodaki bect fleury note computation hastings ratio birth death moves trans dimensional mcmc algorithms signal decomposition problems technical report cole suprieure dlectricit suplec gif sur yvette france clyde george model uncertainty statistical science vol celeux diebolt sem algorithm probabilistic teacher algorithm derived algorithm mixture problem computational statistics quaterly vol celeux diebolt stochastic approximation type algorithm mixture problem stochastics stochastics reports vol nielsen stochastic algorithm estimation asymptotic results bernoulli vol stephens bayesian methods mixture normal distributions thesis phill thesis university oxford oxford applications biometrika vol karr point processes statistical inference second edition crc liu monte carlo strategies scientic computing springer verlag robert casella monte carlo statistical methods second edition springer verlag basu harris hjort jones robust efcient estimation minimising density power divergence biometrika vol dempster laird rubin maximum likelihood incomplete data algorithm journal royal statistical society series statistical methodology tanner wong calculation posterior distributions data augmentation journal american statistical association vol diebolt celeux asymptotic properties stochastic algorithm estimating mixing proportions stochastic models vol huber ronchetti robust statistics edition wiley dav krishnapuram robust clustering methods unied view ieee transactions fuzzy systems vol kgl bayesian estimation metropolis hastings algorithm simple example technical report lal university paris sud cnrs france bardenet kgl veberic single muon response signal model technical report lal university paris sud cnrs france west approximating posterior distributions mixture journal royal statistical society series statistical methodology vol haario saksman tamminen adaptive metropolis algorithm bernoulli bai craiu narzo divide conquer based approach regional adaptation mcmc journal computational graphical statistics vol bardenet capp fort kgl adaptive metropolis algorithm online relabeling proceeding international conference articial intelligence statistics aistats green reversible jump mcmc computation bayesian model nation biometrika vol green trans dimensional markov chain monte carlo highly structured stochastic systems green hjort richardson eds andrieu doucet joint bayesian model selection estimation noisy sinusoids reversible jump mcmc ieee transactions signal processing vol larocque reilly reversible jump mcmc joint detection estimation sources coloured noise ieee transactions signal processing vol rue hurn bayesian object identication biometrika vol ortner descombes zerubia building outline extraction digital elevation models marked point processes international journal computer vision vol andrieu barat doucet bayesian deconvolution noisy ltered point processes ieee transactions signal processing vol auger collaboration pierre auger project design report second edition auger org html auger collaboration properties performance prototype instrument pierre auger observatory nuclear instruments methods physics research vol richardson green bayesian analysis mixtures unknown number components journal royal statistical society series statistical methodology vol
