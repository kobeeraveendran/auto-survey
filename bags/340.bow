klearn background knowledge inference summarization data maxime peyrard epfl maxime ch robert west epfl robert t c o l c s c v v x r abstract goal text summarization press documents relevant information excluding background information ready known receiver far rization researchers given considerably attention relevance background knowledge contrast work puts ground knowledge foreground ing realization choices human summarizers annotators contain implicit information background knowledge develop compare niques inferring background knowledge summarization data based work dene summary scoring functions explicitly model background knowledge scoring functions t man judgments signicantly better lines illustrate tential applications framework provide insights human information importance priors second demonstrate averaging background knowledge multiple potentially biased annotators pora greatly improves summary scoring formance finally discuss potential cations framework tion introduction summarization process identifying important information pieces document humans process heavily guided ground knowledge encompasses tions task priors kind information important mani despite fundamental role background edge received little attention rization community existing approaches largely focus relevance aspect enforces ilarity generated summaries source documents peyrard figure summary s results tion background knowledge k source document d following peyrard s lar d relevance measured small brings new information compared ground knowledge informativeness measured large infer unobserved k choices unexplained relevance criteria previous work background knowledge usually modeled simple aggregation large background corpora instance tfidf sparck jones ize background knowledge set words large document frequency background corpora assumption frequently cussed topics reect average known necessarily hold example sense information discussed liu singh information present background texts gone portance lter humans e writers ers general particular difculty preventing development proper background knowledge models latent nature hope infer proxy signals present principled way compare evaluate background knowledge models s similar small relevance dierent large informativeness work background knowledge foreground propose infer marization data choices human summarizers human annotators provide plicit information background edge build recent theoretical model information selection peyrard tulates information selected summary results desiderata low redundancy mary contain diverse information high relevance summary representative document high informativeness summary adds new information background knowledge tension elements encoded summary scoring function k explicitly depends background knowledge k trated fig latent k inferred residual differences information tion explained relevance dancy example black information unit fig selected summary despite prominent source document intuitively explained unit known receiver leverage implicit signal view k latent parameter learned best observed summarization data contributions develop algorithms ring k settings pairs ments reference summaries pairs observed sec pairs document summaries enriched human judgments sec sec evaluate inferred ks spect induced scoring function k correlates human judgments proposed algorithms signicantly surpass previous baselines large margins sec geometrical perpespective framework clear geometrical structure emerges real summarization data ability infer interpretable importance ors data driven way applications explore sec sec tatively reveals topics emerge known unkown tted priors fer k based different subsets data training data annotator prior specic annotator similarly nd domain specic k s training different datasets explored sec alyze annotators different summarization datasets yielding interesting insights ing potentially biased annotator specic domain specic k s results systematic alization gains finally discuss future work tial applications summarization sec code available epfl dlab klearn related work modeling background knowledge ceived little attention summarization munity problem identifying tent words encountered earliest work summarization luhn simple effective solution came eld information retrieval techniques tfidf background corpora sparck jones similarly dunning proposed likelihood ratio test identify highly descriptive words techniques known useful news summarization harabagiu lacatusu later approaches include heuristics tify summary worthy bigrams riedhammer et al hong nenkova proposed supervised model predicting word appear summary large set features including global indicators new york times corpus serve prior word importance conroy et al proposed model ground knowledge aggregating large random set news articles delort alfonseca bayesian topic models ensure extraction informative summaries finally louis vestigated background knowledge update marization bayesian surprise ideas generalized abstract model importance peyrard discussed section background work builds abstract model duced peyrard relevant aspects briey present let t text function mapping text semantic representation following form pt pt n semantic representation probability tribution p called semantic units jn different text representation techniques chosen e topic models topics mantic units properly renormalized semantic vector space dimensions semantic units summarization setting source ment d summary s represented ability distributions semantic units pd ps similarly k background knowledge represented distribution pk semantic units intuitively j high j known summary scoring d simply document d ambiguous derived simple requirements d k red captures redundancy summary entropy h rel reects relevance summary kullback leibler kl divergence summary document good summary expected similar original document e kl divergence low finally inf models informativeness summary kl divergence summary latent background knowledge k summary bring new information e kl divergence high work x klearn framework laid framework texts viewed distributions choice semantic units jn aim infer general k bution units best explains rization data consider types data human judgments inferring k human judgments assume access dataset xi pairs documents di associated summaries si di si assumption si good summaries e generated humans infer background knowledge k best explains observation summaries deed summaries good assume information selected minimize dancy maximize relevance maximize tiveness use k pk interchangeably guity direct score maximization straightforward proach determine k maximizes k score observed summaries formally corresponds maximizing function xi acts regularization term ing k remain similar predened distribution p p serve prior k factor controls emphasis regularization rst natural choice prior p uniform distribution u semantic units case appendix b maximizing eq yields following simple solution k j j si choice note j positive expected solution fairly itive simply counts prominence semantic unit human written summaries siders ones selected interesting e having low values background knowledge denote technique indicate maximum score uniform prior surprisingly involve documents intuitively k function summaries documents simplistic model works applied broader ios documents fully observed alternatively choose prior p source documents di shown appendix b solution j j j si conservative choice ensure j itivity j min j model j intuitive resulting value j higher j prominent document selected summary ple case black semantic unit fig furthermore choosing d prior implies ing documents knowledge available makes minimal prior commitment k denote approach probabilistic model directly maximizing score observed summaries antee scores unobserved maries remain low principled way address issue formulate probabilistic model observations xi di si s partition function computed set possible summaries ment di practice draw random summaries negative samples estimate partition tion negative samples positive k learned maximize likelihood data gradient descent enforce constraint k probability tribution parametrize k softmax vector k scalars vector k trained mini batch gradient descent mize negative log likelihood observed data approach denoted pm inferring k human judgments assume dataset annotated man judgments observations come form si di hi hi human assessment good si summary di use extra information enforce high scoring low scoring summaries high low k scores regression rst solution propose sion goal minimizing difference predicted k corresponding human scores training set formally task minimize following loss xi scaling parameter k hi comparable range train k gradient descent parametrize k softmax vector scalars sec denote approach hreg preference learning practice regression fers annotation inconsistencies particular human scores documents average higher documents easily confuses regression preference learning pl robust issues learning ative ordering induced human scores gao al pl formulated binary sication task maystre input pair data points si di hi s j d j h j output binary ag indicating si better s j e hi h j j h j j logistic sigmoid function l example binary cross entropy perform mini batch gradient descent train k denote approach hpl comparison approaches compare usefulness k s need way evaluate fortunately natural evaluation setup plug k k summary scoring function described eq use induced k score summaries si compute agreement human scores hi distinguish algorithms duced sec adopt following naming convention scoring functions background knowledge k computed algorithm denote corresponding scoring function e hpl scoring function k ferred hpl data use datasets text ysis conference tac shared task contain ics respectively topic summarized systems humans system maries human written summaries ually evaluated nist assessors readability content selection pyramid nenkova sonneau overall responsiveness dang owczarzak evaluation focus pyramid score framework built model content selection aspect semantic units previous work peyrard use words semantic units sec experiment topic models different choices text representations ily plugged proposed methods words advantage simple directly rable existing baselines nist nist kendall mr baselines lr icsi idf u human judgments pm human judgments hpl best training data optimal hpl table comparison background knowledge based induced k correlates humans kendall s higher better far written summaries ranked compared system maries mr lower better improvements hpl baselines signicant paired t test p baselines reference report summary scoring functions baselines lexrank lr erkan radev graph based approach summary scoring function average centrality sentences summary icsi gillick favre scores summaries based coverage frequent bigrams source documents haghighi vanderwende measure vergences distribution words summary sources js divergence symmetrized smoothed version kl gence additionally report performance choosing uniform distribution k denoted u idf baseline k built document frequency computed english wikipedia denoted idf reference report performance training evaluating hpl data denoted optimal sures ability hpl t training data results table reports fold validation averaged topics rst column reports kendall s correlation humans mary scoring functions second column reports mean rank mr reference summaries figure multi dimensional scaling projection uments summaries k inferred hpl clidean distance projection approximates kl divergence original space geometrical tuition summaries documents k form line documents middle simultaneously respected different randomly selected topics tac datasets summaries produced shared tasks ranked according summary scoring functions lower mr better note techniques rely human judgments signicantly outperform previous baselines results ticularly strong large improvements despite simplicity algorithm time complexity n number topics run faster algorithm seconds single cpu infer k tac dataset despite principled pm outperform improvements baseline obtained hpl leverages ne grained tion human judgments beneting supervision performs larly hpl signicant difference expected preference learning setup hpl stronger robust regression setup hreg signicantly outperform uniform baseline u use hpl human judgments available summary pairs available geometric view previously fig mentioned good k corresponds distribution mary s different k large similar document d small furthermore regularization term eq p d enforcing small makes minimal commitment k look like e priori information documents assumed viewing distributions points clidean space optimal arrangement s d k line d s k human written summaries s documents d given inferring k intuitively consists ing point high dimensional space matching property document summary pairs interestingly easily test ometrical structure appears real data inferred k perform simultaneous multi dimensional scaling mds embedding documents di human written summaries si k space distributions close kl divergence low plot embedding fig randomly chosen topics k inferred hpl deed observe documents summaries k nicely aligned summaries close documents far away k nding holds k inferred observations important sons general framework troduced fig appropriate model summarization data given topic erence summaries arranged document deviate document systematic way explained repulsive tion background knowledge human written summaries contain information document background knowledge puts border space models seen infer appropriate background knowledge common wide spectrum topics shown fact k occupies central point embedding fig applications investigate applications arising framework k easily interpretable explore units receive high low scores use different subsets aggregations training data look annotator specic k s domain specic k s known unknown said like told kill liberty new nation announcement investigation table example words known unknown according best k inferred hpl word j known unknown according k j high low qualitative analysis understand considered known j high unknown j low t best model hpl tac data choices semantic units words lda topics trained english wikipedia topics table report known known words frequent uninformative words like said considered known undesired summary contrary known words low frequency specic words summarization systems systematically failed extract important according humans emphasize inferred ground knowledge encodes different information standard idf provide detailed ison k idf appendix e text representation given topic model trained wikipedia obtain lowing known topics described words government election party united state litical minister president book published work new wrote life novel air aircraft ship navy army service training ight known topics appeared suit following identied series episode tv lm season card player chess game played hand team university research college science sor research degree published topics related military politics receive higher scores k given topics tend frequent news datasets k trained man annotations learns penalize systems tting frequency signal source uments contrary series games figure multi dimensional scaling projections annotators domains euclidean distance projected space represents kl divergence original space disk size proportional k performs tac datasets uated correlation kendall s duced k human judgments versity topics receive low scores extracted systems improve agreement humans inferring domain specic background knowledge tac datasets annotations tagged annotator id possible infer background knowledge specic notator applying algorithms subset annotations performed respective annotator combined annotators identied resulting different k s instead analyzing news datasets human annotations like tac infer ground knowledge summarization dataset domain long document summary pairs observed illustrate consider large collection datasets covering domains news legal documents product reviews pedia articles contain human annotations employ algorithm infer k specic dataset detailed scription datasets given appendix c structure differences visualize ences annotators embed mds annotators close k similar fig annotator dot size proportional k generalizes rest tac datasets uated correlation kendall s induced k human judgments dure applied domains depicted fig b figure correlation human judgments tac datasets news domain resulting averaging annotator specic k s domain specic k s distance optimal k computed running hpl tac datasets news datasets appear center domains meaning news domain seen average peripheral non news domains thermore k s trained different news datasets close indicating good level intra domain transfer unsurprisingly news datasets exhibit best transfer performance tac improvements averaging based vious observations hypothesis averaging different annotator specic k lead better correlation human judgments unseen tac dataset similarly news domains generalize better domains hypothesized averaging domains sult improved correlations humans news domain fig report improvements relation human judgments tac news main resulting averaging increasing ber annotators domains error bars sent condence intervals arising ing different subset compute average increasing number annotators aged results clear signicant improvements error bars small annotators newsdomains figure k distributions visualized density glove embedding space included averaging little impact results source documents illustrated initial results appendix d similarly averaging different domains sults signicant improvements particular averaging non news domains gives better generalization news domain furthermore fig shows glove et al embedding space k s resulting averaging annotators k s ferred hpl news datasets k s inferred c non news datasets k s ferred comparison optimal k learned hpl trained data tac datasets produce visualizations form density estimation k s projection word embeddings averaged k s tend similar mal k indicates prior produces strong results news datasets obtained averaging biased different k s conrmed fig distance optimal k measured terms kl divergence signicantly decreases annotators averaged conclusion focus ignored background edge summarization infer implicit signals human summarizers annotators introduced evaluated different approaches observing strong abilities t data newly gained ability infer interpretable priors importance data driven way potential applications example scribe topics extracted quently systems improve agreement humans pretrained priors helps systems reduce overtting frequency signal y axis normalized ent divergences comparable scale important application possible framework infer k meaningful subset data particular learned specic k s yielded interesting insights annotators exhibit large differences averaging potentially biased k s results generalization improvements inferred k s different summarization datasets found increased performance news domain averaging k s diverse domains future work different choices semantic units explored e learning k directly embedding space xed comparable results methods cluding learnable parameters provide performance boosts investigating infuse tted priors summarization systems promising direction generally inferring k sense task like summarization provide insights general human importance priors inferring priors applications tion framework model information selection task acknowledgments gratefully acknowledge partial support facebook google microsoft swiss national science foundation grant european union grant tailor references jean carletta simone ashby sebastien bourban mike flynn mael guillemot thomas hain jaroslav kadlec vasilis karaiskos wessel kraaij melissa kronenthal guillaume lathoud mike lincoln iain mccowan wilfried post agnes lisowska dennis reidsma pierre wellner ami meeting corpus pre announcement proceedings second international conference machine learning multimodal interaction page berlin heidelberg springer verlag filippo galgani paul compton achim hoffmann citation based summarisation legal texts pricai trends articial intelligence pages berlin heidelberg springer berlin heidelberg jianpeng cheng mirella lapata neural summarization extracting sentences words proceedings annual meeting sociation computational linguistics volume long papers pages association putational linguistics arman cohan franck dernoncourt doo soon kim trung bui seokhwan kim walter chang zli goharian discourse aware attention model abstractive summarization long uments proceedings conference north american chapter association computational linguistics human language nologies volume short papers pages new orleans louisiana association tional linguistics john m conroy judith d schlesinger dianne p topic focused multi document oleary summarization approximate oracle score proceedings coling acl main ference poster sessions pages sydney australia association computational tics hoa trang dang karolina owczarzak overview tac update summarization task proceedings text analysis conference tac workshop notebook papers results pages hoa trang dang karolina owczarzak overview tac update summarization task proceedings text analysis ference tac pages hoa trang dang karolina owczarzak overview tac summarization track proceedings text analysis conference tac pages hoa trang dang karolina owczarzak overview tac summarization track proceedings text analysis conference tac pages jean yves delort enrique alfonseca alsum topic model based approach update summarization proceedings ence european chapter association computational linguistics pages ted dunning accurate methods tics surprise coincidence computational guistics kavita ganesan chengxiang zhai jiawei han opinosis graph based approach stractive summarization highly redundant ions proceedings international ference computational linguistics coling pages yang gao christian m meyer iryna gurevych april interactively learning summarise combining active preference learning forcement learning proceedings ference empirical methods natural language processing pages brussels belgium association computational linguistics dan gillick benoit favre scalable global proceedings model summarization workshop integer linear programming ural language processing pages boulder colorado association computational tics aria haghighi lucy vanderwende ing content models multi document tion proceedings human language gies annual conference north american chapter association tional linguistics pages sanda harabagiu finley lacatusu topic themes multi document summarization ceedings annual international acm gir conference research development information retrieval pages karl moritz hermann tomas kocisky edward stette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read comprehend advances neural formation processing systems pages kai hong ani nenkova improving estimation word importance news proceedings document summarization conference european chapter sociation computational linguistics pages gothenburg sweden association tational linguistics manoel horta ribeiro kristina gligoric robert west message distortion information world wide web conference page cades new york ny usa association computing machinery gnes erkan dragomir r radev lexrank graph based lexical centrality salience text journal articial intelligence summarization research pages byeongchang kim hyunwoo kim gunhee kim abstractive summarization reddit posts multi level memory networks ings conference north american chapter association computational guistics human language technologies volume long short papers pages neapolis minnesota association computational linguistics mahnaz koupaee william yang wang ihow large scale text summarization dataset corr chin yew lin rouge package text matic evaluation summaries rization branches proceedings workshop pages barcelona spain tion computational linguistics hugo liu push singh conceptnet practical commonsense reasoning tool kit bt technology journal annie louis bayesian method rate background knowledge automatic text summarization proceedings annual meeting association computational guistics volume short papers pages baltimore maryland hans peter luhn automatic creation literature abstracts ibm journal research velopment inderjeet mani advances automatic text marization mit press cambridge ma usa lucas maystre efcient learning isons epfl lausanne ryan mcdonald study global inference algorithms multi document summarization proceedings european conference formation retrieval research pages shashi narayan shay b cohen mirella lapata nt details summary topic aware convolutional neural networks treme summarization proceedings conference empirical methods natural guage processing pages brussels gium association computational linguistics ani nenkova rebecca passonneau ing content selection summarization proceedings human mid method guage technology conference north chapter association computational linguistics hlt naacl pages boston massachusetts usa romain paulus caiming xiong richard socher deep reinforced model abstractive summarization corr jeffrey pennington richard socher christopher manning glove global vectors word proceedings representation ference empirical methods natural language processing emnlp pages doha qatar association computational linguistics maxime peyrard simple theoretical model importance summarization proceedings annual meeting association putational linguistics pages florence italy association computational linguistics maxime peyrard judith eckle kohler general optimization framework document summarization genetic proceedings rithms swarm intelligence international conference computational linguistics coling pages avinesh p v s maxime peyrard christian m meyer live blog corpus summarization proceedings international ence language resources evaluation pages korbinian riedhammer benoit favre dilek hakkani tr long story short global unsupervised models keyphrase based speech communication ing summarization evan sandhaus new york times annotated corpus linguistic data consortium philadelphia abigail peter j liu christopher d ning point summarization proceedings pointer generator networks annual meeting association computational linguistics volume long papers pages vancouver canada association computational linguistics karen sparck jones statistical interpretation term specicity application retrieval journal documentation wei zhao maxime peyrard fei liu yang gao tian m meyer steffen eger moverscore text generation evaluating contextualized beddings earth mover distance proceedings conference empirical methods natural language processing tional joint conference natural language cessing emnlp ijcnlp pages hong kong china association computational guistics markus zopf maxime peyrard judith kohler step multi document summarization heterogeneous multi genre pus built novel construction approach proceedings international conference computational linguistics technical papers pages figure visualization annotator s k based projection glove word embedding figure visualization domain s k based projection glove word embedding visualization k annotator domain produce visualizations embedding space procedure fig fig depicts annotators fig depicts domains interesting observe diversity ing domains domain specic k s spread semantic space reects greater topic diversity discussed ferent domains contrast annotator s k inferred based tac datasets domain news b derivation approaches direct score maximization model consists maximizing l use lagrange multipliers constraint k valid distribution p u uniform following derivatives j d j dl j j j j j j j setting lagrange derivative yields j j normalizing constant particular j j note choosing ensures second consider case p d document u changes document summary pair l l d s d s l j derivative concerning modied d j j j sumlegalreports gives following solution setting lagrange derivative ami corpus carletta et al dard product review summarization dataset j j j clear j positive ery units avoid issue notice choose min j j j c datasets summarization track text analysis ference tac direct continuation duc series particular main tasks dang owczarzak dang owczarzak renements pilot update summarization task duc dataset topics released edition new topics created standard benchmark datasets new york times annotated corpus haus counts largest rization datasets currently available contains nearly million carefully selected articles new york times summaries written humans cnn daily mail dataset hermann et al decisive recent opment neural abstractive summarization et al paulus et al cheng lapata contains cnn daily mail articles bullet point summaries zopf et al viewed quality wikipedia featured articles summaries potential sources automatically searched web p v s al recently crawled blog archives bbc guardian gether bullet point summaries reporting main developments event covered evaluate opinion oriented tion system ganesan et al constructed opinosis dataset contains articles discussing features commercial products e ipod s battery life furthermore consider large pubmed taset cohan et al collection scientic publications reddit dataset kim et al collected popular sub reddits koupaee wang automatically crawled wikihow website reported bullet points summaries xsum dataset narayan et al large collection news articles focus abstractive summaries measure effect information distortion summarization cascades scientic results horta ribeiro et al collected manual maries lengths included legalreport dataset et al task summarize legal documents d extracting summaries example k specied summary scoring tion k extract summaries extractive summarization optimal set selection problem mcdonald tunately k linear optimized integer linear programming modular optimized greedy algorithm submodularity rely generic optimization techniques assumption objective function approximately optimize arbitrary function use genetic algorithm proposed peyrard eckle kohler creates tively optimizes summaries time denote k gen summarization system mately solving subset selection problem compare systems k inferred k inferred hpl k form distribution reference report standard summarization baselines described previous section summaries evaluated automatic evaluation metrics stopwords removed lin recent bert based evaluation metric mover zhao et al results reported table encouraging systems based learned priors outperform uniform prior perform comparison baselines inferred prior benet systems preventing overtting frequency signal com genetic swarm mds employ fold cross validation setup dataset creation man input type genre summary length size topics doc topic scisumm cnn daily mail nyt corpus opinosis liveblogs hmds pubmed xsum reddit ami wikihow legalreports mdic m m m m m m mds mds mds sds sds mds temporal mds sds sds sds mds sds sds cascade news news sci news news review snippets heter sci news heter meeting heter legal sci varying k k k k k k k table description datasets experiments visualization optimal k renormalized idf absolute difference bar word support words table comparison summarization systems based maximizing summary scoring function k duced different background knowledge mover mover baselines lr icsi kl greedy js gen u gen gen hpl gen e comparison idf vs optimal k verify inferred k contains different formation id compare idf mal k sec comparable idf weights need malized idf weights known unknown words low high pk high low compute c j word c j fig represent distributions words support k absolute difference renormalized idf weights furthermore fig scatter plot dot represent word coordinates idf k weights low correlation indicates k learns different signal idf scatter plot dot word coordinates probability k renomalized idf optimal krenormalized idfsabsolute differenceoptimal k inferred hplidfs
