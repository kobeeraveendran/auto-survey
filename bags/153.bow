m l c s c v v x r abstractive summarization semantic representations fei liu jeffrey flanigan sam thomson norman sadeh noah smith school computer science carnegie mellon university pittsburgh pa usa feiliu jflanigan sthomson sadeh cmu edu abstract present novel abstractive summarization framework draws recent ment treebank abstract meaning representation amr framework source text parsed set amr graphs graphs transformed summary graph text generated summary graph focus graph graph transformation reduces source semantic graph summary graph ing use existing amr parser ing eventual availability amr text generator framework data driven trainable specically designed particular domain experiments standard amr annotations system parses promising results code available com summarization introduction abstractive summarization elusive ical capability textual summaries tent generated demand rise high quality summaries lengthy texts e books bamman smith texts known prohibitively difcult people derstand e website privacy policies sadeh et al non textual media e videos image collections kim et al kuznetsova et al zhao xing extractive compressive summarization techniques simply sufce believe challenge stractive summarization deserves renewed attention propose recent developments semantic analysis important role play conduct rst study exploring bility abstractive summarization system based transformations semantic representations abstract meaning representation amr narescu et al example sentences amr graphs shown fig amr common earlier formalisms kasper dorr et al today annotated corpus prised amr analyzed english tences knight et al automatic amr parser jamr flanigan et al available framework summarization consists steps illustrated fig parsing sentences individual amr graphs bining transforming graphs single summary amr graph generating text summary graph paper focuses step treating structured prediction problem assume text documents use jamr step use simple method read bag words summary graph allowing evaluation leave text generation amr step future work graph summarizer described rst merges amr graphs input sentence concept merging step coreferent nodes graphs merged sentence conjunction step connects root sentence s amr graph dummy root node optional principle framework applied puts image collections amr parsers able concepts english words dog propbank event predicates special keywords person example resents propbank roleset corresponds rst sense chase according banarescu et al amr uses approximately relations rolesets core semantic relations e adopted propbank annotations ontonotes hovy et al semantic lations include location mode time topic amr provide detailed descriptions banarescu et al scribe amr bank sentence corpus tated amr experts step framework converts input document sentences amr graphs use statistical mantic parser jamr flanigan et al trained amr bank jamr s current mance test dataset f analyze effect amr parsing errors paring jamr output gold standard annotations input sentences experiments addition predicting amr graphs sentence jamr provides alignments spans words source sentence fragments predicted graph example graph fragment headed date entity aligned kens april use alignments simple text generation module step dataset build evaluate framework require dataset includes inputs summaries gold standard amr annotations allows use statistical model step graph rization separate errors step amr parsing important determining approach worth investment fortunately proxy report section amr bank knight et al suits needs isi amr amr guidelines pdf parse quality evaluated smatch cai knight measures accuracy concept lation predictions jamr trained domain training portion experiments multi document summarization datasets ones duc tac competitions gold standard amr annotations figure toy example sentences parsed vidual amr graphs step step conducts graph formation produces single summary amr graph text generated summary graph step graph expansion step additional edges added create fully dense graph level steps result single connected source graph subset nodes arcs source graph selected inclusion summary graph ideally condensed sentation salient semantic content source briey review amr jamr present dataset paper main algorithm presented discuss ple generation step experiments sure intrinsic quality graph transformation algorithm quality terms selected summary explore variations transformation learning gorithm oracle upper bounds kinds background abstract meaning representation jamr amr provides sentence semantic sentation represented rooted directed acyclic graph fig nodes amr graph labeled concepts edges labeled relations saw joe s dog running garden sentence b dog chasing cat joe s dog chasing cat garden docs source graph ave sents summ doc nodes edges expand train dev test table statistics dataset expand shows number edges performing graph expansion numbers averaged documents split use ofcial split dropping training document summary sentences annotated proxy report created annotators based gle newswire article selected english gaword corpus report header contains metadata date country topic short summary report body generated editing rewriting content newswire article approximate style analyst report single ument summarization task sentences paired gold standard amr annotations table vides overview dataset graph summarization given amr graphs sentences step graph summarization transforms single summary amr graph step accomplished stages source graph tion subgraph prediction source graph construction source graph single graph constructed ing individual sentences amr graphs ing identical concepts amr formalism entity event canonicalized represented single graph fragment regardless times referred sentence ple extended multiple sentences ideally resulting source graph redundancy cause repeated mentions concept input signal importance later encode frequency mentions feature subgraph prediction concept merging involves collapsing certain graph fragments single concept merging concepts label collapse graph fragments headed entity date entity named entity figure graph fragments collapsed single concept assigned new concept label fragment structure collapsed named entity combined parent e son concept node child parent graph fragments trated fig choose named date entity concepts appear frequently refer different entities e april vs nov collapsing collapsed graph fragment assigned new label concatenating consisting concept edge bels fragment collapsed new cept node merged tical fragments process wo nt recognize erent concepts like barack obama obama future work porate entity coreference resolution event coreference resolution concept nodes sent concept merging step pair cepts multiple labeled edges merge edges given pair concepts single unlabeled edge ber common labels group edge label feature table ensure source graph connected add new root node connect cept originally root sentence graph fig apply procedure documents dataset source graphs contain nodes edges average investigated automatically constructed source graphs cover gold standard summary graphs produced amr annotators ally source graph cover standard edges summarization complished selecting subgraph source dayyeardate pansion increases average number edges factor fig illustrates vation document level expansion covers standard summary edge garden expansion computationally prohibitive sentence level expansion adds edge dog garden enables prediction ture similar semantic meaning joe s dog garden chasing cat subgraph prediction pose selection summary subgraph source graph structured prediction lem trades including important formation altering meaning ing brevity producing uent language nenkova mckeown incorporate cerns form features constraints statistical model subgraph selection let g v e denote merged source graph node v v represents unique cept directed edge e e connects concepts g connected directed node labeled graph edges graph unlabeled edge labels predicted subgraph selection seek maximize score factorizes graph nodes edges included mary graph subgraph v vv v feature representations node v edge e respectively describe node edge features table vectors empirically estimated coefcients linear model formulate selection subgraph integer linear programming ilp describe supervised learning parameters efcients collection source graphs paired summary graphs decoding cast decoding ilp constraints sure output forms connected nent source graph index source graph concept nodes j giving root node figure source graph formed sentence amr graphs concept collapsing merging graph expansion demonstrated edges unlabeled root node added ensure connectivity edges added optional sion step corresponding document level expansion respectively concept nodes included summary graph shaded summary edge coverage expand sent doc labeled unlabeled train dev test table percentage summary edges ered automatically constructed source graph graph table columns port labeled unlabeled edge coverage beled counts edges matching source destination concepts identical labels ignores edge label order improve edge coverage explore expanding source graph adding ble edge pair concepts sentence explored adding sible edge pair concepts tire source graph edges newly introduced expansion receive default label null report unlabeled edge coverage table columns respectively subgraph prediction infeasable document level sion conducted experiments sentence level expansion sentence level graph graph saw joe s dog running garden sentence b dog chasing cat node features edge features concept freq depth position span entity bias identity feature concept label concept freq input sentence set binary feature dened frequency threshold average smallest depth node root sentence graph binarized depth thresholds average foremost position sentences containing concept binarized position thresholds average longest word span concept binarized length thresholds word spans obtained jamr binary features indicating concept named entity date entity bias term node second frequent edge labels concepts relative freq label binarized thresholds edge frequency label non expanded edges document sentences binarized frequency thresholds average foremost position sentences containing edge label binarized position thresholds node features extracted source target nodes node features bias term label freq position nodes isexpanded binary feature indicating edge graph expansion edge freq label occurrences bias bias term edge table node edge features binarized index let n number nodes graph let vi ei j binary variables vi iff source node included ei j iff directed edge node node j included ilp objective maximized equation rewritten present notation n vi node score ei j j edge score note objective linear vi ei j features coefcients folded node edge scores treated constants coding constraints required ensure selected nodes edges form valid graph particular edge j selected ei j takes value endpoints j included vi ei j vj ei j n connectivity enforced set commodity ow variables fi j taking negative integral value representing ow node j root node sends n units ow reach included node equation included node consumes unit ow ected difference incoming going ow equation flow sent edge edge included equation vi fi j fj k vj j n amr representation allows graph cies concept nodes having multiple parents reentrancies rare edges entrancies dataset preliminary study force summary graph tree structured requiring incoming edge node j ei j n interestingly formulation far equates ilp solving prize collecting steiner tree problem pcst segev known np complete karp ilp tion modied ljubic et al flow based constraints tree structures previously nlp dependency ing martins et al sentence sion thadani mckeown iments use exact ilp approximate methods available finally optional constraint x size summary graph measured number edges l j ei j l performance summarization systems depends strongly compression rate systems directly comparable compression rates similar napoles et al l supplied system control summary graph size n ei fi j n gurobi com parameter estimation experiments given collection input output pairs source graphs summary graphs natural ing place learning coefcients structured perceptron collins easy implement performs tively incorporating factored cost functions structured hinge loss leads structured support vector machine svm taskar et al learned similar stochastic mization algorithm scenario gold standard summary graph actually subset source graph machine tion ramp loss found work ations gold standard output hypothesis space model gimpel smith structured perceptron hinge ramp losses compared table explore learning minimizing perceptron hinge ramp losses optimized adagrad duchi et al stochastic timization procedure let model parameter coefcient let ent loss instance considered tth iteration respect given initial step size update iteration t generation generation amr like representations ceived attention e langkilde knight described statistical method know work progress driven goal machine translation amr currently system available use heuristic approach ate bag words given predicted subgraph system summary created nding quently aligned word span concept node recall jamr parser provides ments words resulting spans generated particular order natural language summary suitable unigram based summarization evaluation methods like table report performance subgraph prediction end end summarization test set gold standard automatic amr parses input gold standard amr annotations model training conditions testing apply trained model source graphs constructed gold standard jamr parses experiments use ber edges gold standard summary graph x number edges predicted subgraph allowing direct comparison conditions subgraph prediction evaluated standard amr graphs summaries report cision recall nodes edges oracle results subgraph prediction stage obtained ilp decoder minimize cost output graph given gold standard assign wrong nodes edges score correct nodes edges score decode structural constraints subgraph prediction resulting graph best summary graph hypothesis space model provides upper bound performance able framework oracle performance node prediction range gold standard amr annotations ing jamr output edge prediction lower mance yielding gold standard jamr parses graph expansion plied numbers increased spectively uncovered summary edge e covered source graph major source low recall values edge prediction table graph expansion slightly alleviates issue summarization evaluated comparing tem summaries reference summaries scores lin system summaries generated heuristic approach presented given predicted subgraph approach nds frequently aligned word span cept node puts bag words particularly usefully recall equal number edges xed version options data structured perceptron loss structured hinge loss structured ramp loss max max g max g g g g g max g table loss functions minimized parameter estimation g denotes gold standard summary graph score dened equation g penalizes vertex edge g g g g cost factors like scoring function max operation accomplished variant ilp decoding cost incorporated linear objective constraints remain standard parses jamr parses perceptron hinge ramp ramp expand oracle oracle expand perceptron hinge ramp ramp expand oracle oracle expand subgraph prediction p nodes r f edges f summarization r f p table subgraph prediction summarization bag words results test set gold standard amr annotations model training conditions expand means result obtained source graph expansion edge performance measured ignoring labels uating formed summaries generated speech transcripts liu liu oracle summaries produced taking gold standard amr parses reference mary obtaining frequently aligned word span unique concept node jamr aligner generating bag words summary evaluation oracle summaries formed manner system maries process involve graph expansion summarization performance conditions oracle oracle expand nd jamr parses large source degradation edge prediction performance smaller signicant source degradation concept prediction surprisingly jamr parses leads slightly improved scores mind bag words generator scores depend concept prediction unaffected edge prediction oracle summarization results scores gold standard jamr parses spectively suggest improved graph marization models step benet future improvements amr parsing step conditions evaluations nd incorporating cost aware loss function hinge vs little effect ing ramp loss leads substantial gains table detailed results graph expansion expand means sults obtained expanded source graph nd graph expansion marginally affects system performance graph expansion slightly hurts system performance edge prediction ample ramp loss jamr parser input obtained node edge prediction graph expansion edge expansion hand creases oracle performance large margin suggests training data sophisticated model able better nate enlarged output space graph sion promise helpful related future work according dang owczarzak jority competitive summarization systems tractive selecting representative sentences documents concatenating form summary combined sentence compression allowing sentences ilps approximations cluded budget encode compression tion mcdonald martins smith gillick favre berg kirkpatrick et al almeida martins li et al decoding approaches included greedy method exploiting submodularity lin bilmes document reconstruction et al graph cuts qian liu previous work abstractive summarization explored user studies compare extractive nlg based abstractive summarization carenini cheung ganesan et al pose construct summary sentences repeatedly searching highest scored graph paths gerani al generate abstractive summaries fying discourse parse trees work similar spirit cheung penn splices recombines dependency parse trees produce stractive summaries contrast work operates semantic graphs taking advantage recently developed amr bank related work graph based rization methods vanderwende et al erkan radev mihalcea tarau derwende et al transform input cal forms score nodes pagerank grow graph high value nodes heuristics erkan radev mihalcea rau graph connects surface terms co occur cases graphs constructed based surface text representation propositional semantics like amr future work explore similar graph based calculations contribute features subgraph selection framework constructed source graph easily reach times size sentence dency graph efcient graph decoding algorithms e based lagrangian relaxation approximate algorithms explored future work future directions include jointly performing subgraph edge label prediction ploring pipeline consists tomatic amr parser graph graph summarizer amr text generator devising uation metric better suited abstractive marization domains stand eventually benet summarization include books audio video segments legal texts conclusion introduced statistical abstractive rization framework driven abstract meaning representation centerpiece approach structured prediction algorithm transforms mantic graphs input single summary mantic graph experiments approach promising suggest directions future research acknowledgments authors thank anonymous reviewers insightful input grateful nathan schneider kevin gimpel sasha rush ark group valuable discussions research supported nsf grant darpa grant funded deft program u s army research laboratory u s army research ofce contract grant number iarpa doi nbc contract number views conclusions contained thors interpreted necessarily representing ofcial policies endorsements expressed implied sponsors references miguel b almeida andre f t martins fast robust compressive summarization dual composition multi task learning proceedings acl david bamman noah smith new ment methods discriminative book summarization laura banarescu claire bonial shu cai madalina georgescu kira griftt ulf hermjakob kevin knight philipp koehn martha palmer nathan schneider abstract meaning representation sembanking proceedings linguistic annotation workshop taylor berg kirkpatrick dan gillick dan klein jointly learning extract compress proceedings acl shu cai kevin knight smatch evaluation metric semantic feature structures proceedings acl giuseppe carenini jackie chi kit cheung extractive vs nlg based abstractive summarization evaluative text effect corpus ity proceedings fifth international natural language generation conference inlg jackie chi kit cheung gerald penn pervised sentence enhancement automatic rization proceedings emnlp michael collins discriminative training ods hidden markov models theory ments perceptron algorithms proceedings emnlp hoa trang dang karolina owczarzak overview tac update summarization task proceedings text analysis conference tac bonnie dorr nizar habash david traum thematic hierarchy efcient generation lexical conceptual structure david farwell rie gerber eduard hovy editors machine lation information soup proceedings conference association machine translation americas lecture notes puter science springer john duchi elad hazan yoram singer adaptive subgradient methods online learning stochastic optimization journal machine learning research gunes erkan dragomir r radev lexrank graph based lexical centrality salience text journal articial intelligence marization search jeffrey flanigan sam thomson jaime carbonell chris dyer noah smith discriminative graph based parser abstract meaning tation proceedings acl kavita ganesan chengxiang zhai jiawei han opinosis graph based approach tive summarization highly redundant opinions proceedings coling shima gerani yashar mehdad giuseppe carenini mond t ng bita nejat abstractive marization product reviews discourse ture proceedings emnlp dan gillick benoit favre scalable global proceedings model summarization naacl workshop integer linear programming natural langauge processing kevin gimpel noah smith structured ramp loss minimization machine translation proceedings naacl hlt zhanying chun chen jiajun bu wang lijun zhang deng cai xiaofei document summarization based data reconstruction ceedings aaai eduard hovy mitchell marcus martha palmer lance ramshaw ralph weischedel ontonotes solution proceedings naacl richard m karp reducibility torial problems complexity computer tations pages springer robert t kasper exible interface linking applications penman s sentence generator ceedings darpa speech natural language workshop gunhee kim leonid sigal eric p xing joint summarization large scale collections web ages videos storyline reconstruction ceedings cvpr kevin knight laura baranescu claire bonial madalina georgescu kira griftt ulf hermjakob daniel marcu martha palmer nathan schneider abstract meaning representation amr annotation release web download phia linguistic data consortium polina kuznetsova vicente ordonez tamara l berg yejin choi treetalk composition compression trees image descriptions tions acl irene langkilde kevin knight generation exploits based statistical knowledge proceedings coling chen li yang liu fei liu lin zhao fuliang weng improving multi documents summarization sentence compression based expanded constituent parse tree proceedings emnlp hui lin jeff bilmes multi document marization budgeted maximization submodular functions proceedings naacl chin yew lin rouge package matic evaluation summaries proceedings acl workshop text summarization branches lucy vanderwende michele banko arul menezes event centric summary generation ings duc bin zhao eric p xing quasi real time proceedings marization consumer videos cvpr fei liu yang liu abstractive speech summarization exploring unsupervised vised approaches spoken utterance compression ieee transactions audio speech language processing ivana ljubic rene weiskircher ulrich pferschy nar w klau petra mutzel matteo fischetti algorithmic framework exact solution prize collecting steiner tree problem matical progamming series b andre f t martins noah smith rization joint model sentence extraction proceedings acl workshop compression integer linear programming natural language processing andre f t martins noah smith eric p xing concise integer linear programming tions dependency parsing proceedings acl ryan mcdonald study global inference gorithms multi document summarization ceedings ecir rada mihalcea paul tarau textrank ing order text proceedings emnlp courtney napoles benjamin van durme chris callison burch evaluating sentence pression pitfalls suggested remedies ceedings workshop monolingual text text generation mttg pages stroudsburg pa usa association computational linguistics ani nenkova kathleen mckeown automatic summarization foundations trends tion retrieval xian qian yang liu fast joint compression summarization graph cuts proceedings emnlp norman sadeh alessandro acquisti travis d breaux lorrie faith cranor aleecia m mcdonald joel r reidenberg noah smith fei liu n cameron russell florian schaub shomir wilson usable privacy policy project technical report cmu carnegie mellon university arie segev node weighted steiner tree problem networks ben taskar carlos guestrin daphne koller max margin markov networks advances neural information processing systems kapil thadani kathleen mckeown sentence compression joint structural inference ceedings conll
