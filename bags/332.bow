supmmd sentence importance model extractive summarization maximum mean discrepancy umanga alexander patrick aditya krishna menon lexing national university canberra act australia google research new york united states bista alex mathews lexing edu com abstract work multi document summarization focused generic summarization mation present individual document set explored setting update summarization goal identify new information present set equal practical interest presenting readers updates evolving news topic work present supmmd novel technique generic update summarization based maximum mean discrepancy kernel sample testing supmmd combines supervised learning salience vised learning coverage diversity ther adapt multiple kernel learning use similarity multiple information sources text features knowledge based concepts efcacy supmmd generic update summarization tasks meeting exceeding current state art datasets introduction multi document summarization problem producing condensed digests salient information multiple sources articles concretely suppose given sets articles denoted set set related topic climate change pandemic separated publication timestamp geographic region identify possible instantiations multi document summarization figure generic summarization goal summarize set individually comparative summarization goal summarize set set highlighting differences iii update summarization goal generic summarization set comparative summarization set versus existing work topic focused generic summarization task figure different summarization tasks generic comparative update sets articles set denoted red blue circles respectively summary prototypes bold circles information coverage tasks lled respective colors update summarization equal practical interest intuitively comparative aspect setting aims inform user new information topic familiar extractive multi document summarization methods unsupervised supervised pervised methods typically dene salience erage global model sentence sentence similarity methods based retrieval goldstein centroids radev graph centrality erkan radev utility maximization lin bilmes gillick favre explored sentence salience depends surface features position length presence cue words effectively capturing requires supervised models specic dataset task body work incorporated information supervised learning example based point processes kulesza taskar learning important words hong nenkova graph neural networks yasunaga support vector regression varma supervised methods separate model learning inference leading disconnect learning sentence salience sentence selection varma yasunaga hong nenkova designed specically generic summarization kulesza taskar work propose supmmd single model learning salience inference applied generic comparative summarization following contributions present supmmd novel technique generic update summarization combines supervised learning salience unsupervised learning coverage diversity supmmd single model learning inference adapt multiple kernel learning cortes model allows similarity multiple information sources text features knowledge based concepts supmmd meets exceeds state art generic update tion datasets literature review multi document summarization extractive salient pieces original text sentences selected form summary abstractive new text generated paraphrasing important information popular creates semantically matically correct summaries nallapati work focus generic update document summarization extractive setting extractive summarizers nents sentence scoring selection variety unsupervised supervised methods developed unsupervised sentence scorers based centroids radev graph centrality erkan radev retrieval relevance goldstein word statistics nenkova vanderwende topic models haghighi vanderwende concept coverage gillick favre lin bilmes supervised techniques include graph based neural network yasunaga learning sentence quality point processes kulesza taskar combining word importances hong nenkova combining sentence phrase importances cao employing mixture submodular functions lin bilmes sentence selection methods broadly egorized greedy methods goldstein radev erkan radev nenkova vanderwende cao haghighi vanderwende hong nenkova kulesza taskar cao varma produce approximate solutions iteratively selecting sentences maximal score exact integer linear programming ilp based methods gillick favre cao greedy methods use objective belongs special class set functions called submodular functions lin bilmes kulesza taskar good approximation guarantees greedy optimization nemhauser limited research update comparative summarization notable prior work includes maximizing concept coverage ilp gillick learning sentence scores support vector regressor varma temporal content ltering zhang bista cast comparative summarization problem classication use mmd gretton work adapt method learn sentence importances driven surface features summarization classication review perspective introduced bista summarization viewed classication provide brief introduction maximum mean discrepancy mmd ideas form basis subsequent method generic summarization classication let topics articles wish summarize topic wish select summary sentences bista lated summarization selecting prototypes minimize accuracy powerful classier sentences input summary intuition powerful classier able distinguish sentences articles summary sentences formally pick argmax sst comprise subsets upto words accuracy best possible classier distinguishes elements sets shall shortly realize mmd comparative summarization competing binary classication comparative summarization sets bista introduced additional term giving rise competing goals classier able distinguish summaries sentences set able distinguish maries sentences set formally let set sentences set sentences set compare set suitable seek summary sentences set argmax sst hyperparameter controls relative tance accurately representing articles set versus representing articles set maximum mean discrepancy mmd mmd kernel based measure distance distributions formally denition let reproducing kernel hilbert space rkhs associated kernel let set functions unit ball topological space mmd distributions maximal difference expectations functions gretton sup small mmd value indicates similar given nite samples empirical estimate mmd denoted computed mmd summarization mmd corresponds minimal achievable loss centroi based kernel classier rumbudur consequently use approximate suitable kernel measures similarity sentences intuitively selects summaries best represent distribution original sentences note expand later rst term irrelevant optimization second term capture coverage diversity summary tences supervision unsupervised summarization supmmd method start developing technique incorporating sentence importance mmd purpose generic multi document extractive summarization extend method comparative summarization incorporate multiple different kernels use diverse sets features mmd weighted mmd cover unsupervised mmd bista selects relevant representative sentences concepts retaining diversity notion representativeness based global model sentence sentence similarity notion representativeness necessarily matched selection salient information salience sentence determined surface features position article number words example news articles written sentences start article characteristics summary kedzie learning notion salience specic summarization task dataset requires supervised training extend mmd model porating supervised sentence importance weighting let independent samples drawn distributions article sentences summary sentences space sentences dene non negative importance functions parameterized learnable parameters restrict functions epf eqf equipped modify mmd importance sentences good summary candidates increased denition weighted mmd sup note classic mmd special case practice supremum impossible compute directly derive alternative form equation lemma equivalently canonical feature mapping sentences summaries rkhs derivation mirrors similar derivation mmd gretton given appendix importance function use log linear models importance functions common choice sentence tance kulesza taskar easy training data scarce formally log linear importance function surface features sentence dene empirical estimates importance functions number sentences number summary sentences topic training generic summarization parameters log linear importance function learned data dene loss function based weighted mmd let training tuples loss topic square importance weighted empirical mmd sentences summary sentences topic weighted trick equation gives appendix empirical estimate applying kernel equation loss single topic training instead minimize average loss topics training set intuitively learn min parameters minimizing importance weighted distance sentences ground truth summary sentences topics training comparative summarization extend learning task comparative marization competing binary classiers idea bista specically replace accuracy terms equation square weighted mmd given comparative training tuples objective minimize min note sets importance parameters document sets multiple kernel learning employ multiple kernel learning mkl use data multiple sources mmd summarization framework adapt stage kernel learning cortes different kernels linearly combined maximize alignment target kernel classication problem mmd interpreted classiability sriperumbudur mkl neatly mmd based summarization objective intuitively mkl identify good combination kernels building classier separates summary non summary sentences untkt let kernel functions topic let kernel matrix according kernel function iunt centered kernel matrix unt let ground truth summary labels iff target kernel represents ideal notion similarity sentences non negative kernel weights lead optimal alignment target kernel given cortes min rpp kernel function characteristic mmd valid metric muandet popular kernels bag words like text features including idf linear kernel cosine kernel characteristic budur fortunately exponential kernel characteristic kernel steinwart use normalized exponential kernel combined cosine kernel inference given learned importance function best set summary sentences generic summarization argmax sst similarly comparative task learned importance functions seek extract relevant text perform sentence word tokenization duc clean text regular expressions details provided code release train punktsentencetokenizer detect sentence boundaries use standard nltk bird word tokenizer tac dataset use preprocessing pipeline employed gillick enables cleaner comparison state art icsi gillick method tac dataset datasets sentences words yasunaga argmax sst feature representations inference problems budgeted maximization problems solved greedy algorithms lin bilmes generic unsupervised summarization task submodular monotone certain tions kim greedy algorithms good theoretical guarantees nemhauser supervised variants guarantees greedy optimization nonetheless leads good solutions experimental setup include guidance applying supmmd details required reproduce experiments datasets use standard multi document tion benchmark datasets dataset statistics provided table datasets multiple topics topic turn multiple news articles human written summaries setting use training set test set setting use training set test set settings common literature duc datasets generic summarization tac update summarization task generic set comparative summarization set data preprocessing preparation duc tac datasets provided collections xml documents necessary nist gov data html method requires different sets sentence features text features compute sentence sentence similarity kernel surface features learning sentence importance model text features sentence different feature sentations unigrams bigrams entities unigrams stemmed words stop words nltk english list removed bigrams combination stemmed unigrams bigrams entities dbpedia concepts extracted dbpedia spotlight mendes use term frequency inverse sentence frequency isf neto tation text features isf extensively multi document summarization dias alguliev wan surface features use surface features duc dataset tac dataset position position features indicators denote later position sentence article nal feature gives position relative length article counts count features number words number nouns use spacy speech tagging nouns tsf sum isf scores unigrams composing sentence sentence inverse sentence frequency unigram term frequency com benob icsisumm dataset topics sents avg summ sents avg summ sents oracle oracle liu lapata table dataset statistics oracle performance report number topics dataset number sentences preprocessing rouge scores oracle method liu lapata average number sentence summary method btsf boosted sum isf scores unigrams composing sentence specically compute boost score unigrams appear rst sentence article generic summarization comparative summarization gillick unigrams appear rst sentence article lexrank lexrank score erkan radev computed bigrams cosine similarity tac datasets additionally use indicator sentence begins paragraph provided cessing pipeline icsi gillick qsim fraction topic description unigrams present sentence topic descriptions available tac oracle extraction duc tac provide human written summaries topic goal tive summarization supervised training need know sentences articles construct summaries training set article sentences best match abstractive summaries called oracles algorithm oracle extraction function argmax return extraction score human maries word budget reached include sentences words gested yasunaga set budget words ensure oracle summaries words consistent evaluation contrast liu lapata uses recall score lin method balances recall scores harmonic mean explicitly accounts sentence length grid search validation sets shows optimal value different datasets summarization tasks reported table average method produces oracles consisting sentences higher scores compared oracles liu lapata consistent datasets implementation details supervised variants use regularized log linear model importance trained oracles ground truth selected number training epochs fold cross validation tune hyperparameters training set hyperparameters generic tion task parameter kernel regularization weight log linear importance function denes length dependent scaling factor greedy selection lin bilmes comparative objective additional hyperparameter controls comparativeness implementation details provided appendix implementation publicly evaluation settings extraction algorithm algorithm spired liu lapata greedily select sentences provide maximum gain evaluate methods use rouge lin metric choice evaluating com computationalmedia supmmd generic summarization hong nenkova cho yasunaga kulesza taskar update summarization varma gillick favre zhang rouge metrics shown correlate human judgments lin generic summarization task recent work bista shows human judgments consistent automatic metrics evaluating comparative summaries duc tac evaluations use rst words generated summary evaluation setup mirrors hong allows compare performance state art methods reported works evaluated standard datasets report recall scores datasets set adopt evaluation settings compare best performing systems standard dataset report rouge recall scores baselines select performing methods recent benchmark paper hong serve baselines report rouge scores benchmark paper icsi integer linear programming method maximizes coverage gillick dpp determinantal point process method learns sentence quality maximizes diversity kulesza taskar submodular method based learned mixture submodular functions lin bilmes method base topic ing conroy regsum method focuses learning word importance hong nenkova lexrank popular graph based sentence scoring method erkan radev include recent deep learning methods evaluated setup hong report rouge scores individual papers dppsim extension dpp model learns sentence sentence similarity rouge args nist summarization args capsule network cho himap recurrent neural model employs modied pointer generator component fabbri model uses graph convolution network combined recurrent neural network learn sentence saliency yasunaga baselines dataset use systems competition task resulting systems altogether best knowledge systems current state art report rouge scores competition systems icsi variants sys uses integer linear programming maximize coverage concepts gillick sys additionally uses sentence compression generate new candidate sentences iit uses support vector regressor predict sentence rouge scores varma ictcas temporal method zhang icl manifold ranking based method ltering content experimental results compare methods baselines datasets present variants method analyze effects different components modeling choices report performance unsupervised mmd unsupmmd explicitly consider sentence importance supervised method supmmd report performance bigram kernel supmmd combined kernels supmmd mkl evaluated impact oracle extraction method replacing extraction method suggested liu lapata supmmd alt oracles supmmd mkl compress presents result applying sentence compression gillick model generic summarization performance methods generic summarization task shown table dataset supmmd variants exceed state art evaluated perform similarly best existing methods evaluated icsi gillick dpp kulesza taskar submodular lin bilmes conroy regsum hong nenkova lexrank erkan radev dpp sim cho himap fabbri yasunaga unsupmmd supmmd alt oracle supmmd supmmd mkl compress supmmd mkl table results generic multi document summarization task best system supmmd mkl outperforms previous best system icsi score dpp baseline achieves highest score relatively low score suggests optimized unigram performance cost bigram performance supmmd mkl strikes better balance scoring best second best generic summarization task table supmmd mkl model outperforms state art icsi model rouge specically supmmd mkl scores best icsi variant scores supervised modeling models supervised training identify important sentences tially outperform unsupervised method supmmd fact unsupmmd lowest ing method metrics datasets strongly indicates degree supervision essential perform task importance function suitable way adapt unsupmmd model supervised training observe strong correlation relative position sentence score given supmmd observation consistent previous works kedzie strates supmmd learned use surface features capture salience details ture correlations provided appendix oracle extraction oracle extraction technique transforming abstractive training data extractive training data helps supmmd methods achieve higher rouge performance alternative technique developed liu lapata gillick gillick varma zhang unsupmmd supmmd alt oracle supmmd supmmd mkl compress supmmd mkl table results generic multi document summarization task set implemented supmmd alt oracle gives lower performance technique example supmmd alt oracle supmmd advantages proposed cle extraction method substantial consistent multiple datasets evaluation metrics multiple kernel learning observe combining multiple kernels helps performance supmmd models generic summarization task supmmd mkl combines bigram entity kernels supmmd uses bigrams kernel scores multiple kernels clearer gains dataset sentence compression incorporated post processing steps supmmd mkl compress clearly improve results supmmd mkl compression clearly reduces performance supmmd mkl compress higher score lower score supmmd mkl incorporating compression summarization pipeline appealing direction future work comparative summarization results comparative summarization task dataset shown table supervised mmd variants supmmd mmd mkl outperform state art baseline icsi rouge fall short hard claim method superior instance supmmd uses substantially different approach icsi provides alternative state art supmmd conclusion icsi sys gillick icsi sys gillick iiit sys varma icl sys unsupmmd supmmd alt oracle supmmd supmmd mkl compress supmmd mkl table results comparative document summarization task set maps set techniques useful comparative summarization generic summarization task supervised training method oracle extraction method essential achieving good performance rouge identify sentence position btsf important features sentence salience appendix multiple kernels supmmd mkl relatively little effect reducing score slightly higher achieved supmmd similar small decrease seen rouge manual inspection shows summaries supmmd supmmd mkl methods largely identical differences primarily topic covers political movements nepal key entities topic resolved accurately dbpedia spotlight contributing additional noise affecting mkl approach model variants tested additional variant model comparative summarization denes different importance functions document sets details contrast supmmd single importance function shared document sets equation performed substantially worse supmmd metrics example supmmd conjecture single importance function performs better training data relatively scarce reduces number parameters simplies learning problem techniques tying eters importance functions hierarchical bayesian model left future work work present supmmd novel technique update summarization based maximum mean discrepancy supmmd combines supervised learning salience unsupervised learning coverage diversity adapt multiple kernel learning exploit multiple sources similarity text features knowledge based concepts efcacy supmmd generic update tion tasks standard datasets compared existing approaches portance model introduce existing unsupervised mmd bista improves summarization performance substantially generic comparative summarization tasks future work leave task rating embeddings features bert devlin evaluating large generic multi document summarization dataset news fabbri acknowledgments work supported data decisions crc arc discovery project research supported use nectar research cloud collaborative tralian research platform supported national collaborative research infrastructure strategy thank minjeong shin helpful feedback suggestions references rasim alguliev ramiz aliguliyev makrufa hajirahimova chingiz mehdiyev mcmr maximum coverage minimum redundant text summarization model expert systems applications steven bird nltk natural language toolkit proceedings coling acl teractive presentation sessions pages sydney australia association computational linguistics umanga bista alexander patrick mathews minjeong shin aditya krishna menon lexing xie comparative document summarisation classication thirty aaai conference articial intelligence aaai thirty innovative applications articial intelligence conference iaai ninth aaai symposium educational advances articial intelligence eaai honolulu hawaii usa january february pages aaai press ziqiang cao furu wei dong sujian ming zhou ranking recursive neural networks application multi document summarization proceedings ninth aaai conference articial intelligence page aaai press natural language processing pages boulder colorado association computational linguistics daniel gillick benoit favre dilek hakkani bernd bohnet yang liu shasha xie icsi utd summarization system tac tac sangwoo cho logan lebanoff hassan foroosh fei liu improving similarity measure determinantal point processes extractive multi document summarization proceedings annual meeting association putational linguistics pages florence italy association computational linguistics jade goldstein mark kantrowitz vibhu mittal jaime carbonell summarizing text documents sentence selection evaluation metrics ings annual international acm sigir conference research development tion retrieval sigir page new york usa association computing machinery john conroy sashka davis jeff kubina kai liu dianne oleary judith schlesinger multilingual summarization dimensionality reduction step optimal term coverage proceedings multiling workshop multilingual multi document summarization pages soa bulgaria association computational linguistics conway course functional analysis second edition volume graduate texts mathematics springer verlag new york corinna cortes mehryar mohri afshin tamizadeh stage learning kernel rithms proceedings annual tional conference machine learning icml jacob devlin ming wei chang kenton lee bert pre training kristina toutanova transformers language deep bidirectional proceedings understanding ference association computational linguistics human language technologies volume long short papers pages minneapolis minnesota association computational linguistics north american chapter gal dias elsa alves jos gabriel pereira lopes topic segmentation algorithms text summarization passage retrieval exhaustive proceedings national evaluation conference articial intelligence volume page aaai press gnes erkan dragomir radev lexrank graph based lexical centrality salience text summarization artif int res alexander fabbri irene tianwei suyi dragomir radev multi news large scale multi document summarization dataset tive hierarchical model proceedings annual meeting association computational linguistics pages florence italy association computational linguistics dan gillick benoit favre scalable global model summarization proceedings workshop integer linear programming arthur gretton karsten borgwardt malte rasch bernhard schlkopf alexander smola kernel sample test aria haghighi lucy vanderwende exploring content models multi document summarization proceedings human language technologies annual conference north american chapter association computational linguistics pages boulder colorado association computational linguistics kai hong john conroy benoit favre alex kulesza hui lin ani nenkova repository state art competitive baseline summaries proceedings generic news summarization ninth international conference language resources evaluation pages reykjavik iceland european languages resources association elra kai hong ani nenkova improving estimation word importance news proceedings document summarization conference european chapter association computational linguistics pages gothenburg sweden association computational linguistics chris kedzie kathleen mckeown hal daum iii content selection deep learning models proceedings summarization conference empirical methods natural language processing pages brussels belgium association computational linguistics kim rajiv khanna oluwasanmi koyejo examples learn criticize criticism interpretability proceedings international conference neural information processing systems page red hook usa curran associates inc alex kulesza ben taskar determinantal point processes machine learning publishers inc hanover usa sujian wei wang yongwei zhang tac update summarization icl tac yujia kevin swersky richard zemel generative moment matching networks ceedings international conference international conference machine learning volume page jmlr org chin yew lin rouge package automatic text summarization evaluation summaries branches pages barcelona spain association computational linguistics hui lin jeff bilmes multi document marization budgeted maximization submodular functions human language technologies annual conference north american association computational chapter linguistics pages los angeles california association computational linguistics hui lin jeff bilmes class submodular functions document summarization ings annual meeting association computational linguistics human language technologies pages portland oregon usa association computational linguistics hui lin jeff bilmes learning mixtures submodular shells application document summarization page arlington virginia usa auai press dong liu jorge nocedal limited memory bfgs method large scale optimization mathematical programming yang liu mirella lapata text summarization proceedings pretrained encoders conference empirical methods natural language processing international joint conference natural language processing emnlp ijcnlp pages hong kong china association computational linguistics pablo mendes max jakob andrs garca silva christian bizer dbpedia spotlight shedding light web documents proceedings international conference semantic systems semantics page new york usa association computing machinery krikamol muandet kenji fukumizu bharath budur bernhard schlkopf kernel mean embedding distributions review foundations trends machine learning ramesh nallapati feifei zhai bowen zhou summarunner recurrent neural network based sequence model extractive summarization documents proceedings thirty aaai conference articial intelligence page aaai press george nemhauser laurence wolsey marshall fisher analysis tions maximizing submodular set functions mathematical programming ani nenkova lucy vanderwende impact frequency summarization microsoft research redmond washington tech rep msr joel larocca neto alexandre santos celso kaestner neto alexandre santos document clustering text summarization ganapati patil calyampudi rao weighted distributions size biased sampling applications wildlife populations human families biometrics pages dragomir radev hongyan jing magorzata stys daniel tam centroid based summarization multiple documents information processing management bharath sriperumbudur kenji fukumizu arthur gretton gert lanckriet bernhard schlkopf kernel choice classiability rkhs embeddings probability distributions proceedings international conference neural information processing systems page red hook usa curran associates inc bharath sriperumbudur arthur gretton kenji fukumizu bernhard schlkopf gert lanckriet hilbert space embeddings metrics probability measures journal machine learning research ingo steinwart inuence kernel consistency support vector machines journal machine learning research vasudeva varma prasad pingali rahul katragadda sai krishna surya ganesh kiran sarvabhotla harish garapati hareen gopisetty vijay bharath reddy kranthi reddy iiit hyderabad tac tac xiaojun wan jianwu yang jianguo xiao iterative reinforcement approach simultaneous document summarization keyword extraction proceedings annual meeting association computational linguistics pages prague czech republic association computational linguistics michihiro yasunaga rui zhang kshitijh meelu ayush pareek krishnan srinivasan dragomir radev graph based neural multi document marization proceedings conference computational natural language learning conll pages vancouver canada association computational linguistics manzil zaheer sashank reddi devendra sachan satyen kale sanjiv kumar adaptive methods nonconvex optimization bengio wallach larochelle grauman bianchi garnett editors advances neural information processing systems pages curran associates inc jin zhang pan hongbo xueqi cheng ictgrasper temporal preferred update summarization proceedings second text analysis conference tac gaithersburg maryland usa november background theory kernels mmd section provide brief overview kernels maximum mean discrepancy mmd detailed overview refer readers muandet gretton brief overview taken positive denite kernels kernel trick denition function called positive denite kernel symmetric gram trix positive denite cnr theorem kernel positive denite exists feature map known kernel trick machine learning feature space called ing kernel hilbert space rkhs kernel known reproducing kernel reproducing kernel hilbert space denition rkhs hilbert space functions function evaluations bounded rkhs function evaluation canonical feature map associated rkhs rkhs fully characterized reproducing kernel positive denite nel uniquely determines rkhs vice versa known riesz representer theorem conway mmd recall class rkhs functions unit ball suppose admits feature map gretton solve supremum equation mmd computed distance tween mean feature embeddings distribution suitable kernel based feature space gretton involves explicitly evaluating arbitrarily high dimensional features instead kernel trick allows efcient computation evaluating pairwise kernels supposing induced kernel characteristic kernel distribution kernel feature map kernel mean map kernel characteristic map injective characteristic kernel ensures mmd information lost mapping distribution rkhs muandet examples characteristic kernels include gaussian kernel laplace kernel mmd gaussian kernel equivalent comparing moments distributions proof lemma weighted mmd contains functions unit ball rkhs dened sup recall non negative importance weighting function according patil rao weighted probability density similarly weighted mmd restrict sup sup rkhs simplies sup penultimate step follows dual norm proof similar mmd gretton empirical estimate expanded applying kernel trick loss generic summarization recalling training details train generic summarization model batch lbfgs liu nocedal learning rate train comparative rization model yogi optimizer zaheer wikipedia org wiki mini batch size topics learning rate decreasing learning rate half epochs choose number training epochs validating folds early stopping set patience epochs early stopping lbfgs optimizer epochs yogi optimizer tune hyperparameters training set optimal hyperparameters best model supmmd mkl searched space shown table kernel combination weights shown table kernel combination weights written order unigrams bigrams entities hyp epoch table optimal hyperparameters search space mkl combination weights dataset additional results section provide additional results correlation rouge score dataset supmmd lexrank supmmd lexrank table correlation sentence importance scores normalized sentence rouge scores analyze correlation normalized rouge recall scores sentences sentence scores supmmd lexrank ized rouge score sentence dened shown table supmmd slightly high correlation sentence rouge scores suggests supmmd better capturing sentence importance summarization feature correlations analyze correlation surface features sentence importance scores supmmd lexrank erkan radev feature supmmd lexrank supmmd lexrank supmmd lexrank position tsf btsf words nouns table correlation features sentence scores supmmd lexrank eigenvector centrality method set set icsi fourth day thrashing thunderstorms began heavier toll southern california deaths blamed rain ooding mudslides forced road closures emergency crews carried harrowing rescue operations downtown los angeles inches rain jan average rainfall entire year including inches record meteorologists southern fornia hit rain nearly years disaster latest caused rain snow battered california dec supmmd downtown los angeles inches rain jan average rainfall entire year including inches record fourth day thrashing thunderstorms began heavier toll southern california deaths blamed rain ooding mudslides forced road closures emergency crews carried harrowing rescue operations roads los angeles county equally frustrating rain saturated hillside gave way sending mississippi like torrent earth trees blocks oceanfront town killing men californians braced rain gled recover storms left people dead triggered mudslides tornadoes washed away roads runways record inches centimeters set mudslides forced amtrak suspend train service tween los angeles santa barbara thursday winter storm pummeled southern fornia straight day claiming lives people raising fears mudslides homes region evacuated staff writers rick orlov lisa mascaro contributed story storms caused million million damage los angeles county roads facilities beginning year multi million dollar homes collapsed mudslides trapped residents homes heavy rains claimed lives pelted los angeles fth straight day scenes reminiscent aftermath northridge earthquake years ago month los angeles area residents faced gridlocked freeways roads day cleanup crews cleared mud rubble bris left week siege rain shattering storm slammed southern california sixth straight day tuesday triggering mudslides tornadoes forcing road closures ers predicted wane wednesday new storm moves sunday night table example summaries topic containing articles rains mudslides southern california highlight phrases bold help identify difference set summaries icsi supmmd methods suggest set contains articles describing events earlier days disaster set contains articles later stage disaster shown table supmmd higher correlation relative position signifying importance position sentence summary sentences lexrank higher correlations number words number nouns tfisf scores sentences expected lexrank eigenvector centrality sentence sentence similarity matrix suggest supmmd able learn rst sentences important news summarization similar result reported kedzie rst sentences important creating summary news articles example summary present update summaries set topic contains articles rains mudslides southern california table
