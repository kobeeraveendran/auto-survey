c e d l c s c v v x r mudos ng multi document summaries n gram graphs tech report george giannakopoulos ncsr demokritos greece george vouros university aegean greece vangelis karkaletsis ncsr demokritos greece october abstract report describes mudos ng summarization system applies set language independent generic methods generating extractive summaries posed methods combinations simple operators generic character n gram graph representation texts work denes set operators n gram graphs proposes operators multi document summarization cess subtasks document analysis salient sentence selection query expansion redundancy control furthermore novel chunking methodology novel way assign concepts sentences query expansion experimental results summarization system performed widely corpora document derstanding text analysis conferences promising provide evidence potential generic methods introduced work aims designate core methods exploiting n gram graph representation providing basis advanced rization systems introduction late luhn luhn information community expressed interest summarizing texts domains application methodologies range news rization wu liu barzilay mckeown radev et al scientic cle summarization teufel moens meeting summarization niekrasz et al erol et al summarization dened reductive transformation given set texts usually described step process selection salient portions text aggregation tion selected portions abstraction information nally presentation nal summary text mani bloedorn jones summarization community aims address major problems arise summarization process detect select salient information included summary use query drive information selection task assure nal summary contain redundant repeated formation especially multiple documents input summarization process develop methods function independently language documents degree achieved date summarization systems developed presented especially endeavors document understanding conferences duc text analysis conferences summarization community appears moved single text multi text input reached domains opinion summarization trend summarization case dierent evaluations performed recent years proved multi summarization task highly complex demanding automatic summarizers long way perform equally humans dang dang dang owczarzak recently shown genest et al extractive approach upper limit performance lower compared abstractive approach humans extractive summarization appears room improvement order reach upper limit performance set humans performing extractive summarization simple sentence selection reordering current methods evaluation summaries criticism jones conroy dang giannakopoulos et al shown ing dierent aspects summary far trivial task comes ranking summarization systems e average performance summarization system set summaries existing evaluation methodologies oer good correlation human judgment dang dang owczarzak giannakopoulos et al work tackle problems salience detection redundancy control extractive multi document summarization unied language independent generic framework based n gram graphs contributed methods oer basic language neutral easily adaptable set tools basic idea framework neighborhood relative position characters words sentences documents oer information bag words approach furthermore methods word level analysis sub word character n gram level oers exibility dence language acts uniform representation sentences senses documents document sets study provide proof concept methodology advanced summarization systems experiment methodology basic summarization system named mudos ng following sections briey review current literature section present proposed approach section perform set experiments evaluate performance potential section article concludes discussion proposals development section literature presently literature automatic multi document summarization grown level hard overview detail jones identify specic commonalities way summarizers extract reproduce information output summaries rizing systems usually classied extractive abstractive proach mani bloedorn extractive approaches focus extraction use text snippets source texts nal summary abstractive text chunks e approaches hand aim rst represent information intermediate sentation example rst order logic use language generation produce output nist nist gov nii ac jp summary representation shown humans summarize abstractive fashion banko vanderwende endres niggemeyer current systems continue use extractive paradigm perform summarization lack highly robust text intermediate representation methods natural guage generation methods hand description summarization system purely abstractive disputed appears summarization systems dierentiate according purpose jones following paragraphs overview approaches existing salience detection redundancy removal focus proposed work brief literature review graph based methods introduce reader related work domain graphs salience detection determine salience information researchers positional structural properties judged sentences respect source texts properties sentence tion e number sentence beginning text beginning current paragraph document fact sentence title abstract ument edmundson radev et al relation sentences respect user specic query specied topic conroy et al varadarajan hristidis park et al features providing evidence importance information sion proper anaphora reiteration synonymy hypernymy coherence based rhetorical structure theory mann thompson relations sentences mani et al dene salience based graph representation sentence vertex vertices connected cohesion coherence relation e common anaphora salience sentence computed operation dependent graph representation e spreading activation starting important nodes torralbo et al following bag words assumption sentence represented word feature vector e cases sequence represented words ignored vector dimensions represent word frequency term frequency inverse document frequency tf idf value given word source texts cases analysis performed aiming reduce dimensionality produce vectors latent topic space steinberger jezek flores et al vector representations exploited measuring semantic similarity information chunks measures cosine distance euclidean distance vectors feature vectors chunks created clustering vectors formed identifying clusters corresponding specic topics cluster represented single vector example centroid corresponding cluster s vectors radev et al chunks closest representative vectors considered salient point aforementioned vector based approaches needs perform ing avoid pitfalls stop words inection words create feature spaces high dimension utility preprocessing step usually involves stemming stop word removal issue dispute ledeneva leite et al recent approaches use machine learning techniques sets dierent features determine source text chunk sentence considered salient included output summary case feature vector calculated sentence include information like sentence length sentence absolute position text sentence position corresponding paragraph number verbs forth e teufel moens shown specic tasks like news summarization task duc ple positional features determination summary sentences prove promising summarization systems dang falsely lead expectation features like ones corresponding rst sentence heuristic e features indicate sentence appears similar content properties rst tences set training instances universal rule example short stories example completely dierent approach taken perform rization kazantseva szpakowicz summary expected describe setting giving away plot jatowt ishizuka nd approach aware summaries account frequency terms time dierent versions web pages determine salience varadarajan hristidis authors create graph nodes sent text chunks edges indicate relation chunks contrast work authors varadarajan hristidis consider optimal summary maximum spanning tree document graph contains keywords graph varadarajan hristidis character n gram graph proposed methodology chunking given parsing delimiter parameter edges kept given threshold parameter furthermore varadarajan hristidis tf okapi function assign weights nodes indicating self importance node multi document summarization dierent iterative ranking algorithms like pagerank brin page hits kleinberg graph representations texts determine salient terms set source texts mihalcea salience determined use graphs based fact documents represented small world topology graphs matsuo et al important terms appear highly linked terms ing salient terms determine containing sentences salience create nal summary approach hendrickx bosma content units sentences assigned normalized value based set graphs representing dierent aspects content unit aspects include query relevance cosine similarity sentences document termed relatedness cross document relatedness considered aspect redundancy redundancy respect prior texts coreference based number coreferences dierent content units aspects corresponding graphs combined model assigns nal value salience iterative cess process spreads importance nodes based probabilistic centrality method takes account direction edges augment penalize salience nodes based neighbors salience notion bayesian expected risk loss applied summarization domain kumar et al selection sentences viewed decision process selection sentence considered decision system select sentences minimize risk conroy et al classy system e conroy et al extracts quently occurring signature terms source texts terms user query terms system estimates oracle score sentences relates terms contained candidate sentences estimated ideal distribution based term pearance query signature terms topic document cluster optimization method integer linear programming determine best set sentences given length summary given sentence weights based oracle score article proposes summarization method uses language independent generic operators apply generic representation chunks based interconnected n grams n gram approach common giannakopoulos et al chunk sentence similarity method overcomes need kind preprocessing oers basic e core method extractive summarization chunking process separates sentence sub sentential strings based statistical analysis given document set method use bag words approach n gram graphs account relevant position n grams text use features like sentence position speech information method deduce salience based centrality connectedness graph vertices method extracts graph expected represent common content input texts turns considered indicate salient information given user query approach combines n gram graph operators common content graph given query overall importance indicative graph calculate salience source text sentences based similarity respective n gram graph representation overall graph e sentence representation similar representation content query considered appropriate nal summary methodology described depth section redundancy novelty problem somewhat complementary salience selection redundancy tion salience desired attribute information chunks summary detected measuring similarity chunks query redundancy indicates unwanted repetition information research redundancy given birth marginal evance measure carbonell goldstein maximal marginal relevance mmr selection criterion basic idea mmr good summary sentences ments sentences documents relevant topic repeating information summary mmr measure generic linear combination principal functions measure relevance redundancy approach redundancy problem cross sentence informational subsumption csis radev et al judges information oered sentence contained sentence summary informationally sumed sentence omitted summary main dierence approaches fact csis binary decision information subsumption mmr criterion oers graded indication utility non redundancy approaches overviewed allan et al use statistical characteristics judged sentences respect sentences included summary avoid tion methods newword cosine distance methods larkey et al use variations bag words based vector model detect similarity pairs candidate summary sentences language model based methods create language model summary sentences independently compare language model candidate sentence summary sentences model zhang et al didate sentence model minimum kl divergence summary sentences language model supposed redundant classy system conroy et al conroy et al represents documents term vector space enforces redundancy following process given pre existing set sentences corresponding sentence term matrix ma currently judged set sentences b corresponding matrix mb b judged term sub space orthogonal eigenvalues space dened means terms considered important taken account valuable content work evaluated dierent strategies detection tion redundancy strategies use statistical graph based model sentences exploiting character n grams rst strategy similarly csis compares candidate sentences determines redundant ones second strategy aiming detect intra summary elty similar mmr creates iterative n gram graph model snapshot summary new sentence added new candidate sentence compared graph model determine redundancy graph based methods graph matching graphs determine salient parts text mihalcea erkan radev erkan radev query related sentences otterbacher et al close relation summarization process lexical relationships mohamed rajasekaran ical structure marcu non apparent information lamkhede represented graphs graphs detect dierences similarities tween source texts mani bloedorn inter document relations witte et al relations granularity cross word cross document described cross document structure theory radev work graphs represent strings length granularity chunk sentence document set proposed methodologies use set dierent operators like similarity merging intersection perform dierent subtasks summarization process query expansion content selection redundancy control graph similarity calculation methods classied main categories according literature isomorphism based isomorphism bijective mapping vertex set graphs mapped vertices equivalent pair vertices shares state neighborhood corresponding vertices words isomorphic graphs nodes graph unique equivalent graph graphs identical connections equivalent nodes based isomorphism common subgraph dened subgraph having isomorphic equivalent graph subgraph maximum common subgraph dened common subgraph maximum number vertices formal denitions excellent introduction error tolerant graph matching e fuzzy graph matching bunke given denition maximum common subgraph series distance measures dened methods calculation maximum common subgraph similar constructs like maximum common edge subgraph maximum common induced graph raymond et al edit distance based edit distance fuzzy string matching time variations navarro survey approximate string matching edit distance strings corresponds minimum number edit ter operations insertion deletion replacement needed transform string based concept similar distance graphs bunke dierent edit operations given dierent weights indicate edit tions indicate important changes edit operations graphs nodes node deletion insertion substitution operations applied edges giving edge deletion insertion substitution transformation text graph aforementioned graph matching methods means indicate text similarity graph method text comparison found tomita et al text represented rst determining weights text s terms tf idf calculation creating graph edges based term occurrences method proposed article require term extraction identication corresponding representation graph constructed exploiting text direct manner e language dependent preprocessing required exploiting ground supportive information corpus calculation tf idf weighting factor main dierence method existing methods enter sub word level use character n grams aim perform required tasks marization set documents uniform representation sentences senses documents document sets regardless underlying language map seemingly dierent summarization subtasks content selection query expansion set basic graph operators function generic purpose nlp operators common representation order understand n gram graph representation use account fact adjacency dierent linguistic units specic contexts important factor meaning contextual information widely methodologies built value e burgess et al yarowsky methodology described detail section summarized following main steps analysis source documents content query expansion candidate content grading redundancy removal novelty detection composition summary following paragraphs present framework e representation operators steps having said need emphasize point single framework allows dierent operators natural language processing nlp domain early presentation concepts processes described found giannakopoulos et al n gram graphs operators algorithms provide denition n gram given text viewed character sequence denition n n z ci th character l length character sequence t l text character n gram sn sn subsequence length n t l l n j n sj shall indicate n gram spanning ci ck si n grams length n indicated sn meaning formal specication n gram sn found substring length n original text spanning th n character original text length n n gram called length size rank n gram n gram graph graph g v g eg l w v g set vertices eg set edges l function assigning label vertex edge w function assigning weight edge consider l labels edges concatenating labels corresponding vertices direction edge edge directed lexicographic order edge undirected adding special separator character labels vertices n grams vg v g edges eg eg superscript g omitted easily assumed connecting n grams indicate adjacency corresponding vertex n grams specic context distance dwin giannakopoulos et al example vertex corresponds n gram abc bcd abc bcd edge connecting abc bcd special separator character edges work weighted applying number co occurrences vertices n grams given window original documents simplicity vertex v v g write v g notation edge e eg write e g given instances n gram graph representation number operators applied provide n gram graph equivalent union intersection operators set theory summarization task operators useful primary tools subtasks e salience detection novelty detection redundancy removal query expansion example operator merging operator corresponding union operator set theory operator adds edges operand graphs making sure duplicate edges created edges considered duplicates share identical vertices note denition identity vertices customized applications vertices correspond n gram denition graph operators actually non trivial number questions arise handling weights common edges union operator meaning handling zero weighted edges application operator operators shall present operate edges consider single nodes little value argue information contained relation n grams n grams minimal unit interest edge actually pair vertices overall dened number operators exception similarity functions g g g g set valid n gram graphs specic rank n operators function graphs given rank produce graph rank operators following similarity function sim g g r returns value similarity n gram graphs function symmetric variations similarity function study tted specic task common ground variations similarity values normalized interval higher values indicating higher actual similarity graphs computation similarity described subsection containment function contains indicates given graph contained second graph function expected asymmetric words function indicate graph contained graph know inverse stands implementations containment function proposed result values normalized interval higher similarity values indicating bigger given graph contained second graph consider graph contained graph edges appear case common edge contributes overall containment function percentage inversely proportional size function value indicates contained computation containment described subsection merging union operator returns graph edges common uncommon operand graphs implementation operator decided union operator set weight common edge equal average weights corresponding graphs intersection operator returns graph common edges operand graphs averaged weights averaging edge weights based idea intersection union graphs graph includes edges operand graphs edge weights close possible original graphs union merge intersection operators presented section delta operator called operator returning subgraph graph common graph operator non symmetric e general inverse intersection operator returning edges graphs common graphs operator symmetric e zero weighted edges treated edges zero weight means edge exist e vertices related graph graph nodes edges size graph edge count indicated graph algorithm use giannakopoulos et al convert given string character n gram graph representation simple extract character n grams rank n given text create graph vertices unique n gram vertices labeled corresponding n gram add edges connecting n grams occur given distance dwin string work weight added edge number co occurrences corresponding similarity containment represent character sequence text use set n gram graphs n gram ranks instead single n gram graph compare sequence characters chunk sentence paragraph document e textual chunk apply variations single algorithm acts n gram graph representation character sequences algorithm actually similarity measure n gram graph sets corresponding texts similarity indicative similarity content information chunks way fuzzy string matching technique apply application operators graphs edge weights e union graphs represent average co occurrences functions co occurrences integer numbers similarity measurement determine e given sentence related user query summarization task consider n gram graph maps given n gram rank work e rank r parameter n gram graph given representation text ti set graphs gi containing graphs ranks texts use value similarity vsr compare graphs rank n gram rank r use corresponding graph rank r e measures edges contained graph contained graph considering weights matching edges measure matching edge e having weight e graph sum matching edges contribute consider contributes edge e dene e valueratio vr scaling factor dened equation indicates valueratio takes values symmetric equation vsr vsr measure converging graphs share edges similar weights means value vsr indicates perfect match compared graphs tant measure normalized value similarity nvs computed e e e e gj e wj e egi e wj e vsr fraction similarity ratio sizes compared graphs play role called size similarity nvs measure overall similarity vsoof sets computed weighted sum vs ranks lmax r vsr lmax r vsr vs measure extracted graphs rank r g lmin lmax arbitrary chosen minimum maximum n gram ranks function contains realizing graph containment operator small signicant dierence value similarity function commutative precisely value containment vcr containment function edge weights vcr e e e e denominator cause asymmetric nature function makes spond graded membership function graphs graph union merging intersection union merge operator important aspects rst deals unweighted edges pairs labeled vertices e second considers weights edges merge operator denes basic operator required perform updates graph model intersection operator hand determine common subgraphs dierent graphs use variety applications common topic detection set documents section detection stopword eect edges stopword eect edges edges apparent graphs texts given language high frequency like stopwords detection stopword eect edges n gram graphs accomplished simply applying intersection operator graphs adequately big texts dierent topics resulting graph represent language appeared text graphs considered noise notion noise relation n gram graphs found section performing union graphs create graph gu v u eu l w u eu eg edge sets correspondingly implementation consider edges equal label e means weight taken account calculating eu eg eg eg calculate weights gu functions depending eect merge weights common edges follow fuzzy logic paradigm maximum weights given edge source graphs w weighting functions corresponding graphs e common edge alternative average values weight represents expected value weights original weights given basic tives chose average value default union operator eect edge weights noted merging operator specic case graph update function presented section formally edge sets correspondingly w u result graph edge weighting function weighting functions operand graphs e eu w edge set eu merged graph eu w e intersection operator returns common edges graphs performing averaging operator edges weights formally edge set ei intersected graph ei e w e delta inverse intersection delta operator non commutative operator given graphs returns subset edges rst graph exist second graph formally edge set e weight remaining edges changed applying delta operator obviously operator non commutative similar operator inverse intersection operator creates graph contains non common edges graphs dierence operator delta operator inverse intersection edges resulting graph belong original graphs formally resulting edge set e consider labeling function graphs delta inverse intersection operators applied determine ences graphs way e remove graph representing noisy content graph application determining non common texts deal subject refer unique novel text respect subject representing document sets updatability n gram graph representation specication indicates map text n gram graph task required represent document set simplistic way n gram graph representation concatenate documents set single overall document kind approach oer updatable model e model easily change new document enters set applications update function u similar merging operator exception weights resulting graph s edges calculated dierent way update function u l takes input graphs considered pre existing graph e graph resulted sequence applications update operator initial graph considered new graph function parameter called learning factor l determines sensitivity changes brings focusing weighting function graph resulting application u l higher value learning factor higher impact new graph existing graph precisely denition weighting performed graph resulting u w w w w l according formula value l indicates completely ignore new graph value l indicates weights edges assigned values new graph s edges weights value gives simple merging operator u operator allows graph representation model set documents approach case represent common content source documents training step creation content representation model comprises initialization common content graph representation rst document subsequent update initial graph graphs documents especially wants common content graph s edges hold weights averaging weights individual graphs contributed common content graph new graph updates common content graph use learning factor l methodology creates common content graph function representative graph source documents expect close individual graphs individual documents terms value similarity common content graph created determine new document similar content source documents measuring similarity document graph common content graph information determine salience information chunks section update operator determine noisy information terms useless graph edges illustrated following paragraphs determining noise n gram graph operators determining common content graph faces presence noise graph noise graphs classication task set common subgraphs classes documents oer distinctive information similarly summarization task consider common content graph appear matter underlying topic sources noise traditional text classication techniques stopword removal usually remove considered noisy data point seen n gram graphs need preprocessing based task usually identify non interesting parts data hinder task noise removed proposed n gram graph algorithms order remove noise use related paradigm classication task classication task consider set training documents number classes consider noise information graphs help determine class document manage nd information represented graphs able remove noise common content graph case classication task create merged graph update operator set training documents tc belonging class creating classes model graphs determine maximum common subgraph classes remove improve distinction dierent classes number questions arise given train thought determine maximum common subgraph classes according operators easy maximum common subgraph intersection class graphs words operator determine common content class documents useful noise indicator inter class analysis unique intersection operator associative edge weights omitted averaging edge weights intersection causes associativity words calculations edge weights approximate noisy subgraph iterating classes yes seen figure noisy subgraph easily approximated steps gure horizontal axis indicates number consecutive intersections performed classes graphs vertical axis illustrates number edges resulting intersected graph shows iteration insignicant change resulting graph size removal noisy class graph improve results answer yes immediately support intuition common n gram graphs eect noise e called stopword eect edges performed set experiments classication easily related performing topic detection set topics performing common content extraction analysis step summarization methodology created topic graph tac topics based documents contained topic tried classify documents corresponding topic tac site nist gov tac figure convergence common graph size number intersections classication performed measuring similarity judged document set topic representative graphs topic graph maximum similarity selected topic document way wanted documents found maximally similar topic graphs training instances expected recognized belonging original topic case eect common elements content dierent topics e noise indication performance classication use recall value e value number documents correctly indicated belonging given class divided numbers documents belong class histogram recall values classes topics removing noise shown gure recall histogram removing alleged noise seen gure y axis indicates number classes recall value given range axis axis indicates recall value ranges course ideally values indicate perfect classication gure shown class results moved higher recall values results illustrate statistically signicant improvement paired wilcoxon ranked sum test wilcoxon non normal distribution dierences recall class noisy noise free tests test indicated statistical condence level p value results removing noise improved conclusion experiment removal noise help determine relation topic n gram graph representation advances eectiveness content selection process noise free topic graph available content analysis original graphs use noise removal process noise free graph including noise noise figure recall values histogram classes classication task noise proposed methodology system mudos ng section provide overview mudos ng system figure depth analysis proposed individual steps analysis source documents content step gets input set source documents extracts represents n gram graph representation documents operators intersection information common information considered important presence source documents output step common content graph section representing common source documents query expansion step optional step aims annotate user supplied query sentence indicating subject requested summary set concepts expand input step query expected free text output graph representing expanded version query candidate content grading step assigns scores sentences source documents order evaluate salience sentence grading takes account user query information common source documents outputs ordered list sentences step uses redundancy removal novelty detection approach avoid repetition output summary step eliminates reranks graded sorted candidate summary sentences order avoid penalize repetition information step fact integrated summary creation nal step input set candidate sentences output possibly reranked subset candidate sentences given output previous steps nal step creates summary sequence selected candidate sentences sentence ordering method improve output system main purpose determine n gram graph based tools devised useful summarization process system aims class figure mudos ng system overview summarysource texts analysisquery expansionquerycommoncontentexpandedquerycandidatecontentcandidate contentgradingredundancy removalornovelty detection provide core methods exploiting n gram graph representation providing basis advanced summarization systems experiments indicate sentence ordering rewrite methodology system provides promising results analysis source documents content analyze source documents need able identify represent minimal units information approaches minimal unit information word need remain language independent account fact word split sub word parts use character entropy chunking section chunk word longer word e collocation represented corresponding n gram graph identify splitting sentence smaller parts makes dierence judging salience sentence perform experiments section taking account alternatives creating graph sentence versus creating graph chunk following subsection describe solutions applied identify chunks character entropy chunking determine information chunks steps leading nal summary need determine appropriate delimiters language neutral way exploit document corpus determine probability p single given character c follow given character n gram sn character c corpus probabilities calculate entropy character given character n gram sn follows ci n m set characters found follow given n gram sn fi frequency count ci found sn character entropy document corpus given pi p fi m fi pi pi m entropy measure indicates uncertainty supposed substrings character sequence entropy p surpassed statistically computed threshold represent candidate delimiters threshold based analysis entropy values illustrated figure left noted detect fuzzy regions entropy graph rst region containing delimiters second region containing non delimiters contains symbols low entropy character e common syllables regions dened non trivial changes curve entropy measure detect prominent changes measured delta entropy values successive symbols graph delta dh absolute value change entropy successive symbols illustrated figure right gures horizontal line parallel symbol axes indicates mean value entropy entropy delta gure correspondingly given ordered set h hm values n figure entropy symbol left delta entropy symbol right ordered scending n n set n grams corpus delta value dh sk n n gram sk n value hk dh hk m dh hm absolute value operator entropy value corresponding local maximum entropy delta right half symbol entropy delta function selected threshold depicted dark circle gure determining delimiter characters happens consider exactly areas depicted left gure expect split points middle symbol delta ordered list symbols formally threshold given argmax m hi oor operator returning closest integer lower equal application checked unigrams e simple letters delimiters delimiters higher rank determined example bi gram chunking sequence comma space considered delimiter unigrams space character considered delimiter given character sequence sn set delimiters d chunking algorithm splits string occurrence delimiter d way sentence split set chunks assigned salience content selection process query expansion summarization systems like ones presented duc tac communities need able respond specic queries information retrieval time use query expansion shown useful times wanted try query expansion summarization system determine oers improvement system performance perform query expansion use step process devise methodology map sentence set concepts provided external knowledge analysis sentence tries remain language independent possible use external resource dictate specic language second step query expansion use concepts descriptions mapped query sentence order expand graph representation query elaborate steps following sections mapping sentence set concepts external knowledge scope work tried map sentences concepts e terms dened meaning usually happens looking words thesauri e net miller et al approach decomposition module based notion symbolic graph symbolic graph graph vertex contains string edges connecting vertices way indicative substring relation example strings abc ab labeling corresponding vertices ab substring abc directed edge connecting ab general symbolic graph given text t contains string t string illustrates set substrings compose symbolic graph constructed run vertices graph look vertex thesaurus determine match entry thesaurus contains entity lexicalized vertex string vertex assigned corresponding term meaning cases polysemous terms vertex annotated possible meanings term annotated graph facility supports comparing meanings semantic index semantic index represents links n grams semantic parts implemented e wordnet denitions textual descriptions possible senses denitions example sets denitions terms compare semantics meaning semantic index actually compare n gram graph representation j pair denitions given terms section consider meaning term map directly set possible senses term relatedness meaning relmeaning considered averaged sum similarities pairs denitions compared terms represented n gram graphs use relatedness implies uncertainty concerning actual meaning terms handled measure alternative senses e high cause lower result relatedness alternative version relatedness measure requires single pair similar determine high relatedness meanings following relmeaning examples section equation example compare smart clever wordnet sense denitions clever cagey cagy canny clever showing self interest shrewdness dealing cagey lawyer clever sound symbolic graph represented eciently trie fredkin smart smart run run run run hollow hollow pretty stupid jump walk die operate relmeaning table examples comparisons ascending relatedness value sense overview apt clever mentally quick resourceful apt pupil clever man reason wit stoker clever cunning ingenious showing inventiveness skill clever gadget cunning maneuvers leading success ingenious solution problem wordnet sense denitions smart smart showing mental alertness calculation resourcefulness chic smart voguish elegant smart new suit voguish cut bright smart characterized quickness ease children brighter subject children talk earlier average fresh impertinent impudent overbold smart saucy sassy wise improperly forward fresh child lecture impudent boy given insulting wise smart painfully gave dog smart blow smart quick gave smart walked smart pace smart capable independent apparently intelligent weapons relatedness meaning relmeaning table present pairs terms corresponding relatedness values preliminary results indicate measure appears higher values terms similar meaning biased words similar spelling happens words appear denitions causing partial match dierent denitions results depend heavily textual description e denition term s individual sense synset wordnet results examples synonyms descriptors individual senses seen table notice e words smart clever found relation whatsoever common synonyms found wordnet furthermore given word appears synonym list word spelling similarity plays important role judging relatedness senses dierent words example words hollow holler important overlap terms spelling makes senses high overlap biases comparison process consider corresponding senses related use semantic index meaning look engine remind reader semantic index actually annotated symbolic graph matching vertex graph provide meaning given input string string considered meaning closest terms graph path length substrings given meaning inheritance meaning short longer strings actually based intuition text chunk contains meaning individual parts furthermore word broken elementary constituents oer meaning uses ontology thesaurus including prexes suxes elementary morphemes meanings annotate smart run smart run smart run hollow run hollow clever jump stupid walk pretty die operate holler relmeaning table examples comparisons ascending relatedness value synonyms overview symbolic graph resulting index powerful semantic annotation engine combine meaning sub word items determine word meaning hand composite words collocations necessarily simple composition meaning parts cases expect resulting meaning annotation false context work combined symbol graph wordnet semantic index annotate queries meanings perform query expansion knowing process non optimal query expansion graph merging query expansion based assumption set words related original query query improve set returned results literature work indicated query expansion carefully applied order improve results voorhees qiu frei approach semantic index based wordnet s overview senses example overview senses words test ambiguous seen example example overview verb test verb test senses tagged texts test prove try try examine essay test quality experimental use approach tried good results test recipe screen test test examine presence disease infection screen blood hiv virus quiz test examine s knowledge teacher tests week got quizzed french irregular verbs test certain characteristic tested tested positive hiv test achieve certain score rating test tested high lsat admitted good law schools test determine presence properties substance test undergo test nt test overview adj ambiguous adj ambiguous senses tagged texts equivocal ambiguous open interpretations uncertain nature significance intended mislead equivocal statement polling complex equivocal ambiguous message potential female candidates officer s equivocal behavior increased victim s uneasiness popularity equivocal crown equivocal response embarrassing question ambiguous having possible meaning ambiguous words frustrated ambiguous instructions parents unable assemble toy ambiguous having intrinsic objective meaning organized conventional patterns ambiguous situation frame reference ambiguous inkblots given word w original query overview senses returned semantic index senses si utilize senses sj graph representations gsj graph similarity common content graph cu greater given threshold section denitions functions gsj cu cu t t remind reader content graph intersection graph representations texts set finally query expanded merging representation original query gq representations gsj senses ltered according procedure giving judge importance new query based content denition cu refer sentences simply comparing graph representation sentence cu removal irrelevant denitions overview senses sense lter having calculated cu query expansion process nally successful rst attempt query expansion noise added chunks like o directly assigned wordnet meanings angstrom inch oxygen correspondingly lowered evaluation scores submitted runs tac giannakopoulos et al sense lter deciency tackled current version system signicantly improving overall performance content selection process concerning content matching presented summarization system following basic assumptions content cu text set u considered noise free intersection graph representations texts set cu tugt gt graph representation text t arbitrary selected n gram ranges words consider common graph representation texts topic indicates common content texts optional query expansion process nally use instead cu query based content denition cu determined described previous section sentence s considered similar content cu text set sentence s chunks sub strings sentence n gram graph representation similar corresponding content representation chunk s similarity content added overall similarity sentence content chunks sentence extracted aforementioned entropy based approach section experiments section test use chunks dierentiates performance system opposed case sentence considered single chunk according chunking process sentence assigned score actually sum normalized value similarities eq chunks content process oers ordered list sentences l naive selection algorithm select scoring sentences list summary word count limit reached redundancy account redundancy removal comes redundancy removal novelty detection composition nal summary step redundancy control fully integrated shortly describe alternatives studied concerning control redundant information detects novelty new piece information respect current summary snapshot user model detects redundancy set source information pieces creation summary approaches represent dierent views problem control redundant information multi document summary novelty detection process aspects intra summary novelty summary user modeled novelty intra summary novelty refers novelty sentence summary given content summary specic time point order ensure intra summary novelty sure sentence minimally repeats existing information achieve goal use following process extract n gram graph representation summary far indicated gsum summary representation contain common content corresponding document set u sum gsum cu candidate sentence l extract n gram graph representation gcs cs gcs cu expect judge redundancy n gram graph contained common content cu c assign similarity cs sum sentence redundancy score candidate sentences l set score sentence rank based similarity cu minus rank based redundancy score select sentence highest score best option add summary repeat process word limit reached sentences remain inter summary user modeled novelty refers novelty information apparent summarization process takes account information available reader tac update task information contained user model keeping track recent summaries provided user tac summarization task systems supposed account rst sets topic set prior user knowledge summary set b topic fact set contains documents cerning news item e antarctic ice melting published documents set b content given set cua redundancy removal process considering pre existing user model merged representation set representation current snapshot summary words content set appears included current version summary new sentences avoid redundancy respect work implemented method redundancy removal opposed novelty detection redundancy pinpointed original set candidate sentences consider sentence redundant surpasses empirically computed threshold experiments threshold value overlap candidate sentence iteration redundancy removal process sentence compared sentences marked redundant result process sentences marked redundant output summary given set tools described far provide experimental results applying variations aforementioned methodology conclusions reached experiments conducted numerous experiments tac corpus consider variation system based dierent parameter set dierent system dierent system id main target components aect summarization process judge individual steps separately ideally summaries judged humans automatic methods lin hovy et al giannakopoulos et al correlate human judgment autosummeng giannakopoulos et al system evaluation method consistently correlates duc tac manually assigned siveness measure responsiveness rst appeared document understanding conference duc extrinsic measure later ducs duc appointed task synthesis word organized answer complex question data answer originate multiple documents dang duc question summarizing peers e summarizer systems humans supposed answer consisted topic identier title narrative question granularity indication values ranging general specic responsiveness score extrinsic measure supposed provide dang states dang coarse ranking summaries topic according information summary helps satisfy information need expressed topic statement level granularity requested user prole automatically evaluating summaries peers aesop task tac autosummeng method shown performing methods terms correlation responsiveness dang giannakopoulos karkaletsis evaluation automatic autosummeng measure meant result partial ordering indicative given summary answers given question taking account cations question following paragraph dene task mudos ng evaluated autosummeng tac tasks main task produce word summary set documents summary update task produce word summary set subsequent documents assumption information rst set known reader summary topics documents topic threshold computed experiments machine learning relate human estimated redundancy information calculation performed work nist gov tac presentations pdf system id cs ss rr nd qe ne score table autosummeng summarization performance dierent settings concerning scoring redundancy query expansion legend cs chunk scoring ss sentence scoring rr redundancy removal nd novelty detection qe query expansion ne expansion best performance bold chronological order summary extracted based topic description dened title narrative query topic model summaries provided evaluation purposes point indicate pitfalls overall evaluation measure like meng rouge lin basic elements hovy et al belz related discussion small variations system performance indicative real performance change statistical error judging system summary measure little individual summaries correlates measure judge performance intermediate steps judges output measure judge summary respect given model summaries given restrictions performed experiments judge change performance chunk salience scoring versus sentence salience scoring redundancy removal versus novelty detection query expansion versus query expansion addition results applying dierent system congurations tion task indicated table performed anova analysis variance test determine system id e system conguration important factor meng similarity peer text model texts shown value topics diculty topic important factor system formance selection dierent components summarizer range proposed components aect summaries quality nding fact systemid important factor performance overview text analysis conference summarization update task system tac sysid peer peer peer average peers proposed system autosummeng score std dev table autosummeng performance data tac note peers based autosummeng measure performance systems systems chunk scoring statistically signicant dierence performance ones use sentence scoring paired t test gave value systems chunk scoring systems slightly lower average performance systems redundancy removal appear statistically signicant dierence performance ones use novelty detection nearly condence level sided t test system chosen use redundancy removal method performs near average systems conclusion drawn concerning query expansion proved query expansion oers improvement t test gave value result consistent slight improvement indicated conroy et al reverse mapping porter stemmer expand query versions words e adding s verb sux noun sux terms query similar non decisive results found blake et al query expansion determined little use experiments applied table information average performance tac participants topics illustrated performance tac systems found dang owczarzak system performs slightly average better successful participant encouraging potential proposed summarization method based generic algorithms performed generic representation providing core operators addressing diculties single summarization step language neutrality method shows provide steady basis eective combined heuristics machine learning methods exploiting language dependent characteristics examine performance system corpora performed rization conguration performed optimally tac corpus corpora duc year systems duc synthesize set documents brief organized uent answer non trivially expressed declaration need information means query answered stating date quantity similar singleton organizers duc nist developed simple baseline system returned leading sentences text eld recent document topic words dang table illustrate performance proposed system duc corpus shown system strongly outperforms baseline system dard deviation mean performance participating systems comparison results duc tac task conclude proposed system performed better terms responsiveness generic summarization task duc update task tac identify exact defects tac summaries non trivial requires investigation dimensions problems aect performance content selection ordering system duc sysid baseline peer peer peer average peers proposed system autosummeng score std dev table autosummeng performance data duc note peers based autosummeng measure performance systems sentences anaphora problems lack coherence problem error quantied yes qualitative ranking quality applied approximated evaluation methodology minimize error maximize quality important proposed summarization components oered petitive results machine learning techniques combined rich set sentence features like sentence position grammatical properties indicates usefulness n gram graphs generality application n gram graph operators functions components need added reach state art performance given existing means evaluation components aim improve overall coherence text tackle problems anaphora resolution examples problems summary appendix section discussion future work oered generic method based language neutral representation algorithms n gram graphs aiming tackle number automatic summarization problems salience detection indicated ways determine content cluster documents judge salience given sentence redundancy removal presented dierent approaches following csis mmr paradigms query expansion proposed scheme broaden given query slightly proving eect summaries query expansion module partially dependent language requires thesaurus language original query perform expansion alternatives examined experiments far responsiveness summaries concerned stands sentence scoring preferred chunk based sentence scoring query expansion oer signicant improvement appear penalize performance redundancy removal performs better novelty detection newspaper international herald tribune reported friday production problems airbus s main parts plants germany root problem safety quality issues construction problems delayed introduction double deck largest passenger plane world prang said airbus s management announcement analysing production timetable project factor blamed delay process reviewing timetable airbus superjumbo passes emergency evacuation test figure sample summary topic tac airbus production launch news experimental results presented judged aspect system sponsiveness based results seen combining dierent methods components overall summarization method achieve signicantly dierent results important proposed summarization components oered tive results simple application n gram graph theory methodologies optimization specic corpora result shown way detect remove noisy patterns n gram graphs simple graph operators furthermore illustrated removal patterns improve results certain tasks tasks like classication topic detection investigated n gram graph representation prism determine potential representation generic nlp tool obvious experiments individual components easy judge parts summarization system focused exhaustive performance evaluations carried identify impact component overall performance needed components examined outside summarization context stand methods chunking semantic annotation redundancy detection future plan test eect n gram ranks dierent parts summarization process far intuitively concluded n grams lower ranks express grammar model given language e set allowed sequences acters higher rank n grams cross word boundaries oer topic information giannakopoulos et al exists methodology detection determined important substrings text called symbols context work use symbols n gram graphs alleviate insertion noise dierent summarization steps diminish computational cost method furthermore emergent subgraphs paths document set graph allow extraction non obvious relations text snippets detection discourse phenomena subtopics document set phenomena subtopics improve structure sentence ordering summary shown sentence ordering important eect summarization dang barzilay et al denitely need evaluate summaries extracted given corpora view additional textual qualities e regardless related score identify way individual extracted summaries figure sample summary appendix worse gold standard summaries able improve promising current work note mudos ng source code available constant revision improvement jinsect open source facilitate study methods presented net projects acknowledgments research described article supported research development project turn funded greek general secretariat research nology sentence splitting module sentencesplitter module javarap toolkit comp nus edu nlptools javarap html references allan et al allan j wade c bolivar retrieval novelty detection sentence level proceedings annual international acm sigir conference research development information retrieval pages acm new york ny usa banko vanderwende banko m vanderwende l n grams derstand nature summaries susan dumais d m roukos s editors naacl short papers pages boston massachusetts usa association putational linguistics barzilay et al barzilay r elhadad n mckeown k inferring strategies sentence ordering multidocument news summarization journal articial intelligence research barzilay mckeown barzilay r mckeown k r sentence fusion multidocument news summarization computational linguistics belz belz s nice comput linguist blake et al blake c kampov j orphanides west d lown c ch duc query expansion lexical simplication sentence selection strategies multi document summarization proceedings document understanding conference duc workshop brin page brin s page l anatomy large scale hypertextual web search engine computer networks isdn systems bunke bunke h error tolerant graph matching formal framework rithms advances pattern recognition lncs burgess et al burgess c livesay k lund k explorations context space words sentences discourse discourse processes carbonell goldstein carbonell j goldstein j use mmr based reranking reordering documents producing summaries proceedings annual international acm sigir conference research development information retrieval pages acm press new york ny usa conroy et al conroy j schlesinger j oleary d classy duc proceedings document understanding conference duc workshop ontosum conroy et al conroy j schlesinger j oleary d goldstein j basics classy proceedings document understanding conference duc workshop volume conroy dang conroy j m dang h t mind gap dangers divorcing evaluations summary content linguistic quality proceedings international conference computational linguistics coling pages ester uk coling organizing committee conroy et al conroy j m schlesinger j d oleary d p classy summarization metrics proceedings text analysis conference tac conroy et al conroy j m schlesinger j d stewart j g classy based multi document summarization proceedings document understanding conf wksp duc human language technology conf empirical ods natural language processing hlt emnlp dang dang h t overview duc proceedings document derstanding conf wksp duc human language technology conf empirical methods natural language processing hlt emnlp dang dang h t overview duc proceedings hlt naacl dang dang h t overview tac summarization track slides proceedings text analysis conference tac dang owczarzak dang h t owczarzak k overview tac update summarization task tac workshop notebook papers results pages maryland md usa edmundson edmundson h new methods automatic extracting journal acm jacm endres niggemeyer endres niggemeyer b human style www summarization erkan radev erkan g radev d r lexrank graph based lexical centrality salience text summarization journal articial intelligence research erkan radev erkan g radev d r michigan duc sentence prestige document summarization proceedings document understanding conferences boston ma erol et al erol b lee d hull j center r menlo park c multimodal summarization meeting recordings multimedia expo proceedings international conference volume flores et al flores j g gillard l ferret o de chandelar g bag senses versus bag words comparing semantic lexical approaches sentence extraction tac workshop notebook papers results pages maryland md usa fredkin fredkin e trie memory communications acm genest et al genest p lapalme g m montreal q tac creation manual extractive run notebook gaithersburg maryland usa nov giannakopoulos karkaletsis giannakopoulos g karkaletsis v n gram graphs representing documents document sets summary system evaluation ceedings text analysis conference appear giannakopoulos et al giannakopoulos g karkaletsis v vouros g tac workshop testing use n gram graphs summarization sub tasks notebook papers results pages maryland md usa giannakopoulos et al giannakopoulos g karkaletsis v vouros g p summarization system evaluation revisited n gram graphs acm trans speech lang process hendrickx bosma hendrickx bosma w coreference links proceedings text analysis sentence compression graph based summarization conference tac hovy et al hovy e lin c y zhou l fukumoto j basic elements jatowt ishizuka jatowt ishizuka m temporal multi page rization web intelligence agent systems jones jones k s automatic summarising state art information processing management text summarization jones jones s automatic summarizing factors directions pages kazantseva szpakowicz kazantseva szpakowicz s summarizing short stories computational linguistics kleinberg kleinberg j authoritative sources hyperlinked environment journal acm kumar et al kumar c pingali p varma v estimating risk picking sentence document summarization proceedings international conference computational linguistics intelligent text processing pages springer lamkhede lamkhede s multidocument summarization concept chain graphs master s thesis larkey et al larkey l allan j connell m bolivar wade c umass trec cross language novelty tracks pages national institute standards technology ledeneva ledeneva y eect preprocessing extractive summarization maximal frequent sequences proceedings micai pages leite et al leite d s rino l h m pardo t s nunes m v extractive automatic summarization linguistic knowledge dierence proceedings second workshop textgraphs graph based algorithms natural language processing pages rochester ny usa association computational guistics lin lin c y rouge package automatic evaluation summaries ceedings workshop text summarization branches pages luhn luhn h p automatic creation literature abstracts ibm journal research development mani bloedorn mani bloedorn e multi document summarization graph search matching proceedings pages aaai mani et al mani bloedorn e gates b cohesion coherence models text summarization intelligent text summarization symposium pages mani bloedorn mani m bloedorn e m summarizing similarities dierences related documents information retrieval mann thompson mann w c thompson s rhetorical structure theory theory text organization university southern california information ences institute marcu marcu d theory practice discourse parsing summarization mit press matsuo et al matsuo y ohsawa y ishizuka m document small world proceedings world multi conference systemics cybenetics infomatics volume pages mihalcea mihalcea r graph based ranking algorithms sentence extraction applied text summarization proceedings annual meeting association computational lingusitics acl volume acl mihalcea mihalcea r multi document summarization iterative graph based algorithms proceedings international conference intelligent analysis ods tools ia mclean miller et al miller g beckwith r fellbaum c gross d miller k j introduction wordnet line lexical database international journal lexicography mohamed rajasekaran mohamed rajasekaran s query based summarization based document graphs navarro navarro g guided tour approximate string matching acm computing surveys niekrasz et al niekrasz j purver m dowding j peters s based discourse understanding persistent meeting assistant proceedings aaai spring symposium persistent assistants living working ai otterbacher et al otterbacher j erkan g radev d r random walks question focused sentence retrieval hlt proceedings conference human language technology empirical methods natural language processing pages morristown nj usa association computational linguistics park et al park s lee j h ahn c m hong j s chun s j query based summarization non negative matrix factorization proceeding kes pages qiu frei qiu y frei h concept based query expansion proceedings annual international acm sigir conference research development information retrieval pages acm press new york ny usa radev radev d common theory information fusion multiple text sources step cross document structure proceedings acl sigdial workshop discourse dialogue radev et al radev d otterbacher j winkel blair goldensohn s newsinessence summarizing online news topics communications acm radev et al radev d r jing h budzikowska m centroid based marization multiple documents sentence extraction utility based evaluation user studies anlp naacl workshop summarization radev et al radev d r jing h stys m tam d centroid based summarization multiple documents information processing management raymond et al raymond j w gardiner e j willett p rascal lation graph similarity maximum common edge subgraphs computer journal steinberger jezek steinberger j jezek k latent semantic ysis text summarization summary evaluation proc isim pages teufel moens teufel s moens m summarizing scientic articles periments relevance rhetorical status computational linguistics tomita et al tomita j nakawatase h ishii m calculating similarity texts graph based text representation model pages washington d c usa acm torralbo et al torralbo r alfonseca e guirao j m moreno sandoval description uam system proceedings document standing conf wksp duc human language technology conf empirical methods natural language processing hlt emnlp varadarajan hristidis varadarajan r hristidis v system specic document summarization proceedings acm international conference information knowledge management pages voorhees voorhees e query expansion lexical semantic relations ceedings annual international acm sigir conference research development information retrieval pages springer verlag new york inc new york ny usa wilcoxon wilcoxon f individual comparisons ranking methods biometrics bulletin pages witte et al witte r krestel r bergler s context based multi document summarization fuzzy coreference cluster graphs proceedings document ing workshop duc new york city ny usa rate substance abuse native american adults percent nationwide retail shopping center proposed nearby section reservation result urban native americans feel driven away juvenile crime strand web social problems facing urban reservation indian communities report said hopes business union gap miles north reservation nearly native americans live new york city metropolitan area powless said onondaga people want work community outside reservation improve economy region creating tourism destinations include indian culture setting free trade zone unused manufacturing sites navajo reservation primarily dependent federal money reservations home gravest poverty worst health care country issue tribe s operation shoe box casino reservation let s find way benefit bowing court ruling congress laid statutory framework allowing american indian tribes offer high stakes bingo games casino style gambling historic reservation lands picture similar smaller reservations like fort peck reservation eastern montana people neah bay point native american communities single monolithic viewpoint communities figure sample summary topic duc wu liu wu c w liu c l ontology based text summarization business news articles proceedings isca international conference computers applications pages yarowsky yarowsky d unsupervised word sense disambiguation rivaling vised methods proceedings annual meeting association computational linguistics pages association computational linguistics morristown nj usa zhang et al zhang y callan j minka t novelty redundancy tection adaptive ltering proceedings annual international acm sigir conference research development information retrieval pages acm new york ny usa sample summary scoring provide sample duc corpus topic example mudos ng extracted summary figure example topic denition topic num title native american reservation system pros cons narr discuss conditions american indian reservations native american communities include benefits drawbacks reservation system include legal privileges problems table indicate candidate sentences document set extract summary sentences appear decreasing order score important note sentences removed redundancy removal step appearing nal summary sentence income disparity reservation widened value reservation residents frustrated rate substance abuse native american adults percent nationwide reservation happy growth retail shopping center proposed nearby section reservation migration reservations continues s economics says joanne dunne spokeswoman boston indian council nonprot cultural group reservation typically nt provide real opportunities native americans travel reservation urban areas tribes traditionally place says dunne micmacs crossed border canada come time immemorial cities city state governments created agencies specically deal native american population result urban native americans feel driven away urban native american population doubled non indian resident reservation tribal government smith thousands like seeking help substance abuse american indian community house largest handful native american cultural institutions new york area help asks place nt understand like native americans country leaving reservations relocating urban areas dizzying rate table sentences provided mudos ng scores sentence scoring
