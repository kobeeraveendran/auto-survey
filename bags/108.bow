extractive summarization deep learning sukriti verma vagisha nidhi delhi technological university shahbad daulatpur main bawana road india dce sukriti vagisha com abstract paper proposes text summarization approach tual reports deep learning model approach consists phases feature extraction feature enhancement summary tion work assimilate core information generate coherent understandable summary exploring features improve set sentences selected summary restricted boltzmann machine enhance abstract features improve resultant accuracy losing important information sentences scored based enhanced features tractive summary constructed experimentation carried articles demonstrates eectiveness proposed approach keywords unsupervised single document deep learning extractive introduction summary dened text produced texts containing signicant portion information original longer half original according text summarization process distilling important information source sources produce abridged version particular user means computer automatically automatic text summarization process seen form compression sarily suers information loss essential tackle information overload abundance textual material available internet text summarization classied extractive summarization stractive summarization based summary generated extractive rization creating summary based strictly original text abstractive summarization mimics process paraphrasing text summarized technique looks human like produces condensed summaries techniques harder implement extractive summarization techniques paper follow extractive methodology develop techniques summarization factual reports descriptions developed approach single document summarization deep learning paper intends propose approach referencing architecture human brain broken phases feature extraction feature enhancement summary generation based values features dicult construct high level abstract features raw data use deep learning second phase build complex features simpler features extracted rst phase extracted features depend highly factual given document end run proposed algorithm factual reports evaluate demonstrate eectiveness proposed approach based measures recall precision measure related works early work text summarization focused technical documents early studies summarization aimed summarizing pre given documents requirements usually known generic tion luhn proposed frequency particular word article provides useful measure signicance number key ideas stemming stop word ltering forward paper understood universal preprocessing steps text analysis baxendale examined paragraphs found paragraphs topic sentence came rst time sentence positional feature complex machine learning based systems edmundson focused work importance word frequency positional importance features features cue words skeleton structure document weights sociated features manually nally sentences scored evaluation found system generated summaries matched target summaries written manually humans upcoming researchers text summarization approached problem aspects natural language processing statistical modelling machine learning initially machine learning systems assumed feature independence relied naive bayes methods recent ones shifted focus selection appropriate features learning algorithms independence assumptions signicant approaches involved den markov models log linear models improve extractive summarization recent papers contrast neural networks goal text summarization document known single document summarization multiple documents known multi document marization basis writing style nal summary generated text summarization techniques divided extractive methodology abstractive methodology objective generating summaries extractive approach choosing certain appropriate sentences ment user idiosyncrasies human invented languages mar extractive approaches select subset sentences input documents form summary instead paraphrasing like human mainstream area extractive summarization methods main obstacles rst obstacle ranking problem rank words phrases sentences second obstacle selection problem select set ranked units obstacle coherence problem ensure selected units form understandable summary set disconnected words phrases sentences algorithms determine relevance textual unit words phrases sentences respect requirement user solve ranking problem selection coherence problems solved ods improve diversity minimize redundancy pick phrases sentences somewhat similar relevant information covered summary lesser words summary coherent proach solves ranking problem learning certain set features sentence basis features score calculated sentence sentences arranged decreasing order scores list ranked sentences trivial problem select subset sentences coherent summary includes diverse information minimizes dancy word limit approach solves problem follows relevant sentence rst sentence sorted list chosen subset sentences form summary sentence selected sentence having highest jaccard similarity rst sentence picked half list process recursively incrementally repeated select sentences limit reached proposed approach preprocessing preprocessing crucial comes processing text ambiguities caused verb forms single word dierent accepted spellings certain word plural singular terms things words like known stop words certain high frequency words carry information serve purpose goal summarization phase document segmentation text divided paragraphs track paragraph sentence belongs position sentence respective paragraph paragraph segmentation paragraphs divided tences word normalization sentence broken words words normalized normalization involves lemmatization results words common verb form crudely stemmed roots ambiguities removed purpose use porters rithm stop word filtering token analyzed remove high frequency stop words pos tagging remaining tokens speech tagged verb noun adjective pos tagging module supplied nltk feature extraction complexity reduced ambiguities removed document structured sentence feature matrix feature vector tracted sentence feature vectors matrix experimented features combination following tence features turned suitable summarize factual reports computations text obtained preprocessing phase number thematic words frequently occurring words text found thematic words sentence ratio thematic words total words calculated sentence hematic thematic words otal words sentence position feature calculated follows sentence osition rst sentence text max min senpos position sentence text min max total number sentences document threshold calculated high feature value beginning ending document progressively decremented value middle sentence length feature exclude sentences short sentences able convey information sentence length number words words sentence sentence position relative paragraph comes directly observation start paragraph new discussion begun end paragraph conclusive closing osition ara rst sentence paragraph number proper nouns feature importance sentences having substantial number proper nouns count total number words pos tagged proper nouns sentence number numerals gures crucial presenting facts feature gives importance sentences having certain gures sentence calculate ratio numerals total number words sentence sentence umerals numerals otal words number named entities count total number named entities sentence sentences having references named entities like company group people important sense factual report term frequency inverse sentence frequency isf working single document taken isf feature account idf frequency word particular sentence multiplied total number occurrences word sentences calculate product add words isf words isf otal words sentence centroid similarity sentence having highest isf score considered centroid sentence calculate cosine larity sentence centroid sentence sentence similarity cosine centroid end phase sentence feature matrix feature enhancement sentence feature matrix generated sentence having feature vector values recalculation matrix enhance abstract feature vectors build complex features simple ones step improves quality summary enhance abstract sentence feature matrix given input restricted boltzmann machine rbm hidden layer visible layer single hidden layers suce learning process based fig restricted boltzmann machine size training data rbm perceptrons layer learning rate use persistent contrastive divergence method sample learning process trained rbm epochs batch size parallel gibbs chains sampling persistent method sentence feature vector passed hidden layer feature vector values sentence multiplied learned weights bias value added feature vector values learned rbm end rened enhanced matrix note rbm trained new document summarized idea document summarized going document unique features extracted section rbm freshly trained new document summary generation enhanced feature vector values summed generate score sentence sentences sorted according decreasing score value relevant sentence rst sentence sorted list chosen subset sentences form summary sentence select sentence having highest jaccard similarity rst sentence selected strictly half sorted list process recursively incrementally repeated select sentences specied summary limit reached sentences arranged order appearance original text produces coherent summary set haywire sentences results performance evaluation factual reports domains health technology news sports varying number sentences experimentation uation proposed algorithm run system generated summaries compared summaries produced humans fig comparison feature vector sum enhanced feature vector sum feature extraction enhancement carried proposed sections documents values feature vector sum enhanced feature vector sum sentence document plotted fig restricted boltzmann machine extracted hierarchical tation data initially variation discovering latent factors sentences ranked basis nal feature vector sum summaries generated proposed section fig precision values corresponding summaries documents evaluation system generated summaries based basic measures precision recall measure fig recall values corresponding summaries documents seen number sentences original document cross certain threshold restricted boltzmann machine ample data trained successfully summaries high precision recall values generated fig fig measure values corresponding summaries documents measure dened follows easure recall recision recall recision comparative analysis existing approach executed set articles layer rbm species average values precision recall measure plotted drawing comparison existing approach proposed approach keeping computation constant fig precison recall measure values proposed approach left bars existing approach right bars proposed approach average precision value average recall value higher existing approach proposed approach responds better summarization factual ports conclusion developed algorithm summarize single document factual reports algorithm runs separately input document instead learning rules corpus document unique advantage approach provides extract features given document enhance score sentence recent approaches rbms stacked feature enhancement approach uses rbm works eectively eciently factual reports demonstrated hand picking factual descriptions domains comparing system generated summaries written humans approach developed adapting extracted features user requirements adjusting hyperparameters rbm minimize processing error encoded values acknowledgments like extend gratitude daya gupta professor department computer science engineering delhi ical university providing insight expertise greatly assisted search references hovy automated text summarization ruslan mitkov oxford handbook computational linguistics mani house klein hirschman firmin sundheim ster summac text summarization evaluation proceedings ninth conference european chapter association computational linguistics association computational linguistics stroudsburg usa chuang yang extracting sentence segments text summarization machine learning approach proceedings annual international acm sigir conference research development information retrieval acm new york usa berger mittal query relevant summarization faqs ings annual meeting association computational linguistics association computational linguistics stroudsburg usa luhn automatic creation literature abstracts ibm journal search development vol issue baxendale machine index technical literature experiment ibm journal research development vol issue doi edmundson new methods automatic extracting journal acm vol issue zhang wang idvs interactive multi document visual rization system machine learning knowledge discovery databases lncs vol springer heidelberg darling song probabilistic document modeling syntax removal text summarization proceedings annual meeting association computational linguistics human language technologies acm press stroudsburg usa wan xiao single document keyphrase extraction neighborhood knowledge proceedings aaai conference articial intelligence shen sun yang chen document summarization conditional random fields proceedings international joint ence artical intelligence morgan kaufmann publishers inc san francisco usa wong extractive summarization supervised semi supervised learning proceedings international conference computational linguistics volume association computational linguistics stroudsburg usa chen yang zha zhang zhang learning object classes image thumbnails deep neural networks ieee international conference acoustics speech signal processing ieee icassp jin huang zhu comparative study ranking lection strategies multi document summarization proceedings international conference computational linguistics posters ciation computational linguistics stroudsburg usa singh kumar mangal singhal bilingual automatic text marization unsupervised deep learning international ence electrical electronics optimization techniques ieee doi iceeot natural language toolkit python nltk deep learning tutorials net performance evaluation information retrieval systems web stanford class handouts evaluation ppt padmapriya duraiswamy approach text summarization deep learning algorithm journal computer science vol issue jcssp
