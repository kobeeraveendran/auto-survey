text summarization deep learning ridge regression karthik bangalore mani illinois institute technology abstract develop models extract relevant features automatic text summarization investigate performance different models duc dataset different models developed ridge regressor multi layer perceptron hyperparameters varied performance noted segregated summarization task main steps sentence ranking second step sentence selection step given document sort sentences based importance second step order obtain non redundant sentences weed sentences high similarity previously selected sentences introduction process text summarization condense information possible losing gist document project develop extractive summarizer extracts important sentences document salient main steps summarization task sentence ranking sentence selection step importance score sentence document second step avoid redundancy summary weeds sentences convey meaning earlier selected sentences ntence ranking use predicted scores models sort descending order ones high predictions considered important ntence selection use greedy approach stitch multiple sentences summary step selection sentence maximal salience added summary similarity sentence summary exceeds threshold use idf cosine similarity set threshold sim process summarization converted regression task features sentence value score sentence real summary duc dataset different models deep mlp ridge trained cross validated heir hyperparameters varied accuracies plotted limited size dataset hand crafted features found simple ridge regressor beat deep models ridge best model sentences ranked selected ridge regressor approach data collection document understanding conference duc standard dataset experiment evaluate summarization models collected duc dataset build models dataset documents complete texts summaries written human feature extraction total features extracted sentence documents features listed position position sentence suppose sentences document ith sentence position computed ngth words sentence average mean term frequency words sentence divided sentence length average idf mean inverse document frequency words sentence divided sentence length average mean cluster frequency words sentence divided sentence length ratio number nouns verbs adverbs adjectives sentence divided length sentence entity ratio number named entities sentence divided length sentence numbe ratio number digits sentence divided length sentence stopword ratio number stopwords sentence divided length sentence use stopword list nltk package extracting features train matrix constructed clusters docs clusteri xij sentences clusteri number features sentence sentence baseline model usually argued sentence document captures important information document dummy model blindly predicts sentence predicted summary built mean score sentence actual summary documents computed performance noted ridge regression model ridge regression ibshirani like squares shrinks estimated coefficients zero given response vector predictor matrix rnp ridge regression coefficients defined utilizes supervised learning called backpropagation training network simple words training mlp main passes forward pass backward pass forward pass compute output activation functions backward pass find error activation functions finally weight updates weight updates generally follows swingler tuning parameter controls strength penalty term note linear regression estimate ridge balancing ideas fitting linear model shrinking coefficients ridge validation error validation phase fold cross validation identify best parameters regressor cross validating polynomial features found validation error minimum polynomial order shown plot mlp input layer output layer varying hidden layers experiments project mlp architecture input nodes total input nodes hidden nodes total hidden nodes output node linear output node predicted rouge score hidden layers varied performance noted example mlp input hidden output layers polynomial order chosen raised order testing phase multi layer perceptron multilayer wikipedia feedforward artificial neural network model maps sets input data set appropriate outputs mlp consists multiple layers nodes directed graph layer fully connected input nodes node neuron processing element nonlinear activation function mlp mlp validation error use fold cross validation deep mlp tune hyperparameters figure best hyperparameters validate model settings epochs optimizers sgd adam lbfgs activation functions logistic anh hidden layers number units hidden layer fixed validated mlp total different settings validation errors settings shown plots find validation error minimum optimizers logistic activation function hidden layers optimizers chose logistic activation function number hidden layers testing phase results best settings identified validation phase fit different models settings sentence model ridge order polynomial features mlp hidden layers adam optimizer mlp hidden layers lbfgs optimizer mlp hidden layers sgd optimizer logistic activation logistic activation logistic activation future work reason ridge regression beats models limited size dataset obtained documents actually low deep learning standard reason features hand crafted fed models future intend following rain duc datasets learn features text instead handcrafting fine tune hyperparameters dropout generate abstract summary instead extracting work query oriented summarization fit models recurrent neural nets est accuracy score predicted summary actual gold summary duc dataset plot accuracies shown find simple ridge regression model beats deep models references kevin swingler multi layer perceptrons stir courses lectures mlp pdf multilayer perceptron wikipedia org wiki neural network models supervised learn org stable modules html ryan modern regression stat cmu datamining pdf ziqiang cao furu wei dong sujian ming zhou ranking recursive neural networks application multi document summarization www aaai org ocs index php aaai paper download
