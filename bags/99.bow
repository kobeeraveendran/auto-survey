text summarization abstract meaning representation shibhansh dohare cse department iit kanpur iitk harish karnick cse department iit kanpur iitk vivek gupta microsoft research bangalore com abstract increasing size text present internet automatic summary eration remains important problem natural language understanding work explore novel pipeline text summarization termediate step abstract meaning resentation amr pipeline proposed rst generates amr graph input story extracts summary graph nally generate mary sentences summary graph proposed method achieves state art results compared text summarization routines based amr point signicant lems existing evaluation methods unsuitable ing summary quality introduction summarization large texts open lem language processing people nowadays lesser time patience large pieces text automatic tion important automatic summarization nicant applications summarizing large texts like stories journal papers news articles larger texts like books existing methods summarization broadly categorized categories tive abstractive extractive methods picks words directly sentences text methods inherently limited sense generate human level summaries large complicated documents require rephrasing sentences rating information text generate maries work summarization past extractive hand abstractive methods advantages recent developments deep learning specically recent success sequence sequence learning models recurrent networks read text encodes generate target text methods recently shown competitive tractive methods far away ing human level quality summary generation work summarization amr started liu abstract meaning representation amr introduced narescu amr focuses capturing meaning text giving specic ing representation text amr tries ture tence formalism aims tation sentences ing meaning example likes apple apples liked assigned amr liu approach aimed produce summary story extracting summary subgraph story graph nally ate summary extracted graph cause unavailability amr text tor time work limited till ing summary graph method extracts single summary graph story graph tracting single summary graph assumes important information graph extracted single subgraph difcult cases information spread graph method compromises size summary sub graph information extract easily solved instead single sub graph extract multiple subgraphs focusing background amr parsing generation amr introduced banarescu aim induce work statistical natural language understanding generation amr represents meaning graphs amr graphs rooted directed edge vertex labeled graphs figure shows graphical representation amr graph sentence looked carefully generated jamr parser gan graphical representation produced amrica saphra lopez nodes amr labeled concepts figure represents cept edges contains information relations concepts figure tion relation concepts amr relies propbank tic relations edge labels concepts form index represents rst sense word run details amr found amr guidelines narescu lot work parsing tences amr graphs main approaches parsing alignment based parsing flanigan parser zhou uses graph based algorithms concept relation tication second grammar based parsers like wang camr generate output performing shift reduce transformations output dependency parser neural parsing konstas peng based models parsing main problem neural methods absence huge corpus human generated amrs peng duced vocabulary size tackle problem konstas larger external corpus external sentences recently work ducing meaningful sentences form amr graphs flanigan number tree string conversion rules generating sentences song reformed problem eling salesman problem konstas learning methods datasets datasets task amr bank knight cnn dailymail figure graphical representation amr graph sentence looked carefully amrica mation different story propose step process extracting multiple summary graphs step select sentences story use idea sentences tant point view summary information contained summary present sentences generate summary second step extract important information selected sentences extracting sub graph selected tences main contributions work folds propose pipeline text summarization providing strong baseline future work summarization amr present novel approach extracting ple summary graphs outperforms vious methods based single sub graph extraction expose problems existing uation methods datasets abstractive summarization rest paper organized follows section contains introduction amr section contains datasets algorithm summary generation respectively tion detailed step step evaluation pipeline section discuss problems current dataset evaluation metric mann nallapati use proxy report section amr bank relevant task cause contains gold standard human ated amr graphs news articles maries training set stories maries contain sentences sentences average respectively training test sets contain summary document pairs respectively cnn dailymail corpus better suited marization average summary size sentences dataset document summary pairs stories having sentences average dataset comes sions anonymized version preprocessed replace named entities times india unique identier ample second non anonymized original text use anonymized version dataset suitable amr parsing parsers trained non anonymized text dataset gold standard amr graphs use automatic parsers amr graphs gold standard effect quality nal summary idea error introduced automatic parsers compare results gold standard automatically generated amr graphs standard dataset pipeline summary generation pipeline consists steps rst convert given story sentences amr graphs followed extracting summary graphs story sentence graphs nally generating tences extracted summary graphs following subsections explain methods greater detail step story amr rst step convert story sentences abstract meaning representations use jamr parser version flanigan openly available performance close state art parsers parsing dailymail corpus amr bank gold standard amr parses parse input stories jamr parser study effect graphs produced jamr parser instead figure graph best recall scores summaries sentences cnn dailymail corpus axis rogue score axis cumulative percentage sentence corresponding score gold standard amr graphs step story amr summary amr parsing step amr graphs story sentences step extract amr graphs summary sentences story sentence amrs divide task parts nding important sentences story extracting key information sentences amr graphs selecting important sentences algorithm based idea sentences important point view summary sentences contain important information sentences generate mary hypothesis information sponding summary sentence found sentence story test hypothesis summary tence sentence story tains maximum information summary tence use lin recall scores measures ratio number words summary contained predicted summary total number words target summary metric information tained story sentence consider story sentence predicted summary mary sentence target summary results obtained randomly chosen ment summary pairs cnn dailymail pus given gure average recall score obtained score fectly summary sentence directly picked story sentence manual inspection summary sentence sponding best sentence story realized score ways information summary sentence contained chosen story sentence score cases perfectly stop words different verb forms story summary sentence summary tences score hypothesis correct summary tences suggests highly extractive ture summary corpus task hand select tant sentences methods use sentence tion summary generation task common summarization tasks specically news articles lot mation contained initial sentences choosing initial sentences summary produces strong baselines state art methods beat marginally cnn dailymail corpus state art tive method beats initial sentences reported nallapati idea picking important sentences beginning propose methods rst simply pick initial sentences rst method stands ber sentences pick initial sentences cnn dailymail corpus rst sentence proxy report section amr bank produce best scores rogue metric compared rst second try capture relation important entities dene importance number occurrences entity story document simply rst sentence contains entities rst occurrence based sentence selection select rst sentence rst occurrence based sentence selection note methods rst rst default followed summary graph extraction step sentence selection methods important sentences rst based sentence selection extracting summary graph datasets consideration news ticles important information entity verb associated extract important information tence try entity talked sentence consider referred tity occurs frequently text main verb associated entity sentence verb closest entity amr graph dene closest verb lies rst path entity root start nding position ferred entity graph closest verb entity nally select subtree hanging verb summary amr step summary generation generate sentences extracted amr graphs use available generators use neural amr konstas provides state art results sentence ation use flanigan generator experiments section generators signicantly effect results analyze effectiveness generator section results analysis baselines cnn dailymail dataset section present baseline models analysis method step pipeline model considered strong baseline stractive paulus extractive lapati state art methods dataset beat baseline marginally model simply produces leading sentences document summary key step pipeline mary graph extraction directly comparing baseline amr based pipeline evaluate effectiveness unfair comparison errors introduced imperfect parser tor amr pipeline evaluate fectiveness baseline table comparison previous methods baselines table reports rogue scores proxy report section alignment based generator recall precision method liu amr occurrence rst table table analyzing effect jamr parser table rogue scores neural amr sentence generation half contains scores standard amr graphs second half amr graphs generated jamr parser method recall precision rogue amr rst occurrence rst gold standard amr jamr parser amr rst occurrence rst need nullify effect errors introduce amr parser generator achieve trying introduce similar errors leading thre sentences document generate amr graphs leading sentences generate sentences amr graph use parser generator pipeline consider generated tences new baseline summary shall refer amr baseline remaining paper proxy report section amr bank consider amr model line dataset standard amr graphs sentences need nullify error introduced generator procedure analyze evaluate step evaluation summaries use dard rogue metric comparison vious amr based summarization methods report recall precision scores literature marization uses scores rogue comparison report scores rogue method recall precision sured uni gram overlap reference predicted summary hand uses gram overlap uses longest common sequence target predicted summaries evaluation rest section provide methods lyze evaluate pipeline step amr parsing understand fects amr parser results compare nal scores following rst use gold standard amr graphs second amr graphs generated jamr parser pipeline tion contains comparison summary graph extraction uating effectiveness summary graph traction step compare nal scores lead amr baselines described section order compare summary graph traction step previous work liu generate nal summary generation method method uses simple module based alignments generating summary ments simply map words original tence node edge amr graph generate summary words aligned sentence selected graph particular order predicted summary generate matically correct sentences use metric similar liu based comparing uni grams target predicted summaries generation evaluating ity sentences generated method compare summaries generated model amr model standard dataset looked scores given rogue decided summaries evaluated humans duced interesting results given detail section results proxy report section table report results pipeline generation alignment based ation module dened section proxy report section amr bank ods perform liu method obtain best scores rst model important sentences perform amr baseline points effects jamr parser subsection analyze effect ing jamr parser instead standard amr graphs table scores gold standard amr graphs second table included scores jamr parser amr graph generation neural amr sentence generation methods scores methods including amr baseline dropped signicantly usage jamr parser affected scores rst amr drop rogue score use rst rogue points amr surprising result believe worthy research effectiveness generator subsection evaluate effectiveness sentence generation step fair comparison generation step use gold standard amrs perform extraction instead use amrs allows errors generated order compare ity sentences generated amr need gold standard sentence generation step simply use original sentence standard sentence generation pare quality summary generated amr scores rogue metric given rows table results signicant drop amr compared perform human evaluation check drop rogue scores drop information contained human readability inability rogue ric judge perform evaluation domly select test examples test cases proxy report section example summaries generated different models man evaluators human evaluator know summaries come model score assigned summary basis readability mation contained summary sponds lower level highest table compare scores cases given rogue human uation parser generator pairs cases gold neural gold neural original sentence spectively gold parser means gold standard amr graphs scores given humans relate rogue human evaluators gives similarly scores summary generated amr amr tually performing better readability dropped information clear scores information contained hand rogue gives high score models scores similar scores model shows tors actually producing meaningful sentences drop rogue scores mainly inability rogue evaluate abstractive summaries rogue gives model higher score compared model human evaluators opposite scores information table comparion scores given rogue human evaluators different models scores suggest rogue relate human evaluators parser generator jamr gold neural jamr gold neural original sentence information contained readability table results cnn dailymail corpus table parts contains baselines method state art non anonymized dataset second scores anonymized dataset method amr baseline non anonymized pointer generator coverage anonymized nallapati intra attention paulus recall rogue precision contained sentence possible reason inability rogue metric properly evaluate maries generated method inability evaluate restructured sentences amr formalism tries assign amr graphs sentences meaning exists mapping amr graphs sentences means automatic generators trying generate original sentence instead ing generate sentence underlying meaning helps plaining low rogue scores sentences getting rephrased loose tri grams original sentence resulting low rogue scores analyzing effectiveness amr extraction aim extracting summary graphs amr graphs sentence drop important information sentences able achieve perfectly recall scores getting remain add new information precision thrown useless formation effectively improving overall score rst rows ble scores amr extracted amr generation respectively safe extracting amr results improved precision recall reduces slightly resulting overall improved results cnn dailymail corpus table report results dailymail corpus present scores model rst row contains amr baseline results achieve petitive amr baseline rest table contains scores baseline followed state art method anonymized non anonymized versions dataset drop scores anonymized amr signicant largely error introduced parser generator related work discussion related work dang owczarzak showed work text summarization tive sentences selected text concatenated form summary vanderwende transformed input nodes pagerank algorithm score nodes nally grow nodes value low value heuristics approaches combine sentence pression sentences packed summary mcdonald martins smith almeida martins gillick favre ilps proximations encoding compression traction recently abstractive approaches proposed sequence sequence learning models task rush nallapati chopra standard encoder decoder models variants takase generate summaries incorporated amr information dard encoder decoder models improve results work similar graph based tive summarization methods penn cheung gerani penn ung dependency parse trees produce summaries hand work takes vantage semantic graphs need new dataset evaluation metric rogue metric design lots ties unsuitable evaluating tive summaries example rogue matches exact words stems words considers stop words evaluation reasons rogue like metrics suitable evaluating abstractive maries incapabilities knowing tences restructured good evaluation metric compare ing sentence exact words showed section rogue suitable evaluating summaries generated amr pipeline cnn dailymail corpus suitable abstractive summarization nature summary points corpus highly extractive section details summary points simply picked sentences story tough good reason start searching better dataset biggest problem dataset dataset property lot important formation rst sentences summary points directly pick sentences extractive methods based tence selection like summarunner ally performing results got slightly better baseline work selected tences rst case sentences selected extractive methods rst sentences problem abstractive methods output getting copied initial sentences problems corpus evoke need corpus concentration important information location information spread summaries abstractive nature possible future directions proposed algorithm step step cess focus improving step duce better results exciting ments summary graph tion method lot work extract amr graphs summaries order pipeline generalizable sort text need rid hypothesis summary extracted exactly tence natural direction joining amr graphs multiple sentences similar extracting summary amr large graph like clustering similar tences extracting summary graph cluster idea use amr graphs important sentence selection conclusion work explored pipeline amr summarization rst time propose new method ing summary graph outperformed previous methods overall provide strong baseline text summarization amr possible future works showed rogue evaluating abstractive summaries generated amr pipeline references miguel almeida andre martins fast robust compressive summarization dual composition multi task learning ings acl laura banarescu claire bonial shu cai madalina georgescu kira griftt ulf jakob kevin knight philipp koehn martha palmer nathan schneider guidelines com amrisi guidelines blob master amr laura banarescu claire bonial shu cai madalina georgescu kira griftt ulf hermjakob kevin knight martha palmer philipp koehn abstract nathan schneider ing ceedings linguistic annotation workshop aclweb org anthology representation sembanking sumit chopra michael auli alexander rush abstractive sentence summarization tentive recurrent neural networks hoa trang dang karolina owczarzak overview tac update summarization task proceedings text analysis conference tac jeffrey flanigan jaime carbonell chris dyer generation noah smith tree abstract meaning proceedings transducers ference north american chapter association computational linguistics org anthology representation jeffrey flanigan sam thomson jaime carbonell chris dyer noah smith inative graph based parser abstract ing representation proceedings annual meeting association tional linguistics association computational linguistics baltimore maryland pages aclweb org anthology shima gerani yashar mehdad giuseppe carenini raymond bita nejat stractive summarization product reviews discourse structure proceedings emnlp org papers pdf pdf dan gillick benoit favre scalable global model summarization ings naacl workshop integer ear programming natural langauge processing acm org citation kevin knight laura baranescu claire bonial madalina georgescu kira griftt ulf hermjakob daniel marcu martha palmer nathan der deft phase amr annotation philadelphia linguistic data tium abstract meaning representation amr notation release web download philadelphia linguistic data consortium ioannis konstas srinivasan iyer mark yatskar yejin choi luke zettlemoyer neural amr sequence sequence models parsing eration proceedings annual ing association computational guistics association computational linguistics org lin rouge package automatic tion summaries text summarization branches post conference workshop acl barcelona spain fei liu flanigan jeffrey thomson sam sadeh man smith noah abstractive summarization semantic representations proceedings conference north american chapter association tational linguistics association computational linguistics denver colorado pages aclweb org anthology andre martins noah smith summarization joint model tence extraction compression ings acl workshop integer linear programming natural language processing aclweb org anthology ryan mcdonald study global inference gorithms multi document summarization ceedings ecir ramesh nallapati feifei zhai bowen zhou summarunner recurrent neural network based quence model extractive summarization uments proceedings thirty aaai conference articial intelligence org anthology ramesh nallapati bowen zhou cicero glar ulehre abstractive text santos sequence sequence rnns computational natural aclweb org anthology dos bing xiang summarization learning language romain paulus caiming xiong richard socher deep reinforced model abstractive marization org karl moritz hermann tomas kocisky ward grefenstette lasse espeholt kay phil blunsom mustafa suleyman teaching machines read comprehend org pdf xiaochang peng chuan wang daniel gildea anwen xue addressing data sparsity sue neural amr parsing proceedings conference european chapter ation computational linguistics association computational linguistics valencia spain pages aclweb org anthology gerald penn jackie chi kit cheung automatic proceedings emnlp supervised sentence enhancement summarization aclweb org anthology alexander rush sumit chopra jason weston neural attention model sentence marization org naomi saphra adam lopez rica amr inspector cross language system demonstrations ments conference north american chapter association computational linguistics aclweb org anthology liu abigail peter manning marization pointer generator org anthology christopher networks point linfeng song yue zhang xiaochang peng zhiguo wang daniel gildea amr text eration traveling salesman problem ings conference empirical ods natural language processing association computational linguistics austin texas pages org anthology sho takase jun suzuki naoaki okazaki tomu hirao masaaki nagata ral headline generation abstract meaning representation proceedings emnlp org anthology lucy vanderwende michele banko arul menezes event centric summary generation proceedings duc chuan wang sameer pradhan xiaoman pan heng nianwen xue camr task extended transition based amr parser proceedings international workshop semantic evaluation association compuational linguistics aclweb org anthology junsheng zhou feiyu hans uszkoreit weiguang ran yanhui amr parsing incremental joint model proceedings conference empirical methods ural language processing association tational linguistics austin texas pages org anthology
