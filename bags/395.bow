machine learning generic user focused summarization inderjeet mani eric bloedorn mitre corporation sunset hills road reston usa org abstract key problem text summarization ing salience function determines information source included summary paper describes use machine learning training corpus uments abstracts discover salience functions describe combination features optimal given summarization task method addresses generic user focused summaries mushrooming quantity line text information triggered growth world wide web especially useful tools help users digest information content text summarization attempts address need ing partially structured source text extracting formation content presenting important content user manner sensitive user application needs end result condensed version original key problem summarization determining information source included summary mination salience information source salience function text depends including nature number interacting factors genre source text desired compression summary length percentage source length application information needs mation needs include reader interests tise suggesting distinction user focused versus generic summaries use summary example intended alert user source tent indicative function stand place source informative function oer critique source evaluative function sparck jones american association articial intelligence www aaai org rights reserved considerable body research years explored dierent levels analysis text help determine information text salient given summarization task salience functions usually sentence lters methods scoring sentences source text based contribution dierent features features included example location edmundson paice jones statistical measures term prominence luhn brandow mitze rau ical structure miike marcu ilarity sentences skorokhodko ence absence certain syntactic features pollock zamora presence proper names kupiec pedersen chen measures nence certain semantic concepts relationships paice jones maybury fum guida tasso general appears number features drawn dierent levels analysis combine contribute salience importance particular feature course vary genre text consider example feature text location newswire texts common narrative style volves lead text oers summary main news item result varieties newswire summarization methods use leading text tend outperform methods brandow mitze rau varieties newswire anecdotal lead ins multi topic articles fare leading text approach genres brandow mitze rau locations salient scientic cal articles introduction conclusion sections contain pre summarized material news broadcasts nds segments contain trailing information summarizing forthcoming segment viously wish develop summarization system adapt dierent genres important automatic way nding location values useful genre instead combined features ing combining features adhoc manner require adjustment new genre text natural suggestion use machine learning training corpus documents abstracts discover salience functions describe combination features optimal given summarization task basis able approach summarization training corpus contains generic stracts abstracts written authors professional abstractors goal dissemination particular usually broad readership nity salience function discovered describes feature combination generic maries likewise training corpus contains focused abstracts abstracts relating information document particular user interest change time learn function user focused summaries generic abstracts traditionally served surrogates text computing environments continue date increased text searching browsing sonalized information ltering user focused abstracts assumed increased importance algorithms learn kinds summaries highly relevant current information needs course interest sort overlap exists features learnt cases paper describe machine learning proach learns generic summaries focused ones focus machine learning pects particular performance level comparison tween dierent learning methods stability ing dierent compression rates ships rules learnt generic focused case overall approach approach summary treated tation user information need words query training procedure assumes provided training data consisting collection texts abstracts training procedure rst assigns source sentence relevance score dicating relevant query basic boolean labeling form procedure source sentences particular relevance threshold treated summary sentences source sentences represented terms feature descriptions summary sentences labeled positive examples training sentences positive tive examples fed machine learning algorithms construct rule function labels new sentence feature vector summary vector generic summary case training stracts generic corpus written abstracts articles user focused case training abstract document erated automatically specication user formation need worth distinguishing approach previous work trainable summarization ular kupiec pedersen chen xerox parc referred henceforth parc proach followed teufel moens goal learn rules easily edited humans second proach aimed generic summaries user focused summaries extending generic summary orientation parc work treating abstract query match tire abstract sentence source instead matching individual sentences abstract sentences source tactic sensible distribution ideas stract sentences abstract sic interest completely avoids tricky problem sentence alignment including sideration cases sentence source match sentence abstract parc approach deal strong assumptions independence features parc based work uses bayes rule assume trainable approaches include lin hovy approach learnt training series sentence positions case learn rules dened variety features lowing abstract characterization rization finally learning process require manual tagging text generic summaries requires generic abstracts available user focused abstracts require user select documents match interests features set features studied encoded ble grouped classes cation features exploit structure text ferent shallow levels analysis consider matic feature based proper names extracted sra nametag krupka system use feature based standard idf metric weight term document given corpus given tfik tfik frequency term document vided maximum frequency term ment dfk number documents term occurs total number documents sorts sentences document feature question assigns current sentence belongs scored sentences pression rate turns removing discretization lter completely use raw scores feature merely increases complexity learnt rules improving performance feature sent loc para para loc section sent special section depth sent section values description sentence occurs rst middle para sentence occurs rst middle section sentence occurs introduction conclusion sentence level section sentence subsubsubsection location features sent highest sent highest idf sent highest sent highest title sent highest pname sent highest syn sent highest occ thematic features average score filter average idf score filter average score filter number section heading title term mentions filter number mentions filter cohesion features number unique sentences synonym link sentence filter number unique sentences occurrence link sentence filter table text features idf metric standard tics better suited small data sets dunning statistic indicates lihood frequency term document greater expected quency corpus given relative sizes document corpus version use based cohen uses raw frequency term document frequency corpus number terms document sum term counts corpus turn features based cohesion text cohesion halliday hasan involves relations words referring expressions tightly connected text cohesion brought linguistic devices repetition synonymy anaphora ellipsis models text hesion explored application tion retrieval salton paragraphs similar threshold paragraphs bushy nodes considered likely salient text cohesion applied explication discourse structure morris hirst hearst focus newed interest text summarization boguraev kennedy mani bloedorn elhadad work use based features synonymy occurrence based bigram statistics compute synonyms gorithm uses wordnet miller comparing tentful nouns contentfulness determined function word stoplist synset common nouns extracted bic speech tagger aberdeen occurrence scores contentful words words apart computed standard mutual information metric fano church hanks mutual information terms document mutinf nitfji tfjitfki tfji maximum frequency bigram document tfji frequency term document total number terms document document question entire cmp corpus occurrence table stores scores counts greater mutinfo scores greater training data use training corpus computational tics texts text articles generic summarizer author supplied stracts computation language print archive cmp provided sgml form university edinburgh articles tween pages length gures captions references cross references replaced place holders average compression rate stracts corpus sentences text extracted sentence tagger aberdeen coded feature vectors labeled respect evance text abstract labeling function uses following similarity metric idf weight word sentence number words common total number words labeling compression rate relevance ranked sentences document picked positive examples ment resulted training vectors considerably redundancy moved yielded unique vectors learning implementations ignore duplicate vectors positive negative positive vectors random subset metric predictive accuracy number testing examples classied correctly denition precision recall balanced score total number test examples number positive examples classied correctly number examples classied positive testing number positive examples classied correctly number known positive testing recision recision recall table metrics measure learning performance negative collected form balanced training data examples labeled vectors input learning methods preliminary data analysis generic training data indicates sion features signicant dierence summary non summary counts ture value feature test suggests reasonable set features problem dierent learning methods disagree importance individual features generating user focused training abstracts overall information need user dened set documents subject told pick sample documents cmp matched interests content words tracted document scored score cmp corpus background corpus centroid vector user interest uments generated follows words documents sorted scores scores averaged words occurring multiple documents words standard deviations mean words scores treated sentation user interest topic words topic ing activation algorithm based mani bloedorn discover document cmp pus words related topic words corpus documents reweighted spreading activation sentence weighted based average word weights compression rate sentences picked positive examples document constituting user focused abstract extract ment allow user focused features learnt sentence vector extended additional user interest specic features number reweighted words called keywords sentence number keywords contentful word note keywords ing terms user focused abstract include use specic keywords features prefer learn rules transfer interests related terms learning methods use dierent learning algorithms ized canonical discriminant function scdf sis spss rules quinlan wnek scdf multiple sion technique creates linear function maximally discriminates summary summary examples method unlike advantage generating logical rules easily edited user fers relatively simple method telling extent data linearly separable results metrics learning algorithms shown table table results averaged runs training test test data runs interestingly learning generic maries corpus thematic cohesion tures referenced rules negative class location features referenced rules positive class focused summary learning number keywords sentence single feature responsible dramatic improvement learning performance pared generic summary learning rules feature combination tests cational features user focused interests tend use subset locational features found generic terests user specic keyword features scdf rules user focused case keywords feature inuential rules learnt algorithm positive user focused examples signicant values keywords feature linearly separable negative ones cases algorithms yield useful rules include keywords features generic case positive examples linearly separable lesser extent overall gures higher ported parc performance metric based uses holdout document method scdf generic scdf user focused generic user focused rules generic pruned rules user focused pruned predictive accuracy precision recall score table accuracy learning algorithms compression overlap positively labeled sentences vidual sentences abstract based overlap abstract making cult compare worth noting eective features generic learning subset parc features cohesion features tributing little overall performance note unlike parc work avail tor phrases known genre dependent recent work similar overlap metric teufel moens reports indicator phrase ture single important feature accurate learning performance sentence extraction task ing corpus striking good learning performance exploiting feature analysis rules learning curves generated compression reveal learning improvement generic case predictive accuracy score user focused case reaches plateau early predictive curacy score attributed relative dominance keyword feature found surprisingly little change learning mance compression results suggests approach maintains high performance certain spectrum summary sizes inspection rules shows learning system learning similar dierent rules compression rates example rules follows sentence conclusion high idf sentence summary sentence generic rule run compression sentence section depth number keywords keyword content word ratio inclusive summary sentence user focused rule run compression seen learnt rules highly ble easily edited humans desired contrast approaches scdf naive bayes learn mathematical function tice useful human use learning methods generate initial set rules performance evaluated data intuition leading improved formance conclusion described based machine learning approach produce generic user specic maries approach shows encouraging learning performance rules learnt user focused ests tend use subset locational features found rules generic interests specic keyword features rules intelligible making suitable human use approach widely applicable require manual ging sentence level text alignment future expect investigate use regression niques based continuous boolean beling function course learning ing function tell useful summaries plan carry task based evaluation summaries finally intend apply approach genres text languages thai chinese acknowledgments indebted simone teufel marc moens byron georgantopoulos university edinburgh providing cmp corpus barbara gates mitre helping occurrence data references aberdeen burger day hirschman robinson vilain mitre description alembic system ings sixth message understanding conference columbia maryland november barzilay elhadad lexical chains text summarization mani bury eds proceedings acl workshop intelligent scalable text tion madrid spain salience based boguraev kennedy content characterization text documents mani maybury eds proceedings acl workshop intelligent scalable text summarization madrid spain maybury generating summaries event data information processing management miike itoh ono sumita text retrieval system dynamic abstract eration function proceedings acm dublin ireland miller wordnet lexical database english communications acm morris hirst lexical cohesion puted thesaural relations indicator structure text computational linguistics paice jones identication portant concepts highly structured technical pers proceedings acm pittsburgh pollock zamora automatic abstracting research chemical abstracts service journal chemical information computer sciences quinlan programs machine learning morgan kaufmann san mateo salton allan buckley singhal tomatic analysis theme generation rization machine readable texts science june skorokhodko adaptive method automatic abstracting indexing ifip congress ljubljana yugoslavia sparck jones summarizing mani maybury eds proceedings acl workshop intelligent scalable text summarization madrid spain spss base applications guide spss inc chicago wnek bloedorn michalski tive inductive learning method method user guide machine learning inference laboratory report george mason sity fairfax virginia teufel moens sentence extraction rhetorical classication flexible abstracts working notes aaai spring symposium intelligent text summarization spring nical report aaai brandow mitze rau automatic condensation electronic publications sentence selection information processing management computation gov cmp language print archive kenneth church patrick hanks word ciation norms mutual information phy proceedings vancouver british columbia june cohen hilights independent automatic indexing terms stracting journal american society formation science vol important erratum dunning accurate methods statistics surprise coincidence computational tics edmundson new methods automatic stracting journal association computing machinery fano transmission information mit press fum guida tasso evaluating portance step text summarization ceedings ijcai halliday hasan cohesion text don longmans hearst texttiling segmenting text multi paragraph subtopic passages computational linguistics george krupka sra description sra system proceedings sixth sage understanding conference columbia maryland november julian kupiec jan pedersen francine chen trainable document summarizer proceedings acm seattle lin hovy identifying topics sition proceedings applied natural language processing conference luhn automatic creation literature stracts ibm journal research development mani bloedorn multi document rization graph search merging proceedings fourteenth national conference articial intelligence providence marcu discourse structures text maries mani maybury eds ceedings acl workshop ligent scalable text summarization madrid spain
