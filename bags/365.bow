an enhanced meansum method for generating hotel multi review summarizations author saibo geng supervisor diego antognini prof boi faltings lab articial intelligence epfl switzerland abstract multi document summaritazion is the process of taking multiple texts as input and producing a short summary text based on the content of input texts up until recently multi document summarizers are mostly supervised extractive however supervised methods require datasets of large paired document summary examples which are rare and expensive to produce in an unsupervised multi document abstractive summarization was proposed by chu and liu and demonstrated competitive performances comparing to extractive methods despite good evaluation results on automatic metrics meansum has multiple limitations notably the inability of dealing with multiple aspects the aim of this work was to use multi aspect as content selector to address the issue with multi aspect moreover we propose a regularizer to control the length of the generated summaries through a series of experiments on the hotel dataset from trip advisor we validate our assumption and show that our improved model achieves higher rouge sentiment accuracy than the original meansum method and also comprarable close to the supervised baseline automatic summarization interpreatability of deep learning multi aspect masker meansum deep learning neural network abstractive summarization keywords i introduction text automatic summarization is a challenging task in nlp and it s also among the most focused research topics recently in industry text automatic summarization has various application in addition to the direct generation of text such as generating headlines it can also play an important role in other nlp tasks as intermediate step for example in text sentiment analysis search engine and recommendation system comparing to use original text employ a summarized text could enhance the performance without losing much information depending on the method of summarizing a summarizer can be either extractive abstractive extrative method explictly uses text level or word level from input texts to construct the output summary while an abstractive method produces novel text which contains the essential information of input and avoid repeating the texts from input document abstractive summarization has been studied using neural sequence transduction methods with datasets of large paired document summary examples however such datasets are rare and expensive to produce recently some progress has been made in unsupervised abstrative leanring meansum an unsupervised multi document abstractive summarization method proposed by chu and liu in demonstrated competitive performance on multiple metrics with extractive methods meansum model takes the similarity between multiple input reviews and generated summary plus an encoder decoder as objective function it does not rely on any specic features of given dataset however meansum is highly abstractive but not takes into account any information on review s content besides evluations on output summaries show that meansum is biased towards high precision and low recall to address the rst issues we suggest to use masks instead of original reviews as input in order to reduce the unnecessary information and guide the summarizer to address the second issue we suggest a regularizer to constraint the output summaries length despite the fact that our masks help the meansum model to achive better performance our study shows it could increase the difculty of training fig meansum ii methods a meansum we chose meansum because it s the latest unsupervised highly abstrative multi reviews summarization model and demonstrates performance comparable to extractive methods on their validation dataset meansum model is composed of two main conponents an auto encoder module that learns representations for each case of no pretrained language model and guarantees the uency of generated language and a summarization module that learns to generate summaries that are semantically similar to each of the input reviews these two modules contribute a reconstruction loss and similarity loss respectively both components contain an lstm encoder and decoder the two encoders weights and the two decoders weights are tied by default the autoencoder reconstruction loss function is a cosinus similarity between the input texts and reconstructed can be reviews masks or rsar the summary review similarity loss is dened as the average cross entropy between the generated summary and each input text the summary review similarity loss is the key how meansum achieves unsupervised learning b masks of reviews the term mask or rationale is generally understood as a long word sequences from the input text which sufce for neural network system to make the prediction we can consider masks as informative text within reviews and the non mask part of reviews are little informative having masks enabled us to implement a content selection on reviews before feeding them to neural network a rst usage of masks is to lter noises from original reviews a second usage is to aggregate review information by categories this could help the summarizer we use the multi aspect to build masks on the hotel review mam allocates to each review segment a most related aspect from ve candidates service cleanliness value location room masks were used in three different ways in this project maskconcatenate all masks as ltered review rsarsplit all reviews into single aspect segments and regroup them by the associated hotel train a single summarizer for the regrouped summaries fig regrouped single aspect review rsar i v use the same regrouped reviews as in the previous case but classify them by aspect and for each aspect train an individual summarizer it is critical to note that masks are not homogeneously distributed over different aspects in particular far more reviews than any other than half of the whole rsar dataset which outlines that customers attach most importance to this aspect when evaluate a hotel and have less than of the whole rsar dataset s reviews dataset rsar rsar rsar rsar rsar rsar review quantity table i reviews distributions on aspects fig rsar i v c controlling summary length this capability of controlling generated text s length is crucial for various nlp applications notably text rization in the context of text summarizaiton generation of headlines requires a concise summaries with a short length while in legal contract analysis a summary potentially longer and with high recall is targeted length control method for extractive summarization has been investigated by a recent review of the literature on this topic found that suggested methods of controlling text encoder decoder system s output length in this work we suggest to control output summary length by adding a length loss term into the objective function of meansum to this end we propose a concept of text shortness intuitively the shortness of a summary is characterized by the length of the summary but as the loss function built upon this denition is not differentiable it s not a good denition in deep learning we use the average probability of giving as next token during the whole text generation process as the denition of shortness in the extreme case where the text generated is very short shortness will be high and in the case where the text generated is very longshortness will necessarily be small as it s not sampled through the whole sampling processes in particular we notice that shortness is for summaries reaching the maximal length here we give an example of the generated summary for readers to better understand this concept i have stayed at the hotel before and it was a lovely experience it is a very old hotel but the rooms are a little dated and could do with a bit of a facelift the staff were all very helpful and friendly nothing was too much trouble we did nt use the restaurant but the food was good value for money pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad once we have dened the shortness we can use it to calculate the shortness of input reviews and the shortness of generated summary the length loss function is dened as below llen si are two coefcient used to regularize the effect of length constraint in case where the length constraint is set to be close to the mean length of input reviews a larger will lead to a longer summary and a small to a shorter summary d supervised baseline we also designed a supervised model to compare with our model as showed in the figure we replace the autoencoder reconstruction loss by a standard cross entropy loss between gold short summaries and generated summaries the nal loss we optimize is simply lsupervised lautoencoder lcrossentropy we use the summarizer trained on masks reviews and rsar to generate summary on our validataion set no tuning was performed we used the exact same model as in the previous part after that we train on each dataset a supervised model and test them on the same validation set as for unsupervised model to compare the performance fig supervised model iii metrics and evaluation a automated metrics without reference summaries here we use the same metrics as proposed in the meansum paper rouge rouge is a common automated metrics in text summarization as we want to evaluate our summarizer without reference summaries a variation of rouge score is adopted instead of calculating rouge score between reference summary and generated summary we do the same calculations between each source review and generated called wordoverlap in meansum paper finally we take the average of these score and dene it as rouge score rou gei rou j n n where k is the number of reviews being in our experiments in this paper we used and sentiment accuracy a useful summary should reect and be consistent with the overall sentiment of the reviews we rst separately train a cnn based classication model that given a review predicts the star rating of a review an integer from to for each summary we check whether the classier s predicted rating is equal to the average rating of the reviews being summarized rounded to the nearest star rating n n clf round k j log likelihood we use nll to measure the uency of generated text a low nll reects high language uency in the generated text b automated metrics with reference summaries rouge to compare our model with supervised baseline we use the reference summary to caculate the rouge of generated summary the rouge used here is identical as in the one widely used a datasets description iv experimental setup to evaluate the performance of our model we crawled hotel reviews from tripadvisor each review contains a ve star rating for each aspect service cleanliness value location and room the average correlation between aspects is high on average dataset hotel review dataset number of reviews before ltering number of reviews after ltering number of hotels before ltering number of hotels after ltering maximal review length average of review length characters characters table ii statistics on hotel review dataset it s benecial to compare our model with a supervised model to enable the training of a supervised model we scraped hotel information including a short overall summary and multiple summaries on various aspects from trustyou com among the hotels of them are also present in our hotel review dataset we take the intersection of the two dataset and use it for supervised learning it is important to note that gold summaries are much shorter compared to reviews a gold summary typically looks like beach hotel close to the beach great rooms and fantastic service beautiful beach while the review generated by meansum are in general much longer b experimental details in subword v results dataset average short gold summary length average long gold summary length number of reviews before ltering number of reviews after ltering number of hotels before ltering number of hotels after ltering average of review length supervised dataset characters characters characters table iii statistics on hotel with ground true summary dataset input reviews rouge l sentiment accuracy nll mean summ comment review masks rsar best overall repetitive highly repetitive too large highly repetitive table iv automated metric results with reviews being summarized a main results the automated metrics for our model and the baselines are shown in table iii using the test split of each input review dataset our experiments conrm that use rsar as input text provided a boost to meansum compared to feeding original reviews on automatic metric evaluations as we mentioned in the dataset description sectionii b masks are not homogeneously distributed over different aspects viii we nd empirically that the dataset size is correlated with the repetitiveness of generated summaries in case of small training dataset such as and the output summaries are highly repetitive despite good rouge scores and nll based on this consideration we only consider and as robust input review datasets among all these datasets rsar outperforms in sentiment and gives second best result in and rouge l while outperforms on rouge l although and other single aspect dataset fails to beat the performance of rsar on we believe this is due to the huge diffrence on size of dataset it could be imagined that given similar size of data single aspect summarizer would outperform multi aspect on other metrics the apparent repetitiveness on the summary of and is mostly due to the lack of data we aware that the inhomogeneity of review number of different aspects is intrinsic and it reveals the priority that customers give while making reviews on the hotel a direct solution to this would be shorten the output summary a simple but brutal method that we tested was to trauncate the output summary after a given number of sentences this method did solve the repetitiveness issue and the output summary are quite uent unfortunately as the summary truncated are very short the metric on it has very low recall and a very high precision thus brutal truncation is not satisfactory and needs to be improved in the future b issue with language uency the introduction of mask into summarization model aims to guide the summarizer model to focus on the important meaningful part of the input reviews however one direct counter effect is the regrouped masks lack language rouge score used in this evaluation is different from the traditional one as meansum it s an unsupervised learning without true summary cf evaluations section highly biaised sentiment distribution in undermines its high sentiment accuracy uency in contrary to reviews written by humans masks are generated by concatenating the selected segments of corresponding reviews this direct concatenation leads to a fragmented language style this counter effect is more signicant on rsar as reviews are split into more ne grained pieces and regrouped together in the rst example below there two places where the mask lost language uency due to the sentences discarded in the second example above the rst phrase is not semantically clear as we do not know who the he refers to and this may confused language model as in real texts a undened he rarely appears as the beginning of the text the and sentences have the same subject which are syntactically repetitive this happens from time to time adding difculties for model to capture the right syntax and semantics original review check in was quick and jessie spelling was very friendly she explained everything and went out of her way to check on things for us the room was nice but older the beds were metal frames weight rating unknown with nice mattresses the headboards interesting and had reading lights attached the room was clean until day when we had a roach wave hello from the side table we killed it and forgot about it then the last day we saw more in all stages of growth from nymph to full adult one had even gotten into the fridge so we were happy to be leaving the a c unit worked well the pool hours were enforced and the place was quiet during quiet time wi worked good enough nice sized tv with an okay line up parking was a pain in the butt ataken from review in hotel test dataset hotelreview reviews qualityi nnf loridac ity f loridac ityf lorida html masks concatenated check in was quick and jessie spelling was very friendly she explained everything and went out of her way to check on things for us the room was nice but older the room was clean until day when we had a roach wave hello from the side table in all stages of growth from nymph to full adult one had even gotten into the fridge so we were happy to be leaving the pool hours were enforced and the place was quiet during quiet time wi worked good enough nice sized tv with an okay line up parking was a pain in the butt rsar he was very friendly to the point of sleeping on our bed when we fell asleep the young man who greeted us was friendly courteous helpful and very accommodating the young man was not so pleased and mentioned that they had been looking for the cat all day there were a lot of nice touches such as a happy hour with complimentary cheese and wine each day which we sampled on our rst night in the afternoons there was complimentary cake a beverage available but we did not try it ataken from entry from rsar test dataset aspect hotelreview reviews roxbroh ouse w arkworthamblen orthumberlande ngland html further observations on the tensorboard for language models conrmed with our initial ndings we notice that language model with the same conguration has higher loss on hotel masks after a given number of batches contrary to expectations the language model loss function on rsar are lower than both hotels and masks which could be due to the fact that rsar texts are single aspect thus helps to reduce the difculty of predicting next word given previous words lm loss function on hotel mask lm loss function on hotel review fig loss function curve for reviews and masks c unbalanced recall and precision interestingly for all input review datasets we nd that rouge score are always biased towards high recall and low precision below is the example of rsar as precision and recall are related to the summary length longer the summary is higher its recall could potentially be and lower its precision could be this is not always true especially when the summary are just recopying its self then no matter how long the summary it s its recall and precision both remain the same but if we can control the output summary length by not just repeating it may allow us to improve the the rouge score by balancing the precision and recall rouge rougel precision recall table v detailed rouge scores of rsar to address this issue we introduced length loss and tested it with different parameter values model length loss mean summ comment baseline table vi effect of length loss parameter the results in particular the column of mean summary length conrmed our hypothesis upon the regularizer effect of length loss both can regularize the output summary length in addition to this we notice the recall and precision were balanced by the variation of summary length as in table vi and table vii recall keeps growing and precision keeps decreasing this remarkable result shows that the effect of length loss is not simply repeating but generating new content unfortunately we did not see any improvement on this is due to the fact that the decreasing rate of precision is faster than the increasing speed of recall thus the gain on recall is model mean summ comment table vii effect of length loss parameter not enough to ll the loss on precision further ne tune of parameters such as learning rate might resolve this issue besides the control on the generated summaries length is only in a qualitative manner we could not constraint the length of generated summaries into a given interval d supervised baseline summarizer meansum on review meansum on mask meansum on rsar supervised on review supervised on mask supervised on rsar in progress in porgress in progress rl table viii supervised vs meansum this part of experiement is still in progress so far we have the results for meansum on review meansum on mask and supervised model on review from current results we could say our model has comparable performance with supervised model and even higher this is not trivial as we could generate comparable results without requirement on the reference summaries we expect our model trained on rsar could surpass supervised model vi conclusion limitations and future work our work consists of improving the recent unsupervised abstractive multi review summarization meansum as a highly abstractive summarizer model meansum lacks attention mechanism to address this limitaion we introduced masks on original reviews to help summrizer focus on important points our model demonstrates remarkable improvement on rouge scores besides to address the unbalanced precision recall phenomenon on meansum we suggested a regularizer on the output summary length which has a notable effect regularizer on output summary length did not lead to improvement on rouge scores this is probably due to the inappropriate parameters of training further ne tune on parameters are necessary the comparison of our model with supervised model is still in progress which would help us better position our model s performance references diego antognini multi dimensional explanation of reviews maximin coavoux hady elsahar and matthias gall unsupervised aspect based multi document abstractive summarization in proceedings of the workshop on new frontiers in summarization pages hong kong china november association for computational linguistics eric chu and peter j liu unsupervised neural multi document abstractive summarization corr eric chu and peter j liu unsupervised neural multi document abstractive summarization corr yuta kikuchi graham neubig ryohei sasano hiroya takamura and manabu okumura controlling output length in neural encoder decoders in proceedings of the conference on empirical methods in natural language processing pages austin texas november association for computational linguistics chin yew lin rouge a package for automatic evaluation of summaries in text summarization branches out pages barcelona spain july association for computational linguistics yashar mehdad amanda stent kapil thadani dragomir radev youssef billawala and karolina ner extractive summarization under strict length constraints in proceedings of the tenth international conference on language resources and evaluation pages portoro slovenia may european language resources association elra
