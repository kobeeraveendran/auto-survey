p e s l c s c v v i x r a podsumm podcast audio summarization aneesh vartakavi and amanmeet garg gracenote inc the diverse nature scale and specificity of podcasts present a unique challenge to content discovery systems listeners often rely on text descriptions of episodes provided by the podcast creators to discover new content some factors like the presentation style of the narrator and production quality are significant indicators of subjective user preference but are difficult to quantify and not reflected in the text descriptions provided by the podcast creators we propose the automated creation of podcast audio summaries to aid in content discovery and help listeners to quickly preview podcast content before investing time in listening to an entire episode in this paper we present a method to automatically construct a podcast summary via guidance from the text domain our method performs two key steps namely audio to text transcription and text summary generation motivated by a lack of datasets for this task we curate an internal dataset find an effective scheme for data augmentation and design a protocol to gather summaries from annotators we fine tune a model with our augmented dataset and perform an ablation study our method achieves rouge l scores of on our dataset we hope these results may inspire future research in this direction ccs concepts information systems speech audio search computing methodologies cross validation applied computing sound and music computing additional key words and phrases podcasts speech summarization neural networks introduction the recent surge in popularity of podcasts presents a big opportunity and a unique set of challenges to existing content discovery and recommendation systems podcasts usually require active attention from a listener for extended periods unlike listening to music subjective attributes such as the speaker s presentation style type of humor or the production quality could influence the listener s preference but are hard to discern from a text description in the video domain movie trailers allow a viewer to preview some content and make a subjective decision to watch a film the frequent release schedule for podcasts would make the production of such trailers for each episode impractical audio summaries have shown promise in improving the performance of spoken document search algorithms we propose a method to create short podcast audio summaries in an automated manner such summaries could inform the listener about the topics of the podcast as well as subjective attributes like presentation style and production quality podcasts present a unique set of challenges for an audio based summarization algorithm for example podcasts usually focus on spoken word content and often contain overlapping speech from multiple speakers free form speech audio effects background music and advertisements a supervised learning algorithm operating in the audio domain would have to identify the nature of an audio segment before being able to judge its importance this would require a large amount of training data manually annotated by listening to the audio in multiple passes which is a difficult and time consuming process however as podcasts largely contain spoken word content summarization can also be performed in the text domain on the transcript of an episode in this work we present our summarization podsumm method to obtain podcast audio summaries guided by the text domain podsumm works by first transcribing the spoken content of a podcast then identifying important sentences in the transcript and finally stitching together the respective audio segments we introduce a protocol and create an internal dataset specific to this task in summary we introduce the both authors contributed equally to this research concept of podcast audio summaries to aid in content discovery these summaries allow a listener to rapidly preview an episode before investing time in listening to the entire episode vartakavi and garg related work text summarization neural models consider this task as a classification problem where a neural encoder creates a latent representation of the sentences followed by a classifier scoring the sentences on their importance towards creating a summary with the rising popularity of deep neural networks and transformers pre trained language models particularly transformer models such as bert have shown promise in a wide range of nlp tasks bert can express the semantics of a document and obtain a sentence level representation recent approaches to text summarization like presumm and matchsum leverage bert and achieve state of the art performance on many benchmark datasets these present a promising avenue for further development and expansion to other application domains speech summarization speech summarization requires directly processing audio streams and providing snippets to create a combined audio summary prior solutions to this task have modelled this problem as a feature classification problem speech text co training problem and graph clustering problem neural extractive summarization such as reinforcement learning hierarchical modeling and sequence to sequence modeling have shown promising results though on a limited variety of data automated speech summarization has many open research problems such as multi party speech spontaneous speech handling disfluencies and more podcast summarization there has been limited research on automated methods for podcast audio summarization the diversity and narrative nature of podcasts with spontaneous speech music audio effects and advertisements may present challenges for existing speech summarization methods to address this issue we pose the podcast audio summarization problem as multi modal data summarization where we create an audio summary of a podcast with guidance from the text domain our method podsumm architecture the podsumm method comprises a sequence of steps starting with the original audio stream and resulting in an audio summary obtained as an output figure the first stage of the process is automatic speech recognition asr which generates a transcript we then process the text to segment each podcast transcript into sentences subsequently we use a fine tuned text summarization model to select important sentences for inclusion in the final summary we discuss each stage in detail below automatic speech recognition asr methods perform the task of speech to text transcription they handle complexities related to varied accents prosody and acoustic features and speaker demographics the quality of asr transcriptions varies significantly and depends on the underlying training data we leveraged a publicly available podsumm podcast audio summarization fig block diagram of the podsumm method and its modules off the shelf solution aws transcribe which allowed us to limit errors and focus on other core modules our pipeline text processing the audio transcripts obtained in section above contain tuples of text for individual words or punctuation marks the start and end timestamps from the audio and a confidence score for the text prediction we use spacy to segment the text into sentences and their corresponding start and end times in the audio additionally we force a sentence break where a pause of over seconds between words occurs this helps us to better handle the cases where the asr method missed a punctuation mark which frequently occurs when music is played between speech segments text summary generation we then build text summaries by selecting appropriate sentences from the transcript by leveraging advances in the field of extractive text summarization we choose the presumm model which builds upon bert to obtain a sentence level encoding and stacks inter sentence transformer layers to capture document level features for summarization we find that a presumm model pre trained on the cnn dailymail dataset does not produce adequate summaries for podcasts motivated by the lack of research datasets for this task we created a dataset to further fine tune the model for podcasts described in section the extractive presumm model performs summarization on a document with sentences sentm by assigning a score yi to each senti indicating exclusion from or inclusion in the summary the model is trained using a binary classification entropy loss to capture difference in prediction yi and ground truth label yi amazon com io usage linguistic audio generation the predictions of the text summarization model include the sentence indices and respective scores using the stored sentence offsets the audio representing the selected sentences are stitched together to obtain vartakavi and garg an audio summary dataset creation to address the lack of datasets for the task of podcast summarization we curate a dataset to support the development and evaluation of our method we selected unique podcast series from different genres selecting on average episodes per series the dataset contains a total of hours of podcasts with an average duration of minutes per episode we built an annotation tool that presented the annotator with a sequence of sentences from the transcript of the episode as well as the metadata from the podcast feed including the original audio of the episode each sentence was paired with the respective audio segment derived using the offsets of each segment additionally the annotation tool dynamically generated audio and text summaries based on annotator s selection enabling them to verify their choices the annotator was instructed to follow the protocol outlined below read the provider submitted description if available or listen to the audio of the podcast episode to understand the context and core message select the set of sentences that represent the summary of the podcast the raters were requested to select continuous sequences of sentences where possible to minimize cuts in the audio while keeping the total summary listen to the newly created sentence summary and repeat the above steps if necessary submit the annotations length within seconds when a satisfactory summary is obtained the resulting annotations include a set of sentence indices selected by the annotator as the most suitable candidates to create a summary due to resource limitations each episode was annotated by a single annotator due to which we are unable to compute the inter annotator agreement discarding some outliers we find that it took minutes seconds minutes seconds to annotate a single episode we collected a total of episodes with an average of selected sentences per summary model training we begin with a presumm model pre trained on the cnn dailymail dataset for steps provided by the authors who report strong performance l we then fine tune the model on our podcast dataset for steps as described in beyond we noticed overfitting on our training set the pre trained model allows position embeddings of length which we deemed sufficient for our application as the annotations in our dataset were contained within the first tokens even for longer episodes model checkpoints were saved and evaluated on the test set for every steps the best performing model checkpoint was used for ablation experiments and to report system performance for predicting summaries on new unseen data we obtain the predicted scores for each sentence subsequently top n sentences are selected from the rank ordered candidates to create the final summary com nlpyang presumm podsumm podcast audio summarization evaluation metrics n l cross validation experiment was repeated for each fold data augmentation we report the precision recall and f measure for the rouge l scores the metrics were selected to measure the ability of the model to produce summaries with overlapping words in comparison to the reference recall the prediction precision and average f measure the n in the rouge n metric signifies the unigram word overlap bigram consecutive word overlap and longest common sequence overlap our current dataset consists of a total of podcast episodes this number is small in comparison to datasets such as cnn dailymail data label pairs to mitigate the effect of sampling bias we report the mean and standard deviation of the rouge metrics from a k fold cross validation experiment the model was trained on the training split or samples and performance reported on the test split or episodes and the process we perform data augmentation to compensate for the relatively small size of our dataset and increase the generalization ability of the model we observe that most previews and advertisements which should not be included in a summary are similar across podcasts episodes we here describe a method to automatically find segments of repetitive content and our augmentation procedure we first find the indices of the sentences in the transcript that also occur in other episodes across our dataset e we then clean up the indices to merge any near by indices with into one large set and to remove any outliers all such repetitive content segments are stored for use in augmentations to generate an augmented output if an episode has repetitive content we replace else we prepend the transcript with a randomly selected repetitive segment to create a new data sample for each transcript we add new samples for the total augmented data size of samples for the training set for each fold ablation studies effect of number of candidate sentences similar to presumm we select the top n sentences with the highest scores as our predictions we study the effect of varying the number of sentences selected to represent the summary from the rank ordered candidates in the model prediction in our experiment n was varied and the l scores are reported effect of data augmentation the data augmentation applied during training alters the repetitive content preceding the sentences relevant to the summary to test the effect of the data augmentation scheme on the model performance we performed a fine tuning experiment with and without data augmentation and report the system performance metrics results we summarize our results and ablation studies in table as outlined in section we report the mean and standard deviation of the f measure for the metrics over the fold cross validation experiment similar to prior work we use a simple baseline lead n where we select the n leading sentences from the document as a summary com abisee cnn dailymail vartakavi and garg metric baseline fine tuning presumm no ft k presumm ft k presumm ft aug k ablation k sentences presumm presumm presumm presumm rouge l table results for the baseline fold cross validation experiment and ablation experiments for the presumm method the f measure for l metrics for pre trained presumm model and the model fine tuned with podsumm dataset reported on the test set for each fold summary statistics for each metric reported as mean std dev over the folds we find that performs well only slightly worse than a presumm model pre trained on the cnn dailymail dataset with no fine tuning after fine tuning on our dataset presumm ft k we find significant improvements in f measure for all l metrics over the baseline and the model with no fine tuning the model with augmentation presumm ft aug k further improves performance demonstrating that model performance on this task improves with even a small amount of task specific data augmentation in the ablation study we find that selecting the top sentences produced the best results compared to or we display the distribution of sentence indices in figure the ground truth data distribution indicates that the initial sentences with less related to the podcast summary task which is corroborated by the relatively high performance of the baseline relative to other lead or scores we also see that the model without fine tuning ft is biased to select sentences from the beginning of the document which is likely a property of the cnn dailymail dataset the distributions after fine tuning ft ft aug are closer to the ground truth distributions which are reflected in the metrics however the tails of these models still appear to follow the distribution model without fine tuning this highlights the need for further analysis and model development on a large dataset to account for all possible variations of the underlying data we present an example transcript along with the model predictions for presumm no ft k in table and presumm ft aug k in table the former model with no fine tuning selects a lot of sentences that are not relevant to the episode in table we see true positive sentences in green false positive sentences in blue and false negative in red sentences repeated content sentences in magenta of which were falsely predicted by the model in cyan this demonstrates that our method is able to correctly identify important sentences from the podcast transcription the transcript also shows some errors that have accumulated through the system eg variations in spoken words org mistranscribed as dot org incorrect sentence segmentation between it is p m and on errors like these can complicate any downstream text processing for example a reader may only identify false positive sentences in the above example whereas the system identified due to incorrect sentence segmentation podsumm podcast audio summarization fig selected sentence index vs the normalized count over all sentences in dataset in the ground truth predictions from presumm no ft fine tuned presumm ft and fine tuned presumm with aug hey there real quick before we start the show california we are coming your way for a live show next month on february we are super excited to finally get to come to southern california we will be in oaks with k c l you talking about the race and more to get your tickets head over to npr prisons dot org oh and if you re in iowa we have a show there tomorrow night friday night and there are still a few tickets available okay here s the show hey there it s the npr politics podcast it is p m on january i m tamara keith i cover the white house i m aisha roscoe i also cover the white house and i m susan davis i cover congress senate will convene as a court of impeachment today the senate impeachment trial is continuing with more questions and answers senators asking questions the house managers and the president s legal team answering those questions and in fact as we take this the q and a is still going on so things could happen that s why we do a time stamp um aisha i m wondering what stood out to you about today well a lot of what the questions seem to be about was getting at this idea of is there a limit to what a president can do to get re elected because one of the president s lawyers representing him alan dershowitz made this argument that most presidents think their re election is in the public interest and therefore if they take actions to kind of help their reelection as long as it s not illegal it s ok and it really seemed like the senators were probing the limits of how far that argument can go on table presumm no ft k output with correct predictions in green false negatives in red and false positive sentences in blue sentences detected as repetitive content magenta and also falsely predicted by the model cyan discussion in this work we proposed podsumm a method to automatically generate audio summaries of podcasts via guidance from the text domain the method involves transcribing the audio followed by some text processing and text summarization an audio summary is then generated by stitching the audio segments that correspond to the sentences selected by the text summarization the resulting model fine tuned on our dataset performed better than a lead n baseline and a model trained on the cnn dailymail dataset as our method contains a sequence of steps the performance of each module directly influences the final produced audio summaries in this paper we heavily leverage prior work in different fields we believe custom modules would bring significant advantages for example a sentence segmentation model that is robust to transcription errors or missing punctuation due to background music would allow us to leverage cheaper less accurate asr solutions further research is needed to develop and understand the effects of the individual modules specific to podcasts truthno ftftft aug vartakavi and garg hey there real quick before we start the show california we are coming your way for a live show next month on february we are super excited to finally get to come to southern california we will be in oaks with k c l you talking about the race and more to get your tickets head over to npr prisons dot org oh and if you re in iowa we have a show there tomorrow night friday night and there are still a few tickets available okay here s the show hey there it s the npr politics podcast it is p m on january i m tamara keith i cover the white house i m aisha roscoe i also cover the white house and i m susan davis i cover congress senate will convene as a court of impeachment today the senate impeachment trial is continuing with more questions and answers senators asking questions the house managers and the president s legal team answering those questions and in fact as we take this the q and a is still going on so things could happen that s why we do a time stamp um aisha i m wondering what stood out to you about today well a lot of what the questions seem to be about was getting at this idea of is there a limit to what a president can do to get re elected because one of the president s lawyers representing him alan dershowitz made this argument that most presidents think their re election is in the public interest and therefore if they take actions to kind of help their reelection as long as it s not illegal it s ok and it really seemed like the senators were probing the limits of how far that argument can go on at one point there was a question from senator susan collins from maine a republican and and a few other republicans including senators crepeau blunt and rubio and remember all of the questions are submitted in writing to the chief justice who then reads them aloud table presumm ft aug k output with correct predictions in green false negatives in red and false positive sentences in blue sentences detected as repetitive content magenta and also falsely predicted by the model cyan although our proposed method showed improved performance after fine tuning on our dataset we recognize that its smaller size may restrict the generalization ability of the model on unseen data manual annotation of a large corpus of podcast data for this task is prohibitively expensive but techniques like data augmentation could alleviate these to some extent conclusion acknowledgments media technology lab at gracenote references we present a novel method to create audio summaries for podcasts via guidance from the text domain and discuss the strengths and limitations this work establishes the proof of working principle and sets direction for future development into a fully learned and automated method for podcast speech summarization we look forward to newer methods emerging from the research community leading to an improved listener experience the authors thank josh morris for his counsel chinting ko for his guidance on asr joseph renner jeff scott gannon gesiriech and zafar rafi for their feedback on the manuscript and the contributions of the our team members at the jacob devlin ming wei chang kenton lee and kristina toutanova bert pre training of deep bidirectional transformers for language understanding in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies volume long and short papers mattia antonino di gangi robert enyedi alessandra brusadin and marcello federico robust neural machine translation for clean and noisy speech transcripts arxiv preprint sadaoki furui t kikuichi yousuke shinnaka and chiori hori speech to speech and speech to text summarization in first international workshop on language understanding and agents for real world interaction citeseer nikhil garg benoit favre korbinian reidhammer and dilek hakkani tr clusterrank a graph based method for meeting summarization in tenth annual conference of the international speech communication association podsumm podcast audio summarization awni y hannun carl case jared casper bryan catanzaro greg diamos erich elsen ryan prenger sanjeev satheesh shubho sengupta adam coates and andrew y ng deep speech scaling up end to end speech recognition arxiv karl moritz hermann tom koisk edward grefenstette lasse espeholt will kay mustafa suleyman and phil blunsom teaching machines to read and comprehend in proceedings of the international conference on neural information processing systems volume montreal canada mit press cambridge ma usa yaser keneshloo tian shi naren ramakrishnan and chandan k reddy deep reinforcement learning for sequence to sequence models ieee transactions on neural networks and learning systems chin yew lin rouge a package for automatic evaluation of summaries in text summarization branches out association for computational linguistics barcelona spain aclweb org anthology tzu en liu shih hung liu and berlin chen a hierarchical neural summarization framework for spoken documents in icassp ieee international conference on acoustics speech and signal processing icassp ieee yang liu and mirella lapata text summarization with pretrained encoders in proceedings of the conference on empirical methods in natural language processing and the international joint conference on natural language processing emnlp ijcnlp ramesh nallapati feifei zhai and bowen zhou summarunner a recurrent neural network based sequence model for extractive summarization of documents in proceedings of the thirty first aaai conference on artificial intelligence san francisco california usa aaai press abigail see peter j liu and christopher d manning get to the point summarization with pointer generator networks corr org damiano spina johanne r trippas lawrence cavedon and mark sanderson extracting audio summaries to support effective spoken document search journal of the association for information science and technology ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser and illia polosukhin attention is all you need in advances in neural information processing systems yuxiang wu and baotian hu learning to extract coherent summary via deep reinforcement learning in thirty second aaai conference on shasha xie hui lin and yang liu semi supervised extractive speech summarization via co training algorithm in eleventh annual conference artificial intelligence of the international speech communication association xingxing zhang mirella lapata furu wei and ming zhou neural latent extractive document summarization in proceedings of the conference on empirical methods in natural language processing ming zhong pengfei liu yiran chen danqing wang xipeng qiu and xuanjing huang extractive summarization as text matching arxiv preprint
