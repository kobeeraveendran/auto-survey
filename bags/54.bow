g u a l c s c v v i x r a better summarization evaluation with word embeddings for rouge jun ping ng bloomberg new york usa viktoria abrecht bloomberg new york usa abstract rouge is a widely adopted automatic evaluation measure for text tion while it has been shown to late well with human judgements it is ased towards surface lexical similarities this makes it unsuitable for the tion of abstractive summarization or maries with substantial paraphrasing we study the effectiveness of word dings to overcome this disadvantage of rouge specically instead of ing lexical overlaps word embeddings are used to compute the semantic similarity of the words used in summaries instead our experimental results show that our posal is able to achieve better correlations with human judgements when measured with the spearman and kendall rank efcients introduction automatic text summarization is a rich eld of search for example shared task evaluation shops for summarization were held for more than a decade in the document understanding ference duc and subsequently the text ysis conference tac an important element of these shared tasks is the evaluation of ing systems initially manual evaluation was ried out where human judges were tasked to sess the quality of automatically generated maries however in an effort to make tion more scaleable the automatic sure lin was introduced in rouge determines the quality of an automatic summary through comparing overlapping units such as n grams word sequences and word pairs with human written summaries oriented understudy of gisting evaluation rouge is not perfect however two problems with rouge are that it favors lexical larities between generated summaries and model summaries which makes it unsuitable to evaluate abstractive summarization or summaries with a signicant amount of paraphrasing and it does not make any provision to cater for the readability or uency of the generated summaries in such as automatic of peers summaries tac there has been on going efforts summarization to prove on the automatically tion measures aesop evaluating dang and owczarzak task owczarzak owczarzak and dang however rouge remains as one of the most popular metric of choice as it has repeatedly been shown to correlate very well with human judgements lin over and yen owczarzak and dang in this work we describe our efforts to tackle the rst problem of rouge that we have tied above its bias towards lexical ties we propose to do this by making use of word embeddings bengio et al word dings refer to the mapping of words into a dimensional vector space we can construct the mapping such that the distance between two word projections in the vector space corresponds to the semantic similarity between the two words by corporating these word embeddings into rouge we can overcome its bias towards lexical ities and instead make comparisons based on the semantics of words sequences we believe that this will result in better correlations with human assessments and avoid situations where two word sequences share similar meanings but get unfairly penalized by rouge due to differences in graphic representations as an example consider these two phrases it is raining heavily and it is pouring if we are performing a lexical string match as rouge does there is nothing in common between the terms raining heavily and pouring ever these two phrases mean the same thing if one of the phrases was part of a human written summary while the other was output by an matic summarization system we want to be able to reward the automatic system accordingly in our experiments we show that word dings indeed give us better correlations with man judgements when measured with the man and kendall rank coefcient this is a icant and exciting result beyond just improving the evaluation prowess of rouge it has the tential to expand the applicability of rouge to abstractive summmarization as well related work as we have while rouge is widely used there is a signicant body of noted earlier work studying the evaluation of automatic text summarization systems a good survey of many of these measures has been written by steinberger and jezek we will thus not tempt to go through every measure here but rather highlight the more signicant efforts in this area elements hovy al has also been used be in the duc tac shared task evaluations it is an automatic method which evaluates the content completeness of a generated summary by breaking up sentences into smaller more granular units of information referred to as basic elements rouge besides basic the pyramid method originally proposed by staple in is another passonneau et al duc tac however is a semi automated it method where signicant human intervention is required to identify units of information called summary content units scus and then to map content within generated summaries recently however an to these scus this method has been mated variant of posed passonneau et al in this variant word embeddings are used as we are proposing in this paper to map text content within generated summaries to scus however the scus still need to be manually identied limiting this variant s scalability and applicability many systems have also been proposed in the aesop task in tac from to the top system ported in owczarzak and dang for example meng giannakopoulos and karkaletsis is a graph based system which scores summaries based on the similarity between the graph tures of the generated summaries and model maries methodology let us now describe our proposal to integrate word embeddings into rouge in greater detail to start off we will rst describe the word embeddings that we intend to adopt a word embedding is really a function w where w w rn and w is a word or word sequence for our purpose we want w to map two words and such that their respective projections are closer to each other if the words are mantically similar and further apart if they are not mikolov et al describe one such ant called which gives us this sired we will thus be making use of we will now explain how word dings can be incorporated into rouge there are several variants of rouge of which and rouge have often been used this is because they have been found to correlate well with human lin over and yen judgements owczarzak and dang sures the amount of unigram overlap between model summaries and automatic summaries and measures the amount of bigram overlap rouge measures the amount of overlap of skip bigrams which are pairs of words in the same order as they appear in a sentence in each of these variants overlap is computed by matching the lexical form of the words within the target pieces of text formally we can dene this as a similarity function fr such that if otherwise where and are the words could be unigrams or n grams being compared in our which we will refer to as rouge we we dene a new similarity function effectiveness of the learnt mapping is such that we can now compute analogies such as king man woman queen fw e such that fw if are oov otherwise where and are the words being compared and vx w wx oov here means a situation where we encounter a word w that our word bedding function w returns no vector for for the purpose of this work we make use of a set of million pre trained vector trained from part of google s news dataset for w reducing oov terms for n grams with our formulation for fw e we are able to compute variants of rouge we that correspond to those of rouge including rouge and rouge we however despite the large number of vector mappings that we have there will still be a large number of oov terms in the case of rouge and rouge we where the basic units of comparison are bigrams to solve this problem we can compose dividual word embeddings together we follow the simple multiplicative approach described by mitchell and lapata where individual tors of constituent tokens are multiplied together to produce the vector for a n gram w w w w wn where w is a n gram composed of individual word tokens w wn multiplication tween two vectors w wi vik and w wj vjk in this case is dened as vik vjk experiments dataset and metrics for our experiments we make use of the dataset used in aesop owczarzak and dang and the corresponding correlation measures for clarity let us rst describe the dataset used in the main tac summarization task the main summarization dataset consists of topics each of which is associated with a set of ments there are also four human curated model summaries for each of these topics each of the participating systems generated a summary for each of these topics these automatically ated summaries together with the human curated model summaries dataset for aesop then form the basis of the this as reviewed in section semi automated measure described in to assess how effective an automatic evaluation system is the system is rst tasked to assign a score for each of the summaries generated by all of the participating systems each of these maries would also have been assessed by human judges using these three key metrics pyramid is a passonneau et al responsiveness human judges are tasked to evaluate how well a summary adheres to the mation requested as well as the linguistic quality of the generated summary readability human judges give their judgement on how uent and readable a summary is the evaluation system s scores are then tested to see how well they correlate with the human ments the correlation is evaluated with a set of three metrics including pearson correlation p spearman rank coefcient s and kendall rank coefcient k results we evaluate three different variants of our proposal rouge rouge and rouge we against their corresponding variants of rouge rouge it is worth noting here that in sop in rouge was shown to late very well with human judgements especially for pyramid and responsiveness and out performs most of the participating systems tables and show the correlation of the scores produced by each variant of rouge we with human assessed scores for pyramid siveness and readability respectively the tables also show the correlations achieved by and rouge the best result for each column has been bolded for readability rouge is observed to correlate very well with the pyramid responsiveness and ability scores when measured with the man and kendall rank correlation however rouge correlates better with human ments for the pearson correlation the key ence between the pearson correlation and man kendall rank correlation is that the former assumes that the variables being tested are mally distributed it also further assumes that the measure rouge rouge rouge we rouge p s k measure rouge rouge rouge we rouge p s k table correlation with pyramid scores sured with pearson r p spearman s and kendall k coefcients table correlation with readability scores sured with pearson r p spearman s and kendall k coefcients measure rouge rouge rouge we rouge p s k table correlation with responsiveness scores measured with pearson r p spearman s and kendall k coefcients variables are linearly related to each other the ter two measures are however non parametric and make no assumptions about the distribution of the variables being tested we argue that the tions made by the pearson correlation may be too constraining given that any two independent uation systems may not exhibit linearity looking at the two bigram based variants rouge and rouge we we serve that rouge improves on most of the time regardless of the correlation ric used this lends further support to our proposal to use word embeddings with rouge however rouge we is only better than rouge when evaluating readability it does consistently worse than rouge for pyramid and responsiveness the reason for this is likely due to how we have chosen to compose unigram word vectors into bigram equivalents the tiplicative approach that we have taken worked better for rouge which looks at ous bigrams these are easier to interpret tically than skip bigrams the target of we the latter by nature of their tion loses some of the semantic meaning attached to each word and thus may not be as amenable to the linear composition of word vectors owczarzak and dang reports only the results of the top systems in aesop in terms of pearson s correlation to get a more plete picture of the usefulness of our proposal it will be instructive to also compare it against the other top systems in aesop when sured with the spearman kendall correlations we show in table the top three systems which correlate best with the pyramid score when measured with the spearman rank coefcient c s kumar et al is a based system which assess summaries based on differences in word co locations between ated summaries and model summaries be hm baseline by the organizers of the aesop task is the be system hovy al where sic elements are identied using a head modier criterion on parse results from minipar lastly oliveira is also a graph based system which frames the summary evaluation problem as a maximum bipartite graph matching problem measure rouge c s be hm s k table correlation with pyramid scores of top systems in aesop measured with the spearman s and kendall k coefcients we see that rouge displays better relations with pyramid scores than the top system in aesop c s when sured with the spearman coefcient the latter does slightly better however for the kendall cient this observation further validates that our proposal is an effective enhancement to rouge references conclusion we proposed an enhancement to the lar rouge metric in this work rouge we rouge is biased towards identifying lexical ilarity when assessing the quality of a generated summary we improve on this by ing the use of word embeddings this ment allows us to go beyond surface lexicographic matches and capture instead the semantic ities between words used in a generated summary and a human written model summary menting on the tac aesop dataset we show that this proposal exhibits very good correlations with human assessments measured with the man and kendall rank coefcients in particular rouge outperforms leading state of art systems consistently looking ahead we want to continue building on this work one area to improve on is the use of a more inclusive evaluation dataset the aesop summaries that we have used in our periments are drawn from systems participating in the tac summarization task where there is a strong exhibited bias towards extractive rizers it will be helpful to enlarge this set of maries to include output from summarizers which carry out substantial paraphrasing li et al ng et al liu et al another immediate goal is to study the use of better compositional embedding models the generalization of unigram word embeddings into bigrams or phrases is still an open lem yin and schutze yu et al a better compositional embedding model than the one that we adopted in this work should help us improve the results achieved by bigram variants of rouge we especially rouge we this is important because earlier works have strated the value of using skip bigrams for marization evaluation an effective and accurate automatic evaluation measure will be a big boon to our quest for ter text summarization systems word embeddings add a promising dimension to summarization uation and we hope to expand on the work we have shared to further realize its potential bengio yoshua bengio rejean ducharme pascal vincent and christian janvin a ral probabilistic language model the journal of machine learning research dang and hoa trang dang and karolina owczarzak overview of the tac summarization track in proceedings of the text analysis conference tac paulo de oliveira catolicasc at tac in proceedings of the text analysis conference tac giannakopoulos and george annakopoulos and vangelis karkaletsis autosummeng and memog in evaluating guided in proceedings of the text analysis summaries conference tac hovy eduard hovy chin yew lin and liang zhou evaluating duc using in proceedings of the document basic elements understanding conference duc kumar niraj kumar kannan srinathan and vasudeva varma using unsupervised system with least linguistic features for aesop task in proceedings of the text analysis conference tac li et chen li fei liu fuliang weng and yang liu document summarization via guided sentence compression in proceedings of the conference on empirical methods in natural language processing emnlp pages chin yew lin looking for a few good metrics rouge and its evaluation in ing notes of the ntcir workshop meeting chin yew lin rouge a age for automatic evaluation of summaries in text summarization branches out proceedings of the workshop liu fei liu jeffrey flanigan sam son norman sadeh and noah smith toward abstractive summarization using semantic representations in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies naacl hlt pages mikolov et tomas mikolov wen tau yih and geoffrey zweig linguistic regularities in continuous space word representations in ceedings of the conference of the north american chapter of the association for computational guistics human language technologies hlt pages mitchell and jeff mitchell and mirella vector based models of lapata tic composition in proceedings of the nual meeting of the association for computational linguistics human language technologies acl pages ng jun ping ng yan chen min yen kan and zhoujun li exploiting timelines to enhance multi document summarization in ceedings of the annual meeting of the ciation for computational linguistics acl pages over and paul over and james yen an introduction to duc intrinsic evaluation of generic new text summarization systems in proceedings of the document understanding ference duc owczarzak and karolina owczarzak and hoa trang dang overview of the tac summarization track guided task and sop task in proceedings of the text analysis ference tac karolina owczarzak overview of the tac summarization track in proceedings of the text analysis conference tac passonneau rebecca j passonneau ani nenkova kathleen mckeown and sergey man applying the pyramid method in duc in proceedings of the document ing conference duc passonneau rebecca j passonneau emily chen weiwei guo and dolores perin mated pyramid scoring of summaries using butional semantics in proceedings of the nual meeting of the association for computational linguistics acl pages steinberger and josef and steinberger karel jezek evaluation measures for text summarization computing and informatics yin and wenpeng yin and hinrich schutze an exploration of embeddings for generalized phrases in proceedings of the acl student research workshop pages yu et mo yu matthew gormley and mark dredze factor based compositional ding models in proceedings of the nips deep learning and representation learning workshop
