r l c s c v v x r qurious question generation pretraining text generation shashi narayan google research com goncalo simoes google research com ji ma google research com hannah craighead google com abstract recent trends natural language processing pretraining shifted focus pretraining ne tuning approaches text generation focus agnostic approaches generalize guage modeling objective propose tion generation pretraining method better aligns text generation tives text generation models pretrained method better understanding essence input better language models target task evaluated text generation tasks abstractive rization answer focused question tion models result state art formances terms automatic metrics man evaluators found summaries generated questions natural cise informative introduction semi supervised song et al unsupervised pretrained encoder decoder models quickly standard text generation khandelwal et al dong et al rothe et al lewis et al following success pretraining methods popular natural language understanding nlu marks peters et al devlin et al radford et al yang et al text generation liu et al models focus task agnostic pretraining tasks generalize language modelling objective combining masked language model language modelling objective left right objective dong et al reconstructing text sequence corrupted input song et al sequence denoising autoencoder lewis et al models set new state art results wide variety text generation tasks summarization ryan mcdonald google research com answer passage mid march cold europe areas snow need winter clothes fun fun fun europe nice question temperature europe march middle figure example qa pair yahoo answers tence splitting sentence fusion rothe et al lewis et al paper investigate pretraining jective better tied challenges involved text generation specically understanding e identifying important content realization e generating text propose qurious question generation pretraining objective pretrains text generation models ate questions conditioning answer passage document key advantages method data question generation ily crawled abundantly community qa forms yahoo answers quora stack overow importantly ii text tors trained generate question answered document passage ture salient terms concepts expressed input learn aggregate paraphrase input figure shows example question pair pretraining reecting point checkpoints paper experiment based sequence sequence models compatible publicly available pretrained bert devlin et al roberta liu et al models pretrained question generation associated text question generation pretraining objective model agnostic improved pretraining objectives studied task agnostic yang et al lan et al multilingual pires et al domain targeted lee et al work closest baldini soares et al study task specic pretraining objectives relation extraction additionally alberti et al use question generation increase ing data qa task specic objectives specically question generation exploited generation tasks figure demonstrates benet training objective summarization quriousz zero shot variant qurious pretrained question generation supervision summarization generates questions ments centered reference summaries appears quriousz simulates tion experts terms selecting source tent relevant summary size netuning quriousz rization guide models focus salient content document generate summaries concise informative serve qurious generates summaries closer reference summaries ated use training question generation main contributions work fold propose question generation pretraining objective text generation ond demonstrate effectiveness method abstractive summarization ing new state art result extreme summarization task narayan et al experiment answer focused question eration task focusing datasets squad rajpurkar et al natural questions kwiatkowski et al demonstrate pretrained model generates questions natural informative terms tomatic human evaluations finally pirically demonstrate reciprocity tion generation pretraining objective text generation tasks makes models robust resource scenarios question generation pretraining qurious designed sequence sequence models aims learn improved tions text generation requires understanding realization opposed task agnostic pretraining objectives devlin et al gold beatle sir paul mccartney topped sunday times rich list musicians m fortune sir paul mccartney named britain s richest man sunday times rich list quriousz richest musician world qurious sir paul mccartney named richest man uk wealth totalling m according sunday times rich list gold pope francis africa rst time week visiting refugee camp slum mosque pope francis big issue pope s decision visit central african public middle rst trip nent quriousz pope francis talk trip kenya qurious pope francis head kenya rst visit africa taking ofce november figure analysis summarization models reference summary gold task agnostic trained model liu et al rothe et al pretrained question generation objective qurious zero shot variant quriousz data pretraining work lect million english question answer pairs community question answering resources stackexchange total subdomains yahoo answers total mains zhidao baidu forums widely community tion answering zhang et al nakov et al nie et al particular low zhang et al data munity qa websites main differences zhang et al data nity qa websites train answer passage tion models use different set websites use question generation pretraining ensure quality posts select english answer question pairs itively rated user finally age lengths questions answers dataset tokens tokens respectively major advantage qurious large amounts pretraining data obtained free annotations grow long people ask answer questions internet real information seeking questions ically condense natural better suited summarization datasets squad rajpurkar et al questions naturally occurring contain high lexical syntactic overlap answer passage pretraining text generation models ply qurious sequence sequence tecture encoder decoder composed transformer layers vaswani et al experimented base large versions transformer layer base model encoder decoder layers hidden size lter size attention heads large model layers hidden size lter size attention heads ing input answers truncated kens length questions limited tokens allow encoder coder warm start transformer layer public bert devlin et al variant roberta liu et al checkpoints ing rothe et al share parameters encoder decoder models global batch size summary pairs standard cross entropy loss fine tuning text generation models ne tune model text generation tasks abstractive document summarization focused question generation abstractive summarization encoder takes document input generates summary output answer focused question generation earlier work duan et al subramanian et al nema et al focused factoid based question answering dataset squad rajpurkar et al unlike tion generation pretraining answer passage open ended necessarily rect response question follow nema et al use target answer span passage separator input generate specic question experiments results abstractive document summarization evaluate model bbc extreme marization xsum narayan et al models bertsum models qurious qurious qurious qurious quriousz quriousz rl table rouge scores extreme tion models block pretrained question generation text discussion l l uments dataset accompanied single sentence summaries high level abstractiveness generating requires document level inference abstraction phrasing dataset consists document summary training validation test pairs report scores lin hovy automatic evaluation rouge table main baseline transformer based model initialized public bert devlin et al checkpoint reported rothe et al report numbers second bert based transformer model bertsum liu lapata finally experimented liu et al checkpoint model signicantly improves state art bertsum following advantages qurious initializes checkpoint pretrains tion generation objective ne tuning extreme summarization perform ablation study initialize model roberta checkpoint roberta quriousz ne tuned treme summarization behaves question eration model takes document input generate question assesses close erated questions reference summary seen table question ation pretraining qurious proves rouge scores improvement points average rious roberta initialization forms counterpart models zhao et al nema et al qurious qurious squad nq rl table question generation results squad natural questions nq datasets model choose best performing variant table task rl rouge l provement consistent base large models qurious achieves new state art extreme summarization forming earlier model rothe et al average rouge points question generation pretraining estingly evates performance roberta initialized model summarization ing objective supplement recent training schemes dong et al song et al lewis et al summarization answer focused question generation question generation task evaluate models factoid based question answering datasets squad rajpurkar et al ural questions nq kwiatkowski et al squad use paragraph input passage sentence containing answer requires paragraph context order generate high quality tions total dataset composed k training examples k development examples nq use provided long answer input passage paragraphs lter list table based long answers lter yes questions questions answerable results training set k examples development set k examples best knowledge rst use nq dataset question eration task automatic evaluation choose best forming model table task report bleu papineni et al rouge l lin hovy scores results listed table table exhibits ilar pattern table qurious tently improve model performance et al nq dataset construct thetic question answer corpora train qa models squad nq squad qurious achieves substantial improvement previous state art nema et al nq pre training dataset consist real information seeking questions expect qurious perform better nq squad turns models trained nq achieve higher scores squad counterparts result suggests naturalness question important factor ing system performance human evaluations addition automatic evaluation rouge bleu evaluated system output eliciting human judgments study rization question generation conducted amazon mechanical turk platform best worst scaling labor intensive alternative paired comparisons louviere woodworth louviere et al summarization participants sented document summaries generated ve systems asked cide summary better order informativeness summary ture important information document uency summary written formed english question generation participants presented answer passage factoid answer questions generated systems asked decide question natural summary uent written formed english correct tion correct factoid answer given sage cases allowed ties dictions additionally ness allowed tie questions equally correct incorrect randomly selected documents xsum test set marization answer passage pairs question generation squad ral questions collected judgments different participants comparison der summaries randomized document order documents participant score system computed percentage times chosen best minus age times selected worst scores range worst best ple predictions human evaluations sented appendix qurious outperformed models nema et al qurious gold xsum quality qgen squad nq nat corr nat corr s e r o c s f l e g u o r qurious table human evaluation results summarization assessing summary quality answer focused tion generation assessing naturalness nat ness corr questions year corliss engine squad passage acme horizontal gine corliss steam engine patented answer qurious corliss steam engine patented prefered gold patented nq passage supper late century mural painting leonardo da vinci answer leonardo da vinci qurious painted supper louvre gold painted world famous painting supper prefered figure qurious predictions squad nq datasets interestingly performed better tasks human authored summaries questions single exception correctness assessment questions nq dataset carried pairwise comparisons models assess system differences statistically signicant way anova posthoc tukey hsd tests summarization signicantly different qurious gold squad nema et al signicantly different systems naturalness correctness signicantly different qurious correctness nq signicantly different rious naturalness gold ness differences statistically nicant difference performance qurious squad nq stem datasets created squad human annotators started passage wrote questions times resorting paraphrasing copying nq dataset creation process volved started questions making ural harder model learn copying percentage training data log scale figure question generation pretraining sample cient summarization consequently qurious appears hallucinate ne tuned nq ne tuned squad examples figure regardless differences qurious gold statistically signicant sample efciency experiments finally evaluated qurious performs low resource scenarios performing sample ciency experiments focus extreme summarization task test model trained subset supervised ne tuning data figure presents results interesting qurious rious outperform low resource settings suggesting content selection driven pretraining objectives important task agnostic masking jectives interesting rious model signicantly outperforms training data consumed point performance converges qurious suggests optimal conguration pretraining objectives include content selection question ation knowledge based language model teria intuitively makes sense good mary rich knowledge content der know select content realize accurately conclusion paper proposed question generation pretraining objective text generation evaluated summarization answer focused question generation tasks model generated summaries questions respectively natural informative terms matic human evaluations future like explore question generation pretraining objective benecial text generation language understanding tasks references chris alberti daniel andor emily pitler jacob vlin michael collins synthetic qa pora generation roundtrip consistency ceedings annual meeting ciation computational linguistics pages florence italy association tional linguistics livio baldini soares nicholas fitzgerald jeffrey ling tom kwiatkowski matching blanks distributional similarity relation proceedings annual meeting ing association computational linguistics pages florence italy jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language proceedings conference standing north american chapter association computational linguistics human language technologies volume long short papers pages minneapolis minnesota ation computational linguistics li dong nan yang wenhui wang furu wei aodong liu yu wang jianfeng gao ming zhou hsiao wuen hon unied language model pre training natural language ing generation corr nan duan duyu tang peng chen ming zhou question generation question answering proceedings conference cal methods natural language processing pages copenhagen denmark association computational linguistics urvashi khandelwal kevin clark dan jurafsky lukasz kaiser sample efcient text marization single pre trained transformer corr tom kwiatkowski jennimaria palomaki olivia eld michael collins ankur parikh chris berti danielle epstein illia polosukhin jacob vlin kenton lee kristina toutanova llion jones matthew kelcey ming wei chang andrew m dai jakob uszkoreit quoc le slav petrov natural questions benchmark question swering research transactions association computational linguistics tom kwiatkowski jennimaria palomaki olivia eld michael collins ankur parikh chris alberti danielle epstein illia polosukhin matthew kelcey jacob devlin kenton lee kristina n toutanova llion jones ming wei chang andrew dai jakob uszkoreit quoc le slav petrov ral questions benchmark question answering research transactions association tational linguistics zhenzhong lan mingda chen sebastian goodman kevin gimpel piyush sharma radu soricut albert lite bert self supervised corr learning language representations jinhyuk lee wonjin yoon sungdong kim donghyeon kim sunkyu kim chan ho jaewoo kang biobert pre trained biomedical biomedical text mining bioinformatics language representation model mike lewis yinhan liu naman goyal jan ghazvininejad abdelrahman mohamed omer levy ves stoyanov luke zettlemoyer bart denoising sequence sequence pre training natural language generation translation comprehension corr chin yew lin eduard hovy automatic uation summaries n gram co occurrence statistics proceedings human guage technology conference north chapter association computational linguistics pages yang liu mirella lapata text proceedings tion pretrained encoders conference empirical methods ural language processing international joint conference natural language processing emnlp ijcnlp pages hong kong china association computational linguistics yinhan liu myle ott naman goyal jingfei du dar joshi danqi chen omer levy mike lewis luke zettlemoyer veselin stoyanov roberta robustly optimized bert pretraining approach corr jordan j louviere terry n flynn anthony fred john marley best worst scaling ory methods applications cambridge sity press jordan j louviere george g woodworth best worst scaling model largest ence judgments university alberta working preslav nakov doris hoogeveen llus alessandro moschitti hamdy mubarak timothy baldwin karin verspoor task community question answering ings international workshop semantic evaluation pages ver canada association computational tics shashi narayan shay b cohen mirella lapata nt details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing pages brussels gium association computational linguistics sascha rothe shashi narayan aliaksei severyn leveraging pre trained checkpoints quence generation tasks corr kaitao song xu tan tao qin jianfeng lu yan liu mass masked sequence quence pre training language generation ceedings international conference machine learning icml sandeep subramanian tong wang xingdi yuan saizheng zhang adam trischler yoshua gio neural models key phrase tion question generation proceedings workshop machine reading question ing pages melbourne australia tion computational linguistics ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez lukasz kaiser illia polosukhin attention need advances neural information cessing systems pages zhilin yang zihang dai yiming yang jaime g bonell ruslan salakhutdinov quoc v le xlnet generalized autoregressive pretraining language understanding corr kai zhang wei wu haocheng wu zhoujun li ming zhou question retrieval high ity answers community question answering proceedings acm international ence conference information knowledge management page association ing machinery yao zhao xiaochuan ni yuanyuan ding qifa ke paragraph level neural question ation maxout pointer gated self attention proceedings conference networks empirical methods natural language ing pages brussels belgium tion computational linguistics summarization outputs figure shows examples bbc articles extreme summaries b squad outputs figure shows examples squad input sages answer spans questions generated preksha nema akash kumar mohankumar mitesh m khapra balaji vasan srinivasan balaraman ravindran let s ask rene network automatic question generation proceedings conference empirical methods natural language processing tional joint conference natural language cessing pages hong kong china sociation computational linguistics liqiang nie xiaochi wei dongxiang zhang xiang wang zhipeng gao yi yang driven answer selection community qa systems ieee transactions knowledge data neering kishore papineni salim roukos todd ward jing zhu bleu method automatic proceedings uation machine translation annual meeting association putational linguistics pages philadelphia pennsylvania usa association computational linguistics matthew peters mark neumann mohit iyyer matt gardner christopher clark kenton lee luke zettlemoyer deep contextualized word proceedings resentations ence north american chapter ation computational linguistics human guage technologies volume long papers pages new orleans louisiana association computational linguistics telmo pires eva schlinger dan garrette multilingual multilingual bert ceedings annual meeting tion computational linguistics association computational linguistics alec radford karthik narasimhan tim salimans ilya sutskever improving language standing generative pre training technical port openai alec radford jeff wu rewon child david luan dario amodei ilya sutskever language models unsupervised multitask learners cal report openai pranav rajpurkar robin jia percy liang know nt know unanswerable proceedings tions squad nual meeting association computational linguistics volume short papers pages melbourne australia association tational linguistics pranav rajpurkar jian zhang konstantin lopyrev percy liang squad questions machine comprehension text proceedings conference empirical methods ral language processing pages austin texas association computational linguistics gold beatle sir paul mccartney topped sunday times rich list musicians m fortune document sir paul worth estimated m year enjoys signicant boost american heiress wife s m stake family s trucking business puts ahead nearest rival list andrew lloyd webber estimated worth m list published newspaper april richest people uk wealthiest ireland list puts irish band place m pop veteran sir elton john rolling stones frontman sir mick jagger follow fortunes thought worth m m respectively sir paul mccartney nancy shevell m rest article abbreviated richest people uk topped list richest people world qurious rolling stones named richest young band uk year sir paul mccartney named britain s richest man sunday times rich list qurious sir paul mccartney named richest man uk wealth talling m according sunday times rich list gold islanders skye demanded greater availability public toilets complaints visitors isle relieving outside document incidents reported scenic spots public conveniences lacking closed uig complaints raised local authority run toilets order beginning year highland council said seeking quotes repair work needed availability toilets skye raised previously highland council received complaints people urinating defecating outdoors stafn public toilets closed cost cutting council asked people toilets bid save money qurious highland council calling public complaints possible route people urinating skye highland council commissioned review public toilets public toilets skye qurious highland council seeking information problems public toilets skye figure example documents summarization model predictions passage terms scotland act elected assembly set edinburgh provided majority scottish electorate voted referendum held march represented total electorate scottish devolution referendum establish devolved scottish assembly failed answer failed nema et al happened scottish devolution referendum percentage vote ireland interpreted result voting scottish devolution referendum fail qurious scottish assembly edinburgh vote pass qurious result scottish devolution referendum gold trying establish devolved scottish assembly passage lacking historical connections middle east japan country dependent arab oil imported oil came middle east answer refnet percentage imported oil came japan japan national inuence oil japan s oil middle east come qurious middle east s oil imported japan middle east qurious japan s imported oil came middle east gold imported oil came middle east figure examples produced answer focused question generation models squad
