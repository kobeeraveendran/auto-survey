noname manuscript inserted editor attributed rhetorical structure grammar domain text summarization ruqian shengluan chuanqing yu chaoqun songmao received date accepted date abstract paper presents new approach automatic text rization combines domain oriented text analysis dota rhetorical structure theory rst grammar form attributed rhetorical ture grammar arsg non terminal symbols domain keywords called domain relations rhetorical relations serve attributes developed machine learning algorithms learning grammar corpus sample domain texts parsing algorithms learned grammar adjustable text summarization algorithms ating domain specic summaries practical experiments shown support domain knowledge drawback missing large training data set eectively compensated shown edge based approach powerful introducing grammar parsing rst inference engine checking feasibility model transfer introduced technique mapping grammar domain acceptable cost comprehensive comparison approach keywords attribute grammar attributed rhetorical structure grammar automatic text summarization grammar learning rhetorical structure theory ruqian lu ac cn key laboratory madis academy mathematics systems science chinese academy sciences beijing china key laboratory intelligent information processing institute computing technology chinese academy sciences beijing china university chinese academy sciences beijing china p e s l c s c v v x r introduction ruqian et al summarizing information knowledge nl texts relying nlu techniques challenging task information neers fortunately seen emerging development successful linguistic theories support analyzing understanding ing nl texts usually dierent approaches text summarization abstractive approach extractive counterpart works techniques machine learning proposed challenge diculties automatic text summarization machine learning hundreds thousands articles millions samples quantity quality sample articles learned aect capability eciency nal summarizer essentially problem information wants text summarization domain oriented huge set news articles general dicult access huge set articles specialized area worse domain oriented chinese texts summarization lack large sized open sources way diculty domain knowledge based approach approach lack scarce domain oriented training data compensated pre collected domain knowledge marizer organized domain knowledge limited set ing data produce good quality summarizers example lexical chain based methods leverage extern knowledge base kb construct cal chains use lexical cohesion features text summarization genest lapalme knowledge base identify patterns representation source documents generate summary text timofeyev choi rst derived syntactic structure mapped words cyc clustering mapped cyc concepts main topics identied identifying informative concepts forming summary sentences works use concepts representation knowledge use inference driving engine edge weakness aected result summarization paper propose knowledge based grammar supported rhetorical structure ory rst enriched approach automatic text summarization grammatical inference rst serve knowledge driving engine rhetorical structure theory rst formally proposed technique studying discourse structure natural language texts use rst automatic generation text summarization bit later daniel marcu nished rst work practical rst based discourse parsing text summarization central rst notion coherence rst understood theory text coherence basic components rst rhetorical relations rre short rre holds attributed rhetorical structure grammar domain text summarization sibling nodes common parent node child node nucleus n remaining satellite s possible children nuclei terms writer s purpose expressed n essential expressed s n comprehension independent s vice versa designed framework attribute grammar terminal non terminal symbols concepts given domain tion rule rule head abstraction consequence rule body rhetorical relations serve attributes non terminal domain concepts attributes include symbolic markers cues punctuations grammar non deterministic complexity natural language resentation domain texts fact probabilistic probability comes machine learning training texts grammar ented precedential parsing following sections provide details grammar learned set training articles applied summarizing domain texts automatically resulting model attributed rhetorical structure grammar arsg remaining paper organized follows section related works section introduces basic concepts approach arsg section grammar learning parser implementation tion arsg based text summarization optimization section presents experimental results section introduces technique model duction section compares approach representative approaches concluding remarks given section related works classical extractive summarization approaches rely textual features summary generation include rst based lexical chain based machine learning based methods rst approaches single document summarization got good sults generally rst construct rhetorical structure tree rtr select content based rtr core rst analysis based rules machine learning techniques deep learning networks marcu et al rst use rule based methods discourse analysis beneting information derived corpus study tree phrases lethanh et al syntactic textual operations erate best discourse structures toloski et al presented discourse menter slseg leading higher precision machine learning approaches utilize probabilistic models svm crf soricut marcu bilistic models spade sentence segmentation tree building extract features syntactic tree researches focused svm based discourse analysis regarded relation identication classication problem joty et al rst dynamic conditional random field dcrf sentence level discourse ruqian et al ysis following hilda recent advances deep learning led ther progress nlp ji eisenstein s representation learning based method state art method identifying relation types deep learning method poor interpretability hand current rst analyzers insucient practical use lexical chain exploits lexical cohesion related words mixed syntactic semantic approach widely text summarization nlp areas easy computation high eciency main approaches focuses use knowledge resources wordnet hirst st onge sented rst implementation based greedy disambiguation barzilay elhadad proposed new method word sense disambiguation wsd exponential complexity galley mckeown gained best results separating wsd lexical chain construction remus biemann latent dirichlet allocation lda topic model estimating tic closeness interpreting lexical chains clusters barzilay presented method scoring chains summary sentences ercan represented topics sets co located lexical chains nal summary graph based methods type classical methods text represented graph nodes edges correspond textual units sentences words similarity respectively according basic idea pagerank models rank select n sentences words nal summary utilizing statistical tools fattah proposed hybrid machine learning model based maximum entropy bayes svm model textual features improve summary content selection details large available datasets high performance computing devices deep neural networks shown great promise text summarization rush et al rst applied attention framework abstractive text summarization large scale datasets good performance advancements cheng lapata proposed deep tive model including hierarchical document reader attention based content extractor trained tested huge datasets dailymail duc attention directly applied decoder hidden units improvements include summarunner nallapati al neusum zhou et al achieved best result cnn dailymail dataset basic concepts attributed rhetorical structure grammar denition domain knowledge base dkb composed kinds concepts acting agents domain called green concepts ldc upenn edu nlpir nist gov projects duc data html attributed rhetorical structure grammar domain text summarization major inuence factors domain called red concepts concepts dynamics domain called blue concepts note kind domain concept dcp called domain relation dre kind concepts forms hierarchy ordered dierent levels domain concept necessary single word phrase example domain world economy trade wet green concepts asean usa developing countries brics imf bank china future option soared red concepts market price ination trade policy gdp pmi stock blue concepts stabilized rise turbulent gladness worry spurt denition lexical core lc short triple green red blue concepts parsing process arsg dened later appear nodes binary tree called basic tree blue concept root green red concepts leaves note dierence lexical core lexical chain ally lexical chain connects words similar meaning runs text nt reect meaning single sentence unit non locality clause level non conformity consisting unstructured single words incomplete information contrary lexical core sentence clause locality characterizing main relatedness conformity elements exactly properties dre include dre denotes change change way change state domain domains organized hierarchies child main inherits parent domain s dre addition paper use following text example mar parsing content summarization example text domain wet known china s foreign trade develops rapidly china s integration global value chain increasing china lower position international division labor especially high tech industries technology services exports china low end global value chain speed transformation upgrading foreign trade enhance status international division labor china important factor china s economic development future example clause extract lc china green foreign trade red develops rapidly blue ruqian et al attribute grammar invented based idea perfect grammar parsing based syntax semantics means parsing process bring information information called attributes attribute grammar parsing attributes calculated brought downwards upwards terminals root grammar called inherited synthesized attributes grammars attributes called l attributed s attributed grammars working tool text marization prefer s attributed grammar dierentiate syntactic attributes semantic attributes syntactic elements nl texts inuence arsg parsing e cues punctuations segmentations paragraph archies characterizes role dre rhetorical relation rre parsing performs functions rst value calculation transmission traditional attribute grammar e example second unique arsg helps guide parsing process shift reduce denition attributed rhetorical structure grammar arsg seven tuple rs dre dcp rre p p p f rs start symbol dre set domain relations dcp set domain concepts rre set rhetorical relations synthesized attributes attribute arithmetical logical function grammar symbols arguments p p set probabilistic tion rules production rules short attached attributes reasons reason propositional formula characterizing state parsing e values attributes cues production rule p p following form ae b d dre x y role attributes nucleus satellite ae set attribute equations lf reason n positive integer dynamically calculating probability taking rule reduction reasons lf resolving reduce reduce conicts parsing p f set precedence tuples tuple form b c slfa b c ps b c rlfa b c pr abc string neighboring grammar symbols parsing slfa b c short shift logic function reason shifting parser c rlfa b c short reduce logic function reason reducing b dre concept truth values slfa b c rlfa b c depend attribute values b c ps pr probabilities ps quintuples resolving shift reduce conicts attributed rhetorical structure grammar domain text summarization fig arsg parsing tree example c taken consideration means arsg symbol looking forward grammar called principle dened high complexity grammar learning consideration denition attributed rhetorical structure tree artr text d parsing tree d example fig shows artr representing parsing process text example line represent clauses text roots basic trees leaves artr basic tree tree representation lc th clause ci correspond non leaf nodes parsing tree domain relation dre attributes dre display rre attribute role attribute example node domain relation good devel attribute value elaboration attribute value s e satellite attributes useful solve representation problem solve parsing problem meaning short notations fig underlined parts example grammar learning parser implementation learn arsg set mannually parsed domain specic nl texts following procedure algorithm note terminology procedure pseudo program performed human programmer computer cooperatively algorithm program executed computer ruqian et al procedure prepare dkb h m mean human manually automatically resp h determine domain d knowledge m collect number e dictionaries domain d scan e dictionaries extract concepts use thesaurus enrich concept set hypernyms hyponyms nicknames use relations construct partial orderings types concepts form dkb describe learn arsg procedure constructs parsing tree sample text algorithm synthesizes parsing trees statistic methods generate wanted arsg learn arsg programmer start training set nl texts domain consideration simulate parsing process future grammar manually generate parsing tree form artr text future arsg constructed statistically evaluating set artrs sense procedure critical computer record dynamical context leads decision parsing step shift reduce conict resolved logical tion called reason case reduce reduce conict resolved attribute equations calculated attribute values passed way records future parsing process convenience implemented annotation system based java web techniques makes human programmer s ulation parsing process interactive way operations context changes recorded computer automatically programmer s work reduced help system note arsg probabilistic single sample artr probabilistic probability calculated synthesizing set artrs following procedure constructs artr stages rst stage preprocessing constructs basic trees including rst steps procedure second stage manual parsing constructs remaining main artr completed step production produced rst stage production rules p p shift reduce precedence rules p f generated second stage procedure construct artrs following procedure transform grammar component instances marked text t e text lcs extracted following lcs called t scan sentences match words dkb nd turn lc t basic tree blue concept gi root green resp red concepts ai bi leaves attributed rhetorical structure grammar domain text summarization determine attributes roots basic trees assign values attributes possible particular syntactic attributes like cue punctuation semantic attributes like rre role positive negative evaluations concepts assigned gi note syntactical attributes determined automatically semantic ones decided manually mode tree scan roots trees left right push rst roots stack loop elements stack assume b begin produce grammar component instances programmer decides shift action following tomatically push root c stack produce dence tuple b c slfa b c slfa b c reason shift return programmer decides reduce action new domain relation d target following automatically replace b d parent node new root produce b c rlfa b c rlfa b c reason reduction production instance ae lf reason taking rule reduction ae set attribute equations calculated reduction x y denote nucleus satellite particular cue attributes b uploaded d d s cue attributes role attributes x y uploaded d return end artr produced stop procedure example apply procedure example generating grammar ponent instances performing rst steps sequence lcs corresponding basic trees china foreign trade develops rapidly china integration global value chain increasing china international division labor lower position china global value chain low end china global value chain low end china transformation upgrading speed china international division labor enhance china economic development future important triples contain green red blue concept borrowed green blue concept borrows green concept technique arsg complement imperfect clauses underlined parts correspond short notations contained fig underlined words labeled abbreviation lc fig ruqian et al performing step attributes values list rst basic trees step procedure level wise loop rst steps use notation fig simplify representation nodes numbered letter k followed integer assume programmer decides reduce nodes node node node reduced node decisions lead building following precedence tuples production instances point point t rue t rue conjunction concession representation reason conjunction attribute propositions text parsing note number attached rule algorithm positive integer probability probability calculated parsing time follows programmer decides reduce string ab computer nds rules b right reason lf implied current parsing context current attribute values b ignores rules attributed rhetorical structure grammar domain text summarization algorithm following procedure assume construction artrs training texts nished grammar component instances generated learn arsg rs dre dcp rre p p p f input start symbol rs sets dre dcp rre dened output p p p f consider sets b c slfi nabc b c rlfj j mabc constructed procedure b c dre multi set construct precedence tuples b c slf ps b c rlf pr slfi slf rlfj rlf j ps nabc mabc mabc mabc let p f b c slf ps exists b c rlf pr exists precedence tuples ps pr removed pair dre concepts b investigate multi set rule instances generated procedure following form aei g means lfi true concept string ab reduced di xi yi equals n s s n n n n nucleus s satellite g total number rule instances right sides b reduction th rule set attribute equations aei calculated performed classify rules t sets essentially identical copies rules set identical reasons lfij allowed dierent aei t j ji ji g cluster set single rule count copy numbers reason lfi disjunction lfij aei ji t ji weight rule note components rules depending particular b omit indices ambiguity exists sets possible b learned p p grammar assume rules lf satised current parsing context indices k aek jk k g probability h th rule h reduction jk ruqian et al example apply algorithm generating grammar rules applying parsing assume procedure generates following rule instances q r q r s m q s m q s q r f v q r f u s m q r s u v attributes digits rule denote number identical copies rule instance combine fourth rule equal lf values m q s v result p p corresponding grammar rules total assume parser decides reduce ab current parsing context satises u s v s following rules applicable q r m q s v q r f u s probability b reduced r f q r v s u s satised following rules applicable q r s m q s v q r f v probability b reduced r f q r u s v s satised rules applicable possibility b reduced r r q f q r f q r need auxiliary information constituents sentence numbers reveal statistical data naming entities denote key persons institutions cues remind role sentence unit particular cues consideration cue phrases suciently accurate indicator rhetorical relations unfortunately text units cue phrases nt attributed rhetorical structure grammar domain text summarization algorithm arsg relation precedence parsing rough sketch preprocessing extract lc clause possible build basic tree lc initial string parsed string basic tree roots domain relations use probabilistic attributed relation precedence parsing technique parse initial string nal parsing tree artr generated use precedence tuples resolve shift reduce conict reduce use rule reason parameter rule head select group rules candidates candidates unique use rule numbers calculate probability selecting single rule resolve reduce reduce conict nally apply rule calculate attribute equations step fails try backtracking backtracking fails stop program parsing failed recognize rhetorical relations purely depending cue phrases combine cue phrases arsg relation precedence parsing improve parsing accuracy way dene cues syntactic marks attributes algorithms denition domain independent cues parts statement notify readers existence conrmation negation formation text topics example announce especially particular domain independent cues parsing process text stages rst stage forms text sequence lcs form basic trees corresponding initial attributes second stage real parsing process learned attributed rhetorical structure grammar cues taken consideration text parsing goal nd artr highest plausibility algorithm rough sketch arsg relation precedence parsing fail backtracking means rule applicable applicable rules failed arsg based text summarization developing idea arsg discussing use analyze summarize nl text rst present technique generating text summarization based arsg parsing dierent majority literature summarization technique purely based generated artr selecting important edus text directly generally text reporting commenting circumstance domain consists parts review current situation proposal corresponds ruqian et al algorithm nucleus centered artr summary generation given artr t number text edus number desired summary edus m h reduction rate summary t number outputted edus t output stop coroutine n coroutine n n coroutine s s sub algorithm n x leaf node output x m h t stop switch n switch n switch s x leaf node output x m h t stop switch s switch s switch root tree t mean nucleus resp satellite child nodes x subtrees artr generated note artr binary want generated summaries balanced review proposal matter edus extracted selection edus alternated subtrees subtrees going produce summary summarizer traverses artr nucleus preference way starts artr s n subtree root nucleus traverses artr s s subtree root satellite alternatively subtree t traverse order t s root t s n subtree t subtree t s n subtree t n subtrees leaf node lc traversed sentence unit represented outputted traversal stopped nodes traversed number edus outputted implementing balanced output edus declared apply coroutine technique coroutine consists nite set subroutines subroutine runs independent dierent subroutines run interleaving way switch instruction interrupts running subroutine switches control subroutine later control switched original subroutine continues running interrupted point theorem algorithm following properties terminates nite artr ergodic sense nodes scanned edus corresponding leaf nodes outputted terminated edus outputted node scanned edu edus corresponding left right subtrees outputted outputted twice alternatively attributed rhetorical structure grammar domain text summarization table current scale dkb wet domain green concepts red concepts blue concepts height hierarchy number concepts edus corresponding subtree t outputted nucleus rst way e edus corresponding t s n subtree outputted earlier corresponding t s s subtree artr s subtrees order outputting edus lexicographic order paths leading leaf nodes nucleus preferred satellite example path n n s preferred n s n matter long outputted summary balanced sense original text s rhetorical structure complexity algorithm linear proof yes traverse function executes nite number instructions makes nite number calls traverse function goes level tree deeper height parsing tree nite number instructions executed nite yes recursive structure algorithm ture nite binary tree program halting condition m h t yes coroutine structure recursive structure traverse sub algorithm yes recursive structure traverse sub algorithm yes traverse function goes level tree deeper backtracking needed yes sub algorithm recursive yes complexity n number tree nodes experimental results run procedure constructed dkb wet cepts collected e dictionaries including english chinese world economy trade dictionary thesaurus onym words tce short current scale dkb shown table evaluate parsing method prepared data set according procedure domain wet collected chinese texts ocial web pages china s ministry tal corpus contains paragraphs sentences support mofcom gov ruqian et al table basic data procedure procedure experimental corpus knowledge domain number texts average length text average number sentences text average number edus text average length edu wet computer aided context analyzing system programmers simulated parsing process texts according procedure procedure basic data procedure procedure listed table edu corresponds domain oriented lc performing procedure procedure counted manually parsed artrs analyzed reasons disagreement dierent programmers regulations following grammers parsed texts independently measure consistency experiments shown programmers marking text segment pairs chinese texts produced mismatches rate mismatches parsing process rre grounded framework rst latest relation denitions available dre grounded type system blue following snapshot artrs arsgs learned artr similar structure shown fig leaves e basic trees blue concepts roots dened denition dierent lengths texts widths artrs ranging average width depths artrs ranging average generating set dened classes synthesized attributes required cover aspects arsg parsing attributes rre denotes rhetorical relation sibling nodes role means nucleus satellite cue usual meaning happy means positive negative regard state state change total collected cues values cue attribute learned p p p f artrs p p production rule instances form classied sets essentially identical copies example method explained procedure synthesized number production rules form p f got preference rule instances form synthesized step algorithm preference rules form sfu denitions html attributed rhetorical structure grammar domain text summarization fig real case parsing method table layer wise outputs applying alogrithm artr fig china s service trade decit grew slowly chinese people traveled overseas service trade decit stood billion u s dollars end percent year year mainly driven tourist spending overseas china s goods trade surplus shrank percent billion u s dollars surplus higher indicating competitiveness foreign trade china s current account continued surplus standing billion u s dollars experiment fig real case parsing method input text left translated chinese artr right output applying algorithm artr fig sequence outputs shown table digital numbers denote original order edus text capital letters denote order generation algorithm fact order signicance summary way users request summarizer generate summary length signicant original text time newly generated edu inserted right place sequence outputted edus example gets edu gets edu sequence note practical application redundant words deleted validate eectiveness grammar learning fold validation evaluate parsing method time data learned asrgs average size p p p f resp average repetition rate p p p f fig precision recall f score measurements estimate mance parsing algorithm algorithm estimation based comparing performance machine learned arsg parser ruqian et al fig distribution repetition rate fold cross validation table average correctness measured fold cross validation level structure nuclearity rre dre sentence level paragraph level discourse level table correctness attributes correctly parsed nodes precision recall f score manually parsed artr precision reects rate correctly parsed artrs machine parsed ones recall reects rate correctly machine parsed artrs manually parsed ones f score harmonic mean precision recall note way calculating precision recall f score manually constructed machine parsed artr number leaf nodes experiment text parsing arsg arsgs text parsing according algorithm note shift reduce conict reduce reduce conict happens parsing highest probability date production rule selected rst second highest probability rule selected rst selection successful ing necessary table shows mean correctness fold parsing arsgs correctness attribute use evaluate attributes correctly parsed nodes e correctly parsed dres table shows mean values illustrate mean precision close mean recall high values indicate correctly parsed nodes correct attributes attributed rhetorical structure grammar domain text summarization table rouge rate comparative evaluations ilp textrank lead mead arsg rouge experiment evaluation arsg based summarization techniques parsing summarization technique elaborated algorithm purely based artr generated arsg parsing shown periment provide exible adjustable summaries form abstract requested length according requested reduction ratio synthetic experiment learning arsg based training texts applied parse text produce artr fig compared method classical summarization methods rouge recall oriented summarization evaluation method measures n gram overlap system generated manually produced summaries evaluate methods rouge scores standard automatic text summarization chose rouge evaluation measures note calculation rouge scores ictclas chinese word splitter split summaries punctuations stop words excluded matching compared performance arsg method based method textrank lead mead methods classical summarization methods ilp text summarization method utilizes integer linear programming ilp inference mum coverage model textrank graph based summarization approach represents text graph nodes edges correspond tences similarity model ranks sentences according voting recommendation adjacent sentences lead selects sentences beginning article mead computes summary sentences cluster centroids produced topic detection system table shows evaluation results reduce rate periments collected chinese corpus rouge scores method better methods arsg based summarization method enjoys best performance ilp transductive approach model generalization supervised learning arsg discussed eective introducing transductive approach model transfer assume dierent application domains models form partial order ruqian et al table current scale dkb extension id text parsing green concepts red concepts blue concepts number concepts table modication arsg wet id production rules attributes precedence rules number changes according knowledge contain domain global situation analysis gsa root big tree nodes represent ferent child domains dierent child models need construct model node explicitly appropriate partial order operations possible transfer models node extending reducing transforming crossing knowledge bases grammar rules upgrade simplify transfer recombine models sense models transferable wet domain taken example paper nodes dicult transfer wet oriented arsg child domains gsa experiment experiment domain texts validate transferability method conduct experiment domain industrial dynamics id child domain gsa sister domain wet check feasibility transferring arsg model collected chinese texts open source ocial web china s ministry industry information nology miit average text length corpus approximately equal corpus wet experiment shows slight extension table wet dkb simple transformation table arsg rules possible obtain usable new arsg id domain fact concept database blue ones id text parsing new green concepts red concepts added correspondingly grammar rule modications shown table comparing arsg learned production rules preference rules statements experiment workload generating arsg new domain id learning arsg original domain wet mention save manual work texts manual construction parsing trees text randomly selected texts corpus parsed mechanically transferred arsg manually human sults comparing automatically generated artrs manually parsed artrs shown table indicate eectiveness method miit gov attributed rhetorical structure grammar domain text summarization table precision model transfer level structure nuclearity rre dre sentence level paragraph level discourse level selective comparative study table compares arsg approach followed approaches graph based resp nn based approaches addition compare arsg ilp methods later need calculate relevance redundancy weights sentence resp sentence pairs consider based graph methods roughly speaking ilp method provide high quality summaries diculty processing large sized documents complexity np hard concluding remarks contributions paper include introduced attribute grammar based approach study automatic text summarization introduced ical structure theory approach help nl analysis combine form framework arsg proposed implemented tive algorithms machine learning arsg proposed implemented eective algorithm parsing nl texts arsg framework proposed implemented rst guided algorithm generating adjustable summaries proposed transductive approach model transfer avoid data retraining given arsg applied new domains performed series ments validate results order save work building new dkb new domain introduced transduction approach model transfer dierent domains similarities abstract representation herit knowledge example domains wet id considered paper concepts output wet production id dierent rule output increases situation improved mapped production increases situation improved given output mapped production reminds afresh retraining necessary transferring new domain shown experiment tables particular table shows workload obtaining id model transferring roughly building wet model new idea paper propose method combining rst lexical chain technique e combining coherent approach cohesive approach approaches forming main streams text summarization research roughly speaking technique isolated ruqian et al table comparison approaches approach graph neural network arsg data request limited data set limited data set representative work paradigm technique information source knowledge request knowledge beneter model application design model structure training model parameters evolution model structure model interpretability generalization model applicability dierent data sources preciseness summary textrank unsupervised mainly syntactical nn se supervised method supervised mainly syntactical mainly semantical data driven data driven knowledge driven linguistic knowledge human graph design domain independent large data set linguistic knowledge human nn design domain independent domain knowledge computer model construct parse domain dependent simple dicult need try test fixed designed training weighted graph revision algorithmic mechanically heuristic analysis revision model behavior supercial poor need manual training algorithmic incremental evolution professional simple reuse result fair simple reuse result fair simple reuse result fair success rate roughly equals simple reuse result fair depending quality training data double success rate dailymail simple reuse domain result good simple reuse new domain result inadequate transfer new domain need dkb extension model mapping generally low generally low generally high advantages disadvantages combination provide new vigor augmenting advantages diminishing disadvantages combination course simple sides adapt meet changed lexical chains lexical cores hand extended rhetorical relations domain relations hand strategy approach operational attributed rhetorical structure grammar domain text summarization spite success rst technique summarization nique research rst based summarization technique phase laboratory experiments appreciated large set rst research pers outstanding experimental results nt engineering commercial application future work concentrated deepening broadening application range arsg approach including applying arsg proach hierarchy domains systematically constructing hierarchy arsg test model transfer capability introducing arsg based summarization multiple texts discussing specic ties techniques encountered context making research results engineering discipline public service practical use paring arsg based summarization techniques approaches deep learning techniques form ecient new approaches acknowledgements work supported national key research ment program china grant national natural science foundation china beijing science technology project machine learning based stomatology tsinghua tencent amss joint project www knowledge structure application references barzilay r elhadad m lexical chains text summarization acl shop intelligent scalable text summarization pp c mann w thompson s rhetorical structure theory functional theory text organization text cao z li w li s wei f retrieve rerank rewrite soft template based neural summarization vol pp carlson l marcu d okurovsky m e building discourse tagged corpus sigdial workshop discourse framework rhetorical structure theory dialogue che w li z liu t ltp chinese language technology platform coling cheng j lapata m neural summarization extracting sentences words demonstrations pp vol pp chopra s auli m rush m abstractive sentence summarization attentive recurrent neural networks hlt naacl pp dong z dong q hownet computation meaning durrett g berg kirkpatrick t klein d learning based single document rization compression anaphoricity constraints ercan g cicekli lexical cohesion based topic modeling summarization international conference intelligent text processing computational linguistics pp springer fattah m hybrid machine learning model multi document summarization applied intelligence feng v w hirst g text level discourse parsing rich linguistic features pp flick c rouge package automatic evaluation summaries workshop text summarization branches p galley m mckeown k improving word sense disambiguation lexical chaining ijcai pp ruqian et al gambhir m gupta v recent automatic text summarization techniques survey articial intelligence review genest p e lapalme g absum knowledge based abstractive summarizer generation par abstraction gillick d favre b scalable global model summarization proceedings workshop integer linear programming natural langauge processing pp hermann k m kocisky t grefenstette e espeholt l kay w suleyman m nips pp blunsom p teaching machines read comprehend hernault h prendinger h ishizuka m al hilda discourse parser support vector machine classication dialogue discourse hirao t yoshida y nishino m yasuda n nagata m single document proceedings conference marization tree knapsack problem empirical methods natural language processing pp hirao t yoshida y nishino m yasuda n nagata m single document rization tree knapsack problem emnlp pp hirst g st onge d al lexical chains representations context tection correction malapropisms wordnet electronic lexical database ji y eisenstein j representation learning text level discourse parsing pp joty s r carenini g ng r t mehdad y combining multi sentential rhetorical parsing document level discourse analysis pp julia h manning c d advances natural language processing science knuth d e semantics context free languages mathematical systems theory lei k zhang l liu y shen y liu c yu q weng w event rizing algorithm based timeline relevance model sina weibo science china information sciences lethanh h abeysinghe g huyck c generating discourse structures written texts international conference computational linguistics p marcu d rhetorical parsing natural language texts acl pp marcu d theory practice discourse parsing summarization mit mihalcea r tarau p textrank bringing order texts unt scholarly works pp miller g wordnet lexical database english commun acm press morris j hirst g lexical cohesion computed thesaural relations indicator structure text computational linguistics nallapati r zhai f zhou b summarunner recurrent neural network based sequence model extractive summarization documents aaai pp nallapati r zhou b dos santos c glar gulcehre c xiang b abstractive text summarization sequence sequence rnns conll p nenkova mckeown k survey text summarization techniques mining text data pp springer nenkova mckeown k al automatic summarization foundations trends information retrieval page l brin s motwani r winograd t al pagerank citation ranking bringing order web pp parveen d mesgar m strube m generating coherent summaries scientic cles coherence patterns emnlp pp pourvali m abadeh m s automated text summarization base lexicales chain graph wordnet wikipedia knowledge base international journal computer science issues ijcsi attributed rhetorical structure grammar domain text summarization qian t ji d zhang m teng c xia c word sense induction lexical chain based hypergraph model coling technical papers pp acl radev d r jing h sty m tam d centroid based summarization multiple documents inf process manage remus s biemann c knowledge free methods automatic lexical chain extraction hlt naacl pp rush m chopra s weston j neural attention model abstractive sentence summarization emnlp pp liu p j manning c d point summarization generator networks vol pp silber h g mccoy k f eciently computed lexical chains intermediate sentation automatic text summarization computational linguistics soricut r marcu d sentence level discourse parsing syntactic lexical toloski m brooke j taboada m syntactic lexical based discourse information hlt naacl menter pp wei t lu y chang h zhou q bao x semantic approach text clustering wordnet lexical chains expert syst appl yoshida y suzuki j hirao t nagata m dependency based discourse parser single document summarization emnlp pp zhang h p yu h k xiong d y liu q hhmm based chinese lexical analyzer clas proceedings second sighan workshop chinese language volume pp zhou q yang n wei f huang s zhou m zhao t neural document rization jointly learning score select sentences vol pp
