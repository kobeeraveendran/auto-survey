leafnats open source toolkit live demo system neural abstractive text summarization tian shi virginia tech edu ping wang virginia tech edu chandan reddy virginia tech edu abstract neural abstractive text summarization nats received lot attention past years industry academia paper introduce open source toolkit leafnats training tion different sequence sequence based models nats task ing pre trained models real world cations toolkit modularized tensible addition maintaining tive performance nats task live news blogging system mented demonstrate models aid blog news editors providing gestions headlines summaries articles introduction prominent natural language generation tasks neural abstractive text rization nats gained lot ity rush paulus different extractive text marization gambhir gupta nallapati verma lee nats lies modern deep learning models particularly sequence sequence models erate words vocabulary based resentations features source documents rush nallapati ability generate high quality summaries verbally innovative easily corporate external knowledge nats models achieved better mance terms commonly tion measures rouge lin score compared extractive text summarization proaches paulus celikyilmaz gehrmann recently provided comprehensive survey models shi ing network structures parameter inference methods decoding generation approaches task abstractive text summarization riety nats models share common erties key techniques widely produce formed human readable summaries inferred source articles encoder decoder framework sutskever word embeddings mikolov attention mechanism bahdanau pointing mechanism vinyals beam search algorithm rush features found tions language generation tasks machine translation bahdanau dialog systems serban addition techniques shared different tasks include training strategies fellow keneshloo zato data pre processing results processing model evaluation ing open source toolbox modularizes ferent network components unies ing framework training strategy researchers language generation ious aspects including efciently implementing new models generalizing existing models different tasks past years different toolkits developed achieve goal designed specically single task parlai miller dialog search extended tasks example opennmt klein xnmt neubig marily neural machine translation nmt applied areas attention model gehrmann achieved state art performance stractive text summarization implemented general purpose language generation packages texar compared toolkits leafnats specically designed nats research adapted tasks toolkit implement end end training framework minimize fort writing codes training evaluation dures users focus building models pipelines framework makes easier users transfer pre trained parameters user specied modules newly built models addition learning framework developed web application driven databases web services nats models demo deploying new nats idea real life application leafnats plication help end users blog news authors editors providing suggestions headlines summaries articles rest paper organized follows section introduces structure design leafnats learning framework section describe architecture live system demo based request system propose implement new model leafnats headline summary generation conclude paper section leafnats section introduce structure sign leafnats toolkit built lower level deep learning platform torch paszke shown fig consists main components engines modules data tools playground engines leafnats engine represents training algorithm example end end training adversarial ing goodfellow different training frameworks need velop different engines specically leafnats implement task independent end end training engine nats adapted nlp tasks nmt question answering ment classication engine uses stract data models pipelines loss functions figure framework leafnats toolkit build procedures training validation ing evaluation application respectively completely reused menting new model example dures include saving loading check point les ing training selecting best models idation best model generation testing feature engine allows users specify neural network train reuse parameters models convenient transfer learning modules modules basic building leafnats blocks different models provide ready use modules constructing current neural network sequence models nats pointer generator network modules include embedder rnn encoder attention luong temporal tion nallapati attention decoder paulus use basic modules assemble pointer generator coder module corresponding beam search embedder algorithms realize embedding weights sharing nism paulus data tools different models nats tested datasets table cnn daily mail cnn hermann newsroom grusky pre processed cnn data available provide tools process datasets data modules prepare input data mini batch mization playground engine modules develop different models assembling com com com leafnats process data cnn dailymail dataset cnn newsroom bytecup table basic statistics datasets validation train test modules building pipelines ground implement different models nats toolkit shi framework performance rouge scores lin pointer generator model different datasets reported table results better previous plementations shi minor changes neural network model dataset pointer generator newsroom newsroom pointer generator pointer generator coverage pointer generator cnn bytecup table performance implemented generator network different datasets represent newsroom summary headline datasets respectively live system section present real world web cation abstractive text summarization els help end users write lines summaries articles posts rst discuss architecture system provide details end design new model built leafnats makes automatic summarization headline generation possible architecture news blog website allows people read duplicate edit post delete comment articles driven web services databases nats models web application developed php html css jquery lowing concept model view controller fig framework people interact end views send html requests controllers manipulate models views changed updated tion example nats rst write ticle text area article edu leafnats figure architecture live system summarization request sent troller jquery ajax controller municates nats models asynchronously json format data finally generated lines summaries shown view design frontend fig presents end design web application creating new post labels represent sequence actions website author rst click new post step bring new post view write content article corresponding text area step specifying headline lights summary clicking nats ton step waiting seconds generated headlines highlights article new tab right hand screen buttons gray color denotes resource training data example bytecup means model trained bytecup headline generation dataset tokenized article content shown apart plain text headlines highlights system enables users visual standing word generated tention weights luong ing mouse tracker step token headlines highlights related content ticle labeled red color author like use suggestions click gray button step add text area left hand edit nally click post step post article proposed model shown fig system suggest users headlines based newsroom headline bytecup datasets summaries based newsroom summary cnn datasets treated tasks section achieve goal use figure end design live demonstration system dataset newsroom newsroom cnn bytecup model multi task multi task transfer coverage transfer table performance model corresponding testing sets shown table table observe model forms better headline generation tasks rouge scores summarization tasks lower models sharing ding encoder output layers noted sharing parameters model requires million parameters achieve performance conclusion paper introduced leafnats toolkit building training testing evaluating deploying nats models live news blogging system demonstrate nats models work writing lines summaries news articles cient extensive set experiments ent benchmark datasets demonstrated fectiveness implementations newly proposed model system achieved petitive results fewer number parameters figure overview model generate lines summaries ules provided leafnats toolkit assemble new model fig shared ding layer shared encoder layer task specic encoder decoder lstm encoder generator decoder layer shared output layer train model rst build multi task learning pipeline newsroom dataset learn parameters modules colored ange fig articles dataset headlines highlights size dataset large articles come variety news agents build fer learning pipeline cnn daily cup dataset learn parameters modules labeled blue green color respectively leafnats accomplish work ciently performance proposed model acknowledgments work supported tional science foundation grants references dzmitry bahdanau kyunghyun cho yoshua gio neural machine translation jointly arxiv preprint learning align translate asli celikyilmaz antoine bosselut xiaodong yejin choi deep communicating agents proceedings abstractive summarization conference north american chapter association computational linguistics man language technologies volume long pers volume pages mahak gambhir vishal gupta recent matic text summarization techniques survey ticial intelligence review sebastian gehrmann yuntian deng alexander rush abstractive summarization proceedings conference cal methods natural language processing pages ian goodfellow jean pouget abadie mehdi mirza bing david warde farley sherjil ozair aaron courville yoshua bengio generative advances neural information versarial nets processing systems pages max grusky mor naaman yoav artzi newsroom dataset million summaries diverse extractive strategies proceedings conference north american chapter association computational linguistics man language technologies volume long pers volume pages karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa leyman phil blunsom teaching chines read comprehend advances ral information processing systems pages zhiting haoran shi zichao yang bowen tan tiancheng zhao junxian wentao wang xingjiang lianhui qin wang texar modularized versatile arxiv preprint ble toolkit text generation yaser keneshloo tian shi chandan reddy naren ramakrishnan deep reinforcement learning sequence sequence models arxiv preprint guillaume klein yoon kim yuntian deng jean senellart alexander rush opennmt open source toolkit neural machine translation proceedings acl system demonstrations pages chin yew lin rouge package matic evaluation summaries text summarization branches thang luong hieu pham christopher ning effective approaches attention based proceedings neural machine translation conference empirical methods natural language processing pages tomas mikolov ilya sutskever kai chen greg rado jeff dean distributed tions words phrases advances neural information processing ity systems pages alexander miller feng dhruv batra antoine bordes adam fisch jiasen devi parikh jason weston parlai dialog research proceedings ware platform ference empirical methods natural language processing system demonstrations pages ramesh nallapati feifei zhai bowen zhou summarunner recurrent neural network based quence model extractive summarization ments thirty aaai conference articial intelligence ramesh nallapati bowen zhou cicero dos santos glar bing xiang tive text summarization sequence sequence rnns conll page graham neubig matthias sperber xinyi wang matthieu felix austin matthews sarguna manabhan devendra singh sachan philip arthur pierre godard xnmt tensible neural machine translation toolkit vol researchers track page adam paszke sam gross soumith chintala gory chanan edward yang zachary devito ing lin alban desmaison luca antiga adam lerer automatic differentiation pytorch romain paulus caiming xiong richard socher deep reinforced model abstractive marization arxiv preprint marcaurelio ranzato sumit chopra michael auli wojciech zaremba sequence level ing recurrent neural networks arxiv preprint alexander rush sumit chopra jason weston neural attention model abstractive proceedings tence summarization conference empirical methods natural guage processing pages abigail peter liu christopher manning point summarization generator networks proceedings nual meeting association computational linguistics volume long papers pages association computational linguistics iulian vlad serban alessandro sordoni yoshua gio aaron courville joelle pineau building end end dialogue systems ative hierarchical neural network models tian shi yaser keneshloo naren ramakrishnan chandan reddy neural abstractive text summarization sequence sequence models arxiv preprint ilya sutskever oriol vinyals quoc sequence sequence learning neural works advances neural information ing systems pages rakesh verma daniel lee extractive summarization limits compression generalized model heuristics computacion sistemas oriol vinyals meire fortunato navdeep jaitly pointer networks advances neural formation processing systems pages
