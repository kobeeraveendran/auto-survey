cite this paper cite copy and paste a formatted citation or use one of the links to import into a bibliography manager mla yadav chandra shekhar and aditi sharan hybrid approach for single text document summarization using statistical and sentiment features international journal of information retrieval research ijirr apa yadav c s sharan a hybrid approach for single text document summarization using statistical and sentiment features international journal of information retrieval research ijirr chicago yadav chandra shekhar and aditi sharan hybrid approach for single text document summarization using statistical and sentiment features international journal of information retrieval research ijirr no harvard yadav c s and sharan a hybrid approach for single text document summarization using statistical and sentiment features international journal of information retrieval research ijirr pp vancouver yadav cs sharan a hybrid approach for single text document summarization using statistical and sentiment features international journal of information retrieval research ijirr oct hybrid approach for single text document summarization using statistical and sentiment features abstract summarization is a way to represent same information in concise way with equal sense this can be categorized in two type abstractive and extractive type our work is focused around extractive summarization a generic approach to extractive summarization is to consider sentence as an entity score each sentence based on some indicative features to ascertain the quality of sentence for inclusion in summary sort the sentences on the score and consider top n sentences for summarization mostly statistical features have been used for scoring the sentences we are proposing a hybrid model for a single text document summarization this hybrid model is an extraction based approach which is combination of statistical and semantic technique the hybrid model depends on the linear combination of statistical measures sentence position tf idf aggregate similarity centroid and semantic measure our idea to include sentiment analysis for salient sentence extraction is derived from the concept that emotion plays an important role in communication to effectively convey any message hence it can play a vital role in text document summarization for comparison we have generated five system summaries proposed work mead system microsoft system opinosis system and human generated summary and evaluation is done using rouge score keywords summarization single document summarization sentiment analysis hybrid model introduction text document summarization playing an important role in ir information retrieval because it condense a large pool of information into a concise form through selecting the salient sentences and discards redundant sentences or information and we termed it as summarization process radev et al in has defined a text summary as a text that is produced from one or more texts that convey important information in the original texts and that is no longer than half of the original text and usually significant less than that as explained in automatic text document summarization is an interdisciplinary research area of computer science that includes ai artificial intelligence data mining statistics as well as psychology we can classify text summarization in two ways by techniques abstractive summarization and extractive summarization abstractive summarization is more human like a summary which is the actual goal of text document summarization as defined by abstractive summarization needs three things as information fusion sentences compression and reformation abstractive summarization may contain new sentences phrases words even which are not present in the source document although till now a lot of research in happened in the last decades in the area of nlp natural language processing nlg natural language generation so much computing power increased but still we are not near for abstractive summarization the actual challenge is a generation of new sentences new phases along with produced summary must retain the same meaning as the same source document has extractive summarization based on extractive entities entities may be sentence sub part of sentence phrase or a word our work is focused on extractive based technique in this paper we are proposing a hybrid method for single text document summarization which is linear combination of statistical features as used in and new kind of semantic feature i e sentiment analysis the idea which is used in this paper has been derived from different papers like for statistical features and their collective sum obtained from centroid measure are taken from to include sentiment analysis is derived from the concept that emotion plays an important role in communication to effectively convey any message hence it can play a vital role in text document summarization outline of paper looks like in section we are presenting categorized literature work done in recent years section contains features used for summarization purpose section contain summarization algorithm and detail approach in section we are presenting description with statistical and linguistic statistic section showing some experiments and results in section is about conclusion related work according to m ramiz summarization in is defined as a three steps process analysis of text as summary representation and produce an appropriate summary eduard hovy and chin yew lin introduced summarist system to create a robust text summarization system system that works on three phases which can describe in form of an equation like summarization topic identification interpretation generation a lot of research done in the direction of extraction based approaches in extractive summarization the important the task is to find informative sentences a subpart of sentence or phrase and include these extractive elements into the summary here we are presenting work done in two categories early work done and work done in recent years in our views these are three works done initially that provides direction of text document summarization extractive explained below the early work in document summarization started on single document summarization by h p luhn he proposed a frequency based model in which frequency of word play crucial role to decide importance of any sentence in the given document another work of p baxendale had been introduced a statistical model based on sentence position in his research he found that starting and ending sentences became salient sentences for summarization but this is not better for every document like scientific research paper but good for newspapers summarization h p edmondson also proposed an effective technique for document summarization at first edmonson designed some rules for manual extraction then rules were applied to technical documents edmondson considers four features sentences position frequency of word presence of cue words and the skeleton of the document the work was done almost manual after these early work lot of work done in this discipline some are available in here in the next section we are presenting only work done in recent years query focused summarization is a special case of document summarization in which summary purposely demands to be biased according to the user query you ouyang et al used svr support vector regression to calculate the importance of the sentences in a given document another query focused summarization multi document summarization done by carbonell j goldstein in researcher done a lot of work in the multi document summarization field and many more like in considering this is as a global multi optimization problem which requires simultaneous optimization of more than one objective function rasim m alguliev in which the objective function is a weighted combination of content coverage and for redundancy objectives in another work they proposed cdds based summarization with two objectives diversity and coverage in summarization similarity evaluation among of sentences is a laborious task because of complex sentence structure and lack of extra information so ming che lee had been proposed transformed vector space model based on word net due to improper ordering of information there is possibility that it can confuse the readers as well as can degrade the readability of the summary to maintain the association and order of sentences danushka bollegala et al defined four criteria chronology topical closeness precedence succession these all four criteria are combined into a single criteria by using a supervised learning approach redundancy can be defined as a multiplicity of sentences sub sentences or information coverage and redundancy are reciprocal to each other summarization objective is maximum coverage and minimum redundancy kamal sarkar gave a simple approach to include a sentence in summary one by one based on modified cosine similarity threshold to include sentences in the summary system first selects the most top rank sentence include it in the summary and this process is repeated for remaining sentences next sentence is included in the summary if similarity between sentences and summary is less than some threshold otherwise the sentence is not included in the summary and algorithm stops when required summary length is reached we are using this model in our implementation to handle redundancy another model mmr is popularly used especially in with a given query to reduce redundancy the mmr maximal marginal relevance criteria strives to reduce redundancy while maintaining query relevance in re ranking retrieved documents and in selecting appropriate passages for text summarization this technique gives better result for multi document summarization rasim m alguliev et al proposed an unsupervised text summarization model which can be used for single as well as multi document summarization in simple terms the problem is treated as a multi objective problem where the objective is to optimize three objectives relevance redundancy and length to find a good summary lot of work done but to decide the quality of the summary still a challenging task research is done by goldstein in he conclusion that even human judgment of the quality of a summary varies from person to person only little overlap among the sentences picked by people human judgment usually does find concurrence on the quality of a given summary hence it is sometimes difficult to judge the quality of the summary for evaluation most researcher use the recall oriented understudy for gisting evaluation rouge introduced by lin and this has been officially adopted by duc for summarizer evaluation rouge compares system generated summary with different model summaries it has been considered that rouge is an effective approach to measure document summarizes so widely accept rouge measures overlap words between the system summary and standard summary gold summary human summary overlapping words are measured based on n gram co occurrence statistics where n gram can be defined as the continuous sequence of n words multiple rouge metrics has been defined for different value of n and different models like lcs weighted standard rouge n is defined by here n stands for the length of the n gram gram is the number of n grams present in the reference summaries and the maximum number of n grams co occurring in the system summary the set of reference summaries is countmatch n gram rouge measures generally gives three basic score precision recall and f score since score is not a sufficient indicator of summarizer performance so another variation of rouge is rouge n rouge l rouge w rouge s rouge su in our evaluation we are using fourteen rouge measure l w s and su for other variation kindly follow proposed model for text document summarization in this section we are presenting features used in our sentence selection approach in section and detailed approach in section we are proposing a hybrid model for salient sentence extraction for single text document summarization based on two types of features statistical based features i e location frequency tf idf aggregate similarity centroid and semantic based feature sentiment features statistical features used a the location feature p baxendale in introduced a feature based on sentence position although his work was almost manual but later on this measure used widely in sentence scoring he proposed that leading sentences of an article are important model which we are using given below where n is total number of sentences the used model is where i n and b the aggregation similarity feature kim et al defined aggregate similarity as the score of a sentence is as the sum of similarities with other all sentence vectors in document vector space model it is given by sim si sj wik wjk score si sim si sj where wik is defined as the binary weight ok kth word in ith sentence similarity measure plays an important role in text document summarization even studied different similarity measure affects the outcome in our implementation using cosine similarity that is widely used the cosine measure between two sentences wim and wjm standard cosine similarity measure gives by following formula which is used in our implementation is below i to n c frequency feature the early work in document summarization started on single document summarization by h p luhn at ibm in the luhn proposed a frequency based model frequency of word play a crucial role to decide the importance of any word or sentence in a given document in our method we are using the traditional method of tf idf measure is defined as below i e tf stands for term frequency idf for inverse document frequency log where tfi is the term frequency of ith word in the document nd represents total number of documents and idfi is the document frequency of ith word in the whole data set in our implementation to calculate importance of word wi for tf we considering the sentence as a document and for idf entire document as a data set d centroid feature radev et al defined centroid as a centroid is a set of words that are statistically important to a cluster of documents as such centroids can be used both to identify salient sentences in a cluster and classify relevant documents the centroid score ci for sentence si is computed as the sum of the centroid scores cw i of all words appeared in the particular sentence sentiment feature or semantic feature used e sentiment feature in previous sections we mentioned statistical measures used by us we are calling this feature as a semantic feature because in this a set of things are related to one other semantic summary generation may be done using shallow level analysis and deep level analysis as defined by in shallow approach to most analysis done on sentence level is syntactic but important to note that word level analysis may be semantic level and in deep analysis at least a sentential semantic level of representation is done so our approach i e sentiment feature is semantic and low level analysis because at the entity level for finding sentiment score for a sentence fist we find all entities present in a sentence then find sentiment score of each entity and then do sum of all entity sentiment score i e sentiment strength if sentiment of entity is neutral then we scorning it as if entity sentiment is positive then considering as same and adding to find the total score of a sentence but if sentiment score is negative we multiplying it by to covert in positive score then adding this score to find total score reason for considering negative score to positive score is that we are interested only in sentiment strength which may be positive or negative i e if sentiment score of an entity if it means sentiment of entity is negative and strength is detail procedure are explained in section s fifth feature here a representing mode a i e a a summarization procedure our summarization approach is based on salient sentence extraction the importance of any sentence is decided by the combined score given by the sum of statistical measures and semantic measure in next step we are explaining our approach algorithm used in this paper basically work of summarization can be dived in three pass sentence scoring sentence extraction and evaluation algorithm sentence scoring according linear combinations of different measures salient sentence extraction summary generation pass evaluation of summary pass sentence scoring input documents output scored sentences step score the sentence given with different measures outcome is m n matrix m no of sentences n no of measures aggregate cosine similarity position sentiment of sentence centroid score of sentence tfidf step normalized columns of matrix step add all the features for every sentence we calling this sum as a score of the sentence step sort according to score a highest score representing most significant sentence pass algorithm for redundancy input number of sentences descending according to total score output extracted sentences parameter initialization empty summary similarity threshold l required step summary scored sentence step for to number of sentences step rearrange summary sentences as given in source document for maintain cohesiveness if ith sentence and length summary l then summary ith sentence length summary human and our proposed algorithm pass evaluation of summary input different summaries as standard summaries and peer summaries output precision recall and f score step generate different summary different length using mead microsoft opinosis human for experiment model summary human generated summary peer summary mead microsoft opinosis our proposed method step used rouge n to rouge l rouge w we set rouge s rouge su measure model summary mead microsoft opinosis peer summary our proposed algorithm for experiment to find precision recall and f measure detailed approach description here we are describing detail approach used as the procedure described above pass sentence scoring and extraction in algorithm defined in the previous section most things are covered and gives the main idea of algorithm still some micro points are needs to specify pass is the sum of the linear combination of five different measures four are statistical dependent i e aggregate similarity position tf idf centroid and fifth measure is semantic dependent i e sentiment first feature is position of sentences position is an important indicator for important sentence and it has been analyzed that first or leading sentences mostly contains important information the n position score for some sentence index to are given in s second column second feature tf idf approach we are using the standard formula as defined in the previous section normalized tf idf score are given in third columns third feature is an aggregate similarity cosine score of a sentence vector can be calculated as the sum of similarities with other all sentence vectors in document vector space model the significance of this is to find a sentences which are highly similar to all other sentences after representing all sentences in a vector space and then find vector cosine similarity with all other sentences as defined standard formula in the section normalized aggregate cosine similarity in column four since other scores centroid position sentiment are between so we need to normalized score normalization of values means adjusting to values measured on different scales to one notionally common that removes chance to be bias w t some values in our implementation we are just using column normalization instead of matrix normalization normalization of a column vector xn is done using equation where xi is the ith element in the column and n is the size of the column b let a is a given matrix which size is and column one and two has does have values between then we are doing normalization of only column one and two but not third column and b is the give normalized matrix in our case fourth feature is centroid based d r radev defined as centroid as a set of words that are statistical important to a cluster of documents in our approach using mead centroid score output as our input the centroid value of a sentence is given by summation of each word centroid score present in the sentence fifth feature is sentiment score this is a novelty in our work to find this feature we depends on alchemy api which is available at alchemyapi our consideration is that it is finding sentiment score is a semantic approach and fall under shallow level approach as defined in section for any sentence or words we can define three kind of sentiment neutral negative and positive neutral sentiment value mean that words or that sentence sentiment score is zero most important to note that it is easy to find sentiment score based on cue word like good bad pleasant but still due to so much complexity in text words limitation of nlp it is not possible to find correct sentiment score sometime even it is also not possible to detect sentiment due to hidden sentiments document naac accredited jnu with the cgpa of on four point scale of a grade highest grade by naac and sentiment of this is neutral document jnu ranked in top in times higher education asia and brics top ranking and sentiment of this document is positive and score is naac stands for national assessment and accreditation council naac and brics stands for five nations brazil russia india china and south africa here document and document both representing positive news about jnu but the sentiment of document is neutral and sentiment of document is positive with score we still have to discover approach which can find correct sentiment hidden sentiment some results are displayed in table with sentiment results in our implementation to find sentiment score of a sentence we are using alchemy api first finding all entities present in the sentence and their sentiment score then we add all entity sentiment score for example consider document number meanwhile bjp spokesperson prakash javadekar has said that party president has five entities as follow prakash javadekar person name rajnath singh person name uttarakhand state county bjp company president jobtitle triplet x y z representing x is entity name y is entity type z sentiment score and to give sentiment score of sentence we add all so sentiment score for sentence but if we see the table result in row and column sentiment score the value is here we are considering only positive sentiment scores if entity sentiment score is negative then by multiplying to convert it into positive score the obvious goal of this procedure is to give equal importance if magnitude is same let consider one childhood story the fox and the grapes in figure figure the fox and the graps story if here we consider two sentences given below document and as document both are important in the story and about same things grapes document just these sweat and juicy grapes to quench my thirst and document they re probably sour anyway with alchemy system if we find a sentiment of both these sentences then the sentiment of document is positive and the score is where the sentiment of document is negative with for us only magnitude is important reasons to consider as value are are interested to find sentiment strength it may be negative or positive and both are important for us and if we will add negative score to find total score then value will reduce in next step we are finding the total score of a sentence by adding all scores the total score can be represented by equation given below in our implementation detail result of individual score is given in table and last column is total score of all scores table different features scores and total score for sentences pass redundancy to remove redundancy we used same model as proposed by sarkar in which the top most sentence according to total score defined in equation is add in summary we add next sentence in the summary if similarity is less than threshold algorithm is described in section input in this pass is a number of sentences which are sorted according to descending total score we need to initialize some parameter to get the desired summary parameter like summary initially empty given similarity threshold and l for desired length summary even in our system l means maximum length of desired summary but due to limitation here length of sentences we can guaranteed minimum maximum length summary we will add the next sentence in the summary if still summary length is less than l and similarity new sentence summary the output of this step is a summary with minimal redundancy and length nearly equal to l but the position of the sentence is zigzag that lost the sequence and cohesiveness to maintain the sequence we need to rearrange the sentences according to given in initial index in table we are representing the summary generated by our system in which similarity threshold is and desired summary length is we can define arbitrary l in a number of words or percentage of summary required here we chosen small if we put large like or then the sentences which are in coming in summary will depend only on the total score as in table in other words the summary is only depended on totalscores as shown in table but our objective is also to minimize redundancy note before calculating sentence summary we are eliminating stopwords stopwords play a big role to increase the similarity between two sentences with different stopwords list we will get different similarity score mead microsoft and our model generated summary with different length are shown below in table the truth is we do have the detail of microsoft generated a summary this summarizer is inbuilt inside microsoft office package when we observed then find little unhappy that microsoft summarizer is not reducing redundancy sentence and are almost similar sentences see table pass evaluation goldstein in he concluded two things even human judgment of the quality of a summary varies from person to person human judgment usually does find concurrence on the quality of a given summary hence it is difficult to judge the quality of a summary for evaluation of any summary we need two summary first one is a system generated summary and other summary is user generated model summary or standard summary to generate different model summary we used three approaches we given our text data set to person and tell them to write a summary in about to to words we generate summary by mead tool in score with and third model summary is generated by summary given in figure microsoft system combination approach centroid position taking linear and this we of sent no position scoretf idfaggregate cosine sim centroid scoresentiment scoresum of to evaluate summary we are using rouge evaluation package rouge is adopted by duc for official evaluation metric for both single text document summarization and multi document summarization rouge finds recall precision and f score for evaluation results based on n gram co occurrence statistic it rouge measures how much the system generated summary machine summary overlaps with the standard summary human summaries model summary where an n gram is a contiguous sequence of n words in our evaluation we are adopting different measures of rouge as rouge n to rouge w rouge l rouge s and rouge su corpus description in june was a multi day cloudburst centered on the north indian state of uttarakhand caused devastating floods along with landslides and became the country worst natural disaster though some parts of western nepal tibet himachal pradesh haryana delhi and uttar pradesh in india experienced the flood over of the casualties occurred only in uttarakhand as of july according to figures provided by the uttarakhand government more than people were presumed corpus is self designed taken from various newspapers ex the hindu times of india this dataset is also published in paper c s yadav here we are showing some statistically and linguistic statics about our data set used statistical statistics total no of sentences in document length of document after stop word removed total number of distinct words minimum sentence length words maximum sentence length words average sentence length is in our experiment we used sql stopword list which is available at by seeing the figure we can interpret that sentences are between length and and sentences are between length and figure sentence length y axis vs sentence number x axis linguistic statistics nn nnp nns dt jj jjr jjs vb vbn vbd vbz vbg vbp where different abbreviation stands for nn noun singular mass nns nounplural nnp proper noun singular nnps proper noun plural vb verb vbd verb past tense vbg verb gerund vbn verb past participle vbp verb non person singular vbz verb person singular jj adjective jjr adjective comparative jjs adjective superlative dt determinant note means x is entity type and is its count experiment and results in this section we are presenting two experiment done on mentioned dataset experiment as explained in section s pass we created types of model summary human summary via we gave data set to persons to summarize it based on their experience with instruction to summarize it within to words length due to limitations and user experiences the generated summary varies from to words length mead microsoft and opinosis system different system generated summary are given in table since opinosis summarizer is abstractive type in figure we are giving summarization result length summary generated by opinosis system table presenting different summaries generated by different systems table our system generated summary using proposed algorithm table microsoft system generated summary table mead system generated summary figure opinosis generated summary in the first experiment we took our own summary generated by algorithm discussed in section as system generate summary and another summary as model summary in next step we find different rouge scores to rouge l rouge w where rouge s and rouge as defined by rouge scores is given by formula defined in section it measures things recall precision and f score for any system generated summary and model summary or reference summary recall and precision are given in a slightly different way as defined by we are comparing our system generated summary with other as model summary same length summary result of this is given is table table and table for length respectively due to limitation of space we providing only three tables figure showing f measure with different model summaries of length of nearly and our summary length is nearly in simple term we can define high precision means that an algorithm retrieved substantially more relevant than irrelevant and high recall means that an algorithm return most of the relevant from figure and for summary length it is clear that we are getting high precision f score w t mead reference summary and high recall w microsoft generated summary table summary generated by our algorithm considered as system summary another summary as a model summary table summary generated by our algorithm as system summary another summary as model summary table summary generated by our algorithm as system summary another summary as model summary summary figure precision curve figure recall curve figure showing f score experiment in this experiment we comparing different system generated summary w t human summary or in other words here model reference summary is human generated summary and other summaries are system generated summary i e mead microsoft opinosis our algo are system generated summary result are shown in table and table table is representing different rouge scores for the summary length of table summary generated by different as system summary human generated summary as model summary table summary generated by different system considered as system summary human generated summary as model summary from table we can say that we are getting high f score comparison to mead microsoft system and opinosis system except rouge w in mead s and opinosis s rouge w f score is represent in we are getting high precision compare to mead and opinosis but microsoft system leading in rouge l rouge w rouge s rouge su only we are getting high recall comparison to mead in to and higher recall comparison to opinosis and microsoft in all measures except opinosis getting higher than our system measureuser method measureuser summary in figure we are representing comparison of different system generated summary length using measure and figure comparison of length summary and we representing here only f score from table we can say that mead system and microsoft performing better in term of recall but our system is performing better compare to opinosis our method getting higher precision compare to opinsis all rouge score p and higher precision achieved compare to mead except to we are getting low f score compare to mead and microsoft system but higher w opinosis figure f score summary figure f score summary experiment in this experiment we are showing the significance of sentiment feature the purpose of this experiment to show is really sentiment score performing a significant role in salient sentence extraction to generate a good quality summary of some words like words is a tedious task in our experiment we are taken five different features we tried all combination of all five features and using this combination we trying to prove this feature is playing a significant role in summarization if number of features are n then the total number of combination so in our experiment we are trying all combination calling approaches here we generate summary using single stand alone feature based summary and summary in which sentiment score is playing a role here first we generate approximate words summary to evaluate this summary we took three human generated summary as reference summary motivated by duc task we are evaluating only first words of the summary stands for tf idf feature stands for aggregate similarity score stands for position based stands for centroid based feature stands for sentiment based score feature showing collective score of tf idf aggregate similarity position based features table different rouge score for summary generated using different approaches here we are presenting different features combination to find a summary by seeing table we can see that position based feature approach highlighted in green is performing best among all but this is due to that in all three human reference summary out of summary are extractive type extractive type summary is available at address which are used for evaluation contains top sentences and which is almost words and the model which we are using for score position giving higher preference for leading sentences but as we know position based score ca perform well in all cases like in scientific article so we need some more features from table this is clear when we are taking sentiment feature i d along with other features we are getting improved summary more rouge score means more accurate summary the conclusion of this experiment is that out of approaches when sentiment feature added times we are getting improved summary by adding sentiment feature for example if we take collective features and by adding sentiment feature we are getting improved results highlighted in red color here position based feature performing best among all approaches the reason is given above and we ca depend only on position based feature so we need more features in approach i e aggregate and position when we add sentiment score done in approach i e highlighted in blue color the performance is reduced this be due to position based score not preferred i e position based feature is not dominating here as in approach results obtain from three human summary as reference summary and summary obtain from different approaches consider as system summary along with document are available at address to remove biasness and evaluate first world summary we use and to evaluate rouge w we have taken conclusion and future work in this work we are taken dataset designed by us we presented a hybrid text document summarization algorithm based on linear combination of different statistical measures and semantic measures in our hybrid approach we taken statistical measures like sentence position centroid tf idf as well as semantic approach doing sentiment analysis that is based on word level analysis sentiment score of a sentence is given as the sum of sentiment score of every entities present in a sentence we are getting three polarity for any entity like neutral negative and positive if entity sentiment is negative then we multiplying every score by to treat it as positive score the reason for doing this we wants to select a sentence in which strong sentiment is present it may be either negative or positive and both have same importance for us the significance contribution of sentiment score is presented in section we are not using any learning or brute force approach to deciding how much importance to given different measures or in other words we giving equal importance for each and every feature to calculate the score for a sentence we just add all the scores for every sentence and pick up a sentence based on highest score in next step we select next sentence based on next highest score and add it to the summary if the similarity between summary and sentence is lower that threshold to maintain redundancy and coverage we stop our algorithm when the desired length summary is found to generate several summaries of different length we used methods like mead microsoft opinosis and human and for evaluation different rouge score is used we done two experiment in first experiment we take our summary generate from algorithm described in section as system summary and all other as model summary and it have showed that we getting high precision almost every time that denotes we covered most relevant results in the second experiment we compare different system generated summary mead microsoft opinosis our algorithm to model summary human generated in this we find that our explained algorithm performed well for generated summary for almost every time but in mead system generate summary leading in some way but here also we getting higher recall compare to mead in third experiment section we have shown that when we are adding sentiment score as a feature we are getting improved results compare to without sentiment score third experiment is showing that sentiment score has contribution in extraction of more appropriate sentences limitation of our work that in step i e salient sentence extraction we are initializing two parameter desired summary length and similarity threshold we need to set very less if we set as or the sentences which came in summary only depends on the output of step which are not following one important property of summary that is coverage since we are using long stop word list and wants to follow coverage property we need to choose with precaution but we can put high if not using any stop word list in future we can use soft computing technique to learn different weights for different feature scores we can extend our approach to multi document summarization we can extend this experiment for benchmark dataset acknowledgement thanks to ugc for funding me to iskandar keskes miracl laboratory anlp research group tunisia to give me description about how to evaluate summary thanks to mr prem ayadav mr sarad ms payal biswas to generate extractive type summary from given document and ashish kumar all from sc ss ir lab jnu delhi to help me at several stages references radev d r hovy e mckeown k introduction to the special issue on summarization computational linguistics alguliev r m aliguliyev r m mehdiyev c a sentence selection for generic document summarization using an adaptive differential evolution algorithm swarm and evolutionary computation mani i maybury m t eds advances in automatic text summarization vol cambridge it press wan x wan using only cross document relationships for both generic and topic focused document summarizations information retrieval pp ko y seo j an effective sentence extraction technique using contextual information and statistical approaches for text summarization pattern recognition letters radev d r blair goldensohn s zhang z experiments in single and multi document summarization using mead ann arbor radev d r jing h stys m tam d centroid based summarization of multiple documents information processing management yeh j y ke h r yang w p meng i h text summarization using a trainable summarizer and latent semantic analysis information processing management aliguliyev r m automatic document summarization by sentence extraction hovy e lin c y october automated text summarization and the summarist system in proceedings of a workshop on held at baltimore maryland october pp association for computational linguistics luhn h p the automatic creation of literature abstracts ibm journal of research and development baxendale p b machine made index for technical literature an experiment ibm journal of research and development edmundson h p new methods in automatic extracting journal of the acm jacm das d martins a f a survey on automatic text summarization literature survey for the language and statistics ii course at cmu ganapathiraju m k relevance of cluster size in mmr based summarizer a report advisors carbonell j and yang y ouyang y li w li s lu q applying regression models to query focused multi document summarization information processing management carbonell j goldstein j august the use of mmr diversity based reranking for reordering documents and producing summaries in proceedings of the annual international acm sigir conference on research and development in information retrieval pp acm alguliev r m aliguliyev r m hajirahimova m s mclr generic document summarization based on maximum coverage and less redundancy expert systems with applications alguliev r m aliguliyev r m isazade n r cdds constraint driven document summarization models expert systems with applications lee m c a novel sentence similarity measure for semantic based expert systems expert systems with applications bollegala d okazaki n ishizuka m a bottom up approach to sentence ordering for document summarization information processing management sarkar syntactic trimming of extracted sentences for improving extractive multi document summarization journal of computing vol pp goldstein j mittal v carbonell j callan j november creating and evaluating multi document sentence extract summaries in proceedings of the ninth international conference on information and knowledge management pp acm alguliev r m aliguliyev r m hajirahimova m s mehdiyev c a mcmr maximum coverage and minimum redundant text summarization model expert systems with applications lin c y july rouge a package for automatic evaluation of summaries in text summarization branches out proceedings of the workshop pp kim j h kim j h hwang d november korean text summarization using an aggregate similarity in proceedings of the fifth international workshop on information retrieval with asian languages pp acm mani i maybury m t eds advances in automatic text summarization vol cambridge normalization n in wikipedia retrieved jan from wikipedia org mit press ganesan k zhai c han j august opinosis a graph based approach to abstractive summarization of highly redundant opinions in proceedings of the international conference on computational linguistics pp association for computational linguistics uttrakhand flood n in wikipedia retrieved jan from wikipedia org yadav c s sharan a joshi m l semantic graph based approach for text mining in issues and challenges in intelligent computing techniques icict international conference on pp ieee yadav c s sharan a kumar r biswas p july a new approach for single text document summarization in international conference on computer and communication technology t aisc series accepted springer oracle n full text stopwords retrieved from mysql com doc en sankarasubramaniam y ramanathan k ghosh s text summarization using wikipedia information processing management precision and recall n in wikipedia retrieved date jan from wikipedia org stopwords html chandra shekhar april in google drive retrieve april google com
