published conference paper iclr structured neural summarization patrick fernandes carnegie mellon university lisbon portugal cmu edu miltiadis allamanis marc brockschmidt microsoft research cambridge united kingdom miallama com abstract summarization long sequences concise statement core problem ural language processing requiring non trivial understanding input based promising results graph neural networks highly structured data velop framework extend existing sequence encoders graph component reason long distance relationships weakly structured data text extensive evaluation resulting hybrid sequence graph models outperform pure sequence models pure graph models range summarization tasks introduction summarization task condensing large complex input smaller representation retains core semantics input classical task natural language processing systems automatic summarization requires machine learning component identify important entities relationships ignoring redundancies common concepts current approaches summarization based sequence sequence paradigm words text sequence encoder typically recurrent neural network cnn narayan self attention mccann processing input sequence decoder generating output recent successful implementations paradigm substantially improved performance focusing decoder extending attention mechanism input sequence copying facilities mccann standard encoders bidirectional lstms theoretically ability handle arbitrary long distance relationships practice fail correctly handle long texts easily distracted simple noise jia liang work focus improvement sequence encoders compatible wide range decoder choices mitigate long distance relationship problem draw inspiration recent work highly structured objects kipf welling gilmer allamanis cvitkovic line work highly structured data entity relationships molecules programs modelled graphs graph neural networks successfully applied directly learn graph representations propose extend idea weakly structured data natural language existing tools annotate accepting noise data additional relationships references obtain graph sequential aspect input data rich meaning propose hybrid model standard sequence encoder generates rich input graph neural network experiments resulting combination outperforms baselines use pure sequence pure graph based representations briey contributions work framework extends standard sequence coder models graph component leverages additional structure sequence data plication extension range existing sequence models extensive evaluation summarization tasks literature release code data com coderpat structured neural summarization data available derived allamanis work working microsoft research cambridge published conference paper iclr public void object value null dbtype dbtype null parameterdirection direction null int size null byte precision null byte scale null new paraminfo value value parameterdirection direction parameterdirection input dbtype dbtype size size precision precision scale scale ground truth lstm bilstm lstm add parameter dynamic parameter list adds new parameter specied parameter creates new instance dynamic type specied add parameter list parameters figure example dataset methoddoc source code summarization task outputs baseline models methodnaming dataset method appears sample requiring predict add subtoken sequence length structured summarization tasks work consider summarization tasks different properties tasks follow common pattern translating long structured sequence shorter sequence trying preserve meaning possible rst tasks related summarization source code figure highly structured prot models advantage structure nal task classical natural language task illustrating hybrid sequence graph models applicable structured inputs methodnaming aim task infer function method oriented languages java python given source code allamanis method names single token usually composed subtokens split snake case camelcase method naming task cast ing sequence subtokens consequently method names represent extreme summary functionality given function average names java dataset subtokens notably vocabulary tokens names large abbreviations specic mitigated fact subtokens names copied directly subtokens method source code finally source code highly structured input data known semantics exploited support prediction methoddoc similar rst task aim task predict succinct description functionality method given source code barone sennrich descriptions usually appear documentation methods docstrings python javadocs java task shares characteristics methodnaming task target sequence substantially longer average tokens dataset tokens umentation copied code method documentation nearer standard natural language method names mixes project specic jargon code segments describes non functional aspects code performance characteristics design considerations nlsummarization finally consider classic summarization natural language widely studied nlp research specically interested abstractive summarization given text input news article machine learning model produces novel natural guage summary traditionally nlp summarization methods treat text sequence sentences sequence words tokens input data explicitly dened structure rst tasks recast task structured summarization lem considering additional linguistic structure including named entities entity coreferences inferred existing nlp tools published conference paper iclr model discussed standard neural approaches summarization follow sequence sequence framework setting decoders require representation complete sequence nal state rnn token representations hti input token token representations memories attention nism bahdanau luong pointer network vinyals work propose extension sequence encoders allows leverage known inferred relationships elements input data achieve combine sequence encoders graph neural networks gnns gilmer kipf welling rst use standard sequential encoder bidirectional rnns obtain token representation hti feed gnn initial node representations resulting node token representations unmodied decoder experimentally found surpass models use sequential structure graph structure sect discuss different parts model detail gated graph neural networks process graphs follow briey rize core concepts ggnns graph composed set nodes node features list directed edge sets number edge types associated real valued vector representing features node embedding string label node initial state node information propagated graph neural message passing gilmer node sends messages neighbors transforming current representation edge type dependent function arbitrary function use simple linear layer computing messages time states updated neously particular new state node computed aggregating incoming messages edge type aggregation function use elementwise summation given aggregated message current state vector node compute new state gru recurrent cell function gated recurrent unit dynamics rolled xed number timesteps state vectors resulting nal step output node representations sequence gnns explain novel combination ggnns standard sequence coders input sequence binary relationships elements sequence example equality relationship choice construction relationships dataset dependent discussed detail sect given sequence encoder maps element representations sequence representation bidirectional rnn construct quence gnn simply computing obtain graph level representation use weighted averaging mechanism gilmer concretely node graph compute weight ing learnable function logistic sigmoid compute graph level representation learnable projection function found best results achieved computing nal learnable matrix method easily extended support additional nodes present original sequence running accommodate meta nodes representing sentences non terminal nodes syntax tree initial node representation additional nodes come sources simple embedding label implementation details processing large graphs different shapes efciently requires come engineering challenges example cnn corpus average nodes graph allow efcient computation use trick allamanis graphs minibatch attened single graph multiple disconnected components varying graph sizes represent problem attention copying mechanisms published conference paper iclr decoder require compute softmax variable sized list memories handle efciently padding associate node attened batch graph index sample minibatch node originated tensorflow unsorted segment operations perform efcient numerically stable softmax variable number representations nodes graph evaluation quantitative evaluation evaluate sequence gnns tasks comparing models use quence graph information comparing task specic baselines discuss tasks respective baselines present data models including relationships considered graph component analyzing results setup methodnaming datasets metrics models consider datasets methodnaming task consider java small dataset alon train validation test splits picked additionally generated new dataset open source projects mined github reasons second dataset removing duplicates information datasets found appendix follow earlier work naming allamanis alon measure performance score generated subtokens task viewed form extreme marization report rouge scores lin believe additional useful indicators quality results omitted equivalent score note widely accepted metric task work identifying appropriate metric required compare current state art alon sequence sequence implementation opennmt project klein concretely combine encoders bidirectional lstm encoder layer hidden units sequence gnn sion hidden units unrolled timesteps decoders lstm decoder layer hidden units attention input sequence extension pointer network style copying mechanism vinyals additionally consider attention alternative rnn based sequence encoding architectures use transformer vaswani implementation opennmt self attention decoder encoder baseline compare version encoder extended gnn component data representation following work allamanis alon break identier tokens variables methods classes source code subtokens splitting according camelcase pascal case heuristics allows models extract information information rich subtoken structure ensures copying anism decoder directly copy relevant subtokens found fective task models provided belonging source code method including declaration actual method replaced placeholder symbol construct graph implement simplied form work allamanis introduce additional nodes identier token nect constituent subtokens appearing input sequence intoken edge ally connect nodes nexttoken edge add nodes parse tree use edges indicate node child finally add lastlexicaluse edges connect identiers lexically recent use source code setup methoddoc datasets metrics models tried evaluate python dataset barone sennrich contains pairs method declarations documentation docstring published conference paper iclr sentence munster signed new zealand international francis saili year deal person person country person duration utility saili sentence token entity ref figure partial graph example input cnn corpus following work lopes found extensive duplication different folds dataset able reach comparable results substantially overtting training data overlapped test set documented details subsection allamanis decided instead evaluate new dataset open source projects removing duplicates methods documentation following barone sennrich measure bleu score models report rouge scores better reect summarization aspect task consider models methodnaming task conguration use data representation setup nlsummarization datasets metrics models use cnn dataset hermann exact data split provided data constructed cnn daily mail news articles sentences summarize article measure performance use standard rouge metrics compare model near state art work use sequence sequence model attention copying basis additionally substantially improved decoder component contribution entirely encoder model uses standard sequence decoder expecting outperform recent models introduce substantial novelty structure training objective decoder chen bansal narayan evaluate contribution opennmt based encoder decoder combination concretely use bidirectional lstm encoder layer hidden units sequence gnn extension hidden units unrolled timesteps decoder use lstm layer hidden units attention input sequence extension pointer network style copying mechanism data representation use stanford corenlp manning version enize text provide resulting tokens encoder graph construction figure extract named entities run coreference resolution corenlp connect tokens ing edge introduce additional super nodes sentence connecting token corresponding sentence node edge connect subsequent sentence nodes edge multi token named entity create new node labeling type entity connecting tokens referring entity edge finally coreferences entities connected special ref edge figure shows partial graph article cnn dataset goal graph construction process explicitly annotate important relationships useful summarization note early efforts experimented adding dependency parse edges found provide signicant benets retrieve annotations corenlp contain errors performance method inuenced accuracy upstream annotators named entities coreferences published conference paper iclr table evaluation results models tasks rouge methodnaming java alon selfatt selfatt selfatt lstm bilstm lstm bilstm gnn selfatt selfatt selfatt lstm bilstm lstm bilstm gnn methoddoc selfatt selfatt selfatt lstm bilstm lstm bilstm gnn nlsummarization cnn lstm bilstm lstm pointer bilstm pointer coverage results analysis rouge bleu average pooling rouge results tab results models literature taken respective papers repeated tasks results advantage hybrid sequence gnn encoders pure sequence encoders methodnaming gnn augmented models able outperform rent specialized state art requiring simple graph structure easily obtained existing parsers programming language results performance ent encoder decoder congurations nicely effects largely orthogonal methoddoc unmodied selfatt selfatt model performs augmentation graph data improves bleu score worsens results rouge inspection results shows length predictions ground truth data average tokens result selfatt selfatt predicts average tokens selfatt tokens additionally experimented ablation model graph information setting comparable simplication architecture allamanis congured gnn use dimensional representations unrolled timesteps keeping decoder conguration models results indicate conguration performs pure sequenced model speculate mainly fact timesteps insufcient propagate published conference paper iclr table ablations cnn corpus nlsummarization cnn base pointer pointer coverage lstm coref entity annotations bilstm bilstm bilstm lstm sentence nodes sentence nodes edges rouge public static bool value span byte destination int byteswritten standardformat format default return tryformatfloatingpoint destination byteswritten format ground truth lstm bilstm lstm formats single string formats number bytes string formats timespan string formats oat string figure example dataset methoddoc source code summarization task outputs baseline models mation graph especially combination summation aggregation function messages graph information propagation finally nlsummarization experiments model suitable tasks highly structured code competitive specialized models natural language tasks gap best conguration larger recent work area believe entirely simplistic decoder training objective contribution combined advances table ablations nlsummarization use ters datasets tasks additionally perform experiment model implemented opennmt settings results achieved lines trend bit worse results reported original paper believe lack hyperparameter optimization task evaluated ditional linguistic structure provided corenlp helps add coreference entity annotations baseline bilstm lstm pointer model extending embedding tokens embedding entity information inserting fresh tokens sources targets references observe minimal improvements suggests graph based encoder better suited exploit additional structured information compared bilstm encoder drop linguistic structure information model keeping sentence edges nodes improves baseline bilstm model score suggesting gnn yields improvements absence linguistic structure finally add long range dependency edges connecting tokens equivalent string representations stems observe minor improvements indicating purely syntactical information semantic parse provide gains qualitative evaluation look sample suggestions dataset tasks highlight vations point interesting aspects failure cases model published conference paper iclr input arsenal newcastle united southampton checked caen midelder ngolo kante born kante defensive minded player impressed caen season willing sell marseille constant contact caen signing year old similarities lassana diarra claude makelele terms stature style ngolo kante attracting interest host premier league clubs including arsenal caen willing sell kante reference ngolo kante wanted arsenal newcastle southampton marseille keen rated midelder kante compared lassana diarra claude makelele click latest premier league news pointer arsenal newcastle united southampton checked caen midelder ngolo kante paris born kante attracting interest host premier league clubs including arsenal paris born kante attracting interest host premier league clubs including arsenal pointer coverage arsenal newcastle united southampton checked caen midelder ngolo kante paris born kante defensive minded player impressed caen season marseille constant contact caen signing year old lstm marseille linked caen midelder marseille interested host premier league clubs including arsenal caen interested host premier league clubs including arsenal ngolo kante attracting interest host premier league clubs marseille constant contact caen signing year old year old similarities lassana diarra claude makelele terms stature figure sample natural language translations cnn dataset methoddoc figures illustrate typical results baselines model methoddoc task appendix examples hardness task stems large number distractors need identify relevant parts input figure token parameter variations appears times identifying correct relationship non trivial evidently eased graph edges explicitly denoting relationships similarly figure variables passed semantics method require understanding information ows nlsummarization figure shows sample summarization samples task found appendix notice model produces natural looking summaries noticeable negative impact uency language existing methods gnn based model capture central named entity article creates summary centered entity hypothesize gnn component links distance relationships helps capture maintain better global view article allowing better identication central entities model suffers repetition information appendix believe model prot advances taking erage account optimizing rouge scores directly reinforcement learning chen bansal narayan related work natural language processing research studied summarization long time related work abstractive summarization core content given text usually news article summarized novel concise sentence chopra nallapati use deep learning models attention input text guide decoder generates summary mccann extend idea pointer networks vinyals allow copying tokens input text output summary approaches treat text simple token sequences explicitly exposing additional structure principle deep sequence networks known able learn inherent structure natural language parsing vinyals entity recognition lample experiments indicate explicitly exposing structure separating concerns improves performance published conference paper iclr recent work summarization proposed improved training objectives summarization tracking coverage input document reinforcement learning directly identify actions decoder improve target measures rouge chen bansal narayan objectives orthogonal graph augmented encoder cussed work interested combining efforts future work exposing language structure explicitly studied years focus based models tai recently rst uses graphs natural language processing explored marcheggiani titov use graph convolutional networks encode single sentences assist machine translation cao create graph named entities set documents assist question answering closer work work liu use abstract meaning representation amr source document rst parsed amr graphs summary graph created nally rendered natural language contrast work use amrs directly encode relatively simple relationships directly tokenized text treat summarization graph rewrite problem combining encoder amrs use richer graph structures promising future direction finally summarization source code studied forms method naming ment documentation prediction method naming tackled series models example allamanis use log bilinear network predict method names features later extend idea use convolutional attention network tokens method dict subtokens names allamanis raychev bichsel use crfs range tasks source code including inference names variables methods recently alon extract encode paths syntax tree gram setting state art accuracy method naming linking text code useful applications code search ity guo detection redundant method comments louis proaches source code treat natural language token sequence use language parser explicitly expose tree structure example barone sennrich use simple sequence sequence baseline summarize source code linearizing abstract syntax tree code sequence sequence model wan instead directly operate tree structure tree recurrent neural networks tai use additional structure related tasks source code studied recently example models conditioned learned traversals syntax tree bielik based approaches allamanis cvitkovic noted liao gnn based approaches suffer tension ability propagate information large distances graph computational expense propagation function linear number graph edges propagation step discussion conclusions presented framework extending sequence encoders graph component age rich additional structure evaluation different summarization tasks shown augmentation improves performance range different sequence models tasks excited initial progress look forward deeper integration mixed sequence graph modeling wide range tasks formal natural languages key insight believe widely applicable inductive biases induced explicit relationship modeling simple way boost practical performance existing deep learning systems published conference paper iclr references miltiadis allamanis adverse effects code duplication machine learning models code arxiv preprint miltiadis allamanis earl barr christian bird charles sutton suggesting accurate method proceedings joint meeting foundations software class names engineering acm miltiadis allamanis hao peng charles sutton convolutional attention network extreme summarization source code international conference machine learning miltiadis allamanis marc brockschmidt mahmoud khademi learning represent programs graphs international conference learning representations uri alon meital zilberstein omer levy eran yahav general path based representation proceedings acm sigplan conference predicting program properties programming language design implementation acm uri alon omer levy eran yahav generating sequences structured tions code international conference learning representations dzmitry bahdanau kyunghyun cho yoshua bengio neural machine translation jointly learning align translate arxiv preprint antonio valerio miceli barone rico sennrich parallel corpus python functions mentation strings automated code documentation code generation proceedings eighth international joint conference natural language processing volume short papers volume benjamin bichsel veselin raychev petar tsankov martin vechev statistical deobfuscation android applications proceedings acm sigsac conference computer communications security acm pavol bielik veselin raychev martin vechev phog probabilistic model code tional conference machine learning icml yen chun chen mohit bansal fast abstractive summarization reinforce selected sentence rewriting arxiv preprint sumit chopra michael auli alexander rush abstractive sentence summarization attentive recurrent neural networks proceedings conference north american chapter association computational linguistics human language technologies milan cvitkovic badal singh anima anandkumar deep learning code unbounded vocabulary machine learning programming nicola cao wilker aziz ivan titov question answering reasoning documents graph convolutional networks arxiv preprint justin gilmer samuel schoenholz patrick riley oriol vinyals george dahl neural message passing quantum chemistry international conference machine learning xiaodong hongyu zhang sunghun kim deep code search proceedings international conference software engineering acm jin guo jinghui cheng jane cleland huang semantically enhanced software traceability deep learning techniques software engineering icse ieee acm international conference ieee published conference paper iclr karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa leyman phil blunsom teaching machines read comprehend advances neural information processing systems xing yuhan wei zhi jin codesum translate program language natural language arxiv preprint robin jia percy liang adversarial examples evaluating reading comprehension systems empirical methods natural language processing emnlp thomas kipf max welling semi supervised classication graph convolutional works international conference learning representations klein kim deng senellart rush open source toolkit neural machine translation arxiv prints guillaume lample miguel ballesteros sandeep subramanian kazuya kawakami chris dyer neural architectures named entity recognition proceedings north american chapter association computational linguistics human language technologies yujia daniel tarlow marc brockschmidt richard zemel gated graph sequence neural networks arxiv preprint renjie liao marc brockschmidt daniel tarlow alexander gaunt raquel urtasun richard zemel graph partition neural networks semi supervised classication international ference learning representations iclr workshop track chin yew lin rouge package automatic evaluation summaries text summarization branches fei liu jeffrey flanigan sam thomson norman sadeh noah smith abstractive summarization semantic representations arxiv preprint cristina lopes petr maj pedro martins vaibhav saini yang jakub zitny hitesh sajnani jan vitek map code duplicates github proceedings acm programming languages annie louis santanu kumar dash earl barr charles sutton deep learning detect dant method comments arxiv preprint minh thang luong hieu pham christopher manning effective approaches based neural machine translation arxiv preprint christopher manning mihai surdeanu john bauer jenny finkel steven bethard david closky stanford corenlp natural language processing toolkit proceedings annual meeting association computational linguistics system demonstrations diego marcheggiani ivan titov encoding sentences graph convolutional networks semantic role labeling proceedings conference empirical methods natural language processing bryan mccann nitish shirish keskar caiming xiong richard socher natural language decathlon multitask learning question answering arxiv preprint ramesh nallapati bowen zhou cicero dos santos caglar gulcehre bing xiang abstractive proceedings text summarization sequence sequence rnns signll conference computational natural language learning shashi narayan shay cohen mirella lapata ranking sentences extractive summarization reinforcement learning arxiv preprint veselin raychev martin vechev andreas krause predicting program properties big code principles programming languages popl published conference paper iclr abigail peter liu christopher manning point summarization generator networks proceedings annual meeting association tional linguistics volume long papers volume kai sheng tai richard socher christopher manning improved semantic representations tree structured long short term memory networks ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan gomez ukasz kaiser illia polosukhin attention need advances neural information cessing systems oriol vinyals meire fortunato navdeep jaitly pointer networks advances neural mation processing systems oriol vinyals lukasz kaiser terry koo slav petrov ilya sutskever geoffrey hinton grammar foreign language advances neural information processing systems yao wan zhou zhao min yang guandong haochao ying jian philip improving automatic source code summarization deep reinforcement learning proceedings acm ieee international conference automated software engineering acm published conference paper iclr code summarization samples methoddoc sample result null try public static bool valuetoconvert type resulttype iformatprovider formatprovider object result result resulttype formatprovider catch invalidcastexception return false catch argumentexception return false return true ground truth lstm bilstm lstm sample sets result valuetoconvert converted resulttype considering formatprovider custom conversions calling parse method calling convert changetype converts specied type primitive type sets result resulttype sets result valuetoconvert converted resulttype public virtual task iproviderruntime providerruntime iproviderconfiguration config log providerruntime gettype fullname serializersettings orleansjsonserializer getdefaultserializersettings return taskdone ground truth lstm bilstm lstm initializes storage provider creates grain object initializes provider provider initialization function initialize specied provider sample public void nullparameter taskparameter new assert wrappedparameter assert equal taskparametertype null parametertype inodepackettranslatable translate translationhelpers getwritetranslator taskparameter taskparameter factoryfordeserialization translationhelpers getreadtranslator assert wrappedparameter assert null parametertype ground truth lstm bilstm lstm veries construction serialization null parameter tests value value value specied type veries construction parameter parameter veries construction serialization parameter null sample public override dbgeometrywellknownvalue geometryvalue geometryvalue var spatialvalue geometryvalue dbgeometrywellknownvalue result spatialexceptions spatialexceptions srid wkb wkt new dbgeometrywellknownvalue coordinatesystemid srid wellknownbinary wkb wellknowntext wkt creates instance system data spatial dbgeometry value standard known spatial formats creates system data spatial dbgeography value based known binary value creates new system data spatial dbgeography instance specied known spatial formats creates new instance system data spatial dbgeometry value based provided geometry value returns resulting known spatial formats published conference paper iclr return result ground truth bilstm lstm lstm methodnaming sample public bool return null val val ground truth lstm bilstm lstm equals foo equals equals sample object obj null int value int obj internal void string switchname hashtable bag string parametername value invariantculture ground truth lstm bilstm lstm append switch integer set string append switch append switch null sample internal static string var currentplatformstring string runtimeinformation windows currentplatformstring windows runtimeinformation linux currentplatformstring linux runtimeinformation osx currentplatformstring osx assert unrecognized current platform return currentplatformstring published conference paper iclr ground truth lstm bilstm lstm platform string platform current platform string sample public override dbgeometrywellknownvalue geometryvalue geometryvalue var spatialvalue geometryvalue dbgeometrywellknownvalue result spatialexceptions spatialexceptions srid wkb wkt new dbgeometrywellknownvalue coordinatesystemid srid wellknownbinary wkb wellknowntext wkt return result ground truth lstm bilstm lstm create known value spatial geometry xml geometry point known value java sample public static void string int expected metricsrecordbuilder assert value metric expected ground truth lstm bilstm lstm assert counter assert email value assert header assert int counter published conference paper iclr natural language summarization samples input cnn gunshots red rapper lil wayne tour bus early sunday atlanta injured shooting arrests atlanta police spokeswoman elizabeth espy said police looking suspects ofcers called parking lot atlanta buckhead neighborhood espy said arrived cated tour buses shot multiple times drivers buses said incident occurred interstate near interstate espy said witnesses provided limited description vehicles suspected involved corvette style vehicle suv lil wayne atlanta performance compound nightclub saturday night cnn carma hassan contributed report reference rapper lil wayne injured shots red tour bus atlanta interstate police arrested shooting pointer police looking suspects incident occurred interstate near interstate police witnesses provided limited description vehicles suspected involved corvette style vehicle suv pointer coverage lil wayne tour bus shot multiple times police police looking suspects arrived located tour buses shot lstm incident occurred interstate near interstate injured shooting arrests atlanta police spokeswoman says gunshots red rapper lil wayne tour bus early sunday atlanta police injured shooting arrests police input tottenham held discussions marseille potential deal midelder florian thauvin year old left squad weekend game metz marseille push sale winger play striker subject enquiries spurs earlier year watched chelsea valencia tottenham held talks ligue marseille possible deal florian thauvin marseille resigned losing andre ayew andre pierre gignac english sides keen everton newcastle swansea shown interest ayew free agent summer reference orian thauvin left marseille squad metz marseille pushing sale tottenham interested winger watched chelsea liga valencia pointer tottenham held discussions marseille potential deal midelder orian thauvin year old left squad weekend game metz marseille push sale pointer coverage orian thauvin left squad weekend game metz marseille push sale year old subject enquiries spurs earlier year lstm year old left squad weekend game metz year old left squad weekend game metz winger left squad weekend game metz tottenham held discussions marseille potential deal winger left squad weekend game tottenham held talks marseille potential deal published conference paper iclr code datasets information dataset extract dataset open source projects github overall dataset contains methods documentation comment dataset split projects exact state repositories listed table table projects dataset ordered alphabetically git sha description actor based concurrent distributed framework object object mapping library benchmarking library akka net automapper benchmarkdotnet commonmark net markdown parser coreclr corefx dapper entityframework humanizer lean mono msbuild nancy nlog opserver orleans polly powershell ravendb roslyn servicestack signalr wox net core runtime net foundational libraries object mapper library object relational mapper string manipulation formatting algorithmic trading engine net implementation build engine http service framework logging library monitoring system distributed virtual actor model resilience transient fault handling library command line shell document database compiler code analysis compilation real time web library push notication framework application launcher java method naming datasets use datasets splits alon provided website scanning methods dataset size corpora seen table information found alon python method documentation dataset use dataset split barone sennrich provided github repository parsing dataset training samples validation samples test ples note documentation samples validation set ples test set sample identical natural language documentation training table statistics extracted graphs java method naming dataset alon dataset train size valid size test size java small published conference paper iclr set eludes potential issue described lopes allamanis lengthier discussion issue graph data statistics present data characteristics graphs use datasets table graph statistics datasets dataset avg num nodes avg num edges cnn method names documentation java small method names
