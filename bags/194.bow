framerank text processing approach video summarization zhuo chao qian guoping doctoral innovation center computer science university nottingham ningbo china information engineering guangdong key lab intellignet information processing shenzhen university china computer science university nottingham uk zhuo lei chao zhang qian edu cn guoping ac uk r l c s c v v x r abstract video summarization extensively studied past decades user generated video summarization explored lack large scale video datasets human generated video summaries biguously dened annotated end pose user generated video summarization dataset consists videos minutes structing dataset subjectivity generated video summarization manually annotate summaries video total summaries best knowledge currently largest dataset user generated video summarization based dataset present framerank pervised video summarization method employs frame level afnity graph identify coherent mative frames summarize video use based graph rank temporal ments according semantic information tained frames illustrate effectiveness method applying datasets summe tvsum achieves state art results index terms video summarization unsupervised learning framerank kl divergence graph introduction user generated video growing exponentially demand efcient ways searching retrieving desired content cost huge amounts resources like time man resources machine congurations users think little time spending cutting content view selection user generated videos consist long including illumination shakiness dynamic background unedited contents text video summarization plays important role assisting users quickly browse important events contained recently video summarization techniques drawn lot attention especially user generated videos fig overview proposed framework essential user generated video summarization identify important parts original videos dene importance insufciency publicly available datasets limited important line research tivity human generated summaries needed meet purpose training evaluation different generated video summarization methods help alleviate introduce new dataset contains videos covering user generated contents human generated video summaries challenge standard criteria ing importance humans agree universal sis generating video summary paper consider frame importance ones substitute based dataset propose novel pervised framework user generated video summarization identies coherent informative video frames summarize video shown figure rst divide original video disjoint segments dense based clustering method develop graph based ranking method framerank score rank ments according semantic information table comparison existing datasets summe tvsum dataset ute static video dynamic video egocentric video total frame avg frame total video length s avg video length s avg mary video f score avg cronb n n n nally sample video segments high scores ate video summaries systematic experiments evaluation proposed novel video summarization method effective outperforms state art methods new dataset existing datasets summe tvsum main tions followings introduce new dataset user generated video summarization best knowledge largest user generated video tion dataset able meet purpose training ation different methods develop new method framerank assess importance video frames proposed novel approach video temporal segmentation segments semantically consistent ate produce good video summaries related work datasets facilitate comparison datasets dataset table dataset ics noted annotation information ute available apply human generated video summaries conduct evaluation asking question participants generally speaking previous datasets greatly boosted researches user generated video marization drawbacks video types insufcient second multiple human generated video summaries video necessary tivity datasets cover abundant categories user generated video summarization works attempt assess importance interestingness video frames supervised methods trained model according signicant interaction people jects learn saliency egocentric videos built links objects create story driven summaries grounded s egocentric feature combined multiple tures train regressor predict interestingness devised steam deep convolutional neural network cnn chitecture fusing spatial temporal information tively steam video highlight detection learned non parametrically transfer summary structures ing videos test ones improved long term memory lstm model variable range ral dependency video frames general supervised methods require large training data lacking eld existing datasets able cover variety user generated videos users interested exactly dened human generated summaries labor intensive time consuming requires multiple summaries single video subjectivity learned models portable work user generated videos unsupervised methods forward generated video summarization detail methods use types intuitive criteria pre trained models elds facilitate assessment importance estingness video frames video s title keywords query obtained canonical viewpoints collected website predict important frames achieve tion employed auto encoder train internet videos topic assessed importance cording reconstruct input video s feature utilized linear svm classier obtain condence event type importance scores tant frames effectively predicted methods work domain specic videos require metadata videos retrieving images videos sive collected metadata relevant correct benchmark dataset user generated video summarization relatively plored domain public datasets ple human generated summaries available lected new dataset contains videos human annotated summaries video collection collected videos captured youtube recorded multiple ways including static dynamic egocentric views duration ranges minutes raw minimally edited group video frames disjoint segments semantically consistent frames second rank segments ing semantic information contained frames graph based framerank finally apply greedy selection strategy generate nal summaries video temporal segmentation comparing divide videos temporal tation method based clustering deep semantic ity graph general connection frames sidered graph vertexes refers video frames edges pairwise similarities initial idea transfer video text form text summarization image tagging image caption open areas correctly classied bels difcult precisely represent semantic content video frames frame contents different labels convey tic information effectively decide use probability detail distribution set labels denote frame feed video frames deep cnn pre trained ages object categories imagenet dataset compute probabilities frames containing objects representation enjoys advantage capturing information presence variety object categories choose kl divergence measure frame represent measurement difference probability distributions information loss distribution proximate distribution interpreted frame contains semantic information fig comparison segments temporal constraint factor vertical axis segment indexes negative represent generated segment indexes temporal order factor positive represent ones temporal order factor horizontal axis temporal order construct graph w v fi texes w edges vertex fi fj edge wij kl divergence computed follows fig videos represented thumbnails collected videos encompassing user generated contents like holidays events sports compared datasets videos categories generated summaries figure shows thumbnails video annotation subjectivity user generated video tion impossible obtain absolute ground truth bels evaluation carried multiple human judgment asked participants collect human generated summaries videos shown participants random order playing speed second frame participants asked watch entire video single provide time slots generate video summary muted audio ensure scores based solely visual stimuli different annotations video taking hours following calculated average wise score collected human ground truth score approximately close summe tvsum dataset puted cronbach standard measure assess reliability psychometric test dataset mean minimum value mum value cronbach summe tvsum datasets respectively ideally considered acceptable exploratory searches dataset video summarization experiments carried condence provide list videos including camera type frame number video length average summary length average score cronbach supplementary material proposed framework proposed framework consists main steps shown figure inputs user generated video output video summary construct graph vertex corresponding frame edge vertexes kl divergence frames semantic probability butions use bundling center clustering algorithm log pfj k j frame indexes means element wise multiplication represents probability label frame fi negate values transfer difference ilarity normalize matrix g addition w constrained graph gaussian function maintain poral order smooth frame difference w w ij edges frames vertex represented w ij e control parameter modify temporal tion smoothness level temporally constrained graph g tc represented g tc g g furthermore cluster center multiple similar frames single denoted bundling center dense neighbor based clustering method identify local clusters based edge connectivity g tc noted elements local cluster locally similar elements inside neighborhood instead close single element details referred examples comparison results temporal constraint factor figure segment selection framerank difculty video summarization dene tant frames segments compose summary standard criteria measuring importance video ments human subjects agree universal sis good summary concise retain informative signicant contents words selected frames segments compose summary able represent unselected ones possible paper dene important frames ones substitute information loss described section w develop framerank method works similarly trank text ranking method natural language ing build graph vertices corresponding video frames edges measure similarity frames implement graph ranking technique measure ative importance video frame segment calculate importance score vertex fi d fj wji wjl damping factor plays role integrating model probability ing given vertex random vertex graph detail damping factor d interpreted dom suffer changing visual contents caused sudden camera moving case user generated videos following set d running algorithm starts arbitrary ues assigned vertex graph iterates implementation stop iteration convergence importance scores consecutive iterations given threshold let score tex fi iteration k iteration stops kth iteration pre set threshold algorithm converges vertex score resenting importance video frames associated vertex nal importance scores vertices erank dependent initial values number iterations converge different related work tried estimate score ment summing frame importance scores result longer segments getting larger importance scores compute relative importance score segment sn average importance tstart tstart tend tstart tend start end frames segment video summary generation generate video summary selecting video segments substitute information loss given set importance scores want nd subset segments total length pre dened imum l total importance scores maximized words want solve optimization problem max s t l xn indicates segment selected assumption independence scores maximization standard knapsack problem greedy selection strategy furthermore generated videos rarely contain redundant interesting events account redundancy diversity evaluation discussion demonstrate effectiveness proposed video marization approach evaluated compared state art methods carried experiments video datasets summe interestingness modular dpp video mmr tvsum web image prior livelight dpplstm random form following compute f socre man summaries evaluation according temporal overlap comparing computed ones table compare approach state art methods summe tvsum ugsum datasets dataset method f score fig quantitative results different features larity measurement interestingness submodular dpp vslstm dpplstm video mmr framerank livelight web image prior tvsum vslstm dpplstm framerank random uniform framerank framerank summe tvsum ugsum results table summarizes performance methods trasts attained prior work highlighted bers indicate framerank obtains best performance corresponding setting achieve highest overall f score summe dataset tvsum dataset previous state art published spectively furthermore carry experiments dataset superior methods f score shows fectiveness proposed framerank method reliability proposed temporal segmentation method comparing framerank uniform framerank methods proves method able nd important segments produce informative summary results demonstrate proposed method create video summaries closer human level performance methods interesting result better supervised methods analyze standard rules dene important content summarize video human generated summaries different different human perception personal experience believe training data user generated video tion sufcient supervised methods ated model able characterize property marize videos tvsum slightly different summe contains egories videos theory characteristic sum suitable supervised methods learn video structure framerank performs better fore reasons believe good unsupervised method appropriate user generated video summarization analysis discussion temporal video segmentation analyze performance gained different temporal segmentation methods figure compare kl divergence based temporal tation approach following methods joint temporal segmentation jts uniform segmentation based temporal segmentation kts superframe motion based temporal segmentation keyframe marization highest scored frames disregarding temporal segment process employ segment selection method framerank summary generation method figure shows temporal segmentation method yields better performance demonstrates signicance structural analysis video summarization based summarization better keyframes lieve summarization annotation segment based frame based expensive difcult participants scores individual frames fact ticipants required select segment tation nd approach greater vantage summe datasets close sults tvsum caused similar videos demonstrates segment based summary better agreement human perception produces reasonable maries segments contain motion information paring keyframes furthermore demonstrates approach cluster semantically similar frames matches ter human perception shows grouping semantically logical tal results prove superiority segmentation approach capable generating meaningful summaries feature similarity metrics investigate portance reliability different features similarity metrics framerank approach figure performance gained different features deep visual feature deep semantic feature label embedding label different similarity metrics euclidean cosine kl vergence label overlap label overlap textrank expected deep semantic features kl y j lee j ghosh k grauman discovering portant people objects egocentric video rization cvpr june pp z lu k grauman story driven summarization egocentric video cvpr m gygli h grabner l v gool video rization learning submodular mixtures objectives cvpr t yao t mei y rui highlight detection pairwise deep ranking rst person video tion cvpr june k zhang w l chao f sha k grauman mary transfer exemplar based subset selection video summarization cvpr k zhang w l chao f sha k grauman video summarization long short term memory eccv pp khosla r hamid c j lin n sundaresan large scale video summarization web image ors cvpr june pp g kim l sigal e p xing joint summarization large scale collections web images videos storyline reconstruction cvpr d potapov m douze z harchaoui c schmid eccv category specic video summarization pp z lei k sun q zhang g qiu user video marization based joint visual semantic afnity graph acm multimedia workshop vision language integration meets multimedia fusion k simonyan zisserman deep tional networks large scale image recognition iclr o russakovsky j deng h su j krause s satheesh s ma z huang karpathy khosla m stein c berg f li imagenet large scale visual recognition challenge s kullback r leibler information sufciency ann math statist pp q zhang g qiu bundling centre landmark image discovery acm icmr r mihalcea p tarau textrank bringing order text conference empirical methods ural language processing pp y li b merialdo multi video summarization based video mmr wiamis april fig quantitative results different temporal segmentation methods kts jts short kernel joint based temporal segmentation methods respectively divergence metric performs best cases tures semantic information better deep visual feature summarizing video similar contents tvsum deep visual feature achieves relatively good sults furthermore interesting observe label ding feature comparable result furthermore kl divergence better bility measuring information loss frame represent proves denition portance frames reasonable effective conclusion introduce new benchmark generated video summarization proposed new unsupervised method video summarization novel dense neighbor based clustering method approach rst partitions video segments based deep semantic similarity frames develop graph based ing method framerank rank segments finally sample segments high information scores generate video summary framerank method achieved results superiority state art methods acknowledgement author acknowledges nancial support national doctoral innovation centre ningbo education reau ningbo science technology bureau versity nottingham work supported uk engineering physical sciences research cil grant number ep references m gygli h grabner h riemenschneider l v creating summaries user videos gool eccv pp y song j vallmitjana stent jaimes sum summarizing web videos titles cvpr pp
