semantic sentence embeddings for paraphrasing and text summarization chi zhang shagan sah thang nguyen dheeraj peri alexander loui carl salvaggio raymond ptucha rochester institute of technology rochester ny usa kodak alaris imaging science rochester ny usa p e s l c s c v v i x r a abstract this paper introduces a sentence to vector encoding work suitable for advanced natural language processing our latent representation is shown to encode sentences with mon semantic information with similar vector tions the vector representation is extracted from an decoder model which is trained on sentence paraphrase pairs we demonstrate the application of the sentence tations for two different tasks sentence paraphrasing and paragraph summarization making it attractive for commonly used recurrent frameworks that process text experimental sults help gain insight how vector representations are suitable for advanced language embedding index terms sentence embedding sentence encoding sentence paraphrasing text summarization deep learning introduction modeling temporal sequences of patterns requires the ding of each pattern into a vector space for example by passing each frame of a video through a convolutional ral network cnn a sequence of vectors can be obtained these vectors are fed into a recurrent neural network rnn to form a powerful descriptor for video annotation similar techniques such as and glove have been used to form vector representations of words using such embeddings sentences become a sequence of word tors when these vector sequences are fed into a rnn we get a powerful descriptor of a sentence given vector representations of a sentence and video the mapping between these vector spaces can be solved ing a connection between visual and textual spaces this ables tasks such as captioning summarizing and searching of images and video to become more intuitive for humans by vectorizing paragraphs similar methods can be used for richer textual descriptions recent advances at vectorizing sentences represent exact sentences faithfully or pair a current sentence with prior and next sentence just like and glove map words of similar meaning close to one another we desire a method to map sentences of similar meaning close to one another for example the toy sentences a man jumped over the stream and a person hurdled the creek have similar meaning to humans but are not close in traditional sentence vector representations just like the words ower rose and tulip are close in good sentence to vector representations our toy sentences must lie close in the introduced embedded tor space inspired by the meteor captioning benchmark which allows substitution of similar words we choose to map similar sentences as close as possible we utilize both phrase datasets and ground truth captions from multi human captioning datasets for example the ms coco dataset has over k images each with ve captions from ve different evaluators on average each of these ve captions from each image should convey the same semantic ing we present an encoder decoder framework for sentence paraphrases and generate the vector representation of tences from this framework which maps sentences of similar semantic meaning nearby in the vector encoding space the main contributions of this paper are the usage of sentences from widely available image and video captioning datasets to form sentence paraphrase pairs whereby these pairs are used to train the encoder decoder model we show the application of the sentence embeddings for graph summarization and sentence paraphrasing whereby evaluations are performed using metrics vector tions and qualitative human evaluation and we extend the vectorized sentence approach to a hierarchical architecture enabling the encoding of more complex structures such as paragraphs for applications such as text summarization the rest of this paper is organized as follows section reviews some related techniques section presents the proposed encoder decoder framework for sentence and graph paraphrasing section discusses the experimental sults concluding remarks are presented in section related work most machine learning algorithms require inputs to be sented by xed length feature vectors this is a challenging task when the inputs are text sentences and paragraphs many studies have addressed this problem in both supervised and unsupervised approaches for example presented a tence vector representation while created a paragraph tor representation an application of such representations is shown by that has used individual sentence embeddings from a paragraph to search for relevant video segments an alternate approach uses an encoder decoder framework that rst encodes inputs one at a time to the rst layer of a two layer long short term memory lstm where can be of variable length such an approach is shown for video captioning tasks by that encodes the entire video then decodes one word at a time there are numerous recent works on generating long tual paragraph summaries from videos for example present a hierarchical recurrent network that comprise of a paragraph generator that is built on top of a sentence the sentence generator encodes sentences into compact tations and the paragraph generator captures inter sentence performed similar narratives from long dependencies videos by combining sentences using connective words at propriate transitions learned using unsupervised learning methodology the vector representation of a sentence is extracted from an encoder decoder model on sentence paraphrasing and then tested on a text summarizer vector representation of sentences we consider the sentence paraphrasing framework as an encoder decoder model as shown in fig given a tence the encoder maps the sentence into a vector and this vector is fed into the decoder to produce a phrase sentence we represent the paraphrase sentence pairs as sx sy let xi denote the word embedding for sentence sx and yj denote the word embedding for sentence sy i tx j ty where tx and ty are the length of the paraphrase sentences several choices for encoder have been explored including lstm gru and bn rhn in our model we use an rnn encoder with lstm cells since it is easy to be plemented and performs well on this model specically the words in sx are converted into token ids and then embedded using glove to encode a sentence the embedded words are iteratively processed by the lstm cell the decoder is a neural language model which conditions on the encoder output the computation is similar to that of the encoder the vector htx encodes the input sentence into a vector and is known as the vector representation of the input sentence or in this paper note that we do not have attention between encoder and decoder this ensures that all the information extracted from the input sentence by encoder goes through in other words attention is not adopted in order to avoid information leakage fig the sentence paraphrasing model the red and blue cells represent encoder and decoder respectively the mediate vector in black is vector encoded sentence in full softmax training for every training example in the word level we would need to compute logits for all classes however this can get expensive if the universe of classes pending on size of vocabulary is very large given the dicted sentence and ground truth sentence we use sampled softmax as a candidate sampling algorithm for each training sample we pick a small set of sampled classes cording to a chosen sampling function a set of candidates c is created containing the union of the target class and the sampled classes the training task gures out given this set c which of the classes in c is the target class hierarchical encoder for text summarization each sentence in a paragraph can be represented by a tor using the method described in section these tors xi i tx are fed into a hierarchical encoder and then the summarized text is generated word by word in an rnn decoder as shown in fig we rst divide all tx vectors into several chunks xn xt xt xt where is the stride and it denotes the number of temporal units jacent chunks are apart for each chunk a feature vector is extracted using a lstm layer and fed into the second layer each feature vector gives a proper abstract of its responding chunk we also use lstm units in the second layer to build the hierarchical encoder the rst lstm layer serves as a lter and it is used to explore local temporal structure within subsequences the second lstm learns the temporal dependencies among subsequences as a result the feature vector generated from the second layer which is called summarizes all input vectors tracted from the entire paragraph finally a rnn decoder converts into word sequence forming a summarized sentence we integrate a soft attention mechanism in the archical encoder the attention mechanism allows the lstm to pay attention to different temporal locations of the input sequence when the input sequence and the output sequence are not strictly aligned attention can be especially helpful start eos levels in each sequence training details sentence paraphrasing we trained the model as described in section on the visual caption datasets the word bedding is initialized using glove the number of units per layer in both encoder and decoder are empirically set to and we generate two sets of vocabularies with size and stochastic gradient descent is employed for timization where the initial learning rate and decay factor are set to and respectively paragraph summarization in this task we summarize tailed description to single sentence in tacos multi level corpus we select detailed descriptions with less than tences there are total of samples are used for training and are used for testing we employed the erarchical architecture described in section with stride s of feature vectors short paragraphs are zero padded are fed into the model with each vector s sentence tation extracted from our paraphrasing model to make the model more robust soft attention is used between each layer during training we use learning rate and adam mizer all the lstm cells are set to units except the one in sentence generation layer which is set to units sentence paraphrasing given a reference sentence the objective is to produce a mantically related sentence the paraphrasing model was trained on visual caption datasets and evaluated on the sick dataset without any ne tuning the results are shown in table the evaluation metrics for this experiment are son s r spearman s and mean squared we use the same setup used by for calculation of these metrics table test set results on the sick semantic relatedness task where denote the number of hidden units and denote the size of the vocabulary r and are son s and spearman s metric respectively r mse in order to visualize the performance of our method we applied pca to the vector representation fig visualizes some of the paraphrase sentence pairs in the sick dataset representations are sensitive to the semantic information of the sentences since pairwise sentences are close to each other for example point and are close because watching and looking are semantically related the semantic relatedness and grammar correctness are veried by human generated scores each score is the erage of different human annotators scores take values fig the paragraph summarizer the red and blue cells represent encoder and decoder respectively the encoder puts xi are the vector representation generated using of the sentences in the paragraph the decoder outputs are the words in summarized text the intermediate vector in black is vector encoded paragraph experimental results datasets visual caption datasets there are numerous datasets with multiple captions for images or videos for example vtt dataset is comprised of videos with tences each describing the videos the sentences are phrases since all the sentences are describing the same visual input we form pairs of these sentences to create input target samples likewise msvd ms coco and are used table lists the statistics of datasets used of captions from all datasets was held out as a test set in total we created over m training samples table sentence pairs statistics in captioning datasets msvd msrvtt mscoco flickr k k sent sent samp sent pairs k m k m k m the sick dataset we use the sentences involving sitional knowledge sick dataset as a test set for tence paraphrasing task it consists about english tence pairs which are annotated for relatedness by means of crowd sourcing techniques the sentence relatedness score on a point rating scale for each sentence pair is provided and meant to quantify the degree of semantic relatedness tween sentences tacos multi level corpus we extract training pairs for the paragraph summarization task from tacos multi level corpus this dataset provides coherent multi sentence descriptions of complex videos featuring cooking activities with three levels of detail detailed short and single tence description there are training and test video sequences with annotations for each of the description a fig t sne visualizations of single sentence descriptions of a subset of all sequences on tacos multi level corpus our skip thoughts and skip gram points are colored based on their sequence ids there are different annotations for each sequence best viewed in color c the young boys are playing outdoors and the man is smiling nearby a group of kids is playing in a yard and an old man is standing in the background a brown dog is attacking another animal in front of the man in pants a brown dog is helping another animal in front of the man in pants two people are kickboxing and spectators are watching two people are ghting and spectators are watching kids in red shirts are playing in the leaves three kids are jumping in the leaves a little girl is looking at a woman in costume the little girl is looking at a man in costume a woman is removing the peel of a potato a woman is peeling a potato ve children are standing in front of a wooden hut ve kids are standing close together and one kid has a gun training are all from captions the styles and ics of the sentences in this dataset are limited however the approach of forming sentence paraphrasing pairs and senting sentences using vectors are valid table evaluation of short to single sentence summarization on tacos multi level corpus using vectors from skip thoughts and skip gram respectively skip gram skip thoughts fig some paraphrase sentence pairs are represented by our and then projected into space using pca each point represents a sentence in sick dataset and the responding sentence is shown on the right between and a score of indicates that the sentence pair is not at all related or totally incorrect syntax while a score of indicates they are highly related or grammatically correct the sentences in human evaluation come from the visual caption and sick test sets the human evaluated scores of most sentence pairs are inversely proportional to the euclidean distance between the vector representation of the corresponding sentences meteor rouge l cider fig shows t sne vector representation using a our skip thoughts and c skip gram of domly selected test sequences in these plots each point represents a single sentence points describing the same video sequence should be clustered points with the same color are nicely grouped in visualization text summarization conclusion we now show that in addition to paraphrasing is useful for text summarization we use the tacos level corpus sentences from detailed descriptions of each video sequence are rst converted into vectors using our model these vectors are fed into our summarizer described in section the performance of the summarized text is evaluated based on the metric scores and compared to thoughts and skip gram note that skip gram is used as the frequency based average of for each word in the sentence as shown in table the scores generated by our model are very close and comparable to the benchmark thoughts this result is reasonable since the dataset used in we showed the use of a deep lstm based model in a quence learning problem to encode sentences with common semantic information to similar vector representations the presented latent representation of sentences has been shown useful for sentence paraphrasing and document tion we believe that reversing the encoder sentences helped the model learn long dependencies over long sentences one of the advantages of our simple and straightforward sentation is the applicability into a variety of tasks further research in this area can lead into higher quality vector resentations that can be used for more challenging sequence learning tasks references subhashini venugopalan et al translating videos to natural language using deep recurrent neural networks li yao et al describing videos by exploiting temporal structure in iccv pp andrew shin et al beyond caption to narrative video in icip ieee captioning with multiple sentences pp junyoung chung et al empirical evaluation of gated recurrent neural networks on sequence modeling arxiv preprint chi zhang et al batch normalized recurrent highway subhashini venugopalan et al sequence to sequence networks in icip ieee video to text in iccv tomas mikolov et al distributed representations of words and phrases and their compositionality in nips pp jeffrey pennington richard socher and christopher d manning glove global vectors for word tion in emnlp pp kyunghyun cho et al on the properties of neural chine translation encoder decoder approaches arxiv preprint quoc v le and tomas mikolov distributed tations of sentences and documents in icml vol pp nal kalchbrenner edward grefenstette and phil som a convolutional neural network for modelling sentences arxiv preprint han zhao zhengdong lu and pascal poupart adaptive hierarchical sentence model arxiv preprint ryan kiros et al skip thought vectors in nips pp satanjeev banerjee and alon lavie meteor tomatic metric for mt evaluation with improved tion with human judgments in proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation summarization tsung yi lin et al microsoft coco common objects in context in eccv pp jinsoo choi et al textually customized video maries arxiv preprint sutskever et al sequence to sequence learning with neural networks in nips pp subhashini venugopalan et al sequence to video to text in iccv pp haonan yu et al video paragraph captioning using hierarchical recurrent neural networks in cvpr pp sebastien jean et al on using very large target cabulary for neural machine translation arxiv preprint pingbo pan et al hierarchical recurrent neural coder for video representation with application to tioning in cvpr pp dzmitry bahdanau kyunghyun cho and yoshua gio neural machine translation by jointly learning to align and translate arxiv preprint jun xu et al msr vtt a large video description dataset for bridging video and language in cvpr david l chen and william b dolan collecting highly parallel data for paraphrase evaluation in proceedings of the association for computational linguistics human language technologies volume acl pp tsung yi lin et al microsoft coco common objects in context in european conference on computer sion springer pp peter young et al from image descriptions to visual denotations new similarity metrics for semantic ence over event descriptions transactions of the ciation for computational linguistics marco marelli et al a sick cure for the evaluation of compositional distributional semantic models in lrec pp anna rohrbach et al coherent multi sentence video description with variable level of detail in german conference for pattern recognition christopher d manning kai sheng tai richard socher from in improved structured long short term memory networks association for computational linguistics representations semantic laurens van der maaten and geoffrey hinton alizing data using t sne journal of machine learning research vol no nov pp
