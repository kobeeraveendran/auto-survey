moverscore text generation evaluating contextualized embeddings earth mover distance wei zhao maxime peyrard fei liu yang gao christian meyer steffen eger computer science department technische universitat darmstadt germany computer science department university central florida darmstadt maxime ucf edu yang informatik darmstadt darmstadt abstract robust evaluation metric profound pact development text generation tems desirable metric compares system references based tics surface forms paper investigate strategies encode system reference texts devise metric shows high correlation human judgment text quality validate new metric moverscore number text generation tasks including summarization machine lation image captioning data text eration outputs produced variety neural non neural systems ndings suggest metrics combining contextualized representations distance measure perform best metrics demonstrate strong generalization capability tasks ease use metrics available web service introduction choice evaluation metric signicant impact assessed quality natural language outputs generated system desirable ric assigns single real valued score tem output comparing erence texts content matching natural language generation nlg tasks benet robust unbiased evaluation including text machine translation summarization data text response generation image text captioning gatt krahmer proper evaluation difcult judge system competitiveness hindering ment advanced algorithms text generation increasingly pressing priority develop better evaluation metrics given recent advances neural text generation neural models provide code publicly available vsqtbz exibility copy content source text generating unseen words aspect hardly covered existing metrics greater exibility comes increased demand unbiased evaluation diversity promoting jectives possible generate diverse ural language descriptions man standard evaluation rics including bleu papineni rouge lin compute scores based marily gram occurrence statistics originally proposed diagnostic evaluation systems capable evaluating text ity reiter designed sure extent system ence texts distinct surface forms veyed meaning recent effort plicability metrics reveals pelling text generation system ascend standard metrics text quality system output hard improved bohm goal paper devise mated evaluation metric assigning single holistic score system generated text comparing human references content matching posit crucial provide holistic sure attaining high correlation human ments neural non neural text generation systems compared directly tuitively metric assigns perfect score system text conveys meaning reference text deviation reference content lead reduced score system text contains content reference system produces ill formed text fails deliver intended meaning investigate effectiveness spectrum distributional semantic representations code system reference texts allowing compared semantic similarity multiple natural language generation tasks new metric quanties semantic distance tween system reference texts harnessing power contextualized representations ters devlin ful distance metric rubner better content matching contributions marized follows formulate problem evaluating tion systems measuring semantic distance system reference texts assuming powerful continuous representations encode type semantic syntactic deviations investigate effectiveness existing textualized representations earth mover distance rubner comparing system predictions reference texts ing new automated evaluation metric achieves high correlation human ments text quality metric outperforms performs bly strong baselines text generation tasks including summarization machine lation image captioning data text eration suggesting promising direction moving forward related work fundamental importance design tion metrics applied natural language generation tasks similar nature including marization machine translation data text eration image captioning tasks involve generating texts sentence paragraph length system texts pared reference texts similar length semantic matching scores cate systems perform task past decades evaluation natural language generation tasks largely carried independently area summarization dominant metric rization evaluation rouge lin measures degree lexical overlap system summary set reference summaries variants consider overlap unigrams grams unigrams skip bigrams imum gap words longest common sequences weighted version metrics pyramid nenkova passonneau hovy tratz hovy compute matches content units head word modier ples need manually extracted reference summaries metrics achieve good correlations human judgments past general count relatedness abstractive maries references system abstract convey meaning different face forms furthermore large scale tion datasets cnn daily mail hermann newsroom grusky use single reference summary making harder obtain unbiased results lexical lap considered summary evaluation machine translation number metrics commonly evaluation metrics compare system reference translations based surface forms word character gram overlaps edit distance meanings convey bleu papineni precision metric measuring system translation overlaps human reference translations gram occurrence statistics metrics include sentbleu nist chrf ter wer cder meteor lavie agarwal described wmt metrics shared task bojar ruse shimanaka recent effort improve evaluation ing sentence embeddings large scale data tained tasks additionally preprocessing reference texts crucial evaluation normalization tokenization compound splitting handled properly different ing strategies lead inconsistent results word based metrics post data text generation bleu poorly suited evaluating data text systems dialogue response generation image ing systems designed generate texts lexical syntactic variation ing information different ways bleu similar metrics tend reward systems use wording reference texts ing repetitive word usage deemed able humans liu similar vein evaluating quality image captions challenging cider vedantam uses idf weighted grams similarity estimation spice anderson incorporates synonym matching scene graphs novikova examine large number grammar based metrics demonstrate weakly reect human judgments system outputs generated data driven end end ural language generation systems metrics based continuous representations moving traditional metrics envision new generation automated evaluation metrics comparing system reference texts based mantics surface forms achieve better correlation human judgments number previous studies exploit static word embeddings abrecht trained classifers peyrard shimanaka improve semantic similarity estimation replacing lexical overlaps contemporaneous work zhang describe method comparing system ence texts semantic similarity leveraging bert representations devlin viewed special case metrics discussed depth later cently clark present semantic ric relying sentence mover similarity elmo representations peters apply summarization essay scoring mathur introduce unsupervised supervised metrics based bert tations improve evaluation peyrard provides composite score combining dundancy relevance informativeness prove summary evaluation paper seek accurately measure system reference texts drawing inspiration contextualized tations word mover distance wmd ner wmd nds traveling tance moving word frequency bution system text reference essential capture tween texts metrics differ temporaneous work facets plore granularity embeddings leading variants metric word mover tence mover investigate effectiveness diverse pretrained embeddings netuning tasks study approach consolidate layer wise information contextualized beddings metrics demonstrate strong eralization capability tasks oftentimes outperforming supervised ones scribe method detail moverscore meric motivated need better metrics pable evaluating disparate nlg tasks describe metric moverscore built combination contextualized sentations system reference texts distance representations ing semantic distance system outputs references particularly important metric capture shared content texts case semantic textual similarity measures peters devlin accurately reect extent system text deviated reference intuition hind distance metric measuring semantic distance let sentence viewed sequence words denote sequence grams sequence words sequence bigrams thermore let vector weights weight gram sume making distribution grams intuitively effect grams like including function words played giving lower weights inverse document frequency idf word mover distance wmd kusner special case earth mover tance rubner measures semantic distance texts aligning semantically similar words nding eling words shown ful text classication textual similarity tasks kusner formulate generalization operating grams let sentences viewed sequences grams distance metric grams dene portation cost matrix cij distance gram gram wmd sequences grams associated gram weights given min gram transportation matrix fij denoting traveling gram denotes sum matrix entries matrix denotes wise multiplication minimal transportation cost grams weighted practice compute euclidean tance embedding representations grams embedding function maps gram vector representation usually static word embeddings like pute capture word order compositionality alternatively investigate contextualized embeddings like elmo bert encode information sentence word vector compute gram embeddings weighted sum word embeddings mally gram sentence embedding given idf word computed sentences corpus word vector furthermore weight associated gram given normalizing constant limiting case larger sentence size contains gram sentence reduces computing distance sentence embeddings sentence mover distance smd denoted size sentences hard soft alignments neous work bertscore zhang models semantic distance system reference texts evaluating text generation tems shown figure bertscore cision recall intuitively viewed hard figure illustration moverscore bertscore alignments words sentence pair word sequence travels semantically similar word sequence contrast moverscore goes bertscore relies soft alignments allows map semantically related words sequence respective word sequence solving constrained mization problem nding minimum effort transform texts formulation word mover distance vides important possibility bias metric precision recall ric transportation cost matrix bridges gap moverscore bertscore proposition bertscore precision recall represented non optimized mover tance transportation cost matrix based bert uniform portation matrix contextualized representations task formulation naturally lends deep contextualized representations inducing word vectors despite recent success layer attentive neural architectures devlin peters consolidating layer wise information remains open problem different layers capture information disparate scales task specic layer selection methods ited liu tenney found scalar mix output layers trained task dependent supervisions tive deep transformer based model instead investigate aggregation functions idate layer wise information forming stationary representations words supervision consider sentence passed alized encoders elmo bert layers layer encoders produces proof appendix system guywith redjacketis standingon boatguymanwearinglifevestsittingcanoeredjacketstandingboatguymanwearinglifevestsittingcanoeredjacketstandingboatword embeddingsword embeddingsref manwearinga lifevestis sittingin tor representation word note representation given layer dimensional vector overall receives different vectors aggregation maps vectors nal vector aggregated representation word study alternatives catenation power means generalized pooling mechanism routing mechanism aggregation zhao relegate routing method appendix yield better results power means power means power means effective eralization pooling techniques aggregating information computes non linear average set values exponent ing ruckle exploit power means aggregate vector representations taining word layers deep neural architecture let mean exponentiation applied elementwise generalized form induce common named means arithmetic mean metric mean extreme cases power mean reduces minimum value set maximum value concatenation mean vectors use paper denoted vector concatenation exponent values use work summary moverscore variations investigate moverscore sions granularity embeddings size grams choice pretrained embedding mechanism tuning task aggregation technique means routing applicable usually requires heavy layers restricts power tuning tasks elmo granularity sentences size sentence embedding mechanism obtained word beddings different methods static bedding contextualized embedding elmo bert gram embeddings calculated note represent sentence embeddings size sentence fine tuning tasks natural language inference nli paraphrasing pose high demands understanding sentence meaning vated tune bert representations nli datasets multinli qanli paraphrase dataset qqp largest datasets glue wang tune bert yielding different contextualized embeddings general evaluation metrics aggregation elmo aggregate word representations given elmo layers means routing appendix word representations bert aggregated layers means routing representations initial layers suited use downstream tasks liu empirical evaluation section measure quality ferent metrics tasks machine tion text summarization image captioning alogue generation major focus study correlation different metrics human judgment employ text encoders embed grams bertbase uses layer elmooriginal uses layer bilstm use pearson spearman measure correlation consider variants moverscore word mover sentence mover described word mover denote word mover notation containing ingredients example represents semantic metric word mover distance unigram based word embeddings tuned mnli aggregated means sentence mover denote sentence mover notation example represents semantic ingredients metric sentence mover distance sentence embeddings computed weighted sum embeddings baselines select multiple strong baselines task comparison sentbleu guo supervised metric ruse machine translation supervised metric best peyrard text summarization bleu meteor dialogue response eration cider spice meteor vised metric leic cui image tioning report bertscore zhang tasks page limit compare strongest baselines rest found appendix machine translation data obtain source language sentences system reference translations wmt news translation shared task bojar consider language pairs german chinese czech latvian finnish russian turkish resp english language pair mately sentences sentence reference translation multiple system tions generated participating systems system translation human assessments independently rated quality results table language pairs best correlation achieved word mover rics use bert pretrained mnli embedding generator pmeans aggregate embeddings different bert layers note unsupervised word mover metrics forms ruse supervised metric word mover metrics outperforms tence mover conjecture important mation lost sentence representation transforming sequence word vectors sentence embedding text summarization use summarization datasets text analysis conference contain clusters spectively cluster includes news articles nist gov topic reference summaries tem summaries generated participating tems summary reference system fewer words receives human judgment scores pyramid score nenkova passonneau responsiveness score pyramid measures important semantic content units reference summaries ered system summary ness measures summary responds overall quality combining content guistic quality results tables observe lexical rics like rouge correlate moderate contrast tac datasets metrics perform poorly tasks like alogue generation novikova image captioning anderson parently strict matches surface forms reasonable extractive summarization datasets word mover rics form better come close vised metric best data text generation use task oriented dialogue datasets bagel mairesse sfhotel wen contains instances meaning representation instance includes multiple references roughly system utterances generated ferent neural systems system utterance ceives human judgment scores tiveness naturalness quality score novikova informativeness measures information system utterance provides spect naturalness measures likely system utterance generated native ers quality measures system utterance captures uency grammar results tables interestingly metric duces moderate correlation human judgments including speculate current contextualizers poor representing named entities like hotels place names numbers appearing system reference texts best correlation achieved word mover metrics combining ized representations direct assessment setting metrics average baselines ruse bertscore sent mover word mover smd smd elmo pmeans smd bert pmeans smd bert mnli pmeans elmo pmeans bert pmeans bert mnli pmeans bert mnli pmeans table absolute pearson correlations segment level human judgments language pairs dataset setting metrics best bertscore baselines sent mover word mover smd smd elmo pmeans smd bert pmeans smd bert mnli pmeans elmo pmeans bert pmeans bert mnli pmeans bert mnli pmeans responsiveness pyramid responsiveness pyramid table pearson spearman correlations summary level human judgments tac image captioning use popular image captioning dataset coco lin contains images image includes roughly ence captions system captions generated participating systems coco captioning challenge system level man correlation system receives human judgment scores son scores sure overall quality captions scores measure correctness detailedness saliency captions following cui compare pearson correlation system level scores cus studying metrics overall quality captions leaving metrics understanding tions different aspects correctness detailedness saliency future work results table word mover metrics form baselines supervised metric leic uses information ing images texts analysis hard soft alignments bertscore harmonic mean bertscore precision bertscore recall composed combination hard mover tance hmd bert prop use representations bert layer fair comparison bertscore moverscore results machine translation task table moverscore forms asymmetric hmd factors combined harmonic mean bertscore par moverscore conjecture bert softens hard alignments bertscore contextualized embeddings encode information sentence word tor observe wmd bigrams slightly outperforms wmd unigrams guage pairs setting metrics baselines sent mover word mover meteor bertscore smd smd elmo pmeans smd bert pmeans smd bert mnli pmeans elmo pmeans bert pmeans bert mnli pmeans bert mnli pmeans inf bagel nat qual inf sfhotel nat qual table spearman correlation utterance level human judgments bagel sfhotel datasets setting metric baselines sent mover word mover leic meteor spice bertscore recall smd smd elmo smd bert smd bert elmo bert bert bert table pearson correlation system level human ments mscoco dataset short names metrics ruse hmd bert hmd recall bert hmd prec bert wmd unigram bert wmd bigram bert table comparison hard soft alignments distribution scores figure closer look sentence level correlation results reveal lexical metric sentbleu correctly assign lower scores system lations low quality struggles ing system translations high quality ing lower scores nding agrees observations found chaganty novikova lexical metrics correlate better human judgments texts low ity high quality peyrard lexical metrics trusted figure score distribution german english pair figure correlation similar language distant language pair bordered area shows tions human assessment metrics rest shows inter correlations metrics direct assessment rated language experts strongly disagree high scoring system puts importantly observe word mover metric combining bert clearly distinguish texts polar qualities correlation analysis figure serve existing metrics evaluation attaining medium correlations human ments high inter correlations selves contrast metrics attain high correlations human judgments forming robust different language pairs believe improvements come clearly distinguishing translations fall tremes impact fine tuning tasks figure badgoodhuman translation translation translation translation translation translation demonstrated strong generalization ability text generation tasks oftentimes forming supervised metrics metric provides promising direction holistic metric text generation direction human like eger evaluation text generation systems future work plan avoid need costly human references evaluation text generation systems instead base tion scores source texts system predictions allow level vised double sense unlimited evaluation louis nenkova bohm acknowledgments thank anonymous reviewers ments greatly improved nal version paper work supported german research foundation search training group adaptive preparation formation heterogeneous sources aiphes technische universitat darmstadt grant grk fei liu supported nsf grant references peter anderson basura fernando mark johnson stephen gould spice semantic tional image caption evaluation computer vision eccv european conference dam netherlands october ceedings pages florian bohm yang gao christian meyer ori shapira ido dagan iryna gurevych ter rewards yield better summaries learning proceedings summarise references conference empirical methods ural language processing hong kong china ondrej bojar yvette graham amir kamran results metrics shared task proceedings conference machine lation wmt arun chaganty stephen mussmann percy liang price debiasing automatic metrics natural language evalaution proceedings annual meeting association tational linguistics volume long papers pages elizabeth clark asli celikyilmaz noah smith sentence mover similarity automatic proceedings uation multi sentence texts figure correlation averaged language pairs pares pearson correlations word mover metrics combining bert tuned ferent tasks observe tuning closely related tasks improves correlations cially tuning mnli leads impressive improvement points average discussions showed metric combining ized embeddings earth mover distance performs strong unsupervised metrics tasks machine translation points spice image captioning points meteor dialogue response eration points best correlation achieved combining contextualized word beddings wmd rivals exceeds sota task dependent supervised metrics different tasks especially machine translation word mover metric pushes correlations chine translation average points sota supervised metric points contemporaneous bertscore major improvements come contextualized bert embeddings elmo tuning bert large nli datasets observed soft alignments moverscore marginally outperforms hard ments bertscore effect grams word mover metrics unigrams slightly outperforms bigrams average effect aggregation functions suggested effective techniques layer wise consolidations means routing close performance best layer par appendix conclusion investigated new unsupervised evaluation rics text generation systems combining tualized embeddings earth mover distance experimented variants metric sentence mover word mover correlation annual meeting association putational linguistics pages florence italy association computational linguistics dorin comaniciu peter meer mean shift robust approach feature space analysis ieee transactions pattern analysis machine intelligence yin cui guandao yang andreas veit xun huang serge belongie learning evaluate age captioning proceedings ieee ence computer vision pattern recognition pages jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language standing steffen eger gul ahin andreas ruckle ung lee claudia schulz mohsen mesgar ishnkant swarnkar edwin simpson iryna gurevych text processing like humans visually attacking shielding nlp systems proceedings conference north american chapter association tational linguistics human language gies volume long short papers pages minneapolis minnesota association computational linguistics albert gatt emiel krahmer survey state art natural language generation core tasks applications evaluation journal cial intelligence research jair max grusky mor naaman yoav artzi newsroom dataset million summaries diverse extractive strategies proceedings conference north american ter association computational linguistics human language technologies naacl hlt yinuo guo chong ruan junfeng incorporating copy knowledge machine translation evaluation proceedings conference machine translation shared task papers pages karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa leyman phil blunsom teaching chines read comprehend proceedings neural information processing systems nips eduard hovy chin yew lin liang zhou junichi fukumoto automated summarization proceedings uation basic elements fifth conference language resources uation lrec pages matt kusner sun nicholas kolkin ian weinberger word embeddings document distances proceedings tional conference machine learning icml alon lavie abhaya agarwal meteor automatic metric evaluation high levels correlation human judgments proceedings second workshop statistical machine translation statmt pages stroudsburg usa association tional linguistics jiwei michel galley chris brockett jianfeng gao bill dolan diversity promoting tive function neural conversation models ceedings north american chapter sociation computational linguistics naacl chin yew lin rouge package proceedings tomatic evaluation summaries acl workshop text summarization branches pages barcelona spain tsung lin michael maire serge belongie james hays pietro perona deva ramanan piotr dollar lawrence zitnick microsoft coco european common objects context ence computer vision pages springer chia wei liu ryan lowe iulian serban michael noseworthy laurent charlin joelle pineau evaluate dialogue system empirical study unsupervised evaluation rics dialogue response generation ings conference empirical methods ural language processing emnlp liyuan liu xiang ren jingbo shang xiaotao jian peng jiawei han efcient textualized representation language model pruning sequence labeling proceedings ference empirical methods natural language processing emnlp nelson liu matt gardner yonatan belinkov matthew peters noah smith tic knowledge transferability contextual resentations arxiv preprint chi kiu meant accurate semantic evaluation output language ings second conference machine tion wmt copenhagen denmark september pages annie louis ani nenkova automatically assessing machine summary content gold standard computational linguistics qingsong ondrej bojar yvette graham results metrics shared task ceedings conference machine lation wmt francois mairesse milica gasic filip jurccek simon keizer blaise thomson kai steve young phrase based statistical language generation graphical models active learning ceedings annual meeting ciation computational linguistics pages association computational linguistics nitika mathur timothy baldwin trevor cohn putting evaluation context contextual beddings improve machine translation evaluation proceedings annual meeting association computational linguistics pages florence italy association tational linguistics ani nenkova rebecca passonneau ating content selection summarization proceedings mid method ence north american chapter ation computational linguistics human guage technologies pages association computational linguistics jun ping viktoria abrecht better marization evaluation word embeddings proceedings conference rouge empirical methods natural language ing pages lisbon portugal tion computational linguistics jekaterina novikova ondrej dusek amanda cas curry verena rieser need new evaluation metrics nlg proceedings conference empirical methods natural language processing pages copenhagen denmark association tional linguistics kishore papineni salim roukos todd ward jing zhu bleu method automatic evaluation machine translation proceedings annual meeting association putational linguistics acl pages stroudsburg usa association tional linguistics matthew peters mark neumann mohit iyyer matt gardner christopher clark kenton lee luke zettlemoyer deep contextualized word resentations proceedings north american chapter association computational guistics naacl maxime peyrard simple theoretical model importance summarization proceedings annual meeting association putational linguistics pages florence italy association computational linguistics maxime peyrard studying summarization evaluation metrics appropriate scoring range proceedings annual meeting association computational linguistics pages florence italy association tational linguistics maxime peyrard teresa botschen iryna learning score system gurevych summaries better content selection evaluation proceedings workshop new frontiers summarization matt post clarity reporting bleu scores proceedings conference machine translation wmt ehud reiter structured review validity bleu computational linguistics yossi rubner carlo tomasi leonidas guibas earth mover distance metric image retrieval international journal computer vision andreas ruckle steffen eger maxime peyrard iryna gurevych concatenated power mean word embeddings universal cross lingual tence representations corr abigail peter liu christopher manning point summarization proceedings annual generator networks meeting association computational guistics acl hiroki shimanaka tomoyuki kajiwara mamoru komachi ruse regressor sentence embeddings automatic machine translation uation proceedings conference machine translation wmt ian tenney patrick xia berlin chen alex wang adam poliak thomas mccoy najoung kim benjamin van durme samuel bowman jan das learn probing sentence structure context arxiv preprint textualized word representations stephen tratz eduard hovy rization evaluation transformed basic ments proceedings text analysing ence tac ramakrishna vedantam lawrence zitnick devi parikh cider consensus based ieee conference age description evaluation computer vision pattern recognition cvpr boston usa june pages matt wand chris jones kernel ing chapman hall crc alex wang amapreet singh julian michael felix hill omer levy samuel bowman glue multi task benchmark analysis platform natural language understanding arxiv preprint tsung hsien wen milica gasic nikola mrksic hao david vandyke steve young semantically conditioned lstm based natural guage generation spoken dialogue systems arxiv preprint sam wiseman stuart shieber alexander rush learning neural templates text proceedings conference eration pirical methods natural language processing emnlp suofei zhang wei zhao xiaofu quan zhou fast dynamic routing based weighted nel density estimation corr tianyi zhang varsha kishore felix kilian bertscore corr weinberger yoav artzi evaluating text generation bert wei zhao haiyun peng steffen eger erik cambria min yang scalable able capsule networks challenging nlp proceedings annual cations ing association computational tics pages florence italy association computational linguistics wei zhao jianbo min yang zeyang lei suofei zhang zhou zhao investigating sule networks dynamic routing text proceedings conference cation empirical methods natural language ing association computational linguistics supplemental material proof prop section prove prop paper viewing bertscore precision recall optimized mover distance reminder wmd formulation denote vectors weights gram bertscore dened min cij fij rbert pbert fbert pbert rbert pbert rbert rbert formulated quasi wmd form cij fij fij cij arg arg size grams similarly pbert quasi wmd form omitted fbert formulated harmonic mean wmd forms pbert rbert routing section study aggregation function routing scheme achieved good results nlp tasks zhao specically introduce nonparametric clustering kernel density estimation kde routing kde bridges family kernel functions underlying empirical distributions leads computational efciency zhang dened min distance function denotes underlying closeness aggregated vector vector layer kernel function instantiations wand jones gaussian exp epanechnikov typical solution kde clustering minimize taking mean shift comaniciu meer dened firstly updated xed intuitively explained nal aggregated vector contextualized layers adopt sgd update hyperparameter control step size routing process summarized algorithm algorithm aggregation routing procedure initialize true return preloss loss break foreach representation layer softmax foreach representation layer foreach representation layer loss best layer layer wise consolidation table compares word mover based metric bining bert representations different layers stronger bert representations consolidated layers means routing layer best performance dependent word mover based metrics wmd means routing schema come close oracle performance obtained best layers experiments table correlations metrics baseline metrics word mover based metrics human judgments machine translation text summarization dialogue response generation respectively word mover based metrics combining bert tuned mnli highest correlations humans outperforming unsupervised metrics supervised metrics like ruse ull routing means perform roughly equally metrics bert layer bert layer bert layer bert layer bert layer bert routing bert pmeans direct assessment table absolute pearson correlations segment level human judgments english translations setting metrics average direct assessment baselines blend ruse sentbleu bertscore word mover bert routing bert mnli routing bert mnli routing bert pmeans bert mnli pmeans bert mnli pmeans table absolute pearson correlations segment level human judgments english translations setting metrics baselines best ull rouge bertscore responsiveness pyramid responsiveness pyramid word mover bert routing bert mnli routing bert mnli routing bert pmeans bert mnli pmeans bert mnli pmeans table correlation automatic metrics summary level human judgments setting baselines metrics rouge nist cider meteor bertscore word mover bert routing bert mnli routing bert mnli routing bert pmeans bert mnli pmeans bert mnli pmeans inf bagel nat qual sfhotel nat qual inf table spearman correlation utterance level human judgments bagel sfhotel datasets
