bigpatent large scale dataset abstractive coherent summarization eva chen lu college computer sciences northeastern university ai lab neu edu neu edu com n u j l c s c v v x r abstract existing text summarization datasets compiled news domain maries attened discourse structure datasets summary worthy content appears beginning input cles large segments input ticles present verbatim respective summaries issues impede ing evaluation systems stand article s global content structure produce abstractive summaries work high compression ratio present novel dataset bigpatent ing million records u s patent uments human written abstractive summaries compared existing rization datasets bigpatent ing properties summaries contain richer discourse structure recurring ties ii salient content evenly distributed input lesser shorter extractive fragments present summaries nally train evaluate baselines ular learning models bigpatent shed light new challenges motivate future rections summarization research introduction growing interest building neural abstractive summarization systems et al paulus et al gehrmann et al requires large scale datasets high quality summaries number tion datasets explored far sandhaus napoles et al hermann et al grusky et al acquired news articles share cic characteristics limit current state art models making extractive allowing understand input content generate formed informative summaries sample cnn daily mail news summary explosion rocks chemical plant china s eastern fujian province second time years injured explosion ing hospitalized explosion triggered oil leak local media reported toxic chemical spills sample bigpatent summary shoelace cover incorporating interchangeable fashion panel covering shoelaces gym shoe shoelace cover secured shoe number straps threaded slots shoelace cover straps secured gym shoe clude loop hook material straps disengaged shoelace cover drawn expose shoelaces figure sample summaries cnn daily mail bigpatent extractive fragments reused input underlined repeated entities indicating course structure highlighted respective colors specically datasets summaries attened narratives simpler discourse ture e entities rarely repeated illustrated news summary fig summaries usually contain long fragments text directly extracted input finally summary worthy salient content present beginning input articles introduce new large scale summarization dataset consisting million patent documents human written abstractive summaries bigpatent addresses mentioned issues guiding summarization search better understand input s global structure generate summaries complex coherent discourse structure key features bigpatent summaries hibit richer discourse structure entities dataset available download online evasharma github io bigpatent curring multiple subsequent sentences shown fig ii salient content evenly distributed document iii summaries considerably abstractive reusing fewer shorter phrases input illustrate challenges text marization benchmark bigpatent lines popular summarization models compare results existing large scale news datasets nd models yield noticeably lower rouge scores bigpatent news datasets suggesting need developing advanced models address new challenges presented bigpatent existing neural abstractive models duce abstractive summaries bigpatent tend repeat irrelevant discourse entities cessively fabricate information observations demonstrate importance bigpatent steering future research text summarization global content modeling semantic understanding entities relations discourse aware text planning build stractive coherent summarization systems related work recent advances abstractive summarization promising results generating uent informative summaries rush et al pati et al tan et al paulus et al summaries contain fabricated repeated content cao et al fan et al content selection existing models rely positional information easily fooled adversarial content present input underpins need global content modeling semantic understanding input discourse aware text ning yield formed summary mckeown barzilay lapata datasets aid velopment text summarization models datasets predominantly news domain drawbacks limited ing data document understanding shorter summaries gigaword napoles et al xsum narayan et al room grusky et al near extractive summaries cnn daily mail dataset hermann et al nature nist dataset doc comp dens summary doc ratio word sent word cnn dm nyt newsroom xsum arxiv pubmed bigpatent table statistics bigpatent rization datasets doc raw number documents dataset columns mean values reported documents bigpatent lower extractive fragment density dens higher pression ratio comp ratio news reporting summary worthy content uniformly distributed article arxiv pubmed datasets cohan et al collected scientic repositories ited size longer extractive maries existing datasets lack cial structural properties limited size learning robust deep learning methods dress issues present new dataset patent guides research ing abstractive summarization systems global content understanding bigpatent dataset present bigpatent dataset consisting million u s patent documents collected google patents public datasets query google contains patents led different technological eas use patent s abstract standard summary description additional details dataset including preprocessing steps appendix table lists statistics including compression ratio extractive fragment density patent commonly summarization corpora compression ratio ratio number words document summary density average length maintained ifi claims patent vices google licensed creative commons tribution international license summarization task studied bigpatent notably different traditional patent summarization task patent claims summarized readable mat cinciruk figure salient unigrams present n ments input figure novel n grams summaries tractive word mary belongs grusky et al isting datasets cnn dm hermann et al nyt napoles et al newsroom leased grusky et al xsum narayan et al news datasets arxiv pubmed cohan et al contain scientic articles notably bigpatent signicantly larger longer inputs summaries dataset characterization salient content distribution inferring distribution salient content input critical content selection tion models prior work uses probabilistic topic models barzilay lee haghighi vanderwende relies classiers trained sophisticated features yang et al focus salient words rences input consider unigrams stopwords summary salient words respective ument divide document equal segments measure percentage unique salient words segment formally let u function returns unique unigrams stopwords given text u di denotes unique unigrams ith segment ment d u y denotes unique unigrams corresponding summary y percentage salient unigrams ith segment document calculated u fig shows bigpatent fairly distribution salient words segments fragments set shared sequences tokens document summary input salient words observed segment segments trast cnn dm nyt newsroom imately salient words present segment proportion drops cally segment indicates salient content present ning news articles datasets xsum news dataset trend rst segments similar bigpatent percentage novel unigrams segment drops compared bigpatent scientic articles arxiv pubmed content organized sections clear drop segment related work discussed salient information present rst introduction conclusion sections bigpatent embodiment patent invention sequentially described document uniform distribution salient content probe far needs read input s start cover salient words present input summary sentences input required construct summaries cnn dm xsum nyt newsroom case bigpatent input required aforementioned tions signify need global content modeling achieve good performance bigpatent summary abstractiveness coherence summary n gram novelty following prior work et al chen bansal compute abstractiveness fraction novel n grams summaries absent input shown fig xsum prises notably shorter abstractive maries bigpatent reports cnn n grams cnn dmnytnewsroomxsumarxivpubmedbigpatent t t t t cnn dm nyt newsroom arxiv pubmed bigpatent table entities occurring t times summaries ent chain length ent recurrence datasets l l l l t t t cnn dm nyt newsroom arxiv pubmed bigpatent table left entities chain length l right avg number entities appear tth summary sentence recur later sentence ond highest percentage novel n grams n signicantly higher novelty scores trigram gram indicate bigpatent fewer shorter extractive fragments compared xsum smaller dataset corroborates fact bigpatent lowest extractive fragment density shown table contains longer summaries coherence analysis entity distribution study discourse structure summaries analyze distribution entities dicative coherence grosz et al strube hahn identify entities extract non recursive noun phrases regex np nltk loper bird finally use entity grid tion barzilay lapata erence resolution rules capture entity bution summary sentences work distinguish entities grammar roles leave future study average unique entities summaries newsroom nyt cnn dm bigpatent pubmed arxiv reported higher number unique entities summaries spectively summaries considerably longer table table shows entities recur bigpatent summaries higher datasets indicating complex discourse structures summaries understand local coherence summaries measure longest chain formed sentences entity denoted l table shows entities bigpatent appear consecutive sentences higher dataset presence longer entity chains bigpatent summaries gests higher sentence sentence relatedness news summaries finally examine entity recurrence tern captures entities rst ring tth sentence repeated subsequent t ith sentences table right shows average entities bigpatent summaries cur later sentences summing numbers corresponding recurring frequency news dataset cnn dm pubmed arxiv report higher number recurrence patterns different e entities recur tences observations imply good tion local global coherence bigpatent experiments analyses evaluate bigpatent popular rization systems compare known datasets cnn dm nyt line use selects rst sentences input summary consider oracles oraclefrag builds summary longest fragments reused input gold summary grusky et al oracleext selects globally mal combination sentences input gets highest score consider unsupervised extractive tems textrank mihalcea tarau lexrank erkan radev basic nenkova vanderwende adopt rnn ext rl chen bansal model selects salient sentences construct summary forcement learning finally train tive systems attention generator pointgen version erage mechanism pointgen cov et al sentrewriting chen bansal experimental setups model parameters described appendix exclude xsum summaries sentence table reports scores cnn dm nyt bigpatent models r l r l r l oraclefrag grusky et al oracleext textrank mihalcea tarau lexrank erkan radev sumbasic nenkova vanderwende rnn ext rl chen bansal sutskever et al pointgen et al et al sentrewriting chen bansal table rouge scores large datasets best results non baseline systems bold sentrewriting cnn dm nyt abstractive models truncate input summaries models novel n grams entities occurring m times n m m m m n gold pointgen cov sentrewriting table novel n grams highest lighted entities occurring m times ated summaries bigpatent peats entities humans l lin hovy models bigpatent models outperform baseline uniform bution salient content bigpatent s input articles extractive models textrank lexrank outperform rnn ext rl trained rst words suggesting need neural models efciently handle longer input finally trewriting reinforcement learning model rouge reward achieves best mance bigpatent table presents percentage novel grams generated summaries novel content generated summaries unigrams bigrams comparable gold observe repeated instances cated irrelevant information example upper portion congured receive upper portion sole portion generated summary irrelevant repetitions pared human summary fig suggests lack semantic understanding control generation existing neural models table shows entity distribution generated summaries bigpatent nd neural abstractive models tend repeat entities humans gold entities mentioned thrice pared employs coverage mechanism explicitly penalize repetition generates cantly fewer entity repetitions ndings dicate current models failt learn entity distribution pattern suggesting lack standing entity roles e importance discourse level text planning conclusion present bigpatent dataset written abstractive summaries containing fewer shorter extractive phrases richer course structure compared existing datasets salient content bigpatent summaries evenly distributed input bigpatent enable future research build robust systems generate abstractive coherent summaries acknowledgements research supported national ence foundation grants ofce director national intelligence odni intelligence vanced research projects activity iarpa contract views conclusions contained thors interpreted necessarily representing ofcial policies expressed implied odni iarpa u s ernment u s government authorized reproduce distribute reprints tal purposes notwithstanding copyright tation thank anonymous viewers constructive suggestions references dzmitry bahdanau kyunghyun cho yoshua gio neural machine translation jointly arxiv preprint learning align translate federico barrios federico lopez luis argerich rosa wachenchauzer variations larity function textrank automated tion arxiv preprint regina barzilay mirella lapata modeling local coherence entity based approach tational linguistics regina barzilay lillian lee catching drift probabilistic content models applications proceedings generation summarization human language technology conference north american chapter association computational linguistics hlt naacl steven bird ewan klein edward loper natural language processing python ing text natural language toolkit oreilly media inc ziqiang cao furu wei wenjie li sujian li faithful original fact aware neural proceedings tive summarization ation advancement articial intelligence aaai yen chun chen mohit bansal fast tive summarization reinforce selected sentence rewriting proceedings annual ing association computational linguistics volume long papers pages tion computational linguistics david cinciruk patent summarization ece drexel phrasing walsh pdf arman cohan franck dernoncourt doo soon kim trung bui seokhwan kim walter chang nazli goharian discourse aware attention model abstractive summarization long documents proceedings conference north american chapter association tional linguistics human language technologies volume short papers pages tion computational linguistics john duchi elad hazan yoram singer adaptive subgradient methods online learning journal machine stochastic optimization learning research gunes erkan dragomir r radev lexrank graph based lexical centrality salience text summarization journal articial intelligence search lisa fan dong yu lu wang robust neural abstractive summarization systems evaluation adversarial information workshop terpretability robustness audio speech language irasl neural information processing systems sebastian gehrmann yuntian deng alexander rush abstractive summarization proceedings conference cal methods natural language processing pages association computational tics sebastian gehrmann yuntian deng alexander rush abstractive proceedings conference tion empirical methods natural language ing pages google paid google patents public datasets private patent cloud connecting public data google com marketplace google patents public accessed barbara j grosz scott weinstein aravind k joshi centering framework ing local coherence discourse computational linguistics max grusky mor naaman yoav artzi newsroom dataset million summaries diverse extractive strategies proceedings conference north american chapter association computational linguistics man language technologies volume long pers pages association tional linguistics aria haghighi lucy vanderwende ing content models multi document proceedings human language tion nologies annual conference north american chapter association tional linguistics pages association computational linguistics karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa leyman phil blunsom teaching chines read comprehend advances ral information processing systems pages chin yew lin eduard hovy matic evaluation summaries n gram proceedings occurrence statistics human language technology conference north american chapter association computational linguistics edward loper steven bird nltk ral language toolkit proceedings workshop effective tools methodologies teaching natural language processing tational linguistics kathleen r mckeown discourse strategies generating natural language text articial gence rada mihalcea paul tarau textrank ing order text proceedings ference empirical methods natural language processing ramesh nallapati bowen zhou cicero dos santos caglar gulcehre bing xiang stractive text summarization sequence sequence rnns proceedings signll conference computational natural language learning pages association computational linguistics courtney napoles matthew gormley benjamin van durme annotated gigaword ceedings joint workshop automatic edge base construction web scale knowledge extraction akbc wekex pages ation computational linguistics shashi narayan shay b cohen mirella lapata nt details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing pages association computational linguistics ani nenkova lucy vanderwende pact frequency summarization microsoft search redmond washington tech rep msr romain paulus caiming xiong richard socher deep reinforced model abstractive marization arxiv preprint alexander m rush sumit chopra jason weston neural attention model abstractive proceedings tence summarization conference empirical methods natural guage processing pages evan sandhaus new york times annotated corpus linguistic data consortium philadelphia abigail peter j liu christopher d manning point summarization generator networks proceedings nual meeting association computational linguistics volume long papers pages association computational linguistics michael strube udo hahn functional tering grounding referential coherence tion structure computational linguistics ilya sutskever oriol vinyals quoc v le sequence sequence learning neural works advances neural information ing systems pages jiwei tan xiaojun wan jianguo xiao abstractive document summarization proceedings based attentional neural model annual meeting association putational linguistics volume long papers pages association computational linguistics cooperative patent classication uspto gov uspto scheme patents classification cpc cpc html accessed yonghui wu mike schuster zhifeng chen quoc v le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey et al google s neural chine translation system bridging gap arxiv preprint human machine translation yinfei yang forrest bao ani nenkova tecting content single document proceedings news summarization conference european chapter tion computational linguistics volume short papers pages association tional linguistics appendices dataset details bigpatent novel large scale summarization dataset million patent documents lected google patents public datasets bigquery google google indexed million patents text different patent ofces far consider patent documents united states patent trademark ofce uspto led english guage order considerably consistent writing formatting style facilitate easier parsing text patent application led der cooperative patent classication cpc code uspto provides hierarchical system language independent symbols classication patents according different areas technology pertain classication categories human necessities b performing operations porting c chemistry metallurgy d textiles paper e fixed constructions f mechanical cpc code doc comp dens summary ratio word sent word doc b c d e f g h y table statistics cpc codes bigpatent engineering lightning heating weapons ing g physics h electricity y eral tagging new cross sectional technology table summarizes statistics bigpatent categories public dataset patent record retained title authors abstract claims invention description text abstract patent generally written inventors patent application proved considered gold standard mary patent description text patent contains elds background invention covering previously published lated inventions description gures tailed description current invention summarization task considered detailed description patent input tokenized articles summaries ing natural language toolkit nltk bird et al large variation size summary input texts removed patent records compression ratio higher kept records summary length words input length focus tive summary input pairs removed records percentage summary worthy unigrams absent input novel unigrams finally removed references ure summaries input bles input salient content distribution bigrams longest common subsequences shown main paper e figure figure patent demonstrates relatively uniform bution salient content summary figure salient bigrams present n th segment input figure salient longest common subsequences present n th segment input parts input salient content considered bigrams longest common sub sequences summary experiment details experiments randomly split patent training pairs validation pairs test pairs cnn dm followed preprocessing steps et al training validation test pairs nyt lowing preprocessing steps paulus et al training tion test pairs extract based systems textrank barrios al ate summary sentences based trank algorithm mihalcea tarau lexrank sumbasic rnn ext rl chen bansal implementation provided abstract based systems neural stractive summarization models trewriting truncated input words output words trewriting models trained org project python org pypi sumy com chenrocks fast abs rl cnn cnn dmnytnewsroomxsumarxivpubmedbigpatent ing opennmt py python based instructions provided authors gehrmann et al provide details model attention sutskever et al trained dimensional embedding dimensional layer lstm bidirectional lstm encoder attention mechanism bahdanau et al model trained adagrad duchi et al learning rate tial accumulator value inference time beam size tings training pointgen pointgen cov et al adding copy attention mechanism allows model copy words source inference time gen cov coverage penalty beta set length penalty wu et al alpha sentrewriting chen bansal implementation train rl based model default parameters summaries sample input document bigpatent sample summary presented tion main paper table list complete gold standard summary summaries generated pointgen cov sentrewriting respective input list rst words brevity net opennmt py summarization html com chenrocks fast abs rl gold standard summary shoelace cover incorporating interchangeable fashion panel covering shoelaces gym shoe shoelace cover secured shoe number straps threaded slots shoelace cover strap secured gym shoe includes loop hook material straps disengaged shoelace cover drawn expose shoelaces shoe fashion panel attached shoelace cover loop hook material whim shoe wearer fashion panel replaced fashion panels convey fashion statement generated summary shoe having sole portion upper portion sole portion includes upper portion lower portion upper portion congured receive upper portion sole portion lower portion upper portion congured receive upper portion sole portion pointgen cov generated summary gym shoe associated shoelace shoe disclosed shoe includes sole portion shoelace cover upper portion upper portion toe area extends toe area opening shoelace cover curved shoelace sentrewriting generated summary gym shoe associated shoelace cover associated shoelace cover fashion panel disclosed shoe includes sole portion upper portion shoelace cover semi rigid panel curved conform shoelace area shoelace area shoelace area generally split shoelace area shoelace area shoe use shoe shoe disclosed tongue extends toe area shoelace input rst words following discussion preferred embodiment concerning gym shoe associated shoelace cover fashion panel merely exemplary nature way intended limit invention applications uses shoe includes sole portion generally comprised rugged rubber material upper portion generally comprised durable pliable leather canvas material location upper portion opening accepting wearer s foot cushion visible opening wearer s foot supported end upper portion toe area extending toe area opening shoelace area shoelace area generally split shoelace threaded eyelets associated shoelace area order bind shoelace area secure shoe wearer s foot tongue extending toe area opening positioned beneath shoelace tongue contacts wearer s foot provides comfort shoelace wearer basic components operation gym shoe understood person normal sensibilities detailed discussion parts shoe specic operation need elaborated secured upper portion shoe covering shoelace area shoelace cover preferred embodiment shoelace cover semi rigid panel curved shaped conform shoelace area upper portion shoelace cover extends certain distance sides upper portion adjacent opening shoelace cover narrows slightly extends toe area specics concerning shape dimensions material rigidity shoelace cover discussed greater detail additionally preferred method securing shoelace cover shoe discussed preferred embodiment afxed surface shoelace cover fashion panel fashion panel secured shoelace cover applicable securing mechanism loop hook velcro type fastener device fashion panel readily removed shoelace cover replaced alternate fashion panel having different design table gold standard system generated summaries bigpatent input pre processed truncated words brevity
