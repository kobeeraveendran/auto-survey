simple qe better automatic quality estimation for text simplication reno kriz marianna and chris callison burch computer and information science department university of pennsylvania cnrs llf france and university of helsinki finland rekriz upenn edu marianna fi c e d l c s c v v i x r a abstract text simplication systems generate versions of texts that are easier to understand for a the quality of broader audience ed texts is generally estimated using metrics that compare to human references which can be difcult to obtain we propose qe a bert based quality estimation qe model adapted from prior summarization qe work and show that it correlates well with man quality judgments simple qe does not require human references which makes the model useful in a practical setting where users would need to be informed about the quality of generated simplications we also show that we can adapt this approach to accurately dict the complexity of human written texts specic pieces of information from the original and omit unimportant passages ed text typically expresses all the content present in the original text using simpler words and tures both types of text however need to ll some linguistic quality constraints in order to be useful such as being grammatical and formed we show that simple qe correlates well with human judgments of linguistic quality on tem output produced by simplication systems in addition we adapt our model to make reasonable complexity predictions at both the sentence and document level our models can be used to mize both simplication system development and the process of writing manual simplications introduction related work simplication systems make texts easier to stand for people with reading disabilities and guage learners or for readers not yet familiar with a specic domain they propose re writings using simpler meaning preserving words and structures for automatically produced simplications to be useful in practical settings users should be able to easily assess their quality traditional evaluation metrics papineni et al xu et al timate the quality of generated texts by comparing them to human written simplications which stricts their use to settings where such references are available in addition comparing tions to a single reference is often too restrictive as most texts can be simplied in a variety of ways we propose a model for measuring the quality of automatically generated simplications which does not require human references our model simple quality estimation simple qe adapts the bert based summary qe model sum qe xenouleas et al to the simplication ting as opposed to summaries which contain quality estimation qe methods were rst troduced in the eld of machine translation to measure the quality of automatically translated text without need for reference translations jar et al martins et al specia et al in the most recent qe task the best tems leveraged bert via pre training for specic language pairs and integrating a transfer learning approach fonseca et al xenouleas et al propose several sions to the bert ne tuning process devlin et al to estimate summary quality their proposed model sum qe predicts ve linguistic qualities of generated summaries using multi task training grammaticality non redundancy erential clarity focus and structure and ence similar to state of the art results obtained by bert on many classication tasks xenouleas et al show that bert can be successfully applied to qe in our work we adapt sum qe to simplication qe estimating the fluency quacy and complexity of simplied text figure the simple qe architecture with and without adding numeric features corresponding to the original complex sentence original features and the system output system features r denotes a regressor layer alva manchego et al most recent simplication research uses both automatic metrics and human judgments during evaluation zhang and lapata kriz et al mallinson and lapata the metrics commonly used are bleu papineni et al meteor banerjee and lavie and sari xu et al contrary to simple qe these metrics require a reference sentence furthermore bleu correlates poorly with deletion a core pect of simplication sulem et al sari correlates well with human simplication ments at the lexical level but this does not transfer to the sentence level as shown in our experiments recently ated a toolkit to calculate various standard tomatic simplication metrics including sari word level accuracy scores and qe features such as compression ratio and average number of added deleted words recent work that addresses qe for simplication experiment with a variety of features including sentence length average token length and language model probabilities stajner et al martin et al however the best models from these works also use reliant features such as bleu and translation error rate as these have been shown to correlate with fluency and adequacy note that these works were carried out before the rise of large scale trained models peters et al devlin et al sum qe and our adaptation simple qe explicitly leverage the ne tuning capabilities of bert for assessing the quality of generated text methodology to estimate the quality of a simplication system output we focus on three linguistic aspects fluency how well formed it is adequacy how well it preserves the meaning of the original text complexity how much simpler it is than the original text we adapt the architecture posed by xenouleas et al in their sum qe model which extends the bert ne tuning cess devlin et al to rate summaries with respect to ve linguistic qualities we expect ency in our setting to align well with cality as addressed by sum qe in the case of equacy and complexity since judgments are is the generated text simpler than the ative e original text does it convey the same meaning we need to also consider the original complex text xenouleas et al use bert as the main encoder and ne tune it in three ways one task and two multi task approaches single task train k models on each annotation type where k is the number of guistic qualities here k multi train one model with a single regressor to predict k annotations multi task k train one model with k separate regressors to adapt sum qe to simplication we extend the architecture to take into account the original complex sentence we do so by passing the inal complex sentence and simplication system output through the bert architecture separately we concatenate the resulting embedding tations and pass them through a nal dense linear regressor layer r to predict each linguistic quality score our adaptation of the sum qe multi approach is described on the left side of figure to further adapt the qe model to our task we also attempt to incorporate task specic features the average length of content words in a tence in characters and in syllables their gram the sentence length and the use the average log unigram frequency from the syntactic parse height we pass these features extracted from the original complex sentence arately through a linear layer before ing them with the bert embeddings of the tence we do the same for the system output the right side of figure describes this architecture qe experiments on system output data and baselines our test data consists of human judgments lected by kriz et al on generated cations for newsela sentences xu et al for each sentence outputs from six simplication models were considered vanilla sequence to sequence nisioi et al learning with reinforcement zhang and lapata memory augmented transformer zhao et al and three ations of with post training re ranking kriz et al annotators were asked to rate the fluency adequacy and complexity of each system output on a point likert scale we compare the simple qe model to baselines that use the simplication specic features scribed in section quality estimates provided by bleu papineni et al and sari xu et al and three additional bert based baselines bert as language model bert lm given a sentence we mask each token and predict the likelihood of the true word ring in this context this captures fluency bert embedding similarity bert sim we convert the original and simplied texts into sentence level bert vector tions via mean pooling and compute their sine similarity this estimates adequacy sum qe we apply sum qe directly tuning only on annotated system output for sum qe and simple qe we perform fold cross validation combining the results to compute the overall correlation results the results are shown in table simple qe relates better with human judgments than the line models tested the correlation of bleu and google n gram corpus brants and franz do not use the qe dataset introduced by stajner et al as it focuses on small scale lexical changes similar to the turk dataset xu et al while current neural models adopt a more holistic approach com xu song bert as language model model bleu sari bert lm bert sim sum qe sum qe sum qe simple qe simple qe simple qe f simple qe ph simple qe sl simple qe all a c table pearson correlation with human fluency f adequacy a and complexity c judgments on plication system output the last three rows rate three numeric feature sets sentence length sl parse tree height ph and all features from section sari with human judgments is particularly low especially for complexity this is not surprising given that sari mainly addresses lexical cation while recent models approach tion more holistically the three versions of simple qe perform ilar to sum qe on fluency where the model does not need to access the original complex tence the difference between the two models is more noticeable for adequacy and ity where accessing the original sentence ally helps simple qe make more reasonable timates from the three versions of simple qe tested the multi task versions perform better than the single task on all three qualities tested the bert lm and bert sim baselines perform well on fluency and adequacy as expected but fall short on the other aspects of simplication as shown in table adding numeric features do not improve performance this may be because the most predictive features e sentence length are already implicitly learned by bert complexity prediction on human written text datasets as seen in the previous section simple qe makes reasonable estimates for fluency and adequacy syntax of a sentence can be extracted from tual word embeddings with reasonable accuracy hewitt and manning but scores lower on complexity to explore this further we test sum qe s capability to predict the complexity of hand written text assuming this text is relatively well formed we can in this way focus on how the model deals with complexity we perform this analysis on the entire newsela corpus xu et al which contains glish news articles re written at four complexity levels we explore how well ne tuning bert performs compared to incorporating features into a linear regression classier linreg since we only address complexity we only consider the single task approach simple qe sentence level complexity prediction we generate data by labelling sentences from newsela articles with the complexity level of the corresponding document to when a tence is found at different complexity levels we label it with the level of the simplest article in which it appears this results in sentences we measure the correlation between each feature and the sentence s complexity level and perform fold cross validation for linreg and qe the results of this experiment are shown in the rst column of table sentence length is the most predictive feature and combining all the features using a linear regression classier proves correlation but both are outperformed by our model document level complexity prediction most recent work has focused on sentence cation but document level simplication might be more useful in practical settings given that bert can only process sub word units at a time we break a document down into documents of up to sub word units at test time to get a single document level complexity prediction we take a length based weighted age of the predictions for the sub documents the results of this experiment are shown in the second column of table we can see that while sentence length and our linear regression classier rating all features perform quite well our model improves correlation even further out of domain evaluation finally we use pwkp zhu et al to plore how well our complexity prediction model com sentence document model word length syllables frequency sentence length parse height linreg simple qe table pearson correlation of the ne tuned bert model and different feature based baselines on the complexity prediction task at the sentence and the document level transfers to a different domain we extract parallel texts from simple and standard english wikipedia aligning texts by their unique article id we label each simple wikipedia document with simpler and each standard wikipedia document with more complex the alignment dure results in parallel documents ilar to our document level complexity prediction experiments we combine the sentence and document predictions into a single document level prediction in this experiment our model reaches a pearson correlation of while this is lower than our in domain newsela experiments it is still reasonably high showing that our model can be applied for complexity prediction on other mains conclusion we present simple qe a quality estimation model for simplication we have shown that ing sum qe xenouleas et al to include the reference complex sentence sensibly improves predictions on adequacy and complexity qe tems can be useful for evaluating the overall ity of model output without requiring expensive human annotations or references future cation systems can incorporate simple qe into the optimization process similar to how sari was incorporated into a network zhang and lapata as shown a ne tuned bert can also predict the complexity of human written text especially at the document level this nding can be leveraged in future work as the simplication eld moves towards simplifying entire documents wikipedia dumps wikimedia org used can at wikimedia org be found and references fernando alva manchego louis martin carolina scarton and lucia specia easse ier automatic sentence simplication evaluation in proceedings of the conference on ical methods in natural language processing and the international joint conference on natural language processing emnlp ijcnlp system demonstrations pages hong kong china association for computational linguistics satanjeev banerjee and alon lavie meteor an automatic metric for mt evaluation with proved correlation with human judgments in ceedings of the acl workshop on intrinsic and trinsic evaluation measures for machine tion summarization pages ann bor michigan association for computational guistics ondrej bojar rajen chatterjee christian federmann yvette graham barry haddow shujian huang matthias huck philipp koehn qun liu varvara logacheva christof monz matteo negri matt post raphael rubino lucia specia and marco turchi findings of the conference on machine translation in proceedings of the second conference on machine translation pages copenhagen denmark association for computational linguistics thorsten brants and alex franz web t gram version in philadelphia vania linguistic data consortium jacob devlin ming wei chang kenton lee and kristina toutanova bert pre training of deep bidirectional transformers for language derstanding in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies volume long and short papers pages minneapolis minnesota ation for computational linguistics erick fonseca lisa yankovskaya andre f t martins mark fishel and christian federmann ings of the wmt shared tasks on quality timation in proceedings of the fourth conference on machine translation volume shared task pers day pages florence italy tion for computational linguistics john hewitt and christopher d manning a structural probe for finding syntax in word sentations in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies volume long and short papers pages minneapolis minnesota ation for computational linguistics reno kriz joao sedoc marianna apidianaki carolina zheng gaurav kumar eleni miltsakaki and chris callison burch complexity weighted loss and diverse reranking for sentence simplication in proceedings of naacl human language technologies volume pages jonathan mallinson and mirella lapata trollable sentence simplication employing tactic and lexical constraints arxiv louis martin samuel humeau pierre emmanuel mazare eric de la clergerie antoine bordes and benot sagot reference less quality tion of text simplication systems in proceedings of the workshop on automatic text adaptation ata pages tilburg the netherlands ciation for computational linguistics andre f t martins marcin junczys dowmunt fabio n kepler ramon astudillo chris hokamp and roman grundkiewicz pushing the its of translation quality estimation transactions of the association for computational linguistics sergiu nisioi sanja stajner simone paolo ponzetto and liviu p dinu exploring neural text simplication models in proceedings of the annual meeting of the association for tional linguistics volume short papers pages vancouver canada association for tational linguistics kishore papineni salim roukos todd ward and jing zhu bleu a method for automatic in evaluation of machine translation ings of the annual meeting of the tion for computational linguistics pages philadelphia pennsylvania usa association for computational linguistics matthew peters mark neumann mohit iyyer matt gardner christopher clark kenton lee and luke zettlemoyer deep contextualized word in proceedings of the resentations ence of the north american chapter of the ation for computational linguistics human guage technologies volume long papers pages new orleans louisiana association for computational linguistics lucia specia blain varvara logacheva ramon astudillo and andre f t martins findings of the wmt shared task on quality estimation in proceedings of the third conference on machine translation shared task papers pages belgium brussels association for putational linguistics elior sulem omri abend and ari rappoport bleu is not suitable for the evaluation of text plication in proceedings of the conference on empirical methods in natural language cessing pages brussels belgium ciation for computational linguistics stratos xenouleas prodromos malakasiotis marianna apidianaki and ion androutsopoulos qe a bert based summary quality estimation model in proceedings of the conference on empirical methods in natural language ing and the international joint conference on natural language processing emnlp ijcnlp pages hong kong china association for computational linguistics wei xu chris callison burch and courtney napoles problems in current text simplication search new data can help transactions of the association for computational linguistics wei xu courtney napoles ellie pavlick quanze chen and chris callison burch optimizing statistical machine translation for text tion transactions of the association for tional linguistics xingxing zhang and mirella lapata sentence simplication with deep reinforcement learning in proceedings of the conference on cal methods in natural language processing pages copenhagen denmark association for computational linguistics sanqiang zhao rui meng daqing he andi saptono and bambang parmanto integrating former and paraphrase rules for sentence in proceedings of the conference on cation empirical methods in natural language ing pages brussels belgium ation for computational linguistics zhemin zhu delphine bernhard and iryna gurevych a monolingual tree based translation model for sentence simplication in proceedings of the international conference on computational linguistics coling pages jing china coling organizing committee sanja stajner maja popovic and hanna bechara quality estimation for text simplication in proceedings of the lrec workshop on quality sessment for text simplication pages toroz slovenia
