powered text generation harmonious machine interaction current state future directions qiuyun zhang bin guo hao wang yunji liang shaoyang hao zhiwen school computer science northwestern polytechnical university xian china edu abstract decades landscape text generation undergone tremendous changes reshaped success deep learning new technologies text generation ranging template based methods neural network based methods emerged research objectives changed generating smooth coherent sentences infusing personalized traits enrich diversification newly generated content rapid development text generation solutions comprehensive survey urgent summarize achievements track state arts survey paper present general systematical framework illustrate widely utilized models summarize classic applications text generation keywords text generation deep learning dialog system research personalized unprecedented attention text generation receiving different prior survey papers text generation overview introduce recent progress methodology perspective summarize emerging applications text generation according difference data modalities tasks text generation divided data text text text image text data text include weather forecast generation financial report generation text text tasks include news generation text summarization text retelling review generation widely studied text tasks include image captioning image questioning answering tasks introduction short main contributions paper shown text generation important research field natural language processing nlp great application prospects enables computers learn express like human types information images structured data text replace human complete variety tasks automatically generated text dated march los angeles times reported small earthquake occurred near beverly hills california providing detailed information time location strength earthquake news automatically generated robot reporter converted automatically registered seismic data text filling blanks predefined template text landscape text generation rapidly expanding initial stage majority studies focused reduce grammatical errors text generated text accurate smooth coherence recent years deep learning achieved great success applications ranging computer vision speech processing natural language processing recent advances text generation field based deep learning technology basic recurrent neural networks rnn sequence sequence generative adversarial networks gan reinforcement learning widely field text generation help technologies generated text coherent logical emotionally harmonious dialogue systems brought great convenience people lives microsoft xiaoice contona apple siri help people accomplish specific tasks communicate people virtual partner nowadays researchers start consider research personalized text generation adjust speaking style according characteristics daily communication text generation process dynamically adjust generation strategy final generated content according different profiles user summarize recent progress text generation present widely models field provide comprehensive collection primary applications text including dialogue summarization review generation image caption visual question answer key techniques systems finally provide promising research direction text generation personalized text generation remaining paper organized follows section introduces commonly models field text generation section presents application scenarios models detail section highlights application personalized text generation fields section summarizes evaluation section concludes paper future work text generation models section introduce basic frameworks widely applied neural networks models text generation including recurrent neural networks rnn sequence sequence generative adversarial networks gan reinforcement learning recurrent neural network rnn special neural network structure proposed according view people cognition based past experience memory different deep neural networks dnn convolutional neural networks cnn rnn considers input previous moment endows network memory function previous content rnn structure shown figure rnn remember previous information apply calculation current output nodes hidden layer longer connectionless connected input hidden layer includes output input layer output hidden layer previous moment idea smooth approximation approximate output generator lstm solve gradient inducibility problem caused discrete data variations rnn networks long short term memory lstm gated recurrent unit gru study pioneering application rnn construction language models experimental results rnn language model outperforms traditional method figure model structure gan reinforcement learning usually decision process performing action state rewarded negative reward punishment goal reinforcement learning find optimal policy maximize rewards dialogue generation task line operating mechanism reinforcement learning dialogue generation process seen process maximizing expected rewards generated dialogue content combination reinforcement learning gan excellent results achieved field text generation discriminator gan source reward reinforcement learning discriminator updated generator continuously optimized according return score current discriminator texts generated generator absolutely true reward mechanism policy gradient technologies reinforcement learning problem gradient propagated gan faces discrete data skillfully avoided interval training generator reinforcement learning method discriminator trained original method gan iii text generation applications generation section summarize classic applications text text summarization review generation image caption visual question answer including dialogue systems task oriented dialogue systems dialogue systems attracted attention recent years according different application fields dialogue systems divided categories oriented non task oriented dialogue systems known chatbots task oriented dialogue systems help users carry specific tasks restaurant reservations travel itineraries apple siri microsoft cortana representatives task oriented dialogue system recently deep learning algorithm applied construction task oriented dialogue systems deep learning automatically learn dimensional distributed feature representation reduce burden manual design large dialogue data build pure data driven end end dialogue system directly map user input system output popular research direction wen constructed task oriented dialogue system modular neural generation model neural network realize process modules figure model structure rnn sequence sequence structure standard model rnn networks compose encoder decoder structure rnn encoded sequence symbols fixed length vector representation representation sequence symbols encoder decoder jointly trained maximize conditional probability target sequence given source sequence structure shown figure second rnn decoded figure model structure cnn process sequence data variable length input output sequence length rnn model encode rnn encoder stage receive sequences indefinite length input decoder stage transform representation vector sequences affected input sequence length widely variety tasks including machine translation text summarization reading comprehension speech recognition gan reinforcement learning proposed goodfellow consists parts generator discriminator generator generate false sample distribution closest real samples discriminator distinguish generated samples real samples model structure gan shown figure original gan supports continuous data instead discrete data text address problem researchers fine tuning gan structure brings hope generation discrete data zhang lstm generator cnn discriminator implement task text generation random inputreal datareal fakeoptimizegeneratorgenerated specific tasks restaurant reservation achieved bordes neural generation model treat dialogue process mapping user input content model reply content encoder decoder structure train mapping relationship order solve problem dependence external knowledge bases oriented dialogue systems eric proposed end end key value retrieval network equipped attention based key value retrieval mechanism entries knowledge base extract relevant information knowledge base addition memory network variant rnn proposed store current user dialogue context similar user conversation history external memory module matching user input context appropriate replies selected alternative reply set non task oriented dialogue systems known chatbots non task oriented dialogue systems aim communicate humans naturally open context microsoft xiaoice typical chatbots main design methods non task oriented dialogue systems retrieval based method generative method rtrieval based methods selects retrieval based method directly corresponding reply alternative replies given according matching principle dual encoder model proposed lowe semantic representation context reply content context reply respectively encoded semantic vectors dual rnn model semantic similarity calculated matrix transformation found matching perspective words achieve good results zhou proposed matching multiple levels word level utterance level multi dimensional thinking provided direction following papers zhou encoder transformer model obtain multi granularity text representation context reply matching matrices calculated representation granularity utterance response pair dependency information words utterance words response added calculation alignment matrix expression words model deeper semantic relationship generative methods recently data driven model widely studied dialogue system pure data driven model directly trains large dialogue data relying external knowledge ritter took reply generation problem translation problem process generating replies regarded translate query corresponding replies based statistical machine translation model generating probability model proposed model dialogue system disadvantages model obvious important user query translated reply translation process considering context information dialogue obviously unable work properly multiple rounds dialogues development deep learning neural generation model began receive attention sordoni vinyals began apply rnn construct dialogue model applied neural network method end end dialogue model time based model past dialogue history mapped reply existing researches realized importance context simplest method use rnn directly encode dialogue sentences sequence obtain semantic representation vector context treated additional input decoding stage method yan utilize context information direct concatenation sentences relative relationship sentences researchers proposed complex methods extract context information multi layer model extract context information level model sentence level encode semantic information single sentence second sentence level model layer output input integrate contextual information tian carried experiments different cross sentence methods came conclusion performance multi layer context information extraction model outperformed single layer model lose stated daily human communication people associate dialogue content related topics mind based assumption xing organized content selected words according topics generating responses latent dirichlet allocation lda topic model obtain topical information dialogue sentences taken consideration additional input decoding process experimental results showed introduction topics dialogue model constructive improved performance choudhary recently gan reinforcement learning applied dialogue systems combining gan reinforcement learning jointly trained models generation model aimed generate reply sequences discriminator distinguish generated machine generated dialogue simulated dialogues virtual agents policy gradient reward sequences showing useful dialogue attributes informativity coherence ease answering related forward looking function text summarization text summarization important research direction text generation provides concise description users compressing refining original text text summarization regarded process information synthesize input documents integrated short abstract banko viewed summarization problem analogous statistical machine translation generated headlines statistical models selecting ordering summary words methods realize text summarization retrieval based method generative method described detail rest chapter retrieval based methods retrieval based method simple method selecting subset sentences original document process thought selecting central sentences document contain necessary sufficient information related subject main theme nenkova word frequency feature summarization attributes related word frequency studied word frequency compound function estimating sentence importance word frequency word frequency weight adjusted based context erkan proposed model based centrality prestige eigenvectors known lexpagerank model constructed sentence connectivity matrix based cosine similarity svore proposed new automatic summarization method based neural network netsum model retrieved set characteristics sentence help determine importance document cheng neural network extract abstract word sentence contents extracted respectively special work use attention mechanism directly scores attention select sentences document actually similar pointer networks cao attention mechanism weight sentences weighted basis correlation document sentences query based attention extracted summary ranking sentences disadvantages retrieval based method include similarity selected sentences lack logic selected sentences generative methods different retrieval based method generative method able generate sentences original text requires generative model stronger ability understanding representation difficult traditional methods achieve abilities paulus application reinforcement learning method based architecture abstract generation pasunuru reinforcement learning generate summarization article introduced theme facebook attention based generate sentence summarization alexander rush proposed sentence model framework encoder decoder later method works construct training data nallapati included work sentence compression presented new data set document multi sentence paper added lot features pos tag idf ner tag feature rich encoder proposed paper great significance work review generation review generation belongs data text natural language generation field recommender systems promising application estimate generate personalized reviews user write product discover nuanced opinions individual aspects order recommend products users need ultimately predict users react new products traditional methods discard comment text makes underlying dimensions users products difficult explain identifying product domain user rating model generate review corresponding rating like love disney movies expected story line predictable dumb jaech use rnn concatenated context word embedding input layer rnn experiments language modeling classification tasks different corpora demonstrated advantages method almahairi developed new models bowlf lmlf normalize rating predictions amazon review data set text reviews lei zheng proposed new method modeling ratings reviews temporal dynamics conjunction rnn proposed recurrent network capture temporal evolution user movie states directly predict ratings user movie rating history input updated status problem review generation use grained attributes input generate diverse specific comments generation long comments challenge image captioning visual question answering development social network task generates captions images received lot attention image captioning image caption basic multimodal problem field artificial intelligence connects computer vision natural language generation divided steps feature extraction natural language generation cnn usually feature extraction sub model extract significant features usually represented context vector fixed length followed rnn model generate corresponding sentence structure similar encoder decoder structure jaech proposed deep boltzmann machine learn generate multimodal data shows model create fused representation combining features modes kiros introduced neural language model multimodal constraint cnn learn word representation image features vinyals proposed generation model based deep rnn architecture given training image model trained maximize probability target sentence socher introduced model recognized objects images training data available object class completely unsupervised model accuracy mao proposed multimodal rnn rnn model generate new sentence descriptions explaining content images model composed subnetworks sentence depth rnn image depth cnn huang determined meaning words context local global documents words explained homonyms polysemy learning multiple embedding word tang generated natural language specific context context introduced text generation models model produced semantically syntactically coherent sentences better sequence long kulkarni introduced automatic natural language description generation system based image lot statistical information text data computer vision recognition algorithm system effective generating image related sentences mitchel new method generate language syntactic models linked computer vision detection generate formed descriptions images filtering unlikely attributes putting objects ordered syntactic structures frome proposed new deep visual semantic embedding model annotated image data semantic information extracted unannotated text identify visual objects visual question answering visual question answering vqa aims answer questions image inputs image question associated image output answer question deep learning model vqa usually uses cnn acquire image information rnn encode question applied cnn vqa tasks provided end end convolutional framework learning images problem representations modal interactions generate answers malinowsk cnn encode image feed question image representation lstm network system trained correct answers questions images ren neural networks visual semantic embedding included intermediate stages object construction image segmentation methods cnn implement vqa task noh independent parametric predictive network gru question input fully connected layer generating output combining hashing techniques reduced complexity constructing parameter prediction network large number parameters yang proposed learning method based hierarchical attention network help models answer natural language questions images zhu evaluated basic patterns personnel performance tasks proposed new lstm model spatial attention handle quality assurance tasks personalized text generation development deep learning techniques hope computers automatically write high quality natural language text previous research focused generated text content user personality daily conversation consider fact content produce corresponding dialogue content consider personalized profiles adjust dialogue style strategy purpose personalized text generation let computer imitate behavior human beings personalized characteristics users text content consideration generating dynamically adjust generated text content generate high quality text personalized text generation embodied applications briefly introduced personalized dialogue systems dialogue system text generation applications best reflects user personalized profiles process chatting different users chatbots want bring pleasant interactive experience users needs adjust dialogue strategies reply content according different characteristics users personalized characteristics user modeled time persona based model proposed different user embedded hidden vector space similar word embedding method user embedding vector adjust dialogue style content dialogue agent kottur extended previous model carried vector embedding user features combined hierarchical recurrent encoder decoder structure model better capture context related information considered user personalized features generate high quality dialogue content considering lack dialogue data user personalized characteristics luan applied task learning mechanism personalized reply generation small personalized dialogue data train reply generation model firstly encoder model trained non conversational data parameters models shared task learning mechanism obtain generation model personalized reply yang use idea transfer learning trained large number general dialogue data generate general reply model small personalized dialogue data fine tune model transfer learning users personalized information considered generating reply considering different influence user characteristics reply content qian applied supervision mechanism judge express appropriate user profiles reply generation process liu built branch neural network automatically learn user profiles user dialogues deep neural network learn fusion representation user queries replies user profiles realize dialogue process user perspective zhang work carried based chatbots task oriented dialogue system important research direction dialogue system studies consider user personalized information joshi published dataset task oriented dialogue system conversation contained user personalized information providing data support subsequent research luo use variant rnn memory network realize task oriented personalized dialogue system profile model encode user personalized information preference model solve ambiguity problem query facing different users time similar user dialogue history stored reply content extracted personalized reply content different users generated combining similar user dialogue history user personalized feature information personalized review generation findings tintarev indicated users mentioned different movie features describing favorite movies short personalized arguments users persuasive personalized user review generation contributes better recommend products radford demonstrated direct influence emotional units process model generation lipton built system giving user item combinations generate comments users write reviewing product designed character level rnn generate personalized product reviews model learned styles opinions nearly thousand different authors large number comments beeradvocate com model able generate sentences close real user written comments identify spelling errors domain specific words rnn decoder structure lstm gru zang introduced deep neural network model generate chinese comments emotional scores representing user opinions paper hierarchical lstm decoder attention consistency proposed dong proposed attention enhanced attribute sequence model generate product reviews given attribute information users products ratings attribute encoder learned represent input attributes vectors sequence decoder generated comments adjusting output vectors introduced attention mechanism syndicate comments align words input attributes sharma model similar added loss terms generate compliant comments designed review generation model use user project information auxiliary text input aspect perception knowledge encoding stage model encoders sequence encoder attribute encoder aspect encoder information integration decoder processing encoded information biased gru model generating phrases statements closest input addition gan generate personal reviews wang proposed new punishment based goal took rational approach minimizing overall punishment maximizing rewards experiments theories shown based punishment force generator produce multiple texts specific emotional tags producing repeated safe good examples addition multi class discriminator target allowed generator focus generating specific emotional tag examples model generate variety different emotional tags high quality text perceptual language evaluation metrics continuous development text generation technology corresponding evaluation method gradually active research direction researchers need use established evaluation method judge quality proposed models good evaluation metric key factor promote research progress date main methods text generation evaluation objective evaluation metric artificial evaluation objective evaluation metric mainly divided aspects word overlapping evaluation matrix bleu rouge second based word vector evaluation matrix greedy matching embedding business word overlap evaluation metrics bleu bilingual evaluation understudy bleu method compare gram model output reference output calculate number matched fragments calculate metric need use translated text called candidate docs text translated professional translators called reference docs essence bleu measure degree similarity machine translation text reference text value ranges closer value better machine translation results bleu adopts gram matching rule calculates proportion groups words similar comparison translation reference translation bleu algorithm relatively valuable evaluation scores quickly rouge recall oriented understudy gisting evaluation rouge evaluates abstract based occurrence information gram evaluation method oriented recall rate gram words basic idea generate abstract set standard abstracts number experts respectively compare automatically generated abstract system artificially generated standard abstract quality abstract evaluated counting number overlapping basic units gram word sequence word pair kind abstract stability robustness system improved comparing multi expert manual abstracts method general notes abstract evaluation technique word vectors evaluation metrics addition word overlap way evaluate response effect judge relevance response knowing meaning word word vector basis evaluation method accordance semantic distributions vector assigned word method represent word represented approximately calculating frequency word appears corpus word vector metrics approximated sentence vectors sentence level vector connection way sentence vectors candidate target reply sentences obtained respectively similarity obtained comparing cosine distance greedy matching greedy matching method matrix matching method based word level sentences given word converse word vector conversion time cosine similarity matching carried maximum extent word vector word sequence final result mean value words matched greedy matching proposed intelligent navigation system subsequent studies found optimal solution method tends result large semantic similarity center word reference answer embedding average embedding average way calculate sentence eigenvector word vector sentence vector sentence calculated averaging vectors word sentence method nlp domains dialogue system like calculating similarity text comparing sentences embedding average calculated respectively cosine similarity indicators evaluate similarity future directions conclusion references decades great achievements deep learning spur development text generation preliminary stage large number open issues section highlight pending questions underpin future research work dataset deficiency different computer vision machine translation lack high quality data field text generation difficult manually label data use small data complete efficient training model primary research direction future ultra long dialogue context human computer dialogue hot area text generation research current chatbots preliminarily understand context difficult grasp long text effectively capture semantic information text ensure consistency language logic dialogue process hot topic future textual information language existing studies focus text content ignore textual information reality specific natural environment time place emotion emotion considering textual information syntactically correct semantically reasonable reasonable text content specific context generated usually generated evaluation metrics text generation field lack unified evaluation metrics system best evaluation method conducted artificial judgement high quality evaluation metric crucial research field artificial intelligence reasonable unified evaluation metric researchers know research work reasonable major research gap future personalized text generation research personalized text generation attracting attention existing research based encoding user personalized profiles effectively obtain relationship personalized profiles text content focus future research problem impact lack personalized data model training use small personalized data achieve personalized text generation focus researchers paper gives comprehensive introduction basic concepts commonly models popular applications text generation time unsolved problems forward researchers work relevant research results endless text inevitably missing hope paper provide help relevant researchers field acknowledgment work partially supported national key program national natural science foundation china almahairi kastner cho courville learning distributed representations reviews collaborative filtering proceedings acm conference recommender systems arjovsky chintala bottou wasserstein gan arxiv preprint banko mittal witbrock headline generation based statistical translation proceedings annual meeting association computational linguistics bordes boureau weston learning end end goal oriented dialog arxiv preprint cao wei attsum joint learning focusing summarization neural attention arxiv preprint cheng lapata neural summarization extracting sentences words arxiv preprint cho van merrinboer gulcehre bahdanau bougares schwenk learning phrase representations rnn encoder decoder statistical machine translation arxiv preprint choudhary srivastava ungar sedoc domain aware neural dialog system arxiv preprint costa ouyang dolog lawlor automatic generation natural language explanations proceedings international conference intelligent user interfaces companion dong huang wei lapata zhou learning generate product reviews attributes proceedings conference european chapter association computational linguistics volume long papers eric manning key value retrieval networks task oriented dialogue arxiv preprint erkan radev lexpagerank prestige document text summarization proceedings conference empirical methods natural language processing frome corrado shlens bengio dean mikolov devise deep visual semantic embedding model advances neural information processing systems gatt krahmer survey state art natural language generation core tasks applications evaluation journal artificial intelligence research goodfellow pouget abadie mirza warde farley ozair generative adversarial nets advances neural information processing systems huang socher manning improving word representations global context multiple word prototypes proceedings annual meeting association computational linguistics long papers volume jaech ostendorf improving context aware language models joshi faltings personalization oriented dialog arxiv preprint kiros salakhutdinov zemel multimodal neural language models international conference machine learning kottur wang carvalho exploring personalized neural conversational models ijcai kulkarni premraj dhar choi berg baby talk understanding generating image descriptions proceedings cvpr kusner hernndez lobato gans sequences discrete elements gumbel softmax distribution arxiv preprint lei noroozi joint deep modeling users items reviews recommendation tenth acm international conference web search data mining galley brockett spithourakis gao dolan persona based neural conversation model arxiv preprint monroe ritter galley gao jurafsky deep reinforcement learning dialogue generation arxiv preprint monroe shi jean ritter jurafsky adversarial learning neural dialogue generation arxiv preprint lipton vikram mcauley generative concatenative nets jointly learn write classify reviews arxiv preprint liu sun wang wang wong content oriented user modeling personalized response ranking chatbots ieee acm transactions audio speech language processing taslp lowe pow serban pineau ubuntu dialogue corpus large dataset research unstructured turn dialogue systems arxiv preprint luan brockett dolan gao galley multi task learning speaker role adaptation neural conversation models arxiv preprint luo huang zeng nie sun learning personalized end end goal oriented dialog arxiv preprint learning answer questions image convolutional neural network thirtieth aaai conference artificial intelligence malinowski rohrbach fritz ask neurons deep learning approach visual question answering international journal computer vision mao yang wang yuille explain images multimodal recurrent neural networks arxiv preprint mcauley leskovec hidden factors hidden topics understanding rating dimensions review text proceedings acm conference recommender systems mikolov karafit burget ernock khudanpur recurrent neural network based language model speech eleventh annual communication association conference international mitchell han dodge mensch goyal berg midge generating image descriptions computer vision detections proceedings conference european chapter association computational linguistics zhang yang personalizing dialogue system transfer reinforcement learning second aaai conference artificial intelligence nallapati zhou gulcehre xiang abstractive text summarization sequence sequence rnns arxiv preprint nenkova vanderwende mckeown compositional context summarizer exploring factors influence summarization proceedings annual international acm sigir conference research development information retrieval sensitive multi document mcauley personalized review generation expanding phrases attending aspect aware representations proceedings annual meeting association computational linguistics volume short papers noh hongsuck seo han image question answering convolutional neural network dynamic parameter prediction proceedings ieee conference computer vision pattern recognition oremus news report earthquake written robot slate pasunuru bansal multi reward reinforced summarization saliency entailment arxiv preprint paulus xiong socher deep reinforced model abstractive summarization arxiv preprint qian huang zhao zhu assigning personality profile chatting machine coherent conversation generation ijcai radford jozefowicz sutskever learning reviews discovering sentiment arxiv preprint generate ren kiros zemel exploring models data image question answering advances neural information processing systems ritter cherry dolan data driven response generation social media proceedings conference empirical methods natural language processing rush chopra weston neural attention model abstractive sentence summarization arxiv preprint sharma sharma bishnu patel cyclegen cyclic consistency based product review generator attributes proceedings international conference natural language generation socher ganjoo manning zero shot learning cross modal transfer advances neural information processing systems sordoni galley auli brockett mitchell neural network approach context sensitive generation conversational responses arxiv preprint srivastava salakhutdinov multimodal learning deep boltzmann machines advances neural information processing systems svore vanderwende burges enhancing document summarization combining ranknet party sources proceedings joint conference empirical methods natural language processing computational natural language learning emnlp conll tang yang carton zhang mei context aware natural language generation recurrent neural networks arxiv preprint tian yan mou song feng zhao context useful empirical study aware neural conversational models proceedings annual meeting association computational linguistics volume short papers tintarev masthoff effective explanations recommendations user centered design proceedings acm conference recommender systems vinyals neural conversational model arxiv preprint vinyals toshev bengio erhan tell neural image caption generator proceedings ieee conference computer vision pattern recognition wang wan sentigan generating sentimental texts mixture adversarial networks ijcai wen vandyke mrksic gasic rojas barahona network based end end trainable task oriented dialogue system arxiv preprint xing liu huang zhou topic aware neural response generation thirty aaai conference artificial intelligence yan song learning respond deep neural networks retrieval based human computer conversation system proceedings international acm sigir conference research development information retrieval yang zhao zhao chen zhu zhou personalized response generation domain adaptation proceedings international acm sigir conference research development information retrieval yang gao deng smola stacked attention networks image question answering proceedings ieee conference computer vision pattern recognition zhang wang seqgan sequence generative adversarial nets policy gradient thirty aaai conference artificial intelligence zang wan automatic generation product reviews aspect sentiment scores proceedings international conference natural language generation zhang dinan urbanek szlam kiela weston personalizing dialogue agents dog pets arxiv preprint zhang gan carin generating text adversarial training nips workshop adversarial training zhou dong zhao tian multi view response selection human computer conversation proceedings conference empirical methods natural language processing zhou dong liu chen zhao multi turn response selection chatbots deep attention matching network proceedings annual meeting association computational linguistics volume long papers zhu groth bernstein fei fei grounded question answering images proceedings ieee conference computer vision pattern recognition
