attend to medical ontologies content selection for clinical abstractive summarization sajad nazli and ross w lab georgetown university washington dc usa sajad cs georgetown edu georgetown university hospital washington dc usa ross net a m l c s c v v i x r a abstract sequence to sequence network is a well established model for text summarization it can learn to produce readable task tent however it falls short in effectively tifying key regions of the source in this per we approach the content selection lem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer our experiments on two licly available clinical data sets ports of mimic cxr and reports of openi show that our model statistically icantly boosts state of the art results in terms of rouge metrics with improvements rg l in the care domain where any range of improvement impacts patients welfare introduction radiology reports convey the detailed observations along with the signicant ndings about a medical encounter each radiology report contains two portant findings that encompasses diologist s detailed observations and interpretation of imaging study and impression summarizing the most critical ndings impression usually couple of lines and thrice smaller than nding is considered as the most integral part of report ware et al as it plays a key role in communicating critical ndings to referring clinicians previous studies have reported that clinicians mostly read the impression as they have less time to review ings particularly those that are lengthy or intricate flanders and lakhani xie et al in clinical setting generating impression from findings can be subject to errors gershanik et al brady this fact is especially crucial when it comes to healthcare domain where even on institution radiology reports may or may not include other elds such as background the smallest improvement in generating sion can improve patients well being ing the process of impression generation in ology reporting would save clinicians read time and decrease fatigue flanders and lakhani kovacs et al as clinicians would only need to proofread summaries or make minor edits previously macavaney et al showed that augmenting the summarizer with entire tology i e clinical terms within the findings can improve the content selection and summary generation to some noticeable extent our ndings further suggest that radiologists select signicant ontology terms but not all such terms to write the impression following this paradigm we pothesize that selecting the most signicant clinical terms occurring in the findings and then rating them into the summarization would improve the nal impression generation we further amine if rening findings word representations according to the identied clinical terms would result in improved impression generation overall the contributions of this work are twofold we propose a novel based model to incorporate the salient clinical terms into the summarizer we pose copying likelihood of a word as an indicator of its saliency in terms of forming impression which can be learned via a sequence tagger our model statistically signicantly improves over the competitive lines on mimic cxr publicly available clinical dataset to evaluate the cross organizational ferability we further evaluate our model on another publicly available clinical dataset openi related work few prior studies have pointed out that although models can effectively produce readable content they perform poorly at selecting salient content to include in the summary gehrmann et al lebanoff et al many attempts have been made to tackle this problem zhou et al lin et al hsu et al lebanoff et al you et al for example zhou et al used sentence representations to lter ondary information of word representation our work is different in that we utilize ontology resentations produced by an additional encoder to lter word representations gehrmann et al utilized a data efcient content selector by aligning source and target to restrict the model s attention to likely to copy phrases in contrast we use the content selector to nd domain knowledge ment between source and target moreover we do not focus on model attention here but on rectifying word representations extracting clinical ndings from clinical reports has been explored previously hassanpour and glotz nandhakumar et al for marizing radiology reports zhang et al recently used a separate rnn to encode a section of radiology report subsequently macavaney et al extracted clinical ontologies within the findings to help the model learn these useful signals by guiding decoder in generation process our work differs in that we hypothesize that all of the ontological terms in the findings are not equally important but there is a notion of odds of saliency for each of these terms thus we focus on rening the findings representations model our model consists of two main components a content selector to identify the most salient logical concepts specic to a given report and a summarization model that incorporates the tied ontology terms within the findings into the summarizer the summarizer renes the findings word representation based on salient ontology word representation encoded by a separate encoder content selector the content selection problem can be framed as a word level extraction task in which the aim is to identify the words within the findings that are likely to be copied into the impression we tackle this problem through a sequence labeling approach we align findings and impression to obtain required data for sequence labeling task eld to this end let bn be the binary tags over the findings terms xn with n being the length of the findings we tag word xi with if it meets two criteria simultaneously it is an ontology term it is directly copied into impression and otherwise at inference we characterize the copying likelihood of each ings term as a measure of its saliency recent studies have shown that ized word embeddings can improve the labeling performance devlin et al peters et al to utilize this improvement for the content selection we train a bi lstm network on top of the bert embeddings with a softmax vation function the content selector is trained to maximize log likelihood loss with the maximum likelihood estimation at inference the content selector calculates the selection probability of each token in the input sequence formally let o be the set of ontological words which the content selector predicts to be copied into the impression o fu poi where fu is a mapping function that takes in findings tokens and outputs word sequences from input tokens if they appear in the ontology i e radlex and otherwise skips them poi notes the selection probability of ontology word oi and is the copying threshold summarization model encoders we exploit two separate encoders ndings coder that takes in the findings and ontology encoder that maps signicant ontological terms identied by the content selector to a x vector known as ontology vector the ndings encoder is fed with the embeddings of findings words and generates word representations h then a separate encoder called ontology encoder is used to cess the ontology terms identied by the content selector and produce associated representations ho bi ho where is the findings text o is the set of ogy terms occurring in the findings and identied by the content selector ho ho l is the ho ho version radlex files xlsx at training or previously generated tokens at ference and is the previous decoder state the decoder also computes an attention tion a with being the ontology aware word representations the tion weights are then used to compute the context vector ct i where n is the length of the findings finally the context vector and decoder output are used to either generate the next token from the vocabulary or copy it from the findings i experiments dataset and ontologies mimic cxr this collection johnson et al is a large publicly available dataset of diology reports following similar report processing as done in zhang et al we obtained radiology reports for tion we used scispacy neumann et al we randomly split the dataset into train dev test splits openi a public dataset from the indiana work for patient care demner fushman et al with reports due to small size it is not suitable for training we use it to evaluate the cross organizational transferability of our model and baselines ontologies we use radlex a comprehensive diology lexicon developed by radiological society of north america rsna including logical terms organized in hierarchical structure baselines we compare our model against both known and state of the art extractive and abstractive models lsa steinberger and jezek an tive vector based model that employs sigular value decomposition svd concept figure overview of our summarization model as shown bilateral in the findings is a signicant tological term which has been encoded into the ogy vector after rening findings word tion the decoder computes attention weight highest on bilateral and generates it in the impression word representations yielded from the ontology coder note that ho l called ontology vector is the last hidden state containing summarized tion of signicant ontologies in the findings ontological information filtering although frameworks implicitly model the information ow from encoder to coder the model should benet from explicitly modeling the selection process to this end we implement a ltering gate on top of the ndings coder to rene the findings word representations according to the signicant ontology terms within the findings and produce ontology aware word representations specically the ltering gate ceives two vectors the word hidden representation hi that has the contextual information of word xi and the ontology vector ho l including the overal formation of signicant ontology words within the findings the ltering gate processes these two vectors through a liner layer with sigmoid tion function we then compute the ontology aware word hidden representation i given the source word hidden representation hi and the associated ltering gate fi fi ho i hi fi neusum zhou et al a state of the art extractive model that integrates the process of source sentence scoring and selection where wh is the weight matrix denotes the bias term and denotes element wise multiplication impression decoder we use an lstm network as our decoder to erate the impression iteratively in this sense the decoder computes the current decoding state st where is the put to the decoder human written summary tokens pointer generator pg see et al an abstractive summarizer that extends works by adding a copy mechanism that allows for directly copying tokens from the source ontology aware pointer generator ont pg macavaney et al an extension of use open code at neusum with default hyper parameters lstmlstmlstmlstm lstmlstm attentionlstm newtl bilateral bilateralnew small method lsa neusum pg ont pg bus ours this work rg l table rouge results on mimic cxr shows the statistical signicance paired t test p pg model that rst encodes entire ontological concepts within findings then uses the encoded vector to guide decoder in summary decoding process bottom up summarization bus gehrmann et al an abstractive model which makes use of a content selector to constrain the model s attention over source terms that have a good chance of being copied into the target parameters and training we use scibert model beltagy et al which is pre trained over biomedical text we ploy layer bi lstm encoder with hidden size of upon bert model the dropout is set to we train the network to minimize cross entropy loss function and optimize using adam optimizer kingma and ba with learning rate of for the summarization model we extended on the open base code by zhang et al for plementation we use layer bi lstm layer lstm as ndings encoder ontology encoder and decoder with hidden sizes of and tively we also exploit glove embeddings pretrained on a large collection of million diology reports zhang et al we train the network to optimize negative log likelihood with adam optimizer and a learning rate of results and discussion experimental results table shows the rouge scores of our model and baseline models on mimic cxr with written impressions as the ground truth our model signicantly outperforms all the baselines re implemented the bus model com summarize radiology findings method rg l bus ours this work table rouge results on open i dataset comparing our model with the best performing baseline shows the statistical signicance paired t test p setting rg l cont sel cont sel table rouge results showing the impact of content selector in summarization model shows the cal signicance paired t test p on all rouge metrics with and improvements for and rg l tively while neusum outperforms the non neural lsa in extractive setting the extractive models lag behind the abstractive methods considerably gesting that human written impressions are formed by abstractively selecting information from the ings not merely extracting source sentences when comparing ont pg with our model it turns out that indeed our hypothesis is valid that a pre step of identifying signicant ontological terms can prove the summary generation substantially as pointed out earlier we dene the saliency of an ontological term by its copying probability as expected bus approach achieves the best results among the baseline models by constraining decoder s attention over odds on copied terms but still underperforms our model this may suggest that the intermediate stage of rening word resentations based on the ontological word would lead to a better performance than supercially stricting attention over the salient terms table shows the effect of content selector on the marization model for the setting without content selector we encode all ontologies within the ings as shown our model statistically cantly improves the results on and to further evaluate the transferability of our model across organizations we perform an uation on openi with our best trained model on mimic cxr as shown in table our model signicantly outperforms the top performing stractive baseline model suggesting the promising cross organizational transferability of our model figure histograms and arrow plots showing differences between impression of manually scored radiology reports although challenges remain to reach human parity for all metrics a b and c of our system generated impressions are as good as human written impressions across different metrics c expert evaluation while our approach achieves the best rouge scores we recognize the limitation of this ric for summarization task cohan and goharian to gain a better understanding of ties of our model we conducted an expert human evaluation to this end we randomly sampled system generated impressions with their associated gold from evenly spaced bins sorted by our system s of mimic cxr dataset the pressions were shufed to prevent potential bias we then asked three experts to score the given pressions independently on a scale of worst to best for three metrics readability understandable or nonsense accuracy fully accurate or ing critical errors completeness having all major information or missing key points figure presents the human evaluation sults using histograms and arrow plots as done in macavaney et al comparing our tem s impressions versus human written sions the histograms indicate the distribution of scores and arrows show how the scores changed between ours and human written the tail of each arrow shows the score of human written sion and its head indicates the score of our system s impression the numbers next to the tails express the count of impressions that gained score of by ours and s by gold we observed that while there is still a gap between the generated and human written impressions over of our system generated impressions are as good as the associated human written radiologists and one medical student tied or improved sions specically readability and accuracy of our system generated impressions ties with human written impressions both ing full score of nonetheless this percentage is for completeness metric the most likely planation of this gap is that deciding which ndings are more important i e should be written into pression is either subjective or highly correlates with the institutional training purposes hence we recognize cross organizational evaluations in terms of impression completeness as a challenging task we also evaluated the inter rater agreement using fleiss kappa fleiss for our system s scores and obtained for readability for accuracy and for completeness all of which are characterized as moderate agreement rate conclusion we proposed an approach to content selection for abstractive text summarization in clinical notes we introduced our novel approach to augment standard summarization model with signicant ontological terms within the source content selection problem is framed as a word level sequence tagging task the intrinsic evaluations on two publicly available real life clinical datasets show the efcacy of our model in terms of rouge metrics furthermore the extrinsic evaluation by domain experts further reveals the qualities of our system generated maries in comparison with gold summaries acknowledgement we thank arman cohan for his valuable comments on this work we also thank additional domain expert evaluators phillip hyuntae kim and ish talati references iz beltagy kyle lo and arman cohan scibert a pretrained language model for scientic text in emnlp adrian p brady error and discrepancy in in insights into diology inevitable or avoidable imaging arman cohan and nazli goharian ing summarization evaluation for scientic articles proc of conference on lrec pages dina demner fushman marc d kohli marc b rosenman sonya e shooshan laritza rodriguez sameer k antani george r thoma and clement j mcdonald preparing a collection of ology examinations for distribution and retrieval journal of the american medical informatics ciation jamia jacob devlin ming wei chang kenton lee and kristina toutanova bert pre training of deep bidirectional transformers for language ing in naacl hlt adam e flanders and paras lakhani ogy reporting and communications a look forward neuroimaging clinics of north america joseph l fleiss measuring nominal scale ment among many raters sebastian gehrmann yuntian deng and alexander m rush bottom up abstractive summarization in emnlp esteban f gershanik ronilda lacson and ramin rasani critical nding capture in the sion section of radiology reports in amia saeed hassanpour and curtis p langlotz mation extraction from multi institutional radiology reports articial intelligence in medicine wan ting hsu chieh kai lin ming ying lee kerui min jing tang and min sun a unied model for extractive and abstractive summarization using inconsistency loss in acl alistair e w johnson tom j pollard seth j berkowitz nathaniel r greenbaum matthew p lungren chih ying deng roger g mark and steven horng mimic cxr a large licly available database of labeled chest radiographs arxiv diederik p kingma and jimmy ba adam a method for stochastic optimization in iclr logan lebanoff kaiqiang song franck dernoncourt doo soon kim seokhwan kim walter chang and fei liu scoring sentence singletons and pairs for abstractive summarization in acl logan lebanoff kaiqiang song and fei liu adapting the neural encoder decoder framework from single to multi document summarization in emnlp junyang lin xu sun shuming ma and qi su global encoding for abstractive summarization in acl sean macavaney sajad sotudeh arman cohan nazli goharian ish talati and ross w filice ontology aware clinical abstractive summarization sigir nidhin nandhakumar ehsan sherkat evangelos e milios hong gu and michael butler ically signicant information extraction from ogy reports in doceng mark neumann daniel king iz beltagy and waleed ammar scispacy fast and robust els for biomedical natural language processing in matthew e peters mark neumann mohit iyyer matt gardner christopher clark kenton lee and luke zettlemoyer deep contextualized word sentations in proc of naacl abigail see peter j liu and christopher d manning get to the point summarization with generator networks in acl josef steinberger and karel jezek using latent semantic analysis in text summarization and mary evaluation in isim jeffrey b ware saurabh w jha jenny k hoang stephen r baker and jill wruble effective radiology reporting journal of the american lege of radiology jacr zhe xie yuanyuan yang mingqing wang ming hui li haozhe huang dezhong zheng rong shu and tonghui ling introducing information tion to radiology information systems to improve the efciency on reading reports methods of tion in medicine yongjian you weijia jia tianyi liu and wenmian yang improving abstractive document in marization with salient information modeling acl mark d kovacs maximilian y cho philip f burchett and michael a trambert benets of grated ris pacs reporting due to automatic tion of templated reports current problems in agnostic radiology yuhao zhang daisy yi ding tianpei qian pher d manning and curtis p langlotz learning to summarize radiology ndings in emnlp workshop on health text mining and mation analysis qingyu zhou nan yang furu wei shaohan huang ming zhou and tiejun zhao neural ment summarization by jointly learning to score and select sentences in acl qingyu zhou nan yang furu wei and ming zhou selective encoding for abstractive sentence summarization in acl
