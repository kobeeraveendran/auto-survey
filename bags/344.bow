evaluating evaluation text summarization manik bhandari pranav gour atabak ashfaq pengfei liu graham neubig carnegie mellon university mbhandar pgour aashfaq cmu edu t c o l c s c v v x r abstract automated evaluation metrics stand manual evaluation essential development text generation tasks text summarization eld progressed standard metrics nearly years rouge standard evaluation paper rization papers attempt evaluate evaluation method text summarization assessing ity automatic metrics scoring tem outputs abstractive extractive recently popular datasets level summary level evaluation settings nd conclusions evaluation rics older datasets necessarily hold modern datasets systems release dataset human judgments lected scoring neural tion systems abstractive extractive com neulab realsumm introduction text summarization manual evaluation plied pyramid method nenkova sonneau gold standard evaluation time required relatively high cost annotation great majority research papers summarization use exclusively automatic evaluation metrics rouge lin louis nenkova peyrard et al bertscore zhang et al score zhao et al metrics rouge far popular relatively little discussion rouge deviate human judgment potential deviation change conclusions drawn garding relative merit baseline proposed methods characterize relative goodness evaluation metrics necessary perform evaluation graham lin och dataset annotated human judgments e dang owczarzak test degree automatic metrics correlate therewith classic tac meta evaluation datasets years clear conclusions found hold modern systems summarization tasks lier works exemplify disconnect peyrard observed human annotated maries tac dataset lower ity produced modern systems automated evaluation metrics strongly disagree higher scoring range rent systems operate rankel et al observed correlation rouge human judgments tac dataset decreases looking best systems systems years ago far today s state art constrained existing human judgment datasets remains unknown existing metrics behave current scoring summarization tems paper ask question rapid progress model development rization models require evaluate ation process text summarization end create release large benchmark meta evaluating summarization metrics including outputs scoring extractive abstractive summarization systems cnn dailymail dataset automatic evaluations ation metrics including traditional metrics e rouge modern semantic matching metrics e bertscore moverscore nist tac summarization task biomedical summarization ability metrics observations existing human judgments tac observations new human judgments cnndm exp evaluate systems sec moverscore outperform metrics exp ii evaluate k systems sec k smaller de correlates humans exp iii compare systems sec moverscore outperform metrics exp iv evaluate summaries sec moverscore outperform metrics metrics lower correlations evaluating maries systems outperforms metrics moverscore performs worse extractive achieved nearly pearson correlation abstractive summaries extractive abstractive systems highly relates humans evaluating mix extractive abstractive systems metrics de correlate reliable abstractive systems reliable extractive systems rouge metrics outperform metrics extractive summaries metrics better evaluating summaries systems abstractive summaries metrics better summary level better system level table summary experiments observations existing human judgments tac contrasting observations newly obtained human judgments cnndm dataset refer sec details manual evaluations lightweight pyramids method shapira et al use gold standard evaluate rization systems automated metrics benchmark perform extensive analysis indicates need examine assumptions evaluation automatic summarization systems specically conduct experiments analyzing correspondence metrics human evaluation somewhat surprisingly nd previously attested properties metrics found tac dataset demonstrate different trends newly collected cnndm dataset shown tab example moverscore best performing metric evaluating summaries dataset tac signicantly worse collected cnndm set additionally ous works novikova et al peyrard et al chaganty et al metrics lower correlations comparing summaries systems extractive summaries cnndm metrics better comparing maries systems calls future research observations demonstrate limitations current performing metrics highlighting need future meta evaluation multiple datasets evaluate metrics different plication scenarios e summary level vs tem level need systematic evaluation summarization metrics updates evolving systems datasets potential benet summarization munity shared task similar rics task machine translation systems metrics co evolve statmt org preliminaries section describe datasets systems metrics meta evaluation methods datasets dang owczarzak multi document multi reference rization datasets human judgments available system summaries submitted shared tasks cnndm cnn dailymail hermann et al nallapati et al commonly summarization dataset contains news articles associated highlights summaries use version entities anonymized representative systems use following representative scoring systems achieve state art sota results competitive performance gather outputs cnndm dataset extractive summarization systems use cnn lstm biclassier clstm sl kedzie et al latent zhang et al ditsum dong et al refresh narayan et al neusum zhou et al hibert zhang et al bert ext liu lapata cnn biclassier ctrans sl zhong et al cnn transformer pointer ctrans pn zhong et al hetergraph wang et al matchsum zhong et al representatives extractive systems totaling extractive system outputs document cnndm test set abstractive summarization systems use pointer et al fastabsrl chen bansal rank chen bansal gehrmann et al raffel et al unilm dong et al unilm dong et al twostagerl zhang et al summabs liu lapata ext liu lapata bart lewis et al semsim yoon et al tive systems total use abstractive system outputs document cnndm test set evaluation metrics examine metrics measure ment texts case system summary reference summary bertscore bscore measures soft overlap tween contextual bert embeddings tokens tween zhang et al moverscore mscore applies distance measure contextualized bert elmo word zhao et al sentence mover similarity sms applies imum distance matching text based sentence embeddings clark et al word mover similarity wms measures larity minimum distance matching texts represented bag word kusner et al js divergence measures jensen shannon divergence text s bigram lin et al measure overlap igrams bigrams lin rouge l measures overlap longest mon subsequence texts lin use recall variant metrics pyramid method human evaluations inherently recall based mscore specic recall variant correlation measures pearson correlation measure linear lation variables popular evaluating metrics system level lee rodgers use implementation given nen et al william s signicance test means ing statistical signicance differences relations dependent variables williams code github com tiiiger bert score code github com aiphes moverscore wms sms github com sms calculated function dened github com ukplab genetic swarm mds l python wrapper com sebastiangehrmann rouge baselines graham baldwin useful metrics evaluated dataset independent meta evaluation strategies broad meta evaluation strategies summary level system level setup document n dataset d j system outputs outputs come extractive systems ext abstractive systems abs union mix let sij j j jth summary ith document mi specic metric k correlation measure summary level summary level correlation calculated follows ksum n n correlation calculated document different system outputs ment mean value reported system level system level correlation calculated follows k sys k n n n n n n n n additionally quality system sysj dened mean human score received e hscoresysj mean n n collection human judgments follow step process collect human judgments collect system generated maries commonly tion dataset cnndm select representative test samples cnndm manually evaluate system generated summaries selected test samples system generated summary collection collect system generated summaries scoring covering extractive abstractive systems sec cnndm dataset organize collected generated maries groups based system type cnndm abs denotes collected output maries abstractive systems cnndm ext denotes collected output maries extractive systems cnndm mix union representative sample selection collecting human annotations costly sample documents cnndm test set samples evaluate system generated summaries documents aim include documents varying difculties resentative sample proxy difculty summarizing document use mean score received system generated summaries document based partition cnndm test set equal sized bins sample uments bin repeat process metrics bertscore moverscore l obtaining sample documents methodology detailed alg sec human evaluation text summarization good summary represent relevant content input document possible acceptable length limits human evaluation methods proposed capture desideratum nenkova passonneau chaganty et al fan et al shapira et al pyramid nenkova passonneau reliable widely method evaluates content tion exhaustively obtaining semantic tent units scus reference summaries weighting based number times mentioned scoring system summary based scus inferred recently shapira et al extended mid lightweight crowdsourcable method litepyramids uses amazon mechanical amt gathering human annotations litepyramids simplies pyramid allowing contacted authors systems gather corresponding outputs including variants systems mturk crowd workers extract subset possible scus eliminating difcult task ing duplicate scus different reference maries instead scu sampling simulate frequency based weighting pyramid litepyramid rely ence multiple references document sign importance weights scus cnndm dataset reference summary document adapt litepyramid method single reference ting follows scu extraction litepyramids annotation structions dene semantic content unit scu sentence containing single fact written briey clearly possible instead focus shorter ne grained scus contain entities allows partial content overlap generated reference mary makes task easy workers tab gives example exhaustively extract reference summary requiring set scus exhaustive creases complexity scu generation task instead relying crowd workers create scus reference summaries end obtained nearly scus age reference summary system evaluation system evaluation set scus presented crowd workers workers paid similar shapira et al scaling rates fewer scus shorter mary texts abstractive systems pay summary extractive systems pay summary extractive summaries readable precisely overlap scus post process system output summaries presenting annotators true casing text stanford corenlp manning et al replacing unknown tokens cial symbol chaganty et al tab depicts example reference summary system summary scus extracted ence summary annotations obtained ating system summary annotation scoring robustness shapira et al system summary evaluated crowd workers worker annotates scus marking scu present representative sample found document ing scus reference summary bayern munich beat porto champions league tuesday pep guardiola s progressed aggregate reach thomas muller scored champions league goal pass mario gomez muller leading german scorer competition game muller led celebrations supporters megaphone system summary bart lewis et al bayern munich beat porto allianz arena tuesday night thomas muller scored champions league goal year old highest scoring german tournament took current shape bayern players remained pitch time celebrated supporters c scus corresponding evaluations bayern munich beat porto bayern munich won bayern munich won champions league bayern munich won tuesday bayern munich managed pep guardiola bayern munich progressed competition bayern munich reached bayern munich progressed aggregate thomas muller scored champions league goal thomas muller passed mario gomez goals thomas muller leading german scorer competition game thomas muller led celebrations thomas muller led celebrations phone table example summary corresponding annotation shows reference summary tative sample cnndm test set shows corresponding system summary generated bart abstractive systems study c shows scus semantic content units extracted marked crowd workers evaluating b inferred system summary present obtain total human tations documents systems workers document identify noisy worker disagrees majority e marks scu present majority thinks present vice versa largest number scus remove annotations noisy workers retain annotations ltering obtain average inter annotator agreement krippendorff s alpha krippendorff finally use majority vote mark presence scu system mary breaking ties class present experiments motivated central research question rapid progress model development rization models require evaluate tion process text summarization use collected human judgments meta evaluate current metrics diverse viewpoints suring ability metrics evaluate systems evaluate k strongest systems compare systems evaluate individual maries nd previously attested erties metrics observed tac exhibit different trends new cnndm dataset agreement extractive stractive systems respectively exp evaluating systems automatic metrics widely determine new system rank existing state art systems meta evaluation studies calculating correlation automatic rics human judgments system level commonly setting novikova et al bojar et al graham follow setting specically ask questions metrics reliably compare different systems answer observe pearson correlation tween different metrics human judgments fig nding moverscore best forming metrics tac poor correlations humans comparing cnndm ext systems metrics high correlations dataset suffer especially rouge based metrics rouge metrics consistently perform collected cnndm datasets metrics signicantly better ers comparing systems automated metrics calculated data dent perform william s test williams establish difference correlations metrics statistically signicant graham baldwin fig report values william s test nd cells p value rounded cnndm mix cnndm abs e cnndm ext figure value william s signicance test hypothesis system left y axis signicantly better system axis bscore refers bertscore mscore refers moverscore dark green value cell j denotes metric mi signicantly higher pearson correlation human scores compared metric mj value cell j refers case pearson correlation mi human scores mj sec ments comparing k systems k chosen based system s mean human score eqn observations presented fig nd k smaller metrics de correlate humans cnndm mix datasets getting negative correlations small values k fig interestingly sms r l improve performance k smaller cnndm ext negative correlations human ments k mains highly correlated human judgments cnndm abs values k takeaway metrics reliably quantify improvements system pecially systems datasets metrics suited specic datasets e reliable indicators improvements cnndm abs respectively exp iii comparing t wo systems instead comparing systems sec ranking systems aims test discriminative power metric e degree ric capture statistically signicant differences summarization systems analyze reliability metrics useful dimension metrics reliably system signicantly better annotated summaries compare systems use paired bootstrap resampling test statistical caveat perform signicance testing experiment small number data points figure system level pearson correlation metrics human scores sec moverscore signicantly better metrics correlating human ments tac datasets cnndm abs cnndm mix signicantly outperforms cnndm ext metrics signicant improvements takeaway results suggest metrics run risk overtting datasets ing need meta evaluate metrics modern datasets systems additionally metric outperform datasets suggests utility different metrics different datasets evaluate systems e moverscore cnndm datasets exp ii evaluating k systems papers propose new state art tem use automatic metrics proxy man judgments compare proposed method scoring systems metrics reliably quantify improvements high quality system makes competitive systems answer instead focusing collected systems evaluate tion automatic metrics human cnndm mix cnndm abs e cnndm ext figure system level pearson correlation humans k systems sec figure scores bootstrapping sec summary level pearson correlation human scores nicance better according metric m koehn dror et al pairs systems compare mean human score eqn paired bootstrap pling assign label ytrue better condence ytrue versa ytrue condence treat ground truth label pair process repeated metrics prediction ym pred ric m pairs m good proxy human judgments score goutte gaussier ym pred ytrue high calculate weighted macro score metrics view fig nd rouge based metrics perform moderately task performs best cnndm datasets tac dataset achieves highest score formance low cnndm ext takeaway different metrics better suited different datasets example cnndm datasets recommend tac datasets recommend exp iv evaluating summaries addition comparing systems real world plication scenarios require metrics reliably compare multiple summaries document example scoring reinforcement learning based summarization systems bohm et al current state art extractive system zhong et al heavily rely summary level reward difference system level summary level son correlation figure pearson correlation metrics man judgments different datasets sec scores guide optimization process experiment ask question different metrics perform summary comparing system summaries level e erated document use eq calculate pearson correlation different metrics human judgments different datasets collected system outputs observations summarized fig nd compared semantic matching metrics r l lower correlations tac datasets strong indicators good maries especially extractive summaries cnndm dataset notably bertscore wms r l negative correlations form moderately datasets including cnndm previous meta evaluation studies novikova et al peyrard et al chaganty et al conclude automatic metrics tend relate humans system level poor correlations instance mary level nd observation holds metrics summary level lations outperform system level cnndm dataset shown fig bins y notably moverscore correlation cnndm ext system level summary level takeaway meta evaluations metrics old tac datasets signicantly different trends meta evaluation modern systems datasets metrics good comparing summaries point wrong direction comparing systems metrics poor generalization ability different datasets e bertscore vs datasets highlights need empirically testing efcacy ent automatic metrics evaluating summaries multiple datasets related work work connected following threads topics text summarization human judgment collection despite approaches acquisition human judgment chaganty et al nenkova passonneau shapira et al fan et al pyramid nenkova passonneau mainstream method meta evaluate automatic metrics specically pyramid provides robust technique evaluating content selection exhaustively obtaining set semantic content units scus set references scoring system summaries scus inferred recently shapira et al proposed lightweight crowdsourceable version original pyramid demonstrated duc dang dang multi document summarization datasets paper human evaluation methodology based pyramid nenkova passonneau litepyramids shapira et al techniques chaganty et al obtain human evaluations system summaries cnndm dataset focus language quality summaries comparison work focused evaluating content selection work covers systems study extractive abstractive vs abstractive meta evaluation human judgment effectiveness different automatic metrics lin rouge l lin rouge ng abrecht louis nenkova peyrard et al commonly evaluated based tion human judgments e dang owczarzak dang owczarzak datasets important supplementary technique evaluation graham advocate use signicance test william s test williams measure improved correlations metric human scores lar variant rouge mean score sub optimal unlike works instead ing new metric paper upgrade meta evaluation environment introducing able human judgment dataset evaluating current scoring systems mainstream datasets evaluate diverse metrics level summary level settings novikova et al analyzes existing metrics focus dialog generation implications future directions work diagnoses limitations current metrics highlights importance upgrading existing meta evaluation testbed keeping date rapid development systems datasets closing highlight potential future directions choice metrics depends different tasks e g summarization translation different datasets e tac cnndm application narios e g system level summary level future works meta evaluation investigate fect settings performance metrics metrics easily overt limited datasets dataset meta evaluation help better stand metric s peculiarity achieving better choice metrics diverse ios collected human judgments supervision instantiate proposed pretrain framework nally machine translation sellam et al learning robust metric text summarization acknowledgements sincerely thank authors systems work sharing systems outputs references ondrej bojar yvette graham amir kamran milos stanojevic results proceedings rics shared task ference machine translation volume shared task papers pages berlin germany sociation computational linguistics florian bohm yang gao christian m meyer ori shapira ido dagan iryna gurevych ter rewards yield better summaries learning marise references arun tejasvi chaganty stephen mussman percy liang price debiasing automatic rics natural language evaluation yen chun chen mohit bansal fast tive summarization reinforce selected sentence rewriting proceedings annual ing association computational tics volume long papers pages bourne australia association computational linguistics elizabeth clark asli celikyilmaz noah smith sentence mover s similarity automatic proceedings uation multi sentence texts annual meeting association putational linguistics pages hoa dang karolina owczarzak overview tac update summarization task ceedings text analysis conference tac pages hoa dang karolina owczarzak overview tac summarization track proceedings text analysis conference tac pages hoa trang dang overview duc proceedings document understanding conf wksp duc human language technology conf empirical methods natural language processing hlt emnlp hoa trang dang overview duc proceedings hlt naacl li dong nan yang wenhui wang furu wei aodong liu yu wang jianfeng gao ming zhou hsiao wuen hon unied language model pre training natural language ing generation advances neural tion processing systems pages rotem dror gili baumer segev shlomov roi ichart hitchhiker s guide testing tical signicance natural language processing proceedings annual meeting sociation computational linguistics volume long papers pages melbourne tralia association computational linguistics angela fan david grangier michael auli controllable abstractive summarization ings workshop neural machine lation generation pages melbourne australia association computational tics sebastian gehrmann yuntian deng alexander rush abstractive summarization proceedings conference cal methods natural language processing pages cyril goutte eric gaussier probabilistic interpretation precision recall score implication evaluation european conference information retrieval pages springer yvette graham evaluating automatic marization bleu shades rouge proceedings conference cal methods natural language processing pages lisbon portugal association tational linguistics yvette graham timothy baldwin testing signicance increased correlation human proceedings conference judgment empirical methods natural language ing emnlp pages doha qatar ation computational linguistics karl moritz hermann tomas kocisky edward stette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read advances neural comprehend tion processing systems pages chris kedzie kathleen mckeown hal daume iii content selection deep learning models proceedings summarization ference empirical methods natural language processing pages philipp koehn statistical signicance tests machine translation evaluation ings conference empirical ods natural language processing pages barcelona spain association tional linguistics yue dong yikang shen eric crawford herke van hoof jackie chi kit cheung sum extractive summarization contextual dit proceedings conference pirical methods natural language processing pages brussels belgium association computational linguistics klaus krippendorff computing krippendorff alpha reliability matt kusner yu sun nicholas kolkin kilian weinberger word embeddings ument distances international conference chine learning pages w alan lee rodgers thirteen ways look correlation coefcient american tician mike lewis yinhan liu naman goyal jan ghazvininejad abdelrahman mohamed omer levy ves stoyanov luke zettlemoyer bart denoising sequence sequence pre training natural language generation translation comprehension arxiv preprint chin yew lin rouge package matic evaluation summaries text summarization branches chin yew lin guihong cao jianfeng gao yun nie information theoretic approach automatic evaluation summaries ings human language technology ence naacl main conference pages new york city usa association tational linguistics chin yew lin franz josef och orange method evaluating automatic evaluation rics machine translation coling ceedings international conference computational linguistics pages geneva switzerland coling yang liu mirella lapata text proceedings tion pretrained encoders conference empirical methods ural language processing international joint conference natural language processing emnlp ijcnlp pages hong kong china association computational linguistics yang liu mirella lapata text tion pretrained encoders annie louis ani nenkova automatically assessing machine summary content gold standard computational linguistics christopher d manning mihai surdeanu john bauer jenny finkel steven j bethard david closky stanford corenlp natural guage processing toolkit association tational linguistics acl system demonstrations pages ramesh nallapati bowen zhou cicero dos santos c glar bing xiang tive text summarization sequence sequence rnns conll page shashi narayan shay b cohen mirella lapata ranking sentences extractive tion reinforcement learning proceedings conference north american ter association computational linguistics human language technologies volume long pers pages new orleans louisiana association computational linguistics ani nenkova rebecca passonneau ing content selection summarization proceedings human mid method guage technology conference north chapter association computational linguistics hlt naacl pages boston massachusetts usa association putational linguistics jun ping ng viktoria abrecht better marization evaluation word embeddings rouge proceedings conference empirical methods natural language processing pages lisbon portugal association computational linguistics jekaterina novikova ondrej dusek amanda cas curry verena rieser need proceedings new evaluation metrics nlg conference empirical methods natural language processing pages copenhagen denmark association tional linguistics maxime peyrard studying summarization uation metrics appropriate scoring range proceedings association computational linguistics pages florence italy association tational linguistics annual meeting maxime peyrard teresa botschen iryna gurevych learning score system summaries better content selection evaluation proceedings workshop new frontiers summarization pages copenhagen mark association computational linguistics colin raffel noam shazeer adam roberts katherine lee sharan narang michael matena yanqi zhou wei li peter j liu exploring limits transfer learning unied text text peter rankel john m conroy hoa trang dang ani nenkova decade automatic tent evaluation news summaries reassessing state art proceedings annual meeting association computational guistics volume short papers pages soa bulgaria association computational guistics abigail peter j liu christopher d manning point summarization generator networks proceedings nual meeting association computational linguistics volume long papers pages vancouver canada association tional linguistics thibault sellam dipanjan das ankur p parikh bleurt learning robust metrics text eration arxiv preprint ori shapira david gabay yang gao hadar nen ramakanth pasunuru mohit bansal yael sterdamer ido dagan crowdsourcing lightweight pyramids manual summary tion proceedings conference north american chapter association putational linguistics human language gies volume long short papers pages minneapolis minnesota association putational linguistics wei zhao maxime peyrard fei liu yang gao tian m meyer steffen eger moverscore text generation evaluating contextualized beddings earth mover distance proceedings conference empirical methods natural language processing tional joint conference natural language cessing emnlp ijcnlp pages hong kong china association computational guistics ming zhong pengfei liu yiran chen danqing wang xipeng qiu xuanjing huang tive summarization text matching arxiv preprint ming zhong pengfei liu danqing wang xipeng qiu xuan jing huang searching tive neural extractive summarization works s proceedings ence association computational tics pages qingyu zhou nan yang furu wei shaohan huang ming zhou tiejun zhao neural ument summarization jointly learning score select sentences proceedings nual meeting association computational linguistics volume long papers pages melbourne australia association tational linguistics pauli virtanen ralf gommers travis e oliphant matt haberland tyler reddy david peau evgeni burovski pearu peterson warren weckesser jonathan bright stefan j van der walt matthew brett joshua wilson k jarrod millman nikolay mayorov andrew r j nelson eric jones robert kern eric larson cj carey ilhan polat yu feng eric w moore jake vand erplas denis laxalde josef perktold robert cimrman ian riksen e quintero charles r harris anne m archibald antonio h ribeiro fabian pedregosa paul van mulbregt scipy contributors scipy fundamental algorithms scientic computing python nature methods danqing wang pengfei liu yining zheng xipeng qiu xuanjing huang heterogeneous graph neural networks extractive document marization arxiv preprint evan j williams regression analysis wiley new york wonjin yoon yoon sun yeo minbyul jeong jun yi jaewoo kang learning mantic similarity makes abstractive summarization better arxiv preprint haoyu zhang yeyun gong yu yan nan duan jun xu ji wang ming gong ming zhou language arxiv preprint eration text summarization pretraining based natural tianyi zhang varsha kishore felix wu kilian q weinberger yoav artzi bertscore international uating text generation bert conference learning representations xingxing zhang mirella lapata furu wei ming zhou neural latent extractive document marization proceedings conference empirical methods natural language ing pages brussels belgium association computational linguistics xingxing zhang furu wei ming zhou hibert document level pre training cal bidirectional transformers document proceedings annual rization ing association computational tics pages florence italy association computational linguistics summary level kendall correlation human scores difference system level summary level kendall correlation figure kendall correlation metrics man judgements different datasets exp ii kendall s tau correlation figure system level kendall s tau correlation k systems different metrics human judgements exp iv kendall s tau correlation figure summary level kendall s tau correlation different metrics man judgements appendices sampling methodology algorithm algorithm sampling methodology data ri si d d cnndm test set source document ri reference summary si set individual system summaries sij si m rouge l bertscore output dout sampled set documents m si m std si m m m m dout m m d sorted m k k sorted m l l randomly sample di dout dout end end end exp kendall s tau correlation figure system level kendall s tau correlation different metrics man judgements figure system level kendall correlation metrics human scores cnndm mix cnndm abs e cnndm ext figure system level kendall correlation humans k systems
