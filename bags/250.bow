c e d l c s c v v x r generating summaries tailored target characteristics kushal chawla hrituraj singh arijit pramanik mithlesh kumar balaji vasan srinivasan adobe research bangalore india indian institute technology roorkee indian institute technology bombay indian institute technology kanpur com com abstract recently research eorts gained pace cater varied user preferences generating text summaries attempts incorporate handpicked characteristics length entities holistic view preferences missing crucial insights certain characteristics incorporated cic manner absent objective provide categorization characteristics relevant task text summarization focusing content needs generated second focusing stylistic aspects output summaries use insights provide guidelines appropriate methods incorporate classes characteristics sequence sequence summarization framework experiments incorporating topics readability simplicity cate viability proposed prescriptions introduction automatic text summarization task generating summary input document retaining key aspects summary helps senting important content long input text succinct form quick information consumption traditional methods summarization tract key sentences source text construct extractive summary recent eorts abstractive summarization geared ating human like paraphrased summaries input article algorithms allow generation single summary desirable generate summary variants tailored specic teristics instance readers interested summaries dierent lengths want focus specic entities topics input text pending dierent age groups readers prefer formal informal variants summary irrespective application context shown incorporating characteristics time generation yield contextual summaries recent works proposed dierent ways incorporate target teristics time summary generation introducing modications architecture learning objectives decoder probabilities attempts handpick characteristics propose ways incorporate absence appropriate insights unclear methodologies work tuning summaries chosen acteristics extended characteristics work objective gain holistic understanding additional constraints centering task text summarization taking step direction propose categorization acteristics content specic primarily focus content presented pivoting semantics information presented output mary style specic focusing stylistic expressions pivoting linguistic presentation output summary comparative tion existing proposed methods prescribe guidelines help choosing right framework tailoring categories characteristics primary contribution providing categorization target characteristics content style specic holistic understanding tailored mary generation additionally propose attention boosting approach improve tailoring content specic characteristics policy gradient based algorithm incorporate stylistic characteristics summaries related work traditional methods summarization extract key sentences source text construct extractive summary features like descriptiveness words word frequencies explored choose summary sentences humans summarize understanding content paraphrasing understood content summary extractive summarization unable produce human like summaries led eorts abstractive summarization paraphrase summaries input article content early attempts abstractive summarization created summary sentences ther based templates ilp based sentence compression niques advent deep sequence sequence models attention based neural models proposed summarizing long tences approaches improved incorporating stract meaning representations hierarchical encoding networks recent approaches focused large scale datasets rization cnn dailymail corpus gulcehre et al introduced ability copy vocabulary words article incorporate rarely seen words like names generated text tu et al included concept coverage prevent models repeating phrases erating sentence et al proposed pointer generator framework incorporates improvements learns switch generating new words copying words source article research primarily focused unconditioned abstractive text summarization recent eorts incorporate variety additional constraints generation algorithm fan et al use explicit indicators control length output summary imposing constraint detailed output needs extend technique control entities focused generating summary krishna et al generated topic oriented summaries indicator topic vector input representation approaches aim control information presented generated summary modies attention distribution focus appropriate parts text dictated target characteristics group approaches specic characteristic tuning direction eorts attempted incorporate aspects like ments tense generative models like variational auto encoders ing adversarial training focusing politeness sennrich et al propose modications neural machine translation setup generate polite variants propose use conditional language model generate ficler et al text variations descriptiveness personal sentiment ously recently generating text varying levels formality studied machine translation oraby et al attempt control personality dimensions generation agreeable disagreeable conscientious scientious extravert indicator tokens stylistic encodings ishna et al modify decoding algorithm produce readable simple summaries exploration focus primarily tuning linguistic presentation generated text group style specic teristic tuning policy learning based approaches shown promise control qualitative characteristics explicitly potentially content style specic characteristics successfully deployed metrics like rouge applicability style specic characteristics proposing policy gradient framework readability simplicity content vs style notion style associated nomenclature convoluted literature approaches style transfer try obtain independent latent representations style semantics content interpretation output text generation system combination semantics information presented style associated content unlike approaches learn notion style implicitly available corpora fragment style set dimensions readability simplicity referred aspects style aligning ad approaches style transfer described pointer generator framework base explorations pointer generator network ndings insights generic extended works loss generality describe pointer generator framework sake completion refer details framework pointer generator network consists encoder coder based lstm architecture given input article encoder takes embedding vectors word source text computes encoder hidden states hn nal hidden state passed coder computes hidden state st decoding step calculates attention distribution words vt wsst batt et t n v wh ws batt model parameters trained attention probability distribution words source text aids decoder generating word summary words source text higher attention context vector h ihi weighted sum attention ith input word encoder hidden states weighted tth step determine word generated attention distribution allows network focus specic parts input output summary generated tailor summary content specic characteristics important modify attention distribution focus appropriate parts input text required characteristics tuned decoding step decoder gets word yt summary generated far computes scalar pgen denoting probability ating new word vocabulary pgen y yt bgen wh ws wy bgen trained vectors network probabilistically decides based pgen generate new word vocabulary copy word source text attention distribution word w vocabulary model calculates probability word getting generated word input article total attention received yields probability copied words occur vocabulary input article non zero probabilities newly generated copied total probability w word generated p given s st wt t wt h h pgen wi w second term allows framework choose word copy text attention distribution pointer generator network employs coverage mechanism encourage diversity attention distributions time steps training loss set average negative log likelihood ground truth summaries model trained propagation adagrad gradient descent algorithm stylistic characteristics deal specic expressions output text tailored modifying incorporate corresponding stylistic preferences complex characteristics possible dene reinforcement learning based loss appended training loss tailor specic characteristics content specic characteristics content specic characteristics primarily govern content needs sented output summary rest paper illustrate needs modeling content based characteristics topical tailoring proposed approach extended content characteristics like entity centric tailoring content article relevant readers prefer specic elements input summarized instance sports enthusiast interested content concerning domain surgeon interested health related content calls need generate multiple summary variants taking information account table shows particular instance dataset talks politics military reader interested politics baseline summary generated pointer generator pgen model refer politics fails meet needs article bernie sanders vermont senator friend years running president noted announcement familiar note wise irony people underestimate americans course sen bernie sanders barely known general public makes long shot win election highest oce nation cnn impressively polite bright eyes boyhood teachers encourager college friends docile captured killer care paramedics tending gunshot wounds dzhokhar jahar tsarnaev s defense team seeking spare death sentence years ago boston marathon bombings murder mit police ocer pgen dzhokhar jahar tsarnaev s defense team seeking spare death sentence docile captured killer care paramedics tending gunshot wounds tsarnaev convicted april counts including carry possible death penalty token based mixed attention boosting politics sen bernie sanders running president barely known general public makes long shot barely known general public makes long shot token based mixed attention boosting military dzhokhar jahar tsarnaev s defense team seeking spare death sentence convicted april counts including carry possible death penalty paramedic testied wednesday common patients shock agitated table sample output topic tailored summaries generated token based proach trained cnn dm mixed dataset sentences input article interest space sequence sequence learning models shown understand look input attention mechanisms output generation tailoring content specic characteristics require attention tuned focus relevant parts input e relevant parts input talking topic interest generate desired output requires model taught explicitly implicitly attend input article tailor summary appropriately possibility maintain explicit indicators category characteristic e topic allowing model learn pay attention directly data fan et al propose use dicator tokens tune characteristics length desired entities training article summary pair belonging particular bin token indicating characteristic topic case represented summary added beginning input article decoding unseen article framework generate multiple summary variants based token prepended input word sequence internally model uses token learn conditioned space parameters ensuring appropriate attention tuning generate summary corresponding tailoring refer approach token based experiments key requirement model learn intricacies training data contain sucient samples category skew dataset calls alternate approach tackle characteristics deal problem krishna et al create separate dataset model sees multiple summary variants input article mixing multi topic articles given dataset vocabulary tokens guide learning process topic specic attention skewed dataset method called token based mixed trained interspersed dataset use token based approaches implicitly teach networks taking advantage diversity training data propose alternative explicitly boost attention distributions referred attn boost restricting model focus parts input formally modify eq pointer generator ivt wsst batt v wh ws batt trainable model parameters use ei compute attention word specic attention boosting parameter explicitly teaches model pay attention specic words leverage topic specic word lists curated select experiments sentences input article related target topic explicitly boost words sentences topic condence measures draw insights approaches evaluate task topic based summarization cnn dailymail cnn dm dataset dataset consists training validation test instances articles average length tokens sentence summaries average length tokens use vanilla pointer generator pgen baseline experiments retaining train token based model topics parameters et al categorizing ground truth summaries topics business education entertainment health military politics social sports technology extending setup prepending topic input article training following setup intersperse articles dierent topics cnn dm resulting multiple topic specic ground truth summaries article topics model sees multiple summaries article article summary topic tuples training tuples validation tuples test dataset evaluate generation quality approaches compare rouge l score note generating summaries topics sense input article particularly article talk target topic article test set generate summary corresponding target topic dened ground truth summary use topic specic word lists topics decoded summaries fraction times target topic lies topics decoded summaries denes accuracies setups method rouge f score accuracy l pgen token based attn boost proposed token based attn boost token based mixed attn boost table performance proposed methodologies generating topic tuned summaries cnn dm mixed test dataset table summarizes results methods generating topic oriented summaries observe boosting attention values explicitly shows ment topic percentage accuracies suers decline quality based rouge scores expected explicit topic attention model attend parts documents dierent ground truth summary hand token based approach improves rouge lesser topical accuracy combined framework token based attention boosting yields best performance rouge topical accuracy metrics combined setup model learns intricacies implicit data explicit attention topics getting best frameworks train setup mixed dataset rouge topical accuracies improve ing importance diversity data network implicitly learn attention patterns generated summaries token based approach table particular instance testing dataset article created bining articles politics military domain proposed approach appended token based framework cnn dm mixed dataset able generate topic specic variants pgen approach fails meet quirement topics figure shows average attention attended parts input instance token based model trained cnn dm mixed generating politics oriented summary attention words like president bernie sanders general public showing bias political phrases hand target topic military focus attention shifts death sentence defence team politics military fig attention distribution source article dierent target ics evaluations tuning content based characteristics achieved modifying attention network implicitly explicitly plicit attention modication uses token based approach relies diversity characteristics data available feeding o interspersed dataset articially infuse diversity benecial bining interspersed dataset explicitly attention boosting framework model able tune characteristics better learning attend attend tuning content based characteristics stylistic characteristics focus incorporating stylistic characteristics generated mary style specic preferences ensure content served appropriately target audience direction prior work focused incorporating dimensions sentiment descriptiveness formality tasks text generation describe methodology incorporate characteristics abstractive text summarization way stylistic aspects incorporated sequence sequence summarization framework depends aspects dened ample simplicity text dened lexical level based frequency simple corpus dened krishna et al extend generating simple summary modifying decoder probability eq incorporate simplicity modifying beam search decoder choose contextual replacement words simpler dening simplicity m m frequency ith word subtlex ishna et al use word word replacement probabilities achieve tailoring aspects dened lexical level straightforward modify decoder probability example ability quantied flesch reading ease score given total words total sentences total syllables total words flesch reading ease score quanties diculty understanding passage written english higher scores indicate easier read passages posits readability inversely related average number words sentence average number syllables word partial form denition propose use shorter words lesser syllables surrogate reading ease use modify decoder probabilities ignoring rst component reading ease makes incomplete tailoring accounting rst component require sentence generated providing feedback model generated ity propose use reinforcement learning based framework incorporate complex objectives requiring generation complete partial feedback generation recently reinforcement learning frameworks successfully optimize text generation content based metrics e rouge scores summarization cider scores image captioning extend propose reinforcement loss stylistic elements additional term cross entropy self critical sequence training scst algorithm given input article word sequence corresponding ground truth t pointer generator framework optimizes summary y y y negative log likelihood objective function given y lnll t y t providing explicit feedback stylistic characteristics output quences generated time training sampled sequence ys baseline sequence yb generate ys sampling bution time step greedily choosing word maximum probability output distribution time step scst algorithm denes loss term lnll reward target style characteristics ys ys lrl ys t reward function based target style characteristic optimized optimizing lrl improves expected reward generated output nal loss linear combination lnll lrl given l lnll lrl governs strength rl based loss term reinforcement learning allows loss function include non dierentiable metric form rewards leveraged optimize complex stylistic aspects directly self critical sequence training approach helps dealing exposure bias limitation teacher forcing algorithm training recurrent neural networks sampled sequences model exposed distribution learning generate accordance global meta properties evaluate methodology incorporating characteristics use setup improve readability simplicity generated maries incorporate corresponding metrics learning algorithm rectly reward function reinforcement learning based loss function lrl gain insights appropriate methods tailoring stylistic acteristics compare rl based approach pointer generator method use vocabulary tokens adapted fying word word anity probabilities adapted adapt token based approach readability dene tokens readable readable based readability ground truth summary compared median value ing dataset evaluate lexical level modications suggested use voting method modify generation probabilities moting generation shorter words longer synonyms finally rl based approach observe training reinforcement loss extremely slow owing computation sampled greedy sequences teacher forced outputs use pgen model pre trained cnn dm dataset initialization point e training train iterations xed similarly simplicity leverage work measure simplicity based eq establish baselines similar readability based method directly uses simplicity score reward function token based approach divide ground truth summaries classes simple simple thresholding median observed training dataset similar content specic characteristics use rouge rouge rouge l f scores evaluate overlap generated truth summaries evaluate models able capture ability denition report average flesch reading ease score ated summaries simplicity report corresponding average simplicity score note objective understand methods able capture given denition style specic characteristics evaluated tailoring based dened target metrics table summarizes experiments readability simplicity serve trade o use simpler readable words vocabulary generation quality captured rouge metric primarily deviation simpler readable words ones erence summaries proposed rl based approach better able capture readability achieving higher average scores approaches best model simplicity lexical modications coder beats rl method suggests entire sequence needs generated measure stylistic aspect like readability useful resort rl based frameworks stylistic aspect sured lexically decoder modications perform better exist works reinforcement learning literature explored actor critic methods provide intermediate feedback model generating plete output sequences partial rewards exploring techniques tackle simpler complex denitions style specic constraints topic future work note token based frameworks mixed results heavily relies diversity training data explicit signal suited stylistic aspects training data contains sucient diversity possible train joint model trained feedback ground truth summaries data sequences sampled output distributions token based framework subject research readability simplicity method rouge f score readability rouge f score simplicity pgen token based voting rl based l l table performance proposed approach improving readability simplicity generated summaries table shows generated output summaries rl based approach pgen baseline model instance cnn dm dataset rl based method achieves better readability scores shorter sentence structs framework teach model sentence level characteristics required achieve target style similarly summaries ated voting based approach shown table generated summaries uses simpler words summaries big place major hurt place injured similar manner careful modications generated probabilities decoding incorporate stylistic aspects dened lexical level killing employee wayne community college goldsboro north carolina hate crime authorities said tuesday investigators looking possibility said goldsboro police sgt jeremy sutton explain hate crime victim ron lane ocials said longtime employee school s print shop operator white suspect lane s relatives said gay cnn aliate wncn reported suspect kenneth morgan stancil iii worked lane work study program let program early march poor attendance college president kay albertson said tuesday monday stancil walked print shop oor campus building aimed pistol grip shotgun red killing lane according sutton stancil tattoos face relatives wayne community college shooting victim gay local media report suspect worked victim let college president says suspect kenneth morgan stancil iii found sleeping orida beach arrested wayne community college north carolina hate crime authorities investigators looking possibility said goldsboro police sgt jeremy sutton investigators looking possibility said goldsboro police sgt jeremy sutton rl killing employee wayne community college hate crime suspect kenneth morgan stancil iii worked lane work study program previous criminal record authorities table sample output summary generated incorporating readability reward function baseline reference summaries instance cnn dm mixed dataset numbers brackets refer sponding readability scores sentences input article interest space conclusions work study variety constraints imposed generating abstractive summaries given input article categorizing constraints content specic govern content needs generated style specic govern stylistic expressions outputs experiments indicate content based characteristics tailored summary explicitly implicitly tuning attention focus relevant parts network approach tailor stylistic constraints depends nature denition characteristics dened lexical level tuned better modifying decoder probabilities beam search complicated metrics tuned reinforced rewards loss function references nenkova mckeown k automatic summarization foundations trends information retrieval article hong kong cnn people hurt explosion troversial chemical plant china s southeastern fujian province sparked huge provincial authorities told state media plant located zhangzhou city produces paraxylene px reportedly carcinogenic chemical production polyester lms fabrics blast occurred oil storage facility monday night oil leak local media reported toxic chemical spill summary ve people broken glass sent hospital treatment article cnn debates climate change break fairly fast believe mankind s activities changing planet s climate nt new way talk climate change emerging shifts focus impersonal discussions greenhouse gas emissions power plants personal health summary s easy brush aside debates involving international corporations nt stop think health table sample simplied summaries generated proposed approach words bold use simpler summaries generated approach words italics picked baseline model nallapati r zhai f zhou b summarunner recurrent neural network based aaai sequence model extractive summarization documents liu p j manning c d point summarization annual meeting association computational generator networks linguistics acl fan grangier d auli m controllable abstractive summarization arxiv preprint krishna k srinivasan b v generating topic oriented summaries neural attention conference north american chapter association computational wang l yao j tao y zhong l liu w du q reinforced aware convolutional sequence sequence model abstractive text tion arxiv preprint niu x martindale m carpuat m study style machine translation controlling formality machine translation output proceedings conference empirical methods natural language processing krishna k murhekar sharma s srinivasan b v vocabulary tailored summary generation international conference computational linguistics coling paulus r xiong c socher r deep reinforced model abstractive marization arxiv wang l cardie c domain independent abstract generation focused meeting summarization acl genest p e lapalme g framework abstractive summarization text generation workshop monolingual text text generation filippova k multi sentence compression finding shortest paths word graphs international conference computational linguistics coling berg kirkpatrick t gillick d klein d jointly learning extract press annual meeting association computational linguistics acl banerjee s mitra p sugiyama k multi document abstractive summarization ilp based multi sentence compression ijcai sutskever vinyals o le q v sequence sequence learning neural advances neural information processing systems networks rush m chopra s weston j neural attention model abstractive tence summarization conference empirical methods natural language processing chopra s auli m rush m harvard s abstractive sentence summarization attentive recurrent neural networks hlt naacl takase s suzuki j okazaki n hirao t nagata m neural headline ation abstract meaning representation proceedings conference empirical methods natural language processing nallapati r zhou b dos santos c gulcehre c xiang b abstractive signll text summarization sequence sequence rnns conference computational natural language learning hermann k m kocisky t grefenstette e espeholt l kay w suleyman m blunsom p teaching machines read comprehend advances neural information processing systems gulcehre c ahn s nallapati r zhou b bengio y pointing known words annual meeting association computational linguistics acl tu z lu z liu y liu x li h modeling coverage neural machine lation annual meeting association computational linguistics volume long papers hu z yang z liang x salakhutdinov r xing e p controlled generation text international conference machine learning shen t lei t barzilay r jaakkola t style transfer non parallel text cross alignment advances neural information processing systems sennrich r haddow b birch controlling politeness neural machine translation constraints proceedings conference north american chapter association computational linguistics human language technologies ficler j goldberg y controlling linguistic style aspects neural language generation proceedings workshop stylistic variation niu x rao s carpuat m multi task neural models translating styles languages arxiv preprint oraby s reed l tandon s sharath t lukin s walker m controlling personality based stylistic variation neural natural language generators arxiv preprint tikhonov yamshchikov p wrong style transfer texts arxiv preprint artetxe m labaka g agirre e cho k unsupervised neural machine lation arxiv preprint han m wu o niu z unsupervised automatic text style transfer lstm national ccf conference natural language processing chinese puting springer xu j sun x zeng q ren x zhang x wang h li w unpaired sentiment sentiment translation cycled reinforcement learning approach arxiv preprint prabhumoye s tsvetkov y salakhutdinov r black w style transfer translation arxiv preprint zhang y ding n soricut r shaped shared private encoder decoder text style adaptation proceedings conference north chapter association computational linguistics human language technologies volume long papers volume duchi j hazan e singer y adaptive subgradient methods online learning stochastic optimization journal machine learning research paetzold g specia l lexenstein framework lexical simplication ceedings acl ijcnlp system demonstrations brysbaert m new b moving kucera francis critical evaluation current word frequency norms introduction new improved word frequency measure american english behavior research methods flesch r f write plain english book lawyers consumers harpercollins rennie s j marcheret e mroueh y ross j goel v self critical sequence training image captioning cvpr bahdanau d brakel p xu k goyal lowe r pineau j courville bengio y actor critic algorithm sequence prediction arxiv preprint
