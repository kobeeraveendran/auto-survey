r m l c s c v v x r published conference paper iclr bert fine tuning arabic text summarization khalid n elmadani mukhtar elgezouli anas showk department electrical electronics engineering p o box khartoum sudan khalidnabigh com anas edu abstract fine tuning pretrained bert model state art method tive abstractive text summarization paper showcase tuning method applied arabic language construct rst documented model abstractive arabic text summarization mance arabic extractive summarization model works multilingual bert arabic language pretrained bert performance english rst applying arabic corpora extractive abstractive tasks introduction arabic ofcial languages united nations mother tongue million ple ofcial language countries africa arabic huge inuence mother africa forming culture religious values west africa consequently safe arabic latin africa arabic script alphabet written right left types symbols arabic script letters diacritics habash letters letters shape changes based position character holds possible diacritics syntax word sentence depends letters diacritic unfortunately diacritics usually absent texts news articles online content main challenge arabic text summarization ambiguity arabic language meaning text depends heavily context text summarization extract generate key information brief expression long documents generally approaches text summarization extractive involves extracting relevant phrases document organizing form summary involves going hole document try write summary abstractive words arabic text summarization works related languages research focused extractive approaches based sentences scoring selecting best ones summary approaches sentence scoring selection al qassem et al symbolic based systems model discourse structures text numerical based systems assign numerical scores words sentences reects signicance hybrid systems combine symbolic based numerical based methods recently jaafar bouzoubaa suggested hybrid approach produce abstractive summaries based extractive ones data sets english golden standard text summarization strongly vast number proposed benchmark data sets containing huge capacity summarized articles tive abstractive schemes like cnn daily mail news highlights data set hermann et al contains k news articles associated highlights important data set english xsum narayan et al contains news articles accompanied sentence authors contributed equally code available com mukhtar algezoli arabic presumm published conference paper iclr table rouge results cnn test set model rl bert m bert summary answering questionwhat article type rich corpus arabic language lacks automatic text summarization lack arabic benchmark corpora makes evaluation arabic summarization difcult unied benchmark corpus results reported existing model hint overall performance comparison al qassem et al recently turnout use corpora like easc containing arabic articles human generated extractive summaries articles kalimat multipurpose arabic corpus containing articles extractive summaries methodology pretrained bert devlin et al abstractive extractive tion encoder bertsum liu lapata pretrained bert expanded adding cls symbols learning sentence representations interval segmentation embeddings distinguish multiple sentences abstractive summarization task decoder layered formers vaswani et al initialized randomly mismatching encoder decoder encoder pretrained decoder lead unstable training liu lapata proposed new ne tuning schedule adopts different optimizers encoder decoder bertsumabs extractive summarization task sigmoid classier serted cls token encoder indicating sentence included summary bertsumext method pretrained bert perfect condition pretrained model compensate relatively small data set model applicable arabic language bert trained english documents answer multilingual bert m bert pires et al similar normal bert trained languages trained bertsumabs time bert m bert time cnn data set steps compare impact m bert instead bert sense m bert supports arabic finally included non pretrained transformer baseline extractive abstractive tasks order measure effect pretrained m bert transformerabs formerext encoders layered transformers rest architecture sumabs bertsumext respectively results ve automatically evaluated quality summary rouge lin och gram bi gram overlap reported means evaluating mativeness longest common subsequence rouge l means evaluating uency table demonstrates rst step arabic text summarization switching monolingual bert multilingual bert results similar performance compared bert m bert table presents results kalimat data set conclude pre trained m bert leads huge improvements performance relatively small data sets extractive abstractive summarization reveals extractive models higher performance extractive data sets corresponding abstractive ones published conference paper iclr table rouge results kalimat test set model rl bertsumext transformerext bertsumabs transformerabs paper showed multilingual bert applied arabic text summarization effective low resource situations research arabic nlp infancy compared english abstractive text summarization attempted time submission metrics output evaluate conclusion references lamees mahmoud al qassem di wang zaid al mahmoud hassan barada ahmad al rubaie nawaf almoosa automatic arabic summarization survey methodologies systems procedia computer science jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language understanding arxiv preprint nizar y habash introduction arabic natural language processing synthesis lectures human language technologies karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa advances suleyman phil blunsom teaching machines read comprehend neural information processing systems pp younes jaafar karim bouzoubaa new hybrid approach abstractive tion procedia computer science chin yew lin fj och looking good metrics rouge evaluation ntcir yang liu mirella lapata text summarization pretrained encoders arxiv preprint shashi narayan shay b cohen mirella lapata nt details topic aware convolutional neural networks extreme summarization arxiv preprint telmo pires eva schlinger dan garrette multilingual multilingual bert arxiv preprint ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser illia polosukhin attention need advances neural information processing systems pp workshop mary data pre processing kalimat multipurpose arabic corpus mainly extractive summarization section prepared bert raw data set category culture economy local news international news religion sport le containing articles month txt le text txt les published conference paper iclr ironically support arabic converted conveniently csv le standalone story le article summary summary formulated highlights end le stage preprocessing suggested liu lapata changes work arabic standford corenlp le replaced stanford stanford models path path stanford corenlp tokenizer sentence splitting tokenization paper split articles summaries sentences list vectors json le lastly tokenized vectors bert vocabulary multilingual bert model formatted pytorch les end got pytorch les entries entry containing src txt src original articles tokenized counterparts tokenized tgt txt tgt original summaries tokenized counterparts tokenized multilingual bert tokenizer multilingual bert tokenizer
