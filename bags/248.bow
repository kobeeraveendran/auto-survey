automatic generation headlines online math questions ke dafang zhuoren liangcai zhi c lee institute computer technology peking university beijing china pennsylvania state university university park pa usa school data computer science sun yat sen university guangzhou china edu cn edu sysu edu cn glc edu cn psu edu v o n l c s c v v x r abstract mathematical equations important tion communication scientic information students feel challenged reading ing math content equations development web students posting math questions online constructing concise math headline gives good description posted detailed math question nontrivial study explore novel summarization task denoted generating concise math headline detailed math question compared conventional summarization tasks task extra essential constraints detailed math questions consist text math equations require unied framework jointly model textual mathematical information unlike text math equations contain semantic structural features captured address issues propose mathsum novel summarization model utilizes pointer mechanism combined head attention mechanism mathematical representation augmentation pointer mechanism copy textual tokens math tokens source questions order erate math headlines multi head attention mechanism designed enrich representation math equations modeling integrating semantic structural features evaluation collect available sets real world detailed math questions written math headlines experimental results demonstrate model mathsum signicantly outperforms state art models datasets introduction math equations widely elds science technology engineering mathematics stem daunting students understand math content equations reading stem lications liu qin jiang et al web students post detailed math questions online help recent question systems mathematics stack attempt address need corresponding authors stackexchange com net figure example detailed math question headline question complex long headline clear brief viewpoint questioners contents detailed math questions usually complex long order efciently help pose question helpful headline concise point correspondingly answer question swerers need clear brief headline quickly termine bother respond giving concise math headline detailed question important meaningful figure illustrates example tion headline posted mathematics stack s clear complicated question difcult answerers understand intent tioner concise headline effectively reduce cost operation end explore novel approach generating math headline detailed questions dene task summarization task pared conventional summarization tasks task extra essential issues need addressed jointly modeling text math equations unied framework textual words mathematical equations stackexchange com detailed math question studying proof existence theorem weak solutions parabolic equations galerkin approximation encountered following problem assume open set orthonormal basis l orthogonal let projection e clear need following sure true need obtain priori estimates appreciate help math headline orthogonal projection complex longclear brief information usually coexisting detailed questions brief headlines shown figure natural necessary process way text math tions schubotz et al yasunaga lafferty evident model ed framework instance yasunaga lafferty sunaga lafferty attempted utilize text mathematical representations treated arate components argue approach loses crucial information e position semantic pendency text equations capturing tic structural features math equations synchronously unlike text math equations contain semantic tures structural features instance equation f semantic tures different structural features isting research separately considers characteristics instance work yuan et al zanibbi et al considered structural mation equations mathematical information retrieval tasks work deng et al yasunaga ferty treated math equation basic symbols modeled text led structural features loss address issues propose mathsum novel method combines pointers multi head attention mathematical representation augmentation pointer mechanism copy textual tokens math tokens source questions order generate math headlines multi head attention mechanism designed enrich representation math equation separately eling integrating semantic structural features evaluation construct large datasets contain detailed questions corresponding math headlines matics stack exchange mathoverow respectively compare model abstractive extractive baselines experimental results demonstrate model signicantly outperforms strong baselines task summary contributions work innovative task generating concise math headline response giving detailed math question novel summarization model mathsum dresses essential issues task textual mathematical information jointly modeled unied framework semantic structural features math tions synchronously captured novel math best knowledge rst mathematical content question datasets associated headline information com yuankepku mathsum related work mathematical equation representation unlike text math equations highly structured contain semantic features structural tures recent work roy upadhyay roth zanibbi et al yuan et al jiang et al focused mainly structural features math equations lized tree structures represent equations mathematical information retrieval mathematical word problem ing work gao et al krstovski blei yasunaga lafferty instead focused mainly semantic features equations processed equation sequence symbols order learn representation mathematical equation generation similar text generation math equation generation widely explored recent work deng et al zhang bai zhu le indurkhya nakagawa utilized end end framework generate tions mathematical images e handwritten math equations work roy upadhyay roth wang et al inferred math equations word problem solving work supported limited types operators e work yasunaga ferty related created model ate equations given specic topics e electric eld task instead aims generating math headlines equations text clear topics challenging requires models erate correct equations correct positions ated headlines summarization headline generation summarization fundamental task natural language processing nlp categorized basically tractive methods abstractive methods extractive ods mihalcea tarau nishikawa et al tract sentences original document form mary abstractive methods liu manning tan wan xiao narayan cohen lapata gavrilov kalaidin malykh aim ating summary based understanding document view headline generation special type marizaton constraint short sequence words generated preserves essential meaning math question document recently line generation methods end end frameworks tan wan xiao narayan cohen lapata zhang et al gavrilov kalaidin malykh achieved signicant success math headline generation similar existing headline generation tasks fers aspects major difference math headline consists text math equations require jointly modeling inferring text math equations datasets avg math num avg text tokens headl ques headl ques avg math tokens headl ques avg sent num text vocab size math vocab size ques ques headl headl headl ques table statistics avg math num average math equation number text tokens average textual token number math tokens average math equation token number sent num average sentence number text vocab size text vocabulary size math vocab size math vocabulary size ques detailed question source headl math headline target datasets question pairs correct question pairs table statistics datasets respect overall number collected question pairs number correct question pairs mathoverow model training evaluation datasets consist detailed questions corresponding math headlines question written detailed math corresponding headline written question summary math equations typically questioner mathematics stack exchange overow math equations enclosed symbols use datasets m replace order indicate begin end equation dition toolkit stanford latex enizer tokenize separately text equations questions headlines specically collect pairs detailed tions math headline mathematics stack exchange pairs mathoverow help sis ensure quality remove pairs contain math equations tokenized latex tokenizer results pairs mathematics stack exchange form pairs ow form table table details average tively math equations question headlines contrast contains math tions question headline questions textual tokens math tokens average headline textual tokens math tokens average spondingly average tual tokens math tokens question average textual tokens math tokens headline compared contains tokens textual token math token questions headlines figure higher proportion novel n grams based observations believe constructed datasets signicantly different mutually complementary approach describe proposed deep model mathsum designed task figure proportion novel n grams gold standard math headlines task dataset task denition let dene task summarization let s sn denote sequence input tailed question n number tokens source sw sw represents textual token word indicates math input s corresponding output math headline m tokens y ym y yw ye yw ye textual tokens math tokens respectively goal generate math headline learned input question s y dataset task new nd public benchmark dataset build real world math datasets mathematics stack exchange token fundamental element form math et al github io com harvardnlp figure architecture mathsum question math equation vector representation multi head attention block produce new vector representation s updated vector representation s n fed update layer pass updates original representation mathsum model shown figure mathsum utilizes pointer anism mutli head attention mechanism matical representation augmentation consists main components encoder jointly learns sentation math equations text decoder learns generate headlines learned representation encoder crucial issue build effective resentations tokens input question mentioned task different token types e textual math characteristics intrinsically different math tokens contain semantic features matical meaning structural features e sub script numerator denominator recursive structure representation learning vary according token type study introduce multi head attention mechanism enrich representation math kens token si input question s rst converted continuous vector representation vector resentation input s sn n number tokens input sw vector resentation textual math tokens respectively vectors math tokens equation fed block multi head attention vaswani et al enriches representation considering mantic structural features note tion input separately fed block equation fundamental unit characterizing mantic structural features series math tokens let j mk denote initial vector tion k th math equation m math tokens input multi head attention block transforms enriched representation calculated j j j m fmultihead multi head attention block j beginning index math equation mk j m end index s enriched vector representation input sw fed s date layer single layer bidirectional lstm hidden state hi updated according previous den state current token vector s n s hi s f dynamic function lstm unit hi step hidden state token s decoder aggregate encoder hidden states hn weighted sum text vector ct ithi t eit h t battn wh battn learnable parameters h t hidden state decoder time step t attention distribution input position math representations representations update layerattention distributioncontext vectorencoder hidden statesdetailed questiondecoder hidden statespartial math headline interior m c m math representationsmulti self attentionlayer normfeed forwardlayer normmulti self attentionlayer normfeed forwardlayer norm multi head attention block multi head attention blocktextual representationupdated math representations point generated math headline tain textual tokens math tokens source vocabulary utilize pointer work liu manning directly copy tokens source considering token w maybe copied source generated vocabulary use copy probability pc soft switch choose copied tokens input generated textual tokens vocabulary y t h t ct wi w pc ct h t xt f non linear function xt decoder input timestep t finally training loss time step t dened negative log likehood target word w t losst log w t y t experimental setup comparison methods compare model baseline methods task tractive methods implemented baselines random randomly selects sentence input question lead simply selects leading sentence input question tail selects sentence extracts sentences text according scores computed algorithm similar pagerank addition stractive compare sum sequence sequence model based lstm unit attention mechanism bahdanau cho bengio ptgen pointer network lows copying tokens source liu manning transformer neural network model signed based multi head attention mechanism vaswani et al experiment settings randomly split training validation testing sets order testing samples split training validation testing experiments dimensionality word bedding number hidden states lstm textrank use implementation summanlp com summanlp textrank implementation com opennmt opennmt py use opennmt fair comparison models experimental data setup models trained tested dataset order achieve better imental results models rst trained training set ne tuned tested units encoder decoder multi head tention block contains heads dimensional hidden states feed forward model trained adagrad duchi hazan singer learning rate initial accumulator value batch size set dropout rate lary size question headline dition encoder decoder share token tions test time decode math headline beam search beam size set minimum length tokens tokens implement model pytorch train single titan x gpu experimental results quantity performance use metrics standard metrics rouge lin bleu papineni et al meteor denkowski lavie evaluation rouge metric measures summary quality counting overlapping units e n gram generated summary reference summaries report scores rl rouge l bleu score widely accuracy measure machine translation computes n gram precision candidate sequence reference meteor recall oriented evaluates translation hypotheses aligning reference translations calculating sentence level similarity scores bleu meteor scores calculated nlg package rouge scores based rouge package use edit distance exact match check similarity generated equations compared gold standard equations math headlines metrics widely evaluation equation generation deng et al wu et al edit tance quanties dissimilar strings ing minimum number operations required form string based n samples test set use types edit distance edit math level dissimilar score ned minm d minimum edit distance equations generated headline gold standard headline number equations erated headline gold headline edit sentence level dissimilar score lated exact match checks exact match accuracy gold standard math tokens generated math tokens calculated exactm atch p mi gmi sets math tokens generated headline gold standard headline minm n minm n com maluuba nlg eval com sebastiangehrmann rouge baselines models random tail lead textrank ptgen transformer meteor meteor rl rl mathsum table comparison different models test sets scores rl rouge l meteor edit edit exact match edit edit exact match models random tail lead textrank ptgen transformer mathsum table comparison different models test sets according math evaluation metrics edit edit evaluate dissimilar smaller better exact match number math tokens accurately generated math headlines larger better results comparisons models found table models perform better possible explanation contains lower proportion novel n grams gold standard math headlines illustrated figure extractive models nd lead obtains good performance textrank performs contains sentences question textrank likely pick accurate sentence prisingly abstractive models perform better extractive models datasets compared ordinary ptgen gets better performance uses copying egy directly copy tokens source question transformer outperform ptgen implies utilizing multi head attention mechanism obtain ter learning representation mathsum signicantly performs models evaluation metrics datasets mathsum initially addresses challenges task generates satisfactory lines questions addition evaluate gap ated headlines human written headlines edit edit exact match scores ferent models shown table results extractive models perform worse use metric edit instead edit evaluation extractive models directly select sentences source questions selected tences contain math equations abstractive lines transformer obtains best performance observation reinforces claim mutli head attention mechanism construct better representation math equations model mathsum achieves best performance metrics sum gets best performance exact match ond best performance slightly weaker transformer edit edit possible son lengths math equations source questions usually long ones lines short compared transformer copying mechanism cause mathsum copy long equations source questions result slight decreased performance edit edit metrics quality analysis jointly modeling quality heatmap figure izes attention weights mathsum figure pares source detailed question human written math headline generated math headline figure heatmap attention weights source detailed questions mathsum learns align key textual tokens math tokens corresponding tokens source question sum figure shows textual tokens math tokens generated headline note math tokens textual tokens effectively aligned corresponding tokens source instance textual tokens coordinate triangle math tokens p c successfully aligned case study gain insightful understanding generation quality method present ical examples table rst selected selected examples generated lines human written headlines comparability similarity generally generated headlines ent grammatical informative observe important locate main equations task generation method emphasizes subordinate equation generate unsatisfactory headline second example table conclusions future work dene explore novel task matic headline generation online math questions new deep model mathsum new datasets constructed algorithm training testing available experimental results demonstrate model generate useful math headlines signicantly outperform series state art models future work focus enriched sentations math equations mathematical information retrieval math related research stackexchange com stackexchange com net partial math detailed question human written mathsum partial math detailed question human written mathsum partial math detailed question human written mathsum examples asked nd inverse elements set z know set gaussian integers pretty nding inverse elements z nding inverse elements z suppose function r continuously differentiable dene function g r chain rule rn nd g s t paper herbert clemens curves generic hypersurfaces author shows generic hypersurface v pn sufciently high degree rational rational curves pn immersion rational curves pn table examples generated math headlines given tailed questions acknowledgments work partially supported china scholarship cil projects national natural science foundation china guangdong basic applied basic research foundation fundamental research funds central ties national science foundation detailed question define coordinate triangle sides define interior kind equation written math headline interior triangle generated math headline interior coordinate triangle example detailed question attention weights partial source detailed question tokens references bahdanau cho bengio bahdanau d cho k bengio y neural machine translation jointly learning align translate proceedings iclr et al deng y kanervisto ling j image markup generation rush m proceedings coarse attention national conference machine learning volume jmlr org denkowski lavie denkowski m lavie meteor universal language specic translation uation target language proceedings ninth workshop statistical machine translation duchi hazan singer duchi j hazan e singer y adaptive subgradient methods online learning stochastic optimization journal machine learning research gao et al gao l jiang z yin y yuan k yan z tang z preliminary exploration mula embedding mathematical information retrieval mathematical formulae embedded like natural guage arxiv preprint gavrilov kalaidin malykh gavrilov d kalaidin p malykh v self attentive model european conference headline generation information retrieval springer et al jiang z gao l yuan k gao z tang z liu x mathematics content standing cyberlearning formula evolution map proceedings acm international conference information knowledge management acm krstovski blei krstovski d m le indurkhya nakagawa le d indurkhya b nakagawa m pattern generation strategies improving recognition handwritten mathematical pressions arxiv preprint lin lin c rouge package automatic evaluation summaries text summarization branches liu qin liu x qin j tive metadata model structural descriptive tial representation scholarly output journal ciation information science technology mihalcea tarau mihalcea r tarau p proceedings textrank bringing order text conference empirical methods natural language processing narayan cohen lapata narayan s cohen s b lapata m nt details summary topic aware convolutional neural networks extreme summarization acl nishikawa et al nishikawa h arita k tanaka k hirao t makino t matsuo y blei arxiv preprint equation embeddings k ing generate coherent summary discriminative den semi markov model proceedings coling papineni et al papineni k roukos s ward t zhu w bleu method automatic tion machine translation proceedings nual meeting association computational linguistics roy upadhyay roth roy s upadhyay s roth d equation parsing mapping sentences grounded equations emnlp schubotz et al schubotz m grigorev leich m cohl h s meuschke n gipp b youssef s markl v semantication identiers ics better math information retrieval proceedings international acm sigir conference research development information retrieval acm liu manning liu p j ning c d point summarization pointer generator networks acl tan wan xiao tan j wan x xiao j abstractive document summarization based attentional neural model proceedings annual meeting association computational guistics tan wan xiao tan j wan x xiao j neural sentence summarization headline ijcai generation coarse approach vaswani et al vaswani shazeer n parmar n uszkoreit j jones l gomez n kaiser sukhin attention need advances neural information processing systems wang et al wang l zhang d gao l song j guo l shen h t mathdqn solving arithmetic word problems deep reinforcement learning second aaai conference articial intelligence wu et al wu j yin f zhang y zhang image markup generation x liu c joint european paired adversarial learning ference machine learning knowledge discovery databases springer yasunaga lafferty yasunaga m lafferty j topiceq joint topic mathematical equation model scientic texts aaai et al yuan k gao l wang y yi x tang z mathematical information retrieval system based rankboost proceedings acm cs joint conference digital libraries acm et al yuan k gao l jiang tang z proceedings formula ranking article acm ieee cs joint conference digital libraries acm zanibbi et al zanibbi r davila k kane tompa f w multi stage math formula search appearance based similarity metrics scale ings international acm sigir conference search development information retrieval acm zhang bai zhu zhang w bai z zhu y improved approach based cnn rnns matical expression recognition proceedings international conference multimedia systems signal processing acm zhang et al zhang r guo j fan y lan y xu j cao h cheng x question headline tion news articles proceedings acm national conference information knowledge agement acm
