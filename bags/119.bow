extractive multi document summarization using multilayer networks jorge v tohalino diego r amancio institute of mathematics and computer science university of sao paulo sao carlos sao paulo brazil v o n l c s c v v i x r a abstract huge volumes of textual information has been produced every single day in order to organize and understand such large datasets in recent years summarization techniques have become popular these techniques aims at nding relevant concise and non redundant content from such a big data while network methods have been adopted to model texts in some scenarios a systematic evaluation of multilayer network models in the multi document summarization task has been limited to a few studies here we evaluate the performance of a multilayer based method to select the most relevant sentences in the context of an extractive multi document summarization mds task in the adopted model nodes represent sentences and edges are created based on the number of shared words between sentences dierently from previous studies in document summarization we make a distinction between edges linking sentences from dierent documents inter layer and those connecting sentences from the same document intra layer as a proof of principle our results reveal that such a discrimination between and inter layer in a multilayered representation is able to improve the quality of the generated summaries this piece of information could be used to improve current statistical methods and related textual models keywords complex networks multilayer networks structure and dynamics pagerank text analysis text summarization introduction since textual information available on the internet has increased in recent years methods that sify understand and present the information in a clear and concise way have played a prominent role in data and text mining applications automatic summarization question answering and information retrieval are some of the multi way proposed solutions to address the problem of managing large volumes of unstructured data such as written texts automatic summarization is the process of creating a compressed version summary of one document summarization or more documents multi document summarization mds by extracting the most important content automatic summarization techniques are traditionally divided into two groups extractive and abstractive summarization the task of extractive summarization consists in concatenating several sentences which are selected without modication i e exactly as they appear in the original ment on the other hand the creation of abstractive summaries is a more complex and dicult task because preprint submitted to journal of latex templates november it involves paraphrasing sections of the source document and for this reason it requires natural language generation tools in addition abstractive methods may reuse clauses or phrases from original documents in this work we target our analysis on extractive summarization applied to a set of documents mds the most traditional employed methods to select relevant sentences for extractive summarization are divided into the following major classes methods based on word frequency sentence clustering and machine learning in recent years a new class of methods based on network theory have been proposed to analyze texts applications of network models in text analysis include the study of scientic documents stylometry sense discrimination and several other applications the problem of creating single document extractive summaries has beneted from these previous network models of texts it has been claimed that network features overcome other traditional statistical methods when they are used to identify the most central sentences while most of the studies applying network concepts in summarization have been limited to the single document counterpart here we evaluate the usefulness of networks in the multi document scenario in particular the main objective of this paper is to probe whether a discrimination between and inter layer edges is able to improve the characterization of documents modeled as multilayer complex networks this is an important feature to be considered in the models because a sentence connected to many other sentences from other documents may indicate a high relevance of the approached topics in the adopted method nodes represent sentences and edges are established according to the lexical similarity between two sentences a multilayer network is created by considering each document as a layer as such two types of links arises those connecting sentences from the same documents and the links connecting sentence from distinct sources in addition to the traditional network measurements we also used dynamical measurements to improve the characterization of the obtained networks an evaluation on three corpora english and portuguese revealed that a simple distinction between and inter layer edges yields better performance in comparison to network methods not relying upon multilayered representations a complimentary analysis also revealed that in general traditional measurements such as degree and pagerank yields a good performance for the mds task finally we also found that dierently from the single document case there is no strong correlation among the evaluated network measurements which suggests that they could be combined to improve the identication of relevant sentences this paper is organized as follows in section we present a brief survey of works that used complex networks for extractive summarization the description of the adopted network model and the network metrics we used to rank sentences are described in section in section the results are presented and discussed finally the conclusions and prospects for future work are discussed in section related work several works have addressed the task of extractive summarization based on complex networks tools and methods for example in the work of ribaldo et al the mds task was applied for documents in brazilian portuguese the authors rst extracted all sentences from the cluster of documents and then they modelled them as a single network after the pre processing stage sentences were represented as nodes which were linked by traditional similarity measurements in order to select the best ranked sentences the authors used simple network measurements including degree clustering coecient and average shortest path length a simple heuristic to avoid redundant sentences in the generated summaries was also applied the results showed that the proposed method yielded competitive results which were close to the best statistical systems available for the portuguese language even though this work addressed the mds with a graph based approach no distinction between and inter layer edges was considered antiqueira et al represented sentences as nodes which are linked if they share signicant lemmatized nouns the authors applied static complex network metrics to identify the relevant sentences to compose the extract a summarization system based on voting system was used to combine the results of summaries generated by dierent measurements some systems achieved good results which are comparable to the top single document summarizers for brazilian portuguese leite and rino used multiple features to automatically select the best attributes from single layer complex networks and other linguistic features more specically the authors combined linguistic features and features network based measurements for extract generation leite and rino used machine learning to classify each sentence as present or not present in summary an evaluation in a corpus portuguese texts conrmed that the proposed network methods can be combined with linguistic features so as to improve the characterization of textual documents in the work of erkan and radev sentences are represented as nodes the bag of words model is used to represent the sentences a connection between two nodes is established if the cosine similarity between the vectors of sentences is higher than a predened threshold to rank the sentences the authors used degree centrality and eigenvector based metrics competitive results were reported even if when applied to noisy data in the work of mihalcea similarly to other studies sentences are nodes and edges represent the lexical similarity between sentences the authors used recommendation algorithms for web pages to select the most informative sentences the proposed algorithms used both google s pagerank and hits mihalcea considered three network types undirected forward edges reecting the natural reading ow and backward edges going from the current to the previous word the systems were evaluated by using the english corpus the best performance was achieved with the hits algorithm for english texts conversely for the portuguese scenario the pagerank algorithm yielded the best performance methodology in the current paper we propose a method based on complex network measurements for multi document summarization by modeling a set of documents as a multilayer network we represent each document sentence by a node and edges are established based on the cosine similarity between two sentences the adopted method to extract the most relevant sentences from the texts can be divided into the following steps document pre processing sentence vectorization network creation measurements extraction and summarization i e sentence selection these steps are detailed in sections datasets the datasets used in this work comprises texts originally written in portuguese and english since in a multi document context texts are organized according to the subject approached each dataset is organized in a set of clusters of related texts the details of the datasets are provided below cstnews for portuguese mds this corpus includes documents extracted from on line brazilian news agencies folha de sao paulo estadao o globo gazeta povo and jornal do brazil this corpus comprises news items which are divided into clusters each cluster contains or documents sharing the same topic this corpus includes two reference manual multi document summaries for each cluster each summary has a compression rate for english mds this corpus comprises a set of texts divided into clusters from the following on line news journals wall street journal ap newswire san jose mercury news financial times la times and fbis each cluster include two word reference summaries for english mds this corpus contains clusters of documents each four man reference summaries with characters length were produced for this corpus the documents were extracted from the following sources associated press newswire new york times newswire and xinhua news agency document pre processing in this step the following pre processing steps are applied text segmentation removal of unnecessary words and lemmatization in text segmentation sentences boundaries are recognized we dened a sentence as any text segment separated by a period exclamation or question mark punctuation marks and stopwords such as articles and prepositions were also removed finally we lemmatized the remaing words so as to map the remaining words to their canonical forms as a consequence plural nouns and conjugated verbs are transformed to their singular and innitive forms to illustrate this process we provide in table a small piece of text undergoing the aforementioned pre processing steps table example of pre processing steps applied to a piece of text extracted from wikipedia we rst show the original document divided into seven sentences g the corresponding preprocessed sentences are shown in lines original sentences a arequipa is the capital and largest city of the arequipa region from peru it is peru s second most populous city with habitants arequipa is the second most industrialized and commercialized city in peru its industrial activity includes manufactured goods and camelid wool products for export e the city has close trade ties with chile bolivia and brazil the city was founded on august by garc manuel de carbajal g the historic center of arequipa spans an area of hectares and is a unesco world heritage site pre proccesed sentences arequipa capital large city arequipa region peru peru second populous city habitant arequipa second industry commerce city peru industry activity include manufacture good camelid wool product export city trade tie chile bolivia brasil city be found august garci manuel carbajal history center arequipa span area unesco world heritage site sentence vectorization the next step in mapping a text into a network is the sentence vectorization the tf idf term inverse document frequency weighting is a widely used method for document representation we used this method because it was employed with satisfactory results in several other nlp tasks the term frequency tf of a term t in a document d is calculated as t where t d is the number of times the term t appears in the document d and is the total number of terms in d the inverse document frequency idf of term t in the collection of documents d is calculated as d log df where d is the total number of documents and df is the number of documents in which the term t appears finally the tf idf weight is computed as tf d d d in order to get the representative vector of each sentence we calculate the tf idf value for each of its content words network creation the multilayered representation of documents is created using the following steps tf idf based network creation in this model we rst calculate the tf idf vector representations for each document sentences next each node is represented by a sentence and edges between two sentences i and j are established based on the cosine similarity wi j between the corresponding tf idf vectors figure shows an example of the tf idf network generated from the example in table figure example of tf idf based network each node number represents the sentences from the piece of text shown in table edge weights are created according to the cosine similarity between sentences edge type identication we dened two edge types i edges connecting sentences from the same document intra layer edges and edges connecting sentences from dierent documents inter layer edges this dierentiation is essential to assign relevance to the sentences according to the types of links established type based edge weighting in multi document summarization it is important to consider document relationships here we emphasize the importance of multi document tionships by reinforcing inter layer edges such a reinforcement is done using the a simple linear function i j i j where is a factor that reinforces inter layer connections if and i j is the original layer edge weight connecting nodes i and j as we shall show reinforcing intra layer links may also be important to improve the characterization of the set of documents such an eect is simulated by considering in the experiments edge removal for non weighted measurements this step is required because some network ments are not dened for weighted networks here we removed a fraction r of the weakest links the remaining edges are considered as unweighted to illustrate the creation of multilayer networks figure shows an example of a multilayer network generated from a cluster of three documents figure network model adopted in this work each layer represents a document continuous lines are edges linking sentences from the same document intra layer while dashed lines link sentences from dierent documents inter layer network measurements in the summarization context the goal of a centrality network measurement is to rank the nodes according to its relevance the importance assigned by network measurements allows us to determine which are the best ranked sentences that could compose the nal summary therefore in this stage we use a set of network measurements to rank each node network every measurement is used individually thus each metric generates one summary in this work we used not only traditional network measurements such as degree strength shortest paths and pagerank but also additional measurements to take into account both the topological structure of the networks and their dynamical behavior the latter can be captured by considering dynamical processes occurring on the top of the networks a well known dynamics used in the context of text analysis in the traditional random walk here we also use the self avoiding random walk an exploratory dynamics used to dene measurements such as accessibility and symmetry below we detail each of the measures used in this work degree the degree of a node i is the number of edges linked to that node a high degree value suggests that a sentence is related to several others in the document or collection strength for weighted networks the strength of a node i is the sum of the weights of all its incident edges in unweighted networks the strength corresponds to the node degree shortest paths l a shortest path between two nodes i and j is one of the paths that connects these nodes with a minimum length the length of such a path is henceforth denoted as dij the average shortest path length is dened as li where n is the total number of words in the network a sentence is considered relevant for a document or collection if its average distance to any other sentence takes low values in textual networks the shortest path length has been useful to identify relevant textual concepts pagerank this measurement considers that a node i is relevant if it is connected to other relevant nodes it can be computed in a recursive way as i aij j j where and are damping factors taking values between and in text analysis this measurement has been used to identify the most probable sense of ambiguous constructions a similar ment based on the number of shortest paths has also been used to gauge similarity in texts modeled as complex networks accessibility the accessibility quanties how many nodes are accessible from an initial node when a self avoiding random walk of length h is performed this measurement has been employed to identify borders in geographical networks and to characterize the interplay between structure and dynamics in a wide range of complex networks dierently from other traditional graph measurements the accessibility takes into consideration dierent levels of hierarchy which can be set by specifying the length h of the random walks in textual analysis this measurement has proven useful to identify key concepts in stylometric applications to calculate the accessibility let j represent the probability of reaching a node j from i through a self avoiding random walk of length h the accessibility is dened as the exponential of the true diversity of j i exp j log j j it can be shown that the accessibility can be interpreted as the eective number of accessed nodes in the considered dynamics to illustrate the accessibility concept we show in figure a subgraph created around node a two congurations of links are considered i continuous red links and ii scenario i two additional blue dotted links note that in the rst scenario all nodes in the second hierarchical level are reached with the same probability p this leads to the maximum accessibility value a in the second scenario the access to the nodes becomes uneven because two additional paths are created see dashed blue lines such an irregular distribution leads to a decreased value of accessibility a generalized accessibility a the accessibility measurement depends on the parameter h for its culation the new version of accessibility called generalized accessibility is an improvement of cessibility because this new version can be computed without any prior choice of length h actually this metric is computed by considering all lenghts in the random walk dynamics the generalized accessibility depends upon the stochastic matrix p whose element j represents the probability of a random walker to go from node i to j in the next step of the random walk the transition probability considering all lengths can be computed as e j pj the transition probabilities obtained in can then be used to compute the generalized accessibility figure example of computation of accessibility considering two conguration of edges i red continuous edges only and ii red continuous and blue dotted edges in i the access to the nodes at the second hierarchical level is uniform therefore the accessibility reaches its maximum value in the access to the nodes becomes uneven as some nodes tend to be accessed more frequently than others as a consequence the accessibility of a drops to a a using the true diversity of i e exp j log j j where is an element of this metric has been employed with success as a centrality surement applied in other text classication tasks symmetry s the network symmetry is a normalized version of accessibility where the number of accessible nodes is used as normalization factor the symmetry uses the concept of concentric level h of a node i see figure which is dened as the set of nodes h hops away from i because the main objective of this metric is to quantify how diverse is the exploration of a neighborhood the symmetry measurement considers that at each step the random walker access the next concentric level thus to compute probabilities transitions all links connecting nodes in the same concentric ap hierarchical hierarchical level level are disregarded the symmetry is calculated as i i exp j log j where i is the set of accessible nodes that are at a distance h from the node i i e the number of nodes in the h th level because this measurement has never been used for summarization in the current work we evaluated the performance of selecting the sentences with the highest and lowest values of symmetry absorption time the absorption time is dened as the time it takes for a particle in an internal node to reach an output absorbent node through a random walk this metric quanties how fast a randomly walking particle is absorbed by output vertices assuming that the particle starts the random walk at the input node the stochastic transition matrix p is used to compute this metric the absorption time is dened using the matrix i where i is the identity matrix and is a submatrix of p which represents the transitions between transient nodes i e non absorbent nodes it can be shown that the time spent in transient nodes can be computed as for each pair i j of nodes we dene i as a starting node and j as an absorbent node to compute thus here the absorption time of a node i is computed as ti j j i n tk by using this measurement we expect that sentences taking low values of absorption time are more semantically related to the other sentences in the text thus to generate the summary we select the sentences with the lowest values of i summary generation in this stage the nal summary is created by selecting the best ranked sentences according to some measurement and strategy selection the selection can be made by choosing either the highest or the lowest values of the considered metrics the strategy used for each measurement is summarized in table for summary generation a compression rate must be specied the size of the generated summaries in the current work is the same as the size of the available reference summaries for the corpora used table adopted network measurements for mds the weighted version of the networks was considered only with the most traditional measurements selection strategy measurement degree strength pagerank accessibility symmetry gen accessibility shortest paths symmetry absorption time abbr dg stg pr pr w access sym gaccess sp sp w sym highest values lowest values an additional important issue in summarization is the so called redundancy treatment in the context of automatic summarization redundancy arises when identical or similar sentences composes the nal summary in network terms two sentences in the nal summary are considered redundant if they are connected by strong links in this paper we adopted two anti redundancy detection methods in both methods a similarity threshold is established to compare sentences at each step if the current best ranked sentence is similar to any of the previously selected sentences in the summary then it is considered redundant therefore the redundant piece of text is not used to compose the nal summary in this case the summarization process resumes and the next candidate sentence is evaluated in the rst anti redundancy method the threshold value is computed as where j is the cosine similarity between two sentences i and j the second anti redundancy method considers the following similarity measurement j j j n k k k n where n is the number of n grams to be considered k is the set of k grams of sentence i and k is the weight associated with the k gram similarity of two sets we chose as threshold for the value the other parameters in equation were chosen in accordance with ref results in this section we evaluate the performance of the multilayered approach considering dierent weighting schemes for inter layer edges we also assess the relevance of each network metric for the adopted network representation finally we analyze the correlation between the network metrics in order to identify possible correspondences equivalences between the adopted multilayer network measurements performance analysis the systems were evaluated using the following corpora cstnews a corpus of portuguese journalistic texts and duc and which are corpora comprising english journalistic texts the evaluation of the informativeness of our method was done by using the automatic evaluation method which compares automatically generated summaries and reference texts this metric was used here because it has been claimed that there is a strong correlation between the rouge index and manual human judgment an important parameter in the analyzed multilayer networks is the setup of relevance weights for layer edges see in equation the parameter accounts for assigning a higher or lower relevance for inter document relationships the values of varied in the range for each value of we removed a xed amount r of the weakest links r concerning the anti redundancy methods both strategies and considered in this article displayed similar performance result not shown for this reason hereafter we only report the best results figure shows the overall performance of the multilayer approach as a function of for the cstnews corpus for each subplot we show the curves for dierent percentages of removed edges remarkably apart from the simmetry measurement we observed an improvement in performance when we note that the best results can be obtained in two distinct scenarios i where a higher relevance is given for intra document relationships and where a higher relevance is assigned for the inter document relationships the second scenario seems to be more important for improving the performance of the system since holds just for the degree we also note from the gures that the best value of r depends on the measurement being analyzed figure shows the performance of the multilayer approach for the corpus as observed in the cstnews figure a value of is able to improve the performance of the systems except for the symmetry measurement dierently from the previous analysis here the intra document relationships seems to play an important role for a larger number of network measurements optimized results were figure performance analysis recall of the adopted multilayer approach in the cstnews corpus for portuguese mds each subgure shows the performance of each proposed network measurement as a function of the inter layer edge weight parameter obtained for for the degree shortest path length pagerank and accessibility both a and a a major improvement in performance for was observed for the absorption time measurement similarly to the behavior observed for the portuguese corpus here the best value of r depends on the adopted network measurement a similar result was obtained with the corpus see figure of the supplementary information si with the best results being obtained for except for the symmetry tables and summarize the results obtained in both cstnews and for the portuguese case the best results were obtained with degree and shortest paths both considering the strategy to address the anti redundancy problem actually apart from the generalized accessibility the best results were always obtained with the technique for the english corpus the pagerank strategy outperformed the other network measurements a good performance was also observed when the generalized accessibility was used here the technique for anti redundancy treatment achieved the best results considering the measurements based on self avoiding random walks the best performance occurred for figure performance analysis of corpus for english mds each sub gure shows the performance of each proposed network measurement considering the inter layer edge weight parameter and thresholds of edge removal axis represents the inter layer edge weight parameter and y axis is the average recall the generalized accessibility this measurement outperformed its hierarchical version probably because the adopted generalization grasps more information about the network organization note that the denition of the generalized accessibility dierently from the hierarchical version considers all hierarchical levels to estimate the eective number of accessed nodes see equation consistently the symmetry measurement displayed low performance in all adopted datasets this might be related to the fact that such measurement mainly quanties the diversity of links weights and not the proeminence of nodes while such a diversity might be of interest to quantify particular textual phenomena see e for an application on authorship recognition the obtained results suggests that the most important information to quantify relevance is not captured by the symmetry the results obtained for see table also conrms that low values of optimizes the performance for particular several measurements the results observed in the above experiments suggests that the multilayer representation is relevant to identify the most prominent nodes sentences in documents the importance of the and table best results obtained for portuguese mds the network measurements are ranked according to the obtained recall for each metric we show the respective parameters for inter layer edge weight and the threshold r for edge remotion the anti redundancy detection ard method that obtained the best result is also shown table best results for english mds corpus the network measurements are ranked according to the obtained recall for each metric we show the respective parameters for inter layer edge weight and the threshold r for edge remotion the anti redundancy detection ard method that obtained the best result is also shown meas dg sp w gaccess pr stg w sp sym access meas w gaccess dg stg sp access sp w sym r r ard ard layer edges seems to be dependent on the dataset language and metric used to rank sentences this was clear when we observed that both scenarios and are possible even when considering the same language while such a multilayer representation has been implicitly used in some textual contexts no discrimination between and inter layer edges has been considered for summary generation given the eectiveness of the adopted representation to optimize the performance obtained by network measurements we believe that it could be considered in other related applications where and relationships are relevant this is the case e of applications related to text mining and identication of key concepts in scientic areas this study focused on the evaluation of multilayer based network approaches for mds even though we aimed at studying the relevance of discriminating and inter layer edges in multilayer networks it is still interesting to compare the eciency of statistical approaches such as the one evaluated in the current study and other approaches dependent upon more informed linguistic data for comparison purposes we show in table a set of other works that achieved the best results for the corpus we used for portuguese mds the works are gistsumm bushypath and path systems and cstsumm which follows a strategy based on cross document structure theory in the case of english mds we considered the following works duc best which is the system with highest rouge scores for duc conferences bstm which uses a bayesian sentence based topic model for summarization fgb which proposes a new language model to simultaneously cluster and summarize the documents and lexpr which constructs a sentence connectivity graph based on cosine similarity and selects important sentences based on the eigenvector centrality considering the portuguese language the multilayer approach outperformed several other statistical methods the best result was obtained however with the gistsumm technique which considers more linguistic and semantical information than the multilayer approach for both english corpora linguistic dependent approaches outperformed the method based on multilayers however in the dataset only a minor dierence between the multilayer and other methods was observed table list of works for portuguese and english mds with the respective average recall scores the best results of the multilayer approach evaluated in this work are highlighted cstnews system gistsumm multilayer bushypath path cstsumm system duc best bstm multilayer fgb lexpr system bstm fgb duc best lexpr multilayer correlation analysis in figure we show the spearman rank correlation coecient observed for both cstnews left and right corpora for the cstnews case in general the correlation are not strong which means that the metrics are not equivalent in the summarization task the highest correlation however occurs for the pair weighted pagerank and absorption time such a similarity might occur because both measurements are based on the behavior of a random walk dynamics for the corpora the correlations are even lower conrming thus an absence of correspondence among the adopted network metrics low values of spearman rank correlation coecient were also observed in the corpus see figure the complimentary role played by the metrics in the adopted multilayer networks suggests that such metrics could be combined e in a voting system to improve the performance of extractive summarizers most importantly the dierentiation of edge types in characterizing collections of documents should be taken into account whenever semantical links are at the core of the target task or investigation figure spearman rank correlation coecients for the considered network measurements considering both cstnews left and note that in general there is a weak correlation between the adopted measurements the strongest correlation occurs for the pair weighted pagerank and absorption time for the portuguese corpus conclusion in this paper we evaluated the eciency of a multilayered approach for the extractive summarization problem several interesting ndings were observed when applying such a simple model to a set of portuguese and english texts we found that the performance observed is increased when and inter layer edges are considered with distinct relevance for the portuguese case for most of the measurements the best performance was obtained when inter document relationships are strenghtened conversely for the english case both and inter layer edges yielded the best results concerning the metrics excellent performance was obtained for the degree portuguese weighted pagerank english and the generalized acessibility for both portuguese and english dierently from previous results obtained for network based single document summarization we found no strong correlation among the adopted measurements given the complimentary role played by the metrics this study could be extended in order to consider acombination of metrics to improve the performance of the systems the adopted model could also be extended in future works by using the concept of word embeddings to enhance the representation of sentences finally future works could combine traditional document summarization techniques and layered network representations such a combination can be created e by combining network concepts and linguistic features such as sentence length number of proper nouns and sentence location via machine learning or hybrid classiers acknowledgments j v t acknowledges nancial support from cnpq brazil d r a thanks sao paulo research tion fapesp grant no for the nancial support references c d manning h schutze foundations of statistical natural language processing mit press cambridge ma usa z gao y yang p fang y zou c xia m du multiscale complex network for analyzing experimental multivariate time series epl europhysics letters r ferreira l de souza cabral r d lins g p silva f freitas g d c cavalcanti r lima s j simske l favaro assessing sentence scoring techniques for extractive text summarization expert syst appl a nenkova s maskey y liu automatic summarization in proceedings of the annual meeting of the association for computational linguistics tutorial abstracts of acl hlt association for computational linguistics d yu w wang s zhang w zhang r liu hybrid self optimized clustering model based on citation links and textual features to detect research topics plos one f n silva d r amancio m bardosova l f costa o n oliveira jr using network science and text analytics to produce surveys in a scientic topic journal of informetrics m p viana d r amancio l f costa on time varying collaboration networks journal of informetrics pp c chen the centrality of pivotal points in the evolution of scientic networks in proceedings of the international conference on intelligent user interfaces iui acm new york ny usa pp d r amancio o n oliveira jr l f costa structure semantics interplay in complex networks and its eects on the predictability of similarity in texts physica a statistical mechanics and its applications a mehri a h darooneh a shariati the complex networks approach for authorship attribution of books physica a statistical mechanics and its applications d r amancio authorship recognition via uctuation analysis of network topology and word intermittency journal of statistical mechanics theory and experiment d r amancio a complex network approach to stylometry plos one e agirre a soroa personalizing pagerank for word sense disambiguation in proceedings of the conference of the european chapter of the association for computational linguistics eacl association for computational linguistics t c silva d r amancio word sense disambiguation via high order of learning in complex networks epl europhysics stroudsburg pa usa pp letters s yu h liu c xu statistical properties of chinese phonemic networks physica a statistical mechanics and its h liu the complexity of chinese syntactic dependency networks physica a statistical mechanics and its applications l antiqueira o n oliveira jr l f costa m g v nunes a complex network approach to text summarization inf applications sci r ribaldo a t akabane l h m rino t a s pardo graph based methods for multi document summarization exploring relationship maps complex networks and discourse information in computational processing of the portuguese language vol springer berlin heidelberg pp d r amancio m g nunes o n oliveira jr l f costa extractive summarization using complex networks and syntactic dependency physica a statistical mechanics and its applications d s leite l h rino combining multiple features for automatic text summarization through machine learning in proceedings of the international conference on computational processing of the portuguese language g erkan d r radev lexrank graph based lexical centrality as salience in text summarization j artif int res verlag pp r mihalcea language independent extractive summarization in proceedings of the acl on interactive poster and demonstration sessions association for computational linguistics pp l page s brin r motwani t winograd the pagerank citation ranking bringing order to the web in proceedings of the international world wide web conference pp j m kleinberg authoritative sources in a hyperlinked environment j acm p over w liggett introduction to duc an intrinsic evaluation of generic news text summarization systems o paul y james an introduction to in proceedings of the document understanding conference duc s robertson understanding inverse document frequency on theoretical arguments for idf journal of documentation d padmanabhan p desikan j srivastava k riaz wicer a weighted inter cluster edge ranking for clustered graphs in proceedings of the ieee wic acm international conference on web intelligence wi ieee computer f wei w li q lu y he a document sensitive graph model for multi document summarization knowledge and society washington dc usa pp information systems d ramage a n raerty c d manning random walks for text semantic similarity in proceedings of the workshop on graph based methods for natural language processing association for computational linguistics stroudsburg pa usa pp n masuda m a porter r lambiotte random walks and diusion on networks physics reports d r amancio e g altmann o n oliveira jr l f costa comparing intermittency and network measurements of words and their dependence on authorship new journal of physics b travencolo l f costa accessibility in complex networks physics letters a d r amancio f n silva l f costa concentric network symmetry grasps authors styles in word adjacency networks epl europhysics letters d r amancio o n oliveira jr l f costa on the concepts of complex networks to quantify the diculty in nding the way out of labyrinths physica a statistical mechanics and its applications r gaizauskas h saggion multi document summarization by cluster prole relevance and redundancy removal in proceedings of the hlt naacl document understanding workshop pp c lin rouge a package for automatic evaluation of summaries in proc acl workshop on text summarization branches out p d r radev a common theory of information fusion from multiple text sources step one cross document structure in proceedings of the sigdial workshop on discourse and dialogue volume sigdial association for computational linguistics stroudsburg pa usa pp d wang s zhu t li y gong multi document summarization using sentence based topic models in proceedings of the acl ijcnlp conference short papers association for computational linguistics pp d wang s zhu t li y chi y gong integrating clustering and multi document summarization to improve document understanding in proceedings of the acm conference on information and knowledge management acm pp g erkan d r radev lexpagerank prestige in multi document text summarization in d lin d wu eds ceedings of emnlp association for computational linguistics barcelona spain pp t mikolov i sutskever k chen g corrado j dean distributed representations of words and phrases and their compositionality arxiv e prints
