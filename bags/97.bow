query adaptive video summarization quality aware relevance estimation arun balajee vasudevan michael gygli anna volokitin luc van gool eth zurich ku leuven gifs com arunv gygli anna volokitin ee ethz ch p e s v c s c v v x r abstract problem automatic video summarization cently received lot attention problem creating video summary highlights elements relevant search query studied address problem posing relevant summarization video frame subset selection problem lets optimise summaries simultaneously diverse representative entire video relevant text query quantify relevance measuring distance frames queries common textual visual semantic ding space induced neural network addition extend model capture query independent properties frame quality compare method previous state art textual visual embeddings thumbnail selection model outperforms relevance prediction introduce new dataset annotated diversity query specific relevance labels dataset train test complete model video summarization performs standard baselines maximal marginal relevance introduction video recording devices omnipresent videos taken smartphones surveillance cameras wearable cameras recorded capture filter later mentality raw videos end getting curated remain long shaky redundant boring watch raises new challenges searching videos problem making videos content accessible spurred research automatic tagging video rization automatic tagging goal predict meta data form tags makes videos searchable text queries video summarization hand aims making videos accessible reducing interesting representative frames shots paper combines goals summarising videos makes searchable text specifically propose novel method generates video summaries adapted text query fig authors contributed equally permission digital hard copies work personal classroom use granted fee provided copies distributed profit commercial advantage copies bear notice citation page copyrights components work owned honored abstracting credit permitted copy republish post servers redistribute lists requires prior specific permission fee request permissions org october mountain view usa copyright held owner publication rights licensed acm isbn doi figure query adaptive video summarization model picks frames relevant query giving sense entire video want summarise video ironman competition participants swim bike run query adapted summaries representative showing sports placing focus frames matching query approach improves previous works area textual visual embeddings proposes extension existing video summarization method submodular mixtures creating summaries query adaptive method creating query relevant summaries consists parts develop relevance model allows rank frames video according relevance given text query relevance computed sum cosine similarity embeddings frames text queries learned semantic embedding space query independent term embedding captures semantic similarity video frames text queries query independent term predicts relevance based quality composition interestingness content train model large dataset image search data newly introduced relevance diversity dataset section second summarization system framework optimising selected set frames relevance representativeness diversity submodular mixture objectives figure shows overview complete pipeline publish codes demos following contributions improvements learning textual visual ding thumbnail selection compared work liu et al include better alignment learning jective task test time modeling text queries lstms fetching significant performance gains com arunbalajeev query video summary way model semantic similarity quality aspects frames jointly leading better performance compared similarity text queries adapt submodular mixtures model video marization gygli et al create query adaptive diverse summaries frame based relevance model new video thumbnail dataset providing query relevance diversity labels judgements subjective collect multiple annotations video analyse consistency obtained labelling related work goal video summarization select subset frames gives user idea video s content glance find informative frames task dominant approaches exist modelling generic frame interestingness additional information video title text query find relevant frames work combine model contributions query adaptive relevance prediction models related automatic ging textual visual embeddings image description following discuss approaches video summarization generic interestingness diction models previous works obtaining embeddings video summarization video summarization methods broadly classified abstractive extractive approaches stractive compositional approaches transform initial video compact appealing representation e lapses montages video synopses goal extractive methods instead select informative subset keyframes video segments tial video method extractive extractive methods need optimise properties summary quality selected frames diversity additional objectives temporal uniformity vance optimised simplest approach obtain representative diverse summary cluster videos events select best frame event sophisticated proaches jointly optimise importance diversity determinantal point process dpps submodular tures related paper work sharghi et al present approach query adaptive video rization dpps method limits small fixed set concepts car flower authors leave handling unconstrained queries approach future work work formulate video summarization maximisation problem set submodular functions following frame quality interestingness methods predict frame interestingness based supervised learning prediction problem formulated classification regression common ranking problem simplify task approaches assume domain video given train model domain alternative approach based unsupervised learning posed xiong et al detects snap points web image prior model considers frames suitable keyframes composition frames matches composition web images regardless frame content approach tially inspired work predicts relevance absence query relies supervised learning unconstrained textual visual models methods exist retrieve images given unconstrained text vice typically project modalities joint embedding space semantic similarity compared measure like cosine similarity glove popular choices obtain embeddings text deep image features mapped space learned projection modalities space easily compared multi modal semantic embedding space zero shot learning approaches predict test labels unseen training habibian et al spirit propose zero shot recognition events videos learning video representation aligns text dio video features similarly liu et al use textual visual embeddings video thumbnail selection relevance model based liu et al provide important provements keeping word representation fixed jointly optimise word image projection instead embedding word separately train lstm model combines complete query single embedding vector learns multi word combinations visit lake star wars movie contrast liu et al directly optimise target objective experiments changes lead significantly better performance predicting relevant nails method relevance prediction goal work introduce method automatically select set video thumbnails relevant respect query diverse represent video later optimise relevance diversity jointly need way evaluate relevance frames relevance model learns projection video frames v text queries t embedding space denote tion t v t v respectively trained relevance frame v given query t estimated similarity measure use cosine similarity v t v lets assess semantic relevance frame w t query possible prediction suitability thumbnails based frame quality composition propose extend notion relevance model quality aspects thumbnails explicitly computing final relevance sum embedding similarity query independent frame quality term e t v v qv qv query independent score determining suitability v thumbnail based quality frame figure overview approach summary created example video query cooking channel obtain query adaptive summary selecting set keyframes video quality aware relevance model submodular mixtures explained sec following investigate formulate task obtaining embeddings t v qv training objective intuitively model able answer best thumbnail query problem picking best thumbnail video naturally formulated ranking problem desire embedding vectors query frame good match similar ones query non relevant frame model learn satisfy rank constraint given query t relevance score higher relevance score relevant frame v irrelevant frame v t v r t v alternatively train model requiring similarity score quality score relevant frame higher irrelevant frame explicitly imposing constraint sum case imposing following constraints v v qv qv experimentally find training explicit constraints leads slightly improved performance tab order impose constraints train model define loss v v v lp max qv qv lp cost function margin parameter low use huber loss lp e robust version loss describe parametrize t v qv learned text frame representation use convolutional neural network cnn predicting v qv t obtained recurrent neural network jointly learn parameters networks use siamese v weights ing network trained triplets t v v shared provide subnets predicting v model architecture supplementary material describe textual representation t image representations v qv detail textual representation feature representation t tual query t project word query dimensional semantic space model trained googlenews dataset fine tune model unique queries bing clickture dataset sentences encode individual word representations single fixed length embedding lstm use prediction model outputs fixed length output final time step allows emphasize visually informative words handle phrases image representation represent image leverage feature representations pre trained network imagenet replace softmax nodes network linear layer m dimensions dimensions embedding v dimension represents quality score qv summarization model use framework submodular optimization create maries account multiple objectives work summarization posed problem selecting subset case frames y maximizes linear combination submodular objective functions y y fn xv specifically y arg max yyv t w y liu et al inverse poses problem learning assign higher similarity corresponding frame query frame random query model learns answer question good query image yv denote set possible solutions y xv features video v work assume cardinality fixed value use k experiments frame level featuressemantic embedding cooking channelquality scorequery spacediversity scoresimilarityqualitydiversityrepresentativeness scorereprsubmodularmaximizationsummary framesobjectives non negative weights w objective eq lar meaning optimized near optimally cient way greedy algorithm lazy evaluations objective functions choose small set objective functions capturing different aspects summary query similarity v y t query embedding v frame embedding s denotes cosine similarity defined eq quality score v y qv qv represents score based quality v thumbnail model scores image relevance query independent manner based properties contrast composition diversity elements summary min j dxv j according larity measure d use euclidean distance features network d y representativeness objective favors selecting medoid frames video visually frequent frames video represented summary weight learning learn weights w eq ground truth summaries query video pairs required previous methods typically optimized relevance small datasets limited vocabularies able train model collected new dataset relevance diversity annotations introduce section relevance diversity labels known estimate optimal mixing weights submodular functions subgradient descent order directly optimize score test time use locally modular approximation based procedure optimize weights adagrad relevance diversity dataset rad collected dataset query relevance diversity tion let train evaluate query relevant summaries dataset consists videos retrieved given different query amazon mechanical turk amt annotate video frames query relevance labels partition frames clusters according visual similarity kind labels previously mediaeval diverse social images challenge enabled evaluation automatic methods creating relevant diverse summaries select representative sample queries videos dataset following procedure youtube queries different categories seed queries typically short generic concepts obtain longer realistic queries use youtube auto complete suggest phrases approach collect queries examples brock lesnar vs big taylor derivation submodularity objective provided suppl google com trends explore swift woods query video result duration minutes annotate videos set consecutive tasks amt videos sampled frame second task worker asked label frame relevance w t given query options answers good trash trash indicates frame irrelevant low quality e blurred bad contrast annotating relevance worker asked distribute frames clusters according visual similarity obtain clustering worker clustering consists mutually exclusive subsets video frames clusters number clusters clustering chosen worker video annotated different people total subjects participated annotation ensure high quality annotations defined qualification task check results manually ensure workers provide good annotations workers pass test allowed assignments analysis analyse kinds annotations obtained procedure describe merge annotations set ground truth labels video label distributions distribution relevance labels good good good trash minimum maximum mean number clusters video respectively videos rad relevance annotation consistency given inherent tivity task want know annotators agree query relevance frames follow previous work compute spearman rank correlation relevance scores different subjects splitting annotations video groups raters split combination find mean video dataset average correlation videos perfect correlation indicate consistency scores related task event specific image importance annotators consistency confident relevance labels high quality cluster consistency best knowledge annotate multiple clusterings video look consistency multiple annotators mediaeval example multiple relevance labels clustering ways measuring consistency clusterings exist e variation information normalised mutual information rand index wagner wagner excellent overview following propose use normalised mutual information nmi information theoretic measure ratio mutual information clusterings c c sum entropies clusterings h c h c n mi c c c c h c h c settings metrics cost lstm quality vg g spear corr map method random loss liu et al huber loss liu et al lstm huber lstm frame quality qexpli huber lstm qimpli huber lstm qexpli lhuber lhuber lhuber lhuber lhuber table comparison different model configurations trained subset clickture dataset fine tuned video thumbnail dataset rad report fraction times select good good thumbnail spearman correlation model predictions true candidate thumbnail scores mean average precision model performs best chose nmi recently proposed variation mation vi nmi fixed range closely related vi supplementary material dataset cluster consistency nmi clusterings independent iff identical annotators high degree agreement ground truth evaluation test videos create single ground truth annotation video merge relevance annotations clustering query video pair final ground truth relevance prediction require labels positive negative video frame map good labels good labels good trash labels compute mean relevance annotation labels label frame positive mean negative merge clustering annotations calculate nmi pairs clustering choose clustering highest mean nmi e prototypical cluster example relevance clustering annotation provided fig configuration testing comparing proposed relevance model state art sec analyze model performance different objectives cost functions text representation evaluation use query dependent thumbnail selection dataset qts vided dataset contains candidate thumbnails video labeled good vg good g fair f bad b bad vb evaluate available query video pairs transform categorical labels numerical values use mapping evaluation metrics evaluation metrics mean average precision map reported defined liu et al spearman s rank correlation computed hit ratio highest ranked thumbnail training dataset training use datasets bing clickture dataset rad dataset sec clickture large dataset consisting queries retrieved images bing image search annotation form triplets k q c meaning image k clicked c times search results query q dataset suited training relevance model task retrieval relevant keyframes video given text query image video domain additionally fine tune models complete rad dataset consisting query video pairs query video pair sample equi number positive negative frames equal weight video total use m triplets sec clickture k triplets rad training implementation details preprocess images truncate number words query mean maximum query length clickture respectively set margin parameter loss eq tradeoff parameter huber loss lstm consists hidden layer units train parameters lstm projection layer m stochastic gradient descent adaptive weight updates adagrad add penalty weights train epochs minibatches triplets tested components discuss important components model objective compare proposed training objective liu et al model trained rank positive query higher negative query given fixed frame contrast method trained rank positive frame higher negative frame given fixed query cost function investigate importance modeling frame quality particular compare different cost functions enforce ranking constraints quality term embedding similarity eq qexpli sum quality similarity term output score enforce rank constraint eq qimpl nt model quality hit method spear map method vg vg g spear map queries liu et al titles qar qexpli qar table comparison thumbnail selection performance state art qts evaluation dataset note uses queries method publicly available text textual input random frame quality qexpl titles liu et al lstm qar qexpl qar queries liu et al lstm qar qexpl qar table performance relevance models rad dataset comparison previous methods figure precision recall curve qts evaluation dataset different methods text representation mentioned sec represent words query word vectors combine ual word representations single vector investigate approaches averaging word embedding vectors ing lstm model learns combine individual word embeddings results results detailed experiments tab insights important points text representation modeling queries lstm averaging individual word representations improves mance significantly surprising model learn ignore words visually informative e objective cost function analysis shows training objective leads better performance compared objective liu et al explained properties videos typically contain frames low quality visually informative formulating thumbnail task way model learn quality aspects beneficial appropriate triplets training boosts performance substantially correlation figure recall precision curve rad testet ent methods method blue performs high terms map loss liu et al lstm huber lstm including quality term model performance improves explicit loss performs slightly better huber lstm qexpli tab somewhat surprisingly modeling quality forms liu et al terms map despite textual information quality adds significant boost performance video domain interestingly different image domain difference quality statistics images returned search engine good quality explicitly accounting improve performance supplementary material conclude better alignment objective keyframe retrieval task addition lstm modeling quality thumbnails improves performance provide substantial improvement compared liu et al s model method achieves absolute improvement map improvement correlation gains significant consider possible ranges metrics e spearman correlation recall qts evaluation datasetliu et alqar qexpliqar recall curve rad datasetliu et qexpliqar liu et al e n r g n r s u o r e g n d n o c n n o l s v g u t k c u r t w e v l y b b figure qualitative results ranked keyframes rad liu et al model left video titles shown left ground truth relevance labels shown blue p positive n negative human agreement rad dataset c sec providing upper bound similarly map small effective ranges given high scores random model experiments previous section determined objective embedding queries lstm explicitly modelling quality performs best model qar quality aware relevance following compare state o models qts rad datasets evaluate rization model rad experiments split rad videos training validation testing evaluation metrics relevance use metrics sec evaluate video summaries rad additionally use scores score harmonic mean precision relevance prediction cluster recall high method selects relevant frames diverse clusters evaluating relevance model evaluate model qar compare liu et al query dependent thumbnail selection dataset qts compare s o qts evaluation dataset tab report performance liu et al paper note results directly comparable use query video pairs predicting relevance titles shared publicly use titles instead important difference relevance annotated respect queries differ video titles compare implementation titles detail tab encouragingly model performs titles outperforms metrics improves map correlation margin c table method pr cr f similarity diversity quality repr mmr hecate upper bound table performance summarization methods rad dataset repr means representativeness pict objective mmr learn corresponding weights percentage ses normalized learnt weights upper bound refers best possible performance obtained ground truth annotations rad figure shows precision recall curve experiment seen qar outperforms recall ratios better understand effects titles queries quantify value rad dataset dataset rad evaluate model rad test set tab qar significantly outperforms previous s o augmenting liu et al lstm qar improves map titles queries implementation liu et al modeling quality leads significant gains terms map titles queries cases query relevance lower including ity believe reason query given textual visual similarity reliable signal single best keyframe including quality improves overall ranking map solely based appearance inhibit fine grained ranking results low title frame quality stronger predictor thumbnail selection improves performance metrics present qualitative results different methods relevance prediction fig evaluating summarization model mentioned sec use objectives tion model referring tab use qar model similarity quality scores diversity representativeness scores obtained described sec compare performance model individual objective baseline based maximal marginal relevance mmr hecate mmr greedily builds set maximises weighted sum terms similarity selected elements query dissimilarity previously selected elements estimate larity query use model qar qexpli dissimilarity diversity defined sec finally query hairstyles men e t c e h r m m y t r l m s s r u o figure video summaries created hecate mmr similarity model summarization proach green number images depicts frame number plot ground truth relevance scores marking selected frames shown methods cluster annotations video rows cluster annotation color represents unique cluster additional examples provided supplementary compare hecate recently introduced hecate estimates frame quality stillness frame selects tative diverse thumbnails clustering video k means selecting highest quality frame k largest clusters results quantitative results shown tab fig shows qualitative results seen combining objectives model works best outperforms single objectives mmr baseline mmr uses performing similarity estimation similarity highest precision tends pick frames visually similar c fig resulting low cluster recall diversification objectives diversity representativeness high cluster recall frames relevant somewhat surprisingly hecate relatively strong baseline particular performs terms relevance despite simple quality score highlights importance quality thumbnail selection task indicates architecture suboptimal predicting quality cnns classification use small input resolutions making difficult predict quality aspects blur finding better architectures task actively researched e improve method analysing learned weights c tab find similarity prediction important objective matches expectations quality gets lower non zero weight showing provides information complementary query similarity helps predicting relevance frame reader aware differences variance objectives affect weights learned taken grain salt considered tendencies conclusion introduced new method query adaptive video rization core lies textual visual embedding lets select frames relevant query contrast earlier works model allows handle unconstrained queries sentences proposed empirically evaluated different improvements learning relevance model empirical evaluation showed better training objective sophisticated text model explicitly modelling quality leads significant performance gains particular showed quality plays important role absence high quality relevance information queries e title finally introduced new dataset thumbnail tion comes query relevance labels grouping frames according visual semantic similarity data tested summarization framework showed compares favourably strong baselines mmr hope new dataset spur research query adaptive video summarization scorespositivenegativemmr acknowledgements work supported toyota project zurich acknowledge support chist era project muster mg supported european research council project varcity references arev hs park yaser sheikh automatic editing footage multiple social cameras acm transactions graphics tog lamberto ballan marco bertini giuseppe serra alberto del bimbo data driven approach tag refinement localization web videos computer vision image understanding andrei barbu alexander bridge zachary burchill dan coroian sven dickinson sanja fidler aaron michaux sam mussman siddharth narayanaswamy dhaval salvi lara schmidt jiangnan shangguan jeffrey mark siskind jarrell waggoner song wang jinlian wei yifan yin zhiqi zhang video sentences uai arxiv jaime carbonell jade goldstein use mmr diversity based reranking reordering documents producing summaries acm sigir xinlei chen c lawrence zitnick learning recurrent visual sentation image caption generation proceedings corr pradipto das chenliang xu richard f doell jason j corso thousand frames words lingual description videos latent topics sparse object stitching cvpr sandra e f avila ana p b lopes da luz de albuquerque araujo vsumm mechanism designed produce static video summaries novel evaluation method pattern recognition letters jia deng wei dong richard socher li jia li kai li li fei fei genet large scale hierarchical image database cvpr j donahue lisa hendricks s guadarrama m rohrbach s venugopalan t darrell k saenko long term recurrent convolutional networks visual recognition description cvpr john duchi elad hazan yoram singer adaptive subgradient methods online learning stochastic optimization journal machine learning research hao fang saurabh gupta forrest iandola rupesh k srivastava li deng piotr dollar jianfeng gao xiaodong margaret mitchell john c platt al captions visual concepts cvpr ana l n fred anil k jain robust data clustering cvpr andrea frome gs corrado jonathon shlens devise deep semantic embedding model nips arxiv boqing gong wei lun chao kristen grauman fei sha diverse sequential subset selection supervised video summarization nips michael gygli helmut grabner luc van gool video summarization learning submodular mixtures objectives cvpr m gygli h grabner h riemenschneider f nater l van gool interestingness images iccv michael gygli yale song liangliang cao automatic generation animated gifs video cvpr amirhossein habibian thomas mensink cees gm snoek videostory embeddings recognize events examples scarce tpami sepp hochreiter jurgen schmidhuber long short term memory neural computation xs hua l yang m ye k wang y rui j li clickture large scale real world image dataset technical report msr bogdan ionescu adrian popescu mihai lupu alexandru lucian ginsca henning muller retrieving diverse social images mediaeval challenge dataset evaluation mediaeval phillip isola devi parikh antonio torralba aude oliva understanding intrinsic memorability images nips m jain jan c van gemert t mensink c gm snoek classifying localizing actions video example iccv andrej karpathy armand joulin fei fei li deep fragment embeddings bidirectional image sentence mapping nips andrej karpathy fei fei li deep visual semantic alignments generating image descriptions cvpr aditya khosla raffay hamid cj lin neel sundaresan large scale video summarization web image priors cvpr gunhee kim leonid sigal eric p xing joint summarization scale collections web images videos storyline reconstruction cvpr ryan kiros ruslan salakhutdinov richard s zemel unifying semantic embeddings multimodal neural language models arxiv preprint johannes kopf michael f cohen richard szeliski person lapse videos acm transactions graphics krause d golovin submodular function maximization yong jae lee joydeep ghosh kristen grauman discovering important people objects egocentric video summarization cvpr hui lin ja bilmes learning mixtures submodular shells application document summarization arxiv preprint feng liu yuzhen niu michael gleicher web photos suring video frame interestingness ijcai wu liu tao mei yongdong zhang c che jiebo luo multi task deep visual semantic embedding video thumbnail selection cvpr xin lu zhe lin xiaohui shen radomir mech james z wang deep multi patch aggregation network image style aesthetics quality tion cvpr zheng lu kristen grauman story driven summarization egocentric video cvpr long mai hailin jin feng liu composition preserving deep photo aesthetics assessment cvpr junhua mao wei xu yi yang jiang wang alan l yuille explain ages multimodal recurrent neural networks arxiv preprint masoud mazloom xirong li cees snoek tagbook semantic video representation supervision event detection ieee transactions multimedia marina meila comparing clusterings variation information learning theory kernel machines springer t mikolov k chen g corrado j dean efficient estimation word representations vector space arxiv preprint t mikolov j dean distributed representations words phrases compositionality nips m minoux accelerated greedy algorithms maximizing submodular set functions optimization techniques jonas mueller aditya thyagarajan siamese recurrent architectures learning sentence similarity aaai mukund narasimhan jeff bilmes submodular supermodular procedure applications discriminative structure learning arxiv preprint gl nemhauser la wolsey ml fisher analysis approximations maximizing submodular set functions mathematical programming m norouzi t mikolov s bengio y singer j shlens frome g s corrado j dean zero shot learning convex combination semantic embeddings arxiv preprint jeffrey pennington richard socher christopher d manning glove global vectors word representation emnlp danila potapov matthijs douze zaid harchaoui cordelia schmid category specific video summarization eccv springer yael pritch alex rav acha shmuel peleg nonchronological video synopsis indexing tpami gj qi xs hua y rui j tang t mei hj zhang correlative multi label video annotation aidean sharghi boqing gong mubarak shah query focused tive video summarization corr karen simonyan andrew zisserman deep convolutional works large scale image recognition arxiv preprint richard socher andrej karpathy quoc v le christopher d manning drew y ng grounded compositional semantics finding describing images sentences acl y song m redi j vallmitjana jaimes click click automatic selection beautiful thumbnails videos cikm acm yale song jordi vallmitjana amanda stent alejandro jaimes tvsum summarizing web videos titles cvpr min sun ali farhadi steve seitz ranking domain specific highlights analyzing edited videos eccv min sun ali farhadi ben taskar steve seitz salient montages unconstrained videos eccv min sun kuo hao zeng yenchen lin farhadi ali semantic highlight retrieval term prediction ieee transactions image processing ba tu truong svetha venkatesh video abstraction acm transactions multimedia computing communications applications silke wagner dorothea wagner comparing clusterings overview graph theoretic concepts computer science yufei wang zhe lin xiaohui shen radomir mech gavin miller garrison w cottrell event specific image importance cvpr wayne wolf key frame selection motion analysis acoustics speech signal processing bo xiong kristen grauman detecting snap points egocentric video web photo prior eccv ting yao tao mei yong rui highlight detection pairwise deep ranking person video summarization cvpr gloria zen paloma de juan yale song alejandro jaimes mouse activity indicator interestingness video icmr kuo hao zeng yen chen lin ali farhadi min sun semantic highlight ke zhang wei lun chao fei sha kristen grauman video rization long short term memory eccv bin zhao eric p xing quasi real time summarization consumer retrieval icip videos cvpr
