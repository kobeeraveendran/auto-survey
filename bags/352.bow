figure meta evaluation factuality summarization saadia gabriel asli celikyilmaz rahul jha yejin choi jianfeng gao paul g allen school computer science engineering university washington microsoft research allen institute articial intelligence skgabrie washington edu aslicel rajh com t c o l c s c v v x r abstract text generation models generate factually inconsistent text containing distorted cated facts source text recent work focused building evaluation models verify factual correctness semantically constrained text generation tasks ment summarization eld ality evaluation growing fast nt dened criteria measuring tiveness generalizability reliability tivity factuality metrics focusing aspects paper introduce meta evaluation framework evaluating tual consistency metrics introduce ve necessary common sense conditions fective factuality metrics experiment recent factuality metrics synthetic human labeled factuality data short news long news dialogue summarization domains framework enables assessing efciency new factual consistency metric variety dimensions tiple summarization domains ily extended new meta evaluation criteria present conclusions dardizing factuality evaluation metrics introduction goal text generation systems produce text uent coherent relevant factually correct recent progress neural proaches building semantically constraint text generation systems shown tremendous ments direction liu lapata guo et al durmus et al wang et al important issue text generation tems yield factually inconsistent text caused somewhat distorted fabricated facts source text especially document summarization tasks models abstract away salient aspects shown generate text figure example ground truth cnn dailymail mary transformed summary key spans ground truth summary highlighted green contain factual errors highlighted red transformed summary factual commonly rouge rization metric assigns higher values summary ground truth summary compare original article reference factual inconsistencies kryscinski et al falke et al zhu et al commonly metrics measuring quality generated text fail capture structural aspects language poorly correlate human ments hashimoto et al clark et al shown figure simple transformations like copying ller terms source text ducing logical negations transform factually grounded summary factually inconsistent summary lead higher rouge score factual summary compare candidate summaries original source document years observed increase research papers factual consistency evaluation metrics reasons number metrics proposed measuring factuality proxy objectives like question answering qa facet overlap scialom et al durmus et al mao et al raising number new research questions including metrics capture multiple aspects dimensions ality summarization metrics capture factuality broader spectrum domains unclear metrics suitable evaluating types text generation methods think answering questions key determining usability effectiveness recent factuality metrics especially sidering previously explored summarization domains like dialogue summarization work propose rst tion framework meta evaluation framework assessing effectiveness tuality metrics multiple dimensions domains extreme news summarization sentence news summarization dialogue marization prior work tual consistency concentrated dataset domain framework allows test bustness accuracy proposed metrics uating factual consistency domains termine metrics truly generalize primarily focus summarization open ended generation source document provides natural grounding factuality contributions follows set agnostics measuring sensitivity metrics different levels factual inconsistency e statistically signicant differences metric results factual generations vs factual generations sensitivity rics types factual errors e lexical semantic changes metrics better capture synthetic evaluation dataset context summary pairs summarization domains suring effectiveness new factuality metrics evaluation dataset contains different levels jected factual errors simulate errors generation models nally evaluation dataset summaries generated based models raffel et al rothe et al annotated types factual errors provides test bed capturing real distribution errors generation models outline understanding evaluation factuality generative publicly release code evaluation work diagnostic datasets soon factuality metric meta evaluation reference summaries incomplete representation salient source ument unavailable consider factuality terms candidate summaries ally grounded respect source document reference summaries assume source documents factually valid use external sources databases fact ication dene summary having factual inconsistency level errors present e summary errors factual sistency level summary error inconsistency level section propose set necessary conditions dening effective factuality metric including theoretical constraints metric values commonsense ditions sections describe construction diagnostic datasets test ditions simulated generated setting section elaborate conditions dened framework practically plied measure sensitivity metrics changes factuality dene good factuality metric dene set ve conditions text tion metric m d si effectively measure factual consistency summary si respect source document d boundedness condition dene mally sf completely factual mary sr completely factually inconsistent expect m d sr m d si m d sf words metric values reasonably bounded bounds relate factuality candidate summaries kryscinski et al dene facts salient spans source document e spans text lighting key information pertaining entities source documents actions performed statistical reporting spans support refute claims summaries simulated data possible duce errors section case maximum number errors dene summary completely factually sistent summary contains facts overlap facts source document stat xsum cnndm samsumm avg words summ source avg entities summ source avg pronoun words summ source avg verbs summ source avg adjectives summ source table dataset statistics summaries summ source documents source evaluation sets corresponding values summaries given left values source documents given right sensitivity condition ii dene tual inconsistency level measure indicate differences metric results e factual generations vs factual generations calculate sensitivity score given metric based magnitude slope line factual inconsistency level average metric values e estimated rate metric values change level factual inconsistency sensitivity l mi m eq l maximum error level l average error level mi average value metric error level m average value metric error levels metric sensitive changes factuality hold statistically signicant difference mi robustness condition iii metric robust types factual errors e able capture intrinsic entity errors types factual errors like pronoun errors table list factual error types consider generality condition iv metric generalizable domains e satises previously dened conditions domain expected satises conditions domain b acknowledge likely corner cases true metric domains factuality difcult dene story generation example consider domains factual consistency evaluation obviously applicable commonsense condition v annotators judge summary si human factually consistent summary sj expect si sj h human judgement score ality words metric correlate human judgements factuality testing factuality metric validity purposes testing boundedness condition dene lower bound metric m m d sr d source document sr randomly sampled summary pus dene upper bound metric m d sf sf reference ground truth summary test sensitivity condition ii report sitivity score eq measure differences metric results different levels factual inconsistency differences statistically signicant test measure correlation pearson s r factual inconsistency level maries e number injected errors average metric score measure statistical signicance p value tailed hypothesis test check metrics satisfy robustness generality conditions iii iv separately running analysis multiple factual error types domains tasks measure commonsense checking correlation factual consistency levels determined manual annotation metric values evaluation datasets evaluate factual consistency metrics categories datasets available tion datasets varying domains diagnostic datasets simulated evaluate different levels factuality model generated datasets dataset train dev test domain diagnostic datasets xsum cnndm samsum short news long news dialogues table summarization domains evaluation summarization datasets work consider summarization domains cover broad range topics lengths truth summaries levels abstractiveness particular focus accurately measuring tuality context news dialogue marization key preventing spread misinformation different domains ample dialog summarization important machine generated summary exchange politician reporter press ence factually consistent nt hallucinate details said considered following summarization domains table dataset statistics short news test ability metrics sure factuality extreme news summarization domain use xsum dataset narayan et al contains bbc news articles paired sentence summaries long news test metrics longer sentence summaries cnn dailymail dataset nallapati et al tend extractive summaries xsum dataset dialogues contrast news dialogue rization resources relatively scarce use recently released samsum corpus gliwa et al test metrics dialogue summarization samsum consists english language sations written linguists style chat messenger dialogues aligned multi sentence summaries compared cnn dailymail dataset xsum considered abstractive based portion novel n grams gold summaries comparison source documents narayan et al compared structured news ments samsum dialog dataset unstructured contains chats varying interlucators text rst person directed speech summaries written person point view makes highly abstractive ture test ability proposed metrics fulll predened conditions set tic datasets consisting transformed reference summaries simulated factuality errors low induce measure factual consistency controlled setting summaries generated state art transformer summarization els allows measure effectiveness metrics real data setting simulated datasets considered domains section sample source document reference mary pairs inject simulated factual errors reference summaries based randomly lecting entities including pronoun words verbs adjectives induce desired level factual inconsistency dene list errors inject transformations table notice transformations duce change reference summary lack lexical features changed ble distribution entity words verbs adjectives example xsum reference summary warm humorous gutsy sparky ful determined fun contains entities verbs transformed addition transformations effect factuality e xsum mary know bob best paramedic finlay newton bbc s casualty ing idris bob change smaller ratio summary content words exchanging idris finlay newton reasons generate ve different versions set diagnostic data randomly selecting ence summary transformations assessing aggregated results table distribution errors control factuality transformed maries setting maximum number random transformations injected errors resenting different levels factual tency sensitivity evaluations condition ii appendix details verb negation focus simple negations e agree agree complex negation e agree disagree agree beg differ reference type description example irish taoiseach pm leo varadkar engaged sock diplomacy rst meeting canadian prime minister justin trudeau dublin intrinsic entity error int entity appearing source document incorrectly canadian taoiseach pm leo varadkar engaged sock diplomacy rst meeting irish prime minister justin trudeau dublin irish taoiseach pm leo varadkar engaged sock diplomacy rst meeting canadian prime minister justin trudeau dublin extrinsic entity error ext entity appearing candidate summary appear source document french taoiseach pm leo varadkar engaged sock diplomacy rst meeting canadian prime minister justin trudeau dublin irish taoiseach pm leo varadkar engaged sock diplomacy rst meeting canadian prime minister justin trudeau dublin irish taoiseach pm leo varadkar engaged sock diplomacy rst meeting canadian prime minister justin trudeau dublin irish taoiseach pm leo varadkar engaged people prescribed powerful anxiety pain relief drugs warned new drug driving law pronoun error pro negation error verb sentiment error sent pronoun candidate summary incorrectly example instead canadian prime minister justin trudeau dublin irish taoiseach pm leo varadkar engaged sock diplomacy rst meeting verb negations candidate summary contradict source document adjective adverb appearing candidate summary contradicts source document irish taoiseach pm leo varadkar engaged sock diplomacy rst meeting canadian prime minister justin trudeau dublin irish taoiseach pm leo varadkar engage people prescribed weak anxiety pain relief drugs warned new drug driving law table table possible factual errors dataset level avg level avg level avg xsum entity xsum non entity cnndm entity cnndm non entity samsum entity samsum non entity avg transformed table analysis simulated diagnostic dataset average different sets runs randomized transformations reference summaries provide results average number induced factuality errors factual inconsistency level level level percentage summaries transformed level levels split diagnostic dataset subsets based simulated errors related entities entity non entity changes like verb negation non entity model generated datasets assess performance metrics actual generated text use version encoder decoder summarization model fel et al pretrained news marization data generate summary text greedy decoding beam search based decoding strategy like k fan et al nucleus sampling holtzman et al conduct ne grained human evaluation tuality generated summaries assess tiveness sensitivity analysis highlighting metric strengths weaknesses generated maries section factuality metrics evaluation mainly focus meta evaluating recently proposed factual consistency metrics use types proxy natural language ing nlu objectives aimed implicitly capturing factuality generated text question answering qa masked token prediction cloze task measure factual awareness marization metrics aimed primarily proving coherency factual consistency e bertscore zhang et al bleurt sellam et al standard summarization evaluation metrics e rouge lin following list metrics factual consistency evaluation qa based quality score given source reference document d candidate summary si qa based evaluation metrics assign generation quality score si measure ability qa system accurately answering questions ated d si use summaqa scialom et al feqa durmus et al rics metric questions erated source document d date summary si input qa system alternatively feqa generates questions si uses d answer questions generation quality score typically gregated score measuring similarity ground truth answers questions generated d answers predicted qa system generally includes aggregated model condence probabilities predictions masked lm prediction cloze task score given source document d candidate mary si cloze based evaluation metrics assign generation quality score si measuring ability nlu system accurately predict masked tokens source document given cess information si use variants blanc vasilyev et al blanc help blanc tune blanc help uses d si input pretrained masked token prediction model blanc tune uses d input model netuned date summary metrics aimed capturing uency informativeness factual correctness summaries semantic similarity semantic similarity rics measure overlap contextual beddings source reference document d candidate summary si use bertscore zhang et al shown correlate better human judgements coherency standard summarization metrics similarly n gram metrics factual consistency cnndm summaries wang et al lexical overlap finally test rouge lin standard metric uating summarization rouge measures gram overlap source reference ment d candidate summary si evaluate results rouge l measures longest common sequence overlap follow prior work sidered rouge factual consistency evaluations wang et al viously noted rouge underweight good summarization examples novikova et al meta analysis factuality metrics controlled data experiments conduct controlled experiments lated datasets introduced mainly measure sensitivity factuality metrics simulated factuality errors provide results sensitivity analysis ulated data xsum domain table cnndm table samsum table reported results aggregated metric ues computed ve different sets random transformations section details focused specically factuality sitive changes factuality compared dard lexical overlap contextual semantic larity metrics metrics tune rouge l satisfy edness condition tables additionally metrics summaqa condence scores summaqa c sensitive entity errors dialogue dataset table cnndm nd metrics blanc tune feqa sensitive factual consistency degree consider entity errors sensitive metric summaqa tivity score actual sensitivity effect size low rouge bertscore s xsum summaqa highest sensitvity score feqa bertscore tively correlated factual inconsistency p indicates factual sistency summaries relatively low factuality metrics high variance terms ness detecting differences levels factual inconsistency overall summaries factually correct xsum correct cnndm table details rouge valid factuality ric remove limitations cal overlap metrics posed reference summaries novikova et al nd high variation domains performance source document referenced rouge metrics identifying factual inconsistency metrics boundness sensitivity tions rouge l fail bounded e xsum summaries factual tency level average score upper bound sensitive case non entity based errors metric values actually increasing factual inconsistency increases correlations xsum cnndm respectively rouge l correlations implies standard lexical overlap metrics able pick obvious lexical errors like indicated entity changes inadequately sensitive subtler changes like captured verb negation differences factuality standard metrics fragile factuality high results collectively suggest metrics qa vs cloze masked token prediction cloze task metrics improve rouge comes detection non entity based errors upper bound level level level lower bound sensitivity correlation p value upper bound level level level lower bound sensitivity correlation p value cloze blanc help blanc tune summaqa c summaqa feqa qa standard contextual bertscore r l table results simulated factual error data experiments xsum average runs signicant p signicant p cells results entity errors reported left results non entity errors reported right details upper lower bounds sensitivity score p value correlation measures explained sensitivity factual consistency correlation factuality levels highlight best performing lowest performing metrics green red respectively cases metric values invalid e metric values increase factuality decreases highlight purple cloze blanc help blanc tune summaqa c summaqa feqa qa standard contextual bertscore r l table results simulated factual error data experiments cnndm average runs table caption details summaqa c summaqa feqa qa standard contextual bertscore cloze blanc help blanc tune upper bound level level level lower bound sensitivity correlation p value r l table results simulated factual error data experiments samsum average runs table caption details cnndm shown table bounded negatively correlated consistent qa metrics blanc tune positively correlated factual inconsistency xsum fact metrics primarily entity focused understanding semantic meaning summary nd metrics rely implicit nlu like summaqa feqa scores effective metrics xsum negatively correlated statistical signicance summaqa c particular highest sensitivity score table impact summary length general metrics tested perform better samsum cnndm xsum metrics showed signicant correlations entity based factual error level cnndm vs metrics xsum hypothesize fact samsum cnndm summaries multi sentence provides context fact checking generated data experiments order observe metrics perform machine generated summaries generate maries ne tuned encoder decoder marization model manually evaluate set summaries xsum dataset pled k decoding model summaries aligned articles sampled random subset use trolled sensitivity experiments nd generated summaries contain factual error summaries factually inconsistent contain errors matches constraints controlled sensitivity experiment shown figure types errors dened controlled sensitivity experiments blanc help pearson s r p blanc tune pearson s r p feqa pearson s r p summaqa c pearson s r p summaqa pearson s r p bertscore pearson s r p figure distribution metric values evaluated work evaluations human annotated generated xsum dataset sample summaries factuality levels different metric types cloze task question answering contextual metrics colored bounds indicate variation samples colors indicate levels factuality errors results shown errors false quote attack doctors actual implication ground truth summary blood tests lead better diagnosis heart attacks unnecessary hospitalization preventing heart attacks nd types false quote errors appear frequently xsum summaries type errors extrinsic entity errors ext figure shows distribution metric values factuality levels sampled xsum summaries excluding false quote errors table lists correlation p values figure including rouge scores nd metrics cloze task rics negatively correlated summaqa metrics statistically signicant correlation line ndings simulated data form table found summaqa performed best terms sensitivity score metrics tively correlated factual inconsistency value compared feqa cloze task metrics bounded sensitive blanc tune figure distribution factual error types generated xsum summaries factual error types described table ext extrinsic entity error int intrinsic entity error pro pronoun error neg negation error sent sentiment error false quote hallucinated quotes described table appear tated generated summaries discovered new category error dene human ation false quote describes instance hallucinated quote generated summary example model generated xsum mary claim blood test help save man having heart attacks says british medical journal ground truth summary blood test halve number people admitted hospital suspected heart factuality metric factuality metric factuality metric factuality metric factuality metric factuality metric valueserror int pro ext verb sent false quote table correlation annotated xsum generated maries false quote errors metric correlation p value blanc help blanc tune summaqa c summaqa feqa r l bertscore metric correlation p value blanc help blanc tune summaqa c summaqa feqa r l bertscore table correlation annotated xsum generated maries error types correlations entity based errors analysis generated data notice difference results feqa rouge l metrics nd metrics sensitive score simulated xsum data entity based errors signicantly sensitive generated data metrics negatively correlated ings indicate magnitude sensitivity score simulated data analysis statistical signicance key predicting results generated data consider errors table nd relatively variation metric scores factuality els generated summaries evidence metric values weakly correlated factuality level discussion meta evaluation analyses contrast prior work factual consistency concentrated specic domain dataset figure work effective testing performance metrics generalize domains highlight following key points periments run figure meta tion simulated data analysis highlights trends worst performing tuality metrics human analysis metrics low sensitivity scores simulated xsum data perform poorly human annotated xsum data regardless correlation factual consistency simulated data conversely high sensitivity scores simulated data indicator better performance human annotated data purposes determining reliable factuality metric suggests simulated data sufcient given metrics e high sensitivity case metrics like bertscore rouge variance performance simulated generated data predictable low sensitivity analysis human annotated data necessary evaluating metrics blanc help metric values decrease factual inconsistency simulated data metric positively correlated factual inconsistency generated data differences factuality metrics lexical overlap metrics clearcut considering generated summaries opposed transformed reference summaries rouge metrics increase factual consistency decreases consider set error types table promising lexical overlap metric simulated summaries simulated experiments positively correlated factual inconsistency remove false quote errors emphasizes importance human annotated test set figure meta evaluation factuality metrics effectiveness clear factual consistency low factuality metrics higher sensitivity scores standard lexical overlap contextual metrics analyses bertscore metric values appear correctly correlated factual consistency score reference summaries transformed simulated factual inconsistencies metrics perform generated summaries room factual inconsistency limitations dene levels factual inconsistencies framework assumes correctness factual claim binary scaled possible generated summaries factually consistent unfaithful meaning carry different implications ground truth summaries example summary uk remain member european union matching ground truth summary uk remain member eu factually consistent topic given underlying news article slight change phrasing question generated summary makes appear leading question impartial framing original summary relates subjectivity generated text including generated misinformation zellers et al measuring shifts faithfulness subjectivity explicitly captured current conditions framework related work factuality summarization recent efforts nlp researchers drawn attention issue factual errors hallucinations output neural summarization models cao et al massarelli et al zhao et al work kryscinski et al similar simulated data collection improving factual consistency models simulated data training evaluation dusek et al introduced reference model based generation quality metric based adversarial training simulated examples number works highlighted effectiveness qa cloze task objectives evaluating improving factuality specic domains eyal et al huang et al aim evaluate metrics broadly evaluation framework prior work cerning evaluation automatic metrics nlg systems mainly focused general evaluations output quality coherence uency callison burch et al graham fabbri et al factuality recent work started explore evaluating factuality faithfulness summarization falke et al goodrich et al celikyilmaz et al particular maynez et al compare correlation summarization metrics human judgements factuality expand prior analyses introducing concretely dened framework evaluating current future factuality metrics contrast earlier works consider broader range domains notably dialogue summarization conclusion meta evaluation framework effectively evaluate sensitivity ity factual consistency metrics ence summaries requiring intensive testing summarization model variants identify metric strengths ings theoretically grounded nature ric conditions allows potential extensions use cases text generation settings like data text generation particular ndings application framework summarization highlight current metrics capable capturing obvious lexical errors e entity errors summaries gle errors related subtle aspects semantics e negation false quotes posed future directions improving ability metrics capture broader spectrum factual inconsistencies include modication qa metrics like summaqa feqa use contextual question generation qg systems e sense qg shwartz et al allows nuanced fact checking acknowledgments authors thank yichen jiang shiyue zhang feedback implementation hannah rashkin tom mccoy help msr gpu clusters rowan zellers elizabeth clark pointers related work members uw nlp msr ai msr msai communities helpful comments references chris callison burch cameron fordyce philipp koehn christof monz josh schroeder evaluation machine translation ceedings second workshop statistical chine translation pages prague czech republic association computational tics ziqiang cao furu wei w li sujian li faithful original fact aware neural tive summarization aaai asli celikyilmaz elizabeth clark jianfeng gao evaluation text generation survey arxiv elizabeth clark asli celikyilmaz noah smith sentence mover s similarity automatic uation multi sentence texts acl esin durmus mona diab feqa question answering evaluation framework fulness assessment abstractive summarization proceedings annual meeting ciation computational linguistics pages online association computational guistics ondrej dusek jekaterina novikova v rieser referenceless quality estimation natural language generation arxiv matan eyal tal baumel michael elhadad question answering automatic evaluation ric news article summarization ings conference north american chapter association computational guistics human language technologies volume long short papers pages neapolis minnesota association computational linguistics r fabbri wojciech kryscinski b mccann summeval arxiv r socher d radev evaluating summarization evaluation tobias falke leonardo f r ribeiro prasetya ajie utama ido dagan iryna gurevych ranking generated summaries correctness teresting challenging application natural guage inference acl tobias falke leonardo f r ribeiro prasetya ajie utama ido dagan iryna gurevych ranking generated summaries correctness teresting challenging application natural guage inference proceedings annual meeting association computational guistics pages florence italy tion computational linguistics angela fan m lewis yann dauphin arxiv story generation hierarchical neural bogdan gliwa iwona mochol maciej biesek aleksander wawer samsum corpus human annotated dialogue dataset abstractive summarization arxiv b goodrich v rao mohammad saleh peter j liu assessing factual accuracy ated text proceedings acm sigkdd international conference knowledge discovery data mining yvette graham evaluating automatic marization bleu shades rouge proceedings conference cal methods natural language processing pages lisbon portugal association tational linguistics han guo ramakanth pasunuru mohit bansal soft layer specic multi task summarization entailment question generation ceedings annual meeting tion computational linguistics volume long papers pages melbourne australia sociation computational linguistics t hashimoto hugh zhang percy liang unifying human statistical evaluation ral language generation arxiv ari holtzman jan buys m forbes yejin choi curious case neural text degeneration arxiv luyang huang lingfei wu lu wang knowledge graph augmented abstractive rization semantic driven cloze reward ceedings annual meeting ciation computational linguistics pages online association computational guistics wojciech kryscinski b mccann caiming xiong r socher evaluating factual sistency abstractive text summarization arxiv chin yew lin rouge package matic evaluation summaries text tion branches pages barcelona spain association computational linguistics yang liu mirella lapata hierarchical formers multi document summarization acl yuning mao liyuan liu qi zhu xiang ren awei han facet aware evaluation tive summarization acl luca massarelli f petroni aleksandra piktus myle ott tim rocktaschel vassilis plachouras f vestri s riedel decoding gies affect veriability generated text arxiv joshua maynez shashi narayan bernd bohnet ryan t mcdonald faithfulness arxiv factuality abstractive summarization george miller wordnet lexical database english commun acm tianyi zhang v kishore felix wu k weinberger yoav artzi bertscore evaluating text generation bert arxiv z zhao shay b cohen b webber ing quantity hallucinations abstractive tion arxiv chenguang zhu william hinthorn ruochen xu qingkai zeng michael zeng xuedong huang meng jiang boosting factual correctness abstractive summarization ramesh nallapati bowen zhou c d santos c aglar gulcehre b xiang abstractive text marization sequence sequence rnns yond conll shashi narayan shay b cohen mirella lapata nt details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing brussels belgium jekaterina novikova ondrej dusek curry ena rieser need new evaluation rics nlg emnlp colin raffel noam shazeer adam roberts katherine lee sharan narang michael matena yanqi zhou w li peter j liu exploring limits transfer learning unied text text arxiv sascha rothe shashi narayan severyn leveraging pre trained checkpoints sequence generation tasks transactions association computational linguistics thomas scialom sylvain lamprier benjamin wowarski jacopo staiano answers unite unsupervised metrics reinforced rization models emnlp ijcnlp thibault sellam dipanjan das ankur parikh bleurt learning robust metrics text generation proceedings annual ing association computational linguistics pages online association tional linguistics noam shazeer mitchell stern adafactor adaptive learning rates sublinear memory cost icml vered shwartz peter west ronan le bras dra bhagavatula yejin choi vised commonsense question answering talk emnlp oleg v vasilyev vedant dharnidharka j hannon blanc human free quality estimation document summaries arxiv fill alex wang kyunghyun cho mike lewis asking answering questions evaluate proceedings tual consistency summaries annual meeting association putational linguistics pages online association computational linguistics rowan zellers ari holtzman hannah rashkin yonatan bisk ali farhadi f roesner yejin choi defending neural fake news summary judged factually incorrect annotators allowed select number type errors observe predened list factual errors screenshot error types examples shown annotation task given figure summaries manually evaluated labeled factual inconsistency graduate student appendices simulated data transformations inject errors reference summaries rst speech tagging model named entity recognition system extract ties verbs adjectives summaries named entity track label type e org gpe intrinsic entity errors inject intrinsic entity errors summary s construct dictionary unique entities appearing source ument s organized entity label type swap random entity reference mary different entity label type constructed dictionary extrinsic entity errors extrinsic entity rors use dictionary construction unique entities appearing corpus source documents change random adjective use wordnet miller obtain synsets adjective swap adjective antonym pronoun entity errors pronoun errors troduced preset list commonly nouns randomly extract pronoun set e text preset list swap random pronoun set e verb negation use rule based system verb negation based verb tense predict tense based sufx preceding words training ne tune base model trained news summaries domain adafactor optimizer shazeer stern learning rate batch size human annotation layout human annotation factual consistency summaries annotators source ment reference summary candidate summary assessed factuality ask factuality question choices yes e summary factual e summary contains factual sure e summary incoherent sistencies judge figure examples factual errors given annotation task
