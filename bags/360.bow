topic centric unsupervised multi document summarization scientic news articles amanuel alambo computer science engineering wright state university dayton alambo edu cori lohstroh oneil center wright state university dayton lohstroh edu erik madaus oneil center wright state university dayton madaus edu swati padhee computer science engineering wright state university dayton padhee edu brandy foster oneil center wright state university dayton brandy edu tanvi banerjee computer science engineering wright state university dayton tanvi edu krishnaprasad thirunarayan computer science engineering wright state university dayton edu michael raymer computer science engineering wright state university dayton michael edu abstract recent advances natural language processing enabled automation wide range tasks including machine translation named entity recognition sentiment analysis automated summarization documents groups ments remained elusive efforts limited extraction keywords key phrases key sentences accurate abstractive summarization achieved inherent difculty problem limited availability training data paper propose topic centric pervised multi document summarization framework generate extractive abstractive summaries groups scientic articles fields study fos microsoft academic graph mag news articles task posed algorithm generates abstractive summary developing salient language unit selection text generation techniques approach matches state art evaluated automated extractive evaluation metrics performs better abstractive summarization human evaluation metrics entailment coherence conciseness readability grammar achieve kappa score author linguists evaluated results plan publicly share human validated gold standard dataset topic clustered research articles summaries promote research abstractive summarization index terms abstraction language units multi document summarization text generation hierarchical clustering effort sponsored air force search laboratory usaf memorandum understanding partnership intermediary agreement government authorized reproduce distribute reprints governmental purposes notwithstanding copyright notation thereon introduction large number articles published research media community increasing demand produce summaries coherent concise informative matical summarization comes forms extractive abstractive extractive summarization focused extracting signicant sentences source documents studied abstractive summarization aims ways fusing paraphrasing sentences source documents form abstractive sentences challenges capturing abstractive concepts shared sentences source documents synthesizing informative summary limited progress abstractive summarization recent advances unsupervised multi document abstractive summarization usually limited forming summaries copying words source documents arranging words form new sentences approaches identify salient phrases sentences source documents fuse form abstractive summaries perform abstraction sentences framework consists phases extractive phase abstractive phase extractive phase follow fold approach identify core article peripheral articles set related articles second instantiate clusters language units core article perform centroid based clustering place language units peripheral articles clusters initialized language units core article fuse language units cluster enhanced multi sentence compression msc technique novel algorithm maximize topical coverage relevance path language units cluster abstractive summarization phase employ text generation generate abstractive language units alus use msc fuse generated alus abstractive summary unlike articles topically clustered scientic articles come topically grouped use topical hierarchical agglomerative clustering hac cluster articles key contributions study alu generation technique novel msc based algorithm selection informative paths gold standard dataset topical clusters articles doc abstractive summaries use abstracts articles mag study related work different techniques proposed unsupervised including sequence sequence abstractive summarization models neural models attention abstract meaning representation amr centroid based summarization approach techniques centroid based extends state art summarization employing language unit identication articles novel text generation technique abstractive summarization received signicant attention progress deep representation learning propose meansum consists autoencoder summarization module produce abstractive summaries abstractive summarization approach called ilpsumm includes identication informative content clustering similar sentences documents form summaries extended technique proposed introducing paraphrastic fusion model called parafuse based sensitive substitution target words lexical tion enables generation novel words limited comes capturing context source document propose pointer generator network summarize news articles cnn dailymail dataset propose framework takes article topic generates summary specic topic work supervised relies availability human generated training corpus train model iii data collection work datasets better understand evaluate proposed approach benchmark dataset scientic articles mag queried mag cited abstracts fos published fos articial intelligence articial neural network big data case based reasoning cybernetics cyberwarfare data mining data science decision support system electronic warfare expert system human machine interaction ligent agent knowledge based systems machine learning multi agent system prediction algorithms predictive lytics predictive modeling sensor fusion proposed method extractive phase fig shows sequence steps devised extractive summarization difference extractive phase tasks topic modeling hierarchical agglomerative clustering pipeline fig extractive summarization pipeline following cluster abstracts cluster topics topic modeling determine groups topically related abstracts fos rst build lda topic models fos number topics range determine optimal number topics ensemble lda models maximizes coherence score topics keywords generated lda model gives highest coherence score topical hac topical hierarchical agglomerative clustering different topics generated lda model semantically redundant keywords cluster topics having high similarity keywords hac use scibert embeddings represent keyword topic topic represented concatenation keywords topic representations represented conduct topical hac determine number clusters collection topics ran hac clusters ranging total number topics use silhouette coefcient determine optimal number clusters introduce topical similarity metric suring similarity pair topics keyword topic compared keywords topic sum highest similarity scores preserved topic topic itopic topic maximum cosine similarities term terms topic cluster topic ids table topics cluster membership abstract assigned topic dominant possible topics abstract addresses table shows clusters constituent topic ids table shows topical distribution abstracts selected eld study seen abstracts dominant topic abstracts form set documents perform multi document summarization abstract dominant topic dominant topic topic keywords inspire state device accelerator small size high power ved advantage inspire state device accelerator small size high power ved advantage table abstracts dominant topic core peripheral articles identication identify core article cluster articles based similar article articles computes article similarity score article article highest cumulative similarity articles cluster chosen core article rest articles cluster peripheral articles casi number articles cluster cluster articles sim based cosine similarity centroid based clustering core peripheral ticles identied generate extractive language units elus core peripheral articles recent studies centroid based summarization utilized sentences documents standalone elus initiate clusters quantify semantic relatedness approach breaks interdependence sentences document eventually leads incoherent summaries address issue identifying sentences interdependent neural coreference resolution preserving elu elus core article instantiated clusters elus peripheral articles placed cluster based cosine similarity embedding elu peripheral article embeddings elus core article elu embedding constructed concatenating embeddings sentences sent bert performing dimensionality tion units sne purpose dimensionality reduction uniform dimension elus contain different number sentences cosine similarity computed multi sentence compression number clusters formed centroid based clustering stage number elus core article clusters elus formed build word graphs cluster fig shows sample word graph constructed cluster consisting following elus radars required limit emissions adjacent bands traditional rectangular pulses high band emissions millimeter wave radars popularly mile radar based defense systems fig word graph elus tokens pos tags tokens node develop algorithm extracting paths based topical coverage relevance path selected additional criterion candidate path span elus cluster generate topically informative relevant paths word graph maintaining word summary limit topical coverage measures path covers dominant topics discussed articles elus relevance measures relevant path elus cumulative score path determined weighted sum topical coverage relevance experimented values range topical coverage formulation ctopics icpath cpath kcctopics cpath candidate path ctopics cluster topics topical coverage measured respect cluster topics path relevance formulation celu cpath candidate path celu cluster elus vectorial representation candidate path vectorial representation cluster elus path relevance measured respect elus cumulative score ctopics celu path selected word graph path longer average minimum length sentence fos topic smaller average maximum length sentence combined topical coverage relevance path meets exceeds threshold path picked word graph semantically similar selected path order threshold compare combined topical coverage relevance paths higher score remove selection based empirical observations abstractive phase fig shows steps followed abstractive tion difference abstractive phase headline generation component elu ability repair ship work key stable coalition alu good time new political party bring ity development table iii alu generated parameters generates candidate alus tuning set temperature number generated samples random sampling generate alus minimize redundancy train epochs batch size attain loss select alu maximizes semantic similarity minimizes syntactic similarity elu generation use normalized sum syntactic similarity introduce abstractiveness score alu shown use bart headline generation article later alu generation elu fig alus generation elu elu elu elu alu alu alu abstractive language unit elu extractive language unit cossimxbert cosine similarity dimension bert embeddings select alu gives highest abstractiveness score candidate alus table iii shows sample elu highest scoring alu generated multi sentence compression generating alus cluster build word graph run msc algorithm extractive phase ranking formulation path selection algorithm selecting informative paths word graph built time cluster alus fig shows cluster alus generated fused paths form nal abstractive summary results discussion extractive evaluation use rouge metrics evaluating extractive summaries taking source articles reference summary fig abstractive summarization pipeline abstractive language unit alu generation start abstractive phase pragmatic assumption title headline article abstraction individual extractive language units elus article propose method generate alu elu elu title headline prompts generating text combining bidirectional encodings title headline elu enables generating abstractive text elus consisting sentences encode sentence sentence bert concatenate representations perform dimensionality reduction sne encode elu encoding title headline use sentence bert dimensionality reduction tune model fos fig use tuned model generate alus given concatenation bidirectional encodings elu title headline article tune model addition human evaluation metrics use copy rate evaluating abstractive summaries copy rate assesses rate novel word generation shown table framework achieves lowest copy rate indicating able generate novel words task model ilpsumm parafuse approach ilpsumm parafuse approach copy rate table copy rate evaluation fig comparison abstractive summaries human evaluator evaluator evaluator model ilpsumm parafuse approach ilpsumm parafuse approach entailment coherence conciseness readability grammar table vii abstractive summarization results human evaluator evaluator evaluator model ilpsumm parafuse approach ilpsumm parafuse approach entailment coherence conciseness readability grammar table viii abstractive summarization results experimental results proposed approach forms signicantly better human abstractive evaluation rics copy rate mainly alu generation tuned model minimizing syntactic similarity generated alus abstractive evaluation proposed approach consistently performs better summ parafuse human evaluation criteria summ parafuse better results entailment contrast approach generally performs comparably criteria clearly infer generating summaries entailed source articles easier generating summaries coherent concise readable ical summaries words copied source articles highly likely entailed source articles baseline approaches ilpsumm parafuse higher copy rate entailment approach having low copy rate fig candidate alus compressed alu paths model ilpsumm parafuse proposed method table extractive evaluation extractive evaluation results shown tables respectively seen proposed method performs comparably baseline approaches rouge metrics abstractive evaluation metrics based lexical overlap rouge favor extractive summaries conduct abstractive summary evaluation human evaluation metrics propose study metrics developed consultation author linguists human evaluation metrics entailment coherence conciseness readability grammar author linguists evaluated abstractive summaries scale human evaluation metrics author linguists independently reviewed results generated approach ilpsumm parafuse determining rating criterion source articles validate summary compiled summaries compare resulting abstractive summary closer tive summary details notes higher entailment human evaluators judged coherence sentence structure sentences showed logical progression examining conciseness looked areas abstractive summary repeated noted sentence carried logical progression paragraph readability grammar spacing consideration looked sentence fragments word order took note instances missing subjects verbs rating grammar gave abstractive summary lower rating comma splices extra spacing fragments inappropriate punctuation model ilpsumm parafuse proposed method table extractive evaluation generating summaries entailed sources articles difcult proposed approach best entailment score task abstractive evaluation proach performs better baseline approaches ence conciseness readability grammar human evaluators marginally losing baselines cording evaluators entailment ilpsumm performs best attributed high copy rate ilpsumm approach generates signicantly novel words ilpsumm parafuse lose best entailment score ilpsumm parafuse proposed approach perform generally better surmise headline generation task use provided titles conclusion future work proposed unsupervised multi document abstractive summarization framework given set documents mag automatically clusters documents generates summaries cluster framework consists extractive abstractive phases extractive phase use coreference resolution extract groups dependent sentences source articles centroid based clustering followed enhanced multi sentence sion algorithm generate topically informative relevant summaries abstractive phase use text generation technique generate abstractive language units thesized abstractive summary number maries proposed method adaptively determined based semantic analysis topics discussed ments introduce dataset topically clustered groups scientic articles fields study abstractive summaries results proposed approach performs better state art centroid based summarization techniques human evaluation metrics copy rate future plan use additional knowledge metadata citation relationships scientic articles document summarization vii acknowledgment authors deeply grateful daniel foose helping developing scripts efcient data collection mag references zhou yang wei huang zhou zhao joint sentence scoring selection framework neural extractive document summarization ieee acm transactions audio speech language processing vol chu liu meansum neural model unsupervised document abstractive summarization international conference machine learning nayeem fuad chali abstractive unsupervised multi document summarization paraphrastic sentence fusion proceedings international conference computational linguistics banerjee mitra sugiyama multi document abstractive summarization ilp based multi sentence compression fourth international joint conference articial intelligence filippova multi sentence compression finding shortest paths word graphs proceedings international conference computational linguistics coling zhao shen aizawa unsupervised rewriter multi sentence compression proceedings annual meeting association computational linguistics sinha shen song eide hsu wang overview microsoft academic service mas applications proceedings international conference world wide web shi keneshloo ramakrishnan reddy neural stractive text summarization sequence sequence models arxiv preprint khatri singh parikh abstractive extractive text summarization document context vector recurrent neural networks arxiv preprint liu saleh pot goodrich sepassi kaiser shazeer generating wikipedia summarizing long sequences arxiv preprint liu manning point tion pointer generator networks arxiv preprint liao lebanoff liu abstract meaning representation multi document summarization arxiv preprint liu flanigan thomson sadeh smith stractive summarization semantic representations arxiv preprint vaswani shazeer parmar uszkoreit jones gomez kaiser polosukhin attention need advances neural information processing systems devlin chang lee toutanova bert pre training deep bidirectional transformers language understanding arxiv preprint krishna srinivasan generating topic oriented summaries conference neural attention proceedings north american chapter association computational linguistics human language technologies volume long papers blei jordan latent dirichlet allocation journal machine learning research vol jan beltagy cohan scibert pretrained language model scientic text arxiv preprint lee lewis zettlemoyer end end neural coreference resolution arxiv preprint reimers gurevych sentence bert sentence embeddings siamese bert networks arxiv preprint liu fine tune bert extractive summarization arxiv preprint boudin morin keyphrase extraction best reranking multi sentence compression narayan cohen lapata ranking sentences extractive summarization reinforcement learning arxiv preprint radford child luan amodei sutskever language models unsupervised multitask learners openai blog vol thirunarayan immaneni shaik selecting labels news document clusters international conference application natural language information systems springer lewis liu goyal ghazvininejad mohamed levy stoyanov zettlemoyer bart denoising sequence sequence pre training natural language generation translation sion arxiv preprint
