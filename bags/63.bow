biclustering readings and manuscripts via non negative matrix factorization with application to the text of jude joey mccollum and stephen brown abstract the text critical practice of grouping witnesses into families or texttypes often faces two obstacles contamination in the manuscript tion and co dependence in identifying characteristic readings and manuscripts we introduce non negative matrix factorization nmf as a simple vised and efficient way to cluster large numbers of manuscripts and readings simultaneously while summarizing contamination using an easy to interpret mixture model we apply this method to an extensive collation of the new testament epistle of jude and show that the resulting clusters correspond to human identified textual families from existing research introduction genealogical analysis has had a prominent role in new testament nt critical theory even before it was popularized in the work of westcott and hort indeed one of the steps in their approach that of classifying manuscripts mss into families and texttypes based on their shared readings goes back over a century and a half earlier to the works of mill bentley and bengel in theory the rationale for this is that the more two mss agree in their readings the more likely they are to represent a close common ancestor or to have an exemplar copy relationship themselves the goal is that by grouping witnesses in this way the critic can then weigh them according to how purely they represent their group or how derivative they are from common sources the theory is not without obstacles however despite the emphasis they placed on the genealogical method westcott and hort misused the method by overlooking the effects of contamination or mixture of readings characteristic of different types on the genealogy they were attempting to derive it turns out that such mixture is somewhat ubiquitous indeed as more mss are discovered and studied placing them into families and texttypes by hard assignment only blurs the lines between these groups even more an additional complication in the assignment of mss to groups is the dual problem of assigning readings to groups any two witnesses will probably agree in a majority of their readings so simply counting places of agreement is insufficient in order to classify texts into well defined well separated groups we must determine which readings are the most significant for this purpose so we must first determine the readings that the most characteristic mss of a group share and that few or no other mss share but in order for us to do this the mss must be assigned to groups already this leaves us with a problem of co dependence characteristic mss of a given type are determined by which characteristic readings they have date february mathematics subject classification key words and phrases textual criticism text analysis text mining text types classification machine learning nonnegative matrix factorization nmf new testament jude mccollum and brown and characteristic readings of a given type are determined by which characteristic mss attest to them these observations have spurred the increased use of approaches that exchange the assumptions of texttype theory for other assumptions seeing the benefits of these methods some researchers have started to question the continued relevance of methods based on texttypes others have proposed to abandon the underlying theory altogether yet the idea of texttypes has not been rejected universally epp for one has argued for its continued value more generally the assumptions made by other methods introduce limitations of their own some of which the theory of texttypes can overcome it is also important to recognize that texttype based methods and newer approaches are not mutually exclusive but can be used in conjunction to achieve more refined results we will elaborate on these points briefly the main implication of our work with regard to theory however is that contamination and co dependence are not truly insurmountable obstacles to texttype based methods as we will show both issues can in fact be handled in this paper we present non negative matrix factorization nmf as a simple unsupervised and efficient computer based method for isolating clusters of mss and their most important readings simultaneously it is a pre genealogical method only in the sense that it does not infer any directed relationships among readings texts or groups as such it is not intended to replace more complex genealogical methods but to help researchers generate hypotheses that these methods can test and refine in the first section we review known classification methods with their advantages and disadvantages in the second section we show how nmf addresses the problems of contamination and co dependence and discuss its advantages over other methods this section involves some mathematics but the more technical details can be found in the references in the third section we describe our plication of nmf to tommy wasserman s full collation of mss of the epistle of jude in the last section we show that the use of nmf in different settings yields results in the form of recognizable texttypes and families established in the literature state of the art the history of textual criticism has seen the development of numerous cation methods we will not attempt an exhaustive treatment here but instead focus our attention on the following generalizations base text this method used in nt textual criticism at its earliest stages classifies ms texts based on their deviations from a single base of readings the base could be anything but historically it was the textus receptus tr classes were formed based on their common agreements against the base text quantitative this method introduced by colwell compares the text of each ms to that of every other ms similarity is generally measured as a simple count or proportion of readings at which two texts agree the set of pairwise similarity measures is then used to group texts according to a variety of algorithms profile the claremont profile method cpm developed by mcreynolds and wisse improves the efficiency and classification power of ing methods by taking identified groups and determining which patterns of readings provide the best profile for each group these profiles can then be used to determine the most likely group of an unclassified text and the strength of a classified text s group membership biclustering readings and manuscripts factor analysis this method which has been developed and put to use extensively at andrews university first determines the factors or combinations of readings that are most correlated to one another among ms texts and then groups mss by their strongest factors in this way it combines the text side approach of with the reading side approach of stemmatic stemmatic methods aim for a more precise and structured classification of texts by examining changes in every variation unit between extant texts and nodes representing their potential ancestors the goal is to construct an undirected stemma of maximum parsimony or the fewest changed readings along all links of the stemma examples of these methods can be found in the recent work of spencer wachtel and howe coherence based the coherence based genealogical method cbgm veloped by mink improves by producing directed stemmata that are robust to contamination it starts by constructing a directed local stemma for the readings at each variation unit based on general agreement among readings witnesses and transcriptional probability so that readings have prior and posterior relationships then it constructs a directed cal stemma for the texts at each unit based on their general agreement and their relative proportions of prior and posterior readings where they disagree these first two steps are applied iteratively to account for the co dependent relationship of good readings and good texts finally the local stemmata of texts are merged to form a global stemma that mizes the objective of simplicity as few ancestors to a text as possible under the constraint that the directed relationships of all readings are served a useful introduction can be found in wachtel s recent feature on the method we will summarize each method s advantages and disadvantages below method is simple to understand but it has many shortcomings it requires the assumption of a base text and it only defines groups in terms of their ments with this text when their agreements might also be informative because it offers no procedure for deciding which readings are the most signficant in ing groups it also fails to address the problem of co dependence between readings and texts typically the evaluation of which readings are important is done under human supervision and can be slow for a large number of readings this method can account for contamination but only after groups have been determined a brief discussion of this method can be found in ehrman s essay on classification methods method presents easy to interpret results requires no human supervision and dispenses with the unnecessary assumption of a base text its major tage is its computational cost building a table of pairwise similarity measures for n mss requires comparisons which becomes inconvenient for a large number of mss because it counts readings rather than weighing them it fails to address the problem of co dependence typical clustering algorithms do not accommodate contamination method is much more efficient by design than produces results that are simple to understand and can identify and quantify contamination between groups in a ms s text its greatest weakness is that it does not identify the groups to be profiled but assumes that they are it therefore does not even attempt has in fact been criticized on the basis of its application with poorly identified groups because of this it is best used in conjunction with methods like or mccollum and brown to address the problem of co dependence finally despite its efficiency it is a supervised method so it will not be as fast as some computer based methods method is extremely efficient is unsupervised and does not require the assumption of a base text as such it could reasonably be said to supersede method as a quantitative method furthermore the way the method fits readings and texts together in factors may be considered an adequate approach to the problem of co dependence the drawback is that the results of factor analysis can be difficult to interpret the method often assigns a negative coefficient for one or more groups to a text and there is no obvious sense of what that means the problem is that factor analysis does not provide a model that accounts for additive mixture between groups naturally this becomes an obstacle to identifying contamination for these reasons factor analysis is often refined using method method is unsupervised and it makes no assumptions about a base text furthermore unlike methods it avoids controversy over the use of texttypes by focusing instead on transmissional details at the level of individual texts and readings the price of this level of detail of course is complexity in implementation the construction of an optimal stemma is a computationally expensive task so one must sacrifice accuracy to complete it in an acceptable amount of time the other major disadvantage is that simple stemmata can not account for contamination in addition simple stemmatic approaches make no statements about good texts or readings until one has to orient the stemma method accounts for the problems of contamination and co dependence tween texts and readings without requiring any assumptions about underlying types in other areas however it is lacking first it is a supervised method ond between the initialization of a pairwise ms coherence table and the supervised construction of local stemmata the method is very time consuming third and haps most importantly it requires the assumption of a working initial text which for all practical purposes is tantamount to the base text assumption of method this assumption severely limits the scope of what can be achieved cbgm can help refine existing hypotheses but it can not compare significantly different hypotheses cbgm has risen to prominence relatively recently having only been applied on a large scale to the catholic epistles and acts during that time it has seen discussion as well as as we will show nmf combines many of best qualities of methods it it is unsupervised and extremely fast even with does not rely on a base text data as large as wasserman s jude collation it performs biclustering on mss and readings at the same time so it does not need a profile method to be applied on top of it most importantly nmf finds an equilibrium in the co dependent relationship of good witnesses and good readings and it does so in a way that is robust to contamination between groups as nmf models mixture additively its results are easy to interpret see table for a comparison of methods and nmf of course nmf relies on the assumptions of texttype theory so it is subject to the criticisms of that theory even so while a comprehensive discussion of texttype theory and its relevance is beyond the scope of this paper it should be noted that the results of nmf can still be used to benefit other methods in the pre processing stage cbgm and other stemmatic methods for instance are often applied only to a sample of all available mss and readings for the sake of time and computational resources nmf can provide a smart selection of significant mss and readings in this situation more information see houghton s survey wasserman s overview and tc featured articles on cbgm at biclustering readings and manuscripts table comparison of textual classification methods the text column label refers to the assumption of a base or working initial text the texttypes label to the assumption of ing texttypes the unsup label to the question of whether the method is unsupervised the fast label to whether the method is efficient and the contam and co dep labels to whether the method is robust to contamination and co dependence tively a text texttypes unsup fast contam co dep base text quantitative profile factor analysis stemmatic coherence based nmf theoretical basis nmf was popularized by daniel lee and sebastian seung in their paper since then it has found use in a wide array of fields see for a detailed survey with regard to fields most relevant to textual criticism it has found use in text mining for the purposes of document clustering and topic modeling and in computational biology for the purposes of classifying gene expressions in dna microarrays and more recently for determining biological admixture or ancestry coefficients the following treatment of the mathematical basis of nmf is primarily a summary but the interested reader is encouraged to refer to for details suppose that we have a collation consisting of m readings with readings in the same variation unit treated as distinct objects and n mss a natural way to represent this collation is an m n matrix where the rows represent the readings and the columns represent mss a cell at row i and column j contains a if ms j attests to reading i and a otherwise we will call this collation matrix a small example of such a matrix is shown in fig figure matrix representation of part of a collation as pected each column ms only has a nonzero value in a single reading in a given unit we want to find k latent features underlying this data in our case the features are texttypes or textual families the larger k is the finer the groupings are for the purposes of this application we assume that the observed readings and mss mccollum and brown have been generated by these hidden features fig gives an illustration of this model m n m k n figure a graphical illustration of the latent feature model sumed by nmf using the data from fig and k notice how the post factorization model weighs readings by the information they provide about a cluster and accounts for a mixture of these clusters in the corresponding equation for this generative process is x wh here w called the basis matrix is an m k matrix describing the makeup of each group in terms of linear combinations of readings and h called the coefficient or mixture matrix is a k n matrix describing the makeup of each mss s text in terms of linear combinations of groups so our goal is to find group membership coefficients for readings and for texts that when combined explain the data as best as possible since the data matrix x is obviously non negative and we want to describe it in terms of sums of parts we restrict w and h to be non negative as well this model has several advantages over standard clustering models first it allows readings and texts to belong to more than one cluster which is critical for providing group profiles and dealing with contamination it assigns weights to readings so that the ones more characteristic of a single cluster have higher priority than those shared among several and third it assigns weights to mss so we can see which ones are the strongest and purest representatives of their groups the closeness of the product wh to x can be measured in a variety of ways but in this paper we will use jjx f which is the squared frobenius norm or the total sum of squared differences between each cell of x and the corresponding cell of wh so our goal in any factorization will be to minimize this quantity how then do we find w and h we must first choose initial matrices and ourselves either with random positive values in each cell or with an educated guess then we alternate between updating them using the following rules biclustering readings and manuscripts arg min jjx f arg min jjx f in other words for each matrix in the factorization we fix the values of the other matrix and choose new non negative values for this matrix that minimize the value of function clearly this means that the value of function will never increase from one step to the next but can only decrease or remain the same until we reach a point in the process where rules and no longer change anything we iteratively update w using the current h and then update h using the new our aim is that by repeating these alternating optimizations we will eventually reach a fixed point in the process where function is no longer improved by these updates at this point the reader may recognize the lurking shadow of co dependence between readings w and witnesses h how do we know that the loop of updates wo nt reach a stable point before the objective function does and what happens if the process never reaches a fixed point as it turns out such scenarios can never happen theorem any limit point of the sequence fwt rules and is a stationary point of function generated by from this theorem we are guaranteed that our update process will not reach a stable point without the objective function doing the same if we add any upper bound it can be as large as we need to ensure accuracy to the entries of w and h then we can also guarantee that the update process has at least one limit point so nmf with objective function update rules and and arbitrarily large upper bounds on the matrix entries will always converge to a factorization that is at a stationary point of the objective as this analysis has shown nmf provides a natural model for identifying textual families and more than adequately addresses the problems of contamination and co dependence with regard to contamination it not only detects the degrees and sources of contamination in individual texts but also quantifies the importance of specific readings to textual clusters with regard to co dependence we have shown that nmf s use of iterative refinement of group readings and group witnesses is guaranteed not only to stop but to stop at a critical point of the function it is trying to minimize application data we applied nmf to tommy wasserman s comprehensive collation of the epistle of jude we considered this a good testing ground for the method for several reasons the size of the collation which might be prohibitive for more complex supervised methods can be handled efficiently and automatically by nmf should be noted however that the process and the objective function may have more than one stationary point meaning that one nmf run may reach a locally optimal but not globally optimal factorization it is therefore important to run nmf with good initial guesses for w and h or to repeat it many times with different random guesses mccollum and brown the collation is complete over nearly all readings and we can fore avoid any biases associated with previous selections of genealogically significant readings and texts moreover starting with virtually all able evidence we can discover new readings and texts of significance and add confidence to existing ones whose significance we re discover to the best of our knowledge no other application of this scale has been done with wasserman s work we hope that our work will spark continued research involving his collation and inspire work towards collations of equal scale elsewhere in the nt the collation covers mss including papyri and lectionaries across variation units in encoding the data we ignored lacunae partially lacunose or uncertain readings from non continuous text sources such as correctors and units contained within larger overlapping all readings that were not skipped including omissions were then represented by their own row in the collation matrix with mss represented in columns see fig the result was a matrix with non zero entries after running nmf on this matrix in different settings we observed that highly lacunose mss and singular readings were being isolated in their own clusters this likely occurred because these witnesses and readings constituted outliers with high influence on the objective function of the factorization to account for this we removed all singular readings from consideration and treated all mss with fewer than readings as secondary non continuous texts filtering these out we were left with a matrix with non zero entries the excluded mss are listed on page prior weights on readings we applied nmf to our collation matrix with the entries being weighed uniformly on the one hand and using the inverse ment frequency idf scheme on the other hand uniform weighting as its name suggests weighs all readings equally prior to nmf all entries of the matrix are therefore entries idf weighting developed to facilitate information retrieval in the context of terms and documents is a heuristic that seeks to weigh dividual terms by their specificity while a theoretical justification of its use has been elusive it has proven to be of great practical effectiveness in text mining tasks the definition is simple if a term t occurs nt times among n documents then we assign it a weight log n nt here log is a logarithm that can be taken to any base greater than with this weighting function the more documents term t appears in the less information it provides about any specific document the word the is an example of such a term if it appears in all n documents then its idf weight would be n notes that his apparatus does not record the most frequent orthographic variants such as instances of movable nu final vowel elisions in prepositions and conjunctions itacisms and other common vowel interchanges but this is actually good for our purposes since such readings are considered unimportant for ms classification readings contain underlying dots or brackets in wasserman s apparatus continuous texts pose the same problems for nmf that they do for other methods like cbgm nevertheless once clusters have been determined for the continuous text data we can make inferences about the non continuous texts on the basis of their readings see appendix a for more details way to handle units contained in larger omissions would be to treat them as omissions themselves we did not attempt to encode the data in this way but the number of variation units in question is small enough that we do not expect significantly different results biclustering readings and manuscripts meanwhile a word appearing in only a single document would have the larger weight in our case we would take readings as terms the highest specificity readings then would be those that occur more rarely with singular readings receiving the highest prior weight balancing this out is the fact that singular readings are less informative about non trivial clusters those consisting of more than a single ms which will lead nmf to give these readings a lower final weight than it gives to readings with attestation from slightly larger groups sometimes however singular readings will exert enough influence to bias the factorization towards outlying mss this is what initially happened with our data as we showed in subsection when this happens it is prudent to perform outlier detection and removal as we have done ultimately in maximizing the cohesiveness of ms clusters non singular readings that are shared exclusively by the mss in a given cluster are likely to become the most important readings meanwhile readings that are common to multiple clusters will be given less weight and therefore will play less of a role in nmf each of these two weighting schemes is best suited for a different set of tasks uniform weighting is better in the context of clustering on the whole picture of readings and explaining as much of the variance between mss as possible this is applicable for example to the construction of a text critical apparatus where we want to group many mss under a few sigla for the purpose of succinctness while having to list as few exceptional cluster members as idf weighting is more useful in producing weighted profiles of textual families based on their most exclusive readings in general it is more aligned with human intuition in identifying textual groups as we will see implementation for ease of use we stored all apparatus matrices along with their row and column headers as microsoft excel spreadsheets for all putational work we used release of the python programming to read and write data from and to excel spreadsheets we used the python pandas for running nmf on our data we chose to use nimfa an open source python library this library best fit our needs because it offered a variety of nmf versions including versions having the convergence guarantees summarized in section numerous factor initialization methods and factorization quality sures for most of our data manipulation needs including linear algebra for matrix operations we used the scipy stack of open source python modules for scientific to factor our collation data in nimfa we used the lsnmf method an implementation of the alternating least squares formulation of nmf proposed by lin we ran this with values of k ranging from to and a maximum iteration limit of we used a single run in each case seeding it with nndsvd initialization a non random initialization method that has been empirically shown to result in faster lower error factorizations we found that single runs ized in this way matched the objective function values for hundreds to thousands of runs with random initialization and in fact tended to give sparser factors this implementation of nmf was run separately on a platform with an intel quad core processor and gb of memory which we will denote and a platform with an intel duo dual core processor and gb of memory which we course the more contaminated the scribal tradition is the more exceptions one can expect to see in the apparatus but even then the level of compression achieved for the average reading may still outweigh the number of exceptions mccollum and brown will denote the differences in performance between the two platforms will be detailed in the following sections results uniform weighted results table gives summary statistics for the weight nmf runs and results for in general nmf obtained tions that explained much of the variance in the observed data and it did so in a very short time table summary statistics for uniform weight nmf results here gives the number of iterations before convergence and give the running time in seconds on both platforms dist gives the value of the objective function from tion evar gives the explained variance as a proportion between and and and give sparseness measures tween and according to hoyer s formula k dist evar we will now examine the results for k in detail table lists the mixture coefficients for consistently cited witnesses in the apparatus for jude note that the coefficients have not been normalized we have left them as is in order to preserve their absolute magnitude which we can interpret as a confidence score for classification if we were to divide each coefficient in a given row by the row wise sum we could interpret the scaled coefficients as mixture proportions under such normalization ms would be interpreted as cluster cluster cluster and cluster in order to determine the textual groups represented by the clusters it is structive to look at their most representative witnesses tables list the top mss in each cluster for the purposes of profiling secondary witnesses we will also want to know the most important readings in each cluster tables list these readings in order of their coefficients the group behind cluster is perhaps the easiest to identify this cluster sents the alexandrian texttype perhaps not surprisingly one of its best tatives is b with papyrus being another leading member the remaining top representatives include a handful of s consistently cited witnesses cials a and c also fall under this cluster but as table shows they all have strong enough elements of mixture with other clusters that they do not make it to the top of the cluster s list the cluster contains mss in total cluster appears to be a mixture of two textual families identified in and the former group ing literature has also been identified in peter and in the catholic epistles it shares important readings with the old georgian versions its namesake is a consistently cited witness in one of s scribes claimed to have copied it from an ancient codex and scholars conjecture that its exemplar dates back at least biclustering readings and manuscripts to the fourth or fifth century further evidence for the family s antiquity has been found in its close similarity to the text used by origen the connection with origen has led some to posit that represents the controversial caesarean texttype in the catholic epistles the latter group has also been identified in peter and in james peter and john its core members have been shown to have a connection to the harklean syriac so and both attest to early forms of several of the catholic epistles and the same situation likely holds in jude as well the cluster is small at mss but the witnesses are generally cohesive the fact that their readings overlap enough for their mss to be grouped together also suggests that and are closely related to each other in most variation units cluster as its witnesses make clear represents the group of lectionaries the existence of a distinct lectionary textual group has been recognized for some time but a thorough examination of this group in the catholic epistles was long delayed the first and perhaps most extensive work in this area was done by junack junack s work confirmed the existence of a large and cohesive textual family among the byzantine lectionaries at least in the context of the epistle of jude our results based on wasserman s complete collation should give additional weight to these findings our results also agree with junack s identification of as an exceptionally non byzantine lectionary in fact table lists it as a strong representative of the alexandrian texttype the cluster does not consist exclusively of lectionaries as it contains mss total but the non lectionary mss are lower on the list due to mixture cluster clearly represents the byzantine subgroup kr also known as as can be seen from the overlap between table and the list of collated mss for john jude in this cluster is by far the largest with mss assigned to it and it exhibits great cohesion among its purest representatives to its disadvantage however it contains no witnesses dating earlier than the tenth century cluster appears to represent another byzantine subgroup but it is unclear if it corresponds to any previously known subgroup while not as massive as cluster it is still large with mss perhaps the most noticeable quality is that it appears to be the earliest byzantine subgroup it contains the following five ninth century mss k and cluster undoubtedly represents the textual family its earliest witness is the tenth century ms but this same ms is also a cited witness in see table this group was independently identified in the catholic epistles through stemmatic methods by spencer wachtel and howe who noted that it contains states of text that are thought to be important for the formation of the byzantine text the family is of moderate size containing mss cluster also looks byzantine but like cluster its precise identity is unclear like cluster it seems to represent a text earlier than that of cluster its earliest witnesses are dated to the tenth century but two prominent representatives of the group are uncials and and both of these possess alexandrian elements quantifiable as cluster mixture proportions of and respectively the cluster is of moderate size consisting of mss cluster appears to be von soden s kc byzantine subgroup as can be seen from the presence of the following kc mss in the cluster von soden s and the cluster as established by nmf has no witnesses from earlier than the tenth century and of mccollum and brown its purest representatives the oldest is the eleventh century ms but the group is large enough with members and tight knit enough with generally strong mixture coefficients that its archetype is surely older than the tenth century there are a few observations to make here nmf on a uniform weight collation matrix reveals a number of distinct subgroups not only of the alexandrian texttype in particular the byzantine texttype splits but also of the byzantine texttype into the lectionary group kr kc and two additional groups it should be noted therefore that the byzantine mss do not form a monolithic group in jude clusters and form two more large as yet unknown byzantine families while we might expect one of these clusters to correspond to the larger more general k group the mss traditionally assigned to that group are divided between both clusters it may be the case that the k mss are divided in jude with two thirds of the family siding with the oldest mss in the group and one third taking the other side a cross reference from tables to wasserman s apparatus reveals that nmf in the uniform weight setting tends to assign higher basis coefficients to common widely divided readings than it does to rarer readings exclusive to groups this is the result of nmf trying to minimize the number of misclassified readings when all readings are all equal in weight to minimize unexplained variance readings are chosen on how cleanly they divide the entire body of mss into their assigned clusters for these reasons an important reading in this setting will likely resent multiple clusters but a given cluster can be uniquely identified by patterns of readings this in essence reflects the methodology of wisse and mcreynolds s original formulation of the claremont profile method while this has the unfortunate side effect of not clustering readings as sparsely as we might like it is useful for certain purposes in particular it allows us to identify widely split variant units which may represent early divisions in the scribal tradition and to determine where different families side in these splits table gives a short list of widely divided readings and their support among uniform weight nmf groups table uniform weight nmf cluster support for highly divided readings cluster wide support is determined not by manuscript count but by basis coefficient with a reading resp group of ings being considered representative if its coefficient resp sum of coefficients is a least twice the value of every alternative s cient resp sum of coefficients in that variation unit the readings are primarily split between and in and in and in and in and in and and in alex split om om split om split om split split kr kc lect split om om om om om split biclustering readings and manuscripts as an example the robinson pierpont greek nt lists and as divided byzantine readings and opts for and respectively as the original readings while the cluster is split in both cases and offers no strong evidence either way has the support of alex and kc and has the support of and kc the external evidence shows earlier and more diverse testimony in favor of with the same situation to a lesser degree in favor of valuing diversity of testimony we therefore agree with robinson and pierpont s textual decisions on the divided readings in jude the results of nmf may also reveal readings that have not yet been recognized as divided byzantine readings and are two of course in other applications we would want to identify readings that are individually more exclusive to their groups in these cases we view less common readings as more valuable a thus to get sparser results we must turn to nmf in the idf weight setting idf weighted results table gives summary statistics for the idf weight nmf runs and results for because idf weighting assigns greater importance to less common readings nmf tends to find more exclusive bases for clusters in this setting another positive effect of idf weighting is that it allows nmf to isolate more distinctive clusters often due to differences that weight nmf overlooks a disadvantage as can be seen in table is that when the factorization sets aside especially rare readings for the sake of more common cohesive ones the high weight of the ignored readings reduces the explained variance of the for all k an nmf run in this setting took at most a couple seconds on both platforms table summary statistics for idf weight nmf results here gives the number of iterations before convergence and give the running time in seconds on both platforms dist gives the value of the objective function from equation evar gives the explained variance as a proportion between and and and give sparseness measures between and according to hoyer s formula k dist evar we will now examine the results for k in detail table lists the mixture coefficients for consistently cited in the apparatus for jude as in the would not consider the agreement of kr and lect to be especially diverse as they both are closely related to the byzantine texttype the only non byzantine support comes from for and for the cluster s support there is essentially split between and this relationship may be worth closer study in the future these locations robinson pierpont gives only the readings and respectively if we were to account for the readings of the other k groups here we would include the readings and respectively in the margin subsection for more details on the problem and how to address it mccollum and brown uniform weight case no normalization has been applied to the coefficients tables list the most representative mss in each cluster and tables list the most representative readings for each cluster cluster clearly represents we also note that now the cluster contains no representatives from and for this reason it now consists of only mss an important observation in table is that uncial c has its highest mixture coefficient in this cluster which suggests that it shares many characteristic readings or at least some high weight characteristic readings with the first few can be found in table and are the following and cluster appears to represent the majority of the byzantine texttype as mss are members of it the group appears to be cohesive enough not to be split up when k but its mixture coefficients are also the lowest of any cluster by far which suggests that there is variance among the members of the cluster this likely arises in splits between byzantine subgroups at common readings in the idf setting these readings will have low enough weight not to split the cluster but their total weight will suffice to produce noticeable variance within the group ertheless the characteristic readings of the cluster have strong coefficients which indicates that uniquely byzantine readings are shared even by the texttype s ferent subgroups cluster represents the group is small consisting of only mss but this is the result of its being split apart from uncial while not a member of this cluster still shares some significant readings with it these readings include and cluster contains the alexandrian witnesses the cluster which consists of mss is slightly smaller than its counterpart in the uniform weight setting due to more exclusive readings being assigned prominent places in the cluster basis the order of the most representative witnesses has shifted somewhat notably uncial a and are considered slightly more alexandrian than b in the idf setting a glance at table will reveal that is relatively pure in its mixture coefficients while and all have at least some mixture with cluster we will revisit this in a moment cluster represents the group consists of mss here which is a bit smaller than it was from uniform weight nmf like the other clusters its readings should now be more exclusive to the group little else has changed cluster is obviously the lectionary group it now consists of mss which means that it may have borrowed some mss placed elsewhere in the uniform weight clusters its readings are now more exclusive to the group but little is different otherwise cluster is a curious group consisting of only mss most of its members were lumped under the alexandrian cluster in the uniform weight setting so it appears to have some relationship with the alexandrian text the top two mss and demonstrate a high level of agreement in both the catholic and pauline epistles in the catholics they and a few other members of this cluster and read in john in corinthians and attest to an infamous variant that places at the end of the chapter with the only other greek ms support coming from western witnesses their support for that reading has led to much debate over whether or not they have a common source in a localized western text and whether or not they support the theory that corinthians is an interpolation despite the rarity of some of its other readings the cluster s characteristic readings are shared by the alexandrian uncials and and which suggests that the biclustering readings and manuscripts cluster preserves some ancient readings as the cluster itself does not appear to have been identified in the literature we will designate it by here cluster is another unusual group made up of mss most of its members were mixtures of multiple byzantine subgroups in the uniform weight setting so it appears to represent a small and distinct branch of the byzantine texttype its top representatives mss and are strong pure representatives of the family some of the mss themselves are noteworthy scrivener describes as valuable but with many errors he finds a similar text in and considers this ms an important copy apart from this the cluster itself does not seem to have received much study lacking an existing name for it we will designate it in this paper we observe one other connection between these mss outside the catholic epistles in the letter to the romans there many of the family mss contain the subscription in jude one of the group s most characteristic readings is shared by which may indicate ancient roots for the reading and possibly for the family on further examination however this is the only significant group reading that supports apart from the much lower weight reading in so the agreement is more likely in this case the best explanation for the agreement is that the reading arose independently in and we will make some observations to conclude this section while nmf in the uniform weight setting succeeds at accounting for variance by giving more priority to common widely divisive readings nmf in the idf setting does better at locating readings more exclusive to specific clusters this in turn allows it to identify sparser reading bases and smaller ms groups for an illustration of this difference please refer to table which gives a short list of widely divided readings and their support among idf weighted nmf groups compare this to table notice how splits among the groups formed tend to be more common for widely divided readings in the idf setting while more distinctive group readings are identified in units with many readings such as in general the re weighting of the observed data results in different clusters with sharper separation while both weighting schemes isolate alexandrian and lectionary clusters idf weighted nmf compresses all previous subgroups of k into a single cluster separates and appropriately and identifies small subgroups of the alexandrian and byzantine texttypes with unique readings for the purposes of identifying the most significant variation units and witnesses to provide more refined and manageable inputs to cbgm or other more complex methods this setting seems to be the most suitable the mss with the romans subscription include which includes the subscription but reorders many words and includes a reference to tertius which omits which changes the begining to and omits and which appears to omit unit concerns the inclusion or omission of the article and all but a few witnesses including most of include the article so this is probably an instance of independent errors producing agreement evidence for coincidental agreement is that wasserman lists as having a defective text reading here with a corrector s hand supplying not the reading of but the reading shared by the majority of mss besides this in the other high ranking variation units of either shares the majority reading or has a unique reading whose derivation from the reading would be difficult to explain in and in other units alternatively adds to omits from or transposes the reading leaving us no indication that the scribe of deviated from the text in any consistent way mccollum and brown table idf weight nmf cluster support for highly divided readings cluster wide support is determined as in table and the readings are split as they are in table alex split split split split lect byz split split split om om split split split om om split om split om om split om split om om om om summary and conclusions in this paper we have shown how non negative matrix factorization or nmf can effectively classify mss and readings on texttype based principles while as a pre genealogical method it can not make inferences regarding prior and rior textual relationships it can be used to facilitate more complex genealogical methods by providing better selections of readings and witnesses for input we have demonstrated the suitability of nmf for these tasks on both theoretical and empirical grounds on the theoretical side nmf is able to cluster both readings and mss by ing the best approximate factorization of the collation matrix by alternatively optimizing the basis and coefficient factor matrices it keeps the problem of dependence between readings and mss under control since for certain nmf update rules this process can be proven to stop only when the objective function of the factorization reaches a critical point we have a theoretical guarantee that co dependence wo nt cause an endless loop or result in arbitrarily bad clusters ditionally nmf provides an easy to interpret model that allows us to determine reading profiles for clusters and account for mixture between different clusters in mss on the practical side nmf provides fast human recognizable results for ces in various weighted settings nmf is able to factor a complete collation matrix of jude for mss in less than minutes in the uniform weight setting and in a matter of seconds in the idf setting as we have indicated the uniform weight ting provides good group classifications over widely divided variation units while the idf weight setting highlights the most distinctive readings of textual families using nmf on wasserman s collation of jude we were able to classify many previously unclassified mss and verify several existing group classifications in the uniform weight setting we identified a distinct textual family for lectionaries in jude we found further empirical justification for von soden s kr and kc groups in addition to a subdivision of his k group and we both verified the choices for the textual and marginal readings of jude in and proposed additional marginal readings based on the readings of the identified byzantine subgroups meanwhile in the idf setting we isolated characteristic mss and readings for well known groups including the alexandrian texttype the byzantine texttype the lectionaries and we found two other groups which we identified as and and we demonstrated that both and have family ties outside of the catholic epistles suggesting that the classification made by nmf is legitimate we feel that nmf has tremendous potential as a tool for automatic vised texttype based textual criticism and we wish to see it implemented in further studies as we have attempted to show its results can be fruitful in a multitude references of applications from organizing known collation data to performing exploratory analysis on what is yet unknown we hope to find the new textual groupings and ms classifications done with nmf examined further and perhaps used as starting points for new research on the complex text of the epistle of jude it certainly deserves our greatest effort references brooke foss westcott and fenton john anthony hort the new testament in the original greek vol cambridge macmillan and company url eldon jay epp textual clusters their past and future in new testament textual criticism in the text of the new testament in contemporary search essays on the status quaestionis ed by bart ehrman and michael holmes second vol new testament tools studies and documents leiden brill pp isbn ernest cadman colwell genealogical method its achievements and its limitations in journal of biblical literature pp issn doi gordon fee the text of john in origen and cyril of alexandria a tribution to methodology in the recovery and analysis of patristic citations in biblica pp issn bart ehrman the use of group profiles for the classification of new testament documentary evidence in journal of biblical literature pp issn doi klaus wachtel towards a redefinition of external criteria the role of coherence in assessing the origin of variants in textual variation logical and social tendencies ed by houghton and david parker vol texts and studies piscataway nj gorgias press pp isbn tommy wasserman the epistle of jude its text and transmission vol coniectanea biblica new testament stockholm almqvist and wiksell ternational isbn ernest cadman colwell method in locating a newly discovered script in studies in methodology in textual criticism of the new testament vol new testament tools and studies leiden brill pp thorpe multivariate statistical analysis for manuscript tion in tc a journal of biblical textual criticism issn url timothy finney mapping textual space in tc a journal of biblical textual criticism issn url org tc mapping paul robert mcreynolds the claremont profile method and the grouping of byzantine new testament manuscripts phd thesis claremont graduate school url www cspmt org pdf mcreynolds frederik wisse the profile method for the classification and evaluation of manuscript evidence as applied to the continuous greek text of the gospel of luke vol studies and documents grand rapids mi wm eerdmans publishing isbn references clinton baldwin factor analysis a new method for classifying new testament greek manuscripts in andrews university seminary studies pp url kenneth keumsang yoo the classification of the greek manuscripts of peter with special emphasis on methodology phd thesis seventh day adventist theological seminary andrews university url clinton baldwin the so called mixed text an examination of the alexandrian and non byzantine text type in the catholic epistles phd thesis seventh day adventist theological seminary andrews university url matthew spencer klaus wachtel and christopher howe the greek lage of the syra harclensis a comparative study on method in exploring textual genealogy in tc a journal of biblical textual criticism issn url rosetta reltech org tc matthew spencer klaus wachtel and christopher howe representing multiple pathways of textual flow in the greek manuscripts of the letter of james using reduced median networks in computers and the humanities pp gerd mink problems of a highly contaminated tradition the new ment stemmata of variants as a source of a genealogy for witnesses in studies in stemmatology ed by pieter van reenen august den hollander and margot van mulken vol amsterdam john benjamins publishing pp isbn klaus wachtel the coherence method and history in tc a journal of biblical textual criticism issn url larry richards a critique of a new testament text critical ology the claremont profile method in journal of biblical literature pp issn doi houghton recent developments in new testament textual icism in early christianity pp doi url pure oai bham ac uk ws files tommy wasserman the coherence based genealogical method as a tool for explaining textual changes in the greek new testament in novum tamentum pp issn doi daniel lee and sebastian seung learning the parts of objects by non negative matrix factorization in nature pp issn suvrit sra and inderjit dhillon nonnegative matrix approximation gorithms and applications tech rep department of computer science university of texas at austin url wei xu xin liu and yihong gong document clustering based on negative matrix factorization in proceedings of the annual tional acm sigir conference on research and development in tion retrieval sigir new york ny acm pp isbn doi references karthik devarajan nonnegative matrix factorization an analytical and interpretive tool in computational biology in plos computational biology pp doi journal pcbi url journals org ploscompbiol article i d journal eric frichot al fast and efficient estimation of individual ancestry efficients in genetics pp genetics url chih jen lin projected gradient methods for nonnegative matrix ization in neural computation pp url viewdoc grippo and sciandrone on the convergence of the block nonlinear gauss seidel method under convex constraints in operations research letters pp larry richards the classification of the greek manuscripts of the hannine epistles missoula mt scholars press isbn karen sprk jones a statistical interpretation of term specificity and its application in retrieval in journal of documentation pp issn url stephen robertson understanding inverse document frequency on oretical arguments for idf in journal of documentation pp issn url viewdoc marinka itnik and bla zupan nimfa a python library for ative matrix factorization in journal of machine learning research pp issn url citeseerx ist edu viewdoc christos boutsidis and efstratios gallopoulos svd based initialization a head start for nonnegative matrix factorization in pattern recognition pp issn url patrik hoyer non negative matrix factorization with sparseness straints in journal of machine learning research ed by peter dayan pp issn url edu viewdoc barbara aland et al eds nestle aland novum testamentum graece eighth stuttgart deutsche bibelgesellschaft isbn robert waltz the encyclopedia of new testament textual criticism url terry dwain robertson relationships among the non byzantine manuscripts of peter in andrews university seminary studies pp url christian amphoux and dom outtier les leons des versions ennes de jacques in biblica pp issn kim codices and origen in journal of biblical ature pp issn christian amphoux la parent textuelle du syh du groupe dans lptre de jacques in biblica pp issn references barbara aland and andreas juckel das neue testament in syrischer lieferung vol berlin walter de gruyter isbn ernest cadman colwell is there a lectionary text of the gospels in harvard theological review pp issn doi klaus junack zu den griechischen lektionaren und ihrer berlieferung der katholischen briefe in die alten bersetzungen neuen testaments die kirchenvterzitate und lektionare der gegenwrtige stand ihrer erforschung und ihre bedeutung fr die griechische textgeschichte ed by matthew black and kurt aland vol arbeiten zur neutestamentlichen textforschung berlin walter de gruyter pp isbn wilbur pickering the greek new testament according to family second wilbur pickering isbn url www hermann freiherr von soden die schriften des neuen testaments in ihrer ltesten erreichbaren textgestalt hergestellt auf grund ihrer textgeschichte vol gttingen vandenhoeck und und ruprecht url maurice robinson and william pierpont eds the new testament in the original greek byzantine textform southborough ma chilton book publishing isbn url www cspmt org pdf rp curt niccum the voice of the manuscripts on the silence of women the external evidence for cor in new testament studies pp issn philip payne ms as evidence for a text without cor in new testament studies pp issn jennifer shack a text without corinthians not according to the manuscript evidence in journal of greco roman christianity and judaism pp url jgrchj net visited on frederick henry ambrose scrivener a plain introduction to the criticism of the new testament for the use of biblical students ed by edward miller fourth vol london george bell sons url org pdf appendix classification of lacunose mss in section we explained that in the process of data selection we regarded the texts of correctors and witnesses with fewer than readings as non continuous and therefore secondary table lists the mss from wasserman s collation that were too lacunose to be included because of their age most papyri and uncials are so lacunose that they must be excluded in this way this leaves us with an unfortunate situation in which we have nothing to say about the mss in which we are most interested fortunately we are not without a remedy once nmf on the primary set of continuous text witnesses has produced a basis matrix w for cluster readings we can use this matrix to classify the secondary witnesses by whatever readings they do have if we take x to be a vector representing the readings of a single secondary witness that we want to classify then the solution h to the least squares equation arg min jjx f references table mss with fewer than readings excluded from the primary nmf run will contain the mixture coefficients for the witness represented by x because the entries of h are required to be non negative we can interepret h as we interpreted the mixture matrix h for the primary witnesses to solve equation we used scipy s method for each ms in table individually in both the uniform weight case and the idf weight case for the sake of space we will not list the mixture coefficients of all mss but we will list the results for ms and the consistently cited witnesses and these results can be found in tables and table uniform weight mixture coefficients for selected ondary mss table idf weight mixture coefficients for selected secondary mss as table shows and are too lacunose to be classified with much dence in the uniform weight case uncial p fares slightly better exhibiting a moderate alexandrian element and weaker lectionary and kr elements mss and on the other hand clearly belong to the cluster the situation is not too different in the idf weighted setting as table shows as in the uniform weight case s extant readings do not commend it to any cluster the situation is nearly the same for it has a slightly higher mixture coefficient for the cluster because it shares the group reading at but it is otherwise too lacunose for us to determine any closer relationship uncial like is inconclusive ms shares characteristic readings of both and the alexandrian cluster finally as we would expect ms clearly belongs to the family bearing its name references appendix nmf results table consistently cited mss uniform weight mixture coefficients for references table uniform weight cluster mss sorted by table uniform weight cluster mss sorted by table uniform weight cluster mss sorted by table uniform weight cluster mss sorted by ms ms ms ms references table uniform weight cluster mss sorted by table uniform weight cluster mss sorted by table uniform weight cluster mss sorted by table uniform weight cluster mss sorted by ms ms ms ms references table uniform weight cluster readings sorted by table uniform weight cluster readings sorted by reading reading reading reading table uniform weight cluster readings sorted by table uniform weight cluster readings sorted by references table uniform weight cluster readings sorted by table uniform weight cluster readings sorted by reading reading reading reading table uniform weight cluster readings sorted by table uniform weight cluster readings sorted by references table idf weight mixture coefficients for cited mss references table idf weight mss sorted by cluster table idf weight mss sorted by cluster table idf weight mss sorted by cluster table idf weight mss sorted by cluster ms ms ms ms references table idf weight mss sorted by cluster table idf weight mss sorted by cluster table idf weight mss sorted by cluster table idf weight mss sorted by cluster ms ms ms ms references table idf weight readings sorted by cluster table idf weight readings sorted by cluster reading reading reading reading table idf weight readings sorted by cluster table idf weight readings sorted by cluster references table idf weight readings sorted by cluster table idf weight readings sorted by cluster reading reading reading reading table idf weight readings sorted by cluster table idf weight readings sorted by cluster
