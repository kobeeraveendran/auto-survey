jadt journes internationales danalyse statistique donnes textuelles condenss de textes par des mthodes numriques juan manuel patricia velzquez jean guy cole polytechnique dgi cp succ centre ville montral canada ermetis univ du qubec boul luniversit chicoutimi canada lanci univ du qubec cp succ centre ville montral canada abstract information electronic form standard variety quantity information increasingly large methods summarizing automatic condensation texts critical phase analysis texts article describes cortex system based numerical methods allows obtaining condensation text independent topic length text structure system enables nd abstracts french spanish short times rsum tant donn que la varit quantit linformation sous forme lectronique deviennent plus en plus grandes mthodes dobtention rsums ou de condensation automatique textes constituent une phase critique textes cet article dcrit cortex un systme bas sur mthodes numriques qui permet lobtention dun condens dun texte indpendant thme lampleur du texte faon nt il crit la structure du systme lui permet la condensation textes multilangues dans des temps trs courts des applications en franais ou espagnol sont prsentes et analyses keywords condenss textes rsums automatiques analyse textes catgorisation mthodes statistiques introduction linformation textuelle lectronique saccumule trs grande quantit alors documents sont catgoriss dune faon trs sommaire le manque standards critique tous analyses textes dpistage exploration rcupration rsums sont taches extrmement difciles torres moreno et al cest pourquoi mthodes dobtention rsums automatique textes constituent une phase cruciale textes les mthodes linguistiques sont pertinentes dans ces tches mais leur utilisation crte demeure encore difcile en raison plusieurs facteurs comme lampleur dynamique ou limite domaines restreints saggion lapalme dun autre ct mthodes statistique neuronales sont plus en plus utilises dans plusieurs domaines traitement linformation textuelle salton salton mcgill deerwester et al leloup veronis et al balpe et al torres moreno et al mi et al meunier nault memmi meunier cet article prsente un tude sur lapproche vectorielle textes salton mcgill pour obtenir denss pertinents de documents la forme la plus connue et la plus visible condensation textes rsum reprsentation abrge et exacte du contenu dun document ansi tant donn que lart ne permet dobtenir que rsums informatifs morris et al nos recherches porteront sur lobtention ce type de condenss nous allons ter un algorithme rcemment dvelopp il sagit dune chane de traitement numrique qui jadt journes internationales danalyse statistique donnes textuelles combine plusieurs traitements statistiques informationnels comme calculs dentropie poids frquentiel segments mots plusieurs mesures dhamming parmi dautres avec un algorithme optimal dcision pour phrases pertinents texte lensemble ces phrases rendent ce quon appelle document pr traitement dans lapproche vectorielle traite textes dans leur ensemble en passant par une tation numrique trs diffrente dune analyse structurale linguistique mais qui permet traitements performants memmi consiste reprsenter les textes dans un espace appropri et appliquer traitements vectoriels la chane conterm seffah nier comporte un ensemble processus ltrage segmentation et lemmatisation par opposition lanalyse symbolique classique ces processus sont trs performants et peuvent tre appliqus gros corpus nous avons adapt les processus de conterm nos besoins ainsi un module pre traitement t dvelopp gravel et al le original comporte nm mots mots fonctionnels noms ou verbes chis composs emploie la notion de pour designer un mot plus abstrait memmi pour rduire complexit processus ltrage du lexique sont la lemmatisation verbes langues morphologie variable langues romances savre trs important pour rduction lexique consiste trouver la racine verbes chis et ramener au singulier culin ce processus permet diminuer la maldiction dimensionnelle qui pose srieux problmes dans grandes dimensions nous explorons aussi dautres voies pour rduction du lexique en processus synonimisation tionnaires la segmentation faite en sparateurs un indice reprage importante dinformation titre dun document toutefois nous expriences ont t ralises sur textes bruts donc titres sous titres et sections ne sont pas plicitement comme cas formats html ou xml aprs pr traitement nouveau texte comporte p segments avec nf termes totaux condensation du texte la segmentation transforme un document dans un ensemble vecteurs nm chaque segment est reprsent par un vecteur composantes binaires la dimension nm nombre total mots diffrents lensemble segments nt dispose consiste en p vecteurs matrice p reprsente texte seulement les termes frquence suprieure ont t utiliss torres moreno et al donc un lexique nl termes est obtenu la relation nl nf nm nous avons donc dni nl nm suppression mots fonctionnels haute et trs basse frquence dapparition suivi par la suppression entre parenthses chiffres symboles pourra ramener mme forme chanter mots chantaient chant chanteront et eventuellement chante chanteur critre segments taille xe t cart car cherchait lextraction phrases compltes jadt journes internationales danalyse statistique donnes textuelles comme ratio rduction lexique ltr lemmatis la matrice terme segment p drive de reprsente lexique rduit texte p p p nl nl nl p nl ou labsence dans cette matrice chaque composante montre la prsence mot dans un segment de faon analogue matrice frquentielle du p o chaque composante nl contient frquence du terme dans un ment cette matrice contient linformation frquentielle essentielle texte la condensation texte sur ces deux matrices qui constituent lespace au systme nous avons dni la rduite matrices comme p nl proportion p de segments par rapport la dimension nl du lexique rduit lentre les segments possdent une quantit htrogne du lexique employ il y segments plus importants que dautres qui seront extraits par lalgorithme pour obtenir un condens algorithme mtriques la mthode cortex de rsums automatiques est compose deux algorithmes une mthode construction mtriques informationnelles indpendantes combine avec un algorithme pour la rcupration linformation code ce dernier prendra une dcision sur les segments en fonction dune stratgie votes des informations mathmatiques et statistiques importantes sont calcules partir matrices et sous forme mtriques elles mesurent la quantit dinformation contenue dans chaque segment plus importante plus il comporte valeurs levs mesures frequentielles frquence mots la somme frquences mots par segment calcule un poids spcique dun segment utilisant lexpression frquence du mot dans segment lexpression f nl t p nl jadt journes internationales danalyse statistique donnes textuelles corresponde lexique frquentiel contenue nous introduisons ici la quantit dnie comme ratio rduction du lexique frquentiel interaction de segments dans chaque segment un mot qui prsent au mme temps dans un ou plusieurs autres segments dit qui interaction la somme toutes les interactions chaque segment constitue alors linteraction entre segments nous la comptabilisons la faon suivante t nm nl p j j pi t p pi nl nl e x x x nl somme frquentielle probabilits calculons dabord soit pi probabilit dapparition du terme dans texte la somme probabilits calcul mesures entropiques lentropie dun segment nous la calculons en utilisant avec mesures dhamming une distance de minskowski t utilise comme base les distances dhamming cette quantit la distance entre paires et j dans lespace des segments chaque mot tant reprsente par un vecteur binaire il faut dabord calculer la matrice dhamming h qui une matrice diagonale suprieure dimension n ensuite calcule somme distances dhamming h j autrement j nl nl h j si j j le poids dhamming des segments chaque segment possde un poids qui gal la somme termes prsentes dans le segment cest dire dans chaque matrice nl jadt journes internationales danalyse statistique donnes textuelles la somme poids dhamming de la mme manire peut mesurer poids spcique sur chaque colonne matrice p ce qui donne un poids dhamming ensuite calcule somme poids dhamming par segments nl p nl mesures mixtes des mesures de distances combins avec mesures frequentielles ont t aussi considrs le poids dhamming lourd obtenu la multiplication du poids dhamming du segment par poids dhamming shm somme poids dhamming par frquence ceci corresponde somme poids dhamming mots existantes dans chaque segment pli par frquence correspondante hm nl algorithme de dcision nous avons dvelopp un algorithme pour rcuprer linformation code par les mtriques est simple tant les votes pour un vnement particulier qui provient dun semble de k votants indpendants chaquun avec une certaine probabilit davoir raison trouver la dcision optimale la mthode que nous avons dveloppe sappelle algorithme de dcision ad torres moreno et al lalgorithme dcision utilise probabilits ment exclusives et prsente les k votants en modiant et en fonction sorties j k sur chaque segment toutes les valeurs mtriques ont t normalises avant dtre utilises dans lad cet algorithme de dcision possde deux proprits intressantes convergence et amplication expriences et rsultats nous avons test notre algorithme articles de vulgarisation scientique les textes extraits presse sur internet sont petite taille lobjectif t dobtenir un condens du du nombre segments nous avons compar avec logiciels minds arizer c et avec word c dans les cas de minds et word paramtre utilis t dobtenir une synthse du taille texte nous avons aussi demand personnes un la main choisir phrases du qui sembleraient plus pertinentes probabilits et sont modies en tout temps de faon mutuellement exclusive lcart entre de lamliorer ampli car un et chang toujours avec une probabilit segment pertinent j meilleur votant branch ce moment nmsu edu minds summarizerdemomain html copernic com les sujets ont un niveau dtudes universitaire habitus rsums jadt journes internationales danalyse statistique donnes textuelles n o s c d n o s c d segment segment b figure choix desegments pertinents pour letexte cortex lessegments choisis humains textes en franais nous avons tudi puces articiellement ambigu et compos dun mlange non homogne textes sujets puces biologiques et puces informatiques dans classication de segments par leur contenu torres moreno et al les segments plus importantes slectionns par les humains sont le et gure nous reproduisons sur gure nos rsultats o voit que les segments importants ont t bien reprs cortex montre un rsum quilibr du mme que celui obtenu par minds mme si ce dernier ne trouve ni segment ni le sur gure par contre rsultats de word sont biaiss et peu pertinents comme voit sur gure torres moreno et al pour ftes les rsultats prliminaires montrent que cortex trouve rsums acceptables gure nous avons effectu comparaisons avec summarizer huot nos condenss sont comparables voire meilleure qualit dans dautres tests condenss trouvs par cortex semblent tre assez cohrentes nous avons constat toujours que les condenss obtenus par sujets humains dpendent personne et ses capacits dabstraction ce qui donne fois rsultats assez carts gure et gure malgr cela choix fait par humains semble tre une rfrence sur les segments importants mais notre mthode comparable textes en espagnol nous avons travaill sur deux textes en espagnol nopal et tabaco les rsultats de cortex sur nopal sont montrs sur gures et constate la bonne qualit du condens mme dans textes trs petit lexique nopal possde seulement nl mots p segments et word est incapable traiter gegi polymtl info jmtomore pvm cortex textos puces html quebecmicro html invdes com mx suplemento anteriores htm espina html invdes com mx suplemento anteriores htm tabaco html jadt journes internationales danalyse statistique donnes textuelles segment segment b figure choix de segments pour puces par systme minds et b par synthtiseur word n o s c d n o s c d n o s c d n o s c d segment segment b figure choix de segments pertinents pour ftes par systme cortex plusieurs segmentsimportants onttchoisis humains jadt journes internationales danalyse statistique donnes textuelles n o s c d n o s c d segment segment b figure choix de segments pour nopal fait par cortex les segments et qui ont une importance particulire onttbienreprs humains discussion taille du lexique nous savions que grce au processus pre traitement lexique tait plus en plus rduit cest dire nl nf nm des tudes sur ratios de rduction moyens du lexique ont t effectus sur lensemble de textes franais et espagnol ceci nous permis dtablir exprimentalement estimateurs l et pour lexique ltr lemmatis rduit l lexique frquentiel respectivement si nous introduisons nm nm nf nl nli t ti alors f l nm t nm nl nm nous avons calcul pour textes en franais f l et sur gures et nous montrons les valeurs de ces ratios et leurs moyennes sur lensemble textes en franais la rduction taille lexique tr lemmatis l suit un comportement linaire par rapport au nombre original donc pour obtenir un condens dun texte avec nos mthodes utilise seulement un seizime volume termes totaux du document toutes ces rductions permettent diminuer maldiction dimensionnelle finalement sur gure montre une courbe qui modle comportement du lexique essentiel nl en fonction originale nm de faon similaire nous avons calcul rduction du lexique pour deux textes en espagnol nous avons constat un comportement semblable textes en franais jadt journes internationales danalyse statistique donnes textuelles o t r f l p nl s e e n n e y o m f l figure textes franais ratios de rduction lexique fonction de f rduction aprs ltrage lemmatisation l rduction lexiquefrequentiel lafractionde par rapport au texte original moyennes ratios de rduction lexique franais calculs sur lensemble de textes l ln e n e s s e e u q e l taille du figure lexique essentiel nl comme fonction taille nm laxe horizontale rithmique onobserve unecroissance parcimonieuse dulexique essentiel jadt journes internationales danalyse statistique donnes textuelles e y t t r c s e e n n e y o m f e mtrique figure moyenne dupouvoir dediscrimination desmtriques ordre prsentation mtriques un tude montr prsentation mtriques un certain impact sur mances de lad initialement prsentation mtriques t arbitraire puis un tude statistique t effectu leur pouvoir discriminatoire t mesur comme fonction types mtriques par rapport chaque segment en effet il y mtriques que sont plus discriminantes que dautres la distances dhamming entre mots lintrieur dun segment est trs discriminante par contre les mtriques calculs dentropie ou dune valeur frquentielle semblent ltre moins la gure montre les moyennes discriminatoire mtriques prsentation t les distances dhamming les poids dhamming lourd le poids dhamming segments la somme probabilits par frquence les interactions la somme poids dhamming la frquence f lentropie e et la somme poids dhamming nous avons dcid donc dutiliser cette ordre prsentation mtriques lalgorithme dcision ce qui permet dobtenir un segments pertinents stable et cohrent ordre prsentation segments nos expriences ont montr prsentation segments na aucune inuence sur choix nal lalgorithme de dcision nous avons dcoup textes en segments et nous les avons mlang au hasard pour obtenir un nouveau texte ce texte t prsent nouveau cortex et mmes rsultats ont t retrouvs aussi bien en espagnol par contre tests sur minds et word montrent que ces mthodes sont parfois dpendantes prsentation segments en effet la segmentation phrases par sparateur tendance perturber la pertinence ces mthodes mais pas dans notre jadt journes internationales danalyse statistique donnes textuelles conclusion lalgorithme cortex est un condensateur textes trs performant cette technologie permet vastes multi langues franais espagnol sans prparation avec une taine quantit bruit manire dynamique un court lapse de temps de plusieurs tests faits comparaison avec sujets humains ou dautres mthodes de condensation ont montr que notre algorithme capable retrouver les segments plus pertinents taille sujets abords obtient ainsi un rsum balanc car la plupart des thmes sont abords dans le condens nal le logiciel summarizer munique avec demandant concepts retenir dans rsume ceci est une approche intressant qui pourrait tre intgr dans notre algorithme de dcision bas sur votes de mtriques dj robuste convergente amplicateur indpendant prsentation segments nous pensons que lajout dautres mtriques entropie rsiduelle dtection des changements dentropie maximum dentropie et dun identicateur automatique langues pourraient amliorer des condensations remerciements references les auteurs tiennent remercier luniversit du qubec chicoutimi crsng canada pour leur soutien nancier ansi american national standards writing abstracts ansi inc usa balpe j lelu papy f saleh techniques avances pour lhypertexte ditions herms deerwester s dumais d furnas t launder g harshman t indexing latent semantic analysis journal amer soc infor science gravel j martel p harvey l un module pre traitement pour latao rapport de stage huot f copernic summarizer ou la tentation limpossible qubec micro leloup c moteurs dindexation recherche eyrolles memmi d le modle vectoriel pour traitement documents cahiers leibniz paris uqac inpg memmi d gabi k meunier j dynamical knowledge extraction texts art networks proc marseille memmi d meunier j proc competitive networks text mining berlin meunier j nault g approche connexioniste au problme les techniques dintelligence articielle appliques sances terminologiques partir textes aux technologies de linformation pages les cahiers scientiques acfas morris kasper g adams d effects limitations automated text condensing reading comprehension performance advances automatic text summarization pages mit press u s saggion h lapalme g concept identication presentation context technical text summarization automatic summarization workshop pages seattle anlp naacl salton g smart retrieval system experiments un automatic document processing englewood cliffs jadt journes internationales danalyse statistique donnes textuelles salton g mcgill m introduction modern information retrieval mcgraw hill seffah meunier j aladin integrated object oriented environment computer assited text analisys cahiers recherche lanci uqam torres moreno j velazquez morales p meunier j cortex un algorithme pour la condensation automatique textes actes des colloque interdisciplinaire en sciences cognitives arco lyon paraitre torres moreno j velazquez morales p meunier j mars classphres un rseau incrmental pour lapprentissage non supervis appliqu la classication de textes jadt pages lausanne epfl m rajman j chappelier diteurs veronis j ide n harie s large neural networks model semantic relations proc cognitiva symposium madrid
