improved spoken document summarization coverage modeling techniques kuan yu chen shih hung liu berlin chen hsin min wang academia sinica taipei taiwan national taiwan normal university taipei taiwan kychen journey sinica edu tw edu tw abstract extractive summarization aims selecting set indicative sentences source document summary express major theme document general consensus extractive summarization relevance coverage critical issues address existing methods designed model coverage characterized reducing redundancy increasing diversity summary maximal margin relevance mmr cited method takes relevance redundancy account generating summary given document addition mmr dearth research concentrating reducing redundancy increasing diversity spoken document summarization task far aware motivated observations major contributions presented paper contrast mmr considers coverage reducing redundancy propose novel coverage based methods directly increase diversity proposed methods set representative sentences relevant given document cover important sub themes document selected automatically second step forward plug document sentence representation methods proposed framework enhance summarization performance series empirical evaluations demonstrate effectiveness proposed methods index terms spoken document summarization relevance redundancy diversity introduction rapid development internet exponentially growing multimedia content music video broadcast news programs lecture recordings continuously filling daily life overwhelming data inevitably leads information overload problem speech important sources information content virtue spoken document summarization sds efficiently digest browse multimedia content listening associated speech summary extractive sds manages select set indicative sentences spoken document according target summarization ratio concatenate form summary attractive research topic recent years general consensus extractive summarization relevance coverage critical issues realistic scenario existing summarization methods focus determining relevance degree given document sentences result ranked sentences returned methods cover partial themes given document fail interpret picture summarization result diversification devoted covering important aspects sub themes document possible developed methods following line research coverage modeling categorized implicit explicit methods formally implicit method reduces redundancy summary considering sentence similarities explicit method increases diversity summary taking sub themes document consideration maximal margin relevance mmr iteratively selects sentence highest combination similarity score respect given document dissimilarity score respect selected sentences canonical representative implicit methods aside mmr little focus investigating summarization result diversification view propose novel coverage based methods extractive spoken document summarization leveraging methods concise summary automatically generated rendering relevance coverage explore incorporate document sentence proposed framework summarization performance representation methods enhance related work wide spectrum extractive sds methods developed far spreads methods simply based sentence position structure information methods based unsupervised sentence ranking methods based supervised sentence classification category important sentences selected salient parts spoken document introductory concluding parts methods applied specific domains limited document structures unsupervised sentence ranking methods attempt select important sentences based statistical features sentences words sentences human annotation involved popular methods include limited vector space model latent semantic analysis markov random walk mmr sentence significant score method language model based framework lexrank linear submodularity based method sm programming based method ilp statistical features include example term word frequency linguistic score recognition confidence measure prosodic information contrast supervised sentence classification methods gaussian mixture model bayesian classifier support vector machines svm conditional random fields crf usually formulate sentence selection binary classification problem e sentence included integer summary interested readers refer comprehensive reviews new insights major methods developed applied good success wide range text spoken document summarization tasks addition mmr ability reducing redundancy increasing diversity aptly incorporated sm ilp structured svm method sm ilp readily suited large scale problems involve time consuming process important sentence selection hand structured svm method needs set training documents corresponding handcrafted summaries difficult collect manual annotation consuming labor intensive training classifiers summarizers view intended develop unsupervised summarization framework simultaneously relevance coverage account principled effective manner coverage modeling techniques common belief document summarization community relevance coverage key issues generating concise summary idea principled realization progressively selecting important sentences formulated s arg max s ds sdrel sdcov s d denotes given document summarized s set sentences selected s candidate sentences d similarity function determine relevance degree source document sentences denotes coverage function context mmr coverage score candidate sentence computed cov mmr sd s ss s rel s s intuitively mmr iteratively selects sentence relevant document dissimilar selected sentences xdtd method opposed mmr reduces redundancy similarities summary sentences promising direction consider coverage increase diversity summary formally given document d probability sentence s meets gold summary s written p s sd sp d pd s s sdp sp s d affect ranking sentence prior probability sentence assumed identical sentences document omit s eq evaluate sentence reasonable gold summary covers important sub themes document taking themes document consideration obtain sp s d k tptsp s d tk k th sub theme d stands coverage degree sentence s k th sub theme seen relative importance measure sub theme tk gold summary s subject obtained test stage generally agreed concise summary document cover important aspects document consequently coverage score simplified cov xdtd sd s k dtptsp k model explicit document sub theme diversification xdtd short practical implementation computed tsp tsrel rel ts ds estimated similar manner j xdtd method mmr xdtd implicitly explicitly model coverage considering redundancy diversity respectively comprehensive method proposed extension define coverage score cov xdtd sd s sp ss d interprets likelihood observing candidate sentence s selected sentences denoted explicitly considering sub themes inherent given document d likelihood decomposed sp ss d k k sp s tpt s d assuming s s conditionally independent given sub theme obtain sp s t ptsp s t obviously term e model coverage sentence s respect sub theme tk provides novelty measure determine dissatisfaction degree sub theme tk selected sentences assuming sentences s independent given sub theme estimate dissatisfied degree p s t s s method extends concept xdtd jointly taking redundancy diversity consideration refer xdtd analytic comparisons implementation details analytic comparisons aforementioned coverage modeling techniques coverage based methods characterized reducing redundancy increasing diversity mmr belongs category xdtd classified second category j xdtd takes redundancy diversity account simultaneously hand marked difference mmr j xdtd compares sentence selected sentence leverages s estimate dissatisfied degree sub theme sentence selection iteration hand major distinction proposed coverage based methods xdtd determines importance degree sub theme referring document j xdtd considers selected sentences document sum importance degree sub theme dynamically determined sentence selection iteration j xdtd kept fixed sentence selection process xdtd mmr j xdtd select indicative sentences recursive manner xdtd generates summary pass process practical implementation mmr j xdtd slightly slower xdtd xdtd j xdtd roots information retrieval community time xdtd xdtd formally introduced adapted evaluated sds task far aware noticeably sub themes play fundamental role proposed coverage based methods sections reality syntactic semantic sub themes document hard determine pilot study empirical comparison coverage based methods paper treat sentence document sub theme similarity function e involved mmr proposed methods estimated based cosine similarity measure normalize document sentence sub theme representations section unit vectors speed calculation resulting similarity scores range document sentence representations bag words representation bag words bow representation long basis natural language processing related tasks major advantage bow simple intuitive efficient effective bow document sentence represented high dimensional vector dimension specifies occurrence statistics associated index term e word subword n grams document sentence eliminate noisy words e function words promote discriminative words e content words statistics usually estimated term frequency tf weighted inverse document frequency idf distributed representation hand representation learning emerged newly favorite research subject excellent performance far aware relatively studies investigating use extractive text spoken document summarization known methods document sentence embedding include distributed memory dm model distributed bag words dbow model distributed memory model dm model inspired hybridized traditional forward neural network language model nnlm formally based nnlm idea underlying dm model given paragraph predefined number context words jointly contribute prediction word end objective function defined d d j log wwp j nj w d j number paragraphs training corpus d di denotes paragraph length di model acts memory unit remembers missing current context named distributed memory dm model implementation given document sentence document document considered paragraph e di vector representations document sentences obtained maximizing objective function depicted eq distributed bag words model simplified version dm model merely draw paragraph representations predict words paragraphs objective function defined d d j log dwp j simplified model ignores contextual words input layer named distributed bag words dbow model document sentence representations obtained similar manner dm model experimental setup dataset study matbn broadcast news corpus collected academia sinica public television service foundation taiwan november april corpus segmented separate stories transcribed manually story contains speech studio anchor field reporters interviewees subset broadcast news documents compiled november august reserved summarization experiments chose documents test set remaining documents held development set reference summaries generated ranking sentences manual transcript spoken document importance assigning score sentence document reference summaries annotated subjects assessment summarization performance adopted widely rouge metrics experimental results reported obtained calculating f scores rouge metrics summarization ratio set subset hour speech data matbn compiled november december bootstrap acoustic model training minimum phone error rate mpe criterion training data selection scheme vocabulary size thousand words average word error rate automatic transcription experimental results set experiments evaluate utilities different paragraph embedding methods e bow dm dbow document sentence representation extractive summarization task sentences given document summarized ranked solely similarity degree sentence document turn selected form final summery results shown table td denotes results obtained based manual transcripts spoken documents sd denotes results speech recognition transcripts contain recognition errors results observations bow simple intuitive representation method outperforms dm dbow td sd cases second dbow outperforms dm cases simplified variant simple efficient ability bow evidenced obvious shortcoming bow address synonymy polysemy words simply matching words occurring sentence document capture semantic intent distributed representation methods capable mitigating difficulty extent intuitive strategy concatenate experimental results shown table cf expected combinative representations outperform respective component representation methods large margin td sd cases interesting observation performance gap dm dbow representations types reduced combined bow incorporate bow accordingly mmr proposed coverage based methods respectively following experiments set experiments evaluate proposed coverage based methods e xdtd j xdtd celebrated mmr method considers relevance redundancy generating summary treated baseline system results shown table viewpoint representation method pairing xdtd j xdtd perform better suited mmr combinative representation methods e outperform bow method conjugated enhanced summarization methods summarization results improved incorporated based methods e mmr xdtd j xdtd td sd cases reason studied lastly compared baseline mmr system proposed methods demonstrate superiority td case achieve comparable results mmr sd case possible reason imperfect speech recognition drift estimation sub themes document xdtd j xdtd benefit taking sub themes account results confirm capabilities proposed methods td case especially pairing set experiments assess performance levels practiced state art summarization methods extractive summarization including variations vector space model e latent semantic analysis lsa continuous bag words model cbow skip gram model sg global vector model glove language model based summarization method e unigram language model ulm graph based methods e markov random walk mrw lexrank combinatorial optimization methods e sm ilp results presented table noteworthy observations drawn table lsa represents sentences spoken document document latent semantic space instead index term word space performs slightly better bow td sd cases table word embedding methods e cbow sg glove disparate model structures learning strategies achieve comparable results td sd cases note concatenated bow representation method implementation interesting comparison outperform expected td case offer small performance gain sd case cf table based methods e mrw lexrank competitive perform better vector space methods e lsa cbow sg glove td case sd case situation reversed reveals imperfect speech recognition negatively affect graph based methods vector space methods possible reason phenomenon speech recognition errors lead inaccurate similarity measures pair sentences pagerank like procedure graph based methods turn performed based problematic measures potentially leading degraded results fourth ulm shows results comparable state art methods td sd cases finally sm ilp stand performance td case deliver results par methods sd case pairing proposed methods achieve comparable results combinatorial optimization methods table summarization results achieved document sentence representations different paragraph embedding methods method bow dm dbow text documents td spoken documents sd rouge l rouge l table summarization results achieved proposed summarization framework different representation methods text documents td spoken documents sd method rouge l rouge l bow bow dm bow dbow mmr xdtd j xdtd mmr xdtd j xdtd mmr xdtd j xdtd table summarization results achieved studied state art unsupervised methods text documents td spoken documents sd rouge l rouge l sm ilp td case outperform sd case cf tables sm ilp aptly integrate ability reducing redundancy increasing diversity summarization heavyweight methods cf section results support potential proposed methods practical applications conclusions future work integrated paper novel coverage based methods proposed extensively evaluated extractive sds addition document sentence representation methods compared study finally methods formal summarization framework experimental results demonstrate effectiveness proposed coverage based methods relation state art baselines compared paper indicating potential new summarization framework future work explore feasible ways enrich representations documents sentences integrate extra cues speaker identities prosodic emotional information proposed framework plan investigate elegant robust estimate sub themes given document techniques furthermore accurately estimate component models involved proposed methods interesting research directions method lsa cbow sg glove ulm mrw lexrank references s furui al fundamental technologies modern speech recognition ieee signal processing magazine pp m ostendorf speech technology information access ieee signal processing magazine pp l s lee b chen spoken document understanding organization ieee signal processing magazine vol pp l s lee al spoken content retrieval cascading speech recognition text retrieval ieee acm transactions audio speech language processing vol pp y liu d hakkani tur speech summarization chapter spoken language understanding systems extracting semantic information speech g tur r d mori eds new york wiley g penn x zhu critical reassessment evaluation baselines speech summarization proc acl pp nenkova k mckeown automatic summarization foundations trends information retrieval vol pp mani m t maybury eds advances automatic text summarization cambridge ma mit press j torres moreno eds automatic text summarization wiley iste j carbonell j goldstein use mmr diversity based reranking reordering documents producing summaries proc sigir pp t nomoto y matsumoto new approach unsupervised text summarization proc sigir pp h takamura m okumura text summarization model based maximum coverage problem variant proc acl pp l li al enhancing diversity coverage balance summarization structure learning proc www pp z cao al learning summary prior representation extractive summarization proc acl pp s harabagiu hickl relevance modeling microblog summarization proc icwsm pp r mihalcea graph based ranking algorithms sentence extraction applied text summarization proc acl k y chen al extractive broadcast news summarization leveraging language modeling techniques ieee acm transactions audio speech language processing vol pp recurrent neural network s h liu al combining relevance language modeling clarity measure extractive speech summarization ieee acm transactions audio speech language processing vol pp w zheng h fang comparative study search result diversification methods proc ddr pp r santos et al exploiting query reformulations web search result diversification proc www pp y gong x liu generic text summarization relevance measure latent semantic analysis proc sigir pp x wan j yang multi document summarization cluster based link analysis proc sigir pp s furui et al speech speech summarization spontaneous speech ieee transactions speech audio processing vol pp speech text g erkan d r radev lexrank graph based lexical centrality salience text summarization journal artificial intelligent research vol pp h lin j bilmes multi document summarization budgeted maximization submodular functions proc naacl hlt pp k riedhammer al long story short global unsupervised models keyphrase based meeting summarization speech communication vol pp m fattah f ren ga mr ffnn pnn gmm based models automatic text summarization computer speech language vol pp j kupiec et al trainable document summarizer proc sigir pp j zhang p fung speech summarization lexical features mandarin broadcast news proc naacl hlt companion volume pp r sipos al large margin learning submodular summarization models proc eacl pp m galley skip chain conditional random field ranking meeting utterances importance proc emnlp pp k y chen al leveraging word embeddings spoken document summarization proc interspeech pp k y chen al incorporating paragraph embeddings density peaks clustering spoken document summarization proc asru q le t mikolov distributed representations sentences documents proc icml pp k y chen et al vector based language modeling spoken document retrieval proc icassp pp y bengio et al neural probabilistic language model journal machine learning research pp h m wang et al matbn mandarin chinese broadcast news corpus international journal computational linguistics chinese language processing vol pp c y lin rouge recall oriented understudy gisting available evaluation isi edu g heigold al discriminative training automatic speech recognition modeling criteria optimization implementation performance ieee signal processing magazine vol pp d yin et al diversifying search results popular subtopics proc trec
