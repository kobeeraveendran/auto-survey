improved spoken document summarization coverage modeling techniques kuan chen shih hung liu berlin chen hsin min wang academia sinica taipei taiwan national taiwan normal university taipei taiwan kychen journey sinica edu edu abstract extractive summarization aims selecting set indicative sentences source document summary express major theme document general consensus extractive summarization relevance coverage critical issues address existing methods designed model coverage characterized reducing redundancy increasing diversity summary maximal margin relevance mmr cited method takes relevance redundancy account generating summary given document addition mmr dearth research concentrating reducing redundancy increasing diversity spoken document summarization task far aware motivated observations major contributions presented paper contrast mmr considers coverage reducing redundancy propose novel coverage based methods directly increase diversity proposed methods set representative sentences relevant given document cover important sub themes document selected automatically second step forward plug document sentence representation methods proposed framework enhance summarization performance series empirical evaluations demonstrate effectiveness proposed methods index terms spoken document summarization relevance redundancy diversity introduction rapid development internet exponentially growing multimedia content music video broadcast news programs lecture recordings continuously filling daily life overwhelming data inevitably leads information overload problem speech important sources information content virtue spoken document summarization sds efficiently digest browse multimedia content listening associated speech summary extractive sds manages select set indicative sentences spoken document according target summarization ratio concatenate form summary attractive research topic recent years general consensus extractive summarization relevance coverage critical issues realistic scenario existing summarization methods focus determining relevance degree given document sentences result ranked sentences returned methods cover partial themes given document fail interpret picture summarization result diversification devoted covering important aspects sub themes document possible developed methods following line research coverage modeling categorized implicit explicit methods formally implicit method reduces redundancy summary considering sentence similarities explicit method increases diversity summary taking sub themes document consideration maximal margin relevance mmr iteratively selects sentence highest combination similarity score respect given document dissimilarity score respect selected sentences canonical representative implicit methods aside mmr little focus investigating summarization result diversification view propose novel coverage based methods extractive spoken document summarization leveraging methods concise summary automatically generated rendering relevance coverage explore incorporate document sentence proposed framework summarization performance representation methods enhance related work wide spectrum extractive sds methods developed far spreads methods simply based sentence position structure information methods based unsupervised sentence ranking methods based supervised sentence classification category important sentences selected salient parts spoken document introductory concluding parts methods applied specific domains limited document structures unsupervised sentence ranking methods attempt select important sentences based statistical features sentences words sentences human annotation involved popular methods include limited vector space model latent semantic analysis markov random walk mmr sentence significant score method language model based framework lexrank linear submodularity based method programming based method ilp statistical features include example term word frequency linguistic score recognition confidence measure prosodic information contrast supervised sentence classification methods gaussian mixture model bayesian classifier support vector machines svm conditional random fields crf usually formulate sentence selection binary classification problem sentence included integer summary interested readers refer comprehensive reviews new insights major methods developed applied good success wide range text spoken document summarization tasks addition mmr ability reducing redundancy increasing diversity aptly incorporated ilp structured svm method ilp readily suited large scale problems involve time consuming process important sentence selection hand structured svm method needs set training documents corresponding handcrafted summaries difficult collect manual annotation consuming labor intensive training classifiers summarizers view intended develop unsupervised summarization framework simultaneously relevance coverage account principled effective manner coverage modeling techniques common belief document summarization community relevance coverage key issues generating concise summary idea principled realization progressively selecting important sentences formulated arg max sdrel sdcov denotes given document summarized set sentences selected candidate sentences similarity function determine relevance degree source document sentences denotes coverage function context mmr coverage score candidate sentence computed cov mmr rel intuitively mmr iteratively selects sentence relevant document dissimilar selected sentences xdtd method opposed mmr reduces redundancy similarities summary sentences promising direction consider coverage increase diversity summary formally given document probability sentence meets gold summary written sdp affect ranking sentence prior probability sentence assumed identical sentences document omit evaluate sentence reasonable gold summary covers important sub themes document taking themes document consideration obtain tptsp sub theme stands coverage degree sentence sub theme seen relative importance measure sub theme gold summary subject obtained test stage generally agreed concise summary document cover important aspects document consequently coverage score simplified cov xdtd dtptsp model explicit document sub theme diversification xdtd short practical implementation computed tsp tsrel rel estimated similar manner xdtd method mmr xdtd implicitly explicitly model coverage considering redundancy diversity respectively comprehensive method proposed extension define coverage score cov xdtd interprets likelihood observing candidate sentence selected sentences denoted explicitly considering sub themes inherent given document likelihood decomposed tpt assuming conditionally independent given sub theme obtain ptsp obviously term model coverage sentence respect sub theme provides novelty measure determine dissatisfaction degree sub theme selected sentences assuming sentences independent given sub theme estimate dissatisfied degree method extends concept xdtd jointly taking redundancy diversity consideration refer xdtd analytic comparisons implementation details analytic comparisons aforementioned coverage modeling techniques coverage based methods characterized reducing redundancy increasing diversity mmr belongs category xdtd classified second category xdtd takes redundancy diversity account simultaneously hand marked difference mmr xdtd compares sentence selected sentence leverages estimate dissatisfied degree sub theme sentence selection iteration hand major distinction proposed coverage based methods xdtd determines importance degree sub theme referring document xdtd considers selected sentences document sum importance degree sub theme dynamically determined sentence selection iteration xdtd kept fixed sentence selection process xdtd mmr xdtd select indicative sentences recursive manner xdtd generates summary pass process practical implementation mmr xdtd slightly slower xdtd xdtd xdtd roots information retrieval community time xdtd xdtd formally introduced adapted evaluated sds task far aware noticeably sub themes play fundamental role proposed coverage based methods sections reality syntactic semantic sub themes document hard determine pilot study empirical comparison coverage based methods paper treat sentence document sub theme similarity function involved mmr proposed methods estimated based cosine similarity measure normalize document sentence sub theme representations section unit vectors speed calculation resulting similarity scores range document sentence representations bag words representation bag words bow representation long basis natural language processing related tasks major advantage bow simple intuitive efficient effective bow document sentence represented high dimensional vector dimension specifies occurrence statistics associated index term word subword grams document sentence eliminate noisy words function words promote discriminative words content words statistics usually estimated term frequency weighted inverse document frequency idf distributed representation hand representation learning emerged newly favorite research subject excellent performance far aware relatively studies investigating use extractive text spoken document summarization known methods document sentence embedding include distributed memory model distributed bag words dbow model distributed memory model model inspired hybridized traditional forward neural network language model nnlm formally based nnlm idea underlying model given paragraph predefined number context words jointly contribute prediction word end objective function defined log wwp number paragraphs training corpus denotes paragraph length model acts memory unit remembers missing current context named distributed memory model implementation given document sentence document document considered paragraph vector representations document sentences obtained maximizing objective function depicted distributed bag words model simplified version model merely draw paragraph representations predict words paragraphs objective function defined log dwp simplified model ignores contextual words input layer named distributed bag words dbow model document sentence representations obtained similar manner model experimental setup dataset study matbn broadcast news corpus collected academia sinica public television service foundation taiwan november april corpus segmented separate stories transcribed manually story contains speech studio anchor field reporters interviewees subset broadcast news documents compiled november august reserved summarization experiments chose documents test set remaining documents held development set reference summaries generated ranking sentences manual transcript spoken document importance assigning score sentence document reference summaries annotated subjects assessment summarization performance adopted widely rouge metrics experimental results reported obtained calculating scores rouge metrics summarization ratio set subset hour speech data matbn compiled november december bootstrap acoustic model training minimum phone error rate mpe criterion training data selection scheme vocabulary size thousand words average word error rate automatic transcription experimental results set experiments evaluate utilities different paragraph embedding methods bow dbow document sentence representation extractive summarization task sentences given document summarized ranked solely similarity degree sentence document turn selected form final summery results shown table denotes results obtained based manual transcripts spoken documents denotes results speech recognition transcripts contain recognition errors results observations bow simple intuitive representation method outperforms dbow cases second dbow outperforms cases simplified variant simple efficient ability bow evidenced obvious shortcoming bow address synonymy polysemy words simply matching words occurring sentence document capture semantic intent distributed representation methods capable mitigating difficulty extent intuitive strategy concatenate experimental results shown table expected combinative representations outperform respective component representation methods large margin cases interesting observation performance gap dbow representations types reduced combined bow incorporate bow accordingly mmr proposed coverage based methods respectively following experiments set experiments evaluate proposed coverage based methods xdtd xdtd celebrated mmr method considers relevance redundancy generating summary treated baseline system results shown table viewpoint representation method pairing xdtd xdtd perform better suited mmr combinative representation methods outperform bow method conjugated enhanced summarization methods summarization results improved incorporated based methods mmr xdtd xdtd cases reason studied lastly compared baseline mmr system proposed methods demonstrate superiority case achieve comparable results mmr case possible reason imperfect speech recognition drift estimation sub themes document xdtd xdtd benefit taking sub themes account results confirm capabilities proposed methods case especially pairing set experiments assess performance levels practiced state art summarization methods extractive summarization including variations vector space model latent semantic analysis lsa continuous bag words model cbow skip gram model global vector model glove language model based summarization method unigram language model ulm graph based methods markov random walk mrw lexrank combinatorial optimization methods ilp results presented table noteworthy observations drawn table lsa represents sentences spoken document document latent semantic space instead index term word space performs slightly better bow cases table word embedding methods cbow glove disparate model structures learning strategies achieve comparable results cases note concatenated bow representation method implementation interesting comparison outperform expected case offer small performance gain case table based methods mrw lexrank competitive perform better vector space methods lsa cbow glove case case situation reversed reveals imperfect speech recognition negatively affect graph based methods vector space methods possible reason phenomenon speech recognition errors lead inaccurate similarity measures pair sentences pagerank like procedure graph based methods turn performed based problematic measures potentially leading degraded results fourth ulm shows results comparable state art methods cases finally ilp stand performance case deliver results par methods case pairing proposed methods achieve comparable results combinatorial optimization methods table summarization results achieved document sentence representations different paragraph embedding methods method bow dbow text documents spoken documents rouge rouge table summarization results achieved proposed summarization framework different representation methods text documents spoken documents method rouge rouge bow bow bow dbow mmr xdtd xdtd mmr xdtd xdtd mmr xdtd xdtd table summarization results achieved studied state art unsupervised methods text documents spoken documents rouge rouge ilp case outperform case tables ilp aptly integrate ability reducing redundancy increasing diversity summarization heavyweight methods section results support potential proposed methods practical applications conclusions future work integrated paper novel coverage based methods proposed extensively evaluated extractive sds addition document sentence representation methods compared study finally methods formal summarization framework experimental results demonstrate effectiveness proposed coverage based methods relation state art baselines compared paper indicating potential new summarization framework future work explore feasible ways enrich representations documents sentences integrate extra cues speaker identities prosodic emotional information proposed framework plan investigate elegant robust estimate sub themes given document techniques furthermore accurately estimate component models involved proposed methods interesting research directions method lsa cbow glove ulm mrw lexrank references furui fundamental technologies modern speech recognition ieee signal processing magazine ostendorf speech technology information access ieee signal processing magazine lee chen spoken document understanding organization ieee signal processing magazine vol lee spoken content retrieval cascading speech recognition text retrieval ieee acm transactions audio speech language processing vol liu hakkani tur speech summarization chapter spoken language understanding systems extracting semantic information speech tur mori eds new york wiley penn zhu critical reassessment evaluation baselines speech summarization proc acl nenkova mckeown automatic summarization foundations trends information retrieval vol mani maybury eds advances automatic text summarization cambridge mit press torres moreno eds automatic text summarization wiley iste carbonell goldstein use mmr diversity based reranking reordering documents producing summaries proc sigir nomoto matsumoto new approach unsupervised text summarization proc sigir takamura okumura text summarization model based maximum coverage problem variant proc acl enhancing diversity coverage balance summarization structure learning proc www cao learning summary prior representation extractive summarization proc acl harabagiu hickl relevance modeling microblog summarization proc icwsm mihalcea graph based ranking algorithms sentence extraction applied text summarization proc acl chen extractive broadcast news summarization leveraging language modeling techniques ieee acm transactions audio speech language processing vol recurrent neural network liu combining relevance language modeling clarity measure extractive speech summarization ieee acm transactions audio speech language processing vol zheng fang comparative study search result diversification methods proc ddr santos exploiting query reformulations web search result diversification proc www gong liu generic text summarization relevance measure latent semantic analysis proc sigir wan yang multi document summarization cluster based link analysis proc sigir furui speech speech summarization spontaneous speech ieee transactions speech audio processing vol speech text erkan radev lexrank graph based lexical centrality salience text summarization journal artificial intelligent research vol lin bilmes multi document summarization budgeted maximization submodular functions proc naacl hlt riedhammer long story short global unsupervised models keyphrase based meeting summarization speech communication vol fattah ren ffnn pnn gmm based models automatic text summarization computer speech language vol kupiec trainable document summarizer proc sigir zhang fung speech summarization lexical features mandarin broadcast news proc naacl hlt companion volume sipos large margin learning submodular summarization models proc eacl galley skip chain conditional random field ranking meeting utterances importance proc emnlp chen leveraging word embeddings spoken document summarization proc interspeech chen incorporating paragraph embeddings density peaks clustering spoken document summarization proc asru mikolov distributed representations sentences documents proc icml chen vector based language modeling spoken document retrieval proc icassp bengio neural probabilistic language model journal machine learning research wang matbn mandarin chinese broadcast news corpus international journal computational linguistics chinese language processing vol lin rouge recall oriented understudy gisting available evaluation isi edu heigold discriminative training automatic speech recognition modeling criteria optimization implementation performance ieee signal processing magazine vol yin diversifying search results popular subtopics proc trec
