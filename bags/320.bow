g u a l c s c v v i x r a fat albert finding answers in large texts using semantic similarity attention layer based on bert omar amgad anandharaju hari and zayed simon fraser university burnaby canada ca abstract machine based text comprehension has always been a signicant research eld in natural language processing once a full understanding of the text context and semantics is achieved a deep learning model can be trained to solve a large subset of tasks text summarization classication and question answering in this paper we focus on the question answering problem specically the multiple choice type of questions we develop a model based on bert a state of the art transformer network moreover we alleviate the ability of bert to support large text corpus by extracting the highest inuence sentences through a semantic larity model evaluations of our proposed demonstrate that it outperforms the leading models in the movieqa challenge and we are currently ranked in the leader board with test accuracy of finally we discuss the model shortcomings and suggest possible improvements to overcome these limitations introduction one of the main challenges in natural language processing nlp is the ability of a machine to read and understand an unstructured text and then reason about answering some related questions such question answering qa models can be applied to a wide range of applications such as nancial reports customer service and health care a signicant number of datasets namely race and swag were created to provide a ground truth for training and evaluating a specic type of qa models that involve multiple choice questions mcqs the movieqa dataset challenge has attracted a large number of promising solutions such as blohm et al where they implement two attention models based on short term memory lstm and convolutional neural networks cnns moreover they combine both model accuracies using an ensemble aggregation however these models are prone to various systematic adversarial attacks like linguistic level attacks word vs sentence level and the knowledge of the adversaries black box vs white box these models only learn to match patterns to select the right answer rather than performing plausible inferences as humans do recently implemented bidirectional encoder representations from transformers bert which has since been used as a pre trained model to tackle a large subset of nlp tasks bert s key technical source code is publicly available com omossad fat albert leader board cs toronto edu plot preprint under review table movieqa dataset description of movies of questions avg q of words avg ca of words avg wa of words train val test total innovation is applying the bidirectional training of transformer a popular attention model to language modelling the paper s results show that a language model which is bidirectionally trained can have a deeper sense of language context and ow than single direction language models a plethora of deep learning models have ever since incorporated bert into several tasks ever improving the state of the art performances a notable limitation of bert is that it is not able to support large texts that include more than the pre trained model s maximum number of words tokens therefore when dealing with large texts the performance of bert is severely affected in our work we aim to overcome the limitations of bert by analyzing and improving how accurate we predict the answer extracted from a large text in the movieqa mcq dataset our approach relies on the concept of sentence attention to extract the most signicant sentences from a large corpus we were able to accomplish this task using a pre trained semantic similarity model the remainder of this paper is organized as follows section describes the datasets focusing on the semantics and the nature of the questions next we highlight the proposed model and the intuition behind all the components we used in section we evaluate the performance of our model in section finally we conclude our report and suggest future modications for the model in section movieqa dataset in this section we give an overview of the dataset used to evaluate our model the movieqa dataset was created by generating a number of mcqs that can be solved from specic context extracted from the plots of real movies an existing is still on going to nd the highest accuracy in solving these mcqs on movie topics the models can be trained to use either video scenes subtitles scripts or movie plots extracted from wikipedia the leader board for this challenge is divided according to the source of input selected for the model the dataset consists of almost mcqs obtained from over movies and features high semantic diversity each question comes with a set of highly plausible answers only one of which is correct the dataset structure and semantics for the movie plots are described in table on average each movie plot has sentences and there are words per sentence on average all training and validation sets are labelled with the correct answer however the test dataset is not labelled and can only be evaluated using the challenge s submission server due to the large nature of the plot texts we have selected this dataset to demonstrate how we can incorporate bert in relatively large texts fat albert model description existing bert mcq codes currently lack the support for large text documents since they are restricted to sequence length of at most tokens furthermore due to our limited compute capabilities we are restricted to tokens according to only tpus with gb memory are able to train models with number of tokens compared to gb gpus therefore we have used another model on top of bert mcq to select the top sentences from the text that are highly similar to the question context subsequently instead of processing the entire corpus bert mcq uses the top sentences only the maximum span of a certain question i e the part from the text needed to answer this question is sentences and all plot alignments are consecutive i e all questions span a specic passage from the text not the entire text challenge cs toronto figure fat albert model overview figure semantic similarity network model our model consists of the following semantic similarity classier pre trained on sts and clinical datasets bert for mcq trained on movieqa dataset a description of the entire model is depicted in fig the large movie plot text along with the concatenated question and answer sequences are fed to the similarity model to produce the top similar sentences for each question we feed the questions answers and the attention made plot text top similar sentences to the bert for mcq model the output of this model is an array of probabilities having the size of the number of possible choices finally we select the choice having the highest probability semantic similarity network we use two pre trained models based on sts and clinical datasets to nd the similarity measure between sentences a number of variation for semantic similarity exists between our dataset and the aforementioned ones but the selected model has proven to be effective in our application a detailed comparison between the performance of these models on the movieqa dataset is provided in the evaluation section the model uses bert to extract the embeddings from both sentences these embeddings undergo a number of similarity functions namely cosine similarity qgram distance levenshtein similarity and the outputs are sent to a fully connected network followed by a softmax layer to provide the similarity index we have selected to use a combination of sts and clinical bert models after normalizing each model probabilities eq describes how the cosine similarity index between two sentences and is calculated fig highlights the contextual structure of the bert similarity model bert for mcq the bert mcq model uses a pre trained bert transformer network modied and ne tuned on the movieqa dataset the embedding outputs of bert are passed to a fully connected layer to produce the predicted probabilities of each possible choice we used the pre trained model which uses layer hidden heads and m parameters the ne tuning is performed on the movieqa dataset after modifying bert outputs to support the variable number of choices when running bert for mcq on the perfectly aligned plot sentences the model was able to achieve a validation accuracy of although the model was initially developed to support sentence completion type of questions we modied the model to handle mcqs by changing the network structure to output probabilities for each choice instead of complete text tokens evaluation results we evaluate the performance of our model on the movieqa dataset in this section we indicate whether the results were obtained from our own implementation or as mentioned in the reference paper some differences appear between our evaluation and the published results probably due to changes in parameters by the authors which were not mirrored in their source codes we also provide a brief case study to highlight two cases from the same movie plot where the model succeeds and fails respectively evaluation on movieqa dataset a properly trained bert for mcq can reach an accuracy in the range of on the movieqa dataset once it is aligned with exact sentences having the answer however when performed without any sentence selection the accuracy drops to a random choice due to the fact that bert truncates the sentences with word count higher than the maximum sequence length words in our case therefore using the semantic similarity model we captured the top similar sentences to the question at hand we selected questions since the average word count of sentences over the entire dataset is in the range of which seems to be acceptable to truncate a few words from the least similar sentences the similarity model performance is depicted in table the combined model aggregates the output probabilities of web and clinical models after normalization a possible improvement for the model accuracy can be done by further training it on the movieqa dataset next we compare the accuracy of our model against the current movieqa challenge leader board models we have included the validation accuracy and test evaluations we received from the movieqa authors after submission another contribution is that we have created an ensemble model that aggregates the results from the top approaches in the challenge and performs a majority ruling to select the label with the highest probability this model uses the cnn and lstm models previously described along with the bert model the main incentive behind this ensemble is to allow different models to correct one another and collaboratively avoid making mistakes table demonstrates the accuracy of our models compared to the leader board models to highlight the effect of the number of tokens in bert we showcase in fig the training loss for models with different number of tokens the main observation is that in order to support larger number of tokens we had to reduce the batch size used during training although the results indicate that larger tokens have lower losses in general it is clear that reducing the batch size has notably affected the model accuracy for instance in fig when using a number of tokens equivalent to table semantic similarity evaluations train acc val acc web bert clinical bert combined table movieqa dataset evaluations val acc test acc fat albert ensemble fat albert lstm cnn word level cnn as included in the paper leader board not obtained from our evaluations the model accuracy increases signicantly compared to a maximum number of tokens where the model truncates any input having tokens due to the compute capability we have nt been able to run the model with tokens as the gpus were not able to allocate enough memory therefore we evaluated the loss for larger number tokens using a smaller batch size in fig the loss is gradually decreasing as the number of tokens becomes higher until it stabilizes when the inputs generally become smaller than the maximum number of tokens hence the input sentences are padded with zeros to reach the required size of tokens case study we demonstrate two cases extracted from the movie forrest gump the movie plot is sentences and a brief extract is shown in fig two sample questions are displayed in fig the model selects the top similar sentences to the question and in that case the answer can be fully interpreted from one of these s sentences highlighted in bold hence after passing these sentences instead of the entire plot to bert mcq it successfully selects the correct choice on the other hand the similarity model was nt able to select the best sentences in the second example as shown in fig despite nding one of the accurate sentences for this specic question the model missed the most informative one therefore the qa model subsequently failed to select the correct answer conclusions and future work in this paper we have created an attention model based on semantic similarity to overcome bert limitations in order to solve an mcq we begin by extracting the most relevant sentences from a large text thereby reducing the complexity of the problem of answering mcq question at the time of writing this report our latest submission is ranked rst in the movieqa challenge as a future work we plan to extend our model to process other input signals provided by the movieqa dataset like subtitles we could build more powerful models by incorporating other human like processing mechanisms such as referential relations entailment and answer by elimination finally migrating the code to work on tpus with higher computational power instead of gpus may allow us to handle larger texts avoiding sentence truncation batch size batch size figure bert mcq training loss on movieqa dataset figure forrest gump plot figure correct model prediction example figure wrong model prediction example references blohm m jagfeld g sood e yu x and vu n t comparing attention based convolutional and recurrent neural networks success and limitations in machine reading hension in proceedings of the conference on computational natural language learning association for computational linguistics devlin j chang m w lee k and toutanova k bert pre training of deep bidirectional transformers for language understanding corr lai g xie q liu h yang y and hovy e race large scale reading comprehension dataset from examinations arxiv preprint tapaswi m zhu y stiefelhagen r torralba a urtasun r and fidler s movieqa understanding stories in movies through question answering in ieee conference on computer vision and pattern recognition cvpr jun ieee zellers r bisk y schwartz r and choi y swag a large scale adversarial in proceedings of the conference on dataset for grounded commonsense inference empirical methods in natural language processing association for computational linguistics
