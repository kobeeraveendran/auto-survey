adapting neural encoder decoder framework single multi document summarization logan lebanoff kaiqiang song fei liu department computer science university central florida orlando usa loganlebanoff ucf edu ucf edu abstract generating text abstract set ments remains challenging task neural encoder decoder framework recently exploited summarize single documents success attributed ability large parallel data automatically quired web contrast parallel data multi document summarization scarce costly obtain pressing need adapt encoder decoder model trained single document summarization data work multiple document input paper present initial investigation novel adaptation method exploits maximal marginal relevance method select tative sentences multi document input leverages abstractive encoder decoder model fuse disparate sentences stractive summary adaptation method robust requires training data system compares favorably state art extractive abstractive approaches judged automatic metrics human assessors introduction neural abstractive summarization primarily focused summarizing short texts written gle authors example sentence summarization seeks reduce rst sentence news article title like summary rush pati takase song single document summarization sds cuses condensing news article handful bullet points paulus summarization studies ered large parallel datasets automatically vested online news outlets including word rush cnn daily mail mann nyt sandhaus newsroom grusky date multi document summarization mds fully beneted development dataset source summary pairs gigaword rush cnn daily mail hermann tac dang duc yen news article rst sentence news article words title like words multi sent news articles words related topic multi sent news articles words related topic multi sent million table comparison datasets available sent marization gigaword single doc cnn multi doc summarization duc tac labelled data multi doc summarization neural encoder decoder models mds seeks condense set documents likely written tiple authors short informative summary practical applications summarizing product reviews gerani student sponses post class questionnaires luo man luo sets news cles discussing certain topics hong state art mds systems tive nenkova mckeown despite promising results systems perform text abstraction paraphrasing generalization sentence fusion jing mckeown annotated mds datasets scarce containing hundreds training pairs ble cost create ground truth summaries multiple document inputs prohibitive mds datasets small train neural encoder decoder models millions parameters overtting promising route generating abstractive summary multi document input apply neural encoder decoder model trained document summarization mega document created concatenating documents set test time nonetheless model scale reasons identifying portant text pieces mega document challenging encoder decoder model trained single document summarization data summary worthy content tained rst sentences article case mega document second dundant text pieces mega document peatedly summary generation current framework attention mechanism encoder decoder model bahdanau position based lacks awareness mantics text piece attended ing summary generation unlikely attention value assigned similar text piece different position fected content repeatedly summary generation issues alleviated improving encoder decoder architecture attention mechanism cheng lapata tan cases model trained large scale mds datasets available current stage increasing need lightweight adaptation encoder decoder model trained sds datasets work document inputs test time paper present novel adaptation method named mmr generate abstracts multi document inputs method bust requires mds training data bines recent neural encoder decoder model pointer generator networks generates abstractive summaries document inputs strong extractive rization algorithm mmr maximal marginal relevance carbonell goldstein identies important source sentences document inputs mmr algorithm tively performs following identies ful important sentences document attention weights model directly modied focus important sentences generating summary sentence system identies number tant sentences likelihood choosing tain sentences reduced based ity partially generated summary ducing redundancy research contributions clude following present investigation novel tion method encoder decoder framework multi document summarization best knowledge rst tempt couple maximal marginal relevance algorithm pointer generator networks multi document summarization demonstrate effectiveness posed method extensive experiments standard mds datasets system compares favorably state art extractive stractive summarization systems measured automatic metrics human judgments related work popular methods multi document tion extractive important sentences extracted set source documents tionally compressed form summary daume iii marcu zajic gillick favre galanis androutsopoulos berg kirkpatrick thadani mckeown wang yogatama filippova rett recent years neural networks exploited learn word sentence resentations multi document marization cheng lapata cao isonuma yasunaga narayan approaches remain extractive despite encouraging results marizing large quantity texts requires phisticated abstraction capabilities alization paraphrasing sentence fusion prior deep learning abstractive tion investigated barzilay carenini cheung ganesan gerani fabbrizio pighin bing liu liao approaches construct domain templates text planner open tem employ natural language generator surface realization limited availability labelled data experiments performed small domain specic datasets neural abstractive summarization utilizing encoder decoder architecture shown ing results studies focus primarily document summarization nallapati kikuchi chen miao blunsom tan zeng zhou paulus gehrmann ing mechanism gulcehre allows summarization system copy words source text generate new words vocabulary reinforcement learning exploited directly optimize tion metrics paulus kryscinski chen bansal studies cus summarizing single documents cause training data abundant work baumel zhang related particular baumel propose extend abstractive marization system generate query focused maries zhang add document set coder hierarchical summarization work exceptions little research dedicated investigate feasibility extending encoder decoder framework erate abstractive summaries multi document inputs available training data scarce paper presents rst steps goal extending encoder decoder model multi document setting introduce tation method combining pointer generator networks maximal marginal relevance mmr algorithm carbonell goldstein model trained sds data detailed section capable generating document abstracts performing text abstraction sentence fusion model applied test time rize multi document inputs tions mmr algorithm presented tion teaches model effectively nize important content input documents improving quality abstractive maries requiring training document inputs limits encoder decoder model encoder decoder architecture standard neural abstractive rization rush encoder bidirectional lstm hochreiter ber converting input text set den states input word indexed decoder unidirectional lstm generates summary predicting word time decoder hidden states represented indexed sentence document summarization nallapati paulus input text treated sequence words model expected capture source syntax inherently attention weight measures tant input word generating output word following calculated measuring strength interaction decoder hidden state encoder hidden state tive attention denotes lative attention input word receives time step large value indicates input word prior time unlikely generating output word context vector constructed summarize semantic meaning input weighted sum encoder hidden states context vector decoder hidden state compute vocabulary probability measuring likelihood vocabulary word selected word encoder decoder models switch estimated pgen indicate system chosen select word cabulary copy word input text switch computed ward layer activation embedding output word time attention weights compute copy probability word appears input text copy probability sum attention weights occurrences nal probability weighted combination vocabulary probability copy bility cross entropy loss function train model end end pgen thoroughly understand aforementioned encoder decoder model divide model rameters groups include parameters encoder decoder calculating switch represents concatenation vectors pointer generator networks use linear layers produce vocabulary distribution use denote parameters layers figure system framework mmr system uses highest scored source sentences case guide model generate summary sentence source sentences muted process best viewed color calculating attention weights training encoder decoder model document summarization sds data containing large collection news articles paired maries hermann model eters effectively learned test time wish model generate abstractive summaries document inputs brings issues parameters ineffective identifying salient content multi document inputs humans good identifying representative sentences set documents fusing abstract capability supported encoder decoder model second tion mechanism based input word positions semantics lead redundant content multi document input edly summary generation ture aspects addressed ducing external model selects tative sentences multi document inputs dynamically adjusts sentence importance duce summary redundancy external model integrated encoder decoder model erate abstractive summaries selected sentative sentences following section present adaptation method multi document summarization method maximal marginal relevance adaptation method incorporates maximal marginal vance algorithm mmr carbonell goldstein pointer generator networks adjusting network attention ues mmr successful extractive approaches despite straightforwardness performs par state art systems luo litman yogatama iteration mmr selects sentence ument includes summary length threshold reached selected tence important remaining sentences content overlap current summary equation measures similarity sentence document serves proxy sentence importance important sentences usually similarity centroid ument maxsj measures imum similarity sentence summary sentences acting proxy dancy balancing factor argmax importance sjs redundancy mmr describes iterative framework summarizing multi document input mary consisting multiple sentences eration mmr follows mmr principle select highest scored source sentences serve basis generate summary sentence scores source tences updated based importance redundancy sentences highly similar partial summary receive lower scores ing sentences mmr algorithm helps system effectively identify salient source content included summary muting allow system effectively utilize source sentences retraining neural model dynamically adjust attention weights test time let sent encoderneural decoderdocument scoressumm sent sent resent selected sentence attention weights words belonging calculated words tences forced receive zero attention weights renormalized new means remaining sentences muted process variant sentence tance affect original attention weights muting alternative setting sentence salience multiplied word salience ized uses reweighted alpha ues predict summary word new sentence importance estimate sentence portance introduce supervised regression model work importantly model trained single document tion datasets training data abundant test time model applied identify portant sentences multi document input model determines sentence importance based indicators inspired humans identify important sentences document set clude sentence length absolute tive position document sentence quality close sentence main topic document set features considered important indicators previous extractive summarization framework galanis sopoulos hong sentence quality age model build sentence tation use bidirectional lstm encoder encode source sentence vector concatenation sentation hidden states forward backward passes document vector average sentence vectors use document vector cosine similarity document sentence vectors indicator support tor regression model trained sentence score pairs training data obtained cnn daily mail dataset target importance score rouge recall sentence pared ground truth summary model chitecture leverages neural representations algorithm mmr algorithm rizing multi document inputs input sds data mds source sentences train model sds data importance dundancy scores source sentence source sentences source sentences summary index summary words lmax find highest mmr scores based compute new run decoder step summary summary period symbol end summary end tences documents data driven restricted particular domain sentence redundancy calculate dancy sentence maxsj compute rouge precision sures longest common subsequence source sentence partial summary ing sentences generated far model divided length source tence source sentence yielding high precision deemed signicant content overlap partial summary receive low mmr score likely serve basis generating future summary sentences alg provides overview mmr gorithm fig graphical illustration mmr scores source sentences updated ter summary sentence generated model different set highest scored tences guide model generate summary sentence muting ing source sentences important helps model focus attention nicant source content code model publicly available mds research experimental setup datasets investigate effectiveness mmr method testing standard document summarization datasets yen com ucfnlp multidoc summarization dang owczarzak include containing topics respectively summarization system tasked ating concise uent summary words set documents discussing topic documents set chronologically ordered concatenated form mega document ing input mmr system sentences start quotation mark end period excluded wong system summary compared human stracts created nist assessors following vention report results datasets standard test sets validation set parameter tuning model trained single document summarization cnn daily mail mann dataset containing single news articles paired summaries human written ticle highlights training set contains articles article contains tokens age summary contains tokens tences training use eters provided test time maximum minimum decoding steps set words respectively corresponding max min lengths mmr summaries cause focus work multi document summarization mds report results cnn daily mail dataset baselines compare mmr broad spectrum baselines including state art extractive abstractive systems described ext sumbasic vanderwende extractive approach assuming words occurring frequently ment set likely included summary ext sum haghighi vanderwende greedily adds source sentences summary leads crease divergence ext lexrank erkan radev uses graph based approach compute sentence importance based vector centrality graph representation ext centroid hong computes importance source sentence based cosine similarity document centroid ext icsisumm gillick leverages ilp framework identify globally optimal set sentences covering important concepts document set hyperparameters mmr variants bestsummrec grateful hong providing summaries generated centroid icsisumm dpp systems available dataset system sumbasic vanderwende klsumm haghighi lexrank erkan radev centroid hong icsisumm gillick favre dpp taskar song opinosis ganesan original mmr summrec mmr sentattn mmr cosine default mmr bestsummrec table rouge results dataset system sumbasic vanderwende klsumm haghighi lexrank erkan radev song opinosis ganesan original mmr summrec mmr sentattn mmr cosine default mmr bestsummrec table rouge results dataset ext dpp taskar selects optimal set sentences determinantal point processes balance erage important information sentence diversity abs opinosis ganesan generates abstractive summaries searching salient paths word occurrence graph created source documents abs song recent proach scores sentences lexrank generates title like summary sentence decoder model trained gigaword data abs original introduces decoder model encourages system copy words source text pointing retaining ity produce novel words generator results having described experimental setup compare mmr method lines standard mds datasets evaluated automatic metrics human assessors rouge lin automatic metric sures overlap unigrams bigrams skip bigrams maximum distance words system summary set reference summaries rouge scores systems presented table spectively datasets explore variants mmr method differ importances source tences estimated sentence tance affects word attention weights cosine computes sentence importance cosine similarity score sentence ment vectors represented sparse idf vectors vector space model rec estimates sentence importance predicted recall score sentence summary support vector regression model trained sentences cnn daily mail datasets applied duc tac sentences test time rec obtains best estimate sentence tance calculating recall score sentence reference summaries serves upper bound performance summrec variants sentence tance scores normalized range sentattn adjusts attention weights words important sentences likely generate summary weights computed seen table mmr method surpasses unsupervised extractive baselines cluding sumbasic klsumm lexrank dataset icsisumm dpp good performance systems trained directly mds datasets utilized mmr method mmr exhibits perior performance compared existing outperforms opinosis tive systems original large margin terms scores particular original original pointer generator networks document inputs test time compared mmr effective identifying worthy content input cosine default mmr shows ter results summrec suggests sentence document representations tained encoder decoder model trained cnn suboptimal possibly vocabulary mismatch certain words duc tac datasets appear cnn embeddings learned ing finally observe bestsummrec yields highest performance datasets nding suggests great potential improvements mmr method extractive abstractive components separately optimized figure median location summary grams multi document input lower higher quartiles grams come summary tence location source sentence index system grams grams grams sent original mmr human abst table percentages summary grams entire tences appear multi document input location summary content ested understanding mmr forms original identifying summary content multi document input ask tion source documents system tend look generating maries ndings indicate original gravitates early source sentences mmr searches rst sentences figure median location rst occurrences summary grams grams come summary sentence original summaries grams summary sentence frequently come source sentences corresponding lower higher quartiles source sentence dices similarly grams summary tence come source sentences mmr summaries patterns ent grams summary tences come source sentences range respectively ndings gest original tends treat input single document identies summary worthy content beginning input mmr successfuly search broader range input summary content capability crucial multi document input tant content come article set degree extractiveness table shows multi document inputpg originalpg summ summ summ summ summ sent linguistic quality system fluency inform nonred lexrank original mmr rankings table linguistic quality rankings system summaries human abstract original summary boeing plane people board crashed tain west sulawesi province indonesia monday january killing passengers possible survivors plane adam air ight departing surabaya java bound manado northeast sulawesi plane crashed mountainous region polewali west lawesi province americans board survived know cause crash known time possible bad weather factor summary plane people board crashes americans board plane indonesia rescue team arrives indonesia plane crash plane crashes west sulawesi killing word fate boeing plane carrying passengers loses contact makassar plane crashes indonesia killing indonesian navy sends planes carry bodies indonesian plane carrying missing indonesian lawmaker criticises slow deployment plane hundreds kilometers plane crash adam air boeing crashed monday vanishing air trafc control radar screens indonesian islands java sulawesi people thought survived rescue teams racing crash site near polewali west sulawesi metres north south sulawesi provincial capital makassar worst air disaster sept mandala line boeing crashed shortly taking north sumatra airport killing people earlier friday ferry carrying people sank java coast mmr summary adam air boeing crashed monday afternoon search rescue teams discovered wreckage early tuesday indonesian rescue team arrived mountainous area west sulawesi province passenger plane people onboard crashed mountain polewali west sulawesi province air force rear commander eddy suyanto told shinta radio station plane operated local carrier adam air crashed mountainous region polewali province monday word fate remaining people board boeing table example system summaries human written abstract sentences manually tokenized readability percentages summary grams entire tences appearing multi document input original mmr summaries high degree extractiveness similar ings revealed mmr relies handful resentative source sentences mutes rest appears marginally extractive original systems encourage generating summary sentences stitching source sentences mary sentences appear source grams summaries generated rewriting selected source sentences title like summary sentences exhibits high degree abstraction close human abstracts linguistic quality assess linguistic quality system summaries employ amazon mechanical turk human evaluators judge summary quality including mmr lexrank original turker asked rate system summary scale worst best based evaluation ria informativeness extent ing expressed ground truth text preserved summary uency summary matical formed non redundancy summary successfully avoid repeating information human summaries ground truth turkers asked provide overall ranking system summaries results presented table observe lexrank summaries highest rated ency lexrank extractive approach summary sentences directly taken input mmr rated best informativeness non redundancy garding overall system rankings mmr maries frequently ranked best summaries outperforming example summaries table present example summaries generated tems original effectively identify portant content multi document input tends generate short title like sentences informative carry stantial redundancy system trained gigaword dataset rush target summary length words mmr generates summaries effectively dense important source content conclusion describe novel adaptation method erate abstractive summaries multi document inputs method combines extractive marization algorithm mmr sentence tion recent abstractive model fusing source sentences mmr system strates competitive results outperforming strong extractive abstractive baselines references dzmitry bahdanau kyunghyun cho yoshua neural machine translation corr bengio jointly learning align translate regina barzilay kathleen mckeown michael elhadad information fusion context multi document summarization proceedings annual meeting association tional linguistics acl tal baumel matan eyal michael elhadad query focused abstractive summarization rating query relevance multi document coverage summary length constraints els arxiv preprint taylor berg kirkpatrick dan gillick dan klein jointly learning extract compress proceedings annual meeting tion computational linguistics acl lidong bing piji liao wai lam weiwei guo rebecca passonneau abstractive multi document summarization phrase selection merging proceedings acl ziqiang cao wenjie sujian furu wei improving multi document summarization text classication proceedings association advancement articial intelligence aaai jaime carbonell jade goldstein use mmr diversity based reranking reordering documents producing summaries ings international acm sigir conference research development information retrieval sigir giuseppe carenini jackie chi kit cheung extractive nlg based abstractive tion evaluative text effect versiality proceedings fifth international natural language generation conference inlg qian chen xiaodan zhu zhen hua ling wei hui jiang distraction based neural networks document summarization proceedings fifth international joint conference ticial intelligence ijcai yen chun chen mohit bansal fast stractive summarization reinforce selected tence rewriting proceedings annual ing association computational linguistics acl jianpeng cheng mirella lapata neural summarization extracting sentences words proceedings acl hoa trang dang karolina owczarzak overview tac update summarization proceedings text analysis conference task tac hal daume iii daniel marcu channel model document compression ceedings annual meeting association computational linguistics acl greg durrett taylor berg kirkpatrick dan klein learning based single document tion compression anaphoricity constraints proceedings association computational linguistics acl gunes erkan dragomir radev lexrank graph based lexical centrality salience text journal articial intelligence summarization research giuseppe fabbrizio amanda stent robert gaizauskas hybrid approach document summarization opinions reviews proceedings international natural guage generation conference inlg katja filippova enrique alfonseca carlos menares lukasz kaiser oriol vinyals sentence compression deletion lstms proceedings conference empirical ods natural language processing emnlp dimitrios galanis ion androutsopoulos extractive supervised stage method sentence compression proceedings naacl hlt kavita ganesan chengxiang zhai jiawei han opinosis graph based approach stractive summarization highly redundant proceedings international ions ence computational linguistics coling sebastian gehrmann yuntian deng alexander rush abstractive proceedings conference tion pirical methods natural language processing emnlp shima gerani yashar mehdad giuseppe carenini raymond bita nejat abstractive summarization product reviews discourse structure proceedings conference pirical methods natural language processing emnlp dan gillick benoit favre scalable global proceedings model summarization naacl workshop integer linear programming natural langauge processing dan gillick benoit favre dilek hakkani tur berndt bohnet yang liu shasha xie icsi utd summarization system tac proceedings tac max grusky mor naaman yoav artzi newsroom dataset million summaries diverse extractive strategies proceedings north american chapter association computational linguistics naacl jiatao zhengdong hang victor incorporating copying mechanism proceedings sequence sequence learning acl caglar gulcehre sungjin ahn ramesh nallapati bowen zhou yoshua bengio pointing unknown words proceedings nual meeting association computational linguistics acl aria haghighi lucy vanderwende ing content models multi document tion proceedings north american ter association computational linguistics naacl karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa leyman phil blunsom teaching chines read comprehend proceedings neural information processing systems nips sepp hochreiter jurgen schmidhuber long short term memory neural computation kai hong john conroy benoit favre alex kulesza hui lin ani nenkova itory state art competitive baseline maries generic news summarization ings ninth international conference guage resources evaluation lrec masaru isonuma toru fujino junichiro mori yutaka matsuo ichiro sakata extractive marization multi task learning document classication proceedings conference empirical methods natural language processing emnlp hongyan jing kathleen mckeown composition human written summary sentences proceedings international acm sigir conference research development mation retrieval sigir yuta kikuchi graham neubig ryohei sasano hiroya takamura manabu okumura ling output length neural encoder decoders proceedings emnlp wojciech kryscinski romain paulus caiming xiong improving abstraction richard socher text summarization proceedings ference empirical methods natural language processing emnlp chen fei liu fuliang weng yang liu document summarization guided sentence pression proceedings conference empirical methods natural language processing emnlp kexin liao logan lebanoff fei liu stract meaning representation multi document summarization proceedings international conference computational linguistics ing chin yew lin rouge package proceedings tomatic evaluation summaries acl workshop text summarization branches fei liu jeffrey flanigan sam thomson norman sadeh noah smith tive summarization semantic representations proceedings north american chapter association computational linguistics man language technologies naacl wencan luo diane litman summarizing student responses reection prompts ings conference empirical methods ural language processing emnlp wencan luo fei liu zitao liu diane litman automatic summarization student course proceedings north american feedback chapter association computational guistics human language technologies naacl yishu miao phil blunsom language latent variable discrete generative models proceedings tence compression ence empirical methods natural language processing emnlp ramesh nallapati bowen zhou cicero dos santos caglar gulcehre bing xiang stractive text summarization sequence sequence rnns proceedings signll conference computational natural language learning conll shashi narayan shay cohen mirella lapata ranking sentences extractive tion reinforcement learning proceedings annual conference north american chapter association computational guistics human language technologies hlt ani nenkova kathleen mckeown matic summarization foundations trends information retrieval paul james yen introduction national institute standards technology romain paulus caiming xiong richard socher deep reinforced model abstractive proceedings conference marization empirical methods natural language processing emnlp daniele pighin marco cornolti enrique alfonseca katja filippova modelling events memory based open patterns proceedings annual tive summarization meeting association computational guistics acl wang hema raghavan vittorio castelli radu rian claire cardie sentence pression based framework query focused document summarization proceedings acl kam fai wong mingli wenjie tractive summarization supervised proceedings supervised learning national conference computational linguistics coling michihiro yasunaga rui zhang kshitijh meelu ayush pareek krishnan srinivasan dragomir radev graph based neural multi document summarization ence computational natural language learning conll proceedings alexander rush sumit chopra jason weston neural attention model sentence proceedings conference marization empirical methods natural language processing emnlp dani yogatama fei liu noah smith extractive summarization maximizing semantic volume proceedings conference pirical methods natural language processing emnlp david zajic bonnie dorr jimmy lin richard schwartz multi candidate reduction tence compression tool document rization tasks information processing ment wenyuan zeng wenjie luo sanja fidler raquel urtasun efcient summarization copy mechanism proceedings international conference learning tions iclr jianmin zhang jiwei tan xiaojun wan neural network approach tive multi document summarization arxiv preprint qingyu zhou nan yang furu wei ming zhou selective encoding abstractive sentence summarization proceedings annual ing association computational linguistics acl evan sandhaus new york times annotated corpus linguistic data consortium abigail peter liu christopher manning point summarization proceedings annual generator networks meeting association computational guistics acl kaiqiang song lin zhao fei liu structure infused copy mechanisms abstractive summarization proceedings international conference computational linguistics ing sho takase jun suzuki naoaki okazaki tsutomu rao masaaki nagata neural headline generation abstract meaning representation proceedings conference empirical ods natural language processing emnlp jiwei tan xiaojun wan jianguo xiao abstractive document summarization proceedings based attentional neural model annual meeting association tional linguistics acl alex kuleszaand ben taskar determinantal point processes machine learning lishers inc kapil thadani kathleen mckeown tence compression joint structural inference proceedings conll lucy vanderwende hisami suzuki chris brockett ani nenkova sumbasic focused summarization sentence simplication lexical expansion information processing management
