journal physical society japan letters belief propagation maximum coverage weighted bipartite graph application text summarization hiroki kitano koujin mechanical systems engineering graduate school science engineering ibaraki university nakanarusawa hitachi ibaraki japan study text summarization viewpoint maximum coverage problem graph theory task text summarization regarded maximum coverage problem bipartite graph weighted nodes recent study belief propagation based algorithm maximum coverage unweighted graph proposed idea tical mechanics generalize weighted graph text summarization apply algorithm weighted biregular random graph verication maximum coverage performance apply bipartite graph senting real document open text dataset check performance text summarization result algorithm exhibits better performance greedy type algorithm setting text summarization text summarization important tasks natural language processing methods proposed focus tion method exclude redundant sentences document possible method regarded optimization problem example reformulated knapsack problem past global optimal solution approximation solution discussed viewed maximum coverage problem nodes graph theory rst discussed ref work ple greedy algorithm approximate solution hard exist appropriate algorithm simple greedy algorithm actually algorithms compared previous work statistical mechanics optimization garded problem ground state system ref proposed novel algorithm based belief gation additional physical parameters perature chemical potential introduced control timization result better solution greedy algorithm tuning physical parameters algorithm unweighted bipartite graph order apply algorithm generalization weighted graph necessary background consider weighted partite graph based algorithm weighted bipartite graph conduct ment biregular random graph order compare improved greedy algorithm weighted graph ply algorithm real document evaluate performance quantitatively formulate weighted bipartite graph separate nodes groups bipartite graph nodes dierent groups directly connected numbers elements tively means cardinality set edges denoted binary variable ned ith node ath node dene weight nodes koujin takeda ibaraki fig weighted bipartite graph left node sentence right node word weight left node number words sentence right node describes importance word sentences selected cover weight connected nodes words possible shaded nodes gure upper bound number words objective solve integer programming maximize waya cixi parameter upper bound constraint inequality means represents neighborhood value means ith node selected covering connected nodes represents connected nodes selected coverage integer programming reduced unweighted case nodes selected cover connected nodes possible performance coverage measured fig context node taken sentence document node corresponds word weight means words ith sentence phys soc jpn letters cludes weight describes importance word integer programming want cover weight words possible selecting nicant sentences document condition number total words selected sentences smaller problem current framework teger programming hard need algorithm good approximate solution ref integer programming solved approximately greedy algorithm performance guarantee algorithm called greedy applied found good performance comparison algorithms algorithm select additional node maximize weight sum connected ered xcov nodes divided weight xcov contrast rithm weight line algorithm argmaxi xcov called simple greedy algorithm letter algorithm greedy algorithm initialize sets xcov xcov argmaxi xcov add xcov end delete end output xcov selected nodes output xcov weight sum covered nodes better solution greedy algorithm construct algorithm original idea apply proposed ref weight graph taken consideration generalize weighted model order apply idea current problem following ref dene partition function weighted bipartite graph exp waya cixi inverse temperature chemical potential heaviside function commented ref constraint cixi directly incorporated algorithm infeasible instead introduced tional control parameter serves lagrange tiplier limit greedy algorithm duced parameter serves relaxation ter optimization partition function want calculate marginal probabilities exp hixi exp aya know node selected variables local elds physical meaning calculate elds generalization algorithm ref weighted case straightforward nal update algorithm beliefs obtained hia hbi hai ewa means nodes neighbourhood ing explain derive equations briey tion function rules written xya xka ewaya beliefs original equations let redene beliefs exponential form ehia ehai computing ratio beliefs gives similarly ratio ewa ewa ewa yields taking logarithm having beliefs calculate local elds liefs hbi xbi ewa probability calculated elds ingly select nodes values elds based algorithm summarized rithm algorithm node largest lected remaining ones like greedy algorithm note cixi directly considered constraint formulation introduce constraint bining algorithm apply algorithm weighted biregular dom graph verication performance periment use random graph randomly assign edges nodes edges set number nodes weight assign random integer number uniformly parameters xed varied iteration algorithm performed times checked convergence beliefs iterations letters phys soc jpn algorithm based algorithm initialize beliefs hia initialize sets xcov repeat update hia update hai reaches maximum number iteration calculate argmaxi xcov add xcov end delete end output xcov output xcov fig result biregular random graph results greedy algorithm algorithm shown fig results averaged random graphs indicated case unweighted graph maximal weight sum exceeds result greedy rithm near present case peak weight sum apply algorithm problem ing weight word experiment use dataset dataset consists clusters news articles associated press new york times cluster documents task summarization text multiple documents cluster references summarization texts written human attached cluster weight word assigned term frequency inverse document frequency idf idf product factors idf word high idf appears frequently specic sentences documents idf assign times idf weight words rst sentence document rst sentence signicant meaning document computing weights idf use dataset addition preprocessing documents use stemming deletion exclamation mark parenthesis conversion letters lowercase fig result dataset removal stop words weight sum covered nodes performance evaluated comparing summarization attached reference quantitatively performance measured precisely computed summarization words measures words appear commonly summarization reference experiment average clusters attached ences cluster evaluation use tool sumeval results experiment tion performed times checked convergence beliefs iterations rst result depicted fig result remove stop words documents natural language stop words prepositions articles peak weight sum shows peak algorithm form greedy terms second result fig stop words removed result maximal exceeds value greedy peak change value range best figs dataset typical value weight small appropriate value large satisfying waya consequence maximal larger greedy stop words removed result worse removal stop words expect reason inclusion stop words aects weight phys soc jpn letters words mind stop words excluded natural language processing summarize generalized based algorithm weighted graph applied algorithm weighted random graph better performance greedy applied result indicates advantage greedy depends weight words future work investigate cases exhibits better performance greedy detail acknowledgment thankful satoshi takabe discussion helpful comments work supported kakenhi nos mcdonald proc european conference information retrieval filatova hatzivassiloglou proc international ference computational linguistics takamura okumura proc conference ropean chapter acl takabe maehara hukushima phys rev khuller moss naor information processing letters gerard automatic text processing addison wesley reading lin hovy proc meeting naacl hlt com chakki works sumeval nltk fig result dataset removal stop words weight sum covered nodes summarization document understanding conference naacl hlt workshop text word including stop words precision idf weight statistically improved larger number
