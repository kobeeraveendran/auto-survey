extracting summary knowledge graphs long documents zeqiu rik koncel kedziorski mari ostendorf hannaneh hajishirzi university washington seattle usa kedzior ostendor edu abstract knowledge graphs capture entities relations long documents facilitate reasoning downstream applications extracting compact knowledge graphs ing salient entities relations important lenging understanding summarizing long documents introduce new text graph task predicting rized knowledge graphs long documents develop dataset document graph pairs automatic human annotations develop strong baselines task based graph learning text summarization provide quantitative qualitative studies effect introduction knowledge graphs popular representations tant entities relationships compact interpretable knowledge graphs facilitate human data analysis empower memory dependent knowledge based tions makes ideal modeling content documents document level information extraction captures relations distant sentences construct knowledge graphs documents jia wong poon yao techniques focus tracting entities relations document long dense documents scientic papers hundreds thousands poses new challenge determine important entities paper key relationships automatic summarization liu lapata sunaga addresses problem identifying salient information document introduces tional challenge discourse structuring tive case text generation summarizing entities relations directly rst step decouple mixed burdens models help assure factual correctness summary line recent trends evaluation summarization wang cho lewis durmus diab zhang work introduce task extracting scientic document compact knowledge graph sents important information figure illustrates situation large knowledge graph extracted document portion entities relations terize main ideas colored nodes thick edges figure introduce task extract summary edge graph long document scientic paper example dataset target mary graph contain entities relations salient included abstract entities relations shown light grey found abstract removed omit entity tion types simplicity rest play minor role task emphasizes ing salient subgraph support task dataset scientic document graph pairs integrates matic human annotations existing knowledge sources scientic domain outline evaluation paradigm balances accuracy redundancy admitting variability textual reference entity develop investigate competitive baselines based text summarization graph learning models compare simple frequency based methods vide analysis tradeoffs general lenges posed proposed dataset example serve missing entities entity coreference errors predicted graphs large impact relation racy hope task data facilitate search future models better capture lenging important textual relations abstract tree adjoining grammars extended domain locality wide coverage lexicalized grammars english lexsys xtag exploit edol main papertree adjoining grammarsedolxtaglexsyslexicalized grammars english background related work information extraction work focuses extracting entities relational facts single sentence zhang stanovsky recent work addresses document level aims capture relations distant sentences jain jia wong poon yao pre dened metadata table entities hou jia wong poon yao hou formulate task classifying relation type pair truth entities expressed document assume existence ground truth entities extract level relations directly text work complements trend applying long document understanding addressing need focused compact knowledge representations closest work jain separately explore idea identifying salient entities related experimental sults weak supervision provided papers code dataset contrast focus identifying salient entities paper based weak supervision abstract framing generalizes wider variety uments domains supports diverse tasks including multi document summarization building scientic edge bases entity salience task requires models identify salience relations challenging text summarization document summarization models create summaries tifying important sentences documents lapati zhai zhou narayan cohen lapata decoder generate abstractive summaries rush chopra weston celikyilmaz text summarization tasks liu lapata yasunaga share objective distilling crucial information documents mix objective goal producing uent natural language text argue summarizing entities relations directly rst step decouple mixed burdens els help models check factual correctness summary advantages benet text tion tasks rely long document understanding resentation generation grounded long text increasing number recent works wang cho lewis durmus diab zhang proposed automatically evaluating summarization models applying information extraction question answering models match entities relations generated reference summaries newly proposed measures found higher correlation human ments standard measures recent applications large pretrained language models ribeiro kale promise generating uent accurate text edge graphs highlighting need identifying correct code paperswithcode com underlying knowledge representations addition rized knowledge graphs multiple documents naturally merged collapsing shared entity nodes bring richer information summarized structures easily leveraged facilitate downstream tasks line work closely related graph based summarization leverages graph tures documents facilitate summary generation erkan radev tan wan xiao sunaga huang wang works try leverage graphs capture lations sentences discourse units wang incorporate graphs entities extracted sentence level systems considering entity lation salience graph summarization general graph summarization work categorized according goal optimizing memory computational resources needed processing ing analysis liu knowledge graph tion safavi node estimation park relevant work normally huge knowledge graph pruning based given query document context unlike works task quires model handle different document contexts inference document contain completely different knowledge graph unique entities work similar falke gurevych collect small corpus data instances concept map annotations openie tuples summarizing sets documents choose science specic annotation scheme provides structure target scientic document understanding proposed idea summarized knowledge graphs applied documents domain focus scientic papers work existing works derstanding scientic documents include limited information extraction luan wadden summarization cohan collins stein riedel yasunaga fact tion wadden citation generation luu xing fan wan recently attention search scientic domain nlp community grown wang esteva urgent need mitigating global pandemic task formulation introduce text graph task extracting succinct structured knowledge graph contains salient entities relations document specically summarized knowledge graph meet ditions contains important entities document includes relations entities crucial understanding main ideas text salient entity represented single node graph conditions evaluated entity salience relation salience entity duplication rate respectively evaluation details section dataset section long documents scientic papers salient entities relations dened included paper abstracts figure shows example task entities relations appear abstract included summary knowledge graph grey moved mentioned paper necessary describe understand main idea paper formally dene problem given document pre dened entity type set relation type set predict summarized knowledge graph represents salient entity entity type mentioned represents important edge relation type note multiple edges consists cluster string names referent entity mentions mni dataset scigraphsumm construct text graph dataset corpus tic papers textual data consists roughly puter science research papers taken corpus million text research papers abstracts leverage abstracts create summarized edge graphs papers abstracts effectively contain summarized information documents existing human annotation information extraction systems enable constructing relational graphs stracts expense difculty annotation access small number human annotated summary graphs use judge system performance data human test set training development weakly supervised approach automatically extracted summary graphs use scientic system extract summary graphs abstracts pair papers entity relation graphs extracted papers divide graph paper ples train dev automatic test sets dev set parameter tuning purposes auto test set compare systems randomly sampling examples observe extracted target entities abstracts automatic test set ful section similar tem performance trends observed human test set automatic test set table gives statistics number size textual documents summary graphs data splits data collection graph construction details described sections follow automatic test set larger human test set reduces problems noise automatic annotation examples doc tokens graph entities graph relations train dev auto test human test table statistics data split manual summarized graph annotation leverage scierc scientic luan human labeled test data scierc consists expert annotated paper abstracts labeled entities types task method metric material scientic term generic reference relations types pare conjunction evaluate feature hyponym construct knowledge graphs annotations collapsing coreferent mentions single node linking nodes annotated relations abstracts scierc texts able order guarantee information richness discard pairs annotated graphs fewer predicted relations ltering human test set consists knowledge graphs text documents automatic summarized graph annotation facilitate model training model development weakly supervised setting automatically create target knowledge graphs remaining papers stracts leverage state art scientic system extracts entities relations references simultaneously wadden train instead use pretrained model scierc processing modeling steps work construct knowledge graphs output collapsing coreferences create entities associate list coreferential text mentions relations tions edges corresponding entities graph sample ltering applied automatic graph construction task designed build summarized graph directly document order perform task models use specic information extraction tools build graph provide edge graphs constructed documents dataset reproducibility encourage future ploration graph learning models task process document text overlapping token windows reduce computation memory consecutive chunks having overlapped sentence serve cross sentence references collapse additionally discard pairs abstracts longer tokens rare avoid memory limitations discard sentences longer tokens guarantee overlapped sentence consecutive chunks fewer sentences discarded tial mentions previous steps collapse ence clusters different windows matching unique non generic mentions single graph node generic entity mention string excluding pronouns determiners token unigram inverse document frequency idf training data higher empirically chosen threshold selected high precision identifying generic mentions generic entity mention clustered model predicts coreferent entity mention evaluation metrics goal evaluate correctness predicted mary knowledge graph compared ground truth mary graph rst align entity nodes predicted graph nodes target graph entity ment step measure qualities predicted graphs entity salience relation salience duplication rate der relaxed alignment condition described entity alignment human test set found annotated entity tions exact string match main paper text analysis showed cases paraphrasing hyphenation differences typos caused ocr parsers process papers pdf format example domain monolingual pus abstract domain monolingual corpus paper equivalent exact match hyphen difference addition assume specic information extraction tools similar sue exact matching occur potentially different entity mention names extracted different models exact string match yield good alignment instead use relaxed alignment method found reasonably accurate evaluation issue aligning entities graphs entity referred multiple strings entity node represents cluster referent tity mentions align predicted node target node cluster mention types maximum similarity possible pairs similarity score target entity mnj predicted entity mni calculated max employ gestalt pattern matching ratcliff metzener calculate string similarity based mon substrings predicted node aligned node gives highest similarity score subject minimum score selected set relaxed exact alignments manually inspected acceptable manually inspected samples fall ing categories paraphrases target nodes consider laxed alignment examples good differences involve typo hyphen item order paraphrases example log linear linear interpolation versus linear log linear interpolation different specicity level consider aligned entities different specicity level relevant ments example speaker intention prediction ules versus intention prediction modules alignments error consider entities ing aligned distinct meanings bad ments example dimensional analog sorting versus dimensional notion sorting human auto test sets applying relaxed alignment graph nodes target nodes increases percentage aligned target nodes exact matching salience duplication measures calculate entity salience align predicted node target graph node collapsing multiple dicted nodes map target entity single node calculating precision recall scores words multiple predicted entities aligned target entity counted calculating scores metrics computed matching ignoring entity types typed untyped evaluation entity entity type adopt dominating type mentions entity type process penalize predicted graphs multiple nodes aligned single target node calculate duplication rate average number dicted nodes aligned target node based entity alignment target relation edge aligned predicted relation sponding nodes align aligns aligns evaluate relation salience based relation ments allowing multiple relation types pair entities report precision recall scores relation prediction considering relation type direction matching typed untyped evaluation evaluating relation type direction merge relations multiple entity pair single edge baseline models develop baseline models graph tion problem text summarization model tracts summary sentences extract entities relations rst builds document graph applies graph learning model graph pruning text text graph ttg model rst produces text summary ment text extractive summarizer bertsumext liu lapata subsequently uses entities tions text summary form summary knowledge graph train original model dataset placing pre trained bert scibert beltagy cohan increase sequence length entities relations pear text summary summarized graph graph graph model predicts summary subgraph graph extracted described section formulate subgraph selection node classication problem encode graph gat velickovic use resulting node representations binary salience prediction original gat node embedded able feature vector contextualized multi headed tention graph neighbors graph tion layer graph attention layer vertex neighborhood contextualized ijwv contextualized original vector representations rhh model parameters attention weights computed vertex representations formulation extended multi head attention layered non linearities produce graph attention network original gat consider different tion types neighboring vertices incorporate lation types model use separate heads ferent relation types head corresponding relation type attend connected edge label different relation types dataset use heads gat sentations heads concatenated transformed non linearity model layers node embedding layer use features bed entity node number mentions ument section entity rst appearance document frequent entity type mentions predicted pooled representation scibert beltagy cohan longest mention string encode node follows nin wssi wtti wes learnable unit feature vector rns rnt hot vectors respectively number unique tion ids node entity types dataset rhe hidden representation rst token nal layer scibert rhns rhnt rhhe trained model parameters following node embedding layer contextualize node representation gat layers pass node nal binary classication layer predict salience supervise training model apply laxed alignment method section align graph entities target graph entities graph entities aligned treated positive examples ers negative finally use negative log likelihood loss function positive labeled salient nodes negative sampling ratio training include graph relations predicted tities output summary graph leave better relation prediction future study implementaion details manually tune rameters gat based dev set entity performance curve versus training steps model rameters vector dimension number layers batch size parameters tuned learning rate dropout rate negative sampling ratio manually change parameter value serve performance instability dev set rst training steps average number tuning trials parameter fewer times finally set negative pling ratio dropout rate learning rate experiments model use adam timizer netune scibert base model gat run experiment single titan rtx select model checkpoint based typed relation score performance valid set experiments evaluated systems compare ttg models section frequency based baselines pagerank authorized entities document graph highest pagerank scores page edge weight initialized number relation mentions entity pair topk freq tkf frequent entities selected els average number graph nodes aligned target nodes training set cases relations document graphs selected ties added generate predicted summary graph report performance gold entity vides performance upper bound relying tities relations extracted text picks graph node est similarity score target node lower old inclusion predicted graph includes relations found graph entities quantitative results table shows precision recall scores typed typed entity relation prediction entity duplication rates automatic test set similar evaluation trends untyped typed evaluation lower scores type matching required pected ttg outperform baselines ent ent ent rel rel rel untyped typed ent ent ent rel rel rel dup tkf ttg table results untyped typed entity relation evaluation precision recall entity duplication rate dup auto test set scores entity duplication rate note entity duplication rates expected untyped typed evaluation entity alignment considers string matching ent ent ent rel rel rel untyped typed ent ent ent rel rel rel dup tkf ttg table results untyped typed entity relation evaluation precision recall entity duplication rate dup human test set scores entity duplication rate human test ttg ttg auto test task method metric material scientic term generic table entity relaxed match entity type entity relation evaluations particular sistently performs best scores ttg higher precision evaluating entity duplication rate ttg consistently performs best systems performances far shows signicant room improvement task future table gives results human test set trends observed automatic test set hold human test set exception shows better formance entities effective typed relations argue automatic test set reasonable extra set test systems development qualitative analysis looked handful abstracts human test set analyze scoring criteria proposed task target graphs hand annotated identify important entities salient entities stract eliminating generic nodes method non essential scientic term nodes occasional duplicated nodes cases added entities gold reference identied automatic algorithms deemed appropriate entities identied automatic algorithms aligned reduced target set untyped entities recall higher reduced set pagerank suggesting algorithms better capturing salient entities errors entity types involved clear cases trends precision reduced graph consistent automatic scoring noticed aligned predicted nodes contain unrelated entities coreference errors systems explains low relation scores impact missing inserted entities investigate causes tkf performing poorly pared ttg specic analyze quency good indicator salient entities cases rst calculate average length mention string names predicted salient entities tkf average length ttg average furthermore tant entities tend long string names especially paper authors start introducing specic tasks els entities tend split smaller segments later parts paper detailed explanations smaller segments tend mentioned frequently predicted tkf comprehensive qualify salient entities ample key entity bayesian semi supervised chinese word segmentation model detected salient ttg tkf predicts chinese words word segmentation closest salient entities ple tkf predicts systems salient entity paper gold entity like knowledge representation systems predicted ttg noted table sizes target graphs pers different human automatic test sets observe ttg produces graphs similar size papers test sets nodes edges contrast produces graphs different sizes different ment lengths averaging nodes edges human test set nodes edges automatic test set documents longer target graphs bigger observe interesting trends sections entities rst appear entities appear rst tion paper time auto human test sets rst mention middle sections nal sections tively numbers consistent test sets observation highlights fact extracting main idea paper needs understanding partly sequence length limitation bertsumext ttg extremely biased entities rst section vulnerable bias fails include entities later paper sections summaries table shows entity score based relaxed match different entity type calculate scores comparing subgraphs predicted target graphs contain entities certain type entities type ric hardest predict correlates fact metric entities likely appear rst section paper overall human test set possible reason metric frequent salient entity type salient entities type metric auto human test set respectively figure sample output ttg figure shows example target metric entity rst appearing second section paper correctly predicted missed ttg red incorrect relation edges relying graph relations limits relation prediction performance evidenced tables gives low relation prediction scores absence gold target relations document graphs conclusions future work described new text graph task ing summary knowledge graphs text documents including standard preprocessed open access dataset evaluation techniques facilitate research investigated graph classication text summarization techniques task detailed qualities analysis relation salience prediction challenging task extracting summary knowledge graphs important investigation leveraging document level graph learning techniques interesting direction explore models merge entity nodes better lead lower entity duplication rate improved relation accuracy major shortcoming gat model consider context entity mention document incorporating tual information entity mentions ing research direction references beltagy cohan scibert trained language model scientic text emnlp celikyilmaz bosselut choi deep communicating agents abstractive tion naacl cohan dernoncourt kim bui kim chang goharian discourse aware tention model abstractive summarization long uments naacl collins augenstein riedel vised approach extractive summarisation scientic papers conll durmus diab feqa question answering evaluation framework faithfulness ment abstractive summarization acl erkan radev lexrank graph based lexical centrality salience text summarization journal articial intelligence research esteva kale paulus hashimotoa yin radev socher search information retrieval semantic search arxiv tion answering abstractive summarization falke gurevych bringing structure summaries crowdsourcing benchmark corpus cept maps emnlp hou jochim gleize bonin ganguly identication tasks datasets evaluation metrics numeric scores scientic leaderboards tion acl huang wang knowledge augmented abstractive summarization driven cloze reward acl corpusspeaker independent recognitionspeaker adaptationword error ratesi corpusspeaker independent recognitionspeaker adaptationword error ratesi corpusspeaker independent recognitionspeaker adaptationtarget velickovic cucurull casanova romero bengio graph attention networks iclr wadden lin wang zuylen han hajishirzi fact fiction verifying scientic claims arxiv wadden wennberg luan hajishirzi entity relation event extraction alized span representations emnlp wang cho lewis asking swering questions evaluate factual consistency summaries acl wang liu zheng qiu huang heterogeneous graph neural networks extractive ument summarization acl wang chandrasekhar reas yang burdick eide funk katsis kinney liu merrill mooney murdick rishi sheehan shen stilson wade wang wang wilhelm xie raymond weld etzioni kohlmeier acl nlp covid open research dataset workshop xing fan wan automatic generation citation texts scholarly papers pilot study acl gan cheng liu aware neural extractive text summarization acl yao han lin liu liu huang zhou sun docred scale document level relation extraction dataset acl yasunaga kasai zhang fabbri friedman radev scisummnet large annotated corpus content impact models scientic paper summarization citation networks aaai zhang merck tsai manning glotz optimizing factual correctness summary study summarizing radiology reports acl zhang zhong chen angeli manning position aware attention supervised data improve slot filling emnlp jain zuylen hajishirzi beltagy scirex challenge dataset document level tion extraction acl jia wong poon document level ary relation extraction multiscale representation learning naacl hlt kale text text pre training data text tasks arxiv liu lapata text summarization trained encoders emnlp liu safavi dighe koutra graph summarization methods applications survey acm computing surveys wang neumann kinney weld semantic scholar open research corpus acl luan ostendorf hajishirzi multi task identication entities relations erence scientic knowledge graph construction emnlp luu koncel kedziorski cachola arxiv smith citation text generation nallapati zhai zhou summarunner recurrent neural network based sequence model tractive summarization documents aaai narayan cohen lapata ing sentences extractive summarization ment learning naacl hlt page brin motwani winograd pagerank citation ranking bringing order web technical report stanford infolab park kan dong zhao faloutsos estimating node importance knowledge graphs graph neural networks kdd ratcliff metzener pattern matching gestalt approach dobb journal ribeiro schmitt schutze gurevych investigating pretrained language models text generation arxiv rush chopra weston neural attention model abstractive sentence summarization emnlp safavi belth faber mottin muller koutra personalized knowledge graph rization cloud pocket icdm stanovsky michael zettlemoyer dagan supervised open information extraction naacl tan wan xiao abstractive ment summarization graph based attentional ral model acl
