query controllable video summarization jia hong huang university amsterdam amsterdam netherlands j nl marcel worring university amsterdam amsterdam netherlands m nl r r s c v v x r abstract video collections huge explore videos efficiently challenging video summarization ways tackle issue traditional summarization approaches limit effectiveness video exploration generate fixed video summary given input video independent information need user work introduce method takes text based query input erates video summary corresponding modeling video summarization supervised learning problem propose end end deep learning based method query controllable video summarization generate query dependent video mary proposed method consists video summary controller video summary generator video summary output module foster research query controllable video summarization conduct experiments introduce dataset contains frame based relevance score labels based experimental sult shows text based query helps control video mary shows text based query improves model formance com jhhuangkay query controllable video summarization ccs concepts computing methodologies artificial intelligence video summarization acm reference format jia hong huang marcel worring query controllable video marization proceedings international conference multimedia retrieval icmr june dublin ireland acm new york ny usa pages introduction video data ubiquitous daily life raw videos long containing redundant content consequence video data people watch overwhelming raises new challenges efficiently exploring videos video summarization helps people explore video efficiently capturing essence video learning essential depends information need user traditional video summarization methods generate fixed video summary given input video create video capturing permission digital hard copies work personal classroom use granted fee provided copies distributed profit commercial advantage copies bear notice citation page copyrights components work owned honored abstracting credit permitted copy republish post servers redistribute lists requires prior specific permission fee request permissions org icmr june dublin ireland copyright held owner publication rights licensed acm acm isbn figure figure shows main idea controllable video summarization user gives text based query represents desired video summary trol video summary generator create video summary based query note input proposed method query video different queries given video input different dependent video summaries generated different traditional video summarization video input details video summary controller video summary generator refer figure possible information needs yield limited reduction time lose essential information specific needs having fixed summary limits effectiveness video exploration video exploration effective efficient need new specialized method steered information need user capable generating video summaries given video query controllable video rization main features query controllable video summarization complicate task compared studied domain conventional video summarization example query controllable video summarization based query input video input conventional video summarization video input query controllable video summarization need model implicit relations teractions input query video evaluating ated video summaries challenge previously researchers usually conduct human expert evaluation based predefined rules showing human experts different video summaries ing select better human expert based evaluation methods task problematic methods expensive time consuming rely ments humans evaluation paper prefer conduct automatic evaluation efficient different solutions model video summarization problem supervised pervised automatic manvideosummarycontrollervideosummarygeneratorvideo summaryoutput module evaluation paper model video summarization pervised learning problem propose end end deep learning based model illustrated figure generate video maries depending text based input queries best knowledge proposing end end deep model query controllable video summarization note non end method query controllable video summarization needs preprocessing steps practice reduce ciency video exploration model consists video summary controller video summary generator video summary module controller uses text words phrases sentences describe desired video summary erator creates video summary based implicit relationship text based description input video video summary output module outputs video summary based relevance score prediction vector build query controllable system videos multiple information sources requires dedicated datasets evaluation methods undertake study work starting existing dataset establish new video dataset build models dataset place right time research exploit deep learning based models textual query inputs steer output mentioned proposed model takes text based query video input effectively fuse multi modal features minimum loss information technical problems shown similar multi modal contexts performance models decrease feature fusion methods improper solve issue general remains open question conduct experiments input query affects model performance conduct experiments commonly feature fusion methods affect model performance foster research community video summarization intend publish dataset code demonstrate experimental results proposed end end deep model proposed method capable ating query dependent controllable video summaries given videos experimental result shows text based input query helps control video summary shows based input query improves performance summarization model sense accuracy contributions propose new end end deep learning based model text visual embedding space query controllable video summarization conduct detailed experiments text based query helps control video summary improves performance proposed end end model introduce query video pair based dataset based dataset proposed query controllable video summarization task dataset contains videos corresponding frame based relevance score annotations related work section discuss related work terms different ods different datasets discuss main types methods video summarization e supervised unsupervised review commonly video summarization datasets unsupervised video summarization unsupervised approaches video summarization usually exploit hand crafted heuristics satisfy properties interestingness ness diversity authors propose method based color feature extraction video frames k means clustering authors observe key visual concepts usually pear repeatedly videos topic propose create summarized video finding shots co occur frequently videos develop maximal biclique finding mbf algorithm find sparsely co occurring patterns authors introduce space time video summarization method extract visually informative space time portions input videos analyze distribution spatial temporal tion video simultaneously authors present video summarization method egocentric camera data develop region cues e nearness hands gaze frequency occurrence egocentric video learn model predict relative importance new region based cues thors present video summarization method discover story given egocentric video proposed method capable selecting short chain sub shots video depicting essential events based modeling ers attention authors propose generic framework video summarization framework fully semantic content understanding given video eliminates needs complicated heuristic rules video summarization task takes advantage computational attention models authors introduce unified method video summarization based analysis structures highlights video approach emphasizes content balance perceptual quality video summary time incorporate normalized cut algorithm partition video clusters motion attention model based human perception compute perceptual quality clusters shots authors develop new method extract video summary captures important particularities arising given video generalities identified set given videos simultaneously authors introduce method learn dictionary given video group sparse coding video summary generated combining segments reconstructed sparsely dictionary authors propose new formulation perform video summarization unpaired data model aims learn mapping set raw videos set video summaries distribution generated video summary similar distribution set video summaries help adversarial objective enforce diversity constraint mapping ensure generated video summaries diverse visually authors introduce end end reinforcement learning based framework train video summarization model work incorporates new reward function jointly account diversity representativeness generated video summaries design reward function makes rely user interactions labels authors propose based method specific objective query adaptive video summarization method end end need preprocessing steps generating video summary practice inconvenient efficient video exploration motivates propose end end deep learning based method existing works model video tion task unsupervised problem propose methods tackle general performance unsupervised approach worse supervised supervised video summarization type approach video summarization task supervised learning ods supervised human expert labeled data e ground truth video summaries authors treat video summarization supervised subset selection task propose probabilistic model selecting diverse sequential subset called tial determinantal point process seqdpp note standard dpp treats video frames randomly permutable elements seqdpp heeds inherent sequential structures video data overcomes deficiency standard dpp retains power modeling diverse subsets essential video summarization authors introduce new video summarization method focus user videos containing set interesting events method starts segmenting given video based superframe segmentation tailored raw videos according estimation score visual interestingness frame set low level mid level high level features method picks optimal subset superframes generate video summary authors propose new model learn importance score global characteristics video summary models jointly optimized multiple objectives capable generating high quality video summaries authors duce new probabilistic model built seqdpp tackle video summarization problem period video segment local diversity imposed dynamically controlled model trained summarization model authors develop reinforcement learning algorithm train proposed model authors formulate video summarization sequence labeling problem propose fully convolutional quence models tackle video summarization task establish novel connection video summarization semantic segmentation second adapted popular semantic mentation networks generate video summaries authors propose improved sequential determinantal point process seqdpp model terms modeling new probabilistic distribution designed integrated seqdpp resulting model accepts input user intended length video summary terms learning large margin algorithm proposed address problem exposure bias seqdpp authors propose subset selection method leverages supervision form human created video maries perform keyframe based video summarization main idea method nonparametrically transferring structures summaries annotated videos unseen testing videos authors generalize proposed method sub shot based video summarization authors cast video summarization task structured prediction problem sequential data propose new supervised learning technique incorporating long short term memory lstm model variable range dependencies entailed task exploit domain tation techniques based auxiliary annotated video datasets improve quality video summary authors propose sequence sequence learning model tackle video summarization problem complement discriminative losses loss measuring generated video summary preserves information original video propose augment standard sequence learning models retrospective encoder embeds predicted video summary abstract semantic space embedding compared original video s embedding space authors introduce novel dilated temporal relational generative adversarial network dtr gan tackle frame based video summarization dtr gan exploits adversarial manner player loss learn dilated temporal relational generator discriminator authors introduce new dilated temporal relational unit enhance capturing temporal representation generator creates keyframes based unit supervised methods capable learning useful cues hard capture hand crafted heuristics ground truth video summaries usually outperform unsupervised models reason prefer model video rization supervised learning problem paper video summarization dataset comparison section shortly introduce commonly video summarization dataset comparison dataset paper tackle video summarization task authors propose dataset named tvsum contains videos categories corresponding shot level importance scores obtained crowdsourcing categories selected trecvid multimedia event detection med task videos category collected youtube names categories search queries search results videos chosen based following criteria selected video contain single shot title video descriptive visual topic video iii creative commons license iv duration video minutes authors exploit amazon mechanical turk amt collect responses video responses treated gold standard labels participant amt asked read title video simulating typical scenario online video browsing watch video single provide importance score uniform length shots video denoting important important audio muted ensure important scores based visual stimuli according authors experience second shot length ate capturing local context good visual coherence authors introduce video summarization benchmark called summe consisting videos covering holidays events sports length video ranges minutes video summarized different people thors asked males females participate making dataset given video participants asked produce video summary containing important content video allowed watch cut edit video simple table summary commonly video summarization datasets based table find proposed dataset larger datasets contains types input modalities including video text video summarization dataset contains video data dataset size large proposed dataset unique relevance scores work important scores tvsum different referring crowd sourced annotation subsection dataset summe tvsum based annotation type interval based shot frame level scores frame based important scores frame based relevance scores content user videos number videos input modality video youtube videos youtube videos video video text interface length video summary required range original video length ensure input video summarized shortened slightly videos shown randomly audio muted ensure generated video summaries based visual stimuli evaluation video summarization approaches viously researchers conduct human expert evaluation following ways based set predefined criteria degree redundancy counting inclusion predefined important content summary duration ii showing human experts different video summaries asking select better authors claim human expert evaluation methods problematic methods expensive time consuming rely judges human evaluation example uation method requires week human labor human expert evaluation methods help tell video summary better fail good video summary look like authors exploit approaches instead let set participants create video summaries collect multiple video summaries video reason true answer correct video summarization multiple possible ways man expert video summaries compare summarization method creates automatic video summary repeatable efficient way automatic versus human ison successfully keyframes authors comparing automatic keyframe based summaries human keyframe based selections yields ratings comparable letting humans directly judge automatic video summaries tvsum summe datasets allow automatic evaluation video summarization approaches paper establish dataset based automatic evaluation query controllable video summarization task proposed dataset contains videos frame level relevance score tations convenience summarize existing datasets comparison dataset table dataset introduction analysis section start describe analyze proposed dataset query controllable video summarization terms types videos video labels statistics dataset note dataset partially matches research pose publicly available discover specification figure figure shows original number frames video axis denotes video index y axis indicates number frames note venience videos number frames develop proposed method annotations videos published dataset different mentioned parts published dataset available anymore base uation dataset published describe process create dataset indicate changes needed suitable purpose setup dataset based rules dataset collection similar proposed dataset consists videos video retrieved based given text based query according authors use amazon mechanical turk amt annotate video frames labels text based query relevance scores labels dataset similarly mediaeval diverse social images challenge purpose human expert annotated labels proposed dataset matically evaluate methods generating relevant diverse video summaries proposed dataset based sentative samples queries videos collected based following procedure seed queries different categories selected youtube queries typically queries generic concepts short youtube auto complete function exploited obtain tic longer queries e ariana grande focus instrumental ark survival evolved dragon query video result frame label query video pair merging corresponding evance score annotations amt workers base majority vote rule evaluate model performance relevance score prediction e predicted relevance score correct majority human annotators provided exact score note map annotations good good good bad note referring relevance score work importance score tvsum different relevance score work capture relation given text based query video frame important score capture importance video frame final video summary video method overview section start describe proposed controllable video summarization method proposed method composed video summary controller video summary generator video summary output module summary controller takes text based query input outputs vector representation query summary generator takes embedded query video inputs outputs frame based relevance score prediction finally video summary output module use score prediction generate video summary figure explains procedure video summary controller text based queries meant represent expected video summary content subtly alludes semantic relationship use following way encode input queries add contribution proposed method paper exploit vector representation text based input query control generated video summary main idea video summary controller generate vector representation input query based dictionary beginning form dictionary based bag words collected unique words training queries encode input query exploiting dictionary encoding vector representation input query represent expected video summary content procedure clearer flowchart explain referring figure video summary generator main idea video summary generator vector representation input text based query video generate frame based relevance score vector summary generator composed convolutional neural network cnn structure multi modality features fusion module note cnn structure trained training set input video goes cnn structure sampled fps case use extract frame based features input video note feature visual layer layer classification layer features extracted exploit feature fusion module fuse frames based features input text based query feature fused feature vector sent fully connected layer frame based relevance score prediction feature fusion module depicted following subsection refer figure flowchart procedure note cross entropy loss figure figure conceptually depicts video mary controller video summary controller queries training set form bag words create dictionary base dictionary embed input query duration minutes collected following task set amt video annotations videos sampled frame second fps amt worker asked annotate frame relevance respect given text based query answer candidates good good good bad bad denotes frame relevant low quality bad contrast blurred reduce subjectivity labels video proposed dataset annotated different amt workers additionally qualification task defined ensure high quality annotations results manually reviewed sure workers provide annotations good quality workers pass task allowed assignments maximum number frames video videos number frames repeat frames starting frame reaching frames total video similar figure shows original number frames video crowd sourced annotation subsection analyze frame based relevance score annotations obtained procedure explain merge relevance score annotations video set ground truth labels label distributions relevance scores distribution evance score annotations good good good bad ground truth mentioned video summarization dataset comparison subsection human based evaluation problematic time consuming work based ing approach evaluation evaluation testing videos way ask human experts watch video instead video summaries access relevance single video responses considered gold standard annotations advantage approach annotations obtained experiments carried indefinitely desirable especially computer vision system involving multiple iterations testing note proposed dataset create single ground truth relevance score thetraining queriesword embeddingmodulequeryvectorrepresentation input querydictionarybag words figure figure conceptually depicts video summary generator generator input video sample fps input sampled frames cnn based structure extracting frame based features feature fused text based input query feature finally fused feature pass prediction layer generate frame based relevance scores finally base predicted relevance scores output query dependent video summary loss function referring equation adam optimizer optimizer parameters coefficients computing moving averages gradient square respectively term added denominator improve numerical stability learning rate class ln j class denotes ground truth class indicates prediction multi modality features fusion module technical problems proposed method fusing query based features minimum loss information shown similar multi modal contexts performance models decrease models poorly designed solve issue general remains open question work exploit difference commonly approaches summation concatenation element wise multiplication fuse query frame based features video summary output module frame based relevance score prediction vector video summary generator pass vector video summary output module main idea module output video summary based relevance score prediction vector case map labels good good good andbad predicted relevance score greater equal consider corresponding frame relevant predicted relevance score consider corresponding frame irrelevant finally collect k relevant frames time order video summary note k user defined parameter length video summary experiments analysis section evaluate proposed end end method query controllable video summarization task based setup proposed dataset analyze effectiveness query methods multi modal features fusion dataset preparation validate proposed query controllable video tion method base following dataset setup conduct experiments separate dataset e training validation testing respectively video corresponding query maximum number words query frame size input cnn channels e red green blue note malize image channel mean std maximum number frames video similar video preprocessing method videos number frames e original number frames video figure effectiveness analysis query experiment want know text based query help generate better video summary conduct experiment based types models query driven non query driven according figure discover query driven model testing accuracy better non query driven testing accuracy based validation accuracy versus number epochs textual query capable guiding query driven model perform better non query driven vector representation input querycandidatefeature fusionmoduleframe basedfeaturesprediction summary figure figure shows model performance cases video figure axis denotes number epochs y axis denotes model accuracy test models epochs ing note purple point denotes video testing accuracy black point indicates testing accuracy compare worst model fusing features summation figure non query driven model discover query driven model performs better motivates conduct experiment comparison multi modal feature fusion methods referring subsection effectiveness analysis different fusion methods general multi modal features fusion open question base commonly methods summation concatenation element wise multiplication conduct experiment according figure model element wise multiplication fusion method best formance compare performance feature fusion methods non query driven model discover model concatenation fusion method better non query driven model model summation fusion method worse non query driven model interaction query video based result figure figure implies proper multi modal feature fusion method important reason fused feature embeds implicit interaction video e frames query use improper fusion method summation query confuse network sense situation happens qualitative results analysis subsection qualitative results illustrated figure note limited space able frames represent original video corresponding generated video summary time order figure input video query civil war spiderman based video summary output module subsection use green indicate relevant frame black indicate evant frames second row represents video frames ground truth labels row represents video frames predicted labels correct number relevance score figure figure shows model performance different cases e multi modal features fusion summation concatenation element wise plication model element wise multiplication sion method best performance figure axis denotes case index y axis denotes model accuracy note model trained ent number epochs prediction note number frames original input video video summary frames selected order figure input video query movies use color indicate relevant irrelevant frames second row b indicates video frames ground truth labels row b represents video frames predicted labels correct number relevance score prediction similar number frames original input video video summary frames selected order based figure shows proposed method capable generating video summaries content relevant input query conclusion future work sum treat query controllable video summarization task supervised learning problem work tackle lem propose end end deep learning based approach generate query dependent video summary proposed method contains video summary controller video summary generator video summary output module foster query controllable video summarization research conduct experiments propose new dataset video proposed dataset notated frame based relevance score labels experimental results text based query helps control video summary improves model performance sense accuracy based experiment know multi modal feature fusion method crucial developing new fusion approach interesting future work video queryvalidation video querytraining videovalidation query civil war spiderman correct number relevance score prediction total number frames query movies correct number relevance score prediction total number frames figure figure based similar qualitative result visualization method generated video summaries corresponding queries color coded red indicates original total number frames input video row frames original video frames represent input video second row represents original input video row represents prediction fourth row e k frames represent generated video summary numbers indicate frame index original video note video frame index starting second generated video summary result corresponding notations similar acknowledgments project received funding european unions horizon research innovation programme marie skodowska curie grant agreement references stanislaw antol aishwarya agrawal jiasen lu margaret mitchell dhruv batra c lawrence zitnick devi parikh vqa visual question answering proceedings ieee international conference computer vision hedi ben younes rmi cadene matthieu cord nicolas thome mutan multimodal tucker fusion visual question answering proceedings ieee international conference computer vision wen sheng chu yale song alejandro jaimes video co summarization video summarization visual co occurrence proceedings ieee ence computer vision pattern recognition sandra eliza fontes de avila ana paula brando lopes antonio da luz jr arnaldo de albuquerque arajo vsumm mechanism designed produce static video summaries novel evaluation method pattern recognition letters akira fukui dong huk park daylen yang anna rohrbach trevor darrell marcus rohrbach multimodal compact bilinear pooling visual question answering visual grounding arxiv preprint boqing gong wei lun chao kristen grauman fei sha diverse sequential subset selection supervised video summarization advances neural information processing systems michael gygli helmut grabner hayko riemenschneider luc van gool creating summaries user videos european conference computer vision springer michael gygli helmut grabner luc van gool video summarization learning submodular mixtures objectives proceedings ieee conference computer vision pattern recognition kaiming xiangyu zhang shaoqing ren jian sun deep residual learning image recognition proceedings ieee conference computer vision pattern recognition tao hu pascal mettes jia hong huang cees gm snoek silco images localize common object proceedings ieee international conference computer vision jia hong huang robustness analysis visual question answering models basic questions king abdullah university science technology ms thesis jia hong huang modar alfadly bernard ghanem vqabq visual question answering basic questions cvpr vqa challenge workshop jia hong huang modar alfadly bernard ghanem marcel worring arxiv preprint assessing robustness visual question answering jia hong huang cuong duc dao modar alfadly bernard ghanem novel framework robustness analysis visual qa models proceedings aaai conference artificial intelligence vol jia hong huang cuong duc dao modar alfadly c huck yang bernard ghanem robustness analysis visual qa models basic questions cvpr vqa challenge visual dialog workshop bogdan ionescu alexandru lucian gnsca bogdan boteanu adrian popescu mihai lupu henning mller retrieving diverse social images mediaeval challenge dataset evaluation mediaeval hong wen kang yasuyuki matsushita xiaoou tang xue quan chen space time video montage ieee computer society conference computer vision pattern recognition vol ieee aditya khosla raffay hamid chih jen lin neel sundaresan scale video summarization web image priors proceedings ieee conference computer vision pattern recognition diederik p kingma jimmy ba adam method stochastic mization arxiv preprint yong jae lee joydeep ghosh kristen grauman discovering important people objects egocentric video summarization ieee conference computer vision pattern recognition ieee yandong li liqiang wang tianbao yang boqing gong local local diversity reinforcing sequential determinantal point processes dynamic ground sets supervised video summarization proceedings european conference computer vision eccv tiecheng liu john r kender optimization algorithms selection key frame sequences variable length european conference computer vision springer yi chieh liu yung hsieh min hung chen chao han huck yang jesper tegner yi chang james tsai interpretable self attention temporal reasoning driving behavior understanding arxiv preprint yi chieh liu hao hsiang yang c h huck yang jia hong huang meng tian hiromasa morikawa yi chang james tsai jesper tegner synthesizing new retinal symptom images multiple generative models asian conference computer vision springer zheng lu kristen grauman story driven summarization egocentric video proceedings ieee conference computer vision pattern recognition yu fei ma lie lu hong jiang zhang mingjing li user attention model video summarization proceedings tenth acm international conference multimedia acm chong wah ngo yu fei ma hong jiang zhang automatic video marization graph modeling proceedings ninth ieee international conference computer vision ieee paul alan f smeaton george awad trecvid bbc rushes summarization evaluation proceedings acm trecvid video summarization workshop acm rameswar panda amit k roy chowdhury collaborative tion topic related videos proceedings ieee conference computer vision pattern recognition danila potapov matthijs douze zaid harchaoui cordelia schmid category specific video summarization european conference computer vision springer mrigank rochan yang wang video summarization learning unpaired data proceedings ieee conference computer vision pattern recognition mrigank rochan linwei ye yang wang video summarization fully convolutional sequence networks proceedings european conference computer vision eccv aidean sharghi ali borji chengtao li tianbao yang boqing gong improving sequential determinantal point processes supervised video marization proceedings european conference computer vision eccv gunnar sigurdsson santosh divvala ali farhadi abhinav gupta asynchronous temporal fields action recognition proceedings ieee conference computer vision pattern recognition alan f smeaton paul wessel kraaij evaluation campaigns trecvid proceedings acm international workshop multimedia information retrieval acm yale song jordi vallmitjana amanda stent alejandro jaimes tvsum summarizing web videos titles proceedings ieee conference computer vision pattern recognition arun balajee vasudevan michael gygli anna volokitin luc van gool query adaptive video summarization quality aware relevance estimation proceedings acm international conference multimedia acm c h huck yang jia hong huang fangyu liu fang yi chiu mengya gao weifeng lyu jesper tegner al novel hybrid machine learning model auto classification retinal diseases joint icml ijcai workshop computational biology c h huck yang fangyu liu jia hong huang meng tian md hung lin yi chieh liu hiromasa morikawa hao hsiang yang jesper tegner auto classification retinal diseases limit sparse data streams machine learning model asian conference computer vision springer chao han huck yang yi chieh liu pin yu chen xiaoli ma yi chang james tsai causal intervention meets adversarial examples image masking deep neural networks ieee international conference image processing icip ieee ke zhang wei lun chao fei sha kristen grauman summary transfer exemplar based subset selection video summarization proceedings ieee conference computer vision pattern recognition ke zhang wei lun chao fei sha kristen grauman video rization long short term memory european conference computer vision springer ke zhang kristen grauman fei sha retrospective encoders video summarization proceedings european conference computer vision eccv yujia zhang michael kampffmeyer xiaodan liang min tan eric p xing query conditioned player adversarial network video tion arxiv preprint yujia zhang michael kampffmeyer xiaoguang zhao min tan gan dilated temporal relational adversarial network video summarization proceedings acm turing celebration conference china acm bin zhao eric p xing quasi real time summarization consumer videos proceedings ieee conference computer vision pattern recognition kaiyang zhou yu qiao tao xiang deep reinforcement learning unsupervised video summarization diversity representativeness reward thirty second aaai conference artificial intelligence
