v o n l c s c v v x r supervised extractive text summarization rnn based sequence classication eduardo brito max lubbering david biesner lars patrick hillebrand christian bauckhage fraunhofer iais sankt augustin germany fraunhofer center machine learning germany b university bonn bonn germany abstract article briey explains submitted approach competition extractive summarization implemented recurrent neural network based model learns classify article s sentence belongs corresponding extractive summary bypass lack large annotated news corpora tive summarization generating extractive summaries abstractive ones available cnn corpus keywords neural networks extractive text summarization introduction doceng competition focused automatic extractive text tion participants provided corpus news articles cnn corpus articles contained corresponding extractive tive summaries aimed train test system perform summarization task gold standard summaries contained original text minimum sentences submission methods tested larger test set consisting articles randomly chosen cnn corpus limited available training data major challenges petition prevented deep learning approach successful external corpus incorporated training set approach work based summarunner model consists layer bi directional gated recurrent unit gru recurrent neural network rnn treats summarization problem binary sequence classication lem sentence classied sequentially sentence included summary introduced modications original summarunner architecture leading better results reducing ity e brito et al fig rnn based sequence classier based word embeddings sentence averaged generate sentence embedding sentence embeddings bidirectional rnn sentence level sigmoid activation based classication layer decides sentence included summary based content richness sentence salience respect document novelty respect accumulated summary representation model operates directly sentence level instead word level sentence compute sentence vector representations means flair library sentence embeddings substitute tom layer summarunner architecture consider position sentence absolute relative logistic layer resulting architecture displayed figure code generate tive summaries according instructions established competition publicly data contrast trained model cnn articles cnn daily mail corpus limited number provided news articles matically annotated large corpus cnn articles abstractive summary available similar approach calculated score sentence article s abstractive summary finally article sorted sentences having highest score picked n sentences com zalandoresearch flair iais fraunhofer stash users dbiesner repos fraunhofer supervised extractive text summarization rnn classication table evaluation labeled news articles provided competition organizers score precision recall sentence matching gold standard evaluated model provided labeled cnn news articles dierent metrics sentences generated summary matching gold dard summary achieved scores trained model epochs displayed table evaluation conclusion approach achieved second best performance compared ods competition score dierence approaches statistically signicant additionally performance proaches hardly better traditional algorithms presented baselines simpler real value dierent approaches use cases automatic text summarization covered current evaluation valuable properties summaries vary depending use case instance ence important summary read nal user summary preprocessing step indexing pipeline interesting assess dierent techniques downstream tasks obtain better overview algorithms suitable references akbik blythe d vollgraf r contextual string embeddings sequence ing coling international conference computational linguistics pp hermann k m kocisky t grefenstette e espeholt l kay w suleyman m blunsom p teaching machines read comprehend advances neural formation processing systems nips org lins r d mello r f simske s competition extractive text summarization proceedings acm symposium document engineering pp doceng acm new york ny usa acm lins r d oliveira h cabral l batista j tenorio b ferreira r lima r franca pereira e silva g simske s j cnn corpus large textual corpus e brito et al single document extractive summarization proceedings acm sium document engineering pp doceng acm new york ny usa acm nallapati r zhai f zhou b summarunner recurrent neural network based sequence model extractive summarization documents thirty aaai conference articial intelligence
