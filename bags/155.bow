modeling comprehending summarizing textual content vinicius guilherme medeiros leandro krug jose palazzo moreira ppgc instituto informatica ufrgs porto alegre brazil vwoloszyn guimmachado wives ufrgs abstract automatic text summarization strategies cessfully employed digest text collections extract essential content usually summaries generated textual corpora belongs domain area summary nonetheless special cases found tual sources possible alternative generate summary dierent domain manner summarize texts consists graph model model allows giving importance words responding main concepts target domain found summarized text gives reader overview main text concepts relationships kind tion presents signicant number repeated terms compared human generated summaries paper present approach produce graph model extractive summaries texts meeting target domain exigences treating terms repetition problem ate proposition performed series experiments showing proposed approach statistically improves performance model based graph centrality achieving better coverage accuracy keywords graph model summarization text modeling graph centrality biased summarization introduction automatic text summarization ats systems play signicant role tracting essential content textual documents important given exponential growth textual information despite newest areas research open ended summarization issues pose challenges scientic community examples summary generated prioritizing sentences present terms specic domain cross domain summarization example dancy problem occurs wrong text modeling leads repetition content supported capes cnpq fapergs wolozsyn cross domain summarization strategy generate biased summaries generally favors subject need bias happens situations summary containing specic aspects extracted general purpose documents instance teacher wants know better educational aspects movie hoping use class looking peoples comments movie example imagine person shopping new novel hoping presents instance historical facts city story works summarization rely supervised algorithms cation regression quality results produced supervised algorithms dependent existence large domain dependent training dataset drawback strategy datasets available construction labor intense error prone documents manually annotated train algorithms correctly unsupervised models conversely interesting strategy situation textual sources need large ing set learning process common problem models redundancy happens wrong text modeling benet generation summaries repeat central sentences select set similar ones documents causes gain accuracy generates redundant summaries poor coverage text aspects meet cross domain summarization needs mitigate redundancy problem propose unsupervised graph based model generate domain summaries generated graphs able uncover main topics concepts document set documents summarization algorithm focus relevant central nodes pre determined domain corpora nodes relationships experiments combination cross domain generation avoiding redundancy improves graph based ats system achieving better coverage precision recall contributions work following unsupervised cross domain summarization depend specic annotated ing set address redundancy problem performing ranking initial centrality index improve coverage decrease redundancy considering distinct datasets results obtained experiments signicantly superior baselines analyzed rest paper organized follows section presents ground area related work section details proposed model section provides case study section describes design periments section discusses results section summarizes conclusions presents future research directions background automatic text summarization ats techniques successfully ployed user content highlight relevant information ments techniques usually employed works explored supervised learning strategies predict text relevance tionally use regression algorithms consistently improves prediction modeling comprehending summarizing textual content graphs fig illustration graph centrality steps symbols represent text words helpfulness supervised techniques need annotated corpus training process cross domains cases unavailable graph centrality widely employed unsupervised extractive marization systems graph representation documents weight sentences relevance set documents based central nodes indicate sentence represent relevant group uments let set sentences extracted input graph representation created set edges connect pairs score node usually given algorithm like pagerank hits figure depicts general steps summarization system based graph centrality builds similarity graph pairs sentences prunes graph removing edges meet minimum threshold similarity uses pagerank calculate centrality scores node greedy strategy employed centrality index produces ranking vertices importance indicate ranking relevant sentences compose nal summary known strategy basis novel unsupervised approaches pagerank computes centrality nodes edge ered vote determine overall centrality score node graph types social networks relationships considered equal importance premise underlying pagerank importance node measured terms number portance vertices related pagerank centrality function given vbu set containing neighborhood number neighborhoods strategy normally employed restrictions ensure minimal intersection sentences lack restrictions increase overall redundancy approaches wolozsyn lexrank popular general purpose extractive summarizer relies graph representation building complete graph sentence document set node edge weight dened value cosine similarity sentences centrality index node computed producing ranking vertices based importance indicates ranking relevant sentences compose summary known strategy basis recent unsupervised approaches approaches sideration repetition problem causes redundancy words present conceptual model meet cross domain summarization mands section describes unsupervised cross domain tion model post processing algorithm reduce repetition improve coverage summaries developed model developed model structures given text set graph model uses specialized text set domain bias extracted summary described necessary extract specialized summary general purpose text set example given related extracting educational aspects user comments movies domain bias model structures post processing treats problem sentences repetition figure shown cross domain redundancy free summary extracted graph model rst steps general graph based summary shown figure process starts output general process graph node page rank score represents central determined sentence figure initial page rank scores recomputed taking consideration keywords found external corpus keywords bias compute importance sentence nal specialized summary based centrality score sentences weighted presence keywords external corpora let set sentences extracted user reviews single movie rst step build graph representation set edges connect pairs score node represent sentence given harmonic mean centrality score graph given pagerank sum cies specialized keywords stated equation pseudo code cross domain scoring given algorithm represented adjacency matrix modeling comprehending summarizing textual content graphs fig illustration cross domain graph centrality building processing avoid redundancy algorithm cross domain scoring algorithm input set sentences extracted general purpose corpora amazon movies reviews corpora bias output extractive biased summary based general purpose corpora idf modied end end end return end sim keyword main steps cross domain scoring algorithm builds similarity graph pairs texts product subject lines graph pruned removing edges meet minimum similarity threshold given parameter lines best parameter obtained experiments wolozsyn pagerank centrality scores node calculated line educational corpora sentence scored according presence educational keywords line nal importance score node given harmonic mean centrality score graph sum education keywords frequencies line similarity nodes dene adapted metric cosine dierence corresponding sentence vectors idf modied tfw xtfw xidfxi tfw number occurrences word sentence employed approach described extract keywords nal corpora similarity sentences keywords extracted external corpora given following equation sim reduce textual redundancy problem developed algorithm employs clustering technique groups sentences graph sentences homogeneous separated entities group similar entities dierent groups dissimilar takes central sentence group compose nal summary graph centrality chooses sentences based ity algorithm divides graph groups sentences chose central sentence group figure literature work employing clustering paradigms provide non redundant multi view textual data agglomerative hierarchical clustering method creates hierarchy tree dendrogram sentence coverage searching purposes conceptually process agglomerating documents creates cluster hierarchy leaf nodes correspond individual sentences internal nodes correspond merged groups clusters groups merged new node created hierarchy tree corresponding bigger merged group work employed complete link hierarchical clustering rithm achieves better results experiments carried compared clustering techniques means medoids default remove stop words remaining terms sentence represented uni grams weighted known term inverse document frequency idf pseudo code decreasing redundancy displayed algorithm represents complete graph obtained ats approach based graph centrality cross domain scoring represents cluster labels extracted function nal solution containing sentences modeling comprehending summarizing textual content graphs algorithm post processing redundancy algorithm input complete graph sentences set edges represents similarity sentences centrality score node number sentences extract output ordered list sentences sort nodes end return case study explained goal presented approach build graph representation main concepts document set documents representation works cross domain summary avoiding redundancy selected application domains validate cross domain summary generation validate redundancy cross domain generation tested educational domain redundancy control tested news domain datasets employed perform experiments rst served word thesaurus implement educational bias cross domain generation collected educational website teachwithmovies twm set movies described teachers goal use learning objects inside classroom second dataset amazon movie reviews amr provides user comments large set movies interested movies appeared datasets lter applied ended movies perform evaluation evaluate post processing treats redundancy problem novel corpus comprises news texts brazilian portuguese divided groups fully employed gold standard recent works content selection automatic production summaries describe dataset details teaching movies teachwithmovies dataset collected crawler developed dierent teachers described movies website movie description challenge collecting data information standardized associated metadata teachwithmovies org index html public available icmc usp pessoas taspardo cstnews html wolozsyn noticed movies presented common information movie description rationale movie movie benets teaching subject movie problems warnings young watchers objectives movie class developed crawler extracted information movie description contains greatest educational aspects end unique movies video clips extracted matching amazon dataset use movies dataset gold standard cross domain summary generation amazon movie reviews amazon movie reviews collected timespan years consists proximately millions reviews include product user information ratings plain text review table shown statistics data table amazon movie reviews statistics dataset statistics number reviews number users expert users reviews number movies mean number words review timespan aug oct cstnews dataset group news texts topic having average sentences words comprises clusters news texts ally annotated dierent ways discursive organization rhetorical structure theory cross document structure theory annotations corpus includes manual multi document summaries cluster news pression rate relation longest text texts manually annotated high level agreement human judges cohen kappa coecient statistic measure inter rater agreement sication tasks means annotation agreement reliable similar presented works languages portuguese reason human generated summaries gold standard post processing language dependent redundancy problem observed dierent languages corpus evaluate post processing strategy modeling comprehending summarizing textual content graphs experiment design section presents experimental setting evaluate cross domain summary generation post processing reduces redundancy scribes methods employed baselines comparison educational plans adopted gold standard metrics applied evaluation details experiment performed assess approach baseline results obtained cross domain summary compared trank algorithm textrank chosen graph based ing algorithm widely employed natural language tools textrank essentially decides importance sentence based idea voting recommending considering approach edge represents vote higher number votes cast node higher portance node sentence graph important sentences compose nal summary second baseline centrality based ranking successfully recent works content tion automatic production textual summaries lexrank know ats system based graph centrality times literature comparisons purposes good performance post processing strategy aims reduce redundancy based approaches employ lexrank baseline uses tence centrality index ranking task mead implementation lexrank publicly available researching purposes framework text summarization provides set perl components rization texts written english languages chinese evaluation metrics rouge evaluation performed applying rouge oriented understudy gisting evaluation metric inspired bilingual evaluation understudy bleu specically rouge evaluation version rouge makes comparison grams summary evaluated gold standard case cross domain summaries twm lesson plans respectively ated rst words summaries obtained approach baseline corresponds median size gold standard rouge chosen measures elds machine translation automatic text summarization wolozsyn redundancy important aspect related redundancy lexical cohesion cohesive links sentences positive component mary long considered key component assessing content relevance text summarization cases improve mean redundancy summaries redundancy aect document summarizer perform comparison baseline man gold standard summary coverage extent words automatic summaries found source documents words global score assessing extent candidate summary covers text given input results subsections present evaluation results cross domain summaries section present cross domain summaries evaluation adopted baselines concerning precision recall score obtained rouge gold standard utilized experiments stated cational description extracted twm website table shows mean precision recall score considering cross domain strategy textrank gold standard baseline results presented table strategy outperformed baseline measurements carried precision dierences range percentage points rouge analyzed size gram rouge wilcoxon statistical test signicance level veried strategy statistically superior compared baseline recall dierences favor strategy ranging compared baseline distribution rouge results fig shown boxplot indicating strategy results better mean terms lower upper quartiles minimum maximal values post processing section discuss results obtained experiments adopted baselines terms coverage redundancy precision recall cstnews redundancy coverage figures post processing strategy outperformed unsupervised baseline generation summaries redundancy coverage closer human gold standard maries mean redundancy dierences range percentage modeling comprehending summarizing textual content graphs table mean rouge results achieved baseline column cross domain strategy column rouge column column values fig distribution rouge results points compared lexrank terms coverage mean ence wilcoxon statistical test signicance level veried strategy results statistically superior redundancy coverage precision recall figure strategy formed unsupervised baseline terms recall precision obtained recall mean dierences ranging compared lexrank precision mean dierences ranging cases wilcoxon statistical test signicance level veried strategy results statistically superior cases wolozsyn fig mean redundancy fig mean coverage fig mean recall fig mean precision conclusion paper presented approach generate cross domain summaries based graphs able represent main concepts document set documents proposed approach reduces text redundancy generated summaries showed approach achieved statistically rior results textrank general summary algorithm lexrank general summary algorithm proposed algorithms require training data avoids costly error prone manual training annotations compared baselines proach outperforms unsupervised techniques terms precision recall statistically reduces redundancy improves coverage easy plug standard graph centrality approach domain periments performed domains educational news attesting approach versatility finally important state found considerable number highly helpful sentences low centrality indexes lead consider investigation techniques select relevant sentences compose movies educational description important rearm approach source language independence reason consider future extend evaluation dierent languages summaries length modeling comprehending summarizing textual content graphs references aggarwal zhai mining text data springer science business media dhelaan suhaim sentiment diversication short review rization proceedings international conference web intelligence acm cardoso jorge pardo exploring rhetorical structure theory multi document summarization congreso sociedad espanola para procesamiento del lenguaje natural xxxi sociedad espanola para procesamiento del lenguaje natural sepln cardoso maziero jorge seno felippo rino nunes pardo cstnews discourse annotated corpus single multi document summarization news texts brazilian portuguese ings rst brazilian meeting carletta assessing agreement classication tasks kappa statistic putational linguistics cheng tran relin relatedness informativeness based ity entity summarization semantic web iswc condori pardo opinion summarization methods comparing extending extractive abstractive approaches expert systems tions cunha torres moreno sierra development rst spanish treebank proceedings linguistic annotation workshop association computational linguistics dias pardo discursive grid approach model local coherence multi document summaries annual meeting special terest group discourse dialogue association computational linguistics acl erkan radev lexrank graph based lexical centrality salience text summarization journal articial intelligence research ganesan zhai han opinosis graph based approach abstractive summarization highly redundant opinions proceedings national conference computational linguistics association computational linguistics kleinberg authoritative sources hyperlinked environment journal acm jacm lin rouge package automatic evaluation summaries text marization branches proceedings workshop maziero hirst pardo semi supervised ending ing rhetorical relation identication international conference recent advances natural language processing bulgarian academy sciences mcauley leskovec amateurs connoisseurs modeling evolution user expertise online reviews proceedings international conference world wide web www international world wide web conferences steering committee republic canton geneva switzerland acm org citation mihalcea tarau textrank bringing order texts association putational linguistics nobrega pardo improving content selection update tion subtopic enriched sentence ranking functions int comput linguistics appl page brin motwani winograd pagerank citation ranking bringing order web wolozsyn poibeau saggion piskorski yangarber multi source multilingual information extraction summarization springer science business media radev allison blair goldensohn blitzer celebi dimitrov drabek hakim lam liu mead platform ment multilingual text summarization saggion poibeau automatic text summarization past present future multi source multilingual information extraction summarization springer dos santos ulbrich woloszyn vieira ddc outlier ing medication errors unsupervised learning ieee journal biomedical health informatics thomas beutenmuller puente remus bordag exb text summarizer sigdial conference wan regression cross language review rating prediction ings annual meeting association computational linguistics volume short papers association computational linguistics soa bulgaria august aclweb org anthology woloszyn machado palazzo moreira oliveira krug wives saggion beatnik algorithm automatic generation educational scription movies proceedings sbie recife brazil cbie sbie woloszyn nejdl distrustrank spotting false news domains ings acm conference web science acm woloszyn dos santos wives becker mrr unsupervised algorithm rank reviews relevance proceedings international ference web intelligence acm unsupervised approach rank product reviews fuzzy systems knowledge discovery fskd eighth international conference vol ieee xiong litman automatically predicting peer review helpfulness ceedings annual meeting association computational guistics human language technologies association tional linguistics portland oregon usa aclweb anthology yang yan qiu bao semantic analysis helpfulness tion text online product reviews proceedings annual ing association computational linguistics association computational linguistics beijing china july aclweb anthology yang duan lai online public opinion hotspot detection analysis based short text clustering string distance journal beijing university technology zeng modeling helpful opinion mining online consumer reviews classication problem proceedings ijcnlp workshop nlp social media socialnlp asian federation natural guage processing nagoya japan aclweb org zhai liu jia clustering product features opinion mining proceedings fourth acm international conference web search data mining acm
