computer assisted text analysis social science topic models ryan wesslen college computing informatics university north carolina charlotte charlotte north carolina usa email edu abstract topic models family statistical based gorithms summarize explore index large collections text documents decade research led computer scientists topic models spread social science new generation data driven social scientists searched tools explore large collections unstructured text recently social scientists contributed topic model literature developments causal inference tools handling problem multi modality paper provide literature review evolution topic modeling including extensions document covariates methods evaluation interpretation advances interactive visualizations aspect relevance application social science research keywords computational social science computer assisted text analysis visual analytics structural topic model introduction topic models framework statistical based rithms identify measure latent hidden topics corpus text documents despite wide use computer science research topic models remained largely absent average social scientist analytical toolkit historically social science text analysis instead focused human coding dictionary based methods semi automated require high pre analysis costs implementation problem magnied considering tremendous increase volume variety unstructured text documents social scientists study overcome problem social scientists started adopt computer assisted text analysis techniques like supervised learning topic models research goal amplifying augmenting social science analysis replacing unlike computer scientists typically use machine learning techniques prediction social scientists found use machine learning analysis latent variables previously measured untestable sequential assumptions ultimately rise assisted text analysis tools social science research major drivers emerging eld computational social science purpose paper survey literature computer assisted text technique topic models provide background importance social science research overview leads newly created structural topic model stm extends general topic model framework estimate causal effects text documents section review evolution topic models introducing latent dirichlet allocation lda related seminal models consider computational methods topic models discuss extensions lda based framework include document covariates model section explore tools application topic models including methods evaluation measures interpretation visualization interfaces section discuss major contributions social scientists topic model literature structural topic model stm techniques handle modality provide examples social science applications use techniques texts like open ended survey responses political rhetoric social media consider ongoing limitations methodology future opportunities topic models social science research relation computational social science explainable articial intelligence xai evolution topic models topic models identify measure latent topics corpus text documents topic models called generative models assume observable data generated joint probability variables interpreted topics lda workhorse topic model bayesian tiered mixture model identies word occurrence patterns interpreted topics section summarize key properties work reviewing evolution topic models starting seminal models review model extensions advances computational methods model framework lda seminal papers generalization approaches assisted text analysis natural language processing nlp statistical based algorithms like topic models unlike nlp methods tags parts speech grammatical structure statistical based models like topic models largely based bag words bow assumption bow models collection text documents quantied term matrix dtm counts occurrence word columns document rows case topic models like lda dtm model inputs number topics bow approach provides key advantages plicity statistical properties expense ignoring word order example bow approach reduces information contained collection text documents word document counts implication word counts ignores word order opposite nlp methods parse language structure accounting word order bow methods perform poorly micro level problems like question answer require exact semantic meaning large collections documents sample size bow assumption provides theoretical foundation richer set statistical methods mixture models assumption exchangeability ultimately vantage underpins statistical based methods success macro document level summarization problems large collection inter related documents early motivation topic models goal dimensionality reduction document term matrix large collections documents corpora example deerwester presented rst predecessor models latent semantic indexing lsi applying singular value decomposition svd linear algebra dimensionality tion technique reduce document term matrix latent factors goal identify broad semantic correlation structure documents removing noise formative factors later landauser dumais extended lsi model create latent semantic analysis lsa model methods improved substituting term frequency inverse document cies idf weightings place raw term counts hofmann identied major drawbacks lsa approach lacked theoretical foundation method svd relied gaussian noise assumption justied word counts document term matrix second lsa account polysemy multiple uses words different contexts address problems hoffman introduced probabilistic latent semantic index plsi model addition probabilistic mixture component lsa model assuming word generated word probability distribution interpreted topic seminal models set stage blei extend predecessor models build workhorse model lda key contribution lda tend hofmann plsi model include second probability mixture component document level assuming documents mixture topics addition yielded tiered model core component typical topic model framework observed words assumed generated joint probability mixtures documents mixture topics topics mixture words topic dened unique distribution words yields algorithms second output word topic matrix word topic matrix provides conditional probability word row given hidden topic column probability distributions researcher rank order word topic determine common word use ding different related methodology non negative matrix factorization nmf theoretically identical plsi approaches maximizing objective function difference methods approach differs inference method referring topic similar idea singular value decomposition svd earlier topic models like latent semantic analysis lsa probabilistic mixture nature lda acts similarly dimensionality reduction process reducing information document large number columns words smaller number columns topics consequence introduction mixture ponents lda based framework problem intractability fact like bayesian methods introduction mixture components allowed theory measurement latent variable topics expense ability measure precisely optimal model exponentially large potential solutions topic values problem lead question best approach compute topic models computational methods following introduction lda major theme topic modeling literature computational methods topic models given problem intractability computing evidence marginal probability observations analytical solution goal computational methods topic model inference tational efcient method best approximates terior general common approaches topic model inference sampling based methods mcmc gibbs sampling variational inference sampling based rithms simulate samples posterior approximate true posterior gibbs sampling common sampling method introduced topic model inference grifths steyvers uses markov chain estimate sequence dependent random variables asymptotically serves posterior distribution ultimately based methods like gibbs sampling advantages theoretically backed unbiased tationally convenient implement downside approach slow large inputs number documents words topics goal alternative approximating posterior sampling variational inference methods transform problem optimization problem context families distributions hidden variables topics closely estimates actual posterior words variational inference attempts tightly estimate posterior simpler distribution includes free variational parameters optimization arguments blei introduce variational methods topic model inference expectation maximization algorithm figure provides graphical models left simplied model variational inference algorithm use variational inference lda model simplied removing edges variables introducing free variational parameters optimization problem uses kullback leibler divergence best minimize estimated posterior true posterior theoretical model lda right discussed section normally highest probability words conditioned topic serve aid researcher interpretation topic left graphical model latent dirichlet allocation lda fig right graphical model variational distribution variational inference lda blei fig mccallum example stream model extension mimno algorithm step process variational distribution estimated estimated parameters new variational parameters chosen variational inference optimization problem process repeated convergence threshold met hoffman extended variational inference introduce faster online batch algorithm massively scale lda large corpora streaming data ultimately given sampling based variational ence methods estimates exact solutions method perfect decision depends trades speed complexity accuracy simplicity required problem hand section introduce basic lda framework generalized include document metadata variables algorithm require modications computational methods later section discuss metadata able extensions impact computational methods possible introducing structural topic model stm model extensions document metadata second theme topic modeling literature deals inclusion metadata variables model rst examples model author topic model proposed rosen zvi original motivation explicit point author direct impact topics discussed publication biologist likely write topics biology sociology politics contrast lda account document variables like author fails incorporate author model lda way analyze impact author post hoc comparing model outputs topics compare relative author noted downside approach model likely effective omitting known variable affects topic proportions address problem rosen zvi introduced author topic model incorporate author attribute modifying lda assumption author documents multinomial distribution topics soon metadata topic model extensions created variety metadata attributes like time dynamic topic model geography geographical topic model emotion emotion topic model given large collection metadata topic model tensions mimno mccallum categorized metadata extension models groups stream stream models key difference approach role metadata variables process generate text instance stream approach metadata fig example stream model extension mimno mccallum like text assumed generated hidden topics approach topics word distributions distributions metadata variables figure provides example plate notation stream model gure metadata variables words text conditionally generated hidden topics common example approach supervised latent dirichlet allocation slda model stream approach algorithm tioned metadata covariates document topic distributions mixtures covariate specic distribution classic example approach topic model dynamic topic model essentially stream models learn assignment words document set entities addition incorporating metadata model information like topic model extensions include additional word context graphical network relationships cal topic structure example hidden markov model hmm extended normal bow assumption facilitate consideration word context topic model framework case network data link topic model relational topic model rtm additional topic models incorporate relational based information model analysis finally teh introduce generalized hierarchical structure topics alleviates problem number topics allows analysis different topic levels main advantages topic models exibility incorporate multiple different computational methods alternative specications section practical considerations use apply topic models introducing social science applications section iii tools model application interpretation model selection visualization section review research focused pre processing interpretation evaluation analysis topic models necessarily changing underlying model framework like discussed section research critical implementation topic models application social science research pre processing critical step analyze text process quantifying text process called pre processing series decisions researcher makes clean normalize text goal removing potential noise maximize analysis underlying signal researchers overlook steps relying instead default rules questioning merits recent research found text analysis methods like topic modeling susceptible potential forking paths leave results subject initial coding decisions set rules pre processing steps necessary need dened quality quantity style underlying text model selection prediction interpretability trade question select validate topic model specications number topics model framework depends researcher objective predictive modeling researcher goal build model best dict sample future documents log likelihood perplexity measures researchers goal exploration knowledge discovery human judgment interpretable topics precedence holdout prediction initially topic model literature prediction accuracy key goal model evaluation wallach outlined different evaluation methods lda gibbs sampling consider approaches evaluating topic models maximizing held documents likelihood plexity document completion long documents trained document evaluated model ability correctly complete document methods like harmonic mean importance sampling document completion methods inaccurate tort relative advantage model versus model instead recommend chib style estimator left right algorithm accurate evaluation methods chang explored trade tween prediction interpretability word sion tasks found counter intuitive result highly predictive topics tend negatively correlated pretability semantic coherence introduced mimno measure internally consistent words topics hand exclusivity measure identify words high probabilities topics topics roberts argue topic cohesive exclusive likely semantically useful finally researchers studied effectiveness topic modeling controlling key factors limitations wallach results tested gibbs sampling based inference vanilla lda hyperparameters number topics document sample size document length wallach explored effect relaxing lda prior distribution assumptions including non symmetric dirichlet parameters topic word topic matrices asymmetric priors document topic distribution provide substantial advantages asymmetric priors provide benet word topic distribution taddy explored estimation methods choosing optimal number topics block diagonal approximations information matrix goodness analysis likelihood based model tion systematic review topic model performance tang analyzed lda performance controlling limiting factors document length number documents prior distribution hyperparameters considering simulated real datasets wikipedia new york times twitter recommendations argue sufcient number documents important factor ensure accurate inference example lda difcult running small sample thousand documents second length document matters matters social media data like twitter messages messages characters alternative cite natives like aggregating messages transform documents user level expand size documents collections topics lend statistical inference methods inefcient fourth lda performance affected separated underlying topics relative euclidean measure variability hyperparameters important depending number topics documents example recommend lower alpha dirichlet parameter documents topics high alpha documents topics visualizations section review semi automation methods alyzing topic models visualizations argue topic models suffer interpretation problem requires need interactive system end users topic results perfect include bad topics perfectly align end user judgment intuition similar argument chang address problem argue systems allow end user annotate model results incorporate feedback model output identify social science addition digital humanities information studies discipline greatly benet interactive systems implementing topic models emphasize social science eld leave problem social scientists extensive domain knowledge lack machine learning expertise modify topic model algorithms shortcoming argument omit role visualizations play interactive systems fail recognize body research visualization community extended proposed different applications visualizations interactive systems dou liu argue visual interfaces allow decision makers explore analyze model results point important considering application topic models non computer scientists like social entists programming computational training run algorithms major motivation use visualizations analyzing topic models output large researcher absorb manually example lda output large datasets word topic document topic matrices size proportional number documents terms topics larger corpus larger output difcult researcher analyze results general common approaches alizing topic models topic oriented time oriented approach differs based important element interest topic oriented visualizations focus relationship words topics word topic matrix document topics topic matrix approaches focus task document summarization information retrieval relationships documents common examples approaches include matrix representations like termite serendip figure parallel coordinates visualizations paralleltopics chuang provide general design framework topic oriented interactive visual systems based analyst makes inference topics interpretation actual perceived accuracy analyst inference trust interfaces like hierarchicaltopics generalized model facilitated interfaces focus hierarchical structure ics aid drill multiple levels document summarization new research network graphs represent correlations topics especially coupled models exible correlation structure like ctm fig topic oriented visualizations including termite model chuang right serendip model alexander hand documents time oriented twitter messages news articles aided dependent visualizations aid exploring trend evolution lead lag effect event detection relative topics tiara interface created visualize topical trends enhanced stacked graph similarly textflow introduced goal exploring evolution topics including identifying topics merge split time textpioneer visual interface introduces problem lead lag relationships exploring topic results lead lag problem researcher needs understand relationship tween corpora especially case corpus social media lead information appear corpus news articles recount information spread social media oriented component explored visual interfaces event detection analysis example leadline visual analysis system identify explore events detecting common words topics short discrete bursts major consideration use visual terfaces topic models includes type data model simplest approach homogeneous data focus single corpus topics stem corpus deeper insight found inclusion heterogeneous data sources append document metadata corpus example recent approach combine sources include topicpanorama interface combines text multiple data sources news articles twitter messages provides network graph link sources figure avenue topic analysis includes impact analyzing topics streaming data sources like twitter social media platforms fig integration multiple corpora topicpanorama liu lda based topic model applications social sciences rst applications topic models social science literature comes quinn paper laid foundation social science mainly political science application topic models ways paper directly compares topic model relative text analysis methods reading human coding dictionary based pervised learning comparing contrasting costs benets method second quinn set list criterion based concepts goals based traditional social science content analysis model evaluation argue considered applying topic models authors modied lda analysis continuous time model limited number mentioned introduction paper cost benet comparison justied benet computer assisted text analysis tools like topic models relative traditional text analysis research like human coding based methods criterion semantic validity convergent construct validity discriminant construct validity predictive validity hypothesis validity semantic validity coherent meaning interpreting word topic probabilities convergent construct validity extent results align existing measures benchmarks known truths discriminant construct validity measures results depart existing benchmarks predictive validity ability results correctly predict external events hypothesis validity extent results effectively test hypotheses fig comparison lda dynamic multitopic model expressed agenda model grimmer stewart topics speech opposed mixture assumed lda model named dynamic multitopic model represented figure unlike lda model single membership mixture model speech assigned unique topic day assumed mixture speeches shown figure analogous lda assigns word topic assumes document mixture topics important rst social science based topic model modications created test theoretically driven hypothesis social science research similarly grimmer created modied topic model analyze political rhetoric expressed agenda model individual senators press releases shown figure expressed agenda model modied lda framework single membership mixture model assumed press release assigned single topic senator press releases corpus assumed mixture topics like dynamic multitopic model units measurement topic assignment level modied standard lda allow author test political theory senator divides attention multiple political issues represented explicit press releases social scientists considered lda analyze text social media particular twitter novel example comes health informatics paul dredze twitter messages authors modify lda create ailment topic aspect model atam goal identifying health related keywords automatically authors discover interpretable topics seasonal allergies exercise obesity correlate signicantly geographic survey data figure provides ndings comparing normalized frequency score trends external survey results allergies approaches identify allergy related tweets words allergy allergies lda atam key methodological contribution model inclusion external background words represent health aspects model identify topics describe aspect topics relative document level metadata time geography tweet limitation approach results correlate external gallup benchmarks work demonstrate statistical signicance relationship twitter topics effect public awareness gallup results core approach lacks causal inference mechanism explain signicance discussions twitter authors explore output fig differences estimated responsiveness different constituent follower groups tests barbera application lda twitter attempts provide causal inference mechanism comes political science barbera paper authors analyzed responsiveness members united states congress constituent conversations twitter order categorize topics lda tweets constituents members congress measured variance topics time estimate members fig monthly allergy prevalence tweets methods gallup survey results paul dredze congress lead follow constituents political issues employing granger causality testing running lda key contribution paper use temporal causal framework granger causality lda provide higher level statistical signicance effect covariates author time analyze result divided members congress constituents groups groups political party democrat publican members congress hardcore constituents uninterested constituents categorized topics lda categories democrat owned owned non political political topics ran post hoc regressions topics groups day lags topic proportions groups independent variables figure provides standard test results topic rows columns group relationship members congress responsive constituents especially prominent issues hardcore constituents little evidence members congress inuence topics constituents discuss publicly novel contribution estimating causal effects lda approach limiting factors analyze author time directly model instead employing aggregation approach suggested combined tweets author day modify denition document tweet collection tweets day author aggregation enables control document covariates time author employing lda mechanism directly control covariates second use regression post hoc generative topic model noted appendix roberts problem approach measurement uncertainty lead spurious results general theme applications represent ity lda based framework modied address unique theoretical question specic document level variate time author geography grimmer stewart recognized requiring social scientists tune model task daunting task provides motivation deriving causal inference component lda framework asking questions involving document covariates facilitate hypothesis testing response problems roberts introduced structural topic model stm general causal inference framework hypothesis testing document covariates structural topic model multi modality section review literature social scientists reconcile major problems standard topic model framework lack causal inference multi modality column represents test measuring followers impact member congress topic proportions column opposite member congress impact followers topic proportions approach stage lda run stage followed running regression topic proportions conditioned covariate interest stage rst issue address standard stream metadata topic models author topic dynamic point standard error estimates facilitate cal hypothesis testing problem computational methods topic model inference hard problem provide local optima guarantee global optima termed multi modality problem threatens stability topic model output lead researchers question stumble result completely chance stm model rst major critique topic models output provides point estimate word topic probabilities condence intervals facilitate statistical hypothesis testing problem especially important stream sions include metadata affect topic proportions example researchers estimate topic proportion different covariate levels statistical condence provided standard error estimates problem directly contrary tradition causal inference employs statistical condence social sciences termine causation example effort reconcile problem roberts roberts introduced structural topic model stm incorporating generalized linear model glm framework document metadata extending elements previous topic model extensions ctm dmr sage let rst start ctm blei lafferty troduce correlated topic model ctm provide realism original lda model incorporates exible correlation structure independence assumption assumed lda model replaces dirichlet assumption topic proportions lda logistic normal distribution main advantage ctm versus lda improved predictive power dirichlet based model predict items based latent topics observations items associated suggest additional topics correlated conditionally probable topics ctm predict like topic model extensions ation model assumptions comes expense model complexity intractability existing methods case simulation techniques like gibbs sampling longer possible markov chain monte carlo mcmc process metropolis hastings untenable given size scale alternative blei lafferty introduce fast variational inference approximates posterior butions ctm approach underpins computational framework stm stm thought identical ctm metadata covariates included models dirichlet multinomial model dmr sparse additive generative model sage provide framework introducing document metadata covariates dmr model applies introduction metadata covariates affect topic proportions model noted earlier simulation approaches ideal topic models theoretically backed unbiased computationally convenient fig roberts covariate inference lda stm simulated datasets replaces lda assumption dirichlet prior topic distribution dirichlet multinomial regression given covariates hand researchers found approach dirichlet multinomial regression feasible word distributions eisenstein identify main problems applying multinomial framework word distribution increase parameters computational complexity lack sparsity especially problem considering word topic relationship large corpus documents extensive vocabulary address problem introduce sparse additive generative model sage sage consists alternative framework uses ations log frequency benchmark distribution main advantages model cutting number parameters approach reduces overtting issues combine generative facets simple addition log space avoiding need latent switching variables given inclusion predecessor models tant review terminology distinguish types covariates model prevalence content prevalence covariates document level attributes affect topics communicated document words prevalence covariates impact topic proportions dmr model hand content covariate document level attribute affects topics conveyed document case content covariate modies words communicate topic word proportion dene topic similarly content covariate sage component stm model stm inference like predecessor models act posterior intractable restricts computational methods possible address intractability roberts introduce partially collapsed variational maximization algorithm inference estimation problem inference estimation model non conjugacy logistic normal distribution replaces dirichlet prior distribution assumed lda posterior distribution multinomial account non conjugacy introduce laplace approximation non conjugate elements model current stm computation allows content covariate covariate multiple levels researcher approximate multiple variables interaction levels variables example instead having binary content covariates gender male female treatment yes approximated levels covariate male yes male female yes female fig lda stm sage dmr sample performance roberts roberts analyze estimation benets stm relative lda stms sub component models like ctm sage dmr metadata generated topic processes stm outperforms lda covariate inference sample prediction figure provides formance lda stm samples simulated dataset including random component generated continuous non linear covariate lda average able identify non linear pattern covariate topic noise component lda robust consistently identify true linear pattern example cases model estimates inferred reverse pattern true shape value hand stm able correctly identify pattern consistently datasets conclusion incorporating covariates directly algorithm post hoc analysis condent stm consistently detect pattern average lda ultimately improved performance measuring covariate relationships yield model consistently perform post hoc lda sample prediction figure analysis dataset lda sage dmr stm model separately stm largely driven inuence dmr best performance sage lda performed worse candidate sets different number topics major advantages stm model model facilitates statistical based framework facilitating hypothesis testing causal impact ment metadata affects topics vary document fact model allows general relationship framework outside typical linear relationships searchers test non linear patterns log spline interaction terms second model introduces enhancements computational methods order model feasible modeling methods model evaluation interpretation handling multi modality authors introduce open source package accompany paper package facilitates implementation model wider audience social scientists providing model high level traditional level languages topic models methods previously available java mallet python gensim able model non linear patterns extension allow spline transformations covariate interactions fig posterior predictive checks ppc instantaneous mutual information roberts despite advancements stm multiple limitations model remains intractable large number covariates content covariate second model produce statistical testing prevalent covariates content covariates given topic proportions zero sum property sum interpretation covariates marginal effects stm difcult increase topic proportion tied decrease similar magnitude topic proportions model uses approximation methods complex simulation based mcmc gibbs sampling methods model complex lda output account differences input covariates point mind consider role explainable interactive visualizations play future research stm conclusion paper multi modality second problem topic models lack stability inherent computational complexity topic model inference hard problem hardness leads problem multi modality optimization problem like maximum likelihood solved locally certainty solved globally multi modality important algorithm output change initialization parameters words different starting parameters alter results threatened legitimacy approach results implication directly solved product algorithms hardness argue solution researchers use improved initialization spectral methods posterior predictive bility checks achieve best possible local optima chuang provide example visualization interface help researchers understand effect multi modality stability results good initialization approach needs balance computational cost implementation write footnote connecting hard plexity multi modality local modes difcult state easily argue hardness sufcient prove algorithm easily solved global convergence roberts note sensitivity starting positions known computer scientists infrequently discussed relative model improvement optimizing initial state stm model researcher option spectral initialization provides quick starting point minimizes chance nding sub optimal local minima approach stm run standard lda dataset use lda results help determine initial state stm roberts lda results initialization improves model results gibbs sampling leads faster convergence lda initialization help increase average quality results simulations instead recommend spectral learning approach provides robust initialization computational complexity lda results spectral approach utilizes connection lda non negative matrix factorization provides theoretical antees optimal parameters recovered essentially approach makes stronger model assumptions matrix decomposition elements non negative order avoid problems multi modality roberts identify practical limitations spectral initialization requires large amounts data perform adequately second modication model tions potential leading interpretable models posterior predictive checks ppc provide insight model assumptions hold figure vides ppc instantaneous mutual information topics plot representing likely words topics examples model assumptions hold signicant difference observed black circle simulated reference distribution open circles instance sars avian flu topic words sar bird observed drastically outside reference distribution indicates words indicate likely better split separate topics deviation like jeopardize entire topic model results goal analyzing ppc identify systematic errors caused poor local optimal solution initialization like multiple topics threaten legitimacy model chuang provide interactive solution problem multi modality topiccheck visualization assume second provides formal way quantifying content prevalance effects topics especially treatment variable cheaper consistent semi automated process application stm use anes national election studies survey dataset dents questions related election addition open ended survey responses related election dataset includes individual covariates respondent including voting issue party identication education age survey randomly assigned respondents test control groups group subjected ferent treatment simulate intuitive test reective control thinking treatment variable collected test political science theory role intuition reection shapes decision making demonstrated ended responses analyze results authors compare nding stm model relative human coders previously analyzed dataset sions aggregate stm categorized responses similar topics human coders second stm recovers covariate relationships closely identical anes human coders rst ndings suggest stm job similar man coders lower cost automation hiring multiple human coders stm additional advantage required assumptions topics stms unsupervised approach naturally found occurring topics requiring know advance topics likely discussed disadvantage stm low incidence pre determined categories unlikely identied stm unsupervised approach likely identify topics instead stm writing style topics frequent words like relevant occur unsupervised approach volume stop words benets stm largely outstrip costs relative human coding example signicant application stm litical scientists analyze political rhetoric rst examples come milner tingley analyzed text lobbying reports estimate impact white house lobbied specic issue economic interest groups tend higher inuence topics high distributional impacts low information asymmetries like military spending topics like military spending economic interest groups likely directly solicit white house instead targeting white house direct lobbying efforts efforts policy focused stm application political scientists includes measurement media bias news articles related china different international media outlets dataset news articles roberts analyzed difference prevalence content media outlets xinhua china bbc great britain jen japan united states afp france fig topiccheck iterations topic stm assess topic stability chuang interface assess stability topics multiple runs stm figure shows topiccheck iterations topic stm dataset political blogs rectangle topic column run stm topics aligned stm iteration horizontal groups rows topics aligned topics different stm run included baseline axis key goals visualization determine robust stable topic different stm iterations example row including words like barack obama topics models feel condent aligned topic robust hand topic row nancial crisis topic stm iterations infer topic stable topics aligned topics stm iterations chuang ndings suggest need consider topic model single topic capture perspectives dataset contribution paper analyzing impact including excluding rare words stability topics novel approach provide users interactive understanding impact pre processing step like sparse word removal potentially signicant impact nal topics stm applications social sciences stm applied multiple areas social science including open ended surveys political rhetoric social media massive online open courses moocs roberts provide rst extensive application stm open ended survey responses traditionally human coding common methodology social scientists analyze open ended survey responses authors argue stm key advantages unsupervised algorithm stm allows researcher discover topics data rst paper introduced stm provided simple applications open ended surveys media bias news articles analyses covered paragraphs provide details model including model setup selection validation acknowledge survey analyses simply ignore open ended survey responses favor closed ended surveys given lack tools analyze results fig likely words topic falungong conditioned news source left estimated topic proportion source right roberts topics related rise china communicated ferent media sources found chinese based media outlet xin general positive view related topics international media sources covering different language sial topics like chinese dissidents protesters example figure provides graphics relating topic relating falungong movement chinese religious group chinese government outlawed leading protests government crackdown participants left represents different words characterize topic conditioned media source content covariate xinhua xin words like illegal smuggler criminal describe movement illegal operation western media outlets like associated press french agence france presse afp characterized movement language characterizing movement protest criminal operation example afp conditioned topic words include protest dissident movement crackdown stm measure difference topic proportion outlet topic example falungong topic right figure shows estimated topic proportions condence intervals media outlets xinhua covered falungong topic frequently western media outlets like afp statistical signicance addition political news rhetoric applications stm social scientists include social media messages particular twitter online course feedback lucas analyzed bilingual social media messages automated machine translation estimate effect language arabic chinese twitter users topics edward snowden sachdeva stm analyze smoke related tweets potential temporal effects wildres users tweets relative individuals reside work close affected areas reich analyzed use massive online mooc course feedback scale open ended course responses reich extended work moocs connected political rhetoric identify political discussions courses ultimately given stm recent introduction examples represent handful early applications technique begins mature researchers learn methodology doubt number range applications begin increase rapidly near future conclusion future research rarely social scientists topic els offer social scientists innovative objective way measure latent qualities large unstructured datasets like social media open ended surveys news research publications topic models machine ing frameworks combined causal inference tools represent signicant opportunity social scientists answer society large scale problems particular stm represents example integrating machine learning topic models causal inference mechanisms generalized framework applied social science problems major impediment expansion stm machine learning algorithms general social scientists high knowledge barriers use models given quick development models social scientists lack training experience machine learning computational ming implement analyze topic models address concern potential research opportunity stm model explainable user interface visualization aid social scientists hypothesis testing large collections text documents importance opportunity exemplied darpa recent explainable articial intelligence xai program inherent problem machine learning niques tasks decision makers lack explanation fig explainable articial intelligence xai darpa specic prediction choice algorithm instead goal xai program provide explainable features traditional machine learning techniques explainable user interface visualization combine human insight predictions model answer question structural topic modeling directly program approach interpretable models learn structured interpretable causal models figure provides graphic representing role explainable user interfaces machine learning tasks like stm inference key research opportunity stm velopment explainable intelligent interactive system analyze interpretation model evaluation multi modality pre processing validation interface built integrating high level visualization tools like shiny vega lite provide robust set tools minimal coding written interface easily combine packages like stm widespread use appendix appendix appendix stm package package stm introduced roberts facilitate widespread use stm users key advantage stm package includes multiple methods posterior predictive checks interpretation data preprocessing model selection static visualizations figure provides outline functions stm package categorized different functionalities appendix appendix word embedding models glove models generally topic models larger work language models called vector space models approach language encoded vector representations based addition interpretable models program cites proaches deep explanation model induction interfaces measure impact processing stemming stop words help researchers determine impact model results stm based visualization packages stmviz stmbrowser functions limited fig functions stm package roberts distributional hypothesis language words similar context words similar meanings interpretation bag words models like lsa lda considered count based models encode language series vector counts mentioned earlier downside approach ignores context words obvious deciency considering semantic meaning alternatively context based models new generation vector space models encode word text vector framework models called word embedding neural language models simply predictive models rst example context based models introduced mikolov models continuous bag words cbow skip grams unlike traditional bag words approaches treated word like atomic unit approach considered rolling window context words build vector space model provided deeper semantic meaning facilitating scalability millions words documents difference models reversal model inputs outputs cbow model uses list words words best predict word likely similar context alternatively skip gram model uses given word predict likely words similar context building framework pennington socher manning unied vector space models combining features count based models like lsa lda context based models like robust model named glove global vectors word representations acknowledging deciencies count based models motivated model pennington socher manning argue models opposite lem analyzing local context words approach fails utilize statistical properties provided count based approach ultimately approach resulted better predictive model produced deeper semantic meanings neural language structure connected directly related breakthroughs tion deep learning text analysis references blei probabilistic topic models communications acm quinn monroe colaresi crespin radev analyze political attention minimal assumptions costs american journal political science grimmer stewart text data promise pitfalls automatic content analysis methods political texts political analysis grimmer social scientists big data machine learning causal inference work political science politics lazer life network coming age computational social science science new york wallach computational social science collaborative future computational social science discovery prediction roberts stewart tingley airoldi structural topic model applied social science advances neural information processing systems workshop topic models tion application evaluation roberts structural topic models open ended survey responses american journal political science blei lafferty correlated topic models neural information blei mcauliffe supervised topic models neural information processing systems processing systems teh jordan beal blei hierarchical dirichlet processes journal american statistical association gelman loken statistical crisis science american scientist denny spirling text preprocessing unsupervised learning matters misleads unpublished manuscript dep polit sci stanford univ inst quant soc sci harvard univ com abstract schoeld thompson mimno quantifying effects text duplication semantic models emnlp schoeld magnusson thompson mimno derstanding text pre processing latent dirichlet allocation acl workshop women nlp winlp schoeld magnusson mimno pulling stops rethinking stopword removal topic models eacl schoeld mimno comparing apples apple effects stemmers topic models tacl vol mimno mccallum topic models conditioned arbitrary features dirichlet multinomial regression uncertainty cial intelligence uai eisenstein sparse additive generative models text international conference machine learning icml gruber rosen zvi weiss hidden topic markov models proc conference articial intelligence statistics liu niculescu mizil gryc topic link lda joint models topic author community proc international conference machine learning acm blei jordan latent dirichlet allocation chang blei hierarchical relational models document journal machine learning research networks annals applied statistics roberts stewart airoldi model text experimentation social sciences journal american statistical association chang boyd graber wang gerrish blei reading topic models neural information tea leaves humans interpret processing systems deerwester dumais furnas landauer harshman indexing latent semantic analysis journal american society information science landauer dumais solution platos problem latent semantic analysis acquisition induction representation knowledge psychological review hofmann unsupervised learning probabilistic latent semantic analysis machine learning ding peng equivalence non negative matrix factorization probabilistic latent semantic indexing comput stat data analysis crain zhou yang zha dimensionality reduction topic modeling latent semantic indexing latent dirichlet allocation mining text data aggarwal zhai eds springer blei lafferty topic models text mining theory applications grifths steyvers finding scientic topics proc national academy science hoffman blei bach online learning latent dirichlet allocation neural information processing systems rosen zvi grifths steyvers smyth author topic model authors documents uai proc conference uncertainty articial intelligence blei lafferty dynamic topic models proc international conference machine learning acm eisenstein oconnor smith xing latent variable model geographic lexical variation emnlp rao mao wenyin sentiment topic models social emotion mining information science mimno wallach talley leenders mccallum optimizing semantic coherence topic models proc conference empirical methods natural language processing bischof airoldi summarizing topical content word frequency exclusivity icml wallach murray salakhutdinov mimno evaluation methods topic models proc international conference machine learning wallach mimno mccallum rethinking lda priors matter neural informational processing systems taddy estimation selection topic models proc international conference articial intelligence statistics aistats tang zhao understanding limiting factor topic modeling posterior contraction analysis journal machine learning research hong davison empirical study topic modeling twitter proc workshop social media analytics acm boyd graber satinoff smith interactive topic modeling machine learning oct dou liu time oriented visual text analysis ieee computer graphics applications chuang manning heer termite visualization niques assessing textual topic models proc international working conference advanced visual interfaces acm alexander kohlmann valenza witmore gleicher serendip topic model driven visual exploration text corpora proc ieee conference visual analytics science technology vast dou wang chang ribarsky paralleltopics probabilistic approach exploring document collections ieee visual analytics science technology ieee chuang topiccheck interactive alignment assessing topic model stability weiss schlkopf platt eds proceedings naacl hlt cambridge mit press chuang ramage manning heer interpretation trust designing model driven visualizations text analysis proc acm annual conference human factors computing systems acm dou wang ribarsky hierarchicaltopics visually exploring large text collections topic hierarchies ieee tvcg cui liu wai hierarchical topics evolve large text corpora ieee trans vis comput graphics wang liu liu chen zhu guo topicpanorama picture relevant topics ieee trans vis comput graphics wei tiara visual exploratory text analytic system proc acm sigkdd international conference knowledge discovery data mining liu zhou pan song qian cai lian tiara interactive topic based visual text summarization analysis acm trans intelligent systems technology cui textow better understanding evolving topics text ieee trans vis comput graphics liu chen wei yang zhou exploring topical lag corpora ieee trans knowl data eng dou wang skau ribarsky zhou leadline interactive visual analysis text data event identication exploration proc ieee conference visual analytics science technology vast liu yin wang cui cao pei online visual analytics text streams ieee trans vis comput graphics milner tingley sailing waters edge domestic politics american foreign policy united states princeton university press lucas nielsen roberts stewart storer tingley computer assisted text analysis comparative politics political analysis feb sachdeva mccaffrey locke social media approaches modeling wildre smoke dispersion spatiotemporal social scientic investigations information communication society reich tingley leder luis roberts stewart computer assisted reading discovery student generated text massive open online courses journal learning analytics reich stewart mavon tingley civic mission moocs measuring engagement political differences forums association computing machinery learning scale chuang computer assisted content analysis topic models exploring multiple subjective interpretations conference neural information processing systems nips workshop human propelled machine learning montreal canada darpa explainable articial intelligence xai darpa darpa mil attachments darpa pdf kulesza burnett wong stumpf principles explanatory debugging personalize interactive machine learning proc international conference intelligent user interfaces shiny rstudio rstudio com june wongsuphasawat moritz anand mackinlay howe heer voyager exploratory analysis facted browsing visualization recommendations ieee trans visualization comp graphics grimmer bayesian hierarchical topic model political texts measuring expressed agenda senate press releases political analysis satyanarayan moritz wongsuphasawat heer lite grammar interactive graphics ieee transactions ization computer graphics jan baroni dinu kruszewski count predict tematic comparison context counting context predicting semantic vectors acl mikolov chai corrado dean efcient estimation word representations vector space arxiv preprint pennington socher manning glove global vectors word representation emnlp bengio ducharme vincent janvin neural bilistic language model jmlr lecun bengio hinton deep learning nature paul dredze discovering health topics social media topic models plos barbera bonneau egan jost nagler tucker leaders followers measuring political responsiveness congress social media data working paper greene econometric analysis harlow pearson tion roberts stewart tingley stm package structural topic models package version mccallum mallet machine learning language toolkit umass edu rehurek sojka software framework topic modelling large corpora proceedings lrec workshop new challenges nlp frameworks fong grimmer discovery treatments text corpora proceedings annual meeting association computational linguistics sontag roy complexity inference topic models advances neural information processing workshop applications topic models text roberts stewart tingley navigating local modes big data case topic models data analytics social science government industry new york cambridge university press gelman bayesian data analysis boca raton chapman hall crc arora practical algorithm topic modeling provable guarantees proc intl conf machine learning acm mimno blei bayesian checking topic models proc conference empirical methods natural language processing
