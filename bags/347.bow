mast multimodal abstractive summarization trimodal hierarchical attention aman khullar iiit hyderabad hyderabad india aman udit arora new york university new york usa edu abstract paper presents mast new model multimodal abstractive text tion utilizes information modalities text audio video timodal video prior work multimodal stractive text summarization utilized formation text video modalities examine usefulness challenges deriving information audio modality present sequence sequence trimodal hierarchical attention based model comes challenges letting model pay attention text modality mast outperforms current state art model video text points terms content score points terms rouge score dataset multimodal guage understanding introduction recent years dramatic rise information access videos facilitated proportional increase number sharing platforms led enormous information accessible help day day activities accompanying scripts automatic speech text transcripts videos present information textual modality information lengthy incomprehensible verbosity limitations user experience information access improved recent advancements eld multimodal text summarization multimodal text summarization task condensing information interacting indicates equal contribution aman khullar presently gram vaani paper appear rst emnlp workshop nlp text modalities output summary ated output summary unimodal modal zhu textual summary turn extractive abstractive task extractive multimodal text summarization volves selection concatenation portant sentences input text altering sentences sequence way selection tant sentences visual acoustic cues corresponding visual auditory modalities hand task abstractive modal text summarization involves identication theme input data generation words based deeper understanding material tougher problem solve alleviated advancements abstractive text summarization techniques rush liu ata sanabria introduced dataset large scale multimodal language understanding palaskar able produce state art results multimodal abstractive text summarization dataset utilized sequence sequence hierarchical tion based technique helcl combining textual image features duce textual summary multimodal input speech generating speech text transcriptions pre trained speech recognizers supplement modalities previous work abstractive timodal text summarization promising able capture effects combining audio features work improves shortcoming examining benets challenges introducing audio modality solution hypothesize audio modality impart additional useful information original text let talk bait tip hook maggot typically going pan real known common nique given day difference catching catching maggot use meal worms bigger probably suited large hook hook right maggot big hook like probably line thing going technique pan perch sunsh smaller maggots like meal worm hook like fantastic setup trout text ice shing ice shing learn ice shing bait tips experienced sherman artist free shing video video text learn ice shing bait ice shing lesson experienced sherman mast maggots good catching perch learn ice shing bait ice shing lesson experienced sherman table comparison outputs different modality congurations test video example quently occurring words highlighted red easier simpler model predict tribute terms useful content summary generated mast model contains content words compared baselines text summarization task letting model pay attention words spoken certain tone level emphasis experiments able prove modalities contribute equally output found higher contribution text followed video audio formed vation mast model places higher importance text input generating summary mast able produce illustrative summary original text table achieves state art results summary primary contributions introduction audio modality abstractive multimodal text summarization examining challenges utilizing audio formation understanding contribution generated summary proposition novel state art model mast task multimodal abstractive text summarization methodology section describe dataset modalities mast model ture code model available dataset use version sanabria open domain videos dataset consists hours short tional videos spanning different domains cooking sports indoor outdoor activities music human generated transcript panies video sentence summary available video written generate interest potential viewer version instead version audio modality information available subset dataset divided training tion test sets training set consists videos totaling hours tion set consists videos totaling hours test set consists videos totaling hours detailed description dataset given sanabria experiments took videos ing set videos validation set videos test set modalities use following inputs corresponding different modalities audio use concatenation dimensional kaldi povey lter bank features raw audio time window frame shift dimensional pitch features extracted dataset obtain nal sequence dimensional audio features text use transcripts corresponding video texts normalized lower cased video use dimensional feature vector group frames tracted videos cnn trained recognize different actions hara results sequence feature vectors video multimodal abstractive summarization trimodal hierarchical attention figure shows architecture multimodal abstractive summarization trimodal com amankhullar mast dently bahdanau att text video decoder hidden state decoder timestep encoder hidden state encoder timestep number encoder timesteps modality attention energy corresponding trainable projection matrices weight vector batt bias term look different strategies bining information modalities rst simple extension hierarchical attention combination second strategy mast combines modalities els hierarchical attention obtain rst baseline model level attention chy context vectors modalities combined second layer attention nism context vector computed separately hierarchical attention combination helcl text video hierarchical attention distribution modalities context vector modality encoder shared parameters modalities modality specic projection matrices figure multimodal abstractive summarization trimodal hierarchical attention mast architecture mast sequence sequence model uses mation modalities audio text video modality information encoded modality encoders followed trimodal hierarchical tion layer combines information level hierarchical attention approach attends pairs modalities audio text text followed modality pair followed individual features ity decoder utilizes combination ities generate output vocabulary chical attention mast model model sists components modality encoders modal hierarchical attention layer modal decoder modality encoders text embedded embedding layer encoded bidirectional gru encoder audio video features encoded bidirectional lstm encoders gives individual output encoding corresponding modalities encoder timestep tokens corresponding modality encoded corresponding modality encoders produce sequence hidden states encoder time step trimodal hierarchical attention layer build hierarchical attention approach proposed helcl bine modalities decoder timestep attention distribution context vector modality rst computed mast obtain mast model text vectors audio text text video bined second layer hierarchical attention mechanisms context vectors computed separately context vectors combined hierarchical attention mechanism audio text text video text text audio text video text text vector obtained corresponding pair wise modality combination finally audio text video text context vectors combined nal tion layer trimodal hierarchical tion architecture combine textual modality twice modalities pair wise manner allows model pay tention textual modality incorporating benets modalities text video text timestep nal context vector decoder trimodal decoder use gru based conditional decoder firat cho generate nal vocabulary distribution timestep timestep decoder aggregate information modalities trimodal decoder focuses modality combination followed individual modality focuses particular tion inside modality finally uses formation information previous timesteps passed linear layers generate word vocabulary experiments train trimodal hierarchical attention mast models version dataset modalities train hierarchical attention models considering audio text video text modalities simple models attention modality individually baselines observed palaskar pointer generator model perform models dataset use baseline experiments consider transformer based baseline text modality bertsumabs liu lapata experiments abs baseline use nmtpytorch toolkit caglayan source target vocabulary consists words train word embeddings use nll loss adam optimizer kingma learning rate trained models epochs generate summaries beam search beam size ate rouge metric lin content metric palaskar experiments text embedded embedding layer size encoded ing bidirectional gru encoder cho hidden layer size gives dimensional output encoding corresponding text timestep audio video frames encoded bidirectional lstm coders hochreiter schmidhuber hidden layer size gives dimensional output encoding corresponding audio video features timestep finally gru based conditional decoder uses hidden layer size followed linear layers transform decoder output generate nal output vocabulary distribution improve generalization model use dropout layers text encoder dropout layer output conditional decoder probability use implicit regularization early stopping mechanism validation loss patience epochs challenges audio modality rst challenge comes obtaining good representation audio modality adds value text modality task text summarization found mohamed dnn acoustic models prefer features smoothly change time frequency like log mel frequency spectral coefcients mfsc decorrelated mel frequency cepstral coefcients mfcc mfsc features easier dnns discover linear relations higher order causes input data leading better overall system performance consider mfcc features experiments use ter bank features instead second challenge arises larger number parameters model needs handling audio information number parameters video text baseline lion compared million add audio high number timesteps audio modality encoder makes learning trickier time consuming demonstrate challenges iment group audio features input timesteps bins average utive timesteps train mast model makes number audio timesteps comparable number video text timesteps observe improvement computational ciency achieves lower performance baseline video text model described table mast binned train audio audio text models fail beat text baseline observe generated summaries audio model similar repetitive indicating model failed learn useful mation relevant task text summarization results discussion model text bertsumabs video audio audio text video text mast binned mast rouge content table results different congurations mast outperforms baseline models terms rouge scores obtains higher content score baselines obtaining score close model preliminaries results given table demonstrate contribution modalities output summary experiment modalities taken individually tion text video audio attention based models bahdanau respective modality features taken coder inputs situate efcacy decoder architecture task use sumabs liu lapata bert based baseline abstractive text summarization text video text models archical attention layer video text model presented palaskar pared version instead version dataset audio modality available model adds audio modality second level archical attention mast binned model groups features audio modality computational efciency models alternative methods utilizing audio modality information evaluate models rouge metric lin content metric palaskar content metric score content words summaries based monolingual alignment calculated ing meteor toolkit denkowski lavie setting zero weight function words equal weights precision recall cross penalty generated words tionally set catchphrases like words free video learn tips expert appear summaries act like function words instead content words removed reference hypothesis summaries processing step ignores uency gives estimate useful content words model able capture output discussion observed scores text model text modality contains information relevant nal summary lowed video audio modalities scores obtained combining audio text video text modalities indicate transformer based model bertsumabs fails form smaller text figure distribution duration videos onds test set data available tune model observe combining text dio modalities leads lower rouge score text model indicates plain hierarchical attention model fails learn audio modality observation line result obtained model simply extend hierarchical attention approach modalities usefulness audio modality mast models achieve higher content score video text line indicating model learns extract useful content utilizing information audio modality corresponding istics speech line initial hypothesis illustrated table model simply adds audio modality second level erarchical attention fails outperform text baseline terms rouge scores tecture lets mast model choose ing attention different combination ties text modality forces model pay attention text modality overcoming shortcoming model achieving better rouge scores maintaining similar content score pared attention distribution modalities understand importance individual ities combinations plot tion distribution different levels attention erarchy decoder timesteps figure corresponds attention weights calculated figure distribution rouge scores summaries produced different video durations seconds mast video text baseline videos binned groups seconds duration tion rouge scores group shown ing density plots dotted lines inside group quartile distribution equation gures correspond product attention weights equations corresponding weight equation decoder timestep nal attention individual modality decoder timestep calculated multiplying corresponding mulative attention weights obtained level attention hierarchy attention weights tained equation gures attention weights assigned audio modality added input timesteps group size order obtain interpretable visualization visualizations observe text modality dominates generation output summary giving lesser attention audio video modalities important ndings support extra importance given text modality mast model interaction modalities figures highlight modest gains audio modality challenge appropriate usage performance video durations look model performs ent video durations test set figure shows variation rouge scores different videos mast video text baseline gure shows videos binned seven groups seconds duration observe quartile distribution mast outperforms baseline seven groups gives lar performance videos duration seconds underperforms videos duration seconds overall looking distribution tion videos test set figure observe mast outperforms baseline vast majority videos durations new tuning schedule abstractive rization adopted different optimizers encoder decoder alleviate mismatch bert models typically require large amounts annotated data produce state art results recent works like gan bert croce focus solving problem related work abstractive text summarization abstractive summarization documents ditionally achieved paraphrasing fusing multiple sentences grammatical rewriting woodsend lapata later improved taking inspiration human comprehension capabilities fang teufel implemented model human hension summarization proposed kintsch van dijk identifying concepts text application reference resolution named entity recognition semantic similarity detection implemented step competition real stimulus eld abstractive marization provided application neural encoder decoder architectures rush rst achieve state art results gigaword graff datasets lished importance end end deep learning models abstractive summarization work later improved copying source text remove problem incorrect generation facts summary coverage mechanism curb problem repetition words generated summary pretrained language models breakthrough eld natural guage processing came use pre trained language models carrying language downstream tasks pre trained language models like bert devlin introduced masked language modelling allowed models learn interactions left right context words models signicantly changed way word embeddings generated training textual embeddings static embeddings liu lapata presented bert text summarization proposed advancements speech recognition computer vision parallel advancements eld speech nition computer vision able successful methods extract useful features speech images peddinti built robust acoustic model speech recognition time delay neural network able achieve state art results iarpa pire challenge similarly advancements convolutional neural networks eld puter vision progressed signicantly demonstrated strength deep residual networks learned residual functions erence layers able achieve art results imagenet dataset hara showed simple convolutional neural network cnn architectures outperform complex architectures trained cnn recognize different human actions kinetics dataset kay summarization text advancements elds turn facilitated text summarization rott cerva input audio generate tual summaries sah rst possibility summarizing long videos annotating summarized video obtain textual summary els able capture mation modalities obtain output textual summary limitations led increasing use multimodal data major drance eld multimodal text tion lack datasets created asynchronous benchmark dataset annotated summaries videos sanabria released large scale dataset structional videos zhu presented multimodal text summarization models textual visual modalities input multimodal outputs summarized text video palaskar dataset figure visualization attention weights trimodal hierarchical attention layer sample video test set figures varying attention distribution different combinations modalities decoder timesteps figures attention distribution encoder timesteps modality decoder timesteps shows usefulness modality generation summary present abstractive summary open domain videos models completely multimodal utilise audio mation major focus work highlight importance audio data input incorporate truly multimodal manner conclusion presented mast state art sequence sequence based model uses information modalities audio text video generate abstractive multimodal text summaries uses trimodal hierarchical tion layer utilize information modalities explored role played adding audio modality compared mast line models demonstrating effectiveness approach future like extend work looking alternate audio modality tations including neural networks audio feature extraction explore use formers end end attention based learning aim explore application mast com amankhullar mast multimodal tasks like translation references dzmitry bahdanau kyunghyun cho yoshua gio neural machine translation jointly arxiv preprint learning align translate ozan caglayan mercedes garca martnez adrien bardet walid aransa fethi bougares loc rault nmtpy exible toolkit advanced neural machine translation systems prague bulletin mathematical linguistics kyunghyun cho bart van merrienboer caglar cehre dzmitry bahdanau fethi bougares holger schwenk yoshua bengio learning phrase representations rnn encoder decoder statistical machine translation arxiv preprint danilo croce giuseppe castellucci roberto basili gan bert generative adversarial ing robust text classication bunch beled examples proceedings annual meeting association computational guistics pages michael denkowski alon lavie meteor automatic metric reliable optimization uation machine translation systems ings sixth workshop statistical machine translation pages jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language ing arxiv preprint yimai fang simone teufel summariser based human memory limitations lexical competition proceedings conference european chapter association putational linguistics pages orhan firat kyunghyn cho gated ditional mechanism tutorial blob master docs cgru pdf recurrent attention unit com nyu david graff junbo kong chen kazuaki maeda english gigaword linguistic data consortium philadelphia kensho hara hirokatsu kataoka yutaka satoh spatiotemporal cnns retrace proceedings tory cnns imagenet ieee conference computer vision tern recognition pages kaiming xiangyu zhang shaoqing ren jian sun deep residual learning image proceedings ieee conference nition computer vision pattern recognition pages sepp hochreiter jurgen schmidhuber neural computation long short term memory chin yew lin rouge package automatic text summarization evaluation summaries branches pages yang liu mirella lapata text proceedings tion pretrained encoders conference empirical methods ural language processing international joint conference natural language processing emnlp ijcnlp pages abdel rahman mohamed deep neural network acoustic models asr paul hoa dang donna harman duc context information processing management shruti palaskar jindrich spandana gella florian metze multimodal abstractive arxiv preprint summarization videos vijayaditya peddinti guoguo chen vimal manohar tom daniel povey sanjeev khudanpur jhu aspire system robust lvcsr tdnns ivector adaptation rnn lms ieee shop automatic speech recognition standing asru pages ieee daniel povey arnab ghoshal gilles boulianne lukas burget ondrej glembek nagendra goel mirko hannemann petr motlicek yanmin qian petr schwarz kaldi speech tion toolkit ieee workshop automatic speech recognition understanding conf ieee signal processing society zhu zhang zong modal summarization guidance multimodal reference association computational tics michal rott petr cerva speech text marization automatic phrase extraction recognized text international conference text speech dialogue pages springer chloe hillier kay joao carreira karen simonyan brian sudheendra zhang narasimhan fabio viola tim green trevor paul natsev kinetics human action video dataset arxiv preprint diederik kingma jimmy adam method stochastic optimization arxiv preprint walter kintsch teun van dijk model text comprehension production chological review haoran junnan zhu cong jiajun zhang chengqing zong multi modal rization asynchronous collection text image audio video jindrich jindrich helcl attention strategies multi source sequence sequence learning proceedings annual ing association computational linguistics volume short papers pages alexander rush sumit chopra jason weston neural attention model abstractive proceedings tence summarization conference empirical methods natural guage processing pages shagan sah sourabh kulhare allison gray hashini venugopalan emily prudhommeaux raymond ptucha semantic text ieee winter tion long videos ence applications computer vision wacv pages ieee ramon sanabria ozan caglayan shruti palaskar desmond elliott loc barrault lucia specia florian metze large scale dataset arxiv multimodal preprint language understanding abigail peter liu christopher point summarization arxiv preprint ning pointer generator networks kristian woodsend mirella lapata multiple aspect summarization integer linear ming proceedings joint conference empirical methods natural language ing computational natural language learning pages association computational guistics junnan zhu haoran tianshang liu zhou ajun zhang chengqing zong msmo multimodal summarization multimodal output
