asking answering questions evaluate factual consistency summaries alex wang new york university edu kyunghyun cho facebook new york university mike lewis facebook abstract practical applications abstractive rization models limited frequent tual inconsistencies respect existing automatic evaluation metrics summarization largely insensitive errors propose automatic ation protocol called designed identify factual inconsistencies ated summary qags based ition ask questions mary source receive lar answers summary factually sistent source evaluate qags collect human judgments factual tency model generated summaries cnn dailymail hermann xsum narayan summarization datasets qags substantially higher relations judgments tomatic evaluation metrics qags fers natural form interpretability swers questions generated ing qags indicate tokens summary inconsistent believe qags promising tool automatically generating usable factually consistent text introduction automatic summarization aims produce maries succinct coherent relevant crucially factually correct recent progress conditional text generation led models generate uent topical summaries lewis model generated summaries quently contain factual inconsistencies limiting applicability kryscinski problem factual inconsistency lack automatic evaluation metrics detect errors standard metrics evaluating generated text predominantly based kags counting grams weigh grams equally insensitive semantic errors inadequacy leaves human evaluation primary method evaluating factual consistencies noted challenging humans daume iii marcu kryscinski addition slow costly argue evaluation metrics able capture subtle semantic errors required build better models work introduce general framework evaluating conditional text generation designed detect factual sistencies generated text respect input framework consists steps given generated text question generation model generates set questions text use question answering models answer questions given input generated text quality score computed based similarity corresponding answers approach leverages recent progress ask answer human readable topic questions devlin song assumes access question ing dataset train models applicable modality model available text images knowledge graphs use framework develop qags tion answering generation tion metric evaluating factual tency abstractive document summaries pared commonly automatic metrics rouge lin qags shows dramatically higher correlations human judgements tuality example achieving pearson correlation coefcient cnn dailymail marization task compared qags achieves new state art results evaluating factuality summaries forming recently proposed nli models task kryscinski finally analyse robustness qags ablation study qags shows ness quality underlying models domain models number questions asked worst ablation settings qags stronger correlation human judgments automatic metrics overall contribute following introduce qags automatic model based ation metric measuring factual consistency model generated text collect new set human judgments factual consistency model generated summaries tion datasets demonstrate qags lates judgments signicantly better automatic metrics tions qags robust number factors including underlying model quality domain mismatch analyze questions swers produced computing qags illustrate parts summaries inconsistent release models code compute qags identify key deciencies gram based evaluation metrics detect factual inconsistencies generated text metrics require reference texts compare obtaining references expensive challenging text generation datasets contain single erence problem exacerbated entropy generation tasks summarization dialogue large number acceptable outputs settings comparing single reference woefully inadequate second given reference compare gram based approach weigh portions text equally small fraction grams carry semantic content factual inconsistencies caused minor changes drowned high gram overlap making metrics insensitive errors example sentences writing paper vancouver writing paper vancouver share nearly unigrams bigrams despite having opposite meaning background automatically evaluating machine generated text framework automatically evaluating factual consistency standard approaches evaluating generated text primarily based counting gram overlap methods assume access ence texts score generated summary based precision recall reference grams generated summary briey describe common metrics family refer readers liu discussion rouge lin developed specically evaluating automatic summarization variants standard common variant rouge typically computes score ence grams generated summary commonly variant length longest common subsequence possibly consecutive summary references bleu papineni closely related rouge developed machine translation bleu computes precision reference grams generated summary meteor lavie agarwal extends bleu alignment generated text erence stemming synonym replacement exible gram matching introduce framework automatically tecting factual inconsistencies generated text addressing deciencies current approaches let sequences tokens coming vocabulary source text summary dene distribution possible questions given summary tributions possible answers ular question given source summary constrain questions answers sequences tokens factual consistency summary function measuring ity answer distributions expression maximized contains subset mation produces answer question happens ially summary usually desiderata solution undesirable figure overview qags set questions generated based summary questions answered source article summary corresponding answers compared similarity function averaged questions produce nal qags score framework addresses issues gram based approaches instead requiring ence compare framework asks tions based generation compares answers provided source text use questions focuses metric tically relevant parts generated text weighting parts text equally practice exactly computing expectation equation intractable large space possible questions potential workaround randomly sample questions suffers high variance requires ples obtain good estimate instead focus producing highly probable questions duced beam search biased limit require fewer questions estimate higher quality questions qags framework requires specifying tion distribution answer distribution answer similarity tion apply framework summarization develop qags describe instantiations components question generation instantiate draw recent work automatic question generation models distribution neural models ishna iyyer sample questions lter low quality questions follows train generate conditional models model receives answer source article trained maximize likelihood paired question test time extract named entities noun phrases answers candidates spacy second lter low quality questions number heuristics duplicates tions tokens long found useful run model section candidate questions lter questions model predicted answer question answering instantiate answer distributions extractive models api entityrecognizer summarizationkevin sineld scored rst try season castleford leeds rhino scored unbeaten run tigers matches ryan hall sent leeds rhino rst time career leeds showed good shape cope kevin sineld retirement claimed derby victory castleford sell crowd mend hose jungle ryan hall sent sin bin rst time career joel moon scored rst try season leeds extended unbeaten run tigers matchesgenerated questionswho scored rst try moonkevin sineldwho sent leeds rhino rst ryan hallhow matches matchessix matchessummary answerssourceanswerssourcesummary simplicity use extractive assume facts represented text spans article summary future work explore abstractive models match paraphrases answer answer similarity use token level compare answers standard extractive equivalent dening max arg max qags score given components obtain qags score generation erating questions conditioned summary answering questions source article summary sets answers comparing corresponding answers answer similarity metric averaging swer similarity metric questions depict process figure experiments human evaluation test qags accurately measures factual consistency summary respect source article computing correlations human judgments factual consistency datasets evaluate abstractive marization datasets cnn daily mail cnndm hermann nallapati xsum narayan abstractive marization particularly interesting tual consistency original text crucial usability lack consistency plagued abstractive neural summarization models cao falke kryscinski cnn standard dataset tion consists cnn dailymail articles reference summary consists nation editor written bullet point lights summaries use test outputs gehrmann xsum created taking rst sentence news article summary rest article source consequently xsum summaries signicantly abstractive cnn extractive summarization models perform poorly dataset found xsum summaries abstractive frequently facts metric cnn xsum rouge meteor bertscore qags table summary level pearson correlation cients automatic metrics human judgments correctness summarization datasets qags obtains substantially higher correlations automatic metrics rst names summary available article quirk especially difcult humans qags tell factual errors summarization model remedy human evaluation qags prepend summary article use subset test outputs bart tuned xsum lewis annotation protocol collect human ments amazon mechanical parlai miller present summaries sentence time entire article summary sentence annotator makes nary decision sentence factually consistent article workers instructed mark non grammatical sentences tent copies article sentences consistent workers paid summary annotated appendix details collect annotations summary obtain single correctness score summary rst majority vote sentence age binary scores summary sentences inter annotator agreement measured pendorff cnn xsum respectively indicating moderate fair agreement ageeva perfect agreement numbers line similar gures previous work tion evaluation daume iii marcu mturk experimental details question generation use fairseq ott tune pretrained bart guage model newsqa trischler dataset consisting cnn articles sourced questions summary use answer candidates generate questions beam search width total tion candidates ltering use probable questions summary ltered questions randomly sample tions reach required number details appendix question answering train models tuning bert devlin rajpurkar use large uncased bert variant transformers library wolf baselines compare number tomatic evaluation metrics rouge lin meteor lavie agarwal bleu pineni bertscore zhang uses bert representations compute alignment generation erence tokens pute soft version unigram use large uncased bert variant results present results table qags strongly outperforms automatic evaluation metrics terms correlation human judgments tual consistency bleu rouge perform parably lower order gram metrics work ter bertscore matches best gram metrics cnn worst overall xsum cnn qags obtains nearly twice correlation best automatic metric speculate large increase sensitivity model sentence fusing behavior exhibited marization models trained cnn lebanoff sentences fused produce incorrect summary statement model produces different answers source article versus summary xsum metrics correlate worse man judgments cnn reects fact xsum abstractive qags outperforms best automatic metric model squad cnn xsum pear pear bert base bert large bert large wwm table pearson correlations human ments factual consistency qags els different qualities measured performance development set tions stable model quality newsqa cnn xsum pear pear ppl table pearson correlations human ments factual consistency qags els varying quality measured perplexity newsqa development set decrease correlation cnn perplexity increases similar trend xsum ablations potential issue model based evaluation quality evaluation metric pend heavily specic hyperparameter settings explore true qags forming ablations factors model quality rst consider degree quality underlying models impacts evaluation capabilities quality answer question training models varying quality tuning different versions bert squad present results table els perform similarly despite substantially ferent performances squad ment set surprisingly best model bert large wwm lead best correlations human judgments cnn bert large wwm slightly performs bert base bert large xsum bert base slightly outperforms bert variants results indicate qags fairly robust quality derlying model note bert strong baseline weaker models lead larger performance dropoffs ablate quality use models questions cnn xsum model metric correct random bert nli esim factcc qags table pearson correlation coefcients qags scores varying number questions human judgments correctness summarization datasets correlation increases number questions decreasing marginal benet table results sentence ranking task falke results bert nli esim falke factcc kryscinski qags outperforms previous work creasing perplexity newsqa development set results table qags robust model quality decrease correlation human judgments perplexity creases cnn clear trend xsum weakest model signicantly performs automatic metrics table domain effects approach relies having labeled dataset train models relatively niche domains labeled dataset exist instead need resort models trained domain data leading domain shift effects negatively impact quality qags scores simulate setting tuning model squad similar size newsqa drawn wikipedia articles cnn articles exactly matches genre summarization datasets evaluating model relations human ments cnn xsum respectively versus newsqa tuned model drop performance indicates negative domain shift effect squad tuned model substantially forms automatic metrics pointing robustness qags number questions investigate correlation human judgments varying number questions results table increasing number questions improves correlations human judgments observe large increase moving questions smaller increase questions indicating decreasing marginal benet moving questions questions qags substantially outperforms automatic metrics indicating robustness answer similarity metric finally consider exact match alternative answer ilarity metric exact match common evaluation metric extractive strictive obtain son correlations human judgments cnn xsum opposed ranking qags works explore use natural language inference nli models detect factual tency generated text welleck falke compare methods evaluating sentence ranking experiment falke experiment uses triplets source sentences cnn summary sentences generated model chen bansal summary sentence factually consistent source sentence inconsistent metric model evaluated based ranks consistent sentence higher inconsistent sentence present results table results nli models tuned multinli williams bert nli esim chen falke factcc kryscinski nli based checking model trained dataset tailor detecting factual inconsistencies ated text qags outperforms methods requiring special supervision task qualitative analysis interpreting qags questions answers produced computing qags directly pretable highlight errors summaries article friday year old usman khan stabbed reportedly people fishmongers hall london large knife london bridge members public confronted man sprayed khan extinguisher struck sts took knife polish chef named ukasz harried foot narwhal tusk summary friday afternoon man named faisal khan entered cambridge university building started attacking people knife extinguisher question attacker article answer large knife question attack place article answer friday question attacker article answer usman khan question attack place article answer fishmongers hall summary answer cambridge university building summary answer knife extinguisher summary answer friday afternoon summary answer faisal khan article ndings published wednesday journal plos international team scientists report ancient egyptians captured sacred ibises threskiornis aethiopicus wild use ritual sacrice domesticating birds team collected dna samples mummied birds collected separate catacombs including sites abydos saqqara tuna gebel permission egyptian ministry state antiquity museums offered send tissue samples mummied ibises collections summary archaeologists dna samples ancient ibis birds determine birds domesticated sacriced ancient egypt question archaeologists determine birds domesticated article answer hatchery structures question dna samples determine birds domesticated article answer answer question archeologists determine birds domesticated article answer dna samples question birds found article answer separate catacombs summary answer archaeologists summary answer dna samples summary answer dna samples summary answer ancient egypt table example questions answers generated computing qags questions overwhelmingly uent relevant answers indicate tokens summary factually consistent inconsistent present examples articles summaries qags questions answers table rst example table qags tects factual inconsistencies ated summary summary mistakes rst attacker location attack weapons model focuses details qags able correctly penalize summary hallucinations answer candidates named entities noun phrases qags particularly effective detecting errors kind verse answer candidates broaden set inconsistencies qags able detect second example table trates failure modes qags example model incorrectly marks question swerable question answers produced correct common kens marked inconsistent qags error analysis interpretability qags lows error analysis metric manually annotate triplets generated questions article answers summary answers produced computing qags xsum summaries label quality generated questions predicted answers answer similarity scores generated questions sensical formed swerable generated summary conditioned gures indicate vast majority questions understandable topic frequently observe multiple questions slightly different wordings likely low number answer candidates xsum summaries sentence long beam search questions formed unanswerable source usually hallucinated fact summary model turns question predicted answers questions potentially answerable summary incorrectly answered percentage creases article indicates transfer ability model lacking small number cases found question single answer summary multiple answers article finally examples tion answered correctly article summary answers high lexical variation score fails detect similarity happens relatively small number cases exploring similarity metrics gram based approaches useful limitations emphasize qags overall framework specically designed tect factual inconsistencies generated summaries relative source article qags sure desirable properties generated text including uency readability factual recall recommend qags conjunction complementary evaluation metrics choices models qags particular abstractive summarization require adaptation conditional text generation tasks example expect extractive summarization models obtain nearly perfect qags scores facts statements directly copied source article related work automatic summarization evaluation long standing lines work nlp dating far document understanding ferences chali kolla primary evaluation metric rouge lin work demonstrated limited ability rouge relatives ate summaries dorr liu liu kedzie metrics cused specic aspects summarization quality including content selection nenkova neau relevance prediction daume iii marcu recent resurgence work aging nlu models evaluating factuality generated text goodrich use mation extraction models measure factual lap facts restricted pre dened schemas falke investigate use nli els evaluate factual correctness cnn summaries conclude current nli models brittle reliably manner kryscinski train nli based checking model building dataset factual consistencies based noise heuristic proach allows ner grained analysis nli operates complete sentences qags ask questions sentence relatedly eyal scialom use models evaluate tion diverge works important ways works use cloze style questions generated masking entities source document reference summary instead generate questions model ing greater range questions second produce questions conditioned generated summary reference summary source article producing questions ated summary appropriate verifying accuracy text reference source measures content selection conclusion introduce framework automatically ing factual inconsistencies conditionally ated texts use framework develop qags metric measuring inconsistencies tive summarization qags correlates human judgments factuality signicantly better standard automatic evaluation metrics rization outperforms related nli based proaches factual consistency checking qags naturally interpretable questions answers produced computing qags indicate kens generated summary inconsistent error analysis shows future work explore improved models approach applied diverse modalities lation image captioning overall believe qags useful quantifying incentivizing factually consistent text generation references ekaterina ageeva mikel forcada francis ers juan antonio perez ortiz evaluating machine translation assimilation task proceedings annual conference european association machine tion pages antalya turkey ziqiang cao furu wei wenjie sujian faithful original fact aware neural tive summarization thirty second aaai ence articial intelligence yllias chali maheedhar kolla proceedings tion techniques duc document understanding conference citeseer qian chen xiaodan zhu zhen hua ling wei hui jiang diana inkpen enhanced lstm proceedings natural language inference annual meeting association tational linguistics volume long papers pages yen chun chen mohit bansal fast tive summarization reinforce selected sentence rewriting proceedings annual ing association computational linguistics volume long papers pages hal daume iii daniel marcu bayesian summarization duc suggestion extrinsic evaluation proceedings document standing conference vancouver usa jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language standing proceedings conference north american chapter association computational linguistics human language nologies volume long short papers pages bonnie dorr christof monz douglas oard david zajic richard schwartz sic evaluation automatic metrics rization technical report maryland univ college park inst advanced puter studies xinya junru shao claire cardie ing ask neural question generation reading proceedings comprehension nual meeting association computational linguistics volume long papers pages matan eyal tal baumel michael elhadad question answering automatic evaluation ric news article summarization ings conference north american chapter association computational guistics human language technologies volume long short papers pages tobias falke leonardo ribeiro prasetya ajie ido dagan iryna gurevych utama ranking generated summaries correctness teresting challenging application natural guage inference proceedings ence association computational tics pages angela fan mike lewis yann dauphin proceedings erarchical neural story generation annual meeting association computational linguistics volume long papers pages sebastian gehrmann yuntian deng alexander rush abstractive summarization proceedings conference cal methods natural language processing pages ben goodrich vinay rao peter liu mad saleh assessing factual accuracy generated text proceedings acm sigkdd international conference knowledge discovery data mining kdd pages new york usa acm karl moritz hermann tomas kocisky edward stette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read comprehend advances neural information processing systems pages ari holtzman jan buys maxwell forbes yejin choi curious case neural text ation arxiv preprint chris kedzie kathleen mckeown hal daume iii content selection deep learning models proceedings summarization ference empirical methods natural language processing pages kalpesh krishna mohit iyyer generating question answer hierarchies proceedings annual meeting association putational linguistics pages florence italy association computational linguistics wojciech kryscinski nitish shirish keskar bryan cann caiming xiong richard socher neural text summarization critical evaluation proceedings conference empirical methods natural language processing volume long short papers wojciech kryscinski bryan mccann caiming xiong richard socher evaluating factual consistency abstractive text summarization alon lavie abhaya agarwal meteor automatic metric evaluation high levels correlation human judgments ings second workshop statistical machine translation pages association tational linguistics logan lebanoff john muchovej franck dernoncourt doo soon kim seokhwan kim walter chang fei liu analyzing sentence fusion tive summarization proceedings shop new frontiers summarization pages mike lewis yinhan liu naman goyal jan ghazvininejad abdelrahman mohamed omer levy ves stoyanov luke zettlemoyer bart denoising sequence sequence training natural language generation translation comprehension arxiv preprint chin yew lin rouge package automatic text summarization evaluation summaries branches pages chia wei liu ryan lowe iulian serban mike worthy laurent charlin joelle pineau evaluate dialogue system pirical study unsupervised evaluation metrics dialogue response generation proceedings conference empirical methods natural language processing pages feifan liu yang liu exploring correlation rouge human evaluation meeting ieee transactions audio speech summaries language processing ilya loshchilov frank hutter decoupled weight decay regularization alexander miller feng dhruv batra antoine bordes adam fisch jiasen devi parikh jason weston parlai dialog research proceedings ware platform ference empirical methods natural language processing system demonstrations pages ramesh nallapati bowen zhou cicero dos santos aglar gulcehre bing xiang tive text summarization sequence sequence proceedings rnns signll conference computational natural guage learning pages berlin germany association computational linguistics shashi narayan shay cohen mirella lapata details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing brussels belgium ani nenkova rebecca passonneau ating content selection summarization mid method proceedings human language technology conference north american ter association computational linguistics hlt naacl pages myle ott sergey edunov alexei baevski angela fan sam gross nathan david grangier michael auli fairseq fast extensible toolkit sequence modeling naacl hlt page kishore papineni salim roukos todd ward jing zhu bleu method automatic proceedings uation machine translation annual meeting association tational linguistics pages association computational linguistics gabriel pereyra george tucker jan chorowski lukasz kaiser geoffrey hinton izing neural networks penalizing condent output distributions pranav rajpurkar robin jia percy liang know know unanswerable tions squad proceedings annual meeting association computational guistics volume short papers pages thomas scialom sylvain lamprier benjamin wowarski jacopo staiano answers unite unsupervised metrics reinforced proceedings rization models ference empirical methods natural language processing international joint ence natural language processing ijcnlp pages kaitao song tan tao qin jianfeng yan liu mass masked sequence quence pre training language generation ternational conference machine learning pages adam trischler tong wang xingdi yuan justin ris alessandro sordoni philip bachman heer suleman newsqa machine proceedings hension dataset shop representation learning nlp pages sean welleck jason weston arthur szlam kyunghyun cho dialogue natural language inference proceedings annual ing association computational linguistics pages florence italy association computational linguistics adina williams nikita nangia samuel bowman broad coverage challenge corpus tence understanding inference ings conference north american chapter association computational guistics human language technologies volume long papers pages thomas wolf lysandre debut victor sanh julien chaumond clement delangue anthony moi ric cistac tim rault remi louf morgan icz transformers state art ral language processing arxiv preprint tianyi zhang varsha kishore felix kilian weinberger yoav artzi bertscore arxiv preprint uating text generation bert answers model predicts question seeing answer article decoding use beam search beam size length penalty trigram repetition blocking experimented man fan outputted questions diverse noisy generations minimum length max length lter questions rst use simple tics including removing rst question mark question exact duplicates questions shorter tokens long remaining questions use model answer question remove questions model deems unanswerable probable questions dom sampling ltered questions question answering tune bert question answering following original work optimize adamw loshchilov ter initial learning rate train epochs warmup ratio use model best development set mance use found swerable questions useful ltering questions questions based hallucinated facts summary unanswerable source article similar setting append question answer source article tervening special marker tokens human evaluation task design restrict pool workers based ers workeres required approved hits acceptance rate base reward task summary include automatic quality checks cluding time checks workers complete task fail check attention checks include exact copies article sentences corrupted mixtures article sentences positive negative control task worker fails answer examples correctly fail check explanation checks sentence summary worker required provide short explanation decision worker passes checks awarded bonus totalling correct tion according turkerview com workers hit paid excess age annotation interfaces tation task cnn xsum respectively figures use slightly different tions accommodate quirks dataset xsum prepend reference summary source article workers struggling identify factual inconsistencies model generation details question generation tune bart question generation tuning parameters original work optimize label smoothed cross entropy smoothing parameter pereyra peak learning rate optimize steps warmup steps use model best perplexity development set turn newsqa answer conditional dataset concatenate answer source article special marker token concatenate special marker token question test time named entities noun phrases answer candidates web spacy model downsampling randomly duplicating figure annotation interface instructions cnn factual consistency task figure annotation interface instructions xsum factual consistency task
