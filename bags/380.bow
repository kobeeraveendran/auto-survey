n j g l s c v v x r adversarial machine learning text analysis generation preprint izzat alsmadi department computing cyber security texas san antonio san antonio tx edu january abstract research eld adversarial machine learning witnessed signicant interest years machine learner model secure deliver main objectives acceptable accuracy efciency time resist different types attempts adversarial attacks paper focuses studying aspects research trends adversarial machine learning specically text analysis generation paper summarizes main research trends eld gan algorithms models types attacks defense attacks keywords adversarial machine learning text generation generative adversarial networks gan introduction basic generative adversarial network gan model includes main modules generator discriminator generator discriminator implicit function expressions usually implemented deep neural networks creswell et al applying gan natural language processing nlp tasks text generation challenging discrete nature text consequently straightforward pass gradients discrete output words generator haidar rezagholizadeh text input discrete text generators model problem sequential decision making process model state previously generated characters words sentences action prediction character word sentence generated generative net stochastic policy maps current state distribution action space generative adversarial network gan create new data instances resemble original training data original gan described goodfellow et al following components workow nns discriminator generator discriminator role simple classier distinguish real instances positive examples original training dataset fake instances e negative example created generator generator tries fool discriminator synthesizing fake instances resemble real ones training progresses generator gets closer producing instances fool discriminator generator trained discriminator gets worse telling difference real fake generally speaking generator module task harder discriminator discriminator job binary generator job complex aml text analysis generation preprint nns compete different goals goal discriminator discriminate real fake instances goal generator eventually learn real instances data fool discriminator trained separately assumes module xed time cycle training avoid dealing moving target complex accuracy generator generate fake instances indicates accuracy discriminator sign competition game rivals generator instances negative training examples discriminator discriminator punishes generator producing incorrect instances rewards producing correct instances generator evolves discriminator punishes rewards effect good discriminator reveal information generator progress addition discriminator generator modules gans include following components generator random input module generator network transforms random input data instance generator loss punishes generator failing fool discriminator propagation module adjusts weights calculating weight s impact output discriminator generator conditional versus joint probability model difference discriminator generator difference conditional probability x joint probability y given set data instances x set labels y conditional probability x known posterior probability denote prior probability events y x respectively conditional entropy indicates extra information need supply average communicate y given party knows x joint entropy represents information needed specify value discrete random variables variations components e generator discriminator work trained function gans problem text generation gradients discriminator passed generator explicitly deal issue gan based models e seqgan yu et al goal gan florensa et al maligan che et al leakgan guo et al rankgan lin et al maskgan fedus et al xu et al caccia et al treat text generation sequential decision making process utilize policy gradient williams overcome difculty score predicted discriminator reinforcement train generator yielding hybrid model gan rl models utilize rl agents control gans rl agent forms decision making network interacts environment taking available actions collects rewards scalability limitation agent trained rl capable achieving single task specied reward function gans methods training propagation applying gan text analysis challenging text discrete consequently need pass gradients discrete output words generator haidar rezagholizadeh generator discriminator modules train improve generator module train self auto variational encoders code decoder randomly values produce different outputs goal self encoder reconstruction error smaller smaller generator uses propagation discriminator improve future instances update model weights discriminator train learn discriminator process distinguish instance label real generated trained based real instances original dataset fake instances generator gan loss functions gan uses loss functions evaluate distance distribution data generated gan distribution real data gan loss functions generator discriminator training minimax loss generator tries minimize loss function discriminator tries maximize goodfellow et al aml text analysis generation preprint wasserstein loss default loss function tf gan estimators arjovsky et al gans discriminator try binary decision instance real fake provide value zero threshold decided range values fake instances versus values real instances character word sentence level attacks aml research publications demonstrate picture based datasets growing recent trend applications aml text analysis nlp taxonomy aml nlp divided following attack levels character level attacks involve different possible types character level manipulations swap substitution deletion insertion repeating hot character embedding visual character embedding hosseini et al zhang et al textbugger li et al belinkov bisk gao et al hotip ebrahimi et al brown et al pruthi et al eger et al le et al character level attacks simple easy defend deploying spell check proofread algorithms word level attacks similar character level attacks approaches word level attacks manipulation include word embedding language models lter words synonyms substitutes e ebrahimi et al ebrahimi et al kuleshov et al yang et al et al wallace et al gao et al garg ramakrishnan et al ribeiro et al et al alzantot et al li et al li et al ribeiro et al wang zhang wang et al search algorithms include gradient descent genetic algorithms saliency based greedy algorithm sampling papernot et al sato et al gong et al alzantot et al zhou et al liang et al ren et al jin et al comparison character level attacks attacks created word level approaches ble humans difcult machine learning algorithms defend sentence level attacks attacks usually based text paraphrasing demand longer time adversary text generation examples research publications sentence level include jia liang iyyer et al cheng et al michel et al lei et al zheng et al jethanandani tang hybrid multi level attacks attacks use combination character word sentence level approaches hotflip ebrahimi et al blohm et al wallace et al sequence generative text generator generative models approaches natural language generation nlg techniques allow generation natural language text based given context nlg involve text generation based predened grammar dada engine baki et al leverage deep learning neural networks rnn yao et al generating text describe popular approaches found relevant literature scope aml classical training language models teacher professor forcing teacher forcing common approach training rnns order maximize likelihood token target sequences given previous tokens sequence williams zipser time step s training model evaluated based likelihood target t given groundtruth sequence teacher forcing training generator means decoder exposed previous groundtruth token rnns trained teacher forcing able model distribution matches target joint distribution modeled properly rnn models prediction future steps created error model propagated following step resulting low performance solution training model professor forcing lamb et al professor forcing rnn results ground truth given input training teacher forcing output looped step forced training discriminator classies wether output created teacher forced model free running model aml text analysis generation preprint conventional inference maximum likelihood estimation mle mle conducted real data samples parameters updated directly according data samples lead overly smooth generative model goal select distribution maximizes likelihood generating data practical sample scenarios mle prone exposure bias issues training set additionally inference generation stage error time step accumulate sentence generation process ranzato et al following methods utilize mle hidden markov model hmm hidden markov model hmm probability graph model depict transition laws hidden states intentional features data model observable variables foundation hmm markov chain represented special weighted nite state automaton majority generative models require utilization markov chains goodfellow et al creswell et al observable sequence hmm participle given sentence speech pos tag hidden state different pos method moments method moments mom method learned moments early principle learning pearson situations mom preferable mle mle computationally challenging mom ravuri et al generalized method moments gmm addition data distribution class set relevant feature functions given instance space hansen rabiner research contributions aml mom moment matching include salimans al mroueh sercu lewis syrgkanis bennett et al restricted boltzmann machine rbm restricted boltzmann machine rbm layer neural network consisting visible layer hidden layer hinton important generative model capable learning representations data generative models evolved rbm based models helmholtz machines hms fodor et al deep belief nets dbn hinton et al variational auto encoders vaes kingma welling generative adversarial networks gans cooperative training method cooperative training method ctm language model trained online offer target distribution minimizing divergence real data distribution generated distribution xie et al yin et al rl based versus rl free text generation gan models originally developed learning continuous discrete distribution discrete nature text input handicaps use gans gans reinforcement learning algorithm policy gradient unbiased gradient estimator generator obtain reward discriminator chen et al rl based generation reinforcement learning rl technique train agent perform certain tasks generality reinforcement learning studied disciplines gan models use discriminating module guide training generative module reinforcement learning policy shown promising results text generation guo et al methods proposed text generation gan e lin et al rajeswar et al che et al yu et al che et al models rl applied sentence generation e actor critic algorithm deep q network e sutton et al guo bahdanau et al optimization challenge rl based approaches yield high variance gradient estimates maddison et al zhang et al rl free gans text generation examples models use alternative rl latent space based solutions continuous approximation discrete sampling models apply simple soft argmax operator gumbel softmax trick provide continuous approximation discrete distribution text examples research efforts category include zhang et al gumbelsoftmax gan gsgan kusner hernndez lobato jang et al maddison et al fm gan chen et al gsgan kusner hernndez lobato relgan nie et al aml text analysis generation preprint long versus short text generation literature area differentiates generation short texts e words generation long text applications different majority publications focus short text generation challenging different challenges discussed literature specially long text generation example unique challenges long text generation sparse reward issue scalar guiding signal available entire sequence generated vezhnevets et al guo et al sutton et al main disadvantage sparse reward problem making training sample inefcient tuan lee model based rls proposed recently solve problems extremely sparse rewards pathak et al supervised versus unsupervised text generation majority work area falls supervised category e robin ishii et al bahdanau et al bengio et al vinyals le wiseman et al bhowmik de melo puduppully et al supervised problem particular sentence terms words sentence seen input features term feature target examples publications fall unsupervised text generation include graves yu et al zhang et al hu et al schmitt et al unsupervised text generated explainable latent topics wang et al structured data schmitt et al sheffer et al knowledge graphs kgs bhowmik de melo koncel kedziorski et al schmitt et al jin et al machine learning algorithms text generation rnn lstm versus gru bidirectionalrnn text generation state art text generation models based recurrent neural networks rnns papers discussed different deep learning rnn algorithms mentioned automatic text generation e kiddon et al hu et al abdelwahab elmaghraby lu et al nie et al zhu et al wang et al mangal et al moila modipa mangal et al unlike traditional methods rnn based approaches rely data driven manual intervention emphasize end end encoder decoder structure different performance metrics methods evaluate output process log likelihood loss function overall processing time loss function training model negative log likelihood negative log probability target sequence lstm shows good model aspects comparison evaluated models mei et al wan mangal et al recent gans text generation kusner hernndez lobato yu et al guo et al lin et al fedus et al lstm papers sutskever et al pouget abadie et al shown standard lstm decoder perform generating long text sequences template based rule based versus neural text generation classical approaches text generation include template based rule based n gram based log linear based models rule based techniques grammar based methods structured rules written based accumulated knowledge template based approaches simple replacing words users choices synonyms reiter deemter et al wiseman et al peng et al n gram models widely nlp tasks text generation n gram approach word n gram e predicted inferred words appear n gram de novais et al beam search greedy search popular deterministic decoding approaches beem search greedy search sutskever et al aml text analysis generation preprint bahdanau et al zheng et al beam search maintains xed size set partially decoded sequences beam search common search strategy improve results tasks text generation machine translation dependency parsing greedy search selects highest probability token time step greedy search seen special case beam search sequence sequence models knowledge enhancement methods seq seq models common architectures text generation tasks input output modeled sequences tokens words model convert input sequence output sequence specically rst model encodes input sequence set vector representations recurrent neural network rnn second rnn decodes output sequence step step seq seq models commonly trained maximum likelihood estimation mle chen et al challenge seq seq models input text provide knowledge generate desired output impact quality generated output methods proposed enhance model knowledge input text attention memory linguistic features graphs pre trained language models multi task learning techniques listed yu et al com kenlg reading particular enhancement techniques attention bahdanau et al encoder compresses input text decoder attention mechanism generates output target decoder bound generate sequence text tokens recursive transition network rtn authors baki et al discuss recursive transition network woods generating fake content similar nature legitimate content rtn detect simplication constructs nodes graph labeled arcs labeled node names terminal symbols rnns essentially equivalent extension context free grammars regular expressions allowed right productions relational memory basic idea relational memory consider xed set memory slots allow interactions memory slots self attention mechanisms vaswani et al rm proposed record key information generation process example record information previous generation processes goal enhance text generation process learning memory patterns long text generation rl provide stateful stateless text generation process self attention memory slots enable interaction facilitate long term dependency modeling vaswani et al relational based text generations showed better ability modeling longer range dependencies described literature santoro et al relgan nie et al google lm released google google lm language pre trained model trained billion word corpus publicly available dataset containing mainly news data jozefowicz et al chelba et al based layer lstm units layer garbacea et al scheduled sampling ss ss proposed bridge gap training inference sequence prediction tasks avoid exposure bias seq seq generation bengio et al mihaylova martins inference process seq seq generation true previous target tokens unavailable result replaced tokens generated model yield discrepancy model training inference bengio et al limitation scheduled sampling target sequences incorrect steps randomly selected ground truth data regardless input chosen zheng et al ranzato et al ranzato et al generating text gans gans implicit generative language models lms learned competition generator network discriminator network discriminator distinguishes uniquely gans lms particularly subject aml adversarial training discriminator gans opposed training based solely maximum likelihood categorical cross entropy lms conventional lms trained adversarial manner unlike traditional approaches e teacher forcing ss gans suffer exposure bias rajeswar et al tevet et al exposure bias occurs models fed predicted data ground truth data inference time causes generating poor samples accumulated error yin et al aml text analysis generation preprint adversarial training techniques adversarial training method help systems robust adversarial attacks examples adversarial training techniques reported literature fast gradient sign method fgsm fgsm add adversarial examples training process goodfellow et al wong et al training original samples replaced corresponding adversarial samples generated model trained kurakin et al suggested use iterative fgsm ifgsm fgsm ll fgsm rand variants adversarial training order reduce effect label leaking kurakin et al variants fgsm momentum iterative fast gradient sign method mi fgsm dong et al pgd based training proposed madry et al iteration original samples replaced corresponding adversarial samples generated model trained pgd enhanced different efforts optimization tricks momentum improve adversary dong et al combination heuristic defenses matrix estimation yang et al defensive quantization lin et al logit pairing mosbach et al kannan et al thermometer encoding buckman et al feature denoising xie et al robust manifold defense jalal et al nonexpansive nets qian et al jacobian regularization jakubovitz giryes universal perturbation shafahi et al stochastic activation pruning dhillon et al today training pgd adversary remains empirically robust wong et al jacobian based saliency map approach jsma jsma gradient based white box method proposed use gradient loss class labels respect component input papernot et al jsma useful targeted miss classication attacks chakraborty et al accelerating adversarial training cost adversarial training reduced reusing adversarial examples merging inner loop pgd gradient updates model parameters shafahi et al zhang et al dawnbench competition submission projects dawnbench competition shown good performance results imagenet classiers comparison research reported training methods coleman et al wong et al text generation models tasks applications text generation refers process automatic programmable generation text human intervention sources utilized generation process vary based nature application types applications generating text particular growing discuss section word prediction applications use smart phones websites word prediction nwp called auto completion typical nlp application machine learning perspective nwp classical prediction problem previous current text pool extract prediction model features parameters word predict target feature different algorithms proposed approach nwp problem term frequencies articial intelligence n grams neural networks aml text analysis generation preprint dialog generation human machine dialog generation prediction essential topic research eld nlp different applications different domains quality performance process widely vary based available resources training pre training efciency neural networks demonstrated impressive results dialog generation vinyals le chang et al gans dialogue generations research publications e li et al hamilton et al kannan et al nabeel et al neural machine translation neural machine translation nmt learning approach automated translation potentials overcome weaknesses classical phrase based translation systems statistical machine learning main difference nmt based model based patterns nmt tries replicate functions human brain assess content sources generating output enhancements nmt achieved attention based neural machine translation popular early open source nmts systran systran rst nmt engine launched examples include google translate facebook e bay microsoft adversarial nmt introduced training nmt model assisted adversary elaborately designed convolutional neural network cnn yang et al wu et al zhang et al shetty et al text generation metrics key issues text generation widely agreed automated metric evaluating text generated output text generation metrics classied based categories summary categories metrics document similarity based metrics popular approaches measure output tg comparing source documents human natural language popular metrics category bilingual evaluation understudy bleu papineni et al embedding similarity embsim zhu et al bleu variants category include popular classical metrics okapi robertson walker word mover s distance wmd kusner et al cosine dice jaccard measures addition term frequency inverse document frequency tf idf likelihood based metrics log likelihood negative training loss function nll nll known multiclass entropy outputs probability class likely class typical approach text generation train model neural network performing maximum likelihood estimation mle minimizing negative log likelihood nll text corpus gans standard gan objective goal objective function minimize nll binary classication task goodfellow et al maximum likelihood suffers predicting probable answers means model trained maximum likelihood tend output short general answers common vocabulary log likelihood improves dimensions easier t hypotheses training step having dimensions consequently hypothesis generating step lower log likelihood perplexity perplexity measures model s certainty predictions advantages perplexity keukeleire calculating perplexity simple nt require human interference easy interpret easy optimize model improved perplexity score held likelihood usually presented perplexity deterministic transformation likelihood information theoretic quantity inception score rewards high condence class labels generated instance salimans et al provide aml text analysis generation preprint general evaluation gans trained imagenet limited utility settings fowl et al frechet inception distance fid fid measure distance vaserstein gaussians means covariances taken embedding real generated data heusel et al cfka et al fid assumes training data sufcient reward producing diversity training data fowl et al n gram based metrics distinct n measure diversity computes number distinct n grams normalized number ngrams li et al sentence similarity metrics sentencebert sent bert reimers gurevych rouge metrics text generation video captioning summarization tasks lin introduced set metrics evaluate machine generated text summaries rouge variants rouge l rouge metrics meteor meteor metric evaluation translation explicit ordering proposed banerjee lavie meteor metric mainly text generation image video captioning question answering tasks embedding based metrics main approach embed generated sentences latent space evaluate space tevet et al du black suggest cluster embedded sentences k means use inertia measure diversity common metrics gleu score edit distance phoneme diacritic error rate metrics gans traditional probability based lm metrics tevet et al papers indicated need use new metrics evaluate gans e esteban et al zhu et al cao metrics proposed gans include divergence based metrics f gan nowozin et al ls gan mao et al divergence koochali et al self bleu zhu et al integral probability metrics wasserstein gan wga arjovsky et al gulrajani et al domain specic metrics e attack success rate gao et al random network distillation rnd burda et al text generation datasets datasets general tasks research nlp mentioned following links org aclwiki com task data text generation awesome org tokenmill awesome com niderhoff nlp datasets ai datasets datasets natural language com datasets natural language kdnuggets com tag datasets list datasets benchmarks gan research papers particular coco image captions chen et al wmt org translation task html guo et al weibodial qian et al aml text analysis generation preprint chinese poems dataset proposed zhang lapata related work yu al lin et al rajeswar et al cub captions wah et al dada engine create phishing emails baki et al memory based models rnn versus lstm mentioned earlier vanilla rnns perform learning sequences long term temporal dependence issues exploding gradients bengio et al alternatively convolutional neural networks cnns recurrent neural networks rnns gated recurrent unit gru long short term memory lstm models effective approaches eld sequential modeling methods design forget gate essence models sun et al lstm model type rnn remember relevant information longer regular rnn result better learn long term patterns olah lstm models provide mechanism able store discard information saved previous steps limiting accumulated error constant error carousels hochreiter schmidhuber manzelli et al defense nlp adversarial attacks generating adversarial attacks text shown challenging images audios discrete nature variations original text applied different levels character word sentence levels recent relevant studies showed examples nlp vulnerabilities zhou et al reading comprehension jia liang text classication alzantot et al liang et al wong machine translation cheng et al ebrahimi et al dialogue systems cheng et al dependency parsing zheng et al black versus white box attacks current adversarial attacks roughly divided categories white box attacks black box gray box attacks according data model architecture parameters target accessible black box attacks called zero knowledge attack limited information target model accessible example certain number model queries e oracle queries granted defenses guo et al xie et al shown robust black box attacks gray box attacks limited knowledge attacks partial knowledge model attack e type features type training data assumed white box perfect knowledge attacks attacks exploit model internal information assume complete knowledge targeted model including parameter values architecture training method cases training data table shows samples research publications categories papers identied category high level classes dimensions attacks barreno et al causative versus exploratory causative attacks training process altered models trained adversary datasets exploratory attacks attacker tries exploit existing weaknesses integrity versus availability false negatives versus false positive targeted particular input indiscriminate input fails reactive versus proactive reactive defense waits attacked detects adversarial example hand proactive attacks involve training model resilient adversarial examples defense specic attacks focus nlp aml text analysis generation preprint dirichlet neighborhood ensemble dne randomized smoothing method training model substitution based attacks zhou et al adversarial training defense method miyato et al sato et al zhu et al increasing model robustness adding perturbations word embedding goodfellow et al certied defenses certied defenses proposed literature order provide guarantees robustness specic types attacks huang et al jia liang defensive distillation defensive distillation arbitrary nn increase robustness reducing success rate attacks ability carlini wagner defense randomization cohen et al liu et al summary conclusion paper recent literature adversarial machine learning text generation tasks summarized goal present stop source researchers interested readers learn basic components research trends eld noticed continuous expansion applications models algorithms paper serve introduction eld readers need follow researchers references referred based focuses interests references antonia creswell tom white vincent dumoulin kai arulkumaran biswa sengupta anil bharath generative adversarial networks overview ieee signal processing magazine md akmal haidar mehdi rezagholizadeh textkd gan text generation knowledge distillation generative adversarial networks canadian conference articial intelligence pages springer ian j goodfellow jonathon shlens christian szegedy explaining harnessing adversarial examples arxiv preprint lantao yu weinan zhang jun wang yong yu seqgan sequence generative adversarial nets policy gradient arxiv e prints page arxiv preprint carlos florensa david held xinyang geng pieter abbeel automatic goal generation reinforcement learning agents international conference machine learning pages pmlr tong che yanran li ruixiang zhang r devon hjelm wenjie li yangqiu song yoshua bengio likelihood augmented discrete generative adversarial networks arxiv preprint jiaxian guo sidi lu han cai weinan zhang yong yu jun wang long text generation adversarial training leaked information proceedings aaai conference articial intelligence volume kevin lin dianqi li xiaodong zhengyou zhang ming ting sun adversarial ranking language generation advances neural information processing systems pages william fedus ian goodfellow andrew m dai maskgan better text generation lling arxiv preprint jingjing xu xuancheng ren junyang lin xu sun diversity promoting gan cross entropy based generative adversarial network diversied text generation proceedings conference empirical methods natural language processing pages massimo caccia lucas caccia william fedus hugo larochelle joelle pineau laurent charlin language gans falling short arxiv preprint ronald j williams simple statistical gradient following algorithms connectionist reinforcement learning machine learning martin arjovsky soumith chintala lon bottou wasserstein gan arxiv preprint hossein hosseini sreeram kannan baosen zhang radha poovendran deceiving google s perspective api built detecting toxic comments arxiv preprint xiang zhang junbo zhao yann lecun character level convolutional networks text classication advances neural information processing systems jinfeng li shouling ji tianyu du bo li ting wang textbugger generating adversarial text real world applications arxiv preprint aml text analysis generation preprint yonatan belinkov yonatan bisk synthetic natural noise break neural machine translation arxiv preprint ji gao jack lanchantin mary lou soffa yanjun qi black box generation adversarial text sequences evade deep learning classiers ieee security privacy workshops spw pages ieee javid ebrahimi anyi rao daniel lowd dejing dou hotip white box adversarial examples text classication arxiv preprint stephan brown petar milkov sameep patel yi zen looi ziqian dong huanying gu n sertac artan edwin jain acoustic visual approaches adversarial text generation google perspective international conference computational science computational intelligence csci pages ieee danish pruthi bhuwan dhingra zachary c lipton combating adversarial misspellings robust word recognition arxiv preprint steffen eger gzde gl sahin andreas rckl ji ung lee claudia schulz mohsen mesgar krishnkant swarnkar edwin simpson iryna gurevych text processing like humans visually attacking shielding nlp systems arxiv preprint thai le suhang wang dongwon lee malcom generating malicious comments attack neural fake news detection models arxiv preprint javid ebrahimi daniel lowd dejing dou adversarial examples character level neural machine translation arxiv preprint classication problems volodymyr kuleshov shantanu thakoor tingfung lau stefano ermon adversarial examples natural language puyudi yang jianbo chen cho jui hsieh jane ling wang michael jordan greedy attack gumbel attack generating adversarial examples discrete data journal machine learning research di jin zhijing jin joey tianyi zhou peter szolovits bert robust strong baseline natural language proceedings aaai conference articial intelligence attack text classication entailment volume pages eric wallace shi feng nikhil kandpal matt gardner sameer singh universal adversarial triggers attacking analyzing nlp arxiv preprint siddhant garg goutham ramakrishnan bae bert based adversarial examples text classication arxiv preprint yichao zhou jyun yu jiang kai wei chang wei wang learning discriminate perturbations blocking adversarial attacks text classication arxiv preprint marco tulio ribeiro sameer singh carlos guestrin semantically equivalent adversarial rules debugging nlp models proceedings annual meeting association computational linguistics volume long papers pages yuan zang fanchao qi chenghao yang zhiyuan liu meng zhang qun liu maosong sun word level textual adversarial attacking combinatorial optimization proceedings annual meeting association computational linguistics pages moustafa alzantot yash sharma supriyo chakraborty huan zhang cho jui hsieh mani b srivastava genattack proceedings genetic evolutionary practical black box attacks gradient free optimization computation conference pages jiwei li monroe dan jurafsky understanding neural networks representation erasure arxiv preprint jianyu wang haichao zhang bilateral adversarial training fast training robust models adversarial attacks proceedings ieee international conference computer vision pages yajie wang haoran lv xiaohui kuang gang zhao yu tan quanxin zhang jingjing hu physical world adversarial patch blinding object detection models information sciences nicolas papernot patrick mcdaniel xi wu somesh jha ananthram swami distillation defense adversarial perturbations deep neural networks ieee symposium security privacy sp pages ieee motoki sato jun suzuki hiroyuki shindo yuji matsumoto embedding space text arxiv preprint interpretable adversarial perturbation input aml text analysis generation preprint zhitao gong wenlu wang bo li dawn song wei shinn ku adversarial texts gradient methods arxiv preprint moustafa alzantot yash sharma ahmed elgohary bo jhang ho mani srivastava kai wei chang generating natural language adversarial examples arxiv preprint bin liang hongcheng li miaoqiang su pan bian xirong li wenchang shi deep text classication fooled arxiv preprint shuhuai ren yihe deng kun wanxiang che generating natural language adversarial examples probability weighted word saliency proceedings annual meeting association computational linguistics pages robin jia percy liang adversarial examples evaluating reading comprehension systems arxiv preprint mohit iyyer john wieting kevin gimpel luke zettlemoyer adversarial example generation syntactically controlled paraphrase networks arxiv preprint yong cheng lu jiang wolfgang macherey robust neural machine translation doubly adversarial inputs arxiv preprint paul michel xian li graham neubig juan miguel pino evaluation adversarial perturbations sequence models arxiv preprint qi lei lingfei wu pin yu chen alexandros g dimakis inderjit s dhillon michael witbrock discrete adversarial attacks submodular optimization applications text classication arxiv preprint haizhong zheng ziqi zhang honglak lee atul prakash understanding diagnosing vulnerability adversarial attacks arxiv preprint mahir jethanandani derek tang adversarial attacks lipnet end end sentence level lipreading ieee security privacy workshops spw pages ieee matthias blohm glorianna jagfeld ekta sood xiang yu ngoc thang vu comparing attention based tional recurrent neural networks success limitations machine reading comprehension arxiv preprint shahryar baki rakesh verma arjun mukherjee omprakash gnawali scaling effectiveness email masquerade attacks exploiting natural language generation proceedings acm asia conference computer communications security pages yuanshun yao bimal viswanath jenna cryan haitao zheng ben y zhao automated crowdturng attacks defenses online review systems proceedings acm sigsac conference computer communications security pages ronald j williams david zipser learning algorithm continually running fully recurrent neural networks neural computation alex m lamb anirudh goyal alias parth goyal ying zhang saizheng zhang aaron c courville yoshua bengio professor forcing new algorithm training recurrent networks advances neural information processing systems pages marcaurelio ranzato sumit chopra michael auli wojciech zaremba sequence level training recurrent neural networks arxiv preprint ian goodfellow jean pouget abadie mehdi mirza bing xu david warde farley sherjil ozair aaron courville yoshua bengio generative adversarial networks communications acm karl pearson asymmetrical frequency curves nature lars peter hansen large sample properties generalized method moments estimators econometrica journal econometric society pages lawrence r rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee tim salimans ian goodfellow wojciech zaremba vicki cheung alec radford xi chen improved techniques training gans arxiv preprint youssef mroueh tom sercu fisher gan advances neural information processing systems pages aml text analysis generation preprint greg lewis vasilis syrgkanis adversarial generalized method moments arxiv preprint andrew bennett nathan kallus tobias schnabel deep generalized method moments instrumental variable analysis advances neural information processing systems pages jerry fodor zenon w pylyshyn al connectionism cognitive architecture critical analysis cognition computation geoffrey e hinton simon osindero yee whye teh fast learning algorithm deep belief nets neural diederik p kingma max welling auto encoding variational bayes arxiv preprint cihang xie jianyu wang zhishuai zhang zhou ren alan yuille mitigating adversarial effects randomization arxiv preprint haiyan yin dingcheng li xu li ping li meta cotgan meta cooperative training paradigm improving adversarial text generation aaai pages liqun chen shuyang dai chenyang tao haichao zhang zhe gan dinghan shen yizhe zhang guoyin wang ruiyi zhang lawrence carin adversarial text generation feature mover s distance advances neural information processing systems pages sai rajeswar sandeep subramanian francis dutil christopher pal aaron courville adversarial generation natural language arxiv preprint lantao yu weinan zhang jun wang yong yu seqgan sequence generative adversarial nets policy gradient proceedings aaai conference articial intelligence volume richard s sutton david mcallester satinder p singh yishay mansour policy gradient methods ment learning function approximation advances neural information processing systems pages hongyu guo generating text deep reinforcement learning arxiv preprint dzmitry bahdanau philemon brakel kelvin xu anirudh goyal ryan lowe joelle pineau aaron courville yoshua bengio actor critic algorithm sequence prediction arxiv preprint chris j maddison andriy mnih yee whye teh concrete distribution continuous relaxation discrete random variables arxiv preprint yizhe zhang zhe gan kai fan zhi chen ricardo henao dinghan shen lawrence carin adversarial feature matching text generation arxiv preprint matt j kusner jos miguel hernndez lobato gans sequences discrete elements gumbel softmax distribution arxiv preprint eric jang shixiang gu ben poole categorical reparameterization gumbel softmax arxiv preprint weili nie nina narodytska ankit patel relgan relational generative adversarial networks text generation international conference learning representations alexander sasha vezhnevets simon osindero tom schaul nicolas heess max jaderberg david silver koray kavukcuoglu feudal networks hierarchical reinforcement learning arxiv preprint yi lin tuan hung yi lee improving conditional sequence generative adversarial networks stepwise evaluation ieee acm transactions audio speech language processing deepak pathak pulkit agrawal alexei efros trevor darrell curiosity driven exploration self supervised prediction proceedings ieee conference computer vision pattern recognition workshops pages jacques robin revision based generation natural language summaries providing historical background corpus based analysis design implementation evaluation kumiko tanaka ishii kiti hasida itsuki noda reactive content selection generation real time soccer commentary coling volume international conference computational linguistics samy bengio oriol vinyals navdeep jaitly noam shazeer scheduled sampling sequence prediction recurrent neural networks advances neural information processing systems oriol vinyals quoc le neural conversational model arxiv preprint aml text analysis generation preprint sam wiseman stuart m shieber alexander m rush challenges data document generation arxiv preprint preprint rajarshi bhowmik gerard de melo generating ne grained open vocabulary entity type descriptions arxiv ratish puduppully li dong mirella lapata data text generation content selection planning proceedings aaai conference articial intelligence volume pages alex graves generating sequences recurrent neural networks arxiv preprint zhishuai zhang siyuan qiao cihang xie wei shen bo wang alan l yuille single shot object detection enriched semantics proceedings ieee conference computer vision pattern recognition pages zhiting hu zichao yang xiaodan liang ruslan salakhutdinov eric p xing controllable text generation arxiv preprint martin schmitt sahand sharifzadeh volker tresp hinrich schtze unsupervised joint system text generation knowledge graphs semantic parsing proceedings conference empirical methods natural language processing emnlp pages yau shian wang yun nung chen hung yi lee topicgan unsupervised text generation explainable latent martin schmitt sahand sharifzadeh volker tresp hinrich schtze unsupervised text generation structured data arxiv preprint oren sheffer castel raz landau going grean novel framework evaluation metric graph text topics generation task rik koncel kedziorski dhanush bekal yi luan mirella lapata hannaneh hajishirzi text generation knowledge graphs graph transformers arxiv preprint zhijing jin qipeng guo xipeng qiu zheng zhang genwiki dataset million content sharing text graphs unsupervised graph text generation proceedings international conference computational linguistics pages chlo kiddon luke zettlemoyer yejin choi globally coherent text generation neural checklist models proceedings conference empirical methods natural language processing pages zhiting hu haoran shi bowen tan wentao wang zichao yang tiancheng zhao junxian lianhui qin di wang xuezhe ma al texar modularized versatile extensible toolkit text generation arxiv preprint omar abdelwahab adel elmaghraby deep learning based vs markov chain based text generation cross domain adaptation sentiment classication ieee international conference information reuse integration iri pages ieee sidi lu yaoming zhu weinan zhang jun wang yong yu neural text generation past present arxiv preprint yaoming zhu sidi lu lei zheng jiaxian guo weinan zhang jun wang yong yu texygen benchmarking platform text generation models international acm sigir conference research development information retrieval pages hechong wang wei zhang yuesheng zhu zhiqiang bai data text generation attention recurrent unit international joint conference neural networks ijcnn pages ieee sanidhya mangal poorva joshi rahul modak lstm vs gru vs bidirectional rnn script generation arxiv preprint mercy m moila thipe modipa development sepedi text generation model long short term memory proceedings international conference intelligent innovative computing applications pages hongyuan mei mohit bansal matthew r walter talk selective generation lstms coarse alignment arxiv preprint hongyu zang xiaojun wan automatic generation product reviews aspect sentiment scores proceedings international conference natural language generation pages ilya sutskever james martens geoffrey e hinton generating text recurrent neural networks icml aml text analysis generation preprint jean pouget abadie dzmitry bahdanau bart van merrienboer kyunghyun cho yoshua bengio overcoming curse sentence length neural machine translation automatic segmentation arxiv preprint ehud reiter nlg vs templates arxiv preprint cmp kees van deemter marit theune emiel krahmer real versus template based natural language generation false opposition computational linguistics sam wiseman stuart m shieber alexander m rush learning neural templates text generation arxiv preprint hao peng ankur p parikh manaal faruqui bhuwan dhingra dipanjan das text generation exemplar based adaptive decoding arxiv preprint eder miranda de novais thiago dias tadeu ivandr paraboni improved text generation n gram statistics ibero american conference articial intelligence pages springer ilya sutskever oriol vinyals quoc v le sequence sequence learning neural networks advances neural information processing systems dzmitry bahdanau kyunghyun cho yoshua bengio neural machine translation jointly learning align translate arxiv preprint renjie zheng mingbo ma baigong zheng liang huang speculative beam search simultaneous translation arxiv preprint liqun chen yizhe zhang ruiyi zhang chenyang tao zhe gan haichao zhang bai li dinghan shen changyou improving sequence sequence learning optimal transport arxiv preprint chen lawrence carin wenhao yu chenguang zhu zaitang li zhiting hu qingyun wang heng ji meng jiang survey knowledge enhanced text generation arxiv preprint william woods transition network grammars natural language analysis communications acm ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser illia polosukhin attention need advances neural information processing systems pages adam santoro ryan faulkner david raposo jack rae mike chrzanowski theophane weber daan wierstra oriol vinyals razvan pascanu timothy lillicrap relational recurrent neural networks advances neural information processing systems pages rafal jozefowicz oriol vinyals mike schuster noam shazeer yonghui wu exploring limits language modeling arxiv preprint ciprian chelba tomas mikolov mike schuster qi ge thorsten brants phillipp koehn tony robinson billion word benchmark measuring progress statistical language modeling arxiv preprint cristina garbacea samuel carton shiyan yan qiaozhu mei judge judges large scale evaluation study neural language models online review generation arxiv preprint tsvetomila mihaylova andr ft martins scheduled sampling transformers arxiv preprint renjie zheng yilin yang mingbo ma liang huang ensemble sequence level training multimodal mt osu baidu multimodal machine translation system report arxiv preprint guy tevet gavriel habib vered shwartz jonathan berant evaluating text gans language models arxiv preprint eric wong leslie rice j zico kolter fast better free revisiting adversarial training arxiv preprint alexey kurakin ian goodfellow samy bengio adversarial machine learning scale arxiv preprint yinpeng dong fangzhou liao tianyu pang hang su jun zhu xiaolin hu jianguo li boosting adversarial attacks momentum proceedings ieee conference computer vision pattern recognition pages aml text analysis generation preprint aleksander madry aleksandar makelov ludwig schmidt dimitris tsipras adrian vladu deep learning models resistant adversarial attacks arxiv preprint yuzhe yang guo zhang dina katabi zhi xu net effective adversarial robustness matrix estimation arxiv preprint ji lin chuang gan song han defensive quantization efciency meets robustness arxiv preprint marius mosbach maksym andriushchenko thomas trost matthias hein dietrich klakow logit pairing methods fool gradient based attacks arxiv preprint harini kannan alexey kurakin ian goodfellow adversarial logit pairing arxiv preprint jacob buckman aurko roy colin raffel ian goodfellow thermometer encoding hot way resist adversarial examples international conference learning representations cihang xie yuxin wu laurens van der maaten alan l yuille kaiming feature denoising improving adversarial robustness proceedings ieee conference computer vision pattern recognition pages ajil jalal andrew ilyas constantinos daskalakis alexandros g dimakis robust manifold defense adversarial training generative models arxiv preprint qiao qian minlie huang haizhou zhao jingfang xu xiaoyan zhu assigning personality prole chatting machine coherent conversation generation ijcai pages daniel jakubovitz raja giryes improving dnn robustness adversarial attacks jacobian regularization proceedings european conference computer vision eccv pages ali shafahi mahyar najibi zheng xu john p dickerson larry s davis tom goldstein universal adversarial training aaai pages guneet s dhillon kamyar azizzadenesheli zachary c lipton jeremy bernstein jean kossai aran khanna anima anandkumar stochastic activation pruning robust adversarial defense arxiv preprint nicolas papernot patrick mcdaniel somesh jha matt fredrikson z berkay celik ananthram swami limitations deep learning adversarial settings ieee european symposium security privacy pages ieee anirban chakraborty manaar alam vishal dey anupam chattopadhyay debdeep mukhopadhyay adversarial attacks defences survey arxiv preprint ali shafahi mahyar najibi mohammad amin ghiasi zheng xu john dickerson christoph studer larry s davis gavin taylor tom goldstein adversarial training free advances neural information processing systems pages dinghuai zhang tianyuan zhang yiping lu zhanxing zhu bin dong propagate accelerating adversarial training maximal principle advances neural information processing systems pages cody coleman deepak narayanan daniel kang tian zhao jian zhang luigi nardi peter bailis kunle olukotun chris r matei zaharia dawnbench end end deep learning benchmark competition training jinxin chang ruifang longbiao wang xiangyu zhao ting yang ruifang wang semi supervised stable variational network promoting replier consistency dialogue generation proceedings conference empirical methods natural language processing international joint conference natural language processing emnlp ijcnlp pages jiwei li monroe alan ritter michel galley jianfeng gao dan jurafsky deep reinforcement learning dialogue generation arxiv preprint hamilton zhitao ying jure leskovec inductive representation learning large graphs advances neural information processing systems pages muhammad nabeel adnan riaz wang zhenyu cas gans approach dialogue policy learning based gan rl techniques int j adv comput sci appl zhen yang wei chen feng wang bo xu improving neural machine translation conditional sequence generative adversarial nets arxiv preprint aml text analysis generation preprint lijun wu yingce xia fei tian li zhao tao qin jianhuang lai tie yan liu adversarial neural machine translation asian conference machine learning pages pmlr zhirui zhang shujie liu mu li ming zhou enhong chen bidirectional generative adversarial networks neural machine translation proceedings conference computational natural language learning pages rakshith shetty bernt schiele mario fritz author attribute anonymity adversarial training neural machine translation usenix security symposium usenix security pages kishore papineni salim roukos todd ward wei jing zhu bleu method automatic evaluation machine translation proceedings annual meeting association computational linguistics pages s e robertson s walker simple effective approximations poisson model probabilistic weighted retrieval proceedings annual international acm sigir conference research development information retrieval pages matt j kusner yu sun nicholas kolkin kilian q weinberger word embeddings document distances proceedings international conference international conference machine learning volume pages jmlr org pia keukeleire correspondence perplexity scores human evaluation generated tv scripts liam fowl micah goldblum arjun gupta amr sharaf tom goldstein random network distillation diversity metric image text generation arxiv preprint leonid nisonovich vaserstein markov processes denumerable products spaces describing large systems automata problemy peredachi informatsii martin heusel hubert ramsauer thomas unterthiner bernhard nessler sepp hochreiter gans trained time scale update rule converge local nash equilibrium advances neural information processing systems pages ondrej cfka aliaksei severyn enrique alfonseca katja filippova eval trust wrong comparing sentence generation models arxiv preprint jiwei li michel galley chris brockett jianfeng gao bill dolan diversity promoting objective function neural conversation models arxiv preprint chin yew lin rouge package automatic evaluation summaries text summarization branches pages satanjeev banerjee alon lavie meteor automatic metric mt evaluation improved correlation human judgments proceedings acl workshop intrinsic extrinsic evaluation measures machine translation summarization pages wenchao du alan w black boosting dialog response generation proceedings annual meeting association computational linguistics pages cristbal esteban stephanie l hyland gunnar rtsch real valued medical time series generation recurrent conditional gans arxiv preprint divya saxena jiannong cao d gan deep generative adversarial nets spatio temporal prediction arxiv preprint sebastian nowozin botond cseke ryota tomioka gan training generative neural samplers variational divergence minimization advances neural information processing systems pages xudong mao qing li haoran xie raymond yk lau zhen wang stephen paul smolley squares generative adversarial networks proceedings ieee international conference computer vision pages alireza koochali peter schichtel andreas dengel sheraz ahmed probabilistic forecasting sensory data generative adversarial networks forgan ieee access ishaan gulrajani faruk ahmed martin arjovsky vincent dumoulin aaron c courville improved training wasserstein gans advances neural information processing systems pages nan gao hao xue wei shao sichen zhao kyle kai qin arian prabowo mohammad saiedur rahaman flora d salim generative adversarial networks spatio temporal data survey arxiv preprint yuri burda harrison edwards amos storkey oleg klimov exploration random network distillation arxiv preprint aml text analysis generation preprint xinlei chen hao fang tsung yi lin ramakrishna vedantam saurabh gupta piotr dollr c lawrence zitnick microsoft coco captions data collection evaluation server arxiv preprint xingxing zhang mirella lapata chinese poetry generation recurrent neural networks proceedings conference empirical methods natural language processing emnlp pages catherine wah steve branson peter welinder pietro perona serge belongie caltech ucsd dataset aolan sun jianzong wang ning cheng huayi peng zhen zeng lingwei kong jing xiao graphpb graphical representations prosody boundary speech synthesis arxiv preprint christopher olah understanding lstm networks sepp hochreiter jrgen schmidhuber long short term memory neural computation rachel manzelli vijay thakkar ali siahkamari brian kulis end end model automatic music generation combining deep raw symbolic audio networks proceedings musical metacreation workshop international conference computational creativity salamanca spain catherine wong dancin fooling text classiers adversarial text example generation arxiv preprint minhao cheng jinfeng yi pin yu chen huan zhang cho jui hsieh evaluating robustness sequence sequence models adversarial examples aaai pages marco barreno blaine nelson anthony d joseph j doug tygar security machine learning machine learning yi zhou xiaoqing zheng cho jui hsieh kai wei chang xuanjing huang defense adversarial attacks nlp dirichlet neighborhood ensemble arxiv preprint takeru miyato andrew m dai ian goodfellow adversarial training methods semi supervised text classication arxiv preprint chen zhu yu cheng zhe gan siqi sun thomas goldstein jingjing liu freelb enhanced adversarial training language understanding arxiv preprint po sen huang robert stanforth johannes welbl chris dyer dani yogatama sven gowal krishnamurthy dvijotham pushmeet kohli achieving veried robustness symbol substitutions interval bound propagation arxiv preprint nicholas carlini david wagner evaluating robustness neural networks ieee symposium security privacy sp pages ieee jeremy m cohen elan rosenfeld j zico kolter certied adversarial robustness randomized smoothing arxiv preprint xuanqing liu minhao cheng huan zhang cho jui hsieh robust neural networks random ensemble proceedings european conference computer vision eccv pages
