adversarial machine learning text analysis generation preprint izzat alsmadi department computing cyber security texas san antonio san antonio edu january abstract research eld adversarial machine learning witnessed signicant interest years machine learner model secure deliver main objectives acceptable accuracy efciency time resist different types attempts adversarial attacks paper focuses studying aspects research trends adversarial machine learning specically text analysis generation paper summarizes main research trends eld gan algorithms models types attacks defense attacks keywords adversarial machine learning text generation generative adversarial networks gan introduction basic generative adversarial network gan model includes main modules generator discriminator generator discriminator implicit function expressions usually implemented deep neural networks creswell applying gan natural language processing nlp tasks text generation challenging discrete nature text consequently straightforward pass gradients discrete output words generator haidar rezagholizadeh text input discrete text generators model problem sequential decision making process model state previously generated characters words sentences action prediction character word sentence generated generative net stochastic policy maps current state distribution action space generative adversarial network gan create new data instances resemble original training data original gan described goodfellow following components workow nns discriminator generator discriminator role simple classier distinguish real instances positive examples original training dataset fake instances negative example created generator generator tries fool discriminator synthesizing fake instances resemble real ones training progresses generator gets closer producing instances fool discriminator generator trained discriminator gets worse telling difference real fake generally speaking generator module task harder discriminator discriminator job binary generator job complex aml text analysis generation preprint nns compete different goals goal discriminator discriminate real fake instances goal generator eventually learn real instances data fool discriminator trained separately assumes module xed time cycle training avoid dealing moving target complex accuracy generator generate fake instances indicates accuracy discriminator sign competition game rivals generator instances negative training examples discriminator discriminator punishes generator producing incorrect instances rewards producing correct instances generator evolves discriminator punishes rewards effect good discriminator reveal information generator progress addition discriminator generator modules gans include following components generator random input module generator network transforms random input data instance generator loss punishes generator failing fool discriminator propagation module adjusts weights calculating weight impact output discriminator generator conditional versus joint probability model difference discriminator generator difference conditional probability joint probability given set data instances set labels conditional probability known posterior probability denote prior probability events respectively conditional entropy indicates extra information need supply average communicate given party knows joint entropy represents information needed specify value discrete random variables variations components generator discriminator work trained function gans problem text generation gradients discriminator passed generator explicitly deal issue gan based models seqgan goal gan florensa maligan che leakgan guo rankgan lin maskgan fedus caccia treat text generation sequential decision making process utilize policy gradient williams overcome difculty score predicted discriminator reinforcement train generator yielding hybrid model gan models utilize agents control gans agent forms decision making network interacts environment taking available actions collects rewards scalability limitation agent trained capable achieving single task specied reward function gans methods training propagation applying gan text analysis challenging text discrete consequently need pass gradients discrete output words generator haidar rezagholizadeh generator discriminator modules train improve generator module train self auto variational encoders code decoder randomly values produce different outputs goal self encoder reconstruction error smaller smaller generator uses propagation discriminator improve future instances update model weights discriminator train learn discriminator process distinguish instance label real generated trained based real instances original dataset fake instances generator gan loss functions gan uses loss functions evaluate distance distribution data generated gan distribution real data gan loss functions generator discriminator training minimax loss generator tries minimize loss function discriminator tries maximize goodfellow aml text analysis generation preprint wasserstein loss default loss function gan estimators arjovsky gans discriminator try binary decision instance real fake provide value zero threshold decided range values fake instances versus values real instances character word sentence level attacks aml research publications demonstrate picture based datasets growing recent trend applications aml text analysis nlp taxonomy aml nlp divided following attack levels character level attacks involve different possible types character level manipulations swap substitution deletion insertion repeating hot character embedding visual character embedding hosseini zhang textbugger belinkov bisk gao hotip ebrahimi brown pruthi eger character level attacks simple easy defend deploying spell check proofread algorithms word level attacks similar character level attacks approaches word level attacks manipulation include word embedding language models lter words synonyms substitutes ebrahimi ebrahimi kuleshov yang wallace gao garg ramakrishnan ribeiro alzantot ribeiro wang zhang wang search algorithms include gradient descent genetic algorithms saliency based greedy algorithm sampling papernot sato gong alzantot zhou liang ren jin comparison character level attacks attacks created word level approaches ble humans difcult machine learning algorithms defend sentence level attacks attacks usually based text paraphrasing demand longer time adversary text generation examples research publications sentence level include jia liang iyyer cheng michel lei zheng jethanandani tang hybrid multi level attacks attacks use combination character word sentence level approaches hotflip ebrahimi blohm wallace sequence generative text generator generative models approaches natural language generation nlg techniques allow generation natural language text based given context nlg involve text generation based predened grammar dada engine baki leverage deep learning neural networks rnn yao generating text describe popular approaches found relevant literature scope aml classical training language models teacher professor forcing teacher forcing common approach training rnns order maximize likelihood token target sequences given previous tokens sequence williams zipser time step training model evaluated based likelihood target given groundtruth sequence teacher forcing training generator means decoder exposed previous groundtruth token rnns trained teacher forcing able model distribution matches target joint distribution modeled properly rnn models prediction future steps created error model propagated following step resulting low performance solution training model professor forcing lamb professor forcing rnn results ground truth given input training teacher forcing output looped step forced training discriminator classies wether output created teacher forced model free running model aml text analysis generation preprint conventional inference maximum likelihood estimation mle mle conducted real data samples parameters updated directly according data samples lead overly smooth generative model goal select distribution maximizes likelihood generating data practical sample scenarios mle prone exposure bias issues training set additionally inference generation stage error time step accumulate sentence generation process ranzato following methods utilize mle hidden markov model hmm hidden markov model hmm probability graph model depict transition laws hidden states intentional features data model observable variables foundation hmm markov chain represented special weighted nite state automaton majority generative models require utilization markov chains goodfellow creswell observable sequence hmm participle given sentence speech pos tag hidden state different pos method moments method moments mom method learned moments early principle learning pearson situations mom preferable mle mle computationally challenging mom ravuri generalized method moments gmm addition data distribution class set relevant feature functions given instance space hansen rabiner research contributions aml mom moment matching include salimans mroueh sercu lewis syrgkanis bennett restricted boltzmann machine rbm restricted boltzmann machine rbm layer neural network consisting visible layer hidden layer hinton important generative model capable learning representations data generative models evolved rbm based models helmholtz machines hms fodor deep belief nets dbn hinton variational auto encoders vaes kingma welling generative adversarial networks gans cooperative training method cooperative training method ctm language model trained online offer target distribution minimizing divergence real data distribution generated distribution xie yin based versus free text generation gan models originally developed learning continuous discrete distribution discrete nature text input handicaps use gans gans reinforcement learning algorithm policy gradient unbiased gradient estimator generator obtain reward discriminator chen based generation reinforcement learning technique train agent perform certain tasks generality reinforcement learning studied disciplines gan models use discriminating module guide training generative module reinforcement learning policy shown promising results text generation guo methods proposed text generation gan lin rajeswar che che models applied sentence generation actor critic algorithm deep network sutton guo bahdanau optimization challenge based approaches yield high variance gradient estimates maddison zhang free gans text generation examples models use alternative latent space based solutions continuous approximation discrete sampling models apply simple soft argmax operator gumbel softmax trick provide continuous approximation discrete distribution text examples research efforts category include zhang gumbelsoftmax gan gsgan kusner hernndez lobato jang maddison gan chen gsgan kusner hernndez lobato relgan nie aml text analysis generation preprint long versus short text generation literature area differentiates generation short texts words generation long text applications different majority publications focus short text generation challenging different challenges discussed literature specially long text generation example unique challenges long text generation sparse reward issue scalar guiding signal available entire sequence generated vezhnevets guo sutton main disadvantage sparse reward problem making training sample inefcient tuan lee model based rls proposed recently solve problems extremely sparse rewards pathak supervised versus unsupervised text generation majority work area falls supervised category robin ishii bahdanau bengio vinyals wiseman bhowmik melo puduppully supervised problem particular sentence terms words sentence seen input features term feature target examples publications fall unsupervised text generation include graves zhang schmitt unsupervised text generated explainable latent topics wang structured data schmitt sheffer knowledge graphs kgs bhowmik melo koncel kedziorski schmitt jin machine learning algorithms text generation rnn lstm versus gru bidirectionalrnn text generation state art text generation models based recurrent neural networks rnns papers discussed different deep learning rnn algorithms mentioned automatic text generation kiddon abdelwahab elmaghraby nie zhu wang mangal moila modipa mangal unlike traditional methods rnn based approaches rely data driven manual intervention emphasize end end encoder decoder structure different performance metrics methods evaluate output process log likelihood loss function overall processing time loss function training model negative log likelihood negative log probability target sequence lstm shows good model aspects comparison evaluated models mei wan mangal recent gans text generation kusner hernndez lobato guo lin fedus lstm papers sutskever pouget abadie shown standard lstm decoder perform generating long text sequences template based rule based versus neural text generation classical approaches text generation include template based rule based gram based log linear based models rule based techniques grammar based methods structured rules written based accumulated knowledge template based approaches simple replacing words users choices synonyms reiter deemter wiseman peng gram models widely nlp tasks text generation gram approach word gram predicted inferred words appear gram novais beam search greedy search popular deterministic decoding approaches beem search greedy search sutskever aml text analysis generation preprint bahdanau zheng beam search maintains xed size set partially decoded sequences beam search common search strategy improve results tasks text generation machine translation dependency parsing greedy search selects highest probability token time step greedy search seen special case beam search sequence sequence models knowledge enhancement methods seq seq models common architectures text generation tasks input output modeled sequences tokens words model convert input sequence output sequence specically rst model encodes input sequence set vector representations recurrent neural network rnn second rnn decodes output sequence step step seq seq models commonly trained maximum likelihood estimation mle chen challenge seq seq models input text provide knowledge generate desired output impact quality generated output methods proposed enhance model knowledge input text attention memory linguistic features graphs pre trained language models multi task learning techniques listed com kenlg reading particular enhancement techniques attention bahdanau encoder compresses input text decoder attention mechanism generates output target decoder bound generate sequence text tokens recursive transition network rtn authors baki discuss recursive transition network woods generating fake content similar nature legitimate content rtn detect simplication constructs nodes graph labeled arcs labeled node names terminal symbols rnns essentially equivalent extension context free grammars regular expressions allowed right productions relational memory basic idea relational memory consider xed set memory slots allow interactions memory slots self attention mechanisms vaswani proposed record key information generation process example record information previous generation processes goal enhance text generation process learning memory patterns long text generation provide stateful stateless text generation process self attention memory slots enable interaction facilitate long term dependency modeling vaswani relational based text generations showed better ability modeling longer range dependencies described literature santoro relgan nie google released google google language pre trained model trained billion word corpus publicly available dataset containing mainly news data jozefowicz chelba based layer lstm units layer garbacea scheduled sampling proposed bridge gap training inference sequence prediction tasks avoid exposure bias seq seq generation bengio mihaylova martins inference process seq seq generation true previous target tokens unavailable result replaced tokens generated model yield discrepancy model training inference bengio limitation scheduled sampling target sequences incorrect steps randomly selected ground truth data regardless input chosen zheng ranzato ranzato generating text gans gans implicit generative language models lms learned competition generator network discriminator network discriminator distinguishes uniquely gans lms particularly subject aml adversarial training discriminator gans opposed training based solely maximum likelihood categorical cross entropy lms conventional lms trained adversarial manner unlike traditional approaches teacher forcing gans suffer exposure bias rajeswar tevet exposure bias occurs models fed predicted data ground truth data inference time causes generating poor samples accumulated error yin aml text analysis generation preprint adversarial training techniques adversarial training method help systems robust adversarial attacks examples adversarial training techniques reported literature fast gradient sign method fgsm fgsm add adversarial examples training process goodfellow wong training original samples replaced corresponding adversarial samples generated model trained kurakin suggested use iterative fgsm ifgsm fgsm fgsm rand variants adversarial training order reduce effect label leaking kurakin variants fgsm momentum iterative fast gradient sign method fgsm dong pgd based training proposed madry iteration original samples replaced corresponding adversarial samples generated model trained pgd enhanced different efforts optimization tricks momentum improve adversary dong combination heuristic defenses matrix estimation yang defensive quantization lin logit pairing mosbach kannan thermometer encoding buckman feature denoising xie robust manifold defense jalal nonexpansive nets qian jacobian regularization jakubovitz giryes universal perturbation shafahi stochastic activation pruning dhillon today training pgd adversary remains empirically robust wong jacobian based saliency map approach jsma jsma gradient based white box method proposed use gradient loss class labels respect component input papernot jsma useful targeted miss classication attacks chakraborty accelerating adversarial training cost adversarial training reduced reusing adversarial examples merging inner loop pgd gradient updates model parameters shafahi zhang dawnbench competition submission projects dawnbench competition shown good performance results imagenet classiers comparison research reported training methods coleman wong text generation models tasks applications text generation refers process automatic programmable generation text human intervention sources utilized generation process vary based nature application types applications generating text particular growing discuss section word prediction applications use smart phones websites word prediction nwp called auto completion typical nlp application machine learning perspective nwp classical prediction problem previous current text pool extract prediction model features parameters word predict target feature different algorithms proposed approach nwp problem term frequencies articial intelligence grams neural networks aml text analysis generation preprint dialog generation human machine dialog generation prediction essential topic research eld nlp different applications different domains quality performance process widely vary based available resources training pre training efciency neural networks demonstrated impressive results dialog generation vinyals chang gans dialogue generations research publications hamilton kannan nabeel neural machine translation neural machine translation nmt learning approach automated translation potentials overcome weaknesses classical phrase based translation systems statistical machine learning main difference nmt based model based patterns nmt tries replicate functions human brain assess content sources generating output enhancements nmt achieved attention based neural machine translation popular early open source nmts systran systran rst nmt engine launched examples include google translate facebook bay microsoft adversarial nmt introduced training nmt model assisted adversary elaborately designed convolutional neural network cnn yang zhang shetty text generation metrics key issues text generation widely agreed automated metric evaluating text generated output text generation metrics classied based categories summary categories metrics document similarity based metrics popular approaches measure output comparing source documents human natural language popular metrics category bilingual evaluation understudy bleu papineni embedding similarity embsim zhu bleu variants category include popular classical metrics okapi robertson walker word mover distance wmd kusner cosine dice jaccard measures addition term frequency inverse document frequency idf likelihood based metrics log likelihood negative training loss function nll nll known multiclass entropy outputs probability class likely class typical approach text generation train model neural network performing maximum likelihood estimation mle minimizing negative log likelihood nll text corpus gans standard gan objective goal objective function minimize nll binary classication task goodfellow maximum likelihood suffers predicting probable answers means model trained maximum likelihood tend output short general answers common vocabulary log likelihood improves dimensions easier hypotheses training step having dimensions consequently hypothesis generating step lower log likelihood perplexity perplexity measures model certainty predictions advantages perplexity keukeleire calculating perplexity simple require human interference easy interpret easy optimize model improved perplexity score held likelihood usually presented perplexity deterministic transformation likelihood information theoretic quantity inception score rewards high condence class labels generated instance salimans provide aml text analysis generation preprint general evaluation gans trained imagenet limited utility settings fowl frechet inception distance fid fid measure distance vaserstein gaussians means covariances taken embedding real generated data heusel cfka fid assumes training data sufcient reward producing diversity training data fowl gram based metrics distinct measure diversity computes number distinct grams normalized number ngrams sentence similarity metrics sentencebert sent bert reimers gurevych rouge metrics text generation video captioning summarization tasks lin introduced set metrics evaluate machine generated text summaries rouge variants rouge rouge metrics meteor meteor metric evaluation translation explicit ordering proposed banerjee lavie meteor metric mainly text generation image video captioning question answering tasks embedding based metrics main approach embed generated sentences latent space evaluate space tevet black suggest cluster embedded sentences means use inertia measure diversity common metrics gleu score edit distance phoneme diacritic error rate metrics gans traditional probability based metrics tevet papers indicated need use new metrics evaluate gans esteban zhu cao metrics proposed gans include divergence based metrics gan nowozin gan mao divergence koochali self bleu zhu integral probability metrics wasserstein gan wga arjovsky gulrajani domain specic metrics attack success rate gao random network distillation rnd burda text generation datasets datasets general tasks research nlp mentioned following links org aclwiki com task data text generation awesome org tokenmill awesome com niderhoff nlp datasets datasets datasets natural language com datasets natural language kdnuggets com tag datasets list datasets benchmarks gan research papers particular coco image captions chen wmt org translation task html guo weibodial qian aml text analysis generation preprint chinese poems dataset proposed zhang lapata related work lin rajeswar cub captions wah dada engine create phishing emails baki memory based models rnn versus lstm mentioned earlier vanilla rnns perform learning sequences long term temporal dependence issues exploding gradients bengio alternatively convolutional neural networks cnns recurrent neural networks rnns gated recurrent unit gru long short term memory lstm models effective approaches eld sequential modeling methods design forget gate essence models sun lstm model type rnn remember relevant information longer regular rnn result better learn long term patterns olah lstm models provide mechanism able store discard information saved previous steps limiting accumulated error constant error carousels hochreiter schmidhuber manzelli defense nlp adversarial attacks generating adversarial attacks text shown challenging images audios discrete nature variations original text applied different levels character word sentence levels recent relevant studies showed examples nlp vulnerabilities zhou reading comprehension jia liang text classication alzantot liang wong machine translation cheng ebrahimi dialogue systems cheng dependency parsing zheng black versus white box attacks current adversarial attacks roughly divided categories white box attacks black box gray box attacks according data model architecture parameters target accessible black box attacks called zero knowledge attack limited information target model accessible example certain number model queries oracle queries granted defenses guo xie shown robust black box attacks gray box attacks limited knowledge attacks partial knowledge model attack type features type training data assumed white box perfect knowledge attacks attacks exploit model internal information assume complete knowledge targeted model including parameter values architecture training method cases training data table shows samples research publications categories papers identied category high level classes dimensions attacks barreno causative versus exploratory causative attacks training process altered models trained adversary datasets exploratory attacks attacker tries exploit existing weaknesses integrity versus availability false negatives versus false positive targeted particular input indiscriminate input fails reactive versus proactive reactive defense waits attacked detects adversarial example hand proactive attacks involve training model resilient adversarial examples defense specic attacks focus nlp aml text analysis generation preprint dirichlet neighborhood ensemble dne randomized smoothing method training model substitution based attacks zhou adversarial training defense method miyato sato zhu increasing model robustness adding perturbations word embedding goodfellow certied defenses certied defenses proposed literature order provide guarantees robustness specic types attacks huang jia liang defensive distillation defensive distillation arbitrary increase robustness reducing success rate attacks ability carlini wagner defense randomization cohen liu summary conclusion paper recent literature adversarial machine learning text generation tasks summarized goal present stop source researchers interested readers learn basic components research trends eld noticed continuous expansion applications models algorithms paper serve introduction eld readers need follow researchers references referred based focuses interests references antonia creswell tom white vincent dumoulin kai arulkumaran biswa sengupta anil bharath generative adversarial networks overview ieee signal processing magazine akmal haidar mehdi rezagholizadeh textkd gan text generation knowledge distillation generative adversarial networks canadian conference articial intelligence pages springer ian goodfellow jonathon shlens christian szegedy explaining harnessing adversarial examples arxiv preprint lantao weinan zhang jun wang yong seqgan sequence generative adversarial nets policy gradient arxiv prints page arxiv preprint carlos florensa david held xinyang geng pieter abbeel automatic goal generation reinforcement learning agents international conference machine learning pages pmlr tong che yanran ruixiang zhang devon hjelm wenjie yangqiu song yoshua bengio likelihood augmented discrete generative adversarial networks arxiv preprint jiaxian guo sidi han cai weinan zhang yong jun wang long text generation adversarial training leaked information proceedings aaai conference articial intelligence volume kevin lin dianqi xiaodong zhengyou zhang ming ting sun adversarial ranking language generation advances neural information processing systems pages william fedus ian goodfellow andrew dai maskgan better text generation lling arxiv preprint jingjing xuancheng ren junyang lin sun diversity promoting gan cross entropy based generative adversarial network diversied text generation proceedings conference empirical methods natural language processing pages massimo caccia lucas caccia william fedus hugo larochelle joelle pineau laurent charlin language gans falling short arxiv preprint ronald williams simple statistical gradient following algorithms connectionist reinforcement learning machine learning martin arjovsky soumith chintala lon bottou wasserstein gan arxiv preprint hossein hosseini sreeram kannan baosen zhang radha poovendran deceiving google perspective api built detecting toxic comments arxiv preprint xiang zhang junbo zhao yann lecun character level convolutional networks text classication advances neural information processing systems jinfeng shouling tianyu ting wang textbugger generating adversarial text real world applications arxiv preprint aml text analysis generation preprint yonatan belinkov yonatan bisk synthetic natural noise break neural machine translation arxiv preprint gao jack lanchantin mary lou soffa yanjun black box generation adversarial text sequences evade deep learning classiers ieee security privacy workshops spw pages ieee javid ebrahimi anyi rao daniel lowd dejing dou hotip white box adversarial examples text classication arxiv preprint stephan brown petar milkov sameep patel zen looi ziqian dong huanying sertac artan edwin jain acoustic visual approaches adversarial text generation google perspective international conference computational science computational intelligence csci pages ieee danish pruthi bhuwan dhingra zachary lipton combating adversarial misspellings robust word recognition arxiv preprint steffen eger gzde sahin andreas rckl ung lee claudia schulz mohsen mesgar krishnkant swarnkar edwin simpson iryna gurevych text processing like humans visually attacking shielding nlp systems arxiv preprint thai suhang wang dongwon lee malcom generating malicious comments attack neural fake news detection models arxiv preprint javid ebrahimi daniel lowd dejing dou adversarial examples character level neural machine translation arxiv preprint classication problems volodymyr kuleshov shantanu thakoor tingfung lau stefano ermon adversarial examples natural language puyudi yang jianbo chen cho jui hsieh jane ling wang michael jordan greedy attack gumbel attack generating adversarial examples discrete data journal machine learning research jin zhijing jin joey tianyi zhou peter szolovits bert robust strong baseline natural language proceedings aaai conference articial intelligence attack text classication entailment volume pages eric wallace shi feng nikhil kandpal matt gardner sameer singh universal adversarial triggers attacking analyzing nlp arxiv preprint siddhant garg goutham ramakrishnan bae bert based adversarial examples text classication arxiv preprint yichao zhou jyun jiang kai wei chang wei wang learning discriminate perturbations blocking adversarial attacks text classication arxiv preprint marco tulio ribeiro sameer singh carlos guestrin semantically equivalent adversarial rules debugging nlp models proceedings annual meeting association computational linguistics volume long papers pages yuan zang fanchao chenghao yang zhiyuan liu meng zhang qun liu maosong sun word level textual adversarial attacking combinatorial optimization proceedings annual meeting association computational linguistics pages moustafa alzantot yash sharma supriyo chakraborty huan zhang cho jui hsieh mani srivastava genattack proceedings genetic evolutionary practical black box attacks gradient free optimization computation conference pages jiwei monroe dan jurafsky understanding neural networks representation erasure arxiv preprint jianyu wang haichao zhang bilateral adversarial training fast training robust models adversarial attacks proceedings ieee international conference computer vision pages yajie wang haoran xiaohui kuang gang zhao tan quanxin zhang jingjing physical world adversarial patch blinding object detection models information sciences nicolas papernot patrick mcdaniel somesh jha ananthram swami distillation defense adversarial perturbations deep neural networks ieee symposium security privacy pages ieee motoki sato jun suzuki hiroyuki shindo yuji matsumoto embedding space text arxiv preprint interpretable adversarial perturbation input aml text analysis generation preprint zhitao gong wenlu wang dawn song wei shinn adversarial texts gradient methods arxiv preprint moustafa alzantot yash sharma ahmed elgohary jhang mani srivastava kai wei chang generating natural language adversarial examples arxiv preprint bin liang hongcheng miaoqiang pan bian xirong wenchang shi deep text classication fooled arxiv preprint shuhuai ren yihe deng kun wanxiang che generating natural language adversarial examples probability weighted word saliency proceedings annual meeting association computational linguistics pages robin jia percy liang adversarial examples evaluating reading comprehension systems arxiv preprint mohit iyyer john wieting kevin gimpel luke zettlemoyer adversarial example generation syntactically controlled paraphrase networks arxiv preprint yong cheng jiang wolfgang macherey robust neural machine translation doubly adversarial inputs arxiv preprint paul michel xian graham neubig juan miguel pino evaluation adversarial perturbations sequence models arxiv preprint lei lingfei pin chen alexandros dimakis inderjit dhillon michael witbrock discrete adversarial attacks submodular optimization applications text classication arxiv preprint haizhong zheng ziqi zhang honglak lee atul prakash understanding diagnosing vulnerability adversarial attacks arxiv preprint mahir jethanandani derek tang adversarial attacks lipnet end end sentence level lipreading ieee security privacy workshops spw pages ieee matthias blohm glorianna jagfeld ekta sood xiang ngoc thang comparing attention based tional recurrent neural networks success limitations machine reading comprehension arxiv preprint shahryar baki rakesh verma arjun mukherjee omprakash gnawali scaling effectiveness email masquerade attacks exploiting natural language generation proceedings acm asia conference computer communications security pages yuanshun yao bimal viswanath jenna cryan haitao zheng ben zhao automated crowdturng attacks defenses online review systems proceedings acm sigsac conference computer communications security pages ronald williams david zipser learning algorithm continually running fully recurrent neural networks neural computation alex lamb anirudh goyal alias parth goyal ying zhang saizheng zhang aaron courville yoshua bengio professor forcing new algorithm training recurrent networks advances neural information processing systems pages marcaurelio ranzato sumit chopra michael auli wojciech zaremba sequence level training recurrent neural networks arxiv preprint ian goodfellow jean pouget abadie mehdi mirza bing david warde farley sherjil ozair aaron courville yoshua bengio generative adversarial networks communications acm karl pearson asymmetrical frequency curves nature lars peter hansen large sample properties generalized method moments estimators econometrica journal econometric society pages lawrence rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee tim salimans ian goodfellow wojciech zaremba vicki cheung alec radford chen improved techniques training gans arxiv preprint youssef mroueh tom sercu fisher gan advances neural information processing systems pages aml text analysis generation preprint greg lewis vasilis syrgkanis adversarial generalized method moments arxiv preprint andrew bennett nathan kallus tobias schnabel deep generalized method moments instrumental variable analysis advances neural information processing systems pages jerry fodor zenon pylyshyn connectionism cognitive architecture critical analysis cognition computation geoffrey hinton simon osindero yee whye teh fast learning algorithm deep belief nets neural diederik kingma max welling auto encoding variational bayes arxiv preprint cihang xie jianyu wang zhishuai zhang zhou ren alan yuille mitigating adversarial effects randomization arxiv preprint haiyan yin dingcheng ping meta cotgan meta cooperative training paradigm improving adversarial text generation aaai pages liqun chen shuyang dai chenyang tao haichao zhang zhe gan dinghan shen yizhe zhang guoyin wang ruiyi zhang lawrence carin adversarial text generation feature mover distance advances neural information processing systems pages sai rajeswar sandeep subramanian francis dutil christopher pal aaron courville adversarial generation natural language arxiv preprint lantao weinan zhang jun wang yong seqgan sequence generative adversarial nets policy gradient proceedings aaai conference articial intelligence volume richard sutton david mcallester satinder singh yishay mansour policy gradient methods ment learning function approximation advances neural information processing systems pages hongyu guo generating text deep reinforcement learning arxiv preprint dzmitry bahdanau philemon brakel kelvin anirudh goyal ryan lowe joelle pineau aaron courville yoshua bengio actor critic algorithm sequence prediction arxiv preprint chris maddison andriy mnih yee whye teh concrete distribution continuous relaxation discrete random variables arxiv preprint yizhe zhang zhe gan kai fan zhi chen ricardo henao dinghan shen lawrence carin adversarial feature matching text generation arxiv preprint matt kusner jos miguel hernndez lobato gans sequences discrete elements gumbel softmax distribution arxiv preprint eric jang shixiang ben poole categorical reparameterization gumbel softmax arxiv preprint weili nie nina narodytska ankit patel relgan relational generative adversarial networks text generation international conference learning representations alexander sasha vezhnevets simon osindero tom schaul nicolas heess max jaderberg david silver koray kavukcuoglu feudal networks hierarchical reinforcement learning arxiv preprint lin tuan hung lee improving conditional sequence generative adversarial networks stepwise evaluation ieee acm transactions audio speech language processing deepak pathak pulkit agrawal alexei efros trevor darrell curiosity driven exploration self supervised prediction proceedings ieee conference computer vision pattern recognition workshops pages jacques robin revision based generation natural language summaries providing historical background corpus based analysis design implementation evaluation kumiko tanaka ishii kiti hasida itsuki noda reactive content selection generation real time soccer commentary coling volume international conference computational linguistics samy bengio oriol vinyals navdeep jaitly noam shazeer scheduled sampling sequence prediction recurrent neural networks advances neural information processing systems oriol vinyals quoc neural conversational model arxiv preprint aml text analysis generation preprint sam wiseman stuart shieber alexander rush challenges data document generation arxiv preprint preprint rajarshi bhowmik gerard melo generating grained open vocabulary entity type descriptions arxiv ratish puduppully dong mirella lapata data text generation content selection planning proceedings aaai conference articial intelligence volume pages alex graves generating sequences recurrent neural networks arxiv preprint zhishuai zhang siyuan qiao cihang xie wei shen wang alan yuille single shot object detection enriched semantics proceedings ieee conference computer vision pattern recognition pages zhiting zichao yang xiaodan liang ruslan salakhutdinov eric xing controllable text generation arxiv preprint martin schmitt sahand sharifzadeh volker tresp hinrich schtze unsupervised joint system text generation knowledge graphs semantic parsing proceedings conference empirical methods natural language processing emnlp pages yau shian wang yun nung chen hung lee topicgan unsupervised text generation explainable latent martin schmitt sahand sharifzadeh volker tresp hinrich schtze unsupervised text generation structured data arxiv preprint oren sheffer castel raz landau going grean novel framework evaluation metric graph text topics generation task rik koncel kedziorski dhanush bekal luan mirella lapata hannaneh hajishirzi text generation knowledge graphs graph transformers arxiv preprint zhijing jin qipeng guo xipeng qiu zheng zhang genwiki dataset million content sharing text graphs unsupervised graph text generation proceedings international conference computational linguistics pages chlo kiddon luke zettlemoyer yejin choi globally coherent text generation neural checklist models proceedings conference empirical methods natural language processing pages zhiting haoran shi bowen tan wentao wang zichao yang tiancheng zhao junxian lianhui qin wang xuezhe texar modularized versatile extensible toolkit text generation arxiv preprint omar abdelwahab adel elmaghraby deep learning based markov chain based text generation cross domain adaptation sentiment classication ieee international conference information reuse integration iri pages ieee sidi yaoming zhu weinan zhang jun wang yong neural text generation past present arxiv preprint yaoming zhu sidi lei zheng jiaxian guo weinan zhang jun wang yong texygen benchmarking platform text generation models international acm sigir conference research development information retrieval pages hechong wang wei zhang yuesheng zhu zhiqiang bai data text generation attention recurrent unit international joint conference neural networks ijcnn pages ieee sanidhya mangal poorva joshi rahul modak lstm gru bidirectional rnn script generation arxiv preprint mercy moila thipe modipa development sepedi text generation model long short term memory proceedings international conference intelligent innovative computing applications pages hongyuan mei mohit bansal matthew walter talk selective generation lstms coarse alignment arxiv preprint hongyu zang xiaojun wan automatic generation product reviews aspect sentiment scores proceedings international conference natural language generation pages ilya sutskever james martens geoffrey hinton generating text recurrent neural networks icml aml text analysis generation preprint jean pouget abadie dzmitry bahdanau bart van merrienboer kyunghyun cho yoshua bengio overcoming curse sentence length neural machine translation automatic segmentation arxiv preprint ehud reiter nlg templates arxiv preprint cmp kees van deemter marit theune emiel krahmer real versus template based natural language generation false opposition computational linguistics sam wiseman stuart shieber alexander rush learning neural templates text generation arxiv preprint hao peng ankur parikh manaal faruqui bhuwan dhingra dipanjan das text generation exemplar based adaptive decoding arxiv preprint eder miranda novais thiago dias tadeu ivandr paraboni improved text generation gram statistics ibero american conference articial intelligence pages springer ilya sutskever oriol vinyals quoc sequence sequence learning neural networks advances neural information processing systems dzmitry bahdanau kyunghyun cho yoshua bengio neural machine translation jointly learning align translate arxiv preprint renjie zheng mingbo baigong zheng liang huang speculative beam search simultaneous translation arxiv preprint liqun chen yizhe zhang ruiyi zhang chenyang tao zhe gan haichao zhang bai dinghan shen changyou improving sequence sequence learning optimal transport arxiv preprint chen lawrence carin wenhao chenguang zhu zaitang zhiting qingyun wang heng meng jiang survey knowledge enhanced text generation arxiv preprint william woods transition network grammars natural language analysis communications acm ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan gomez ukasz kaiser illia polosukhin attention need advances neural information processing systems pages adam santoro ryan faulkner david raposo jack rae mike chrzanowski theophane weber daan wierstra oriol vinyals razvan pascanu timothy lillicrap relational recurrent neural networks advances neural information processing systems pages rafal jozefowicz oriol vinyals mike schuster noam shazeer yonghui exploring limits language modeling arxiv preprint ciprian chelba tomas mikolov mike schuster thorsten brants phillipp koehn tony robinson billion word benchmark measuring progress statistical language modeling arxiv preprint cristina garbacea samuel carton shiyan yan qiaozhu mei judge judges large scale evaluation study neural language models online review generation arxiv preprint tsvetomila mihaylova andr martins scheduled sampling transformers arxiv preprint renjie zheng yilin yang mingbo liang huang ensemble sequence level training multimodal osu baidu multimodal machine translation system report arxiv preprint guy tevet gavriel habib vered shwartz jonathan berant evaluating text gans language models arxiv preprint eric wong leslie rice zico kolter fast better free revisiting adversarial training arxiv preprint alexey kurakin ian goodfellow samy bengio adversarial machine learning scale arxiv preprint yinpeng dong fangzhou liao tianyu pang hang jun zhu xiaolin jianguo boosting adversarial attacks momentum proceedings ieee conference computer vision pattern recognition pages aml text analysis generation preprint aleksander madry aleksandar makelov ludwig schmidt dimitris tsipras adrian vladu deep learning models resistant adversarial attacks arxiv preprint yuzhe yang guo zhang dina katabi zhi net effective adversarial robustness matrix estimation arxiv preprint lin chuang gan song han defensive quantization efciency meets robustness arxiv preprint marius mosbach maksym andriushchenko thomas trost matthias hein dietrich klakow logit pairing methods fool gradient based attacks arxiv preprint harini kannan alexey kurakin ian goodfellow adversarial logit pairing arxiv preprint jacob buckman aurko roy colin raffel ian goodfellow thermometer encoding hot way resist adversarial examples international conference learning representations cihang xie yuxin laurens van der maaten alan yuille kaiming feature denoising improving adversarial robustness proceedings ieee conference computer vision pattern recognition pages ajil jalal andrew ilyas constantinos daskalakis alexandros dimakis robust manifold defense adversarial training generative models arxiv preprint qiao qian minlie huang haizhou zhao jingfang xiaoyan zhu assigning personality prole chatting machine coherent conversation generation ijcai pages daniel jakubovitz raja giryes improving dnn robustness adversarial attacks jacobian regularization proceedings european conference computer vision eccv pages ali shafahi mahyar najibi zheng john dickerson larry davis tom goldstein universal adversarial training aaai pages guneet dhillon kamyar azizzadenesheli zachary lipton jeremy bernstein jean kossai aran khanna anima anandkumar stochastic activation pruning robust adversarial defense arxiv preprint nicolas papernot patrick mcdaniel somesh jha matt fredrikson berkay celik ananthram swami limitations deep learning adversarial settings ieee european symposium security privacy pages ieee anirban chakraborty manaar alam vishal dey anupam chattopadhyay debdeep mukhopadhyay adversarial attacks defences survey arxiv preprint ali shafahi mahyar najibi mohammad amin ghiasi zheng john dickerson christoph studer larry davis gavin taylor tom goldstein adversarial training free advances neural information processing systems pages dinghuai zhang tianyuan zhang yiping zhanxing zhu bin dong propagate accelerating adversarial training maximal principle advances neural information processing systems pages cody coleman deepak narayanan daniel kang tian zhao jian zhang luigi nardi peter bailis kunle olukotun chris matei zaharia dawnbench end end deep learning benchmark competition training jinxin chang ruifang longbiao wang xiangyu zhao ting yang ruifang wang semi supervised stable variational network promoting replier consistency dialogue generation proceedings conference empirical methods natural language processing international joint conference natural language processing emnlp ijcnlp pages jiwei monroe alan ritter michel galley jianfeng gao dan jurafsky deep reinforcement learning dialogue generation arxiv preprint hamilton zhitao ying jure leskovec inductive representation learning large graphs advances neural information processing systems pages muhammad nabeel adnan riaz wang zhenyu cas gans approach dialogue policy learning based gan techniques int adv comput sci appl zhen yang wei chen feng wang improving neural machine translation conditional sequence generative adversarial nets arxiv preprint aml text analysis generation preprint lijun yingce xia fei tian zhao tao qin jianhuang lai tie yan liu adversarial neural machine translation asian conference machine learning pages pmlr zhirui zhang shujie liu ming zhou enhong chen bidirectional generative adversarial networks neural machine translation proceedings conference computational natural language learning pages rakshith shetty bernt schiele mario fritz author attribute anonymity adversarial training neural machine translation usenix security symposium usenix security pages kishore papineni salim roukos todd ward wei jing zhu bleu method automatic evaluation machine translation proceedings annual meeting association computational linguistics pages robertson walker simple effective approximations poisson model probabilistic weighted retrieval proceedings annual international acm sigir conference research development information retrieval pages matt kusner sun nicholas kolkin kilian weinberger word embeddings document distances proceedings international conference international conference machine learning volume pages jmlr org pia keukeleire correspondence perplexity scores human evaluation generated scripts liam fowl micah goldblum arjun gupta amr sharaf tom goldstein random network distillation diversity metric image text generation arxiv preprint leonid nisonovich vaserstein markov processes denumerable products spaces describing large systems automata problemy peredachi informatsii martin heusel hubert ramsauer thomas unterthiner bernhard nessler sepp hochreiter gans trained time scale update rule converge local nash equilibrium advances neural information processing systems pages ondrej cfka aliaksei severyn enrique alfonseca katja filippova eval trust wrong comparing sentence generation models arxiv preprint jiwei michel galley chris brockett jianfeng gao bill dolan diversity promoting objective function neural conversation models arxiv preprint chin yew lin rouge package automatic evaluation summaries text summarization branches pages satanjeev banerjee alon lavie meteor automatic metric evaluation improved correlation human judgments proceedings acl workshop intrinsic extrinsic evaluation measures machine translation summarization pages wenchao alan black boosting dialog response generation proceedings annual meeting association computational linguistics pages cristbal esteban stephanie hyland gunnar rtsch real valued medical time series generation recurrent conditional gans arxiv preprint divya saxena jiannong cao gan deep generative adversarial nets spatio temporal prediction arxiv preprint sebastian nowozin botond cseke ryota tomioka gan training generative neural samplers variational divergence minimization advances neural information processing systems pages xudong mao qing haoran xie raymond lau zhen wang stephen paul smolley squares generative adversarial networks proceedings ieee international conference computer vision pages alireza koochali peter schichtel andreas dengel sheraz ahmed probabilistic forecasting sensory data generative adversarial networks forgan ieee access ishaan gulrajani faruk ahmed martin arjovsky vincent dumoulin aaron courville improved training wasserstein gans advances neural information processing systems pages nan gao hao xue wei shao sichen zhao kyle kai qin arian prabowo mohammad saiedur rahaman flora salim generative adversarial networks spatio temporal data survey arxiv preprint yuri burda harrison edwards amos storkey oleg klimov exploration random network distillation arxiv preprint aml text analysis generation preprint xinlei chen hao fang tsung lin ramakrishna vedantam saurabh gupta piotr dollr lawrence zitnick microsoft coco captions data collection evaluation server arxiv preprint xingxing zhang mirella lapata chinese poetry generation recurrent neural networks proceedings conference empirical methods natural language processing emnlp pages catherine wah steve branson peter welinder pietro perona serge belongie caltech ucsd dataset aolan sun jianzong wang ning cheng huayi peng zhen zeng lingwei kong jing xiao graphpb graphical representations prosody boundary speech synthesis arxiv preprint christopher olah understanding lstm networks sepp hochreiter jrgen schmidhuber long short term memory neural computation rachel manzelli vijay thakkar ali siahkamari brian kulis end end model automatic music generation combining deep raw symbolic audio networks proceedings musical metacreation workshop international conference computational creativity salamanca spain catherine wong dancin fooling text classiers adversarial text example generation arxiv preprint minhao cheng jinfeng pin chen huan zhang cho jui hsieh evaluating robustness sequence sequence models adversarial examples aaai pages marco barreno blaine nelson anthony joseph doug tygar security machine learning machine learning zhou xiaoqing zheng cho jui hsieh kai wei chang xuanjing huang defense adversarial attacks nlp dirichlet neighborhood ensemble arxiv preprint takeru miyato andrew dai ian goodfellow adversarial training methods semi supervised text classication arxiv preprint chen zhu cheng zhe gan siqi sun thomas goldstein jingjing liu freelb enhanced adversarial training language understanding arxiv preprint sen huang robert stanforth johannes welbl chris dyer dani yogatama sven gowal krishnamurthy dvijotham pushmeet kohli achieving veried robustness symbol substitutions interval bound propagation arxiv preprint nicholas carlini david wagner evaluating robustness neural networks ieee symposium security privacy pages ieee jeremy cohen elan rosenfeld zico kolter certied adversarial robustness randomized smoothing arxiv preprint xuanqing liu minhao cheng huan zhang cho jui hsieh robust neural networks random ensemble proceedings european conference computer vision eccv pages
