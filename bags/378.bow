scientic document summarization laysumm longsumm sayar ghosh roy nikhil pinnaparaju risubh jain manish gupta vasudeva varma information retrieval extraction lab international institute information technology hyderabad india sayar ghosh nikhil iiit risubh iiit manish gupta abstract text summarization automatic task widely studied important traditionally natural language processing feature engineering machine learning based systems proposed extractive abstractive text summarization recently deep learning based specically transformer based systems immensely popular summarization cognitively challenging task extracting summary worthy sentences laborious expressing semantics brief abstractive summarization complicated paper specically look problem summarizing scientic research papers multiple domains differentiate types summaries laysumm short summary captures essence research paper layman terms restricting overtly specic technical jargon longsumm longer detailed summary aimed providing specic insights ideas touched paper leveraging latest transformer based models systems simple intuitive based paper sections contribute human maries types described evaluations gold standard summaries rouge lin metrics prove effectiveness approach blind test corpora system ranks rst longsumm laysumm tasks respectively introduction popularity data science recent years led massive growth number published papers online generated epochal change way retrieve analyze consume tion papers wider interest data science implies lay persons readers outside author works researcher microsoft data science community signicantly ested keeping latest developments readers access huge research papers web human standing large documents assimilating crucial information laborious time consuming task motivation concise representation huge text retaining core meaning original text led ment automated summarization systems systems provide users ltered high quality concise content work dented scale speed summarization methods mainly classied categories extractive abstractive extractive methods aim select salient phrases sentences elements text abstractive techniques focus generating summaries scratch constraint reusing phrases original text scientic papers large complex documents tend geared particular audience small percentage population majority individuals unable fully comprehend contents long scientic ments people able understand material length ments spanning pages demand great deal time attention tasks like layman summarization laysumm long form rization longsumm great importance today world typically scientic research papers fairly structured documents containing standard sections like abstract introduction background related work experiments results discussion conclusion acknowledgments summarization documents aware sectional structure intuitive way pick tences sections summary decide sentences pick section sentences pick rewrite sentences obtain concise abstractive summary investigate answers questions paper multiple survey papers provided detailed overview automatic text summarization task tas kiyani nenkova eown allahyari practically usable summarization systems tractive nature summarization ies focused summarization news articles work mainly focus interesting pects text summarization summarization scientic research papers summarization laymen cohan propose section level processing scientic documents useful ther collins conclude sections equally useful recent papers observed hierarchical summarization scientic documents highly effective rst level extractive summary section independently generated ond level sectional output abstracted brief summary subramanian erera xiao carenini observe summarizing local context useful global approach sectional level use extracted information section text obtain section extractive summary ignoring remaining text entire paper laysumm task observe abstract relevant section scientic paper layman perspective feed abstract transformer based model ate abstractive summary laysumm task longsumm task rst perform tive summarization section choose selected number sentences section nal summary blind test corpora papers laysumm longsumm tasks proposed system leads rouge respectively results helped bag positions leaderboards tasks related work section discuss related areas including text summarization style transfer automatic text summarization text summarization focuses summarizing given document obtaining key information bits types text summarization methods extractive summarization tive summarization extractive summarization extractive summarization deals extracting pieces text directly input document tractive summarization seen text classication task try predict given sentence summary liu papers area focus summarization news articles focus specic domains like tion medical documents legal documents entic documents summarization performed query sensitive manner user centric manner sentence scoring methods include graph based methods like lexrank erkan radev textrank mihalcea rau machine learning deep learning techniques position based methods recently deep learning architectures ert zhang bertsum liu lapata summarunner nallapati csti singh hybrid net singh proposed extractive summarization abstractive summarization abstractive summarization model tries generate summary instead extracting tences keywords compared tive summarization challenging requires strong language modeling schemes achieve good results traditionally abstractive summarization techniques focused erating short text headlines titles recently efforts ation longer summaries older methods depended tree transduction rules cohn pata quasi synchronous grammar proaches woodsend lapata tive abstractive summarization recently neural summarization approaches found effective effective neural representative language models important text eration tasks recent breakthrough transformer based vaswani tectures like bert devlin raffel summary set research papers vided blind test data laysumm dataset comprises text papers lay summaries variety domains epilepsy archeology materials engineering number nals elsevier available collection lay summaries multidisciplinary collection journals abstracts texts small sample dataset look laysumm ofcial github longsumm dataset corpus task includes training set consists extractive summaries abstractive summaries scientic papers domains natural language processing machine learning extractive summaries based video talks associated ences lev abstractive maries blog posts created nlp searchers average gold summary length tokens research papers parsed ing science library collection pdfs research papers served blind test set longsumm train test datasets publicly accessible longsumm ofcial github system overview section present overview posed systems laysumm longsumm tasks system overview laysumm observed laysumm summaries train set highly abstractive nature length limit words fig alyze information paper section contributes nal lay summary ing rouge overlap paper section available gold summary analysis performed entire dataset fig shows abstract signicant section followed conclusion tively high rouge overlap indicates gree verbatim copying abstract com wing scisumm corpus blob master readme laysumm com figure rouge laps paper sections laysumm summary figure rouge laps paper sections longsumm summary bart lewis ing types models crucial obtaining good textual representations target neural abstractive summarization text style transfer neural text style transfer related area work document style converted style loss content tics syed vadapalli work leverages transformer encoder decoder els text encoder obtain robust latent representations decoder generates text particular target style datasets rst describe datasets provided organizers workshop scholarly document processing laysumm dataset dataset research papers ing gold standard lay summaries available training tokens average length github science parse sharedtasks html com guyfe longsumm scoresmean scoresmean scoresmean scoresmean scoresmean scoresmean lay summary addition providing high rouge overlap conclusion section atively shorter length indicates conclusion section contains great degree ful information condensed fashion note picked paper sections directly paper text performing orate conation section headers conation general hurt performance models particular paper contain form section heading tain materials methods methods plan explore deeper section wise analysis improved conation future work leveraged pretrained transformer models conditional generation given set individual tions results indicate abstract sequence conditional generation ter choice compared utilizing sections problem hand ing salient information expect summarization task additional avor text style transfer figure system architecture longsumm system overview longsumm performed similar section contribution uation considered section headings peared papers training set longsumm task fig shows introduction important section comes creating summaries followed related work results summary generation architecture considered section time global context discussed earlier guided isting scientic evidence xiao carenini showed considering global context focusing purely section hand marginally better based section contribution evaluations constructed budget module calculate weight assign section purpose combining tion summaries nal long summary fig illustrates broad architecture proposed system summarizing individual section summarunner nallapati ple neural extractive summarizer pre trained summarunner pubmed cohan dataset generate paper abstracts ious paper sections results tions budget module setting cutoff thresholds overlap order section considered summary ignore section overlap threshold value system performance indicates fairly simple neural summarizer base architecture capable achieving superior results blind test dataset experimental settings hugging implementation bart experimented length settings training generation found minimum maximum sequence lengths respectively generation gave best results adam optimizer tial learning rate learn rate scheduling based values calculated dation split hyper parameter tuning phase repetition penalty generating lay maries provided optimal results hpzhao implementation default hyper parameter values topk parameter dynamically adjusted set summary length section based section specic budget results system team summaformers ranks rst tasks respectively details tasks found shared tasks overview paper chandrasekaran section present detailed results com hpzhao summarunner draco res ibm codalab abstractsummarized introductionsummarized conclusion long summary budget module method baseline base base base small recall recall recall table laysumm results best results highlighted bold method section cutoff section cutoff section cutoff section cutoff post proc recall recall recall table longsumm results best results highlighted bold lay summary generation experimented bart large cnn model pre trained cnn dailymail rization dataset base summarization mode tuned conditional generation architectures models available laysumm train corpus documents split training validation splits ratio initial results proved superiority large cnn bartl experimented generative sources abstract abstract conclusion abstract conclusion introduction abstract conclusion introduction methods furthermore owing structure abstract considered rst second nal paragraphs abstract referred small abs source results ble complete abstract input bartl best performing setting laysumm papers dataset published scientic journals original abstracts contain highly domain specic technical bartl model captures salient points abstract short word budget transferring text style scientic layman style hyper parameter tuning generation end achieved score blind test corpus generated summaries coherent addition highly abstractive nature comparison present results nave baseline outputs rst tokens abstract summary shown table surprisingly simple line leads impressive results especially recall metrics running summarunner abstract leads results worse baseline long summary generation summarunner nallapati neural extractive summarization system base section summarizer pretrained ing set publicly available pubmed dataset glove pennington word embeddings generate paper abstract closely possible given section grounds network setting easily capture salient points plan explore ing datasets future work netuned longsumm train set follows given longsumm training dataset divided train validation splits ratio previous settings netune documents longsumm train split pretrained summarunner model conditioned extract sentences mize overlap provided gold standard long summaries finally based budget module assign weight available section generate section summaries computed lengths concatenated generate nal summary experiment settings weight assignment based specied overlap cutoffs budget module shown table best forming setting corresponds selecting sections overlap long summary greater intuitively prunes irrelevant sections abbreviations knowledgements remaining sections assigned weights based overlap provided long summary generated long summaries extractive capture salient pieces information given search papers results improve slightly perform post processing heuristics like removing paper citations brackets moving non english unicode characters ematical notation symbols case studies following present cases lay maries generated system generated summaries highly abstractive coherent capture important aspects paper article generated lay summary follows paper proposes novel approach support transformation bioinformatics data linked open data lod denes competency questions drive denition transformation rules data transformation exploration paper presents support toolset scribes successful application proposed approach functional genomics domain cording approach set competency teria drive transformation process paper presents framework development open data management system easily adapted different data types article generated lay engappai engappai summary follows foster interaction autonomous robots need understand ronment operate main challenges semantic segmentation recognition important objects aid robots exploration planning new actions interacting environment study extend multi view semantic mentations system based entangled forests integrating rening object tectors mask cnn look yolo bayesian fusion iterated graph cuts new system takes best ponents successfully exploiting data finally following lay summary ated model paper paper develop novel system summarizing scientic research papers multiple domains differentiate types summaries laysumm short summary captures essence research paper man terms restricting overtly specic technical gon longsumm longer detailed summary aimed providing specic insights ideas touched paper leveraging latest transformer based models systems simple intuitive based cic paper sections contribute human summaries types described conclusions paper studied scientic document summarization tasks laysumm longsumm experimented popular text neural models section aware manner results indicate modeling document structure strong focus parts research paper attend composing summary gives signicant boost quality resultant output blind test corpora system ranks rst longsumm laysumm tasks respectively references mehdi allahyari seyedamin pouriyeh mehdi asse saeid safaei elizabeth trippe juan text rez krys kochut arxiv preprint tion techniques brief survey chandrasekaran feigenblat hovy ravichander shmueli scheuer waard overview insights scientic document summarization shared tasks scisumm laysumm longsumm proceedings workshop scholarly document processing sdp page forthcoming arman cohan franck dernoncourt doo soon kim trung bui seokhwan kim walter chang zli goharian discourse aware attention model abstractive summarization long ments arxiv preprint trevor cohn mirella lapata sentence proceedings pression word deletion international conference tional linguistics coling pages collins isabelle augenstein sebastian riedel supervised approach extractive arxiv preprint marisation scientic papers jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language ing arxiv preprint shai erera michal shmueli scheuer guy feigenblat ora peled nakash odellia boni haggai roitman doron cohen bar weiner yosi mass rivlin summarization system scientic documents arxiv preprint gunes erkan dragomir radev lexrank graph based lexical centrality salience text summarization journal articial intelligence search guy lev michal shmueli scheuer jonathan herzig achiya jerbi david konopnicki summ dataset scalable annotation method scientic paper summarization based conference talks arxiv preprint mike lewis yinhan liu naman goyal jan ghazvininejad abdelrahman mohamed omer levy ves stoyanov luke zettlemoyer bart denoising sequence sequence pre training natural language generation translation comprehension arxiv preprint chin yew lin rouge package automatic evaluation summaries page yang liu fine tune bert extractive rization arxiv preprint yang liu mirella lapata text proceedings tion pretrained encoders conference empirical methods ural language processing international joint conference natural language processing emnlp ijcnlp pages rada mihalcea paul tarau textrank ing order text proceedings ference empirical methods natural language processing pages ramesh nallapati feifei zhai bowen zhou summarunner recurrent neural network based quence model extractive summarization ments arxiv preprint ani nenkova kathleen mckeown mining vey text summarization techniques text data pages springer jeffrey pennington richard socher christopher manning glove global vectors word resentation proceedings conference empirical methods natural language ing emnlp pages colin raffel noam shazeer adam roberts katherine lee sharan narang michael matena yanqi zhou wei peter liu exploring limits transfer learning unied text text arxiv preprint abhishek kumar singh manish gupta vasudeva varma hybrid memnet extractive rization proceedings acm ence information knowledge management pages abhishek kumar singh manish gupta vasudeva varma unity diversity learning tributed heterogeneous sentence representation extractive summarization aaai sandeep subramanian raymond jonathan lault christopher pal tive abstractive neural document summarization transformer language models arxiv preprint bakhtiyar syed gaurav verma balaji vasan vasan anandhavelu natarajan vasudeva varma adapting language models non parallel aaai pages author stylized rewriting oguzhan tas farzad kiyani survey matic text summarization pressacademia procedia raghuram vadapalli bakhtiyar syed nishant prabhu balaji vasan srinivasan vasudeva varma science journalism meets articial gence interactive demonstration ings conference empirical methods natural language processing system strations pages ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan gomez ukasz kaiser illia polosukhin attention advances neural information need cessing systems pages kristian woodsend mirella lapata ing simplify sentences quasi synchronous grammar integer programming proceedings conference empirical methods natural language processing pages wen xiao giuseppe carenini tive summarization long documents arxiv preprint bining global local context xingxing zhang furu wei ming zhou hibert document level pre training cal bidirectional transformers document proceedings annual rization ing association computational linguistics pages
