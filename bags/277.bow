hierarchical network abstractive meeting summarization cross domain pretraining chenguang zhu ruochen michael zeng xuedong huang microsoft cognitive services research group chezhu ruox nzeng com abstract meeting transcript turns abundance automatic meeting scripts meeting summarization great terest participants parties traditional methods summarizing meetings depend complex multi step pipelines joint optimization intractable handful deep neural els text summarization dialogue tems semantic structure styles meeting transcripts ent articles conversations propose novel abstractive summary network adapts meeting scenario design hierarchical structure modate long meeting transcripts role tor depict difference speakers furthermore inadequacy meeting summary data pretrain model scale news summary data empirical results model outperforms previous proaches automatic metrics man evaluation example icsi dataset score increases introduction meetings common forum people exchange ideas plans share information ubiquity automatic speech recognition systems come vast amounts meeting transcripts need succinctly summarize content meeting naturally arises methods generating summaries meetings proposed mehdad murray wang cardie oya shang murray points users prefer abstractive meeting summaries extractive maries methods tive require complicated multi stage machine equal contribution point skip teletext world upcoming internet think teletext going thing past rst works simple everybody knows remote works user presses button remote determines button buttons talked docking station lcd general functions default materials summary model sentences project manager announced project include teletext feature industrial designer gave presentation functions remote group decided features include remote include lcd screen docking station change layout interface table example excerpt meeting transcript summary generated model ami dataset keywords highlighted colors program ager industrial designer roles ers meeting transcript contains word errors grammatical glitches result matic speech recognition system learning pipelines template generation tence clustering multi sentence compression didate sentence generation ranking approaches end end optimisable hard jointly improve parts pipeline enhance overall performance components template generation quire extensive human involvement rendering solution scalable transferrable end end systems successfully employed tackle document marization pointer generator network reinforced summarization work paulus memory network jiang bansal deep learning methods effectively generate abstractive ment summaries directly optimizing pre dened goals meeting summarization task ently bears number challenges difcult end end training ment summarization example meeting transcript ami dataset summary generated model table transcript summary single meeting usually longer document instance cnn daily mail dataset hermann average tokens article tokens summary ami meeting corpus contains meetings tokens transcript tokens mary average structure meeting transcript distinct news articles challenges prevent existing news summarization models successfully applied meetings second meeting carried tiple participants different semantic styles standpoints roles participant tribute heterogeneous nature meeting transcript compared news limited labelled training data meeting summary meetings ami articles cnn privacy meetings atively high cost writing summaries long transcripts tackle challenges propose end end deep learning framework hierarchical meeting summarization network hmnet net leverages encoder decoder transformer chitecture vaswani produce tive summaries based meeting transcripts adapt structure meeting summarization propose major design improvements meeting transcripts usually lengthy direct application canonical transformer structure feasible instance ducting multi head self attention mechanism transcript thousands tokens time consuming cause memory overow problem leverage hierarchical structure reduce burden computing meeting consists utterances different ipants forms natural multi turn hierarchy hierarchical structure carries level understanding turn turn level understanding meeting summary generation hmnet applies attention levels understanding ensure summary stems different portions transcript varying granularities second accommodate multi speaker scenario hmnet incorporates role encode different semantic styles standpoints participants example program ager usually emphasizes progress project user interface designer tends focus user experience hmnet train role tor meeting participant represent speaker information encoding role vector appended turn level representation later decoding tackle problem insufcient training data meeting summarization leverage idea pretraining devlin lect summarization data news domain convert meeting format group news articles forms multi person ing sentence turn turns reshufed simulate mixed order ers pretrain hmnet model news task netuning meeting summarization empirical results cross domain training effectively enhance model quality evaluate model employ widely ami icsi meeting corpus mccowan janin results hmnet signicantly outperforms previous ing summarization methods example icsi dataset hmnet achieves higher points higher points higher rouge points compared vious best result human evaluations hmnet generates better summaries baseline methods conduct ablation studies verify effectiveness different components model problem formulation formalize problem meeting tion follows input consists meeting transcripts meeting participants pose meetings total datasets experiments provide role tion participant real applications use vector represent participant personal identier available scripts meeting transcript consists multiple turns turn utterance participant pli uli participant wlj tokenized utterance human labelled summary meeting denoted sequence tokens simplicity drop meeting index script goal system generate meeting summary given scripts acts user portrait evolves data user collected hierarchical transformer transformer recall transformer block consists multi head attention layer feed forward layer followed layer norm residuals layer attention feed forward layer vaswani attention mechanism position agnostic append positional encoding input vectors model hierarchical meeting summarization network hmnet based encoder decoder structure vaswani goal maximize conditional probability ing summary given transcript network parameters encoder role vector meeting transcripts recorded ticipants different semantic styles viewpoints model speaker information account ating summaries incorporate participants information integrate speaker role component periments meeting participant distinct role program manager industrial designer role train vector represent xed length vector number roles distributed representation role person proved useful sentiment analysis chen vector appended embedding speaker turn section according results tion vectorized representation speaker roles plays important boosting mance summarization idea extended richer data able practice organization chart participants able add representations lationship participants manager developers network pool registered participants participant personal vector stands dimension tional encoding word input sequence choose sinusoidal functions extend arbitrary input length inference summary transformer block sequence input embeddings generate output beddings dimension input multiple transformer blocks sequentially stacked form transformer network long transcript problem canonical transformer attention mechanism putational complexity quadratic input length struggles handle long quences tokens meeting transcripts usually fairly long consisting thousands tokens note meetings come natural turn structure reasonable number turns turns meeting average ami dataset number tokens turn meeting employ level transformer structure encode meeting transcript word level transformer word level transformer processes token sequence turn meeting encode token turn trainable embedding matrix token turn associated uniform length vector incorporate syntactic semantic information train embedding matrices represent speech pos entity ent tags fore token represented vector figure hierarchical meeting summary network hmnet model structure bos special start token inserted turn encoding turn level transformer encoder tokens encodings enter cross attention module decoder osi note add special token sequence represent beginning turn denote output word level transformer follows word turn level transformer turn level processes information turns meeting represent turn ploy output embedding special token word level transformer furthermore concatenate role tor speaker turn follows output turn level transformer turn decoder decoder transformer generate mary tokens input decoder transformer contains previously generated summary tokens token represented vector embedding matrix encoder decoder transformer uses lower triangular mask prevent model look future kens transformer block includes cross attention layers self attention embeddings rst attend token level puts turn level puts followed layer norm makes model attend different parts inputs varying scales inference step output decoder transformer noted decoder predict token reuse weight embedding matrix decode ability distribution vocabulary illustrate hierarchical meeting summary network hmnet fig training training seek minimize cross entropy logp self attnadd normadd normfeed forwardself attnadd normadd normfeed forwardcross attnadd normcross attnadd normself attnadd normadd normfeed forwardgood softmaxlinearrole vectorpositional encodingword level transformerturn level begin masking use teacher forcing decoder training decoder takes ground truth summary tokens input speaker identication information use single role vector model speaker role information simultaneously inference inference use beam search select best candidate search starts special token ploy commonly trigram blocking paulus beam search candidate word create trigram exists previously generated sequence beam forcibly set word probability finally select summary highest average log likelihood token pretraining limited availability meeting rization data propose utilize summary data news domain pretrain hmnet warm model parameters summarization tasks structure news articles different meeting transcripts transform news articles meeting format concatenate news articles meeting treat sentence gle turn sentences article considered utterances speaker named dataset instance xsum meeting speakers names xsum simulate real meeting scenario randomly shufe turns pseudo meetings target summary concatenation maries pretrain hmnet model large tion news summary data details section netune real meeting summary task experiment datasets employ widely ami mccowan icsi janin meeting corpora datasets contain meeting transcripts automatic speech recognition asr respectively follow shang use train development test split ami icsi meeting tive summary written human annotators thermore participant associated role project manager marketing speaker role meeting ami average words turns meeting transcript words summary icsi average words turns meeting transcript words summary transcript produced asr system word error rate ami icsi shang pretraining conduct news rization datasets cnn dailymail hermann nyt sandhaus xsum narayan containing article summary pairs union datasets pretraining choose groups news articles match speaker setting ami dataset converted meetings contain average words turns words summary baseline models comparison select variety baseline systems previous literatures basic lines random riedhammer copy train randomly copies mary training set template based method template oya ranking systems textrank mihalcea tarau clusterrank garg unsupervised method uns ment summarization model multi modal model addition implement baseline model extractive oracle concatenates tences highest scores golden summary number sentences termined average length golden summary ami icsi metrics following shang employ rouge metrics lin evaluate meeting summarization models metrics respectively evaluate curacy unigrams bigrams unigrams plus reduce variance article randomly sample times report averaged metrics select scenario meetings ami shang treats meeting transcript article generates summary model random template textrank clusterrank uns extractive oracle pgnet copy train hmnet ami icsi table rouge scores generated summary ami icsi datasets numbers bold overall best result baseline models require additional human annotations topic segmentation visual signals cameras results statistically signicant level skip bigrams maximum skip distance metrics shown highly correlate human judgment lin implementation details employ spacy honnibal johnson word tokenizer embed pos ner tags dim vectors dimension role vector transformers layers heads attention dimension word input output dimensions transformers dmodel decoder word level turn level transformer transformers layer dimensionality dmodel hmnet parameters total use dropout probability layers pretrain hmnet news summarization data radam optimizer liu initial learning rate set linearly increased warmup steps netuning meeting data optimization setup initial learning rate set use gradient clipping maximum norm gradient accumulation steps results table shows rouge scores generated maries ami icsi datasets shown cept ami hmnet outperforms baseline models metrics result tistically signicant level paired test best baseline results icsi dataset net achieves higher rouge points previously best results note multi modal model requires human annotation topic segmentation topicseg visual focus attention vfoa collected cameras rarely able practice comparison model net entirely based transcripts asr pipelines ami dataset hmnet forms points points higher points hmnet signicantly outperforms document summarization model pgnet ing traditional summarization models carefully adapted meeting scenarios hmnet compares favorably extractive oracle showing human summaries tive extractive meetings worth noting copy train obtains surprisingly good result ami icsi higher baselines including pgnet reason meetings ami icsi isolated events instead form series related discussions project project keywords appear multiple meetings summaries explains relatively high rouge scores evaluation hmnet focus salient information model hmnet pretrain role vector hierarchy hmnet pretrain role vector hierarchy ami icsi table ablation study hmnet result achieves considerably higher score copy train baseline ablation study table shows ablation study hmnet test set ami icsi shown pretraining news summarization data help increase ami points icsi points role vector removed score drops points ami points icsi net hierarchy structure level transformer removed role vectors appended word level embeddings score drops points ami points icsi components propose play important role rization capability hmnet human evaluation conduct human evaluation meeting summary assess readability relevance readability measures uent summary guage including word grammatical error rate relevance measures summary sums main ideas meeting model summarization text trained model available compare results hmnet uns shang meeting test set ami icsi human evaluators amazon mechanical turk label summaries hmnet uns choose labelers high approval rating increase credibility results annotator presented meeting transcript summaries annotator needs score higher better readability summary consists figure percentage novel grams ence summaries generated hmnet uns shang ami test set dataset source readability relevance dataset source readability relevance hmnet uns ami icsi hmnet uns table average scores readability vance summaries ami icsi test sets summary judged human evaluators standard deviation shown parenthesis ent coherent sentences easy understand likewise relevance summary contains important information meeting annotators need read meeting script summary evaluations reduce bias meeting versions summaries randomly ordered table shows hmnet achieves higher scores readability relevance uns datasets scores hmnet indicating generate readable highly relevant meeting summaries insights abstractive model abstractive system innovative words transcript mary similar measure abstractiveness summary model ratio novel words phrases summary higher ratio indicate abstractive system fig displays percentage novel grams appear meeting transcript summary reference hmnet uns novelreferencehmnetuns shown reference hmnet summaries large portion novel grams grams copied transcript contrast uns lower ratio novel grams generates summary mainly original word sequence transcripts error analysis qualitatively examine outputs hmnet summarize major types errors nature long meeting transcripts system summarizes salient tion parts meeting different reference summaries system summarizes meetings high level topics decisions cover detailed items reference related work meeting summarization number studies generating summaries meetings dialogues zhao liu chen chen metze liu mehdad uses utterance clustering entailment graph semantic word graph ranking strategy construct meeting summaries murray wang cardie focus aspects meetings cisions action items oya ploys multi sentence fusion construct rization templates meetings leading maries higher readability informativeness recently shang leverages sentence compression graph budgeted ular maximization generate meeting summaries general multi step methods joint optimization intractable proposes encoder decoder structure end end modal meeting summarization depends manual annotation topic segmentation sual focus available practice comparison model requires meeting transcripts directly speech recognition document summarization rush rst introduces attention based sutskever model abstractive sentence summarization task ity generated multi sentence summaries long documents low vocabulary oov words efciently handled tackle challenges proposes pointer generator network produce words vocabulary generator copy words source text pointer paulus adds reinforcement learning improve result gehrmann uses content selector determine phrases source documents helps constrain model likely phrases achieves state art results document summarization datasets cently works large scale pretrained language models summarization proposed achieves good performance liu zhu raffel lewis zhang hierarchical neural architecture riety nlp data conversation document internal hierarchical structure works applying hierarchical structures nlp tasks proposes chical neural auto encoder paragraph ment reconstruction applies levels rnn tokens sentence sentences lin applies cal rnn language model hrnnlm document modeling similarly encodes token level turn level information better language ing performance serban puts forward hierarchical recurrent encoder decoder network hred model open domain dialogue systems generate system responses given previous context nallapati proposes archical attention mechanism word level turn level encoder decoder structure stractive document summarization conclusion paper present end end hierarchical neural network hmnet abstractive meeting summarization employ level cal structure adapt long meeting transcript role vector represent participant alleviate data scarcity problem ing news summarization data experiments hmnet achieves state art mance automatic metrics human ation ablation study role vector hierarchical architecture ing contribute model performance future work plan utilize organizational chart knowledge graph topic modeling erate better meeting summaries better capture salient information transcript acknowledgement thank william hinthorn proof reading paper thank anonymous reviewers valuable comments references tao chen ruifeng yulan yunqing xia xuan wang learning user product tributed representations sequence model ieee computational sentiment analysis gence magazine yun nung chen florian metze integrating intra speaker topic modeling temporal based inter speaker topic modeling random walk improved multi party meeting summarization thirteenth annual conference international speech communication association jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language ing arxiv preprint nikhil garg benoit favre korbinian reidhammer dilek hakkani tur clusterrank graph based method meeting summarization tenth nual conference international speech munication association sebastian gehrmann yuntian deng alexander rush abstractive summarization proceedings conference cal methods natural language processing pages karl moritz hermann tomas kocisky edward stette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read comprehend advances neural information processing systems pages matthew honnibal mark johnson proved non monotonic transition system dency parsing proceedings conference empirical methods natural language ing pages adam janin don baron jane edwards dan ellis david gelbart nelson morgan barbara peskin thilo pfau elizabeth shriberg andreas stolcke icsi meeting corpus ieee international conference acoustics speech signal processing proceedings yichen jiang mohit bansal closed book training improve summarization encoder memory proceedings conference cal methods natural language processing pages mike lewis yinhan liu naman goyal jan ghazvininejad abdelrahman mohamed omer levy ves stoyanov luke zettlemoyer bart denoising sequence sequence pre training natural language generation translation comprehension arxiv preprint jiwei minh thang luong dan jurafsky hierarchical neural autoencoder paragraphs documents arxiv preprint manling lingyu zhang heng richard radke meeting summaries topic abstractive multi modal meeting summarization proceedings annual meeting ciation computational linguistics pages chin yew lin rouge package matic evaluation summaries text summarization branches rui lin shujie liu muyun yang ming zhou sheng hierarchical recurrent neural network document modeling proceedings conference empirical methods natural language processing pages chunyi liu peng wang jiang zang jieping automatic dialogue summary generation customer service proceedings acm sigkdd international conference knowledge discovery data mining pages liyuan liu haoming jiang pengcheng weizhu chen xiaodong liu jianfeng gao jiawei han variance adaptive learning rate international conference ing representations yang liu fine tune bert extractive rization arxiv preprint zhengyuan liu nancy chen reading turn turn hierarchical attention architecture ken dialogue comprehension proceedings annual meeting association putational linguistics pages florence italy association computational linguistics zhengyuan liu angela sheldon lee nancy chen topic aware generator networks summarizing spoken sations arxiv preprint iain mccowan jean carletta wessel kraaij simone ashby bourban flynn guillemot thomas hain kadlec vasilis karaiskos ami meeting corpus proceedings national conference methods techniques behavioral research yashar mehdad giuseppe carenini frank tompa abstractive meeting summarization linguistics volume long papers pages iulian serban alessandro sordoni yoshua bengio aaron courville joelle pineau building end end dialogue systems generative chical neural network models thirtieth aaai ference articial intelligence guokan shang wensi ding zekun zhang toine tixier polykarpos meladianos michalis giannis jean pierre vised abstractive meeting summarization sentence compression budgeted submodular proceedings annual maximization meeting association computational guistics volume long papers pages ilya sutskever oriol vinyals quoc sequence sequence learning neural networks advances neural information processing systems pages ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan gomez ukasz kaiser illia polosukhin attention need advances neural information ing systems pages wang claire cardie independent abstract generation focused ing summarization proceedings annual meeting association computational guistics volume long papers jingqing zhang yao zhao mohammad saleh ter liu pegasus pre training extracted gap sentences abstractive summarization arxiv preprint zhou zhao haojie pan changjie fan yan liu lin min yang deng cai tive meeting summarization hierarchical tive segmental network learning world wide web conference pages chenguang zhu ziyi yang robert gmyr michael zeng xuedong huang lead bias favor simple effective method news summarization arxiv preprint entailment fusion proceedings ropean workshop natural language generation pages rada mihalcea paul tarau textrank ing order text proceedings ference empirical methods natural language processing gabriel murray giuseppe carenini raymond generating validating abstracts ing conversations user study proceedings international natural language generation conference pages ramesh nallapati bowen zhou cicero dos santos aglar gulcehre bing xiang tive text summarization sequence sequence proceedings rnns signll conference computational natural guage learning pages shashi narayan shay cohen mirella lapata details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing pages tatsuro oya yashar mehdad giuseppe carenini raymond template based abstractive meeting summarization leveraging summary source text relationships proceedings international natural language generation ence inlg pages romain paulus caiming xiong richard socher deep reinforced model abstractive marization international conference ing representations colin raffel noam shazeer adam roberts katherine lee sharan narang michael matena yanqi zhou wei peter liu exploring limits transfer learning unied text text arxiv preprint korbinian riedhammer dan gillick benoit favre dilek hakkani tur packing meeting marization knapsack ninth annual conference international speech communication tion alexander rush sumit chopra jason weston neural attention model abstractive proceedings tence summarization conference empirical methods natural guage processing pages evan sandhaus new york times annotated corpus linguistic data consortium philadelphia abigail peter liu christopher manning point summarization generator networks proceedings nual meeting association computational ami icsi beam size dev test dev test table hyperparameter search trials beam size minimum generation length xed ami icsi bold numbers best development set performance selected beam size table gpu memory overow issue large beam size word errors grammatical glitches compared document tion tasks like cnn daily mail hermann nallapati meeting transcript pretty long lacks important rst structure add complexity meeting summarization tasks summary generated hmnet includes individual actions proposals group ties similar reference contrast result uns clear structure hmnet effective selecting salient information lengthy transcript language summary hmnet smoother fewer grammatical errors uns reason hmnet learns language pattern reference summary ing training uns generates summaries concatenating transcript word sequences min len beam size ami icsi table selected hyperparameters development set rouge scores reported performance table ami icsi min len dev test dev test table hyperparameter search trials minimum eration length beam size xed bold bers best development set performance selected minimum generation length training details training conducted tesla gpu memory batch size gpu tokens pretraining ing pretraining converges steps runs approximately days tuning meeting datasets converges steps runs hours pick model highest score development set news meeting datasets pretraining netuning respectively large computation cost pretraining tune hyperparameters decoding minimum length generated mary beam size ami icsi rst set beam size grid search imum length selecting best minimum length tune beam size tuning based development set score selected hyperparameters ami icsi corresponding development set performance shown table hyperparameter search als development test set performance found table example meeting summary demonstrate table table table examples ami meeting transcript speaker information versions summaries ence hmnet uns shang transcript results asr pipelines meeting transcript turns research research usability lab observed users operating remote controls let questionnaire remotes considered ugly seventy percent people questioned indicated thought remote ugly additional eighty percent indicated spend money fancy looking remote control percent people indicated loo percent buttons remote control got presentation working design rst works simple everybody knows remote works user presses button remote determines button uses infrared send signal use percent buttons buttons point skip teletext world upcoming internet think teletext going thing past function need remote control got functions remote control simple remote control buttons remote control got lot buttons people like thinking general functions like extra button info possible let fancy fancy design easy learn buttons talked docking station lcd general functions default materials attent putting corporate image product visible design way device works minutes project document folder lunch break reference summary sentences project manager stated agenda marketing expert discussed functions relevant remote target demographic vision appearance remote marketing expert brought idea include docking station prevent remote getting lost idea include lcd screen user interface designer pushed user interface large buttons display function touchscreen capability controlling different devices team discussed teletext target demographic buttons remote idea marketing remote designed elderly audio signal sound remote lost lcd screens language options include teletext design despite new requirement indicates team work teletext buttons generally main feature ugly ugly remote buttons remote feature small lcd screen remote docking station summary hmnet sentences user interface designer industrial designer presented components remote control device marketing expert presented research working design selling buttons meeting industrial designer gave presentation functions remote project manager announced project include teletext feature project manager post minutes cent minutes user interface designer focus corporate image company group decided features include remote include lcd screen docking station change layout interface remote buttons buttons possible include docking station selection functions remote summary uns sentences buttons talked docking station lcd general functions fancy design easy learn buttons right places simple manner lot functions remote control pricing need great deal people indicated lcd screen remote control preferred focusing elderly people people plus wanted work seventy percent people indicated remote got lost room minimum number buttons real buttons use rebecca required existing remote control simply table example meeting transcript ami summary reference hmnet uns roles participants coded follows project manager marketing expert industrial designer user interface designer manually capitalize words summaries hmnet uns better demonstration meeting transcript turns conceptual design meeting points interest meeting conceptual specication components conceptual specication design trend watching doh gon inform trend watching past days market research distributed enquetes questionnaires need new attractive functions attract people like speak speech recognition special button selecting subtitles overall user friendly large buttons components design energy source use basic battery optional thing kinetic energy like watch casing manufacturing department deliver casing single double curved casing chip set advanced let look case normal single curved gon look like like type better better prevent repetitive strain injury bit suggest single curved maybe curve pretty good screen buttons changing channel maybe possible like let colour like right colour user interface design story product evaluation industrial designer user interface designer going work reference summary sentences project manager opened meeting recapped decisions previous meeting marketing expert discussed personal preferences design remote presented results trend watching reports indicated need products fancy innovative easy use dark colors recognizable shapes familiar material like wood user interface designer discussed option include speech recognition functions include remote industrial designer discussed options preferred remote terms energy sources casing case supplements buttons chips team discussed decisions energy sources speech recognition lcd screens chips case materials colors case shape orientation button orientation industrial designer user interface designer work remote use conventional battery docking station recharges battery use kinetic energy conventional battery docking station recharges remote summary hmnet sentences project manager opened meeting conceptual components conceptual design industrial designer discussed interior workings remote suggested remote feature speech recognition user interface designer presented existing products discussed option design remote docking station marketing expert discussed research trend watchers trend watchers consulted energy sources voice recognition speech recognition case recognition overall buttons discussed possibility double curved case double curved double curved cases group discussed options energy source energy sources designers work prototype evaluation having lcd screen remote covers outside station kinetic energy sources needed add extra buttons case fancy simple case plastic single curved case summary uns sentences older people like shake remote control fresh changing channels button right time look easily screen held making remote control easier leads personal preferences remote control people pay speech recognition remote control research designing interface designer going work trendwatchers consulted advise remote control docking station telephone shape imagine start choosing case people like wood raised price table example meeting transcript summary reference hmnet uns meeting transcript turns decided meeting working design presented rst thing question asked trying design device sends signal change state power channel volume unique people want buy features concept model findings people prefer user friendly complex remote controls trendy design eighty percent spend money remote control look fancy prepared spend money bit nicer looking current remote controls match operating behaviour user overall asked questions table relates questions differentiate prefer lcd screen multi function remote pay speech recognition remote control initially looking ndings focus younger age group initially broaden market later right away focus biggest market people age group thirty biggest market reference summary sentences industrial designer gave presentation basic functions remote presented basic components remotes share suggested smaller batteries considered product design user interface designer presented ideas making remote easy use discussed simple design hiding complicated features main interface marketing expert presented ndings lab study user requirements remote control device discussed users demand simple interface advanced technology project manager presented new requirements remote include teletext function control television include company image design group narrowed target marketing group youth market group discussed shell like shape remote including different casing options buyers remote bundled docking station recharge remote batteries user friendly instruction manual multiple casings available limitations budget restrict development features features group wanted include simpler decrease cost summary hmnet sentences project manager recapped decisions previous meeting industrial designer discussed interior workings remote team discussed options batteries volume control lcd screens marketing expert found users want fancy look feel trendy fashionable user design user interface designer presented ndings trend watching reports indicated need products technologically innovative attractive user group decided include lcd screen discussed interface incorporated team discussed minimize number functions functions include design discussed making remote prot target group include lcd ease noise voice recognition locator function lcd screen marketing expert focus making product user possible compensate younger consumers remote small trendy design buttons meeting summary uns sentences important project accessible wide range consumers white age groups remote got press button beeps seventy percent user remote controls point pressing pound sign bleep room stick program control remote control hold palm hand set occur fair run long time change state appliances sending signal market research table example meeting transcript summary reference hmnet uns
