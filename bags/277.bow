hierarchical network abstractive meeting summarization cross domain pretraining chenguang zhu ruochen xu michael zeng xuedong huang microsoft cognitive services research group chezhu ruox nzeng com p e s l c s c v v x r abstract meeting transcript turns abundance automatic meeting scripts meeting summarization great terest participants parties traditional methods summarizing meetings depend complex multi step pipelines joint optimization intractable handful deep neural els text summarization dialogue tems semantic structure styles meeting transcripts ent articles conversations propose novel abstractive summary network adapts meeting scenario design hierarchical structure modate long meeting transcripts role tor depict difference speakers furthermore inadequacy meeting summary data pretrain model scale news summary data empirical results model outperforms previous proaches automatic metrics man evaluation example icsi dataset score increases introduction meetings common forum people exchange ideas plans share information ubiquity automatic speech recognition systems come vast amounts meeting transcripts need succinctly summarize content meeting naturally arises methods generating summaries meetings proposed mehdad et al murray et al wang cardie oya et al shang et al li et al murray et al points users prefer abstractive meeting summaries extractive maries methods tive require complicated multi stage machine equal contribution pm point skip teletext world upcoming internet think teletext going thing past id rst works simple everybody knows remote works user presses button remote determines button pm buttons talked docking station lcd general functions default materials summary model sentences project manager announced project include teletext feature industrial designer gave presentation functions remote group decided features include remote include lcd screen docking station change layout interface table example excerpt meeting transcript summary generated model ami dataset keywords highlighted colors pm program ager id industrial designer roles ers meeting transcript contains word errors grammatical glitches result matic speech recognition system learning pipelines template generation tence clustering multi sentence compression didate sentence generation ranking approaches end end optimisable hard jointly improve parts pipeline enhance overall performance components e template generation quire extensive human involvement rendering solution scalable transferrable end end systems successfully employed tackle document marization pointer generator network et al reinforced summarization work paulus et al memory network jiang bansal deep learning methods effectively generate abstractive ment summaries directly optimizing pre dened goals meeting summarization task ently bears number challenges difcult end end training ment summarization example meeting transcript ami dataset summary generated model table transcript summary single meeting usually longer document instance cnn daily mail dataset hermann et al average tokens article tokens summary ami meeting corpus contains meetings tokens transcript tokens mary average structure meeting transcript distinct news articles challenges prevent existing news summarization models successfully applied meetings second meeting carried tiple participants different semantic styles standpoints roles participant tribute heterogeneous nature meeting transcript compared news limited labelled training data meeting summary meetings ami v s k articles cnn dm privacy meetings atively high cost writing summaries long transcripts tackle challenges propose end end deep learning framework hierarchical meeting summarization network hmnet net leverages encoder decoder transformer chitecture vaswani et al produce tive summaries based meeting transcripts adapt structure meeting summarization propose major design improvements meeting transcripts usually lengthy direct application canonical transformer structure feasible instance ducting multi head self attention mechanism transcript thousands tokens time consuming cause memory overow problem leverage hierarchical structure reduce burden computing meeting consists utterances different ipants forms natural multi turn hierarchy hierarchical structure carries level understanding turn turn level understanding meeting summary generation hmnet applies attention levels understanding ensure summary stems different portions transcript varying granularities second accommodate multi speaker scenario hmnet incorporates role encode different semantic styles standpoints participants example program ager usually emphasizes progress project user interface designer tends focus user experience hmnet train role tor meeting participant represent speaker s information encoding role vector appended turn level representation later decoding tackle problem insufcient training data meeting summarization leverage idea pretraining devlin et al lect summarization data news domain convert meeting format group news articles forms multi person ing sentence turn turns reshufed simulate mixed order ers pretrain hmnet model news task netuning meeting summarization empirical results cross domain training effectively enhance model quality evaluate model employ widely ami icsi meeting corpus mccowan et al janin et al results hmnet signicantly outperforms previous ing summarization methods example icsi dataset hmnet achieves higher points higher points higher rouge points compared vious best result human evaluations hmnet generates better summaries baseline methods conduct ablation studies verify effectiveness different components model problem formulation formalize problem meeting tion follows input consists meeting transcripts x meeting participants p pose s meetings total datasets experiments provide role tion participant real applications use vector represent participant personal identier available scripts x xs meeting transcript consists multiple turns turn utterance participant xi pli uli pj p j li participant wlj tokenized utterance pj human labelled summary meeting xi denoted yi sequence tokens simplicity drop meeting index script goal system generate meeting summary y given scripts x pm um acts user portrait evolves data user collected hierarchical transformer transformer recall transformer block consists multi head attention layer feed forward layer followed layer norm residuals layer attention feed forward layer vaswani et al attention mechanism position agnostic append positional encoding input vectors model hierarchical meeting summarization network hmnet based encoder decoder structure vaswani et al goal maximize conditional probability ing summary y given transcript x network parameters p y encoder role vector meeting transcripts recorded ticipants different semantic styles viewpoints model speaker s information account ating summaries incorporate participants information integrate speaker role component periments meeting participant distinct role e program manager industrial designer role train vector represent xed length vector rp p p p number roles distributed representation role person proved useful sentiment analysis chen et al vector appended embedding speaker s turn section according results tion vectorized representation speaker roles plays important boosting mance summarization idea extended richer data able practice organization chart participants able add representations lationship participants e manager developers network pool registered participants participant personal vector j stands j th dimension tional encoding th word input sequence choose sinusoidal functions extend arbitrary input length inference summary transformer block sequence n input embeddings generate n output beddings dimension input multiple transformer blocks sequentially stacked form transformer network xn long transcript problem canonical transformer attention mechanism putational complexity quadratic input length struggles handle long quences e tokens meeting transcripts usually fairly long consisting thousands tokens note meetings come natural turn structure reasonable number turns e turns meeting average ami dataset number tokens turn meeting employ level transformer structure encode meeting transcript word level transformer word level transformer processes token sequence turn meeting encode token turn trainable embedding matrix d token th turn wi j associated uniform length vector j gi j incorporate syntactic semantic information train embedding matrices represent speech pos entity ent tags fore token wi j represented vector figure hierarchical meeting summary network hmnet model structure bos special start token inserted turn encoding turn level transformer encoder tokens encodings enter cross attention module decoder xi j gi j p osi j en ti note add special token sequence represent beginning turn denote output word level transformer follows word xi li xw xw li turn level transformer turn level processes information m turns meeting represent th turn ploy output embedding special token word level transformer e xw furthermore concatenate role tor speaker turn pi follows output turn level transformer turn pm xt m xt decoder decoder transformer generate mary tokens input decoder transformer contains k previously generated summary tokens token represented vector embedding matrix d encoder gi decoder transformer uses lower triangular mask prevent model look future kens transformer block includes cross attention layers self attention embeddings rst attend token level puts xw turn level puts xt followed layer norm makes model attend different parts inputs varying scales inference step li m output decoder transformer noted decoder predict token yk reuse weight embedding matrix d decode ability distribution vocabulary p k x illustrate hierarchical meeting summary network hmnet fig training training seek minimize cross entropy logp x n n self attnadd normadd normfeed forwardself attnadd normadd normfeed forwardcross attnadd normcross attnadd normself attnadd normadd normfeed forwardgood softmaxlinearrole vectorpositional encodingword level transformerturn level begin masking use teacher forcing decoder training e decoder takes ground truth summary tokens input speaker identication information use single role vector model speaker role information simultaneously inference inference use beam search select best candidate search starts special token ploy commonly trigram blocking paulus et al beam search candidate word create trigram exists previously generated sequence beam forcibly set word s probability finally select summary highest average log likelihood token pretraining limited availability meeting rization data propose utilize summary data news domain pretrain hmnet warm model parameters summarization tasks structure news articles different meeting transcripts transform news articles meeting format concatenate m news articles m meeting treat sentence gle turn sentences article considered utterances th speaker named dataset instance xsum meeting speakers names xsum m simulate real meeting scenario randomly shufe turns pseudo meetings target summary concatenation m maries pretrain hmnet model large tion news summary data details section netune real meeting summary task experiment datasets employ widely ami mccowan et al icsi janin et al meeting corpora datasets contain meeting transcripts automatic speech recognition asr respectively follow shang et al use train development test split ami icsi meeting tive summary written human annotators thermore participant associated role e project manager marketing speaker role meeting ami average words turns meeting transcript words summary icsi average words turns meeting transcript words summary transcript produced asr system word error rate ami icsi shang et al pretraining conduct news rization datasets cnn dailymail hermann et al nyt sandhaus xsum narayan et al containing k k k article summary pairs union datasets pretraining choose groups m news articles match speaker setting ami dataset converted meetings contain average words turns words summary baseline models comparison select variety baseline systems previous literatures basic lines random riedhammer et al copy train randomly copies mary training set template based method template oya et al ranking systems textrank mihalcea tarau clusterrank garg et al unsupervised method uns ment summarization model et al multi modal model mm li et al addition implement baseline model extractive oracle concatenates tences highest scores golden summary number sentences termined average length golden summary ami icsi metrics following shang et al employ rouge metrics lin evaluate meeting summarization models metrics respectively evaluate curacy unigrams bigrams unigrams plus reduce variance article randomly sample times report averaged metrics select scenario meetings ami shang et al treats meeting transcript article generates summary model random template textrank clusterrank uns extractive oracle pgnet copy train mm mm hmnet ami r icsi r table rouge scores generated summary ami icsi datasets numbers bold overall best result baseline mm models require additional human annotations topic segmentation visual signals cameras results statistically signicant level skip bigrams maximum skip distance metrics shown highly correlate human judgment lin implementation details employ spacy honnibal johnson word tokenizer embed pos ner tags dim vectors dimension role vector transformers layers heads attention dimension word input output dimensions transformers dmodel decoder word level turn level transformer transformers layer dimensionality df dmodel hmnet m parameters total use dropout probability layers pretrain hmnet news summarization data radam optimizer liu et al initial learning rate set linearly increased warmup steps netuning meeting data optimization setup initial learning rate set use gradient clipping maximum norm gradient accumulation steps results table shows rouge scores generated maries ami icsi datasets shown cept ami hmnet outperforms baseline models metrics result tistically signicant level paired t test best baseline results icsi dataset net achieves higher rouge points previously best results note mm multi modal model requires human annotation topic segmentation topicseg visual focus attention vfoa collected cameras rarely able practice comparison model net entirely based transcripts asr pipelines ami dataset hmnet forms points points higher points hmnet signicantly outperforms document summarization model pgnet ing traditional summarization models carefully adapted meeting scenarios hmnet compares favorably extractive oracle showing human summaries tive extractive meetings s worth noting copy train obtains surprisingly good result ami icsi higher baselines including pgnet reason meetings ami icsi isolated events instead form series related discussions project project keywords appear multiple meetings summaries explains relatively high rouge scores evaluation hmnet focus salient information model r hmnet pretrain role vector hierarchy hmnet pretrain role vector hierarchy ami icsi table ablation study hmnet result achieves considerably higher score copy train baseline ablation study table shows ablation study hmnet test set ami icsi shown pretraining news summarization data help increase ami points icsi points role vector removed score drops points ami points icsi net hierarchy structure e level transformer removed role vectors appended word level embeddings score drops points ami points icsi components propose play important role rization capability hmnet human evaluation conduct human evaluation meeting summary assess readability relevance readability measures uent summary guage including word grammatical error rate relevance measures summary sums main ideas meeting mm model li et al summarization text trained model available compare results hmnet uns shang et al meeting test set ami icsi human evaluators amazon mechanical turk label summaries hmnet uns choose labelers high approval rating increase credibility results annotator presented meeting transcript summaries annotator needs score higher better readability summary consists figure percentage novel n grams ence summaries generated hmnet uns shang et al ami s test set dataset source readability relevance dataset source readability relevance hmnet uns ami icsi hmnet uns table average scores readability vance summaries ami icsi s test sets summary judged human evaluators standard deviation shown parenthesis ent coherent sentences easy understand likewise relevance summary contains important information meeting annotators need read meeting script summary evaluations reduce bias meeting versions summaries randomly ordered table shows hmnet achieves higher scores readability relevance uns datasets scores hmnet indicating generate readable highly relevant meeting summaries insights abstractive model abstractive system innovative words transcript mary similar et al measure abstractiveness summary model ratio novel words phrases summary higher ratio indicate abstractive system fig displays percentage novel n grams e appear meeting transcript summary reference hmnet uns novelreferencehmnetuns shown reference hmnet summaries large portion novel n grams n grams copied transcript contrast uns lower ratio novel n grams generates summary mainly original word sequence transcripts error analysis qualitatively examine outputs hmnet summarize major types errors nature long meeting transcripts system summarizes salient tion parts meeting different reference summaries system summarizes meetings high level e topics decisions cover detailed items reference related work meeting summarization number studies generating summaries meetings dialogues zhao et al liu chen chen metze liu et al mehdad et al uses utterance clustering entailment graph semantic word graph ranking strategy construct meeting summaries murray et al wang cardie focus aspects meetings cisions action items oya et al ploys multi sentence fusion construct rization templates meetings leading maries higher readability informativeness recently shang et al leverages sentence compression graph budgeted ular maximization generate meeting summaries general multi step methods joint optimization intractable li et al proposes encoder decoder structure end end modal meeting summarization depends manual annotation topic segmentation sual focus available practice comparison model requires meeting transcripts directly speech recognition document summarization rush et al rst introduces attention based sutskever et al model abstractive sentence summarization task ity generated multi sentence summaries long documents low vocabulary oov words efciently handled tackle challenges et al proposes pointer generator network produce words vocabulary generator copy words source text pointer paulus et al adds reinforcement learning improve result gehrmann et al uses content selector determine phrases source documents helps constrain model likely phrases achieves state art results document summarization datasets cently works large scale pretrained language models summarization proposed achieves good performance liu zhu et al raffel et al lewis et al zhang et al hierarchical neural architecture riety nlp data e conversation document internal hierarchical structure works applying hierarchical structures nlp tasks li et al proposes chical neural auto encoder paragraph ment reconstruction applies levels rnn tokens sentence sentences lin et al applies cal rnn language model hrnnlm document modeling similarly encodes token level turn level information better language ing performance serban et al puts forward hierarchical recurrent encoder decoder network hred model open domain dialogue systems generate system responses given previous context nallapati et al proposes archical attention mechanism word level turn level encoder decoder structure stractive document summarization conclusion paper present end end hierarchical neural network hmnet abstractive meeting summarization employ level cal structure adapt long meeting transcript role vector represent participant alleviate data scarcity problem ing news summarization data experiments hmnet achieves state art mance automatic metrics human ation ablation study role vector hierarchical architecture ing contribute model s performance future work plan utilize organizational chart knowledge graph topic modeling erate better meeting summaries better capture salient information transcript acknowledgement thank william hinthorn proof reading paper thank anonymous reviewers valuable comments references tao chen ruifeng xu yulan yunqing xia xuan wang learning user product tributed representations sequence model ieee computational sentiment analysis gence magazine yun nung chen florian metze integrating intra speaker topic modeling temporal based inter speaker topic modeling random walk improved multi party meeting summarization thirteenth annual conference international speech communication association jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language ing arxiv preprint nikhil garg benoit favre korbinian reidhammer dilek hakkani tur clusterrank graph based method meeting summarization tenth nual conference international speech munication association sebastian gehrmann yuntian deng alexander m rush abstractive summarization proceedings conference cal methods natural language processing pages karl moritz hermann tomas kocisky edward stette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read comprehend advances neural information processing systems pages matthew honnibal mark johnson proved non monotonic transition system dency parsing proceedings conference empirical methods natural language ing pages adam janin don baron jane edwards dan ellis david gelbart nelson morgan barbara peskin thilo pfau elizabeth shriberg andreas stolcke et al icsi meeting corpus ieee international conference acoustics speech signal processing proceedings yichen jiang mohit bansal closed book training improve summarization encoder memory proceedings conference cal methods natural language processing pages mike lewis yinhan liu naman goyal jan ghazvininejad abdelrahman mohamed omer levy ves stoyanov luke zettlemoyer bart denoising sequence sequence pre training natural language generation translation comprehension arxiv preprint jiwei li minh thang luong dan jurafsky hierarchical neural autoencoder paragraphs documents arxiv preprint manling li lingyu zhang heng ji richard j radke meeting summaries topic abstractive multi modal meeting summarization proceedings annual meeting ciation computational linguistics pages chin yew lin rouge package matic evaluation summaries text summarization branches rui lin shujie liu muyun yang mu li ming zhou sheng li hierarchical recurrent neural network document modeling proceedings conference empirical methods natural language processing pages chunyi liu peng wang jiang xu zang li jieping ye automatic dialogue summary generation customer service proceedings acm sigkdd international conference knowledge discovery data mining pages liyuan liu haoming jiang pengcheng weizhu chen xiaodong liu jianfeng gao jiawei han variance adaptive learning rate international conference ing representations yang liu fine tune bert extractive rization arxiv preprint zhengyuan liu nancy chen reading turn turn hierarchical attention architecture ken dialogue comprehension proceedings annual meeting association putational linguistics pages florence italy association computational linguistics zhengyuan liu angela ng sheldon lee ai ti aw nancy f chen topic aware generator networks summarizing spoken sations arxiv preprint iain mccowan jean carletta wessel kraaij simone ashby s bourban m flynn m guillemot thomas hain j kadlec vasilis karaiskos al ami meeting corpus proceedings national conference methods techniques behavioral research yashar mehdad giuseppe carenini frank tompa et al abstractive meeting summarization linguistics volume long papers pages iulian v serban alessandro sordoni yoshua bengio aaron courville joelle pineau building end end dialogue systems generative chical neural network models thirtieth aaai ference articial intelligence guokan shang wensi ding zekun zhang toine tixier polykarpos meladianos michalis giannis jean pierre vised abstractive meeting summarization sentence compression budgeted submodular proceedings annual maximization meeting association computational guistics volume long papers pages ilya sutskever oriol vinyals quoc v le sequence sequence learning neural networks advances neural information processing systems pages ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser illia polosukhin attention need advances neural information ing systems pages lu wang claire cardie independent abstract generation focused ing summarization proceedings annual meeting association computational guistics volume long papers jingqing zhang yao zhao mohammad saleh ter j liu pegasus pre training extracted gap sentences abstractive summarization arxiv preprint zhou zhao haojie pan changjie fan yan liu lin li min yang deng cai tive meeting summarization hierarchical tive segmental network learning world wide web conference pages chenguang zhu ziyi yang robert gmyr michael zeng xuedong huang lead bias favor simple effective method news summarization arxiv preprint entailment fusion proceedings ropean workshop natural language generation pages rada mihalcea paul tarau textrank ing order text proceedings ference empirical methods natural language processing gabriel murray giuseppe carenini raymond ng generating validating abstracts ing conversations user study proceedings international natural language generation conference pages ramesh nallapati bowen zhou cicero dos santos c aglar gulcehre bing xiang tive text summarization sequence sequence proceedings rnns signll conference computational natural guage learning pages shashi narayan shay b cohen mirella lapata nt details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing pages tatsuro oya yashar mehdad giuseppe carenini raymond ng template based abstractive meeting summarization leveraging summary source text relationships proceedings international natural language generation ence inlg pages romain paulus caiming xiong richard socher deep reinforced model abstractive marization international conference ing representations colin raffel noam shazeer adam roberts katherine lee sharan narang michael matena yanqi zhou wei li peter j liu exploring limits transfer learning unied text text arxiv preprint korbinian riedhammer dan gillick benoit favre dilek hakkani tur packing meeting marization knapsack ninth annual conference international speech communication tion alexander m rush sumit chopra jason weston neural attention model abstractive proceedings tence summarization conference empirical methods natural guage processing pages evan sandhaus new york times annotated corpus linguistic data consortium philadelphia abigail peter j liu christopher d manning point summarization generator networks proceedings nual meeting association computational ami icsi beam size dev test dev test n n n n n table hyperparameter search trials beam size minimum generation length xed ami icsi bold numbers best development set performance selected beam size n table gpu memory overow issue large beam size word errors grammatical glitches compared document tion tasks like cnn daily mail hermann et al nallapati et al meeting transcript pretty long lacks important rst structure add complexity meeting summarization tasks summary generated hmnet includes individual actions proposals group ties similar reference contrast result uns clear structure hmnet effective selecting salient information lengthy transcript language summary hmnet smoother fewer grammatical errors uns reason hmnet learns language pattern reference summary ing training uns generates summaries concatenating transcript word sequences min len beam size ami icsi r table selected hyperparameters development set rouge scores reported performance table ami icsi min len dev test dev test table hyperparameter search trials minimum eration length beam size xed bold bers best development set performance selected minimum generation length training details training conducted tesla gpu g memory batch size gpu tokens pretraining ing pretraining converges steps runs approximately days tuning meeting datasets converges steps runs hours pick model highest score development set news meeting datasets pretraining netuning respectively large computation cost pretraining tune hyperparameters decoding minimum length generated mary beam size ami icsi rst set beam size grid search imum length selecting best minimum length tune beam size tuning based development set score selected hyperparameters ami icsi corresponding development set performance shown table hyperparameter search als development test set performance found table b example meeting summary demonstrate table table table examples ami meeting transcript speaker information versions summaries ence hmnet uns shang et al transcript results asr pipelines meeting transcript turns ve research research usability lab observed users operating remote controls let ll questionnaire remotes considered ugly f seventy ve percent people questioned indicated thought remote ugly additional eighty percent indicated spend money fancy looking remote control percent people indicated loo percent buttons remote control id ve got presentation working design rst works s simple everybody knows remote works user presses button remote determines button uses infrared send signal tv use percent buttons buttons pm point skip teletext world upcoming internet think teletext going thing past s function nt need remote control ui got functions remote control simple remote control buttons remote control got lot buttons people nt like thinking general functions like pm extra button info possible let s fancy fancy design easy learn buttons talked docking station lcd general functions default materials attent putting corporate image product visible design way device works pm minutes project document folder lunch break reference summary sentences project manager stated agenda marketing expert discussed functions relevant remote target demographic vision appearance remote marketing expert brought idea include docking station prevent remote getting lost idea include lcd screen user interface designer pushed user interface large buttons display function touchscreen capability controlling different devices team discussed teletext target demographic buttons remote idea marketing remote designed elderly audio signal sound remote lost lcd screens language options include teletext design despite new requirement indicates team work teletext buttons generally main feature ugly ugly remote buttons remote feature small lcd screen remote docking station summary hmnet sentences user interface designer industrial designer presented components remote control device marketing expert presented research working design selling buttons meeting industrial designer gave presentation functions remote project manager announced project include teletext feature project manager post minutes cent minutes user interface designer focus corporate image company group decided features include remote include lcd screen docking station change layout interface remote buttons buttons possible include docking station selection functions remote summary uns sentences buttons talked docking station lcd general functions fancy design easy learn buttons right places simple manner lot functions remote control pricing need great deal people indicated lcd screen remote control preferred focusing elderly people people plus wanted work seventy ve percent people indicated remote got lost room minimum number buttons real buttons use rebecca required existing remote control simply table example meeting transcript ami summary reference hmnet uns roles participants coded follows pm project manager marketing expert id industrial designer ui user interface designer manually capitalize words summaries hmnet uns better demonstration meeting transcript turns pm s conceptual design meeting points interest meeting conceptual specication components conceptual specication design trend watching doh m gon na inform trend watching ve past days ve market research distributed enquetes questionnaires ui need new attractive functions attract people s like speak speech recognition special button selecting subtitles overall user friendly large buttons id components design energy source use basic battery optional thing kinetic energy like watch casing manufacturing department deliver casing single double curved casing chip set advanced id let s look case s s normal single curved m gon na look like s like type better better prevent repetitive strain injury bit pm suggest single curved maybe curve pretty good screen ui buttons changing channel ui maybe s possible like let s colour like right colour pm user interface design s story product evaluation industrial designer user interface designer going work reference summary sentences project manager opened meeting recapped decisions previous meeting marketing expert discussed personal preferences design remote presented results trend watching reports indicated need products fancy innovative easy use dark colors recognizable shapes familiar material like wood user interface designer discussed option include speech recognition functions include remote industrial designer discussed options preferred remote terms energy sources casing case supplements buttons chips team discussed decisions energy sources speech recognition lcd screens chips case materials colors case shape orientation button orientation industrial designer user interface designer work remote use conventional battery docking station recharges battery use kinetic energy conventional battery docking station recharges remote summary hmnet sentences project manager opened meeting conceptual components conceptual design industrial designer discussed interior workings remote suggested remote feature speech recognition user interface designer presented existing products discussed option design remote docking station marketing expert discussed research trend watchers trend watchers consulted energy sources voice recognition speech recognition case recognition overall buttons discussed possibility double curved case double curved double curved cases group discussed options energy source energy sources designers work prototype evaluation having lcd screen remote covers outside station kinetic energy sources needed add extra buttons case fancy simple case plastic single curved case summary uns sentences older people like shake remote control fresh changing channels button right time look easily screen held making remote control easier leads personal preferences remote control people pay speech recognition remote control research designing y interface designer going work trendwatchers consulted advise remote control docking station telephone shape imagine start choosing case people like wood raised price table example meeting transcript summary reference hmnet uns meeting transcript turns pm ll decided meeting id working design presented rst thing question asked trying design device sends signal tv change state power channel volume ui unique people want buy features concept ip model findings people prefer user friendly complex remote controls ip trendy design eighty percent spend money remote control look fancy prepared spend money s bit nicer looking current remote controls match operating behaviour user overall asked questions table relates questions nt differentiate prefer lcd screen s multi function remote pay speech recognition remote control initially looking ndings focus younger age group initially broaden market later right away ui focus biggest market people age group thirty ve biggest market reference summary sentences industrial designer gave presentation basic functions remote presented basic components remotes share suggested smaller batteries considered product design user interface designer presented ideas making remote easy use discussed simple design hiding complicated features main interface marketing expert presented ndings lab study user requirements remote control device discussed users demand simple interface advanced technology project manager presented new requirements remote include teletext function control television include company image design group narrowed target marketing group youth market group discussed shell like shape remote including different casing options buyers remote bundled docking station recharge remote s batteries user friendly instruction manual multiple casings available limitations budget restrict development features features group wanted include simpler decrease cost summary hmnet sentences project manager recapped decisions previous meeting industrial designer discussed interior workings remote team discussed options batteries volume control lcd screens marketing expert found users want fancy look feel trendy fashionable user design user interface designer presented ndings trend watching reports indicated need products technologically innovative attractive user group decided include ip lcd screen discussed interface incorporated team discussed minimize number functions functions include design discussed making remote prot target group include lcd ease noise voice recognition locator function lcd screen marketing expert focus making product user possible compensate younger consumers remote small trendy design buttons meeting summary uns sentences important project accessible wide range consumers white age groups remote got ta press button tv beeps seventy ve percent user nd remote controls point pressing pound sign bleep room stick program control remote control hold palm hand set tv occur fair run long time change state tv appliances sending signal market research table example meeting transcript summary reference hmnet uns
