information rich logical text generation knowledge enhanced neural models hao bin wei zhiwen polytechnical university xian china research beijing china nwpu edu cn guob edu cn com r m s c v v x r abstract text generation system massive ing progress contributed deep learning niques widely applied life existing end end neural models suffer problem tending generate tive generic text ground input context background knowledge der solve problem researchers begin consider combining external knowledge text generation systems knowledge enhanced text generation challenges enhanced text generation including select appropriate knowledge large scale edge bases read understand extracted knowledge integrate knowledge generation process survey gives hensive review knowledge enhanced text eration systems summarizes research progress solving challenges proposes open issues research directions introduction text generation known natural language generation nlg aims machines express like humans capability produce smooth meaningful mative textual contents original template based statistical methods deep learning based methods text generation attracted attention massive searchers remarkable advances depending data sources text generation divided text data text image text generation focus text text generation survey massive research challenges wider range cations text text generation takes natural language text input understands input text obtain semantic tations generates corresponding output text according task requirements advances text generation recent years ted deep neural networks recurrent neural work rnn elman transformer vaswani et al contact author help technologies text generation systems able generate smooth topic consistent personalized text existing text tion systems lack interactions real world little access external knowledge making easy generate short meaningless text humans constantly acquiring understanding storing knowledge automatically combine knowledge understand current situation communicating writing reading huge challenge faced text generation systems generate informative diverse logical text text generation systems ability combine external knowledge promising research direction fig example dialogue system sense knowledge combining monsense knowledge including structured knowledge graph kg composed triples unstructured knowledge base kb composed natural language text dialogue agent generate informative diverse logical response researchers academia dustry begun explore knowledge enhanced text eration system incorporating different types knowledge complexity real world scale edge base usually extremely large extract relevant knowledge massive knowledge facts based simple text input huge challenge sity natural languages effectively derstand extracted knowledge integrate neural network models facilitate text generation difcult problem best knowledge rst survey summarize knowledge enhanced text generation systems detail sum summarize contributions work follows briey introduce development process text generation formalize denition enhanced text generation analyze number key challenges research area summarize current knowledge enhanced text generation systems tematically categorizing state art works cording research challenges research progress propose open issues research directions reference community figure dialogue examples rst line combining external knowledge background formalized denition section briey introduce development text generation formalize denition general knowledge enhanced text generation summarize research challenges nnlm rnnlm neural network language model nnlm bengio et al rstly proposed text generation tasks leverages neural networks model language representation nnlm maps input low dimensional space reducing parameters model given text quence sn parametrized language model p nnlm proximated eq t represents t th word sn p p nnlm achieved promising results experiments typical feedforward neural network length text receives xed advance capture context information variable length solve problem rnn language model rnnlm mikolov et al proposed auto regressive language model utilizes rnn encode variable length inputs vector resentations process formulated eq p p n theoretically rnnlm model text sequences length xed dimension hidden vector information excessively long context stored efciently variants rnn including long term memory lstm gated recurrent unit gru utilized improve performance rnnlm perform capturing long term dependencies encoder decoder framework length input output text language models equal cases length different e question answer qa system deal problem encoder decoder framework sutskever et al proposed composed encoder decoder encoder uses rnn encode input sequence x xm intermediate tics representation c m length input sequence decoder utilizes rnn generate t th output word yt according c process dened eq y xn n length output text sequence y t t encoder decoder general computing framework specic model encoder decoder justed based tasks widely text generation tasks proposed machine translation text summarization dialogue system knowledge enhanced text generation addition encoder decoder framework ral network models algorithms applied text generation tasks improve quality generated text development text generation systems requires ated text informative diverse logical simple smooth surface correct combined ternal knowledge text generation systems deeply stand input generate informative sistent logic human expression common sense mistakes given set knowledge facts f k fi text sequence knowledge triple k number facts knowledge types challenges structured kg representing knowledge graphs vectors incorporating knowledge vectors models unstructured kb extracting knowledge reading understanding knowledge existing solutions word embedding based knowledge representation wang et al distance based knowledge representation gunel et al graph attention based knowledge representation guan et al concatenated input vector liu et al attention based knowledge graph decoder qiu al gcn based knowledge incorporation de cao et al keyword matching ghazvininejad et al semantical level knowledge extraction lian et al memory network based knowledge understanding madotto et al transformer based knowledge understanding kim et al rl based knowledge understanding xu et al table summary challenges knowledge enhanced text generation system knowledge enhanced text generation model lated eq f f y t t forms external knowledge tured kg unstructured kb kg essentially mantic network containing multiple types entities lations form head relation tile head tile different entities entities refer things real world relations express connections entities kb xed form usually store edge related specic concepts textual sequence form challenges combining external knowledge text generation systems shown table combining structured knowledge rst challenge obtain vector representations knowledge triples ceptable inputs neural network models neural network models need input data vector form tion stored structured kb symbolized difcult problem map symbols low dimensional dense vector spaces incorporate knowledge vectors additional input neural network models guide eration process challenge knowledge facts unstructured kb stored form natural language text mapping knowledge facts vector tions pose research challenge rst challenge combining unstructured knowledge extract appropriate knowledge massive knowledge facts possible semantic duplication different edge understanding sentence level natural language text long term research challenge nlp ciently read understand textual knowledge facts tegrate generation systems challenge combining unstructured knowledge researchers great efforts address challenges tailed summarized following sections text generation structured kg structured kgs store wider range knowledge types information simple representation triples unique symbolic storage form different vectors required neural network models map knowledge triples low dimensional vector representations efciently incorporate knowledge vectors neural network models key directions research summarized section word embedding based knowledge representation simplest way obtain vector representations tured kbs directly treat entities relations edge triples common words use word embedding methods obtain vector representations widely initial research stage order comprehensive understand content ument reading comprehension tasks mihaylov et al haylov frank utilize bigru encode edge triples text sequences key value memory key value retrieval algorithm selects single sum weighted fact representations token hance understanding document context wang et al wang et al propose kb based single relation qa system entity linking module determines optimal subject question select knowledge facts encoded vectors bilstm relation tion module calculates similarity scores question relation candidates select triple highest score answer question distance based knowledge representation gap kg symbolic form vector resentation directly encoding entities common words lead certain information loss concept edge representation learning proposed represente entities relations low dimensional dense vector spaces culation reasoning bordes et al bordes et al propose transe algorithm uses translation variant phenomenon word vector distance based ing function obtain vector representations entities relations better integrated text generation system provide powerful knowledge support moussallem et al moussallem et al incorporate external knowledge machine translation system prove quality results knowledge facts linked based translated document encoded modied trane concatenated vectors internal tors nmt embeddings input decoder gune et al gunel et al incorporate entity level knowledge knowledge graph transformer encoder decoder chitecture produce coherent summaries extracted entities initialized pretrained algorithm vector representations fed separate head attention channel generating summaries graph attention based knowledge representation obtain accurate vector representations graph tention algorithm zhou et al proposed uses relation information aggregate entities generate new tity representations attention mechanism makes better use interconnections graph entities guishes hierarchy connections enhance effective information needed text generation tasks generate informative responses zhou et al zhou et al propose static graph attention mechanism generate static representation retrieved graph augment semantics input words dynamic graph attention mechanism designed attentively reading knowledge triples text generation guan et al guan et al propose incremental encoding scheme story ending generation context clues hidden story context adopt graph attention contextual attention respectively obtain graph vectors multi source attention mechanism combines commonsense knowledge facilitating story comprehension generate coherent sonable story endings comprehensive understanding paragraph level ment qiu et al qiu al construct sub graphs entities capture structural information kb resentations nodes sub graph updated graph attention network document context combined document representations generate nal answer concatenating knowledge input vector vector representations knowledge triples tained challenge facing knowledge enhanced text generation systems integrate knowledge vectors neural network models simplest method directly concatenate knowledge vectors input vectors enhance vector representations input send decoding stage text generation instance young et al young et al extract triples according entity keys input form text sequence encoded lstm obtain vector sentations knowledge vectors added input vector calculate degree correlation tive responses liu et al liu et al propose idea entity diffusion means conversation usually drifts entity similarity extracted entities entities calculated retrieve relevant tities word vectors entities relations averaged obtain vector representations triple nated input vector guide response generation attention based knowledge graph decoder attention mechanism focus important contents numerous input information select key formation ignoring unimportant tention mechanism knowledge enhanced text generation tems focus critical parts knowledge instead feeding selected knowledge directly neural works produce informative text example moon et al moon et al construct kg embeddings represent entities algorithm aggregate input contexts relevant entities ate candidate kg entities efciently attention based graph decoder proposed walk optimal path large kg select candidate entities paragraph level essay generation yang et al yang et al present memory augmented neural model bine commonsense knowledge knowledge concepts tracted input topics query stored memory matrix model attend memory ically update incorporate information generated text diverse topic consistent essay generation cel et al koncel kedziorski et al introduce graph transforming encoder leverage relational structure knowledge graphs encode knowledge graphs vectors decoder attend input title edge graphs generate informative topic coherent text gcn based knowledge incorporating gcn kipf welling natural extension cnn graph domain learns node feature structure information end end manner powerful neural network framework graphs begun attract researchers attention text generation systems combining structured knowledge graphs de et al de cao et al consider question answering inference problem graph document tion nodes graph entities appeared ment edges graph represent relations entities gcn capture reasoning chains propagating local contextual information edges form multi step reasoning generating answers lv et al et al extract evidence knowledge graph predictions based evidence graph based contextual word representation learning module dene distance words learning better textual word representations graph structural tion graph based inference module applied encode neighbor information representations nodes gcn aggregate evidence generate answers text generation unstructured kb unstructured kbs composed natural language text lated concepts express rich semantic information textual form unstructured kb ily combined text generation systems input text sequences scale knowledge base usually extremely huge contains redundant information extract knowledge required text generation systems efciently understand knowledge integrate generation process main research challenges researches grounded text generation unstructured kb discussed detail section key word matching based knowledge extraction simplest way extract knowledge unstructured kb key matching method words input keywords method simple direct extract knowledge according surface information words combine deeper semantic information knowledge extraction instance ghazvininejad et al ghazvininejad et al rstly introduce external knowledge fully driven neural conversation model given dialogue history relevant knowledge facts identied keyword matching method entities context keys retrieved know facts fed memory network retrieve weight facts based input dialogue context hance semantic representation input semantical level knowledge extraction simple key word matching method hard accurately select required knowledge information contained single word searchers focus knowledge selection semantic level forward novel ideas query human conversation related different responses different knowledge utilized lian et al solve problem lian et al pose idea posterior distribution knowledge calculated input query response provide accurate guidance knowledge selection minimizing distance prior posterior distribution knowledge prior distribution lized select appropriate knowledge generate mative responses actual response unknown ren et al ren et al propose global local edge selection mechanism global perspective select appropriate background knowledge topic tion vector learned dialogue context external knowledge distantly supervised learning schema lect likely text fragments vector guide local knowledge selection module decoding stage generate uency appropriate responses zhao et al zhao et al represent disentangled response coder separate parameters relying knowledge grounded dialogues model solve problem ing knowledge grounded training data decoder posed components including language model generate common words context processor generate text words knowledge processor generate words knowledge document hierarchical attention mechanism memory network based knowledge understanding extracting relevant knowledge facts import read understand textual knowledge enhance input representation guide text generation memory work sukhbaatar et al proposed improve poor memory ability rnn external memory ponent realize storage long term memory powerful memory storage capacity memory network widely knowledge enhanced text generation systems retrieve read condition external knowledge madott et al madotto et al augment memory network sequential generative architecture edge facts fed memory network update input query vector gru dynamic query generator generate output words produce tion decide generate common words memory contents order carefully read understand trieved knowledge dinan et al dinan et al combine memory network transformer encode selected knowledge dialogue context higher level semantic representation dot product attention tween knowledge context performed retrieved relevant knowledge generating response transformer based knowledge understanding transformer emerging sequential model caused great repercussions nlp exceeds rnn tic information abstraction long term feature extraction task comprehensive feature representation researches begun use transformer read attend external knowledge text generation systems example zhao et al zhao et al use multi head attention mechanism transformer encode dialogue context response candidate relevant ment hierarchical interaction context document importance different parts document context determined select appropriate sponse li et al li et al employ multi head tention vector representation external knowledge input incremental transformer incorporates tor representation knowledge context encoding process encode knowledge utterances span turn dialogue decoder contains processes rst pass focuses contextual coherence pass renes results rst pass attending knowledge increase knowledge relevance ness kim et al kim et al propose sequential latent model sequentially conditions previously selected knowledge produce informative responses input terance knowledge sentences encoded vectors model knowledge selection latent variables joint inference knowledge selection multi turn dialogue rl based knowledge understanding reinforcement learning subeld machine learning emphasizes act based state maximize expected rewards continuously interacting environment rl use rewards punishments given environment continuously improve strategy kind actions kind state imum cumulative rewards rl actually close way human thinking likely future general articial intelligence paradigm based deep q network dqn typical rl algorithm xu et al xu et al propose knowledge routed dqn age topic transitions dialogue relational nement branch encodes relations different symptoms knowledge routed graph branch decides policy rl different medical knowledge branches ensure dialogue manager agent interacting vironment reasonable decisions edge guiding relation encoding conclusion future directions survey makes systematic literature review search trends knowledge enhanced text generation help external knowledge text generation system understand input text deeply comprehensively generate informative text promising search direction emerging research direction open issues research knowledge enhanced text generation system briey discussed combining structured unstructured knowledge present researches mainly focus incorporating form external knowledge forms knowledge combined appropriately informatively text generated structured kg narrow knowledge candidates prior information entities graph paths unstructured kb provide abundant mation enhance text generation need strong pability natural language understanding select useful information forms knowledge vantages disadvantages structural ences challenging research direction combine structured unstructured knowledge generation tems certainly bring promising progress knowledge enhanced text generation system lifelong learning humans continuously learn new knowledge update knowledge base adapt fast changing pace society existing text generation systems utilize xed knowledge bases knowledge updating real time text generation models morphic ability continuous lifelong learning meaningful exploration discussed mazumder et al propose mazumder et al lifelong interactive learning inference model actively ask users questions encountering unknown concepts update knowledge base corresponding answers reached continuously obtain information numerous external inputs achieve lifelong learning important research direction text generation acknowledgments work supported national key program china national natural ence foundation china references bengio et al yoshua bengio rejean ducharme pascal vincent christian jauvin neural tic language model journal machine learning research bordes al antoine bordes nicolas usunier oksana alberto garcia duran yakhnenko translating embeddings modeling multi relational data advances neural information processing systems pages jason weston de cao et al nicola de cao wilker aziz ivan titov question answering reasoning documents proceedings graph convolutional networks naacl hlt pages dinan et al emily dinan stephen roller kurt shuster angela fan michael auli jason weston wizard wikipedia knowledge powered conversational agents international conference learning sentations elman jeffrey l elman finding structure time cognitive science ghazvininejad et al marjan ghazvininejad chris brockett ming wei chang bill dolan jianfeng gao wen tau yih michel galley knowledge grounded neural conversation model thirty second aaai ference articial intelligence guan et al jian guan yansen wang minlie huang story ending generation incremental ing commonsense knowledge proceedings aaai conference articial intelligence volume pages gunel et al beliz gunel chenguang zhu michael zeng xuedong huang mind facts boosted coherent abstractive text summarization neurips kim et al byeongchang kim jaewoo ahn gunhee kim sequential latent knowledge selection international knowledge grounded dialogue ence learning representations kipf welling thomas n kipf max welling semi supervised classication graph convolutional networks arxiv preprint koncel kedziorski et al rik koncel kedziorski dhanush bekal yi luan mirella lapata hannaneh hajishirzi text generation knowledge graphs proceedings naacl hlt graph transformers pages et al zekang li cheng niu fandong meng yang feng qian li jie zhou incremental deliberation decoder document grounded conversations proceedings annual meeting association computational linguistics pages lian et al rongzhong lian min xie fan wang jinhua peng hua wu learning select knowledge response generation dialog systems proceedings international joint conference articial telligence pages aaai press liu et al shuman liu hongshen chen zhaochun ren yang feng qun liu dawei yin knowledge diffusion neural dialogue generation proceedings annual meeting association tational linguistics volume long papers pages et al shangwen lv daya guo jingjing xu duyu tang nan duan ming gong linjun shou daxin jiang guihong cao songlin hu based reasoning heterogeneous external knowledge arxiv preprint commonsense question answering madotto et al andrea madotto chien sheng wu pascale fung effectively incorporating knowledge bases end end task oriented dialog tems proceedings annual meeting sociation computational linguistics volume long papers pages mazumder et al sahisnu mazumder nianzu ma bing liu continuous knowledge ing engine chatbots arxiv preprint knowledgeable reader mihaylov frank todor mihaylov anette enhancing frank style reading comprehension external commonsense knowledge proceedings annual meeting association computational linguistics volume long papers pages mikolov et al tomas mikolov martin karaat lukas burget jan sanjeev khudanpur current neural network based language model eleventh annual conference international speech cation association moon et al seungwhan moon pararth shah anuj kumar rajen subba opendialkg explainable conversational reasoning attention based walks proceedings annual knowledge graphs meeting association computational linguistics pages et al diego moussallem mihael arcan axel cyrille ngonga ngomo paul buitelaar augmenting neural machine translation knowledge graphs arxiv preprint qiu al delai qiu yuanzhe zhang xinwei feng xiangwen liao wenbin jiang yajuan lyu kang liu jun zhao machine reading comprehension proceedings tural knowledge graph aware network conference empirical methods ral language processing international joint conference natural language processing ijcnlp pages ren et al pengjie ren zhumin chen christof monz jun ma maarten de rijke thinking globally acting locally distantly supervised global local edge selection background based conversation arxiv preprint sukhbaatar et al sainbayar sukhbaatar jason ston rob fergus al end end memory networks advances neural information processing systems pages sutskever et al ilya sutskever oriol vinyals quoc v le sequence sequence learning neural networks advances neural information processing systems pages vaswani et al ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser illia polosukhin attention need advances neural information processing tems pages wang et al run ze wang zhen hua ling yu hu knowledge base question answering ieee access tive pooling question representation xu et al lin xu qixian zhou ke gong dan liang jianheng tang liang lin end end knowledge routed relational dialogue system matic diagnosis proceedings aaai conference articial intelligence volume pages yang et al yang quan wang jing liu kai liu yajuan lyu hua wu qiaoqiao sujian li enhancing pre trained language representations rich knowledge machine reading comprehension ceedings annual meeting association computational linguistics pages young et al tom young iti chaturvedi hao zhou subham biswas minlie huang augmenting end end dialogue systems thirty second aaai commonsense knowledge conference articial intelligence erik cambria zhao et al xueliang zhao chongyang tao wei wu xu dongyan zhao rui yan document grounded matching network response arxiv preprint lection retrieval based chatbots zhao et al xueliang zhao wei wu chongyang tao xu dongyan zhao rui yan low resource knowledge grounded dialogue generation tional conference learning representations et al hao zhou tom young minlie huang haizhou zhao jingfang xu xiaoyan zhu monsense knowledge aware conversation generation graph attention ijcai pages
