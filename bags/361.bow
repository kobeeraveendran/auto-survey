bengali abstractive news summarization bans a neural attention approach prithwiraj avi md saiful and marium e department of computer science and engineering shahjalal university of science and technology bangladesh sust edu com saiful cse jannat edu abstract abstractive summarization is the process of generating novel sentences based on the information extracted from the original text ument while retaining the context due to abstractive summarization s underlying complexities most of the past research work has been done on the extractive summarization approach nevertheless with the umph of the sequence to sequence model abstractive rization becomes more viable although a significant number of notable research has been done in the english language based on abstractive summarization only a couple of works have been done on bengali stractive news summarization bans in this article we presented a based long short term memory lstm network model with attention at encoder decoder our proposed system deploys a local attention based model that produces a long sequence of words with cid and human like generated sentences with noteworthy information of the original document we also prepared a dataset of more than articles and corresponding human written summaries collected from bangla which is till now the most extensive dataset for bengali news document summarization and publicly published in we evaluated our model qualitatively and quantitatively and pared it with other published results it showed significant improvement in terms of human evaluation scores with state of the art approaches for bans keywords attention abstractive summarization bleu rouge dataset lstm encoder deocder bengali introduction text or document summarization is the process of transforming a long ment or documents into one or more short sentences which contain the key kaggle com prithwirajsust bengali news summarization dataset p bhattacharjee et al points and main contents automatic summarization became vital in our daily life in order to minimize the effort and time for finding the condensed and vant delineation of an input document that captures the necessary information of that document despite different ways to write the summary of a document the summarization can be categorized into two classes based on the content lection and organization extractive and abstractive approach extractive summarization basically finds out the most important sentences from the text using features and grouped to produce the summary it is like highlighting a text through a highlighter in contrast abstractive summarization is a technique that generates new sentences instead of selecting the essential sentences of the original document that contain the most critical information like a human ing writing a summary from his thinking with a pen machine learning based summarizing tools are available nowadays but the language specific models are hard to find although a notable number of works have been done on bengali extractive marization only a few abstractive summarizations are available the majority of the available works are based on the basic machine learning ml techniques and the dataset was too small due to the lack of standard datasets no ca nt work is available on encoder decoder based summarization systems so the most challenging part for bans is to prepare a standard and clean dataset to build a bengali news summarization dataset a crawler has been made to crawl data from online resources like a daily newspaper we have collected more than data from bangla online portal the dataset represents the article and its corresponding summary in this paper a sequence to sequence lstm encoder decoder architecture with figure illustration of our neural attention model for abstractive rization of bengali news incorporates a set of lstm encoder decoder on top of a standard word embedding attention has been presented for bengali abstractive news summarization bengali abstractive news summarization bans ure illustrates the proposed model the source code and other details of the model already uploaded to then the dataset of size has also been prepared which is till now the largest one and published it in the word embedding layer has been used to represent the words in numbers and fed them into the encoder moreover both the encoder and decoder parts are ciated with some attention mechanisms we got a notable improvement in terms of human assessment compared to other available bengali abstractive rization methods we also evaluated rouge and bleu scores in short our contribution to this work is threefold they are preparation of till now the largest bengali news summarization dataset of size documents with its summary and published it in presenting the encoder decoder architecture with the attention mechanism for bengali abstractive news in an efficient way evaluation of the model both qualitatively and quantitatively and the sented approach outperforms bengali state of the art approaches related work there are different kinds of abstractive text summarization approaches that ist we found that yeasmin et al have described the different techniques regarding abstractive approaches then as we decided to focus on abstractive text summarization approaches on the bengali language context we covered haque et al where approaches of bengali text summarization regarding both extractive and abstractive approaches are described in islam et al first introduced bengali extractive summarization based on document indexing and keyword based information retrieval then techniques of english extractive text summarization were applied for bengali by uddin et al in das et al used theme identification page rank algorithms for extractive marization sentence ranking and stemming process based bengali extractive summarization were first proposed by a researcher named kamal sarkar and later in a better way by efat et al haque et al respectively proposed a key phrase based extractive approach and a pronoun replacement based sentence ranking approach in the heuristic approach proposed by abujar et al k means clustering method of akther et al and lsa latent semantic analysis method stated in chowdhury et al became popular techniques for bengali extractive rization the graph based sentence scoring feature for bengali summarization was first used by ghosh et al moreover sarkar et al and ullah et al proposed term frequency and cosine similarity based extractive approach respectively recently munzir et al instigated a deep neural network based bengali tractive summarization again abujar et al introduced based word embedding for bengali text summarization then talukder et al com bengali deep news summarization p bhattacharjee et al proposed an abstractive approach for bengali where bi directional rnns with lstm are used at the encoder and attention at the decoder we also used lstm rnn based attention model like but we applied attention to both the encoder and the decoder layer and did some comparative study with the responding result part and dataset part with the existing one another rnn based text generation process is introduced by abujar et al for bengali abstractive text summarization we used the concept stated in lopyrev et al for our system the model and the lstm encoder decoder architecture we used was introduced by sutskever et al and bahdanau et al respectively again the decoder and encoder part s attention technique is the concept stated in luong et al and rush et al respectively furthermore the lstm concept based guage parsing method has been adopted from vinyals et al dataset a standard dataset is a vital part of text summarization we gathered a ceptual idea of preparing a standard dataset from hermann et al and also observed some of the existing public english datasets like cnn daily dataset we need a vast amount of data for training but no significant dard public dataset is available for bengali summarization so we collected table statistics of the dataset total no of articles total no of summaries maximum no of words in an article maximum no of words in a summary minimum no of words in an article minimum no of words in a summary news and its summary from the online news portal bangla as it had both the article and its summary we made a crawler and crawled news articles and their summaries from different categories like sports politics economics online news contains lots of garbage like advertisements bengali words different websites links so we started preprocessing by making a data cleaning program that eliminates all kinds of garbage from the dataset we uploaded data crawling cleaning and analysis source and their working details to github and publicly published our dataset in a tabular representation of our processed data is shown in table the cance and comparison of our dataset with only publicly available bangla natural nyu kcho com data manipulation bengali abstractive news summarization bans language processing community summarization dataset has been shown in table table comparison of our standard dataset with bnlpc dataset source dataset our total articles no of summary per article total summaries model architecture by observing the significant performance of lstm encoder decoder with the attention mechanism described in lopyrev et al we ve used a similar ral attention model architecture it has an lstm encoder part and an lstm decoder part both of the parts are associated with some attention nisms tensorflow s embedding layer has been used to represent the words in numbers to feed into encoders after generating the decoder s output a comparison between the actual and predicted summary has been done using the softmax loss function and for minimizing the loss the network started back propagating lastly a summary has been generated with minimal loss the whole process works as a approach and can be alized by figure let s describe the major two components of our model firstly an input sequence is encoded to numbers via word embedding layer and fed into the lstm encoder in reverse order sutskever et al proposed that because of calculating short term dependencies the first few words of both the input sequence and output sequence must be closer to each other and it can be achieved by feeding input in reverse order and thus the result can be significant that means bengali sentence like is fed into each encoder cell reversely as individual word and respectively attention is also used to the encoder part as mentioned by rush et al secondly we used a greedy lstm decoder which is different from a beam search decoder firstly encoder output is fed into the first decoder cell then the put of the current decoder cell is fed into the next decoder cell along with the attention as well as the information from the previous decoder cell and ued the process till the last decoder cell that means if the first generated word in the decoder cell is then this word will help to predict the next word suppose for the next decoder cell combining with attention and ued the process till the end the decoder attention mechanism is implemented as stated in before training we made a vocabulary of the most frequent words both from bnlpc org research php p bhattacharjee et al articles and summaries the out of vocabulary words are denoted by unk ken pad token is used for padding the article and its summary to the bucket sizes a bucket is nothing but an array where we define how many words an article and its summary can hold while training we used five encoder decoder lstm models for training now the trained model also padded the words of the given input sentences to the bucket sizes so the model can well summarize the articles containing the number of words in all sentences equal to the largest bucket size and in our case it was for article and summary respectively result and discussion we assessed our model based on two types of evaluation matrices for analyzing the result they are quantitative evaluation and qualitative evaluation both of the evaluation methods are mandatory for checking how much the mary system is suitable for generating a summary of our data was used for training for validating and was used for testing the system was trained three times with different parameter specifications after the evaluation we found that the system has the best output when the vocabulary size was set to hidden unit to learning rate to and steps per checkpoint to table shows some generated examples of our best model we showed two good quality as well as two poor quality predictions in table from our system here the first two predictions are well summarised by our model and sometimes the new word has also been generated like in the second ample on the other hand from the last two predictions on the table we found that repetition of words like in the third example and in the fourth example occurred twice further from the third example we can see inaccurate reproduction of factual details that means word has been produced by the model rather than predicting the word in the fourth example moreover due to bucketing issues some summaries are forcefully stopped before hitting the end token of the sentence which can be shown in third predictions on table quantitative evaluation quantitative evaluation is a system oriented evaluation in this evaluation cess both the actual and predicted summaries are given as input to a gram and the program generates a score comparing how much the predicted summary deviates from the actual summary we found that recall oriented understudy for gisting evaluation rouge and bilingual evaluation derstudy bleu are two standard quantitative evaluation matrices as far as our knowledge quantitative evaluation of the existing bengali abstractive text summarization techniques is not mentioned or publicly available so we could not compare our evaluation with them but as per standard scoring tioned in the papers our achieved score was also significant there are bengali abstractive news summarization bans table illustrates some predictions of our bans system showing the input news article actual summary and bans predicted summary e r o c s e v i a t i n a u q rouge l bleu figure illustrates the quantitative analysis of our proposed model based on rouge l and bleu scores new articleactual summarypredicted summarybengali english the miscreants set fire to a bus in steel mill area of chittagong city during the strike and blockade of the bnp alliance bengali english fire on bus in chittagong bengali fire on the buses of chittagongbengali english two children drowned at melandho in jamalpur bengali two children drowned in jamalpurbengali the child drowned in the pondbengali english truck driver zahid ahmed died in a hospital after eight days being burnt by a petrol bomb in a blockade at polash in narsingdi bengali truck driver killed in bomb blast in narsingdibengali more death from burns burns in the siegebengali english the body of a young man who went missing after falling into the river at thakurgaon sadar has been recovered bengali english the dead body of a missing young boy was recovered in thakurgaon bengali english the dead body dead bodyof a missing young boy was recovered in kushtia p bhattacharjee et al different variants of rouge calculation exist l rouge n are some of them here we computed the most adapted rouge l and measured the bleu score as well firstly we took generated summaries and corresponding actual summaries and calculated the average bleu score again for rouge calculation we first calculated the precision and recall then using these two measurements calculated the average score for that examples the bar diagram of figure denotes rouge and bleu scores of the best model qualitative evaluation qualitative evaluation is the user oriented evaluation process here some users of different ages take part in rating the generated summary on a scale of compared with the actual one for the qualitative evaluation we took some examples from our system and some from the existing one as far as our table qualitative evaluation of existing system and the proposed system system proposed system existing system average of knowledge qualitative evaluation of the existing method is not publicly available so for comparison we also had to calculate the rating for we provided the examples of both the systems to the users via a google survey a total of users participated in a rating on a scale of among the users were female and were male moreover all the users were from the educational background with an average age of again were from linguistic faculty were from engineering faculty and were from other faculties we calculated the average rating regarding each of the models and found that our system outperforms the existing system based on human assessment the qualitative rating of the systems is shown in table conclusion to recapitulate the development of the standard summarization dataset of bengali news has been one of our pioneering accomplishments cially since it is the largest publicly published dataset in this field here a neural attention based encoder decoder model for abstractive summarization of bengali news has been presented which generates human like sentences with core mation of the original documents along with that a large scale experiment was gle bengali abstractive news summarization bans conducted to investigate the effectiveness of the proposed bans from the itative evaluation we have found that the proposed system generates more manoid output than all other existing bans indeed the lstm based decoder has been exceptionally successful nonetheless the model s performance can deteriorate quickly for long input sequences repetition of summaries and inaccurate reproduction of factual details are two significant problems to fix these issues we plan to drive our efforts on modeling hierarchical encoder based on structural attention or pointer generator architecture and developing ods for multi document summarization acknowledgements we would like to thank shahjalal university of science and technology sust research center and sust nlp research group for their support references yeasmin s tumpa p b nitu a m uddin m p ali e afjal m i study of abstractive text summarization techniques american journal of engineering research haque m m pervin s hossain a begum z approaches and trends of tomatic bangla text summarization challenges and opportunities international journal of technology diffusion ijtd islam m t al masum s m bhasa a corpus based information retrieval and summariser for bengali text in proceedings of the international conference on computer and information technology uddin m n khan s a a study on text summarization techniques and ment few of them for bangla language in international conference on computer and information technology pp ieee das a bandyopadhyay s topic based bengali opinion summarization in ing posters pp sarkar k bengali text summarization by sentence extraction arxiv preprint efat m i a ibrahim m kayesh h automated bangla text summarization by sentence scoring and ranking in international conference on informatics electronics and vision iciev pp ieee haque m m pervin s begum z enhancement of keyphrase based approach of automatic bangla text summarization in ieee region conference tencon pp ieee haque m pervin s begum z al an innovative approach of bangla text summarization by introducing pronoun replacement and improved sentence ing journal of information processing systems abujar s hasan m shahin m hossain s a a heuristic approach of text summarization for bengali documentation in international conference on computing communication and networking technologies icccnt pp ieee akter s asa a s uddin m p hossain m d roy s k afjal m i an extractive text summarization technique for bengali document s using k means clustering algorithm in ieee international conference on imaging vision pattern recognition icivpr pp ieee p bhattacharjee et al chowdhury s r sarkar k dam s an approach to generic bengali text marization using latent semantic analysis in international conference on information technology icit pp ieee ghosh p p shahariar r khan m a h a rule based extractive text rization technique for bangla news documents international journal of modern education and computer science sarkar a hossen m s automatic bangla text summarization using term quency and semantic similarity approach in international conference of computer and information technology iccit pp ieee ullah s hossain s hasan k a opinion summarization of bangla texts using cosine simillarity based graph ranking and relevance based approach in international conference on bangla speech and language processing icbslp pp ieee al munzir a rahman m l abujar s hossain s a al text analysis for bengali text summarization using deep learning in international ference on computing communication and networking technologies icccnt pp ieee abujar s masum a k m mohibullah m hossain s a al an approach for bengali text summarization using in international ference on computing communication and networking technologies icccnt pp ieee talukder m a i abujar s masum a k m faisal f hossain s a bengali abstractive text summarization using sequence to sequence rnns in international conference on computing communication and networking nologies icccnt pp ieee abujar s masum a k m islam m s faisal f hossain s a a bengali text generation approach in context of abstractive text summarization using rnn in innovations in computer science and engineering pp springer lopyrev k generating news headlines with recurrent neural networks arxiv preprint sutskever i vinyals o le q v sequence to sequence learning with neural networks in advances in neural information processing systems pp bahdanau d cho k bengio y neural machine translation by jointly learning to align and translate arxiv preprint luong m t pham h manning c d effective approaches to attention based neural machine translation arxiv preprint rush a m chopra s weston j a neural attention model for abstractive sentence summarization arxiv preprint vinyals o kaiser koo t petrov s sutskever i hinton g grammar as a foreign language in advances in neural information processing systems pp hermann k m kocisky t grefenstette e espeholt l kay w suleyman m blunsom p teaching machines to read and comprehend in advances in neural information processing systems pp lin c y rouge a package for automatic evaluation of summaries in text summarization branches out pp pastra k saggion h colouring summaries bleu in proceedings of the eacl workshop on evaluation initiatives in natural language processing are evaluation methods metrics and resources reusable pp
