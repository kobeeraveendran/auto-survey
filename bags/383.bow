fairness understanding reader s perception fairness text summarization anurag shandilya abhisek dash indian institute technology kharagpur india abhijnan chakraborty max planck institute software systems germany kripabandhu ghosh indian institute science education research kolkata india saptarshi ghosh indian institute technology kharagpur india e f r s c v v x r abstract surge user generated textual tion recent increase use rization algorithms providing overview extensive content traditional metrics evaluation algorithms e rouge scores rely matching algorithmic summaries human generated ones shown textual contents heterogeneous e come different socially salient groups existing rization algorithms represent social groups differently compared distribution original data mitigate adverse impacts fairness preserving summarization algorithms proposed studies considered normative notions fairness perspective writers contents neglecting readers perceptions underlying fairness notions bridge gap work study interplay fairness notions readers perceive textual summaries experiments reader s perception fairness context sensitive standard rouge evaluation metrics unable quantify perceived summaries end propose human loop metric automated graph based methodology quantify perceived bias textual summaries demonstrate utility quantifying summaries heterogeneous socio political microblog datasets introduction surge textual information web text summarization algorithms increasingly quick overview information standard framework text summarization broadly divided parts summary generation summary evaluation shown figure summary generation given document set documents marization algorithm summarizes generally kinds summarization approaches followed literature extractive summarization algorithms select sentences document include summary ii abstractive summarization algorithms produce natural language summaries traditional summarization algorithms meant rizing homogeneous documents e news topic work accepted international workshop fair interpretable learning algorithms fila held conjunction ieee bigdata cite version appearing proceedings fig generic block diagram explaining summarization pipeline machine generated summaries evaluated based match human written reference summaries metrics rouge scores quantify goodness automated summaries research focused worthiness textual units deciding include exclude summary growing popularity social media websites facebook twitter user generated content constitutes large chunk textual information generated web today social media different user groups discuss different socio political issues observed ferent opinions topic event textual information summarised gradually heterogeneous prior work shown text contains different opinions people different ideologies social groups downstream applications algorithm generated summaries consumed people play vital role shaping opinion different socio political issues summary quality fairness aspect algorithmic summaries produced automatic summarization algorithms essential lately led different fair summarization algorithms heterogeneous user generated textual units evaluation algorithmic summaries traditionally evaluation algorithmic summaries carried uating closely match human generated summaries source document set documents given number human annotators summarize metrics like documentrougescoressummarization algorithmsummaryhuman annotatorsgold standard summariesevaluationsummarygenerationsummaryevaluation rouge quantify goodness algorithmic summaries measures perform evaluating goodness summaries based textual quality readability explicitly quantify algorithmic summary process evaluation laborious expensive task evaluation multi document marization particularly expensive reported hours human effort required evaluate summaries document understanding conferences duc drawbacks existing framework existing fair summarization algorithms tried incorporate normative representational fairness goals tive content producers writers nal summary summaries perceived fair consumers readers debate additionally different existing approaches evaluating summaries popular computation rouge scores limitations comes quantication fairness aspect summaries heterogenous user generated text corpora current work work posit context summarization fairness highly context dependent ideally involves multiple stakeholders important stakeholders summarization set producers writers textual units consumers readers nal summary interpretation fairness vary envisage reader s perspective end work investigate interplay earlier proposed denitions fairness summarization consumers perceptions fairness interplay varies context underlying topic investigate effectiveness existing measures e rouge quantifying summary specically seek answer following research questions rqs readers perception summaries context dependent traditional metrics summary quality rouge scores capture readers perception fairness summaries nally metric based representation opinions better capture readers perception summaries answer aforementioned rqs conducted series surveys socio political datasets obtained microblogs tweets related dential elections metoo movement different analyses main contributions observations present work summarised follows readers differentiate fair unfair summaries reasons summary perceived context dependent cases perceived fairness agrees standard resentational fairness notions demographic groups producers cases perceived fairness use word pairs producers writers consumers readers interchangeably paper agree fairly opinions represented summary case standard rouge metrics capture bias summaries perceived consumers propose metric perceived bias summary based manual identication opinions input text judging opinions represented summary finally propose graph based methodology matically measuring bias summary observe correlates perceived opinion bias metric stated ii background related work section discuss relevant prior works fairness text summarization motivate present work contextualizing existing literature fairness text summarization dataset like fairness ml literature proposed methodologies fair text summarization divided categories e pre processing processing post processing based algorithms based stage fairness intervention performed pre processing based algorithms fed summarization algorithms way generated summaries end fair similarly post processing algorithm fairness interventions applied output standard summarization algorithms generate fair summaries finally processing based approach rithm designers treat summarization optimization problem solve modifying tion function adding fairness constraints generate fair summaries briey discuss fairsumm algorithm proposed fairsumm algorithm fair summarization prior work developed processing fair summarization gorithm called fairsumm fairsumm treats rization task sub modular optimization problem fairness constraints solves maximize coverage diversity textual units adhering standard fairness notions given heterogeneous set blogs coming different socially salient groups desired target representation groups algorithm produces extractive summaries reconcile textual quality summaries quantied rouge scores fair representation different social salient groups summary instance fairsumm applied set tweets posted male female authors obtain good summary having equal fractions tweets posted male authors tweets posted female authors shall fairsumm algorithm extensively experiments paper b notions fairness text summarization prior works fair summarization deal idea group fairness specically input data e tweets reviews generated users different socially salient groups algorithms explicitly enforce summaries fairly represent different groups equal representation notion equality nds roots eld morality justice advocates redress undeserved inequalities e inequalities birth natural context tion ensures nal summary include equal number textual units coming different socially salient groups proportional representation possible equally represent different user groups summary especially input data contains different proportions different groups consider notion fairness proportional representation known cal parity context summarization proportional representation requires proportion content different user groups summary original input notions fairness ensure probability ing item independent user group generated c drawbacks current literature process summarizing involves parties producers information writers consumers summarized information readers prior works fairness summarization attempted ensure fair representation producers fairness consumers readers completely ignored inclusion exclusion certain opinions voices tend maximum effect consumers summaries summary summary shapes opinion topic bias nal summary severe impact shaping public discourse work focus exploring interplay existing fairness denitions perceived readers read consumers limitations existing measures quantication summaries evaluation generated summaries prior works evaluated generated summaries based rouge metric work observe rouge metric unable capture aspect generated summaries end work propose metric perceived fairness textual summaries propose automated quantication perceived bias textual maries correlates signicantly aforementioned perceived fairness best knowledge rst work quantication summaries understanding interplay perceived fairness text tion perspective writers readers textual content iii datasets reuse following datasets prior work election dataset dataset originally provided darwish et al contains english tweets posted presidential election tweet annotated supporting attacking presidential candidates donald trump hillary clinton neutral attacking simplicity grouped tweets classes pro republican tweets support trump attack clinton pro democratic tweets support clinton attack trump neutral tweets neutral attack candidates metoo dataset collected set tweets related metoo movement october specically collected english tweets containing hashtag metoo twitter search api asked human annotators examine bio twitter accounts posted tweets annotators observed classes tweets based posted tweets tweets posted male users ii tweets posted female users iii tweets posted organizations mainly news media agencies tweets annotators understand type gender user posting tweet purpose study decided focus tweets annotators certain written male users female users datasets selected set tweets having equal representation different graphic groups words selected tweets uselection dataset containing pro democratic tweets pro republican tweets neutral tweets similarly selected tweets metoo dataset containing tweets posted male users tweets posted female users selecting sets tweets ensured choosing distinct tweets removed near duplicates formed informative experiments paper conducted sets tweets rest paper conduct number surveys experiments aforementioned datasets pursuit answers rqs mentioned introduction iv understanding consumers perception fairness summaries section investigate stated introduction readers perception summaries context dependent end rst generate summaries having different levels biases conduct survey understand consumers human annotators perceive bias fairness summaries generating differently biased summaries consider set tweets elections dataset pro democratic tweets pro republican tweets neutral tweets repetitive nature apply fairsumm algorithm set tweets generate summaries length tweets having wide variety bias completely biased pro republican ideology completely biased pro democratic ideology end x certain number neutral tweets vary number pro republican pro democratic tweets create variously biased summaries specically create batches summaries batch neutral tweets batch neutral tweets rst batch summaries neutral tweets term fairsumm contains lowing summaries length tweets pro rep tweets pro dem tweets neutral tweets actually unfair summary pro rep tweets pro dem tweets neutral tweets actually unfair summary pro rep tweets pro dem tweets neutral tweets pro rep tweets pro dem tweets neutral tweets actually fair summary pro rep tweets pro dem tweets neutral tweets pro rep tweets pro dem tweets neutral tweets actually unfair summary pro rep tweets pro dem tweets neutral tweets actually unfair summary second batch summaries neutral tweets term fairsumm contains following summaries length tweets pro rep tweets pro dem tweets neutral tweets actually unfair summary pro rep tweets pro dem tweets neutral tweets actually unfair summary pro rep tweets pro dem tweets neutral tweets pro rep tweets pro dem tweets neutral tweets actually fair summary actually fair summary pro rep tweets pro dem tweets neutral tweets actually unfair summary pro rep tweets pro dem tweets neutral tweets actually unfair summary similarly consider set tweets metoo dataset containing tweets posted male users tweets posted female users stated section iii apply fairsumm generate following summaries length tweets having wide variation bias completely biased tweets posted male users completely biased tweets posted female users batch summaries fairsumm metoo contains following summaries length tweets male tweets female tweets actually unfair summary male tweets female tweets actually unfair male tweets female tweets male tweets female tweets male tweets female tweets actually fair male tweets female tweets male tweets female tweets actually unfair male tweets female tweets actually unfair summary summary summary summary noted summaries generated fairsumm algorithm actual biases known terms number tweets included summary ent perspectives check bias fairness summaries viewed consumers human annotators b understanding consumers perception start group annotators males females substantial knowledge politics metoo phenomenon age group years questionnaire ascertain knowledge politics metoo movement annotators familiar use social media platforms including twitter annotators author paper annotators rst asked sets tweets uselection metoo note distinct opinion expressed tweets opinion dened unique idea information conveyed tweet hitherto covered previous tweet note annotators shown text tweets told gender political ideology users authored tweets limit opinions identify opinion required conned maximum sentences table tabulates opinions identied annotators set tweets related elections annotators shown summaries fairsumm fairsumm metoo batches random order asked judge fairness summary label summary following labels fair representation somewhat fair representation somewhat unfair representation unfair representation labeling summary asked provide reasoning judgement words asked indicate based judging summary fair unfair fair unfair representation political gender groups fair unfair representation political contextual opinions fair unfair representation political gender groups political contextual opinions hillary derogatory titles voting hillary trump facing rape charges deter trump stop ghting clinton admitted obamacare bad hillary pissed trump claims credit terrorist acts like terrorists college affordable says come presidential debate people feel hillary winning claims sources report negatively campaign trusted know net worth hillary cause disclosed assets thinks solid strategy defeat isis trump trump supporters want win abuse women want getting ready battle reclaim mosul hillary shames thinks voting stupid thinks hillary crooked refuses accept current potus born america bad hillary happy bill clinton said nt drive america great cancelling subscriptions dallas arizona newspapers smart people nt wanna vote need told hillary rid huge college debt thinks hilary ghting isis success years s time change thinks hillary told lies life sold america s interests way hillary handling e mail case unt post president proponent love kindness america solid strategy defeat isis unlike trump guys want trump win oppress women thankful nation helped bring paris agreement action unarmed black men unacceptable women country deserves free harm fear release police video keith lamont scott shooting delay table set distinct opinions separated identied annotators set tweets related elections reason requires subjective response examine consumer s perception fairness varies different contexts scenarios end plot fraction annotators annotated summary fair representation input text unfair representation input text fractions termed fair approval fraction unfair approval fraction respectively figure depicts result uselection dataset gures fairsumm summaries respectively metoo dataset c fairsumm metoo summaries recall batch group summaries having number neutral tweets varying number tweets perspectives results evident election dataset fraction annotators said summary fair fraction annotators said summary unfair correlates actual fairness fairsumm summaries instance summaries having larger number pro republican tweets summaries having larger number democratic tweets labeled unfair annotators summaries having relatively similar numbers pro republican pro democratic tweets labeled fair annotators uselection dataset consumers perception fairness summaries aligns traditional notions fairness representing political groups producers authored tweets metoo dataset figure case correlation group wise representation tweets posted male female users consumers perception fairness summaries difference datasets leads explore closely consumers think summary fair unfair c consumers think summary stated earlier section asked annotators indicate labeled certain summary fair unfair considered political gender groups users posted tweets specically told political contextual opinions identied annotators factor look distribution reasons stated annotators figure shows distribution reasons stated annotators batches summaries batches uselection dataset figure figure consumers judgement fairness bias dictated fair unfair representation opinions fair unfair representation political groups point note consumers annotators specically informed group label producers explicitly evident able deduce political group author textual content tweets reason determination political grouping relatively easy opinions properly expressed metoo dataset figure situation different previous section observed consumers perception fairness correlate group wise representation producers dataset figure gives explanation observation case metoo dataset annotators disproportionately higher importance fair unfair representation opinions compared reason recall annotators knowledge groups class labels gender case producers authored tweets appears dataset possible consumers inference group labels text tweets summary section section stood human annotators understand fairness bias summaries perception fairness bias maries dependent context data cases e uselections dataset perceived fairness agrees standard fairness notions demographic groups producers cases e metoo dataset perceived fairness agree fairly fairsumm summaries fairsumm summaries fairsumm metoo summaries fig fraction consumers annotators labeled summaries fair representation marked red circles unfair representation marked blue squares uselection dataset neutral tweets b neutral tweets c metoo dataset uselection dataset majority consumers perception agrees actual summaries agreement lower metoo dataset fairsumm summaries fairsumm summaries fairsumm metoo summaries fig relative proportions reasons given annotators judging summary fair unfair uselection dataset neutral tweets b neutral tweets c metoo dataset observe uselection dataset consumers labeled summary based representation political opinions groups consumers gave priority representation opinions metoo dataset opinions represented summary results indicate proper representation opinions input text central consumers idea fairness summaries check traditional metrics uation summaries capture perceived fairness summaries v rouge metrics capture consumers perception fair summary previous section established important fair representation opinions consumers perception fairness summaries section study stated introduction traditional rouge metrics popularly measure quality summaries capture summaries end follow traditional approach evaluating summaries rst obtain gold standard summaries written human annotators datasets set tweets related election set tweets related metoo movement compute rouge scores fairsumm fairsumm metoo summaries considering gold standard summaries obtaining gold standard summaries datasets uselection dataset conducted survey amazon mechanical turk amt crowdsourcing platform selected amt master workers known especially skilled performing data annotation labeling tasks required worker knowledgeable politics asked indicate political leaning democratic left leaning republican right leaning neutral selected annotators amt workers right leaning left leaning ensure balanced set gold standard summaries survey amt worker shown tweets screen asked select important tweets according opinion generating summary set tweets different workers shown tweets different randomly selected orders ensure order workers tweets affect selection lines survey conducted survey metoo dataset selected male annotators female annotators survey balanced set gold standard summaries annotators framing questions political leaning followed naire pew research center known organization conducting social surveys fair approval fractionvery unfair approval fair approval fractionvery unfair approval fair approval fractionvery unfair approval unfair representation ideasfair unfair representation groupsfair unfair representation ideas groupsother unfair representation ideasfair unfair representation groupsfair unfair representation ideas groupsother unfair representation ideasfair unfair representation groupsfair unfair representation ideas groupsother reasons shown tweets different randomly selected orders asked choose important tweets according opinion generating summary set tweets computing rouge scores consider summaries written human annotators gold standard summaries measure average score based overlap unigrams different summaries fairsumm fairsumm metoo batches note score computed mic summary individually gold standard summary written human annotator average score gold standard summaries considered accordance standard procedure evaluation summaries agreement rouge scores consumers perception fairness summaries figure shows average scores shown green triangular markers obtained different summaries fairsumm fairsumm fairsumm metoo batches fraction annotators judged sponding summaries fair unfair described section iv visually rouge scores appear low correlation consumers perception fairness summaries unfair biased summaries seen similar rouge scores fair unbiased summaries instance figure biased unfair summary taining pro republican tweets pro democratic tweets neutral tweets obtained similar rouge score fair summary containing pro republican tweets pro democratic tweets neutral tweets quantify agreement rouge scores sumers perception fairness summaries compute pearson correlation coefcient average score summary fair approval fraction fraction annotators judged summary fair pearson correlation coefcients batches summaries shown table ii rst row observe pearson correlation coefcients moderate range batches results popular rouge metrics correlate fairness summaries perceived consumers vi metric capturing consumers perception opinion bias having established popular rouge scores capture bias unfairness summaries formulate metric capture bias summaries respect representation opinions input perceived human annotators words section study mentioned introduction brief proposed bias metric based rst asking human annotators identify set distinct opinions given input text summarized checking different opinions represented particular summary describe setup detail survey described section iv set n annotators asked identify distinct opinions conveyed input set tweets consider union distinct opinions identied annotators let set distinct opinions input text denoted o assume k distinct opinions ok extension survey annotators shown set o distinct opinions summaries batches fairsumm fairsumm fairsumm metoo random order summary n annotators asked label summary adequately represents distinct opinions formally respect particular summary s evaluated ask annotator ai label opinion oj following based function gij dened follows opinion oj completely represented summary s opinion oj somewhat adequately represented summary s opinion oj inadequately represented mary s opinion oj completely absent summary s dene cumulative representation score cj obtained opinion oj summary s mean gij scores given annotators n n intuitively denotes opinion oj sented summary s judged annotators finally dene perceived opinion bias summary s gini coefcient cumulative representation score distinct opinions given summary perceived opinion bias s computed gini s motivation gini coefcient follows gini coefcient originally measure income inequality wealth inequality group people e people certain country apply gini coefcient measure inequality representation exposure set distinct opinions different opinions widely different amounts representation exposure summary s s biased opinions perceived opinion bias score s high agreement perceived opinion bias scores sumers perception unfairness investigate proposed perceived opinion bias scores agree consumers perception bias unfairness maries figure depicts perceived opinion bias scores fairsumm summaries fairsumm summaries fairsumm metoo summaries fig score values different summaries shown green triangular markers fair unfair approval fractions batches summaries general scores poor correlation fairness approval scores good indicator fairness algorithmic summary correlation score fair approval fraction perceived opinion bias scores unfair approval fraction perceived opinion bias scores opinion interaction graph scores fairsumm fairsumm fairsumm metoo table ii pearson s correlation coefcient different metrics scores measured batches summaries scores correlate strongly fairness approval fractions fraction annotators judged summary fair proposed metric perceived opinion bias score stronger correlation bias unfairness summaries judged annotators fairsumm summaries fairsumm summaries fairsumm metoo summaries fig perceived opinion bias scores shown triangle markers approval fractions batches summaries perceived opinion bias scores good agreement unfair approval fractions words summaries judged unfair high respectively low fraction annotators high respectively low perceived opinion bias scores fair unfair approval fractions section iv denition fractions batches summaries plots evident good agreement perceived opinion bias unfair approval fraction words summaries judged unfair large fraction annotators high perceived opinion bias scores contrast summaries judged fair large fraction annotators low perceived opinion bias scores quantify agreement compute pearson correlation coefcient perceived opinion bias score summary unfair approval fraction fraction annotators judged summary unfair pearson correlation coefcients batches summaries shown table ii second row batch summaries observe pearson correlation coefcients substantially higher corresponding correlation coefcients rouge scores results proposed perceived opinion bias scores reliable measures bias unfairness summaries rouge scores utility perceived opinion bias scores clear lot human annotation effort needed computing scores rst identifying distinct opinions judging representation opinion summary approach directly computing perceived opinion bias scores scalable large datasets section attempt develop automated methodology computing bias unfairness summaries vii automated approach quantify rouge scores supposed higher good summaries measure correlation fair approval fraction contrast perceived opinion bias scores supposed higher biased unfair summaries measure correlation unfair approval fraction fair approval fractionvery unfair approval score fair approval fractionvery unfair approval score fair approval fractionvery unfair approval score fair approval fractionvery unfair approval fractionperceived opinion fair approval fractionvery unfair approval fractionperceived opinion fair approval fractionvery unfair approval fractionperceived opinion bias consumers perceived bias summaries section present automated method compute bias unfairness summaries proposed method spired represents input text document undirected weighted network graph called opinion interaction graph oig describe steps algorithm detail algorithm step generation key graph given input text rst extract named entities keywords textrank algorithm construct keyword co occurrence graph called keygraph based set extracted keywords keyword vertex keygraph connect keywords edge co occur sentence edge keywords weighted frequency co occurrences said keywords step concept detection structure keygraph reveals connections keywords subset keywords highly correlated form densely connected subgraph keygraph opinion opinions extracted applying community detection algorithms keygraph community detection rithm split keygraph set communities o community oi contains keywords related certain opinion end use popular louvain community detection algorithm clustering keygraph xed sized communities clustering methods step step sentence attachment edge construction opinions discovered step associate sentences opinions calculate cosine similarity sentence opinion sentences opinions represented tf idf vectors words assign sentence opinion oi similar said sentence similarity computed based fraction keywords associated opinion contained said sentence sentences match opinion document attached dummy vertex contain keywords construct opinion interaction graph oig vertex node opinion construct edges reveal similarity different opinions vertex represent associated set sentences concatenation sentences attached edge weight vertices computed tf idf similarity associated sentence sets step computing exposure opinion summary constructed oig node opinion associated set sentences idea similar followed topic modeling topic essentially set frequently co occurring terms quantify representation exposure different opinions given summary s evaluated simply compute exposure opinion fraction sentences attached said opinion present summary s step quantifying skew distribution sure finally compute gini coefcient exposure received distinct opinions computed quantify bias distribution exposure different opinions summary s intuition gini coefcient discussed section vi noted intuitively adhere tional representation notion fairness explained section ii b exposures obtained different opinions words summary considered fair distribution exposure received opinions resembles distribution sentences attached opinions b results based opinion interaction graph figure shows bias summaries batches computed proposed opinion interaction graph algorithm perceived opinion bias scores summaries obtained previous section evident high correlation metrics table ii row shows pearson correlation perceived opinion bias scores bias scores computed oig based method batches summaries correlation scores results proposed graph based algorithm good proxy automatic calculation perceived opinion bias summaries viii conclusion knowledge work rst attempt explore fairness context automatic summarization perspective consumers readers summary notion fairness summaries consumers perspective varies context e correspond fair representation demographic groups producers writers fair representation opinions input text popular rouge metrics evaluation summaries usually capture fairness summaries bridge gap proposed alternative metric measuring bias summaries based human annotation automatic methodology approximate metric believe work potential applications areas text summarized consists tiple different perspectives opinions news article summarization debate summarization plan complex models applied compute exposure opinions exposure oj thought diffuse similar opinion oj similarity opinions quantied edge weight oig avoided complexities order model simple fairsumm summaries fairsumm summaries fairsumm metoo summaries fig opinion interaction graph scores computed automatically perceived opinion bias scores computed based human annotation batches summaries scores high agreement establishing methodology based opinion interaction graph automatically measure perceived opinion bias summaries b t luong s ruggieri f turini k nn implementation situation testing discrimination discovery prevention proc acm sigkdd conference knowledge discovery data mining pp k darwish w magdy t zanouda trump vs hillary went viral presidential election international conference social informatics springer pp b liu d niu h wei j lin y k lai y xu matching article pairs graphical decomposition convolutions proc conference association computational linguistics acl pp v d blondel j guillaume r lambiotte e lefebvre fast unfolding communities large networks journal statistical mechanics theory experiment vol p explore applications future plan develop metrics simultaneously capture quality fairness summaries e suitably combining rouge metrics bias metric proposed work acknowledgments authors like thank annotators judged summaries work research supported european research council erc advanced grant project foundations fair social computing funded eu horizon framework programme grant agreement dash supported fellowship tata consultancy services references m allahyari s pouriyeh m asse s safaei e d j b gutierrez k kochut text summarization available trippe techniques brief survey corr org w el kassas c salama rafea h mohamed automatic text summarization comprehensive survey expert systems applications p dash shandilya biswas k ghosh s ghosh chakraborty summarizing user generated textual content tion methods fairness algorithmic summaries proceedings acm human computer interaction vol cscw pp r mukherjee h c peruri u vishnu p goyal s bhattacharya n ganguly read need controllable aspect based opinion summarization tourist reviews proc acm sigir conference p shandilya k ghosh s ghosh fairness extractive text summarization companion proceedings web conference pp c lin rouge package automatic evaluation summaries text summarization branches pp k ganesan rouge updated improved measures uation summarization tasks corr vol j ali m babaei chakraborty b mirzasoleiman k p gummadi singla fairness time critical inuence maximization social networks arxiv preprint s friedler c scheidegger s venkatasubramanian s choudhary e p hamilton d roth comparative study fairness enhancing interventions machine learning proc acm fat g k patro biswas n ganguly k p gummadi chakraborty fairrec sided fairness personalized ommendations sided platforms proceedings web conference pp j rawls theory justice harvard university press opinion biasopinion interaction graph opinion biasopinion interaction graph opinion biasopinion interaction graph bias
