fairness for whom understanding the reader s perception of fairness in text summarization anurag shandilya abhisek dash indian institute of technology kharagpur india abhijnan chakraborty max planck institute for software systems germany kripabandhu ghosh indian institute of science education and research kolkata india saptarshi ghosh indian institute of technology kharagpur india e f r i s c v v i x r a abstract with the surge in user generated textual tion there has been a recent increase in the use of rization algorithms for providing an overview of the extensive content traditional metrics for evaluation of these algorithms e rouge scores rely on matching algorithmic summaries to human generated ones however it has been shown that when the textual contents are heterogeneous e when they come from different socially salient groups most existing rization algorithms represent the social groups very differently compared to their distribution in the original data to mitigate such adverse impacts some fairness preserving summarization algorithms have also been proposed all of these studies have considered normative notions of fairness from the perspective of writers of the contents neglecting the readers perceptions of the underlying fairness notions to bridge this gap in this work we study the interplay between the fairness notions and how readers perceive them in textual summaries through our experiments we show that reader s perception of fairness is often context sensitive moreover standard rouge evaluation metrics are unable to quantify the perceived of the summaries to this end we propose a human in the loop metric and an automated graph based methodology to quantify the perceived bias in textual summaries we demonstrate their utility by quantifying the of several summaries of heterogeneous socio political microblog datasets i introduction with the surge in the amount of textual information on the web text summarization algorithms are increasingly being used to get a quick overview of the information the standard framework for text summarization can be broadly divided into two parts summary generation and summary evaluation as shown in figure in summary generation given a document or sometimes a set of documents a marization algorithm summarizes it generally two kinds of summarization approaches are followed in the literature i extractive summarization where the algorithms select sentences from the document to include in the summary and ii abstractive summarization where the algorithms produce natural language summaries traditional summarization algorithms are meant for rizing homogeneous documents e news on a topic work has been accepted at international workshop on fair and interpretable learning algorithms fila which was held in conjunction with ieee bigdata please cite the version appearing in the proceedings fig a generic block diagram explaining summarization pipeline machine generated summaries are evaluated based on how well they match human written reference summaries metrics such as rouge scores quantify the goodness of such automated summaries or research and they have only focused on worthiness of textual units while deciding on whether to include or exclude them in the summary however with the growing popularity of social media websites facebook twitter user generated content constitutes a large chunk of the textual information generated on the web today on social media different user groups discuss different socio political issues and it has been observed that they often have very ferent opinions on the same topic or event hence the textual information to be summarised has gradually become heterogeneous in our prior work we have shown that such text often contains very different opinions from people of different ideologies social groups in many downstream applications algorithm generated summaries are consumed by people and hence they often play a vital role in shaping their opinion in different socio political issues hence along with summary quality the fairness aspect of algorithmic summaries that are produced by automatic summarization algorithms have also become essential lately this has led to different fair summarization algorithms for heterogeneous user generated textual units evaluation of algorithmic summaries traditionally the evaluation of algorithmic summaries are carried out by uating how closely they match human generated summaries the same source document or set of documents is given to a number of human annotators to summarize metrics like documentrougescoressummarization algorithmsummaryhuman annotatorsgold standard summariesevaluationsummarygenerationsummaryevaluation rouge are used to quantify the goodness of the algorithmic summaries even though these measures perform very well in evaluating the goodness of summaries based on textual quality and readability they do not explicitly quantify the of an algorithmic summary moreover this process of evaluation is often laborious and hence an expensive task evaluation in multi document marization is particularly expensive it is reported that hours of human effort is required to evaluate the summaries from the document understanding conferences duc drawbacks in the existing framework the existing fair summarization algorithms have mostly tried to incorporate normative representational fairness goals from the tive of the content producers writers in the nal summary however whether the summaries are perceived to be fair by the consumers readers is still up for debate additionally the different existing approaches of evaluating summaries the most popular being computation of rouge scores have several limitations when it comes to quantication of fairness aspect of the summaries of heterogenous user generated text corpora current work in this work we posit that in the context of summarization fairness is highly context dependent and ideally involves multiple stakeholders the most important stakeholders in a summarization set up are producers or writers of the textual units and consumers or readers of the nal summary however the interpretation of fairness may vary when we envisage it from the reader s perspective to this end in this work we investigate the interplay between the earlier proposed denitions of fairness in summarization and the consumers perceptions of fairness and how this interplay varies with the context of the underlying topic further we also investigate the effectiveness of existing measures e rouge in quantifying the of a summary specically we seek for the answer to the following research questions rqs is the readers perception of in summaries context dependent do traditional metrics for summary quality such as rouge scores capture readers perception of fairness of summaries and nally can a metric based on representation of opinions better capture readers perception of in summaries to answer the aforementioned rqs we conducted a series of surveys on two socio political datasets obtained from of microblogs tweets related to i the us dential elections and the metoo movement through the different analyses the main contributions observations of the present work can be summarised as follows we show that readers can differentiate between fair and unfair summaries however the reasons why a summary is perceived to be is context dependent in some cases the perceived fairness agrees with standard resentational fairness notions for demographic groups of producers while in other cases the perceived fairness use the word pairs producers and writers as well as consumers and readers interchangeably throughout this paper seems to agree more with how fairly various opinions are represented in the summary in either case standard rouge metrics can not capture the bias in summaries as perceived by the consumers we propose a metric for perceived bias in a summary based on manual identication of opinions in the input text and then judging how well various opinions are represented in the summary finally we propose a graph based methodology for matically measuring the bias in a summary we observe that correlates well with the perceived opinion bias metric stated above ii background and related work in this section we discuss a few relevant prior works on fairness in text summarization and motivate the present work by contextualizing it in the existing literature a fairness in text summarization the dataset much like in the fairness in ml literature the proposed methodologies for fair text summarization can be divided into three categories e pre processing processing post processing based algorithms based on the stage at which fairness intervention is performed in the pre processing based algorithms is fed to the summarization algorithms in a way such that the generated summaries will end up being fair similarly in post processing algorithm fairness interventions are applied on the output of standard summarization algorithms to generate fair summaries finally in the in processing based approach the rithm designers often treat summarization as an optimization problem and solve the same by either modifying the tion function or adding fairness constraints to generate fair summaries next we briey discuss the fairsumm algorithm that was proposed in fairsumm algorithm for fair summarization our prior work developed an in processing fair summarization gorithm called fairsumm fairsumm treats the rization task as a sub modular optimization problem with fairness constraints and solves it to maximize coverage and diversity across the textual units while adhering to standard fairness notions given a heterogeneous set of blogs coming from different socially salient groups and a desired target representation of the groups the algorithm produces extractive summaries that reconcile between textual quality of the summaries as quantied by rouge scores and fair representation of different social salient groups in the summary for instance fairsumm can be applied over a set of tweets posted by male and female authors to obtain a good summary having equal fractions of tweets posted by male authors and tweets posted by female authors we shall be using fairsumm algorithm extensively for the experiments throughout this paper b notions of fairness in text summarization most of the prior works on fair summarization deal with the idea of group fairness specically when the input data e tweets or reviews are generated by users from different socially salient groups the algorithms explicitly enforce the summaries to fairly represent these different groups equal representation the notion of equality nds its roots in the eld of morality and justice which advocates for the redress of undeserved inequalities e inequalities of birth or due to natural in the context of tion this ensures that the nal summary must include equal number of textual units coming from different socially salient groups proportional representation often it may not be possible to equally represent different user groups in the summary especially if the input data contains very different proportions from different groups hence we consider another notion of fairness proportional representation also known as cal parity in the context of summarization proportional representation requires that the proportion of content from different user groups in the summary should be same as in the original input these notions of fairness ensure that the probability of ing an item is independent of which user group generated it c drawbacks in the current literature the process of summarizing involves two parties namely producers of the information a a writers and consumers of summarized information a a readers all of the prior works on fairness in summarization have attempted to ensure the fair representation of the producers whereas the fairness toward consumers or readers has been completely ignored the inclusion or exclusion of certain opinions voices tend to have the maximum effect on the consumers of the summaries as the summary is what the summary shapes their opinion on the topic hence bias in the nal summary can have severe impact on shaping the public discourse hence in this work we focus on exploring the interplay of existing fairness denitions and how they are perceived by the readers is read by the consumers limitations of existing measures in quantication of in summaries for evaluation of generated summaries all of the prior works have evaluated the generated summaries based on rouge metric however in this work we observe that rouge metric is unable to capture the aspect of the generated summaries to this end in this work we also propose a metric for perceived fairness of textual summaries further we also propose an automated quantication of the perceived bias of textual maries that correlates signicantly with the aforementioned perceived fairness to the best of our knowledge this is the rst work towards quantication of in summaries and understanding the interplay between the perceived fairness in text tion from the perspective of both writers and readers of the textual content iii datasets we reuse the following two datasets from our prior work us election dataset this dataset originally provided by darwish et al contains english tweets posted during the us presidential election each tweet is annotated as supporting or attacking one of the presidential candidates donald trump and hillary clinton or neutral or attacking both for simplicity we grouped the tweets into three classes i pro republican tweets which support trump and or attack clinton pro democratic tweets which support clinton and or attack trump and neutral tweets which are neutral or attack both candidates metoo dataset we collected a set of tweets related to the metoo movement in october specically we collected english tweets containing the hashtag metoo using the twitter search api we asked three human annotators to examine the name and bio of the twitter accounts who posted the tweets the annotators observed three classes of tweets based on who posted the tweets i tweets posted by male users ii tweets posted by female users and iii tweets posted by organizations mainly news media agencies also there were many tweets for which the annotators could not understand the type gender of the user posting the tweet for purpose of this study we decided to focus only on those tweets for which all the annotators were certain that they were written by male users or female users from each of these two datasets we selected a set of tweets having an equal representation of the different graphic groups in other words we selected tweets from the uselection dataset containing pro democratic tweets pro republican tweets and neutral tweets similarly we selected tweets from the metoo dataset containing tweets posted by male users and tweets posted by female users while selecting these two sets of tweets we ensured choosing distinct tweets for which we removed near duplicates that were well formed and informative all experiments in this paper are conducted over these two sets of tweets each in the rest of this paper we conduct a number of surveys and experiments on the aforementioned datasets in pursuit of answers to the rqs mentioned in the introduction iv understanding consumers perception of fairness in summaries in this section we investigate the stated in the introduction whether readers perception of in summaries is context dependent to this end we rst generate summaries having different levels of biases and then conduct a survey to understand how consumers human annotators perceive the bias fairness of these summaries a generating differently biased summaries we consider a set of tweets from the us elections dataset pro democratic tweets pro republican tweets and neutral tweets which are not repetitive in nature we apply the fairsumm algorithm on this set of tweets to generate summaries of length tweets having a wide variety of bias from completely biased towards pro republican ideology to completely biased towards pro democratic ideology to this end we x a certain number of neutral tweets and then vary the number of pro republican and pro democratic tweets to create variously biased summaries specically we create two batches of summaries one batch with neutral tweets each and the other batch with neutral tweets each the rst batch of summaries with neutral tweets each which we term as fairsumm us contains the lowing summaries each of length tweets pro rep tweets pro dem tweets neutral tweets actually very unfair summary pro rep tweets pro dem tweets neutral tweets actually very unfair summary pro rep tweets pro dem tweets neutral tweets pro rep tweets pro dem tweets neutral tweets actually very fair summary pro rep tweets pro dem tweets neutral tweets pro rep tweets pro dem tweets neutral tweets actually very unfair summary pro rep tweets pro dem tweets neutral tweets actually very unfair summary the second batch of summaries with neutral tweets each which we term as fairsumm us contains the following summaries each of length tweets pro rep tweets pro dem tweets neutral tweets actually very unfair summary pro rep tweets pro dem tweets neutral tweets actually very unfair summary pro rep tweets pro dem tweets neutral tweets pro rep tweets pro dem tweets neutral tweets actually very fair summary actually very fair summary pro rep tweets pro dem tweets neutral tweets actually very unfair summary pro rep tweets pro dem tweets neutral tweets actually very unfair summary similarly we consider a set of tweets from the metoo dataset containing tweets posted by male users and tweets posted by female users as stated in section iii we then apply fairsumm to generate the following summaries of length tweets each having a wide variation of bias from completely biased towards tweets posted by male users to completely biased towards tweets posted by female users we call this batch of summaries fairsumm metoo which contains the following summaries each of length tweets male tweets female tweets actually very unfair summary male tweets female tweets actually very unfair male tweets female tweets male tweets female tweets male tweets female tweets actually very fair male tweets female tweets male tweets female tweets actually very unfair male tweets female tweets actually very unfair summary summary summary summary it can be noted that for all these summaries generated using the fairsumm algorithm the actual biases are known in terms of the number of tweets included in a summary from the ent perspectives we will next check how the bias fairness of these summaries is viewed by consumers human annotators b understanding consumers perception of we start with a group of six annotators males and females who have substantial knowledge of us politics and the metoo phenomenon and are in the age group of years we used a questionnaire to ascertain their knowledge of us politics and the metoo movement also the annotators are familiar with use of social media platforms including twitter and none of the annotators is an author of this paper the annotators were rst asked to go over the two sets of tweets each one on uselection and the other on metoo and to note down every distinct opinion expressed in the tweets an opinion is dened as a unique idea information being conveyed by a tweet hitherto not covered by any other previous tweet note that the annotators were only shown the text of the tweets they were not told anything about the gender political ideology of the users who authored the tweets there was no limit to how many opinions they may identify however each opinion was required to be conned to a maximum of two sentences table i tabulates the opinions identied by two of the six annotators from the set of tweets related to the us elections thereafter the annotators are shown the summaries from the fairsumm us fairsumm us and metoo batches in random order they were asked to judge the fairness of each summary and label each summary with one of the following labels very fair representation somewhat fair representation somewhat unfair representation very unfair representation along with labeling each summary they were also asked to provide a reasoning for their judgement in other words they were asked to indicate the based on which they were judging a summary to be fair unfair fair unfair representation of political gender groups fair unfair representation of political contextual opinions fair unfair representation of both political gender groups and political contextual opinions hillary has derogatory titles for anyone not voting for her hillary trump is facing rape charges will deter trump and he will not stop ghting for you clinton has admitted that obamacare is bad and hillary is pissed about it trump claims credit for terrorist acts just like terrorists is only one that can make college affordable says he has come on top in the presidential debate out of people feel that hillary is winning claims that sources that report negatively about his campaign are not to be trusted know the net worth of hillary cause she has disclosed her assets thinks she has a solid strategy to defeat isis while trump has none trump supporters want him to win so that they can abuse women they want is getting ready for a battle to reclaim mosul hillary shames everyone and thinks anyone not voting for her is stupid thinks hillary is crooked refuses to accept that the current potus was born in america is bad and hillary is not happy with what bill clinton said about it does nt have the drive to make america great again who are cancelling subscriptions to dallas and arizona newspapers are smart people who do nt wanna vote they need to be told that only hillary can get rid of their huge college debt thinks hilary has been ghting isis without success for years and now it s time for a change thinks hillary has told lies throughout her life and has sold america s interests way hillary is handling the e mail case she is unt for the post of president is a proponent of more love and kindness in america has a solid strategy to defeat isis unlike trump guys want trump to win so that they can oppress women should be thankful to every nation that helped bring paris agreement into action of unarmed black men is unacceptable women in this country deserves to be free from harm and fear should release police video of the keith lamont scott shooting without delay table i set of distinct opinions separated by identied by two of the annotators from the set of tweets related to us elections any other reason requires a subjective response now we examine how the consumer s perception of fairness varies across different contexts scenarios to this end we plot the fraction of annotators who have annotated a summary as either very fair representation of the input text or as very unfair representation of the input text these two fractions are termed as very fair approval fraction and very unfair approval fraction respectively figure depicts the result for the uselection dataset gures a and for fairsumm us and us summaries respectively and for the metoo dataset c for the fairsumm metoo summaries recall that a batch is a group of summaries having the same number of neutral tweets but varying number of tweets from other perspectives from the results it is evident that for the us election dataset the fraction of annotators who said that a summary was very fair and the fraction of annotators who said that a summary was very unfair correlates well with the actual fairness in the fairsumm summaries for instance both summaries having much larger number of pro republican tweets and summaries having much larger number of democratic tweets were labeled as very unfair by most annotators whereas the summaries having relatively similar numbers of pro republican and pro democratic tweets were labeled as very fair by most annotators thus for the uselection dataset the consumers perception of fairness in the summaries aligns very well with traditional notions of fairness in representing political groups among the producers those who authored the tweets however for the metoo dataset see figure this is not the case there is no correlation between group wise representation of tweets posted by male and female users and the consumers perception of fairness of the summaries this difference for the two datasets leads us to explore more closely why consumers think of a summary as being fair unfair c why do consumers think of a summary as being as stated earlier in this section we also asked the annotators to indicate why they labeled a certain summary as fair unfair whether they considered the political gender groups of the users who posted the tweets which were not specically told to them or the political contextual opinions which were identied by the annotators themselves or both or some other factor we now look at the distribution of the reasons as stated by the annotators for figure shows the distribution of reasons as stated by the annotators the three batches of summaries for both batches of the uselection dataset see figure and figure the consumers judgement of fairness bias is dictated by both the fair unfair representation of opinions and the fair unfair representation of political groups one point to note here is that the consumers annotators were not specically informed of the group label of the various producers explicitly however it is quite evident that they are able to deduce the political group of the author from the textual content of the tweets one reason for this would be that determination of political grouping is relatively easy if the opinions are properly expressed however for the metoo dataset see figure the situation is different in the previous section it was observed that the consumers perception of fairness does not correlate well with group wise representation of the producers for this dataset figure gives us an explanation for this observation in the case of the metoo dataset the annotators give a disproportionately higher importance to fair unfair representation of opinions as compared to any other reason recall once again the annotators have no knowledge of the groups class labels gender in this case of the producers those who authored the tweets thus it appears that for this dataset it was not possible for the consumers to make any inference about group labels from the text of the tweets summary of the section from this section we have stood that human annotators can understand the fairness bias of summaries and their perception of fairness bias in maries is dependent on the context of the data in some cases e for the uselections dataset the perceived fairness agrees with standard fairness notions on demographic groups of producers while in other cases e for the metoo dataset the perceived fairness seems to agree more with how fairly fairsumm us summaries fairsumm us summaries fairsumm metoo summaries fig the fraction of consumers annotators who labeled various summaries as very fair representation marked by the red circles and very unfair representation marked by the blue squares for uselection dataset with a neutral tweets b neutral tweets and c for the metoo dataset for the uselection dataset the majority of consumers perception of agrees with the actual of the summaries however the agreement is much lower for the metoo dataset fairsumm us summaries fairsumm us summaries fairsumm metoo summaries fig the relative proportions of the various reasons given by annotators for judging a summary as fair unfair for uselection dataset with a neutral tweets b neutral tweets and c for the metoo dataset we observe that for the uselection dataset most consumers labeled a summary to be based on the representation of both political opinions and groups whereas the consumers gave priority to representation of opinions in the metoo dataset various opinions are represented in the summary these results also indicate that proper representation of opinions in the input text is central to the consumers idea of fairness in the summaries next we check whether traditional metrics used for uation of summaries can capture the perceived fairness of summaries v can rouge metrics capture consumers perception of fair summary in the previous section we have established the important of fair representation of opinions in the consumers perception of fairness in summaries in this section we study the stated in the introduction whether the traditional rouge metrics that are popularly used to measure quality of summaries can capture the of summaries to this end we follow the traditional approach of evaluating summaries we rst obtain gold standard summaries written by human annotators for the two datasets the set of tweets related to us election and the set of tweets related to metoo movement then we compute rouge scores for the fairsumm us fairsumm us and metoo summaries considering the gold standard summaries obtaining gold standard summaries for the datasets for the uselection dataset we conducted a survey on the amazon mechanical turk amt crowdsourcing platform we selected amt master workers who are known to be especially skilled in performing data annotation and labeling tasks we required that every worker be from the us and be knowledgeable about us politics we asked them to indicate their political leaning democratic or left leaning republican or right leaning or neutral we selected annotators amt workers who are right leaning and who were left leaning to ensure that we get a balanced set of gold standard summaries during the survey each amt worker was shown the tweets on a screen and then asked to select the most important tweets according to his her opinion for generating a summary of the whole set of tweets different workers were shown the tweets in different randomly selected orders to ensure that the order in which the workers see the tweets do not affect their selection along the lines of the above survey we conducted a survey for the metoo dataset as well we selected male annotators and female annotators for this survey so that we get a balanced set of gold standard summaries these annotators framing the questions on political leaning we followed a naire of the pew research center which is a well known organization for conducting social surveys fair approval fractionvery unfair approval fair approval fractionvery unfair approval fair approval fractionvery unfair approval unfair representation of ideasfair unfair representation of groupsfair unfair representation of both ideas and groupsother unfair representation of ideasfair unfair representation of groupsfair unfair representation of both ideas and groupsother unfair representation of ideasfair unfair representation of groupsfair unfair representation of both ideas and groupsother reasons were shown the tweets in different randomly selected orders and were asked to choose the most important tweets according to her his opinion for generating a summary of the whole set of tweets computing rouge scores we consider the summaries written by the human annotators as gold standard summaries and measure the average score based on overlap of unigrams of all the different summaries in the fairsumm us fairsumm us and metoo batches note that score is computed for an mic summary individually with every gold standard summary written by a human annotator and then the average score across all gold standard summaries is considered this is in accordance with the standard procedure for evaluation of summaries agreement of rouge scores with consumers perception fairness in summaries figure shows the average of scores shown by green triangular markers obtained by the different summaries in the fairsumm fairsumm us and fairsumm metoo batches along with the fraction of annotators who judged the sponding summaries to be very fair unfair as was described in section iv visually the rouge scores appear to have low correlation with the consumers perception of fairness of the summaries very unfair biased summaries are seen to get similar rouge scores as very fair unbiased summaries for instance in figure a very biased unfair summary taining pro republican tweets pro democratic tweets and neutral tweets obtained a very similar rouge score as a very fair summary containing pro republican tweets pro democratic tweets and neutral tweets to quantify the agreement of rouge scores with sumers perception of fairness in summaries we compute the pearson correlation coefcient between the average score of a summary and the very fair approval fraction the fraction of annotators who judged the summary to be very fair the pearson correlation coefcients for the three batches of summaries are shown in table ii rst row we observe the pearson correlation coefcients to be moderate in the range for all three batches these results show that the popular rouge metrics do not correlate well with the fairness of summaries as perceived by the consumers vi metric for capturing consumers perception of opinion bias having established that the popular rouge scores can not capture the bias unfairness in summaries we now formulate a metric that can capture the bias of summaries with respect to representation of various opinions in the input as perceived by human annotators in other words in this section we study as mentioned in the introduction in brief our proposed bias metric is based on rst asking human annotators to identify the set of distinct opinions in the given input text which is to be summarized and then checking how well the different opinions are represented in a particular summary we describe the setup below in detail we go back to the survey described in section iv where a set of n annotators say an were asked to identify all the distinct opinions being conveyed by an input set of tweets we consider the union of all distinct opinions identied by all the annotators let the set of all distinct opinions in the input text be denoted by o and assume that there are k distinct opinions ok in an extension of that survey the annotators were shown the set o of all distinct opinions and all the summaries from the batches fairsumm us fairsumm us and fairsumm metoo in random order for each summary all the n annotators were asked to label whether the summary adequately represents each of the distinct opinions more formally with respect to a particular summary s that is to be evaluated we ask each annotator ai to label each opinion oj as one of the following based on which the function gij is dened as follows the opinion oj is completely represented in the summary s the opinion oj is somewhat adequately represented in the summary s the opinion oj is inadequately represented in the mary s the opinion oj is completely absent in the summary s we dene the cumulative representation score cj obtained by the opinion oj in summary s as the mean of all the gij scores given by all the annotators n n intuitively denotes how well the opinion oj is sented in the summary s as judged by all the annotators finally we dene the perceived opinion bias of summary s as the gini coefcient of the cumulative representation score of all the distinct opinions so for a given summary the perceived opinion bias of s is computed as gini s the motivation for using the gini coefcient is as follows the gini coefcient has been originally used to measure the income inequality or wealth inequality within a group of people e the people in a certain country here we apply the gini coefcient to measure the inequality of representation exposure within the set of distinct opinions if different opinions get widely different amounts of representation exposure in a summary s then s is biased towards some of the opinions and hence the perceived opinion bias score of s will be high agreement of perceived opinion bias scores with sumers perception of unfairness now we investigate whether our proposed perceived opinion bias scores agree with the consumers perception of bias unfairness of maries figure depicts the perceived opinion bias scores fairsumm us summaries fairsumm us summaries fairsumm metoo summaries fig score values for the different summaries shown by green triangular markers along with the very fair unfair approval fractions for the three batches of summaries in general scores have poor correlation with the fairness approval scores and hence are not a good indicator of fairness of an algorithmic summary correlation between score very fair approval fraction perceived opinion bias scores very unfair approval fraction perceived opinion bias scores opinion interaction graph scores fairsumm us fairsumm us fairsumm metoo table ii pearson s correlation coefcient between different metrics scores as measured for the three batches of summaries while the scores do not correlate strongly with the fairness approval fractions fraction of annotators who judged a summary to be fair the proposed metric perceived opinion bias score has a much stronger correlation with the bias unfairness of summaries as judged by the annotators fairsumm us summaries fairsumm us summaries fairsumm metoo summaries fig perceived opinion bias scores shown by the triangle markers along with the approval fractions for the three batches of summaries the perceived opinion bias scores have good agreement with the very unfair approval fractions in other words the summaries that are judged to be unfair by a high respectively low fraction of annotators have high respectively low perceived opinion bias scores and the very fair unfair approval fractions see section iv for the denition of these fractions for the three batches of summaries from the plots it is evident that there is a good agreement between the perceived opinion bias and the very unfair approval fraction in other words those summaries that are judged to be very unfair by a large fraction of annotators get high perceived opinion bias scores in contrast those summaries that are judged to be very fair by a large fraction of annotators get low perceived opinion bias scores to quantify the agreement we also compute the pearson correlation coefcient between the perceived opinion bias score of a summary and the very unfair approval fraction the fraction of annotators who judged the summary to be very unfair the pearson correlation coefcients for the three batches of summaries are shown in table ii second row for every batch of summaries we observe the pearson correlation coefcients to be substantially higher than the corresponding correlation coefcients for the rouge scores these results show that the proposed perceived opinion bias scores can be used as more reliable measures of bias unfairness in summaries than the rouge scores while the utility of the perceived opinion bias scores is clear a lot of human annotation effort is needed in computing these scores rst identifying the distinct opinions and then judging the representation of each opinion in the summary hence the approach of directly computing perceived opinion bias scores may not be scalable to really large datasets in the next section we attempt to develop an automated methodology for computing the bias unfairness of summaries vii an automated approach to quantify that rouge scores are supposed to be higher for good summaries hence we measure correlation with very fair approval fraction in contrast the perceived opinion bias scores are supposed to be higher for biased unfair summaries hence we measure correlation with very unfair approval fraction fair approval fractionvery unfair approval score fair approval fractionvery unfair approval score fair approval fractionvery unfair approval score fair approval fractionvery unfair approval fractionperceived opinion fair approval fractionvery unfair approval fractionperceived opinion fair approval fractionvery unfair approval fractionperceived opinion bias consumers perceived bias in summaries in this section we present an automated method to compute the bias unfairness of summaries our proposed method spired by represents the input text a document as an undirected and weighted network graph called the opinion interaction graph oig we now describe the various steps of the algorithm in detail a the algorithm step generation of key graph given the input text we rst extract the named entities and keywords by the textrank algorithm then we construct a keyword co occurrence graph called keygraph based on the set of extracted keywords each keyword is a vertex in the keygraph we connect two keywords by an edge if they co occur in the same sentence the edge between two keywords is weighted by frequency of co occurrences of the two said keywords step concept detection the structure of keygraph reveals the connections between keywords if a subset of keywords are highly correlated they will form a densely connected subgraph in keygraph which we call an opinion opinions can be extracted by applying community detection algorithms on the keygraph a community detection rithm is used to split a keygraph into a set of communities o where each community oi contains the keywords related to a certain opinion to this end we use the popular louvain community detection algorithm for clustering the keygraph into xed sized communities however other clustering methods can also be used in this step step sentence attachment and edge construction after the opinions are discovered the next step is to associate sentences to opinions we calculate the cosine similarity between each sentence and each opinion where sentences and opinions are represented by tf idf vectors of the words we assign each sentence to that opinion oi which is the most similar to the said sentence where the similarity is computed based on what fraction of the keywords associated with an opinion is contained in the said sentence the sentences that do not match any opinion in the document will be attached to a dummy vertex that does not contain any keywords then we construct the opinion interaction graph oig where each vertex node is an opinion to construct edges that reveal the similarity between different opinions for each vertex we represent its associated set of sentences as a concatenation of the sentences attached to it the edge weight between two vertices is computed as the tf idf similarity between their associated sentence sets step computing exposure of an opinion in a summary as of now we have constructed the oig where every node is an opinion and is associated with a set of sentences next the idea is similar to what is followed in topic modeling where each topic is essentially a set of frequently co occurring terms we quantify the representation exposure of different opinions in a given summary s which is to be evaluated we simply compute the exposure of an opinion as the fraction of the sentences attached to the said opinion that is present in the summary s step quantifying the skew in the distribution of sure finally we compute the gini coefcient of the exposure received by all the distinct opinions as computed above to quantify the bias in the distribution of exposure of different opinions in the summary s the intuition behind using the gini coefcient has been discussed in section vi it can be noted that intuitively we adhere to the tional representation notion of fairness that was explained in section ii b among the exposures obtained by different opinions in other words a summary would be considered most fair if the distribution of exposure received by the various opinions resembles the distribution of sentences attached to the opinions b results based on opinion interaction graph figure shows the bias of the various summaries in the three batches as computed by our proposed opinion interaction graph algorithm and the perceived opinion bias scores of the summaries as obtained in the previous section it is evident that there is a very high correlation between the metrics also table ii last row shows the pearson correlation for the perceived opinion bias scores and the bias scores computed by the oig based method for all three batches of summaries the correlation scores are above these results show that our proposed graph based algorithm is a good proxy for automatic calculation of perceived opinion bias of summaries viii conclusion to our knowledge this work is the rst attempt to explore fairness in the context of automatic summarization from the perspective of consumers readers of the summary we show that the notion of fairness in summaries from the consumers perspective varies from one context to another e may correspond to fair representation of demographic groups of the producers writers or the fair representation of opinions from the input text also the popular rouge metrics for evaluation of summaries usually can not capture the fairness of summaries to bridge this gap we have proposed an alternative metric for measuring the bias in summaries based on human annotation as well as an automatic methodology to approximate the metric we believe that this work has several potential applications in areas where the text to be summarized consists of tiple different perspectives or opinions in news article summarization debate summarization and so on we plan to that more complex models can be applied to compute the exposure of opinions a part of the exposure of oj can be thought to diffuse to another very similar opinion oj where the similarity between the two opinions is quantied by the edge weight in the oig however we have avoided such complexities in order to keep our model simple fairsumm us summaries fairsumm us summaries fairsumm metoo summaries fig opinion interaction graph scores computed automatically along with perceived opinion bias scores computed based on human annotation for the three batches of summaries the two scores have very high agreement thus establishing that our methodology based on opinion interaction graph can be used to automatically measure the perceived opinion bias of summaries b t luong s ruggieri and f turini k nn as an implementation of situation testing for discrimination discovery and prevention in proc acm sigkdd conference on knowledge discovery and data mining pp k darwish w magdy and t zanouda trump vs hillary what went viral during the us presidential election in international conference on social informatics springer pp b liu d niu h wei j lin y he k lai and y xu matching article pairs with graphical decomposition and convolutions in proc conference of the association for computational linguistics acl pp v d blondel j guillaume r lambiotte and e lefebvre fast unfolding of communities in large networks journal of statistical mechanics theory and experiment vol no p explore such applications in future also we plan to develop metrics that can simultaneously capture both the quality and the fairness of summaries e by suitably combining the rouge metrics with the bias metric proposed in this work acknowledgments the authors would like to thank the annotators who judged the summaries as part of the work this research was supported in part by a european research council erc advanced grant for the project foundations for fair social computing funded under the eu horizon framework programme grant agreement no a dash was supported by a fellowship from tata consultancy services references m allahyari s a pouriyeh m asse s safaei e d j b gutierrez and k kochut text summarization available trippe techniques a brief survey corr org w el kassas c salama a rafea and h mohamed automatic text summarization a comprehensive survey expert systems with applications p a dash a shandilya a biswas k ghosh s ghosh and a chakraborty summarizing user generated textual content tion and methods for fairness in algorithmic summaries proceedings of the acm on human computer interaction vol no cscw pp r mukherjee h c peruri u vishnu p goyal s bhattacharya and n ganguly read what you need controllable aspect based opinion summarization of tourist reviews in proc acm sigir conference p a shandilya k ghosh and s ghosh fairness of extractive text summarization in companion proceedings of the the web conference pp c lin rouge a package for automatic evaluation of summaries in text summarization branches out pp k ganesan rouge updated and improved measures for uation of summarization tasks corr vol j ali m babaei a chakraborty b mirzasoleiman k p gummadi and a singla on the fairness of time critical inuence maximization in social networks arxiv preprint s a friedler c scheidegger s venkatasubramanian s choudhary e p hamilton and d roth a comparative study of fairness enhancing interventions in machine learning in proc acm fat g k patro a biswas n ganguly k p gummadi and a chakraborty fairrec two sided fairness for personalized ommendations in two sided platforms in proceedings of the web conference pp j rawls a theory of justice harvard university press opinion biasopinion interaction graph opinion biasopinion interaction graph opinion biasopinion interaction graph bias
