neural network based abstract generation opinions arguments wang college computer information science northeastern university boston neu edu wang ling google deepmind london com abstract study problem generating tive summaries opinionated text pose attention based neural network model able absorb information ple text units construct informative concise uent summaries importance based sampling method designed allow coder integrate information tant subset input automatic evaluation dicates system outperforms state art abstractive extractive tion systems newly collected datasets movie reviews arguments system summaries rated informative grammatical human evaluation introduction collecting opinions integral daily activities discovering ple think help navigate different pects life ranging making decisions ular tasks judging fundamental societal issues forming personal ideology efciently absorb massive opinionated information pressing need automated systems erate concise uent opinion summary entity topic spite substantial researches opinion summarization prominent proaches mainly rely extractive summarization methods phrases sentences nal documents selected inclusion mary liu lerman problems extractive methods suffer movie martian reviews smartest sweetest satisfyingly suspenseful lms years intimate epic smart spectacular stirring martian thrilling human moving picture easily emotionally engaging ridley scott pretty sunny funny space oddity director known pictures sense humor martian highlights book best qualities tones worst adds style opinion consensus summary smart thrilling prisingly funny martian offers faithful adaptation bestselling book brings best leading man matt damon director ridley scott topic house supports death penalty arguments state responsibility protect lives innocent citizens enacting death penalty save lives ducing rate violent crime prospect life prison frightening surely death daunting prospect study stephen layson university north carolina showed single execution deters murders reducing wait time death row prior execution dramatically increase deterrent effect united states claim summary death penalty deters crime figure examples opinion consensus fessional reviews critics movie martian www rottentomatoes com claim death penalty supported arguments idebate org tent similar meaning highlighted color unavoidably include secondary dant information contrary abstractive marization methods able generate text original input produce ent concise summaries paper present attention based ral network model generating abstractive maries opinionated text system takes set text units containing opinions topic reviews movie arguments controversial social issue outputs sentence abstractive summary describes opinion consensus input specically investigate abstract tion model types opinionated text movie reviews arguments controversial topics amples displayed figure rst ple contains set professional reviews ics movie martian opinion sensus written editor ful automatically generate uent opinion sus simply extracting features plot music opinion phrases previous summarization work zhuang second example lists set arguments death penalty argument supports central claim death penalty deters crime guments special type opinionated text tain reasons persuade inform people certain issues given set arguments topic aim investigating capability abstract generation system novel task claim ation existing abstract generation systems ated text approach rst salient phrases merges tences bing ganesan systems capable generating new words output summary suffer ungrammatical structure line work quires large human input enforce summary quality example gerani utilize set templates constructed human lled extracted phrases generate grammatical sentences serve different discourse functions address challenges propose use attention based abstract generation model data driven approach trained generate tive concise uent opinion summaries method based recently proposed work neural encoder decoder models ner blunsom sutskever translates sentence source language target language different previous work summarization system designed port multiple input text units attention based model bahdanau deployed low encoder automatically search salient information context furthermore pose importance based sampling method encoder integrate information portant subset input text importance score text unit estimated novel regression model pairwise preference based regularizer importance based sampling model trained manageable time able learn diversied input demonstrate effectiveness model newly collected datasets movie reviews arguments automatic evaluation bleu ineni indicates system forms state art extract based based methods tasks example achieved bleu score rotten toes movie reviews compared stractive opinion summarization system rouge evaluation lin hovy indicates system summaries reasonable information coverage human judges rated summaries informative grammatical compared systems data collection collected datasets movie reviews arguments controversial topics standard abstracts rotten tomatoes www rottentomatoes com movie review site aggregates professional critics user generated reviews henceforth toes movie sentence critic sensus constructed editor summarize opinions professional critics crawled critics opinion consensus movies reviews movie average select movies training movies idation movies testing opinion sensus treated gold standard summary collect argumentation dataset idebate org henceforth idebate wikipedia style website gathering pro con arguments controversial issues arguments debate topic organized datasets downloaded ccs neu edu home ferent points point tains sentence central claim constructed editors summarize corresponding arguments treated gold standard instance debate death penalty claim death penalty deters crime argument acting death penalty save lives reducing rate violent crime figure crawled debates claims treat tence argument results ments total debates training debates validation debates testing neural network based abstract generation model section rst dene problem tion followed model description eral utilize long short term memory network generating abstracts section latent representation computed attention based coder section encoder designed search relevant information input ter inform abstract generation process discuss importance based sampling method low encoder integrate information tant subset input sections processing section conducted rank generations pick best nal mary problem formulation summarization goal generate summary composed sequence words unlike previous neural encoder decoder approaches decode input input sists arbitrary number reviews arguments henceforth text units ity denoted text unit composed sequence words word takes form representation vector initialized randomly pre trained beddings mikolov updated training summarization task dened ing likely sequence words log denotes conditional likelihood output sequence given input text units sections describe attention model model log decoder similar previous work sutskever bahdanau decompose log sequence word level predictions log log word predicted conditional previously generated input probability estimated standard word softmax sof recurrent neural networks rnns state variable timestamp modeled recurrent update function generating new state representation ously generated word obtained word lookup table previous state input text representation section work implement long term memory lstm network hochreiter schmidhuber shown fective capturing long range dependencies summarize update rules lstm cells refer readers original work hochreiter schmidhuber details given bitrary input vector timestamp previous state typical lstm denes lowing update rules uuj woccj argmaxy log component wise logistic sigmoid function denotes hadamard product projection matrices biases parameters learned ing training long range dependencies captured cell memory updated linearly avoid vanishing gradient problem accomplished predicting vectors determine forget current timestamp vector decides mation new cell memory passed new state finally model concatenates representation previous output word input representation section serves input timestamp encoder representation input text units computed attention model bahdanau given single text unit previous state model generates weighted sum aibi attention coefcient obtained word context dependent sentation work construct building bidirectional lstm sequence combining ward backward states formally use lstm formulation generate ward states setting jection word word lookup table wise backward states generated backward lstm feeding input reverse order cients computed softmax input sof function computes afnity word current output context likely input word ate word summary set parameters learned attention multiple inputs key distinction model isting sequence sequence models sutskever bahdanau input consists multiple separate text given input text units units simple extension concatenate sequence seg special token delimits inputs seg seg problems proach firstly model sensitive order text units contain thousands words bottleneck model training time attention efcients computed input words generate output word address problems sub sampling input intuition number input text units large redundant contain secondary information task emphasize main points input removed ing information dene importance score document section training candidates sampled multinomial distribution constructed normalizing input text units notice training process goes training set multiple times model able learn text units ing candidates highest importance scores collapsed descending order importance estimation describe importance estimation model outputs importance scores text units general start ridge regression model add regularizer enforce separation summary worthy text units given cluster text units summary compute number overlapping content words text unit summary gold standard importance score scores uniformly normalized text unit represented ddimensional feature vector label text units training data denoted feature matrix label vector aim learning mizing standard formulation ridge regression use tures table furthermore pairwise preference constraints utilized learning ranking models joachims consider adding pairwise preference based regularizing constraint incorporate bias summary worthy text units xqt cluster text units rized term enforces separation summary worthy text construct contain pairwise differences vector size element objective function tuned development set closed form solution num words unigram num pos tags num named entities centroidness radev mpqa wilson avg max idf scores category general inquirer stone num positive negative neutral words general inquirer table features text unit importance estimation post processing testing phase rank best summaries according cosine similarity input text units highest similarity cluded nal summary uses ticated ranking methods charniak johnson konstas lapata gated future work pre trained embeddings features size word representation set output words initialized randomly pre trained embeddings learned google news mikolov extend model additional features described table discrete features pos tags mapped word representation lookup tables continuous features idf scores attached word vectors additional values named entity category general inquirer capitalized pos tag dependency relation sentiment polarity general inquirer mpqa idf score table token level features abstract generation hyper parameters stop criterion lstms equation decoder encoders dened states cells dimensions attention input word state pair computed projected vector dimensions equation training performed adagrad duchi terminates performance prove development set use bleu grams papineni evaluation ric computes precision grams erated summaries gold standard abstracts reference finally importance based sampling rate set experiments sections decoding performed beam search beam size probable sequences stack step outputs end sentence token considered ranking decoding stops beam stack generates end sentence token experimental setup results data pre processing pre process datasets stanford corenlp manning tokenization extracting pos tags dency relations rottentomatoes dataset place movie titles generic label training substitute movie generic label generated testing importance estimation evaluation rst evaluate importance estimation nent described section compare support vector regression svr smola nik baselines length baseline ranks text units based length centroid baseline ranks text units according centroidness computed sine similarity text unit centroid cluster summarized erkan radev figure evaluation importance estimation mean ciprocal rank mrr normalized discounted cumulative gain returned results regression model pairwise preference based izer uniformly outperforms baseline systems datasets evaluate mean reciprocal rank mrr normalized discounted cumulative gain returned results text units considered relevant ping content word gold standard summary figure importance timation model produces uniformly better ranking performance datasets automatic summary evaluation automatic summary evaluation consider popular metrics rouge lin hovy employed evaluate grams recall summaries gold standard abstracts erence rouge measures unigram bigrams separated words reported utilize bleu precision based metric evaluate language generation systems chiang angeli karpathy fei fei consider meteor denkowski lavie recall oriented metric calculates similarity generations references considering synonyms paraphrases comparisons rst compare stractive summarization method presented rottentomatoes dataset ganesan utilize graph based rithm remove repetitive information merge opinionated expressions based syntactic tures product reviews datasets sider extractive summarization approaches lexrank erkan radev vised method computes text centrality based pagerank algorithm sipos propose supervised submodular summarization model trained support vector machines addition longest sentence picked line variations system tested uses randomly initialized word embeddings rest use pre trained word embeddings additional features table combination systems generate sentence summary results displayed table system pre trained word embeddings additional tures achieves best bleu scores datasets boldface statistical signicance tailed wilcoxon signed rank test notice system summaries conciser shorter average lead higher scores precision based metrics bleu lower scores recall based metrics meteor rouge rottentomatoes dataset summaries erated different systems similar length system outperforms methods meteor rouge addition signicantly ter bleu scores true idebate length summaries extract based systems signicantly longer bleu scores system considerably higher systems models pre trained word embeddings general achieve better scores additional features improve performance help systems converge faster human evaluation summary quality human evaluation consider aspects formativeness indicates salient mation contained summary grammaticality measures summary grammatical compactness denotes summary contains unnecessary information aspect rated scale best judges run model idebate relies high redundancy detect repetitive expressions observed idebate rottentomatoes idebate length bleu meteor rouge length bleu meteor rouge extract based systems longest lexrank submodular abstract based systems opinosis systems words words pre trained words features words pre trained features table automatic evaluation results bleu meteor rouge scores multiplied abstract generation systems average lengths human written summaries rottentomatoes idebate best performing system column highlighted boldface system pre trained word embeddings additional features achieves best bleu scores datasets systems statistically signicantly better comparisons highlighted tailed wilcoxon signed rank test system best meteor rouge scores italics rottentomatoes dataset learning based systems info gram comp avg rank lexrank opinosis system human abstract table human evaluation results abstract generation tems inter rater agreement overall ranking pendorff informativeness info grammaticality gram compactness comp rated scale best system achieves best informativeness grammaticality scores learning based systems summaries ranked best evaluations ranked higher compared systems average asked ranking summary tions according overall quality randomly sampled movies tomatoes test set evaluated distinct human judges hired procient glish speakers evaluation system maries lexrank opinosis system human written abstract representative reviews displayed movie reviews highest gold standard importance scores selected results reported table seen system outperforms abstract based tem opinosis aspects achieves ter informativeness grammaticality scores lexrank extracts sentences nal form system summaries ranked best evaluations average ranking higher opinosis lexrank average inter rater ment krippendorff achieved overall ranking implies based abstract generation model produce maries better quality existing summarization systems system summaries constructed style closer human abstracts sample summaries displayed figure sampling effect investigate taking inputs pled distributions estimated importance scores trains models better performance ones learned xed input sampled input recall sample text units based importance scores importance based sampling consider setups sampling text units uniformly uniform sampling picking text units highest scores try ous values results figure demonstrates importance based sampling produce ble bleu scores methods outperform uniform sampling meteor score importance based sampling uniformly performs discussion finally discuss observations tential improvements applying ranking component model generates best stracts leads better performance preliminary periments simply picking observe similar results idebate dataset movie neverending story reviews little adventure fed tivated need think wonder magical storytelling targeted children fascinates art direction volved lot imagination human magical journey power young boy imagination save dying fantasy land neverending story remains loved kids adventure lexrank pokes times lapses occasionally dark moments preachy philosophy ing amusing harmless kids opinosis neverending story silly fantasy movie shows age system neverending story entertaining dren adventure heart imagination spare movie joe strummer future unwritten reviews late punk rock legend joe strummer rendered fully human julian temple engrossing encompassing portrait movie fascinates strummer way temple ganized edited compelling documentary portraits musician human displaying joe strummer warts ture unwritten succeeds engrossing tary comprehensive examination music legendary gures lexrank joe strummer future unwritten fans big fans opinosis joe strummer future unwritten fans big fans system fascinating insightful joe strummer future unwritten thoroughly engrossing documentary topic house detain terror suspects trial arguments governments powers protect citizens threats life nation recognise rules applied peacetime appropriate wartime human governments powers protect citizens harm lexrank merely directly protect citizens political violence political violence caps process reconstruction nation building efforts system governments obligation protect izens harmful substances topic house replace christmas festival arguments christmas celebrations western world respect rights gious states instead sponsoring celebrating events join equally regardless religion race class human states respect freedom religion freedom religion lexrank school children share christian faith christmas celebrations require ticipation want coercion non participation isolation whilst celebrations inclusiveness system people right freedom religion figure sample summaries generated different systems movie reviews arguments subset reviews arguments limited space figure sampling effect rottentomatoes ations produces inferior results ranking simple heuristics suggests current models oblivious task specic issues informativeness post processing needed better use summary candidates example future work study sophisticated ranking algorithms charniak johnson konstas lapata furthermore look difcult cases summaries evaluated lower formativeness shorter gold standard human abstracts information coverage limited cases generations contain incorrect information domain dependent facts named entities numbers stance summary poignant coming age tale marked breakout lead performance cate shortland generated movie lore mary contains cate shortland tor movie instead actor require semantic features handle issue attempted related work work belongs area opinion rization constructing uent natural language ion summaries mainly considered product views liu lerman munity question answering wang editorials paul extractive tion approaches employed identify worthy sentences example liu rst identify frequent product features attach extracted opinion sentences sponding feature model instead utilizes stract generation techniques construct natural guage summaries far know rst study claim generation arguments recently growing interest generating abstractive summaries news cles bing spoken meetings wang cardie product reviews ganesan fabbrizio gerani approaches based phrase tion algorithm concatenates sentences bing ganesan output summaries guaranteed grammatical gerani design set manually constructed realization templates producing grammatical sentences serve different discourse functions approach require human annotated rules applied domains task closely related recent advances neural machine translation kalchbrenner som sutskever based sequence sequence paradigm rnns based els investigated compression summarization filippova rush hermann sentence level built attention based lation model bahdanau rush study problem constructing abstract single sentence task differs els presented model carries stractive decoding multiple sentences instead single sentence conclusion work presented neural approach generate abstractive summaries opinionated text employed attention based method nds salient information different input text units generate informative concise summary cope large number input text ploy importance based sampling mechanism model training experiments showed tem obtained state art results tomatic evaluation human evaluation references gabor angeli percy liang dan klein simple domain independent proceedings abilistic approach generation conference empirical methods ral language processing pages association computational linguistics bahdanau dzmitry bahdanau kyunghyun neural machine cho yoshua bengio translation jointly learning align translate corr bing lidong bing piji liao wai lam weiwei guo rebecca passonneau stractive multi document summarization phrase lection merging proceedings nual meeting association computational linguistics international joint conference natural language processing volume long pers pages beijing china july ation computational linguistics charniak eugene charniak mark johnson coarse best parsing proceedings maxent discriminative reranking annual meeting association tional linguistics acl pages burg usa association computational guistics david chiang hierarchical phrase based model statistical machine translation proceedings annual meeting ation computational linguistics pages association computational linguistics denkowski michael denkowski alon lavie meteor universal language specic translation evaluation target language proceedings eacl workshop statistical machine translation fabbrizio giuseppe fabbrizio amanda stent robert gaizauskas hybrid approach multi document summarization opinions reviews inlg page duchi john duchi elad hazan yoram singer adaptive subgradient methods mach line learning stochastic optimization learn res july erkan gunes erkan dragomir radev lexrank graph based lexical centrality salience text summarization artif int res december filippova katja filippova enrique seca carlos colmenares lukasz kaiser oriol vinyals sentence compression deletion lstms proceedings conference empirical methods natural language processing pages lisbon portugal september ation computational linguistics ganesan kavita ganesan chengxiang zhai jiawei han opinosis graph based proach abstractive summarization highly proceedings dant opinions tional conference computational linguistics pages association computational linguistics gerani shima gerani yashar mehdad giuseppe carenini raymond bita nejat abstractive summarization product reviews discourse structure conference empirical methods natural language processing emnlp pages doha qatar october association computational linguistics proceedings hermann karl moritz hermann tomas cisky edward grefenstette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read comprehend corr hochreiter sepp hochreiter jurgen schmidhuber long short term memory neural comput november minqing bing liu ing summarizing customer reviews ings tenth acm sigkdd international ence knowledge discovery data mining kdd pages new york usa acm thorsten joachims ing search engines clickthrough data ceedings eighth acm sigkdd international conference knowledge discovery data ing kdd pages new york usa acm kalchbrenner nal kalchbrenner phil blunsom recurrent continuous translation models emnlp pages acl karpathy fei andrej karpathy deep visual semantic alignments arxiv preprint fei generating image descriptions konstas ioannis konstas mirella lapata concept text generation inative reranking proceedings annual meeting association computational tics volume long papers pages jeju land korea july association computational guistics lerman kevin sasha lerman goldensohn ryan mcdonald sentiment summarization evaluating learning user proceedings conference erences european chapter association putational linguistics eacl pages stroudsburg usa association computational linguistics fangtao chao han minlie huang aoyan zhu ying xia shu zhang hao structure aware review mining proceedings international tion ference computational linguistics coling pages stroudsburg usa association computational linguistics lin chin yew lin eduard hovy automatic evaluation summaries proceedings gram occurrence statistics conference north american chapter association computational linguistics human language technology volume pages manning christopher manning mihai deanu john bauer jenny finkel steven bethard david mcclosky stanford corenlp proceedings ural language processing toolkit annual meeting association tional linguistics system demonstrations pages baltimore maryland association tional linguistics mikolov tomas mikolov kai chen greg corrado jeffrey dean efcient tion word representations vector space corr papineni kishore papineni salim roukos todd ward wei jing zhu bleu method automatic evaluation machine translation proceedings annual meeting association computational linguistics pages ation computational linguistics paul michael paul chengxiang zhai roxana girju summarizing contrastive points opinionated text proceedings conference empirical methods natural guage processing emnlp pages burg usa association computational guistics dragomir radev experiments single multidocument summarization mead document understanding conference rush alexander rush sumit chopra jason weston neural attention model proceedings stractive sentence summarization conference empirical methods natural language processing pages lisbon gal september association computational guistics sipos ruben sipos pannaga shivaswamy thorsten joachims large margin learning submodular summarization models proceedings conference european chapter association computational linguistics eacl pages stroudsburg usa association computational linguistics smola alex smola vladimir support vector regression machines nik advances neural information processing systems stone philip stone dexter dunphy marshall smith daniel ogilvie general inquirer computer approach content analysis mit press cambridge sutskever ilya sutskever oriol vinyals quoc sequence sequence ing neural networks advances neural formation processing systems annual conference neural information processing systems cember montreal quebec canada pages sutskever ilya sutskever oriol vinyals quoc sequence sequence learning neural networks corr wang wang claire cardie domain independent abstract generation cused meeting summarization proceedings annual meeting association tational linguistics volume long papers pages soa bulgaria august association computational linguistics wang wang hema raghavan claire cardie vittorio castelli query focused opinion summarization user generated content proceedings coling international conference computational linguistics technical papers pages dublin ireland august dublin city university association tional linguistics wilson theresa wilson janyce wiebe paul hoffmann recognizing contextual larity phrase level sentiment analysis ings conference human language ogy empirical methods natural language cessing hlt pages stroudsburg usa association computational linguistics zhuang zhuang feng jing xiao yan zhu movie review mining summarization proceedings acm international ference information knowledge management cikm pages new york usa acm
