prism unified framework parameterized submodular information measures targeted data subset selection summarization preprint vishal kaushal department computer science indian institute technology bombay iitb suraj kothawade department computer engineering university texas dallas suraj edu ganesh ramakrishnan department computer science indian institute technology bombay iitb jeff bilmes department electrical computer engineering university washington seattle edu rishabh iyer department computer science university texas dallas rishabh edu march abstract increasing data techniques nding smaller effective subsets specic characteristics important motivated present prism rich class parameterized submodular information measures applications targeted subsets desired demonstrate utility prism applications apply prism improve supervised model performance given additional labeling cost targeted subset selection prism tss subset unlabeled points matching target set added training set prism tss generalizes connected existing approaches targeted data subset selection second apply prism nuanced targeted summarization prism tsum data image collections text videos summarized quicker human consumption additional user intent prism tsum handles multiple avors targeted summarization focused topic irrelevant privacy preserving update summarization unied way prism tsum generalizes unies existing past work targeted summarization extensive experiments image classication image collection summarization empirically verify superiority prism tss prism tsum state art introduction recent times seen unprecedented growth data modalities text images videos naturally given rise techniques nding effective smaller subsets data variety end tasks example data subset selection efcient cost effective training machine learning models need select samples informative training model training smaller subsets data entails signicant speedups reduction labeling time cost sacricing accuracy example summarization image collection video text document summarized quicker human consumption equal contribution authors ordered alphabetically preprint march eliminating redundancy preserving main content end tasks want able select subsets align certain target set present motivating applications fig motivating applications targeted data subset selection real world settings distribution shift training data test data cases model performance improved given additional labeling cost augmenting training data informative samples matching target distribution called targeted subset large pool unlabeled data way achieving assuming access clean validation set matching target set distribution target example target set critical slice data indoor images people dark background example images specic classes user care want improve model performance target sacricing overall accuracy minimum additional labeling costs fig figure motivating applications example targeted data subset selection night images target represented train example targeted summarization query set private set target targeted summarization number applications require generic summarization simply picking representative diverse subset massive dataset important capture certain user intent summarization fig user intent somewhat nuanced modeled query focused summarization small representative set points relevant specic query selected irrelevant privacy preserving summarization small representative set points desired irrelevant given topic completely different given private set data points update summarization subset selected conditioned summary seen user rest paper collectively refer different avors targeted summarization target assuming different semantics case contributions motivated applications present prism rich class parameterized submodular information measures specically summarize key contributions follows prism build submodular mutual information functions conditional gain functions recently introduced iyer unique novel extension described section comes ability consider query set conditioning set different auxiliary set compared ground set requirement targeted data subset selection targeted summarization target different ground set subset desired extension restricted submodularity enables potentially richer class functions novel parameterization functions help model aspects trade offs query relevance diversity hardness privacy constraints study rich modeling capabilities different functions prism state specic results lemmas prism tss targeted data subset selection apply prism targeted data subset selection prism tss section demonstrate empirically section signicantly outperforms techniques improving accuracy image classication mnist classes interest gain model performance training added targeted subset methods given tional labeling cost increase overall accuracy prism tss generalizes interesting connections number existing approaches targeted data subset selection lemma prism tsum targeted summarization apply prism targeted summarization prism tsum tion prism tsum offers unied approach different semantics target query focused targeteddata subsetselectionaugment ttargeted subset tlabelled training datatargetsunlabelled datasetretrain modelaugmented training datageneric summarizationquery focusedprivacy collection preprint march summarization topic irrelevant privacy preserving summarization update summarization prism tsum generalizes number past approaches query focused update summarization demonstrate section outperforms methods real world image collections dataset owing richer learning parameters related work submodularity submodular information measures submodularity fujishige rich tractable non linear combinatorial optimization ensures tractable algorithms krause golovin nice connections convexity concavity bach lovsz iyer bilmes work builds provides unique novel extension recently introduced class submodular information measures gupta levin iyer data subset selection number papers studied data subset selection different applications set past works explores supervised data subset selection reducing training time examples approaches include submodular functions selection kaushal wei liu coresets effective weighted subsets training data craig mirzasoleiman discrete level optimization optimize held validation set performance glister killamsetty explore unsupervised subset selection optimal subset unlabeled set selected labeled minimize labelling costs kaushal iteratively called active learning number techniques uncertainty sampling query committee settles studied recently batch active learning prominent recent techniques combine diversity uncertainty wei sener savarese ash state art approach badge ash samples points diverse hypothesized gradients apply prism tss targeted subset unlabeled data improving model performance target interest given additional labeling cost demonstrate superior performance compared summarization number instances summarization studied past including image tion summarization celis keswani ozkose singh tschiatschek text document summarization lin bilmes chali yao bairi video summarization kaushal gygli works focused generic summarization works studied query focused video summarization sharghi vasudevan xiao jiang han query focused document summarization lin bilmes update summarization documents dang owczarzak delort alfonseca best knowledge prism tsum rst attempt offer unied treatment different avors summarization preliminaries submodular functions let denote ground set data points set function function submodular fujishige satises diminishing marginal returns facility location set cover log determinants examples iyer close connections submodularity entropy submodular functions viewed information functions zhang yeung submodularity ensures greedy algorithm achieves bounded approximation factor maximized nemhauser conditional gain given set items conditional gain gain function value adding intuitively measures different refer conditioning set private set submodular conditional mutual information cmi given set items submodular mutual information gupta levin iyer dened intuitively measures similarity refer query set conditional submodular mutual information cmi dened intuitively cmi jointly models mutual similarity dissimilarity properties cmi cmi non negative monotone argument xed gupta levin iyer cmi necessarily submodular argument xed krause iyer instantiations dene turn submodular preprint march prism introduce prism extend cmi handle case target come auxiliary set different ground set targeted data subset selection source set data instances target subset data points validation set specic set examples interest case targeted summarization set data points user wants summarize images video frames video shots sentences target query set query focused summarization private set topic irrelevant privacy preserving summarization conditioning set update summarization let dene set function dened discrete optimization problem dened subsets optimal subset given query set dene maximize private set conditioning set set topics want subset irrelevant dene function maximized shall offer rich class models motivating applications extend dening generalized submodular mutual information functions restricted submodularity generalized submodular mutual information gmi submodular tions expressive natural choices submodular need submodular sets optimizing subsets instead requiring submodular inequality hold pairs sets particular dene subset restricted submodularity satises instances restricted submodularity form intersecting crossing submodular functions considered past fujishige consider following form restricted submodularity dene gmi given sets dene sets satisfy following conditions set set use notion gmi dene concave modular com query saturation sat functions interesting connections past work section state properties gmi following lemma defer proof appendix lemma given restricted submodular function monotone xed equivalently monotone xed instantiations prism psc sij sij sij sij sij logdet log max sij max sij log log sij max sij log sij sij max useful log sap sij max max useful sij sij com equation useful useful sat table instantiations parameterizations prism section particularly useful lemma present expressions different instantiations prism table discuss introduce new instantiations log determinant com sat borrow basic instantiations set cover probabilistic set cover psc graph cut facility location iyer adapt setting distinct summary space auxiliary space derive alternative expression flmi interesting characteristics different submodular functions model different characteristics instantiations differ treatment interplay characteristics alignment target important note instantiations considered table parameterized models internal parameters represented jointly learned model parameters section functions let address broad spectrum semantics max sij max sij sij sij preprint march log determinant logdet refer cmi applied logdet function logdetmi logdetcg logdetcmi respectively present expressions fourth row table denote similarity matrix items sets denote sab sab construct similarity matrix way cross similarity multiplied control trade query relevance diversity cross similarity control hardness privacy constraints higher values ensure stricter privacy constraints transitioning topic irrelevant privacy preserving summarization simplicity notation provide cmi expression defer general expression proof lemma appendix lemma similarity matrix dened log log log similarly log sap log facility location present versions functions rst similar derived iyer presented fth row table instantiate variant considers cross similarities data points target note expression interesting characteristics different particular gets saturated models pairwise similarities target data points vice versa state lemma defer proof appendix lemma given similarity kernel sij facility location function maxja sij obtain expression maxjq sij cmi expressions particularly useful case maxja sij finally note similar log determinant parameters functions appropriately multiplying cross similarities appendix details concave modular com notion generalized submodular mutual information functions presented earlier allows characterize rich class concave modular functions gmi functions dene set function sij sij jav jav sij sij jav jav sij restricted submodular state expression gmi function following lemma proof appendix lemma function restricted submodular function furthermore gmi exactly sij given kernel matrix satises sij cmi expressions particularly useful case query saturation sat dene set function rst restricted submodular function provide expression gmi result defer expressions conditional gmi variants proofs appendix lemma function dened restricted submodular furthermore expression interesting fact generalizes rouge lin common evaluation metric summarization details section graph cut dened fgc sij sij measures similarity elements sij parameter captures trade diversity representativeness reproduce expressions gcmi gccg iyer row table note cmi expression involve private set exactly version proof appendix like logdet introduce additional parameter gccg control sensitivity privacy modeled easily objective multiplying cross similarity data points private instances set cover probabilistic set cover psc let denote concepts covered set psc functions dened weights concepts set concepts probability cover concept reproduce expressions psc functions iyer rst rows table preprint march figure behavior different functions prism effect parameters plots share legend representational power prism empirically verify intuitive understanding expressions synthetically created dataset maximize different functions prism different parameters study characteristics subsets qualitatively quantitatively dene query coverage fraction queries covered subset query relevance fraction subset pertaining queries diversity measure diverse points selected subset privacy irrelevance fraction subset matching private instances present representative results fig provide detailed results appendix functions verify increasing tends increase query relevance reducing query coverage diversity left fig gcmi lies end spectrum favoring query relevance lies end favoring diversity query coverage logdetmi com lie right fig expected functions increasing increases privacy irrelevance logdetcg outperforms flcg gccg terms diversity privacy irrelevance left fig cmi functions flcmi tends favor query coverage diversity contrast query relevance privacy irrelevance logdetcmi favors query relevance privacy irrelevance query coverage diversity right fig prism tss setting rst apply prism simple setting targeted data subset selection improving model accuracy target classes instances given additional labeling cost instances compromising overall accuracy follows let initial training set labeled instances set examples user cares desires better performance let large unlabeled dataset maximize function compute optimal subset size given query target set augment labeled train model achieve better accuracy compromising accuracy classes instances instantiating rich class functions including gcmi com logdetmi prism tss offers rich treatment targeted subset selection framework allows adding explicit diversity term helpful cases gcmi model diversity algorithm summarized algorithm algorithm prism tss require initial labeled set examples large unlabeled dataset target subset slice want improve accuracy loss function learning train model loss labeled set obtain parameters compute gradients hypothesized labels compute similarity kernels includes kernel elements dene submodular function diversity function maxau obtain labels elements train model combined labeled set preprint march algorithm generalizes interesting connections number recently proposed subset selection approaches special case prism tss viewed approximating target set gradients connections glister closest setting glister killamsetty selects subset optimizing validation set target setting authors study active learning variant called active glister framework authors solve discrete level problem online meta learning based approach essentially gradient step instead completely solving inner optimization problem authors approach results submodular optimization problem number loss functions including hinge loss logistic loss square loss perceptron loss lemma shows glister applied targeted data selection appendix details fact special case algorithm defer proof appendix glister tss lemma glister tss hinge loss logistic loss perceptron loss special case algorithm com connections badge craig recently proposed data selection active learning algorithms craig mirzasoleiman badge ash craig applied supervised data selection proceeds selecting subset maximizes facility location objective maxja sij similarity sij computed gradients ith jth data point badge studies active learning based setting gradient based instead considers hypothesized labels computing gradients unlabeled set similar algorithm badge uses select diverse subset data points instead maximizing facility location function easy consider extension badge note easily extend craig badge targeted scenario optimize function maxja sij sij gradient similarity points hypothesized labels unlabeled set function exactly prism tss approximating target set gradients natural formulation targeted data subset selection select subset average gradient difference target set minimized particular dene loss ith data point denote loss unlabeled set loss target set following lemma proof appendix shows minimizing gradient difference special case algorithm lemma minimizing gradient difference rewritten special case algorithm gcmi diversity function prism tsum setting given set data points images sentences document frames shots setting video goal summary desired characteristics target assumes different semantics different avors summarization query set query focused summarization private set topics topic irrelevant privacy preserving summarization context update summarization target summary user seen goal summary different unied framework prism tsum given sets restricted submodular function consider following master optimization problem discuss different avors summarization seen special cases master optimization problem setting yields generic summarization similarly setting yields query focused summarization query set setting gives privacy preserving summarization update summarization set framework allows address avor joint query focused privacy preserving marization set possible avor query focused update summarization want summary similar different achieved setting preprint march parameter learning prism tsum multiple instantiations submodular information functions imparting certain characteristics summaries propose learning mixture model supervised human summaries build prior work learns mixtures submodular functions applications document summarization lin bilmes video summarization gygli kaushal image collection summarization tschiatschek extend joint learning internal parameters weights individual components mixture denote parameter vector prism tsum mixture model fis instantiations prism diversity representation terms given training examples learn parameters optimizing following generalized hinge loss training example margin formulation min human summary max nth ground set video image collection text document features parameters learnt gradient descent specic objective functions gradient computations case query focused privacy preserving joint query focused privacy preserving summarizations presented appendix generic summarization add standard submodular functions modeling representation diversity coverage mixture query focused summarization privacy preserving summarization use cmi functions respectively dened similar tschiatschek parameters learnt instantiate model learnt parameters maximize desired automatic summaries prism tsum generalizes existing approaches proposed prism tsum framework generalizes unies past work area inadvertently submodular information measures models mention past works defer details appendix query dpp considered sharghi special case logdetmi similarly graph cut based query relevance term vasudevan lin actually gcmi submodular function update summarization gccg furthermore joint diversity query relevance term lin bilmes instance com square root concave function finally query specic rouge lin common evaluation metric document image summarization lin bilmes tschiatschek example query saturation sat function connections demonstrate prism tsum rich effective model instances summarization experiments results effectiveness prism tss dataset baselines implementation details demonstrate effectiveness prism tss obtaining targeted subset improving image classication accuracy target classes mnist datasets simulate real world setting split available train set train validate data lake train set labeled instances poorly represents randomly picked classes target data lake large set labels use resembling large pool unlabeled data real world poorly represented classes perform validation set hold clue picking target interest performance measured test set respective datasets apply prism tss algorithm comparing functions existing approaches specically functions use logdetmi gcmi gcmi diversity equivalent intuitive approach minimizing average gradient difference target lemma existing approaches compare active learning baselines uncertainty sampling badge glister active glister running setting select unlabeled subset active learning baselines explicitly information target set strengthen compare variants target aware rst targeted uncertainty sampling tus product uncertainty similarity target identify subset second glister tss lemma target set level optimization finally compare pure diversity representation functions logdet disparity sum dsum random sampling train model lenet lecun mnist cross entropy loss sgd optimizer training accuracy exceeds base model augmenting train set labeled version selected subset training model report average gain accuracy target classes overall gain accuracy classes averaged runs randomly picking classes target query focused case privacy preserving case cmi degenerates respectively preprint march figure comparison different methods targeted subset selection different budgets mnist axis budgets axis gain model accuracy target classes based approaches lines red signicantly outperform subset sizes section figure targeted summarization results image collection summarization joint learning parameters proposed model prism tsum outperforms settings target section run prism tss different budgets study effect budget performance applicable internal parameters default values results table report results budget mnist setting realistic possible set target set smaller budget budget mnist report effect budget gain accuracy target classes fig datasets functions yield best improvement accuracy target classes gain model performance training added targeted subset methods simultaneously increasing overall accuracy consistently outperform badge glister tss tus budgets recall discussion behavior different functions section expected logdetmi modeling query relevance diversity perform better functions tend prefer relevance gcmi tus functions tend prefer diversity representation badge dsum logdet observe budget increased functions outperform methods greater margins target class accuracy fig expected methods effective considering target details experimental setup additional discussion results appendix effectiveness prism tsum dataset implementation details use image collections dataset tschiatschek dataset image collections images provides human summaries collection extend acquiring dense noun concept annotations image query focused privacy preserving joint query focused privacy preserving human summaries image collection suitable targeted summarization extract concepts images pre trained shelf networks represent preprint march mnist overall target method base random badge ash glister killamsetty glister tss settles tus logdet dsum logdetmi gcmi target overall table comparison prism tss functions methods budget mnist numbers gain accuracy target classes target classes overall base model training model text best existing approaches indicated highest blue highest red green respectively concept queries vector universe concepts defer dataset implementation details appendix prism tsum mixture model components appropriate instantiations cmi functions logdet com psc mixture weights internal parameters learnt following tschiatschek perform leave cross validation report average rouge runs normalize rouge human average random average results present targeted summarization results fig discussed section individual components mixture model models document video summarization compare approaches explicit past work targeted summarization image collection contrast performance individual components verify effect joint learning parameters compare prism tsum mixture model mixture exactly components prism tsum model weights learnt internal parameters set xed default values prism tsum outperforms techniques including mixture conrming effectiveness proposed framework especially joint learning parameters conclusion presented prism novel rich framework parameterized submodular information measures instantiations prism allow model broad spectrum semantics demonstrated effectiveness targeted data subset selection improving model accuracy prism tss targeted summarization prism tsum showed prism tsum prism tss unify generalize past works areas experiments mnist image collections dataset empirically verify superiority prism existing methods references jordan ash chicheng zhang akshay krishnamurthy john langford alekh agarwal deep batch active learning diverse uncertain gradient lower bounds iclr francis bach learning submodular functions convex optimization perspective arxiv preprint ramakrishna bairi rishabh iyer ganesh ramakrishnan jeff bilmes summarization multi document topic hierarchies submodular mixtures proceedings annual meeting association tational linguistics international joint conference natural language processing volume long papers pages preprint march elisa celis vijay keswani implicit diversity image summarization proceedings acm computer interaction yllias chali moin tanvee mir tafseer nayeem abstractive multi document summarization submodular function based framework sentence compression merging proceedings eighth international joint conference natural language processing volume short papers pages hoa trang dang karolina owczarzak overview tac update summarization task tac jean yves delort enrique alfonseca dualsum topic model based approach update summarization proceedings conference european chapter association computational linguistics pages satoru fujishige submodular functions optimization elsevier anupam gupta roie levin online submodular cover problem acm siam symposium discrete algorithms michael gygli grabner gool video summarization learning submodular mixtures objectives ieee conference computer vision pattern recognition cvpr pages kaiming xiangyu zhang shaoqing ren jian sun deep residual learning image recognition proceedings ieee conference computer vision pattern recognition pages rishabh iyer jeff bilmes polyhedral aspects submodularity convexity concavity arxiv preprint rishabh iyer ninad khargoankar jeff bilmes himanshu asnani submodular combinatorial information measures applications machine learning arxiv preprint rishabh krishnan iyer submodular optimization machine learning theoretical results unifying scalable algorithms applications phd thesis zhong kailin xiong yanwei pang xuelong video summarization attention based encoder decoder networks ieee transactions circuits systems video technology pin jiang yahong han hierarchical variational network user diversied query focused video summarization proceedings international conference multimedia retrieval pages vishal kaushal iyer kothawade sandeep subramanian ganesh ramakrishnan framework domain specic video summarization ieee winter conference applications computer vision wacv pages vishal kaushal rishabh iyer suraj kothawade rohan mahadev khoshrav doctor ganesh ramakrishnan learning data unied data subset selection active learning framework computer vision ieee winter conference applications computer vision wacv pages ieee vishal kaushal rishabh iyer khoshrav doctor anurag sahoo dubal kothawade rohan mahadev kunal dargan ganesh ramakrishnan demystifying multi faceted video summarization tradeoff diversity representation coverage importance ieee winter conference applications computer vision wacv pages krishnateja killamsetty durga sivasubramanian ganesh ramakrishnan rishabh iyer glister generalization based data subset selection efcient robust learning arxiv preprint andreas krause daniel golovin submodular function maximization andreas krause ajit singh carlos guestrin near optimal sensor placements gaussian processes theory efcient algorithms empirical studies journal machine learning research alina kuznetsova hassan rom neil alldrin jasper uijlings ivan krasin jordi pont tuset shahab kamali stefan popov matteo malloci tom duerig open images dataset unied image classication object detection visual relationship detection scale arxiv preprint yann lecun bernhard boser john denker donnie henderson richard howard wayne hubbard lawrence jackel backpropagation applied handwritten zip code recognition neural computation chen yang liu lin zhao improving update summarization supervised ilp sentence reranking proceedings conference north american chapter association computational linguistics human language technologies pages jingxuan lei tao multi document summarization submodularity applied intelligence chin yew lin rouge package automatic evaluation summaries text summarization branches pages preprint march hui lin submodularity natural language processing algorithms applications phd thesis hui lin jeff bilmes class submodular functions document summarization proceedings annual meeting association computational linguistics human language technologies pages hui lin jeff bilmes learning mixtures submodular shells application document summarization arxiv preprint yuzong liu rishabh iyer katrin kirchhoff jeff bilmes svitchboard sver high quality complexity corpora conversational english speech sixteenth annual conference international speech communication association lszl lovsz submodular functions convexity mathematical programming state art pages springer baharan mirzasoleiman jeff bilmes jure leskovec coresets data efcient training machine learning models international conference machine learning pages pmlr george nemhauser laurence wolsey marshall fisher analysis approximations maximizing submodular set functions mathematical programming yunus emre ozkose bora celikkale erkut erdem aykut erdem diverse neural photo album summarization ninth international conference image processing theory tools applications ipta pages ieee joseph redmon ali farhadi incremental improvement arxiv preprint ozan sener silvio savarese active learning convolutional neural networks core set approach international conference learning representations burr settles active learning literature survey technical report university wisconsin madison department computer sciences aidean sharghi boqing gong mubarak shah query focused extractive video summarization european conference computer vision pages springer aidean sharghi jacob laurel boqing gong query focused video summarization dataset evaluation memory network based approach proceedings ieee conference computer vision pattern recognition pages anurag singh lakshay virmani subramanyam image representative summarization ieee fifth international conference multimedia big data bigmm pages ieee sebastian tschiatschek rishabh iyer haochen wei jeff bilmes learning mixtures submodular functions image collection summarization advances neural information processing systems pages arun balajee vasudevan michael gygli anna volokitin luc van gool query adaptive video summarization quality aware relevance estimation proceedings acm international conference multimedia pages kai wei rishabh iyer jeff bilmes submodularity data subset selection active learning international conference machine learning pages pmlr shuwen xiao zhou zhao zijian zhang xiaohui yan min yang convolutional hierarchical attention network query focused video summarization aaai pages jin yao xiaojun wan jianguo xiao recent advances document summarization knowledge information systems zhen zhang raymond yeung characterization entropy function information inequalities information theory ieee transactions bolei zhou agata lapedriza jianxiong xiao antonio torralba aude oliva learning deep features scene recognition places database advances neural information processing systems pages bolei zhou agata lapedriza aditya khosla aude oliva antonio torralba places million image database scene recognition ieee transactions pattern analysis machine intelligence preprint march appendix summary notations topic prism notation sab explanation ground set instances auxiliary set containing private set query set subset cross similarity matrix items sets similarity matrix items parameter governing trade representation diversity parameter governing trade query relevance diversity cmi functions parameter governing hardness privacy constraints cmi functions initial set labeled instances set instances unlabeled data set set instances target query set diversity function added function rithm weight private set conditioning set targeted summarization query set targeted summarization mixture model prism tsum parameters generalized hinge loss training example ter table summary notations paper targeted data subset selection prism tss targeted tion prism tsum appendix proofs results section properties generalized submodular mutual information functions restating lemma given restricted submodular function monotone xed equivalently monotone xed proof non negativity generalized submodular mutual information follows denition particular holds restricted submodular prove monotonicity given restricted submodular holds follows submodularity inequality holds long sets subset subsets non intersection monotone preprint march log determinant based information measures logdetmi logdetcg logdetcmi restating lemma setting log sap log log log log similarly proof given positive semi denite matrix log determinant function log sub matrix comprising rows columns indexed following expressions follow directly denitions log cmi log log note schur complement sab sab matrix includes cross similarities items sets similarly result mutual information log log log log log log similarly proof conditional submodular mutual information follows simple observation log log plugging expressions mutual information log determinant function sqp sap log log sap apq log proof cmi implicitly assumes simple way solve follows denote sap similarity matrix obtained multiplying cross similarity entries similarly denote sap cross similarity obtained multiplying cross similarity cross similarity cmi function choice similarity matrix log apsap facility location based information measures flcg theorem given similarity kernel set facility location written function maxja sij mutual information written sij maxjq sij facility location written sij maxjp sij expression conditional submodular mutual information sij maxjq sij maxjp sij similarly proof facility location set function maxja sij similarity kernel preprint march max sij max sij max jaq sij max sij max sij sij max sij sij max sij sij max sij max sij max sij max sij conditional gain finally expression iinu sij max sij max sij jina sij max jinp sij sij max sij max max jaq sij max sij step follows observation term rst term second term cancelling depending obtain expression flcg flcmi special cases corollary setting expression cmi theorem obtain expression sij maxjp sij flcmi sij maxjq sij flcg sij maxjq sij maxjp sij corollary follows directly theorem similarly obtain expression restating lemma given similarity kernel sij facility location function maxja sij obtain expression maxjq sij cmi expressions particularly useful case maxja sij proof assuming sii maximum similarity score kernel alternative formulation assumption break sum elements ground set follows maxja sij minimum sets term corresponding similar argument follows terms sij max sij max sij max sij sij max sij sij max sij max sij max sij iaq follows finally note sij max sij sij max sij sij similarly sij leaves maxja sij maxjq sij expressions cmi sense require computing terms access preprint march concave modular gmi restating lemma function restricted submodular function furthermore gmi exactly sij given kernel matrix satises sij cmi expressions particularly useful case sij proof assume kernel matrix sij given sij notice holds kernel identity kernel terms cross sets similarly sij sij finally obtain sij sij combining terms obtain sij sij finally restricted submodular notice submodular restricted similarly given sets holds implies restricted submodularity like expressions cmi sense com require computing terms access expressions query saturation function restating lemma function dened submodular furthermore restricted proof rst expand expression note finally note set holds similarly sets dened restricted submodular similar manner obtain expressions conditional gain conditional gmi cgsmi query saturation function skip proof interest brevity expression gccmi useful lemma graph cut function words cmi function depend private set preprint march proof deriving expression conditional submodular mutual information proceed follows let sij sij iaq disjoint second term rst term effect conditional submodular mutual information graph cut useful appendix representational power prism section experimental setup create synthetic dataset understand behaviour different functions prism corresponding control parameters generate different collections points space emulates space images queries private instances collection points representing images points representing queries points representing private instances points set distributed clusters different number points cluster standard deviation varied set query points private instances set randomly sampled replacement randomly selected clusters different functions prism different settings internal parameters maximize function produce summary compute relevant measures averaged different budgets intervals different collections scoring functions characterize query focused privacy preserving summaries dene following saturation phenomenon function gains picking query relevant items having picked query coverage calculated fraction query points covered summary measures summary starve query picking elements matching queries query point said covered summary exists selection summary belongs cluster query point quantify diversity summary calculating fraction unique clusters covered summary dene query relevance fraction points selected match query point dene privacy irrelevance fraction points selected match private instance figure comparison different functions prism effect parameters plots share legend additional quantitative results fig left main paper presented behavior rst variant flmi change internal parameter fig present similar observations functions like logdetmi preprint march logdetmi figure effect effect different functions fig right compare query coverage diversity query relevance gcmi flmi loddetmi com xing value applicable case compare version adds small diversity term functions measure effect saturation functions fig following observations gcmi logdetmi com favor query relevance diversity query coverage favors diversity query coverage query relevance furthermore observe com change addition diversity suggests saturated logdetmi signicantly changes behaviour addition diversity cases adding small diversity term reduces query relevance favor query coverage diversity expect report results privacy preserving summarization fig shows effect irrelevance term gccg flcg logdetcg expect increasing increases privacy irrelevance score ensuring stricter privacy irrelevance constraint fig compares diversity privacy irrelevance score different choices functions logdet xed value compare variants add small diversity unlike case functions saturate adding small diversity change selection finally trend log det outperforms terms diversity privacy irrelevance fig report results joint summarization comparison different functions flcmi flcmi div logdetcmi similar private query versions observe flcmi tends favor query coverage diversity contrast query relevance privacy irrelevance logdetcmi favors query relevance privacy irrelevance query coverage diversity qualitative analysis fig visualization image points black query points green collection number synthetic dataset selected summary points blue selected labeled order selection stand query coverage query relevance diversity privacy irrelevance respectively discussed soon increased summary produced query relevant diverse preprint march figure behavior different functions prism effect parameters different fig add version adds small diversity term functions measure effect saturation functions text details figure visualization behavior varying collection number synthetic dataset appendix details proofs related prism tss section applying glister targeted subset selection subsection rst study application glister targeted data selection particular formulate glister killamsetty min min recall given set loss examples use hypothesized labeles similar glister active killamsetty furthermore set consists unlabeled manner similar glister active apply targeted setting follows given current model parameters obtained training model labeled set apply step gradient approximation preprint march obtain min directly adapt theorem killamsetty obtain following lemma loss function hinge loss logistic loss square loss perceptron loss written constrained submodular maximization problem means obtain solution simple greedy algorithm glister tss special case prism tss certain cases restating lemma glister tss hinge loss logistic loss perceptron loss special case algorithm com proof proof follows directly appendix killamsetty particular form hinge loss perceptron loss similarly form logistic loss functions concave modular functions glister tss special case algorithm com gmi function minimizing gradient difference target special case prism tss restating lemma minimizing gradient difference rewritten special case algorithm gcmi diversity function proof prove result expand gradient difference expression note minimizing gradient difference dene immediately rst term independent constant similarly term instance gcmi expand second term expanding minimizing gradient difference rewritten maximizing sum gcmi diversity term appendix learning parameterized submodular information measures section present specic forms mixture model objective function computation gradients different cases generic query focused privacy preserving joint summarization generic summarization denote dataset training examples human summary nth ground set image collection features denote mixture model case generic summarization preprint march instantiations different submodular functions weights internal parameters respectively example case graph cut function dened parameters vector case generic summarization max purpose learning parameters compute gradients argmax gradients respect respective internal parameters individual function components generalized graphcut example compute gradient consider query focused summarization denote dataset training examples human query summary query nth ground set image collection features denote mixture model case query summarization instantiations different submodular mutual information functions weights internal parameters respectively query relevance diversity tradeoff parameters parameters vector case query focused summarization max wiifi purpose learning parameters compute gradients ifi ifi ifi ifi argmax preprint march gradients individual function components trade parameters computation functions follows ifi respect respective query relevance diversity max maxjy maxjy max logdetmi log log privacy preserving summarization denote dataset training examples human privacy summary privacy set nth ground set image collection features denote mixture model case privacy preserving summarization instantiations different conditional gain functions weights internal parameters respectively privacy sensitivity parameters parameters vector case privacy preserving summarization max purpose learning parameters compute gradients argmax preprint march gradients individual function components computation functions follows flcondgain maxjp respect respective privacy sensitivity parameters max max logdetcondgain log log joint summarization denote dataset training examples human query privacy summary query set privacy set nth ground set image collection features denote mixture model case joint query focused privacy preserving summarization instantiations different conditional submodular mutual information functions weights internal parameters respectively query relevance diversity trade parameters privacy sensitivity parameters parameters vector case joint summarization max purpose learning parameters compute gradients argmax preprint march appendix prism tsum generalizes past work section section discuss past works unknowingly fact instances functions gcmi query focused summarization works document summarization lin video summarization vasudevan use gcmi papers study simple graph cut based query relevance term special case submodular mutual information framework single query point gcmi seamlessly extends consider query set gccg gccmi graph cut conditional gain function update summarization table paper furthermore authors consider query focused update summarization case use gccmi expression existing summary goal select summary relevant query different authors study graph cut query based summarization cases observe utility class functions logdetmi query focused summarization model sharghi similar logdetmi consider sequential dpp model structure particular assume elements independent log saqst similar query term sharghi equation paper shows logdetmi model makes sense query focused summarization com lin bilmes propose combination query relevance diversity term document summarization expression propose similar com ignore diversity term achieved state art results query focused document summarization rouge rouge common evaluation metric document summarization lin lin bilmes shown lin bilmes rouge metric actually submodular actually observe rouge fact exactly query saturation sat function subsumed framework gmi framework signicantly extends provides rich class functions query focused preserving irrelevance update summarization appendix additional details experimental setup discussion results prism tss experiments section classes scarce classes mnist train class valid class target total lake class train class valid class target total lake class table number datapoints partition dataset provide details experimental setup targeted subset selection datasets simulate real world scenario creating class imbalance classes training unlabeled dataset creating ratio classes scarce classes classes times datapoints classes particular training set classes examples class examples class mnist scarce classes examples class examples class mnist mnist lake unlabeled set contains examples class classes examples class scarce evident goal able good representation scarce slices case slices obtain good results slices case scarcity classes slice data need correlated class functions baselines use class information use validation set examples class pick small targeted set consisting performing slices case observe slices highest error corresponds data scarce classes pick examples total target set examples total target set mnist pick target set mis classied examples average results multiple settings scarce classes datapoints randomly selected validation set small equal number datapoints class discuss exact number datapoints table hyperparamters training dataset preprint march optimization algorithm sgd momentum learning rate cosine annealing momentum weight decay number epochs mnist got numbers taking stopping condition training accuracy training loss figure comparison different methods targeted subset selection different budgets mnist axis budgets axis gain model accuracy target classes based approaches lines red signicantly outperform subset sizes section report better resolution image presenting effect budget size performance methods fig following additional observations results pure retrieval function gcmi works better pure diversity function dsum expected task hand targeted subset selection relevance target plays important role accordingly tends model diversity query relevance performs worse gcmi appears counter intuitive targeted version tss performs better glister cifar expected worse glister mnist think case glister tss depends heavily target set optimizing performance tends overt target instances case mnist case contrast functions work target set small note glister tss setting special case algorithm cross entropy loss appendix additional details prism tsum experiments use image collection dataset tschiatschek dataset image collections images provides human summaries collection extend creating dense noun concept annotations image suitable task start designing universe concepts based object classes kuznetsova scenes zhou eliminate concepts common example closet unied list concepts ease annotation process adopt pseudo labelling followed human correction specically image concept labels model pre trained object concepts model pre trained scene concepts ask human annotators separately individually correct automatically generated labels pseudo labels followed nding consensus set concepts image preprint march arrive nal annotation concept vectors image developed python gui tool ease pseudo label correction process plan release addition available generic human summaries augment dataset query focused preserving joint query focused privacy preserving summaries image collection specically design uni concept concept queries private sets image collection cover different cases like concepts belonging image concepts belonging different images concept image collection similar spirit sharghi ask group human annotators different annotated concepts create human summary images image collection query private pair ensure gold standard summaries followed verication round specically asked annotators accept reject summaries produced discarded human summaries rejected human annotators instantiate prism tsum represent images probabilistic feature vector taken output layer model redmon farhadi pre trained open images dataset kuznetsova concatenate probability vector scenes output layer zhou trained dataset zhou queries sets concepts mapped similar feature space hot vectors number concepts query facilitate image query similarity images queries elements private set represented vector universe concepts complex queries methods learning joint embedding text images employed chose simpler alternatives stick main focus area work initialize parameters randomly train mixture model epochs tschiatschek use rouge max margin learning discussed section update parameters nesterov accelerated gradient descent
