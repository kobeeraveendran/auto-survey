dialogue discourse aware graph convolutional networks abstractive meeting summarization xiachong feng xiaocheng feng bing qin xinwei geng ting liu research center social computing information retrieval harbin institute technology china xiachongfeng xcfeng qinb xwgeng hit edu abstract sequence sequence methods achieved promising results textual abstractive ing summarization different documents like news scientic papers meeting naturally dialogue specic structural formation previous works model meeting sequential manner ing rich structural information develop dialogue discourse aware graph convolutional networks dda gcn meeting summarization utilizing logue discourse dialogue specic structure provide pre dened tic relationships utterance rst transform entire meeting text dialogue discourse relations discourse graph use dda gcn encode semantic representation graph finally employ recurrent neural network addition utilize erate summary question answer discourse relation struct pseudo summarization corpus pre train model mental results ami dataset model outperforms baselines achieve state art performance c e d l c s c v v x r figure example meeting sponding summary id short industrial designer ui user interface pm project manager summary generated sentence gated goo chen models utterances tially summary generated dda gcn models utterances incorporating dialogue discourse introduction automatic summarization fundamental task natural language generation computational guistics crucial help user quickly read understand daily events uously studied decades paice kupiec et al paper focus meeting summarization extensively studied task eld automatic summarization given tiple speakers corresponding utterances text task calls generating shorter transcript covering salient information entire meeting example shown figure includes speakers utterances human written summary meeting summarization typically regarded kind abstractive summarization problem literature majority existing studies build summarization systems based sequence sequence model adopts sequence eling strategy encoding utterances goo chen ganesh dingliwal liu et al li et al zhu et al despite id like power cradle ui neat little sexy design cradle remote pm increase cost pm change end cost parts meetingground truth summarythe industrial designer proposed including battery charging stand device decided useful feature sentence gatedthe industrial designer research necessary power cradle device gcnthe industrial designer presented design power cradle project manager decided useful effectiveness approaches typically use sequential text information ing important inuences dialogue structure claim dialogue specic structural tion important meeting summarization example dialogue discourse effective tural feature shown figure contrast question answer continuation dialogue discourse relations provide precise semantic relationships utterance specically existing sequence modeling method unable generate correct summary results shown figure attributed system knowing opposed s proposal differently dialogue discourse provide key information labeling contrast tionship shown figure accordingly effectively integrate discourse ship existing summarization model crucial step meeting summarization paper propose dialogue aware graph convolutional networks gcn address problem detail rst convert entire meeting dialogue discourse labeling discourse graph represents utterances discourse relationships tices additionally design types directed edges global vertex course graph facilitate information ow nally employ graph convolutional network schlichtkrull et al encode graph pass semantic representation rnn decoder use answer discourse relationship construct summarization corpus pre training dda gcn conversation question sparks sion naturally question pseudo summary subsequent discussions conduct experiments widely ami benchmark carletta et al proach outperforms baselines analyze effectiveness dialogue discourse pseudo summarization corpus end brief summary contributions best knowledge rst ply dialogue discourse model structure meeting meeting summarization design discourse aware graph model encode entire meeting model achieves new sota ami dataset figure levi graph transformation background section rst describe task tion meeting summarization brief introduction dialogue discourse levi graph task denition meeting summarization task aims producing summary y input meeting u u consists utterances y consists words terance meeting represented quence words ui ui j denotes j th word th utterance utterance ui associates speaker pi p p set participants dialogue discourse dialogue discourse indicates relations discourse units conversation utterances meeting different constituency based discourse structures rhetorical structure theory rst mann thompson dependency based structure allows relations tween non adjacent utterances applicable multi party conversions discourse relations total comment clarication question elaboration acknowledgment continuation nation conditional question answer alternation question elaboration result background tion correction parallel contrast levi graph graph transformed levi graph levi gross et al turning labeled edges additional vertices let g v e r denote directed graph corresponding levi graph dened gl vl el rl vl v e order facilitate information ow graph previous works marcheggiani titov beck et al dene types edges reverse self refer original forward direction new reverse tion self loop direction separately approach encode utterances relations way example shown figure vivjrvivjrdefaultreverseselflevi graphoriginal graph figure illustration discourse graph discourse graph construction section rst notation course graph describe details discourse graph construction process example discourse graph shown figure notation let gd vd ed rd denote discourse graph vertices vi vd labeled edges vi r vj ed r rd relation type edge comes default discourse default discourse reverse discourse reverse discourse global self dialogue discourse aware graph convolutional networks section describe details logue discourse aware graph convolutional works dda gcn consists nents utterance encoder graph encoder pointer decoder model shown figure discourse graph vertex representation given meeting corresponding dialogue discourse construct discourse graph based levi graph transformation described tion types vertices cluding utterance vertices edge vertices example edge continuation original graph default tion continuation default levi graph note different types vertices different features fall different space beck et al specically previous works ignore type source target vertices use type edge pass information default reduce ness discourse information end propose discourse graph transforms default edge default discourse discourse edges shown figure reverse edges reverse discourse reverse discourse edges shown figure furthermore aggregate non local information global vertex added connects tices global edges ize decoder shown figure finally types relations rd global vertex relation vertices obtain initial representation looking embedding table utterance vertices ploy bilstm utterance encoder updates hidden state received word sequentially hi j bilst m hi j hi j ei j denote hidden state embedding word ui j respectively party conversation speaker additionally plays important encode speaker pi hot vector ei j concating responding word embedding hot speaker embedding concatenation forward backward nal hidden states utterance coder indicated representation input graph encoder graph encoder getting initial feature vertex vi vd feed graph encoder digest structural information use tional graph convolutional networks schlichtkrull et al capture high level hidden features considering different types edge lution computation vertex vi l answercontinuationexplanationdefault discoursedefault discoursereverse discoursereverse discourseggg figure illustration dda gcn model utterance encoder encodes utterance meeting hidden vectors graph encoder performs convolutional computation discourse graph pointer decoder attends updated utterance representations word representations generate summary words xed length vocabulary copy input layer takes representation l th layer input dened relu w l r j r nr vi denotes set neighbors tex vi relation r w l r denotes specic learnable parameters l th layer uniformly accepting information different discourse relations suitable tifying important discourse shown figure contrast important answer use gate mechanism marcheggiani titov control formation passing j sigmoid w l r g j w l r g denotes learnable parameter relation type r l th layer equipped gate mechanism convolution computation dened relu w l r j j r pointer decoder use standard lstm decoder attention copy mechanism generate summary bahdanau et al et al global representation described section initialize decoder step t coder receives word embedding previous word decoder state st attention bution calculated luong et al consider word level attention level attention word level context vector hwl t computed j j et hwl t j j wa learnable parameter j obtained utterance encoder ui j utterance level context vector hul calculated t ilarly word level context vector use nal outputs graph encoder represent utterances calculate attention distribution nal context vector nation word level utterance level context vector h late generation probability nal probability distribution et al t hwl t training objective use maximum likelihood training train model given ground truth summary y y input meeting u y y copyutterance encodergraph encoderpointer decoderfinal attentionutterance experiments dataset evaluate model ami ing dataset carletta et al participants play different roles design team including project manager marketing expert industrial designer user interface designer remote control design project kick completion preprocess divide dataset training meetings ment meetings test meetings sets shang et al current meeting summarization dataset dialogue course annotation dialogue discourse meeting based deep sequential shi huang sota dialogue discourse parser trained stac corpus asher et al implementation details model mension hidden states set encoder decoder use dimensional glove vectors pennington et al updated training train adam kingma ba learning rate gradient clipping maximum gradient norm vocabulary size set dropout rate set test process beam size set pre training stop training model converges pseudo data discourse parser use default rameters vocabulary size set evaluation metrics adopt standard metrics rouge lin evaluation obtain scores l measures word overlap bigram overlap longest common sequence truth generated summary respectively package evaluate mance model baseline models compare model eral baselines including extractive abstractive methods textrank mihalcea tarau graph based extractive method selects portant sentences input document cheng lapata extractive method based sequence sequence framework decoder receives sentence embeddings puts sentence labels summarunner nallapati et al extractive method based erarchical rnn iteratively constructs mary representation predict sentence labels com shizhouxing dialoguediscourseparsing python org pypi figure instance pseudo summarization data samples mize negative log likelihood target words sequence l log p t y u pre training section introduce struct pseudo summarization corpus based question answer discourse relation pre train model given meeting corresponding discourse relations nd question sparks cussion shown figure user interface asked s standard colour ipants start discuss small topic view discussion small meeting question pseudo summary small meeting according observation collect pseudo summarization data meeting marization dataset question identied dialogue discourse serves pseudo summary n utterances experiments n question serve pseudo input detail uninformative normal questions suitable pseudo summarization corpus construction lter questions contain noun adjective pseudo data cleaner given pseudo corpus rst pre train model ne tune meeting marization dataset motivations fold potentially augment training data pseudo data constructed meeting summarization dataset pre training model warm start different colour standard colour got different colours standard colour colours going black black black standard black standard yellow regular remote colour want different silver dark grey like colour different covers use silver better silver nowadays silver black id ui pm ui pm ui mewhat standard colour ui meetingpseudo summarywhat standard colour uiwe different colour standard colour got different colours standard colour colours going black black black standard black standard yellow regular remote colour want different silver dark grey like colour different covers use silver better silver nowadays silver black id ui pm ui pm ui mepseudo inputdiscussion colorquestion color erank shang et al unsupervised stractive method generates summaries combining approachs pointer generator et al abstractive method equips copy mechanism decoder erate vocabulary copy hred serban et al hierarchical sequence sequence model composed word level lstm sentence level lstm sentence gated goo chen stractive method incorporates dialogue acts sentence gated mechanism topicseg li et al abstractive method archical attention mechanism levels topic utterance word hmnet zhu et al abstractive method incorporates speech entity information pretraining scale news summary data ne tuning meeting datasets automatic evaluation dda gcn table stands model based discourse graph pre trained pseudo summarization data dda gcn pre train stands model rectly trained meeting summarization dataset dda gcn pre stands model based levi graph pre training dda gcn zero shot means directly testing pre trained model meeting summarization test set model dda gcn outperforms baselines compared dda gcn model dda gcn pre train achieves better performance indicates effectiveness taking type source target vertices account pre training summarization data model dda gcn boost performance large margin achieves improvement rouge l pared dda gcn pre ditionally dda gcn zero shot achieves basic effect indicates effectiveness pseudo data model textrank summarunner corerank pointer generator hred sentence gated topicseg hmnet dda shot dda gcn pre train pre r l table test set results ami meeting dataset ing rouge short r l rouge l dg short discourse graph human evaluation assess quality generated maries conduct human evaluation study paring summaries generated model lines choose metrics uency flu grammatical problems relevance rel consistent original input informativeness info preserves meaning expressed truth hired graduates passed mediate english test familiar summarization tasks perform human tion asked rate summary scale worst best metric results shown table model flu rel info ground truth summarunner pointer generator sentence gated dda gcn pre train table human evaluation results et al proposed model named incorporating vision features multi modal setting paper compare model baselines textual features model increases performance tomatic evaluation metrics entails better human evaluation scores method achieves higher scores evaluation rics compared baselines dda gcn signicant improvement informativeness indicates pre training help model select key information dda gcn pre train scored better dda gcn uency argue ference pseudo summary ground truth summary pre training impact language model decoder ground truth obtained signicant high scores pare model generated summaries indicating challenge task analysis effect dialogue discourse verify effectiveness dialogue discourse randomly provide parts discourse lations model test process sults shown figure dialogue discourse higher rouge l score indicates discourse good summary generation given discourse formation model gets similar scores compared hred serban et al models utterances sequentially figure rouge l score respect age dialogue discourse furthermore verify importance discourse relation type test model giving different discourse relations results shown figure contrast acknowledgement important discourse relations attribute fact relations strongly indicate change viewpoint inuences meeting information ow analysis effect pseudo summarization data study effectiveness summarization data instead questions figure rouge l score respect dialogue course relations model r l pre train rule based discourse based table results pre training dda gcn different types pseudo summary data identied dialogue discourse pseudo maries extract questions following rules utterances begin wh words utterances end question mark pseudo data discourse based rule based according way question obtained rst pre train model types pseudo data arately ne tune ami dataset results shown table pre training discourse based data better rule based data demonstrating effectiveness dialogue discourse pre training rule based data achieves good result indicates rationality pre training strategy analysis case study table shows example summary generated different models visualization ance attention weights generating mary darker color higher weight sentence gated goo chen focuses second utterance terance shown table second mainly talks fruit shape leads omission keyword vegetable differently observe model pays tion rst utterances form lpercentage dialogue discourserouge elaborationcontinuationnarrationquestion answer correctionelaborationclarification questionparallelresultalternation ground truth marketing expert presented trends remote control market fruit vegetable spongy material trends fashion pointer generator discussed possibility fruit fruit fruit sentence gated need incorporate fruit theme design remote buttons included fruit vegetable theme shape remote control dda gcn table example summaries generated different models utterance attention weights visualization dda gcn sentence gated contrast discourse structure shown table mention fruit vegetables help model generate correct summary contains keywords related work meeting summarization previous works focused extractive meeting summarization xie et al recent study shows meeting marization people prefer abstract summaries extracted ones murray et al shang et al proposed unied framework fully pervised abstractive meeting summarization goo chen incorporated dialogue acts indicate effect utterances ganesh wal crf tag utterance course label remove utterances contribute meeting based rules liu et al incorporated topic information serves coarse grained structure meeting li et al proposed hierarchical model der multi modal setting incorporating vision features liu et al generated summary stage manner rst producing sequence keywords summary zhu et al use large scale news datasets rst pretrain model ne tune ing dataset koay et al revealed domain terminology substantial impact meeting summarization performance paper rst propose transform utterances meeting graph dialogue discourse graph sequence generation recent research efforts text generation consider utilizing graph neural networks gnn better model structured data amr beck et al ribeiro et al sql xu et al edge graph koncel kedziorski et al ditionally works employed gnn non structural scenarios summarization yasunaga et al fernandes et al tognini faltings comment tion li et al transforming input meaningful graph propose discourse graph facilitate information ow graph conclusions paper apply dialogue discourse model structure meeting meeting marization rst transform entire meeting text corresponding dialogue discourse relations discourse graph specically ances discourse relations constructed tices design types edge global vertex facilitate information ow develop dialogue discourse aware graph convolutional networks dda gcn sists utterance encoder graph encoder pointer decoder addition construct summarization corpus utilizing answer discourse relation train model experiments ami dataset effectiveness model achieve sota performance fashion trends people want sort clothes shoes things fruit vegetables theme start making buttons fruit shaped complicated use fruit vegetables popular moment know fickle fashion markets realistic remote control market thing takes kinds fashion trends marketing expertuser interfaceproject managerproject references diego antognini boi faltings learning create sentence semantic relation graphs proceedings document summarization workshop new frontiers summarization pages hong kong china association computational linguistics nicholas asher julie hunter mathieu morey farah benamara stergos afantenos discourse structure dialogue acts multiparty dialogue stac corpus dzmitry bahdanau kyunghyun cho yoshua gio neural machine translation jointly arxiv preprint learning align translate daniel beck gholamreza haffari trevor cohn graph sequence learning gated graph neural networks annual meeting association putational linguistics volume long papers pages melbourne australia association computational linguistics proceedings jean carletta simone ashby sebastien bourban mike flynn mael guillemot thomas hain jaroslav kadlec vasilis karaiskos wessel kraaij melissa kronenthal al ami meeting corpus pre announcement international workshop machine learning multimodal interaction pages springer jianpeng cheng mirella lapata neural marization extracting sentences words proceedings annual meeting sociation computational linguistics volume long papers pages berlin germany sociation computational linguistics patrick fernandes miltiadis allamanis marc brockschmidt structured neural tion arxiv preprint prakhar ganesh saket dingliwal tive summarization spoken written tion arxiv preprint chih wen goo yun nung chen stractive dialogue summarization gated modeling optimized dialogue acts ieee spoken language technology workshop slt pages ieee jonathan l gross jay yellen ping zhang handbook graph theory chapman hall crc diederik p kingma jimmy ba adam method stochastic optimization arxiv preprint jia jin koay alexander roustai xiaojin dai dillon burns alec kerrigan fei liu domain terminology affects meeting summarization proceedings performance national conference computational linguistics pages barcelona spain online national committee computational linguistics rik koncel kedziorski dhanush bekal yi luan mirella lapata hannaneh hajishirzi text generation knowledge graphs proceedings graph transformers conference north american chapter association computational linguistics human language technologies volume long short papers pages minneapolis minnesota association computational linguistics julian kupiec jan pedersen francine chen trainable document summarizer advances tomatic summarization pages friedrich wilhelm levi finite geometrical tems public lectues delivered february university calcutta university cutta manling li lingyu zhang heng ji richard j radke meeting summaries topic abstractive multi modal meeting summarization proceedings association computational linguistics pages florence italy association tational linguistics annual meeting wei li jingjing xu yancheng shengli yan fang wu xu sun coherent ments generation chinese articles sequence model proceedings nual meeting association computational linguistics pages florence italy ciation computational linguistics chin yew lin rouge package matic evaluation summaries text tion branches pages barcelona spain association computational linguistics chunyi liu peng wang jiang xu zang li jieping ye automatic dialogue summary generation customer service proceedings acm sigkdd international conference knowledge discovery data mining pages acm zhengyuan liu angela ng sheldon lee ai ti aw nancy f chen topic aware generator networks summarizing spoken sations arxiv preprint minh thang luong hieu pham christopher d manning effective approaches based neural machine translation arxiv preprint william c mann sandra thompson rhetorical structure theory functional ory text organization text interdisciplinary nal study discourse guokan shang wensi ding zekun zhang toine tixier polykarpos meladianos michalis giannis jean pierre vised abstractive meeting summarization sentence compression budgeted submodular maximization nual meeting association computational linguistics volume long papers pages melbourne australia association tational linguistics proceedings zhouxing shi minlie huang deep tial model discourse parsing multi party logues proceedings aaai conference articial intelligence volume pages shasha xie yang liu hui lin ating effectiveness features sampling ieee extractive meeting summarization spoken language technology workshop pages ieee kun xu lingfei wu zhiguo wang yansong feng vadim sheinin sql text generation proceedings graph sequence model conference empirical methods ural language processing pages sels belgium association computational guistics michihiro yasunaga rui zhang kshitijh meelu ayush pareek krishnan srinivasan dragomir radev graph based neural multi document summarization proceedings ence computational natural language learning conll pages vancouver canada association computational linguistics chenguang zhu ruochen xu michael zeng dong huang hierarchical network stractive meeting summarization cross domain pretraining proceedings conference empirical methods natural language ing findings pages diego marcheggiani ivan titov coding sentences graph convolutional works semantic role labeling arxiv preprint rada mihalcea paul tarau textrank bringing order text proceedings conference empirical methods natural guage processing pages barcelona spain association computational linguistics gabriel murray giuseppe carenini raymond ng generating validating abstracts ing conversations user study proceedings international natural language generation conference pages association tational linguistics ramesh nallapati feifei zhai bowen zhou summarunner recurrent neural network based quence model extractive summarization ments chris d paice constructing literature abstracts computer techniques prospects information processing management jeffrey pennington richard socher christopher manning glove global vectors word resentation proceedings conference empirical methods natural language ing emnlp pages doha qatar ciation computational linguistics leonardo f r ribeiro claire gardent iryna gurevych enhancing amr text tion dual graph representations ings conference empirical methods natural language processing national joint conference natural language cessing emnlp ijcnlp pages hong kong china association computational guistics michael schlichtkrull thomas n kipf peter bloem rianne van den berg ivan titov max welling modeling relational data graph tional networks european semantic web ence pages springer abigail peter j liu christopher d manning point summarization generator networks proceedings nual meeting association computational linguistics volume long papers pages vancouver canada association tional linguistics iulian v serban alessandro sordoni yoshua bengio aaron courville joelle pineau building end end dialogue systems generative archical neural network models thirtieth aaai conference articial intelligence
