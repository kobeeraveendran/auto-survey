train agent read write mengge guanghui mingkui school software engineering south china university technology pazhou laboratory university adelaide key laboratory big data intelligent robot ministry education seliushiya semenggehe scut edu edu edu abstract reading writing research papers leged abilities qualied researcher master difcult new researchers students fully grasp ability fascinating train intelligent agent help people read summarize pers discover exploit potential knowledge clues write novel papers existing works focusing summarizing reading knowledge given text generating writing text based given knowledge ability ously reading writing development cally requires agent fully understand knowledge given text materials generate correct ent novel paragraphs challenging practice paper propose deep reader writer draw network consists reader extract edge graphs kgs input paragraphs discover tial knowledge graph text writer generates novel paragraph reviewer reviews generated graph different aspects extensive experiments draw network outperforms considered lines state art methods agenda agenda datasets code supplementary leased com menggehe draw introduction currently hundreds papers published online day small topics study wang shows scientists read papers year average researchers exhausted following sharply increased numbers papers standing research coming new ideas write novel papers gopen buenz practice writing novel papers requires abilities reading reasoning ability creative thinking nontrivial fresh researchers xiao fantastic agent help people especially authors contributed equally corresponding author copyright association advancement articial intelligence www aaai org rights reserved figure intuitive understanding draw network draw network reads multiple related works discovers potential knowledge writes new paragraph based knowledge graph reviews output uses feedback rewards improve quality writing new researchers read write building agent encounters challenges understand multiple related works agent needs capture complex logic related works trivial knowledge extraction methods min gerber chai yoshikawa achieve identifying entities texts extracting ships entities representing knowledge graph trouble covering potential connections entities hampers comprehensive understanding related works second generating agent required decode uent novel paragraph practice evaluate quality generated texts accurately open problem existing methods kedziorski wang adopt forcing scheme aims match tokens generated texts tokens target texts methods related workswriteknowledge graphnew paragraphscores focus token level matching ignoring level graph level evaluation generated texts paper propose method named deep writer draw draw network able read multiple texts discover potential knowledge write novel paragraph figure draw network consists reader writer reviewer modules cally reader rst extracts kgs research texts discovers potential knowledge enrich kgs reader considers multi hop neighborhood predict new links conceptual nodes writer writes novel paragraph describe main idea enriched kgs graph attention network aggregates global local graph information inspired review process research papers propose reviewer module evaluate quality generated paragraphs return rewards feedback signals rene writer specic given generated paragraph reviewer output feedback signals including quality reward reects metric scores generated paragraph adversarial reward denotes probability generated paragraph passing turing test alignment reward represents matching score tween generated paragraphs enriched kgs way writer able write better paragraphs clearly represent key idea enriched kgs summary main contributions threefold propose deep reader writer draw network reads multiple research texts discovers potential knowledge write novel paragraph covering key idea source inputs propose feedback mechanism review generated paragraph consistent enriched generated paragraph human written greatly improving quality paragraph tion extensive experiments writer reviewer leads signicant improvements kgs text eration task outperforms state art methods related work automatic writing paperrobot wang forms automatic research assistant incrementally write chemical related research datasets enriches kgs predicting links input papers kgs according given title selects entities related title enriched kgs generate texts robot neglects consider multi hop neighborhood predict links important capturing potential relationships addition generated texts closely align kgs address use graph attention network consider multi hop neighborhood capturing complex hidden information inherently plicit neighborhood design reviewer measure quality generated text different mensions effectively align kgs particular draw network different multi document mary ling hui compresses lengthy document content relatively short paragraphs extract important knowledge discover potential knowledge multiple paragraphs predicting links writing novel paragraph link prediction translation based approaches zhen lin widely link prediction result poor representation ability recently cnn based models dettmers nguyen proposed relation prediction methods focus entity neighborhood considering relationships nodes methods kipf welling schlichtkrull relationships entities hop neighbors consideration omit information multi hop neighborhood instead pose reader module capture semantic information multi hop neighborhood graph text task graph text active research area works generate texts based structured edge trisedya feng neural graph text models use different coders based gnn ribeiro gardent gurevych zhijiang huang vaswani architectures learn graph representations koncel kedziorski proposes novel graph transformer encoder leverages topological structure kgs generate texts ignores global graph information important text tion solve ribeiro introduce novel architecture aggregates global local graph information generate texts encoder decoder framework presents problems word repetition lack diversity solve issues propose reviewer module review generated paragraphs rene quality paragraphs feedback rewards reviewer consists modules review evaluate generated paragraphs real align given kgs order improve text generation ability proposed method paper focus generating novel paragraphs reading multiple related paragraphs end pose deep reader writer draw network consists modules reader writer reviewer shown figure understand sort textual logic given paragraphs reader rst reads extracts knowledge graphs kgs considering multi hop neighborhood reader predicts new links conceptual nodes potential knowledge enrich kgs writer adopts graph encoder encode rich semantic information kgs delivers text encoder generate novel paragraph inspired adversarial learning cao wang cao chen devise reviewer evaluate quality generated paragraph serves feedback signal rene writer relate details modules following sections figure overview deep reader writer draw network draw network consists modules reader writer reviewer given multiple related works reader rst extracts knowledge construct initial knowledge graphs kgs performs link prediction enrich kgs based enriched kgs writer captures global local topology information graph encoder generates novel paragraph text decoder particular reviewer employs feedback modules measure quality generated paragraph reader text graph extract textual logic given related paragraphs use standard sciie luan science domain information extraction system constrcu edge graphs specically output sciie system list triplets triplet consists entities corresponding relation knowledge graph noted node set edge set represents number nodes represent extracted entities relations respectively initial knowledge graph exploit potential knowledge address perform link prediction predict new links entities based initial kgs link prediction given kgs obtain entity bedding relation embedding rij separated embedding layers feature sion formally given entity embedding relation embedding rij triplet represented rij aggregate information introduce auxiliary edges entity hop hood entity hop neighborhood sum embeddings relations path auxiliary relation embedding apply linear formation update entity representation rij trainable parameter denotes catenation operation particular entity involved multiple triplets neighborhood denoted denotes neighborhood entity learn importance triplet entity apply self attention calculate attention weights follows exp exp help attention weights update feature fusing information neighborhood trainable parameter sigmoid function based original relation feature rij apply ear transformation obtain updated relation embedding rij updating node relation embeddings need determine relationship given entities intuitive way calculate ability triple following convkb nguyen train scoring function perform relation prediction follows denotes convolution operation set convolution lters linear transformation layer following nathani assign score triplet eqn indicates probability triplet holds entity rst traverse entities relationships construct triples select triplet highest score new link way reader capture potential relations different nodes derive new graph finally denote enriched knowledge graph writer graph text based enriched graph entities propose writer generate novel paragraphs consists bcedafhggraph encoderwriter related workstext decoderbcdaafefhgknowledge graphreaderrewardrevieweralignmentmoduleadversarialmodulequalitymodulenew paragraphreading writing researchpapers recently consider task paper propose anew paper consider graph encoder text decoder specically writer rst uses graph encoder extract knowledge resentations writes new paragraph text decoder vaswani graph encoder comprehensive understanding rst step generate desired paragraph difcult directly capture rich semantic information knowledge graph address extract edge representations sub encoders graph encoder local graph encoder following cge ribeiro integrate global context information local topology information generate new paragraphs aggregate global context information rst nate node features feed graph encoder follows standard transformer encoder vaswani contains multi head self attention layers feed forward networks global graph encoder treat knowledge graphs fully connected graph labeled edges based self attention mechanism global graph encoder suitable discovering global correlation nodes node ability capture nodes information better represent interaction nodes need build local relations node hood global graph encoder explicitly consider graph topology information address use local graph encoder model local relations node rst calculate attention weights adjacent nodes different types relationships considerable discrepancies impact fusing tion based attention weights obtain hidden node features aij rij jni jni aij denotes model parameters denotes hidden features encode local interaction node neighborhood denotes bourhood node perform multi head attention operation learn structural information ferent perspectives employ gru cho merge local information different layers follows nal node representation text decoder based node representations use standard transformer decoder vaswani generate novel paragraph words auto regression manner step text decoder consumes previously generated tokens additional input outputs probability candidate vocabularies train writer supervised learning follows lsl ground truth hot vector step generates words selecting element highest score step practice text decoder use sequence generation models lstm hochreiter schmidhuber reviewer feedback rewards encoder decoder framework great progress sequence generation tasks including text rization image captioning suffers problems training sample framework tends use word ground truth generation step candidate words reasonable leads lack diversity generated text language complex requires evaluate quality generated paragraph different dimensions grammatical correctness topic relevance language logic coherence inspired review process research paper propose reviewer module review generated paragraph different dimensions output reviewer auxiliary training signal optimize writer similar researchers polishing paper based reviews specically design feedback rewards viewer use metric scores generated graph reward meet rules metrics second train turing test discriminator determine paragraph generated agent written human draws idea adversarial training requires paragraph conform natural language cation design alignment module align generated paragraphs corresponding enriched edge graphs ensures correctness completeness generated texts different teacher forcing ods reviewer focuses sentence level graph level alignment given generated paragraph evaluation processes non differentiable discussed seqgan discrete signals limited passing gradient update reviewer writer address denote outputs reviewer rewards maximize expectation rewards reinforcement learning formally goal reviewer represented max denotes trainable rameters model paragraph generated writer based generation probability specically reward function denoted correspond modules reviewer control contribution corresponding reward following policy gradient ods williams schulman solve problem batch training follows lrl logp logp training batch size introduce reward modules detail quality reward given generated paragraph calculate quantitative metrics meteor denkowski lavie cider vedantam zitnick parikh directly metrics training reward boost sentence generation quality paper simply adopt bleu score reward bleu score popular automated inexpensive metrics practice bleu replaced metric needs optimized adversarial reward based paragraph ule acts discriminator determine manual annotation real generated machine fake ing use convolutional neural network cnn extract text features capture sequence information shown exhibited high performance complicated sequence classication task zhang cun specically given generated paragraph rst concatenate token embedding text tion use different numbers kernels different window sizes extract different features text sentation produce new feature map applying max pooling operation perform fully connected layer sigmoid activation output probability notes probability input text real calculation formulated inspired adversarial training cao module aims minimize performance gap humans writer alignment reward paragraph supposed align enriched generated writer according sense propose compute similarity based attention mechanism given abstract words rst use long short term memory lstm extract text representation following attngan obtain hidden representation follows softmax trainable parameters scaling factor rdn node features obtained writer help self attention nism vaswani hidden feature fuses text representations merges graph formation calculate cosine similarity ing score follows far obtain rewards reviewer modules finally train draw network dene overall training loss follows lsl lrl trade parameter lsl trains draw network supervised learning lrl allows draw network explore diverse generation ment learning evaluate generation multiple entations experiments datasets agenda dataset agenda popular kgs text datasets concludes pair samples collected proceedings conferences sample consists title abstract sponding extracted sciie system composed recognized scientic terms tionships particular types scientic terms include task metric method material types tionships include conjunction feature compare evaluate hyponym agenda dataset demonstrate tiveness draw network create new dataset called agenda specically rst calculate sine similarity abstract agenda dataset select related instances combine new data example agenda dataset experimental settings implementation details draw network consists design modules reader writer reviewer rst train reader writer reviewer agenda dataset use trained reader writer model agenda generate novel paragraphs speed convergence early training adopt different ing strategies module reader rst use bordes train entity relation dings aggregate information passed hop neighborhood update embedding node ing nathani use adam optimization initial learning rate writer pre train epochs early stopping following ribeiro use adam optimization initial learning rate ensure generation effect set maximum generation length reviewer pre train adversarial module sgd optimization initialize learning rate pre training graph encoder alignment module use model rameters writer addition systematically adjust values conduct ablation studies experimental results different coefcient combinations uctuate causing little effect results writer reviewer obtains best results set trade parameter implement method pytorch model graphwriter graformer cge writer reviewer bleu meteor cider model writer writer reviewer bleu meteor cider table quantitative evaluations generation systems agenda dataset higher better table ablation study modules reviewer agenda dataset paragraph turing test results human machine written human written draw table quantitative results turing test model paperrobot cge draw grammar coherence informativeness table automatic evaluations results higher better evaluation metrics demonstrate quality erated paragraphs report quantitative results human study results divide evaluation parts kgs text evaluation overall performance evaluation kgs text evaluations adopt general titative evaluation metrics bleu papineni meteor denkowski lavie cider tam zitnick parikh evaluate reviewer addition demonstrate realness paragraphs generated model set ing test specically randomly select abstracts shufe evaluation set half stracts written authors rest generated writer reviewer test turkers amazon mechanical turk amt determine paragraphs evaluation set written humans overall performance evaluation set human study rate abstracts generated draw network cge paperrobot model randomly select generated paragraphs score terms grammar informativeness coherence amazon mechanical turk amt specically metric grammar measures paragraphs written formed english metric informativeness denotes paragraphs use appropriate scientic terms metric herence denotes generated text conforms general specications example complete abstract clude brief introduction task describe solution analyze discuss results metric scribed contains levels rankings bad good following relation prediction task nathani evaluate link prediction method reader proportion correct entities ranks kgs text evaluation agenda dataset verify model kgs text task compare writer reviewer state art models cluding graphwriter koncel kedziorski graformer schmitt cge ribeiro agenda dataset results report results method compared models respect quantitative evaluation metrics table shown table writer reviewer achieves better performance compared models quantitative evaluation metrics specically reviewer outperforms state art method cge points bleu points meteor points cider results demonstrate superiority writer reviewer kgs text task addition carry human evaluation strate effectiveness writer reviewer specic paragraph evaluation set ask human choose paragraphs written authors results table nearly half paragraphs generated writer reviewer reviewed written humans critically paragraphs written humans chosen written system results demonstrate writer reviewer erate realistic paragraphs similar written humans ablation studies reviewer investigate effect different modules reviewer conduct ablation study shown table writer combined ules reviewer arbitrarily obtains better performance writer demonstrates effectiveness modules reviewer writer combined modules viewer writer reviewer achieves best performance evaluation agenda dataset effectiveness draw network duct experiments agenda dataset agenda dataset provide ground truth conduct human study instead quantitative evaluations specically metric human study average scores paragraphs rated humans nal score results draw report experimental results draw network compared methods table results draw network achieves best performance terms grammar coherence formativeness specically paperrobot wang initial kgs paperrobot entities relations global scene level contextual information spatial context recurrent convnet model wikipedia multilingual ner systems local image scriptors tion spatial congurations paper propose novel approach multilingual named entity recognition tasks proposed method based semantic similarity measure improve word retrieval performance wikipedia type words text documents build efcient query language model allows users similar information entities clusters different domains speech tags generated user document representation knowledge base system evaluated state art approaches trained object covering entities cge draw paper propose spatial context recurrent convnet model incorporate global scene level contextual information spatial context recurrent convnet model object retrieval contextual information candidate boxes object retrieval positional language model captures contextual information candidate boxes object retrieval proposed system evaluated tac kbp data experimental results proposed system signicantly improve entity linking performance covering entities paper propose novel approach entity based statistical language model based information exploits local contexts global world improve entity performance propose spatial context recurrent convnet model integrate global context features local image spatial congurations global scene level contextual spatial context recurrent convnet model recurrent network local global information guide search candidate boxes object retrieval covering entities table example outputs models better visualize generated text omit information irrelevant comparisons repetitive words represented red entities included kgs represented orange potential knowledge represented blue corresponding superscript method paperrobot table accuracy link prediction agenda dataset values percentage obtains poor performance neglect logical structure entities cge ribeiro takes advantage graph information effectively achieves points terms metrics ignores fact generated graphs supposed match kgs different methods draw network performs link prediction multi hop information reader matches graphs generated paragraphs achieves best performance ablation experiments reader found supplementary material results reader shown table report perimental results link prediction method reader paperrobot method achieves scores outperforming paperrobot points respectively demonstrates effectiveness link prediction method visualization analysis shown table visualize generated paragraph draw network ization results found supplementary material draw network ability cover entities represented orange paperrobot mentions entities given addition cge tends repeat unrelated entities sentences represented red help reviewer generated text draw network uent grammatically correct draw work able discover potential relationships entities represented blue superscript conclusions future work paper propose deep reader writer draw work reads multiple related abstracts writes new paragraph represent enriched knowledge combining potential knowledge covering topics mentioned source abstracts inspired review process propose reviewer rate quality generated texts ent dimensions serve feedback signals rene draw network ablation experiments demonstrate tiveness method writer reviewer achieves state art results kgs text generation task terms human study generations draw work successfully pass turing test confuse turkers future study extend draw network write complete paper iterative manner develop niques discover novel ideas creating new entities acknowledgments work partially supported key area search development program guangdong province national natural science foundation china nsfc key project program dong introducing innovative entrepreneurial teams international cooperation open project state key laboratory subtropical building science south china university technology fundamental research funds central universities references repulsive bayesian sampling diversied attention modeling workshop neurips bordes usunier garcia duran weston yakhnenko translating embeddings modeling multi relational data neurips buenz essential elements high impact tic writing nature doi cao guo shen huang tan adversarial learning local coordinate coding icml cao guo shen huang tan improving generative adversarial networks local coordinate coding ieee transactions pattern analysis machine intelligence cao zhang jia shen tan multi marginal wasserstein gan neurips chen zhang tan xiao huang gan generating visually aligned sound videos ieee trans image process cho merrienboer aglar glehre bahdanau bougares schwenk bengio learning phrase representations rnn encoder decoder statistical machine translation emnlp denkowski lavie meteor universal language specic translation evaluation target language acl dettmers minervini stenetorp riedel convolutional knowledge graph embeddings aaai feng jinpeng jin rong chin yew operation guided neural networks high fidelity data text generation emnlp gerber chai nombank study implicit arguments nominal predicates acl gopen science scientic writing american scientist hochreiter schmidhuber long short term memory neural computation huang chen zeng tan gan location aware graph convolutional networks video question answering aaai kipf welling semi supervised tion graph convolutional networks iclr koncel kedziorski bekal luan lapata hajishirzi text generation knowledge graphs graph transformers naacl hlt lin liu sun liu zhu ing entity relation embeddings knowledge graph completion aaai ling hui multi document summary lda spectral clustering computer engineering applications luan ostendorf hajishirzi multi task identication entities relations erence scientic knowledge graph construction emnlp min jie jian guodong ite kernel extract relations entities flat structured features acl nathani chauhan sharma kaul learning attention based embeddings relation tion knowledge graphs acl nguyen nguyen nguyen phung novel embedding model knowledge base completion based convolutional neural network naacl hlt papineni roukos ward zhu bleu method automatic evaluation machine translation acl ribeiro gardent gurevych enhancing amr text generation dual graph representations emnlp ijcnlp ribeiro zhang gardent gurevych modeling global local node contexts text generation knowledge graphs transactions association computational linguistics schlichtkrull kipf bloem berg titov welling modeling relational data graph convolutional networks eswc schmitt ribeiro dufter gurevych schutze modeling graph structure relative position better text generation knowledge graphs arxiv schulman wolski dhariwal radford klimov proximal policy optimization algorithms arxiv trisedya jianzhong rui wei lstm triple encoder sentence generation rdf data acl vaswani shazeer parmar uszkoreit jones gomez kaiser polosukhin attention need neurips vedantam zitnick parikh cider consensus based image description evaluation cvpr wang wang wang zhao zhang zhang xie guo graphgan graph tion learning generative adversarial nets aaai wang huang jiang knight bansal luan paperrobot incremental draft eration scientic ideas acl williams simple statistical gradient following algorithms connectionist reinforcement learning machine learning xiao wang jin copy rewrite hybrid summarization hierarchical ment learning aaai guo wang chen sheinin sql text generation graph sequence model emnlp zhang huang zhang gan huang fine grained text age generation attentional generative adversarial works cvpr yoshikawa riedel hirao asahara sumoto coreference based event argument relation extraction biomedical text journal biomedical tics zhang wang seqgan sequence generative adversarial nets policy gradient aaai zhang lecun text understanding scratch arxiv zhen jianwen jianlin zheng knowledge graph embedding translating planes aaai zhijiang yan zhiyang wei densely connected graph convolutional networks graph sequence learning transactions association computational linguistics references repulsive bayesian sampling diversied attention modeling workshop neurips bordes usunier garcia duran weston yakhnenko translating embeddings modeling multi relational data neurips buenz essential elements high impact tic writing nature doi cao guo shen huang tan adversarial learning local coordinate coding icml cao guo shen huang tan improving generative adversarial networks local coordinate coding ieee transactions pattern analysis machine intelligence cao zhang jia shen tan multi marginal wasserstein gan neurips chen zhang tan xiao huang gan generating visually aligned sound videos ieee trans image process cho merrienboer aglar glehre bahdanau bougares schwenk bengio learning phrase representations rnn encoder decoder statistical machine translation emnlp denkowski lavie meteor universal language specic translation evaluation target language acl dettmers minervini stenetorp riedel convolutional knowledge graph embeddings aaai feng jinpeng jin rong chin yew operation guided neural networks high fidelity data text generation emnlp gerber chai nombank study implicit arguments nominal predicates acl gopen science scientic writing american scientist hochreiter schmidhuber long short term memory neural computation huang chen zeng tan gan location aware graph convolutional networks video question answering aaai kipf welling semi supervised tion graph convolutional networks iclr koncel kedziorski bekal luan lapata hajishirzi text generation knowledge graphs graph transformers naacl hlt lin liu sun liu zhu ing entity relation embeddings knowledge graph completion aaai ling hui multi document summary lda spectral clustering computer engineering applications luan ostendorf hajishirzi multi task identication entities relations erence scientic knowledge graph construction emnlp min jie jian guodong ite kernel extract relations entities flat structured features acl nathani chauhan sharma kaul learning attention based embeddings relation tion knowledge graphs acl nguyen nguyen nguyen phung novel embedding model knowledge base completion based convolutional neural network naacl hlt papineni roukos ward zhu bleu method automatic evaluation machine translation acl zhen jianwen jianlin zheng knowledge graph embedding translating planes aaai zhijiang yan zhiyang wei densely connected graph convolutional networks graph sequence learning transactions association computational linguistics ribeiro gardent gurevych enhancing amr text generation dual graph representations emnlp ijcnlp ribeiro zhang gardent gurevych modeling global local node contexts text generation knowledge graphs transactions association computational linguistics schlichtkrull kipf bloem berg titov welling modeling relational data graph convolutional networks eswc schmitt ribeiro dufter gurevych schutze modeling graph structure relative position better text generation knowledge graphs arxiv schulman wolski dhariwal radford klimov proximal policy optimization algorithms arxiv trisedya jianzhong rui wei lstm triple encoder sentence generation rdf data acl vaswani shazeer parmar uszkoreit jones gomez kaiser polosukhin attention need neurips vedantam zitnick parikh cider consensus based image description evaluation cvpr wang wang wang zhao zhang zhang xie guo graphgan graph tion learning generative adversarial nets aaai wang huang jiang knight bansal luan paperrobot incremental draft eration scientic ideas acl williams simple statistical gradient following algorithms connectionist reinforcement learning machine learning xiao wang jin copy rewrite hybrid summarization hierarchical ment learning aaai guo wang chen sheinin sql text generation graph sequence model emnlp zhang huang zhang gan huang fine grained text age generation attentional generative adversarial works cvpr yoshikawa riedel hirao asahara sumoto coreference based event argument relation extraction biomedical text journal biomedical tics zhang wang seqgan sequence generative adversarial nets policy gradient aaai zhang lecun text understanding scratch arxiv
