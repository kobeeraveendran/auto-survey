user guided aspect classication domain specic texts peiran fang jingbo department computer science engineering university california san diego usa halcoglu data science institute university california san diego usa department computer science university illinois urbana champaign usa edu edu abstract aspect classication identifying aspects text segments facilitates numerous tions sentiment analysis review summarization alleviate human fort annotating massive texts paper study problem classifying aspects based user provided seed words pre dened aspects major challenge lies handle noisy misc aspect designed texts dened aspects domain experts culties nominate seed words misc aspect making existing seed driven text sication methods applicable propose novel framework arya enables mutual enhancements pre dened pects misc aspect iterative sier training seed updating specically trains classier pre dened aspects leverages induce supervision misc aspect prediction results misc aspect later utilized lter noisy seed words pre dened aspects experiments domains demonstrate superior performance proposed work necessity importance properly modeling misc aspect introduction aspect classication fundamental task text understanding aiming identifying aspects text segments facilitate ous downstream applications including sentiment analysis product review summarization stance understanding aspects product review sentences help deliver holistic summary product missing important pect angelidis lapata following supervised paradigm extract aspects requires extensive human effort ing massive domain specic texts aspects vary domains example restaurant reviews possible aspects include food service location comes laptop reviews aspects battery display fore alleviate effort study problem user guided aspect classication relies limited supervision small number seed words aspect major challenge problem lies handle misc aspect misc aspect designed capture types text segments makes noisy text segments specic aspects pre dened scope common real world text segments talking specic aspect favorite restaurants noisy nature domain experts difculties nominate seed words misc aspect making existing seed driven text tion methods agichtein gravano riloff kuipers tao meng applicable aim better incorporate misc aspect user guided aspect extraction intuitive crucial observations shed light development posed framework given text segment distribution pre dened aspects likely belongs misc aspect provides chance inducing supervision classier trained pre dened aspects ond given word strong indicator misc aspect unlikely good seed word pre dened aspect excluding words seed words pre dened aspects reduce ambiguity wise decision acknowledging observations propose novel framework incorporating misc aspect systematic manner shown figure iterative framework alternatively training figure overview proposed framework arya enables mutual enhancements pre dened aspects misc aspect iterative classier training seed updating pre dened aspects help induce supervision misc aspect misc aspect helps lter noisy seed words pre dened aspects classier aspects updating seed words pre dened aspects arya specically rst train classier dened aspects based user provided seed words aspect classier induces supervision misc aspect based normalized entropy estimation enabling classier facilitates comparative sis updates seed words pre dened pects strong aspect indicative words predicted misc aspect information utilized ensure noisy words appear seed words pre dened aspects arya achieves mutual enhancements dened aspects misc aspect best knowledge rst tematically handle misc aspect user guided aspect extraction main contributions identify keystone user guided aspect extraction noisy misc aspect develop arya based intuitive servations making pre dened aspects misc aspect mutually enhance experiments domains demonstrate superiority arya necessity ering misc aspect systematically reproducibility release code datasets github framework named arya stark game thrones kills night king bringing end white walkers wights forever com peiranli arya overview problem formulation given domain specic corpus text segments pre dened aspects small number seed words aspect vak paper aims build aspect classier domain specic text segments domain refers relatively consistent category products services hotel domain restaurant domain laptop domain paper assume specic aspect text segments practice segment text grained way ensure assumption holds words input text segment classier aims predict corresponding aspect label pre dened aspects number denoting focuses pre dened aspects framework arya iterative framework illustrated figure algorithm iteration apply following steps order pseudo label generation given seed words aspects generate aspect pseudo bels text segments raw corpus classier training train aspect based generated pseudo labels framework compatible text classiers illustration choose use cnn paper brief neural architecture self contained purpose thisismyfavoriterestaurantaspect seed wordsfoodservice foodspicypizzasushitastytipswaitressmanagerwaitservers text pseudo labelgenerationusing multi head attentions foodservice classifier trainingconvolutional seed tuning expansion miscaspect handling aspect labelsk aspect labelsfoodservice food spicy pizza sushi tasty steak noodle tips waitress manager wait servers fast courteous algorithm overall algorithm input corpus text segments user provided seed words pre dened aspects vak output classier train word embedding seed words converged compute aspect embedding aspect supervision train aspect classier sec supervision tune expand lter seed words sec return classier misc aspect handling leverage tions trained aspect classier produce pseudo labels misc aspect train new classier makes end end aspect extraction seed tuning expansion filtering conduct comparative analysis compare contrast text segments projected ent aspects new discriminative seed words aspect misc aspect lized lter noisy seed words pre dened aspects discuss details major components following sections basic notations notations text segment consists quence tokens number tokens note token includes single word words punctuation multi word phrases battery life chocolate cake subword pieces tokens pre processed raw texts applying tokenization phrasal segmentation shang let vocabulary set tokens token denote dimensional embedding vector embedding representation matrix text segment dened concatenating row vector pseudo label generation generate pseudo labels following multi head attention mechanism attention head focuses specic aspect helps model focus aspect indicative words ignore evant ones derive aspect oriented tation outputs attention heads nally aggregated derive prominent aspect text segment assume user provided seed words characterize aspect semantics compute aspect representation averaging embedding seed words wvaj higher embedding similarity word aspect implies word closely related aspect paid greater attention given word tion weight dened maximum similarity aspects text segments usually short use erage tokens following attention weights aspect oriented representation max wsi wsi based similarity text segment representation aspect representation derive pseudo label assignments normalize label distribution aspects aspect classier training framework generally compatible text classiers paper choose use cnn model multi head attention mechanism pseudo label generation viewed applying corresponding tional lters specically aspect tation equivalent convolutional lter window size mentioned ding representation matrix text segment feed cnn model illustrated figure specically employ lters window sizes ing grams tri grams grams assign higher pmisc hnorm higher propose leverage relu like function quantify pmisc based hnorm misc hnorm hnorm hnorm choose value quantile hnorm scores documents based figure quantile suitable pivot point specically figure values restaurant laptop datasets respectively getting combine misc misc finally obtain pseudo labels aspects including misc aspect train cnn classier seed tuning expansion filtering user provided seed words usually strong aspect indicator words ded raw input corpus helpful discover add words seed sets seed tuning word date seed word stopwords build candidate pool based aspect sier specically try replace word special unk token compute divergence prediction results given word exists text segment word leads divergence difference word didate intuition want prepare candidate pool high recall reasonable precision ranking ltering applied threshold fairly easy decide seed expansion expand seed sets ranking adding words candidate pool given aspect candidate pool mainly consider measurements indicative pseudo label generation cess viewed soft version string matching embedding want select words presence strongly indicate tain aspect mathematically want select word high posterior probability means given ence word likely text segment restaurant dataset laptop dataset figure hnorm distribution pmisc visualization apply lters input matrix add dropout layer convolutional layers viate finally use softmax layer transform output probabilities noting probability belonging aspect pseudo label distribution generated previous step serves supervision divergence loss log classication logic applies ing aspect classiers misc aspect handling aspect extraction types text segments long misc aspect text segments specic aspects different dened aspects text segments talking ing specic aspects text segments expected relatively distribution predictions aspect classier fore intuitive leverage normalized entropy hnorm measures chaotic tion estimate likelihood belonging misc aspect pmisc specically hnorm log shown figure plot distribution hnorm text segments restaurant laptop datasets easily observe large volume text segments low hnorm indicating belong pre dened aspects time misc aspect text segments follow long tail distribution large hnorm values ideally want classify text segments low hnorm values text text segmentspmisc table dataset statistics dataset unlabeled segments test segments restaurant laptop belongs aspect dene indicative measure table user provided seed words restaurant dataset default randomly sample seed words aspect run experiments aspect seed word list location drinks street convenient block avenue river subway neighborhood downtown bus drinks beverage wines margaritas sake beer wine list cocktail vodka soft drinks food food spicy sushi pizza tasty steak delicious bbq seafood noodle faj faj faj frequency word peared text segments aspect faj refers total text segments aspect frequency calculated based prediction results training set distinctive ideally seed word frequent aspect pose distinctive measure capture measures distinctive word aspect compared aspects faj scores different scales aggregate geometric mean shown effective comparative yses tao ranking aggregated score replace seed words aspect words seed filtering worth noting ranking heuristic applied misc pect observe highly ranked words misc aspect general words noisy words related multiple dened aspects checking examples restaurant dataset observe restaurant ranked high misc aspect appear text segments aspects word place ranked word misc aspect location related text segments appears frequently text segments like restaurant great place intuitively user lect word seed word location aspect fact noisy replacing seed words propose maintain new pool noisy words following ranking misc aspect exclude words pool seed words pre dened aspects experiments ambience romantic atmosphere room seating small spacious dark cozy quaint music service tips manager wait waitress servers fast prompt friendly courteous attentive methods explore effects number iterations number seeds case study seed word evolution presented datasets prepared review datasets rant laptop domains evaluation table presents statistics datasets found restaurant aspects rant dataset food service ambience drinks location training collected unlabeled restaurant reviews yelp dataset challenge laptop aspects dataset support display battery software keyboard mouse training unlabeled zon reviews laptop collected mcauley mcauley user provided seed words datasets ask domain experts provide seed words pre dened aspect table shows seed word list provided expert restaurant dataset default randomly choose seed words train models including baselines report average test results tricky aspect keyboard aspect laptop dataset collected seed words pre processing pre process corpus special characters redundant punctuations removed learn word embedding unlabeled training corpus com peiranli arya yelp com section empirically evaluate posed framework arya compared challenge table evaluation results restaurant laptop datasets precision recall scores averaged macro weighted manner underlines highlight best compared models restaurant laptop method precision recall precision recall cossim abae mate westclass dataless bert arya arya noiter arya notuning arya nofilter compared models compare model wide range line models described follows cossim assigns similar aspect text segment according cosine similarity average word embedding text segment average word embedding seeds aspect dataless song roth accepts aspect names supervision leverages wikipedia explicit semantic analysis esa derive vector representation aspects ments class assigned based vector similarity aspects documents abae unsupervised ral topic model extend abae ing user provided seed words aspect align topics pre dened aspects mate angelidis lapata tended version abae accepts seed information guidance replaces abae aspect dictionary seed matrices meng art weakly supervised text classication model accepts seed words supervision bert devlin powerful tualized representation learning technique use seed words matching majority voting generate sentence labels tune bert classication models care misc aspect systematically tune best compared method proposed aspect handling referred denote model arya addition ablated versions follows noiter uses proposed misc aspect handling technique generate probability misc pect based aspect classier steps arya notuning refers version model seed tuning nique divergence threshold seed word candidates arya nofilter model seed ltering technique noisy seed words removal pre dened aspects based misc aspect information experiment setup default parameters set word embedding dimension classier training number epoch training error tends converge epochs gence threshold seed tuning set value set based human efforts easily observe words lead divergence difference representative aspect based raw corpus sizes set maximum number seed words aspect restaurant dataset laptop dataset evaluation metrics use macro weighted erage precision recall scores experiment results present evaluation results rant laptop datasets table clear proposed method arya outperforms methods signicant margins datasets models considers misc aspect systematically compared tuned second best models arya results absolute provements restaurant laptop table seed word evolution examples iteration indicates user provided seeds dataset aspect iter seed words restaurant laptop food location keyboard spicy pizza sushi food tasty pizza spicy variety tasty tuna sushi portion food specials bland avenue convenient river street block located block view convenient river avenue located block street view convenient park river avenue located block street view convenient park river york avenue keyboard key space keyboard keys key keys keyboard numeric volume palm key layout keyboards system ios windows mac system ios operating mac windows lion interface decided automatically figure shows score increases iterations datasets suggests framework truly enables tual enhancements pre dened aspects misc aspect iterations table presents seed words aspect different iterations datasets observe seed words better seed expansion initial seed words mentioned domain experts feel challenging provide seed words keyboard aspect seed words board key space given beginning rounds seed tuning pansion ltering interesting words added seed set layout numeric palm sense keyboard aspect example palm describes comfortable palms typing board big keyboard compared palms interesting model automatically discover words typical examples come experts observe seed word sets lar aspects converge faster infrequent aspects example restaurant dataset food ambience service aspects converge iteration drinks location pects requires iterations respectively rst signicantly text segments observation tricky aspects converge slower aspects ple laptop dataset keyboard aspect converges slower aspects cause counter intuitive come seed words palm numeric contrary aspect relatively easy figure scores different iterations arya keeps iterating seed words converge datasets respectively worth noting arya noiter signicantly outperforms pared methods observations importance properly handling misc aspect compared methods mate guably second best method utilizes head attention mechanism pseudo label generation step implies attention mechanism important aspect extraction tasks arya generalizes attentions convolutional lters able train powerful model advantage arya arya noiter demonstrates importance progressively model updating seed words iteration comparing arya notuning noiter carefully limit scope seed word candidates risk adding noisy seed words lead worse performance laptop dataset improvement arya arya nofilter reveals effectiveness ltering seed words pre dened aspects misc aspect seed word evolution arya keeps iterating seed words verge number iterations arya scorerestaurantlaptop pared aspects misc text segment examples present successfully classied text ments different types misc aspect rst example restaurant dataset pleasant specic aspect arya detects word pleasant noisy word refer service ambience ltered aspects eventually arya predicts probabilities segment belong misc service ambience respectively misc wins end second example laptop dataset problem add ram computer kinda slow pre dened hardware aspect arya predicts misc chances respectively mainly word slow widely complain related works aspect extraction originated level task instead working text segments rule based methods liu liu zhuang scafdi zhang qiu pioneers direction number unsupervised learning methods based lda topic model variants titov mcdonald zhao brody elhadad jee liu zhang shams baraani dastjerdi treat extracted topics aspects recently neural model extra luo proposed improve aspect extraction document level problem focuses text segments directly applying document level methods leads unsatisfactory results recent unsupervised attempts aspect extraction text segments abae employs attention module learn embedding text segments auto encoder framework build aspect dictionaries requires users rst set number topics larger number number sired aspects manually merge map extracted topics aspects building abae angelidis lapata proposed multi seed aspect extractor mate ing seed aspect words guidance model keeps human effort minimal degree problem setting multi task counterpart reconstruction objective mate model able provide adequate training signals proposed method leverages seed word tuning expansion overcome issue outperforming mate signicantly extensive experiments problem shares certain similarities weakly supervised text classication problem isting methods build document classiers taking hundreds labeled training ments tang miyato class category names song roth user provided seed words meng source weak supervision methods assume users provide seeds classes overlooking noisy misc aspect problem incorporate misc aspect atically framework conclusions future work paper explore build aspect traction model text segments user provided seed words aspect identify key challenge lies properly handle misc aspect domain experts easily design seed words propose novel framework arya incorporates misc aspect systematically framework induce supervision misc aspect seed words pre dened aspects time utilize misc aspect information lter noisy words seed list pre dened aspects extensive experiments demonstrated effectiveness arya veried sity modeling misc aspect future like integrate tracted aspect information downstream tasks sentiment analysis opinion tion want explore use alized representation weakly supervised aspect extraction disambiguating words based contexts addition interested ing work document classications multiple labels document references eugene agichtein luis gravano snowball extracting relations large plain text collections proceedings fth acm conference tal libraries pages acm stefanos angelidis mirella lapata marizing opinions aspect extraction meets ment prediction weakly supervised samuel brody noemie elhadad pervised aspect sentiment model online reviews naacl pages jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language ing ruidan wee sun lee hwee tou daniel dahlmeier unsupervised neural attention acl pages model aspect extraction ruining julian mcauley ups downs modeling visual evolution fashion trends class collaborative ltering www minqing bing liu mining sigkdd pages rizing customer reviews benjamin kuipers patrick beeson joseph modayil jefferson provost bootstrap learning foundational representations connection science keqian hanwen zha xifeng yan unsupervised neural categorization siam data mining pages entic publications siam bing liu minqing junsheng cheng opinion observer analyzing comparing ions web www pages zhiyi luo shanshan huang frank bill yuchen lin hanyuan shi kenny zhu extra extracting prominent review aspects customer feedback emnlp pages julian mcauley christopher targett qinfeng shi anton van den hengel image based mendations styles substitutes sigir meng jiaming shen chao zhang jiawei han weakly supervised neural text classication cikm pages takeru miyato andrew dai ian low adversarial training methods supervised text classication guang qiu bing liu jiajun chun chen opinion word expansion target extraction double propagation computational tics ellen riloff janyce wiebe theresa wilson learning subjective nouns extraction pattern bootstrapping proceedings seventh ence natural language learning hlt naacl volume pages association putational linguistics christopher scafdi kevin bierhoff eric chang mikhael felker herman chun jin red opal product feature scoring reviews proceedings acm conference tronic commerce pages mohammadreza shams ahmad baraani dastjerdi enriched lda elda combination latent dirichlet allocation word occurrence sis aspect extraction expert systems cations jingbo shang jialu liu meng jiang xiang ren clare voss jiawei han automated phrase mining massive text corpora tkde yangqiu song dan roth dataless chical text classication aaai jian tang meng qiaozhu mei pte dictive text embedding large scale sigkdd pages geneous text networks fangbo tao chao zhang xiusi chen meng jiang tim hanratty lance kaplan jiawei han automated document allocation text cube dimension aware joint embedding sion ivan titov ryan mcdonald modeling online reviews multi grain topic models www pages acm weidi haoze sun chao deng ying tan variational autoencoder semi supervised text classication aaai chen zhang hao wang liangliang cao wei wang hybrid term term topic detection fanjiang relations analysis approach knowledge based systems lei zhang bing liu suk hwan lim eamonn obrien strain extracting ranking uct features opinion documents proceedings international conference tional linguistics posters pages ciation computational linguistics arjun mukherjee bing liu aspect acl tion semi supervised modeling pages wayne xin zhao jing jiang hongfei yan ing jointly modeling aspects opinions maxent lda hybrid emnlp pages zhuang feng jing xiao yan zhu movie review mining summarization cikm pages
