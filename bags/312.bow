evaluation text generation survey asli celikyilmaz microsoft research com elizabeth clark university washington washington edu jianfeng gao microsoft research com abstract paper surveys evaluation methods natural language generation nlg tems developed years group nlg evaluation methods categories human centric evaluation metrics automatic metrics require training machine learned metrics egory discuss progress challenges faced focus evaluation recently proposed nlg tasks neural nlg models present case studies automatic text summarization long text generation conclude paper proposing future research directions n u j l c s c v v x r equal contribution grateful following people rahul jha sudha rao ricky lyond helpful comments suggestions earlier versions paper like thank authors papers gave permission use gures tables examples survey paper summarize related work contents introduction evolution natural language generation survey evaluation natural language generation outline survey human centric evaluation methods intrinsic evaluation extrinsic evaluation evaluators inter evaluator agreement percent agreement cohen s fleiss krippendorff s untrained automatic evaluation metrics n gram overlap metrics content selection f score bleu nist rouge meteor hlepor ribes cider distance based evaluation metrics content selection edit distance based metrics vector similarity based evaluation metrics n gram based diversity metrics type token ratio ttr self bleu measure textual lexical diversity explicit semantic content match metrics pyramid spice spider semantic similarity models evaluation metrics syntactic similarity based metrics machine learned evaluation metrics sentence semantic similarity based evaluation evaluating factual correctness regression based evaluation evaluation models human judgments bert based evaluation composite metric scores case studies task specic nlg evaluation case study automatic document summarization evaluation intrinsic methods extrinsic summarization evaluation methods case study long text generation evaluation evaluation discourse structure evaluation lexical cohesion evaluation writing style evaluation multiple references conclusions future directions chapter introduction natural language generation nlg natural language processing nlp deals building software systems produce coherent readable text nlg applied broad range nlp tasks generating responses user questions chatbot translating sentence document language offering suggestions help write story generating summaries time intensive data analysis nlg evaluation challenging mainly nlg tasks open ended example dialog system generate multiple plausible responses user input document summarized different ways human evaluation remains gold standard nlg tasks human evaluation expensive researchers resort automatic metrics quantifying day day progress performing automatic system optimization recent advancements deep learning yielded tremendous improvements nlp tasks turn presents need evaluating deep neural network dnn models nlg paper provide comprehensive survey nlg evaluation methods focus uating neural nlg systems group evaluation methods categories human centric evaluation metrics automatic metrics require training machine learned metrics category discuss progress challenges faced proposals new directions nlg evaluation evolution natural language generation nlg dened task building software systems write e producing explanations summaries narratives english human people communicate ideas writing speech nlg systems designed produce natural language text speech conveys ideas readers clear useful way nlg systems generate text real world applications generating weather forecasts carrying interactive conversations humans spoken dialog systems chatbots captioning images visual scenes translating text language generating stories news articles nlg techniques range simple template based systems generate natural language text ing rules templates machine learned systems complex understanding human grammar rst generation automatic nlg systems uses rule based data driven pipeline methods seminal paper reiter dale present classical stage nlg ture shown figure rst stage document planning content order determined text plan outlines structure messages generated second micro planning stage referring expressions identify objects like entities places generated choice words aggregated collating similar sentences improve readability natural ow occurs stage stage realization actual text generated linguistic knowledge morphology syntax semantics earlier work focused modeling discourse structures learning representations relations text units text generation mckeown marcu ehud reiter s blog reiter figure stages traditional nlg process reiter dale ono et al stede umbach example rhetorical structure theory mann thompson discourse representation theory lascarides asher large body work based template based models statistical methods improve generation introducing new methods sentence compression reordering cal paraphrasing syntactic transformation sporleder steinberger knight clarke lapata quirk et al earlier text generation approaches extensions play important role lution nlg research true nlg research decade witness paradigm shift learning representations large textual corpora vised manner deep neural network dnn models recent nlg models built training dnn models typically large corpora human written texts paradigm shift starts use recurrent neural networks graves e long short term memory networks lstm hochreiter schmidhuber gated recurrent units grus cho et al learning language representations mikolov et al glove et al later sequence sequence learning sutskever et al opens new chapter characterised wide application encoder decoder architecture sequence sequence models originally developed machine translation soon shown improve performance nlg tasks models weakness capturing long span dependencies long word sequences motivates development attention networks bahdanau et al pointer networks vinyals et al transformer architecture vaswani et al incorporates encoder decoder implemented self attention mechanism adopted new state art nlg systems large body research recent years focuses improving performance nlg large scale pre trained language models contextual word embeddings peters et al devlin et al sun et al dong et al better sampling methods reduce eration decoding zellers et al holtzman et al learning generate text better discourse structures narrative ow yao et al fan et al dathathri et al rashkin et al neural models applied nlg tasks discuss paper including summarization common tasks include single multi document tasks query focused generic summarization summarization news meetings screen plays social blogs machine translation document level dialog response generation goal oriented chit chat dialogs paraphrasing question generation long text generation common tasks story news poem generation data text generation table summarization caption generation non text input input tables images sequences video frames e visual storytelling survey evaluation natural language generation question interested paper measure quality text generated nlg models text generation key component language translation chatbots question answering marization applications people interact everyday building language models traditional approaches complicated task needs account multiple aspects language including linguistic structure grammar word usage perception requires non trivial data labeling efforts recently transformer based neural language models shown effective leveraging large amounts raw text corpora online sources wikipedia search results blogs reddit posts example advanced neural language models radford et al generate long texts able human generated texts zellers et al empathetic social chatbots xiaoice zhou et al understand human dialog generate interpersonal responses establish long term emotional connections users training powerful language model relies evaluation metrics measure model quality different perspectives instance imperative build evaluation methods determine text generated human machine prevent potential harm similarly evaluating generated text based factual consistency recently drawn tention nlg eld concerning neural language models generate open ended texts uent grounded real world knowledge facts fake news situation particularly alarming generated reports news related humankind summaries health reports zhang et al addition mainstream nlg evaluation methods survey discusses recently proposed metrics address human facing issues metrics evaluate factual consistency generated summary pathy level chatbot s response nlg surveys published years gatt krahmer zhu et al zhang et al survey specic nlg tasks nlg models image captioning kilickaya et al hossain et al li et al bai machine translation dabre al han wong wong kit summarization deriu et al shi et al question generation pan et al extractive key phrase generation c ano bojar deep generative models pelsmaeker aziz kim et al text image synthesis agnese et al dialog response generation liu et al novikova et al deriu et al dusek et al gao et al published papers review evaluation methods specic nlg tasks image captioning kilickaya et al machine translation goutte online review generation garbacea et al interactive systems hastie belz conversational dialog systems deriu et al human centric evaluations lee et al amidei et al closest paper nlg survey paper gkatzia mahamood includes chapter nlg evaluation metrics different work survey dedicated nlg evaluation focus evaluation metrics developed recently neural text generation systems provides depth analysis existing metrics date best knowledge paper extensive date survey nlg evaluation outline survey review nlg evaluation methods categories chapters human centric evaluation natural way evaluate quality text ator involve humans judges naive expert subjects asked rate compare texts generated different nlg systems perform turing test turing distinguish machine generated texts human generated texts human evaluations task specic need designed implemented differently outputs different tasks example human evaluation image captioning different text summarization untrained automatic metrics category known automatic metrics commonly research community evaluation methods compare machine generated texts human generated texts references input data metrics require machine learning simply based string overlap content overlap string distance lexical diversity n gram match distribution similarity nlg tasks critical select right automatic metric sures aspects generated text consistent original design goals nlg system machine learned metrics metrics based machine learned models measure similarity machine generated texts machine generated human generated texts models viewed digital judges simulate human judges investigate differences evaluations shed light potential factors contribute differences chapter present case studies evaluation methods developed tasks automatic document summarization long text generation e story review generation respectively choose tasks attracted lot attention nlg research community task specic evaluation metrics adopted nlg tasks provide general guidelines building evaluation metrics correlate human judgements lastly conclude paper future research directions nlg evaluation chapter human centric evaluation methods system generating answer user s query justication classication model s decision short story ultimate goal nlg generate text valuable people reason human evaluations typically viewed important form evaluation nlg systems held gold standard developing new automatic metrics automatic metrics fall short replicating human decisions reiter belz krahmer theune reiter nlg papers include form human evaluation example hashimoto et al report generation papers published present human evaluation results human evaluations best insight model performs task worth noting human evaluations pose challenges human evaluations sive time consuming run especially tasks require extensive domain expertise online crowd sourcing platforms amazon mechanical turk enabled researchers run experiments larger scale lower cost come problems maintaining quality control ipeirotis et al mitra et al furthermore large group annotators dimensions generated text suited human evaluations diversity hashimoto et al lack consistency human evaluations run prevents researchers reproducing experiments ing results systems inconsistency evaluation methods worse inconsistent reporting methods details human evaluations run incomplete vague example van der lee et al nd sample nlg papers acl inlg papers report number participants human evaluations chapter describe common approaches researchers evaluating generated text human judgments grouped intrinsic evaluations belz extrinsic reiter ways incorporate human subjects evaluation process training models human judgments discussed chapter intrinsic evaluation intrinsic evaluation asks people evaluate quality generated text overall specic dimension e uency coherence correctness typically erating samples text model asking human evaluators score quality simplest way type evaluation evaluators generated texts time judge quality individually asked vote text good bad ne grained decisions marking quality likert sliding scale figure judgments format inconsistent comparing results straightforward amidei et al nd analysis nlg evaluations format incorrectly little justication chosen methods directly compare model s output baselines model variants human generated text intrinsic evaluations performed having people choose generated likert scale question rankme style question figure different methods obtaining intrinsic evaluations text generated meaning representation image source novikova et al com rankme texts prefer generally rank set generated texts comparative approach found produce higher inter annotator agreement callison burch et al cases captures models relative quality sense absolute quality generated text way address use method like rankme novikova et al adds magnitude estimation bard et al ranking task asking evaluators indicate better chosen text figure based approaches prohibitively costly requiring lots head head comparisons complex requiring participants rank long lists output models compare methods help cases example best worst scaling louviere et al nlg tasks kiritchenko mohammad koncel kedziorski et al simplify comparative evaluations best worst scaling asks participants choose best worst elements set candidates simpler task fully ranking set provides reliable results text generation tasks today evaluated intrinsic human evaluations machine translation text generation tasks intrinsic human evaluations huge impact development reliable accurate translation systems automatic metrics validated correlation human judgments metric commonly judge translated output humans measuring adequacy dened linguistic data consortium meaning expressed gold standard translation source expressed target translation annotators bilingual source target languages order judge information preserved translation dimension text quality commonly considered machine translation uency measures quality generated text e target translated sentence taking source account accounts criteria grammar spelling choice words style ical scale measure uency based question language output uent fluency adopted text generation tasks including document summarization ilmaz et al narayan et al recipe generation bosselut et al image captioning lan et al video description generation park et al question generation du et al uency adequacy standard dimensions human evaluation machine translation text generation tasks established set dimensions researchers use dimensions common human evaluations generated text adequacy dimensions focus contents generated text factuality important tasks require generated text accurately reect facts described context example tasks like data text generation summarization information output contradict information input data table news article challenge neural nlg models known hallucinate information holtzman et al welleck et al maynez et al nd generated sentence summaries contained hallucinations nding held different modeling approaches explicit set facts adhere researchers want know generated text follows rules commonsense logical generation tasks involve extending text researchers ask evaluators gauge coherence consistency text ts provided context example story generation characters appear generated text sequence actions sense given plot far dimensions focus generated text saying said uency dimensions evaluated showing evaluators context basic checking simple language errors asking evaluators rate grammatical generated text involve asking overall style formality tone generated text particularly important style transfer tasks multi task settings hashimoto et al ask evaluators typicality generated text words expect text looks like dimensions focus efciently generated text communicates point asking evaluators repetitive redundant ldc upenn edu docs pdf note dimensions common referred names explained evaluators different terms measured different ways van der lee et al consistency user evaluations run especially dened generation tasks useful producing comparable results focused efforts improving performance given generation task way enforce consistency handing task human evaluation individual researchers evaluation platform usually run people hosting shared task leaderboard setting researchers submit models model outputs evaluation platform organizes runs human evaluations example chateval evaluation platform open domain chatbots based human automatic metrics sedoc et al turingadvice zellers et al tests models language understanding capabilities having people read rate models ability generate advice course leaderboards evaluation platforms uniformity consistency come rigidity possibility overtting wrong objectives standardize human evaluations account person s goal producing text nuanced diverse ways evaluating text reect extrinsic evaluation extrinsic evaluation people evaluate system s performance task designed extrinsic evaluations meaningful evaluation system actually performs downstream task expensive difcult run reiter belz reason intrinsic evaluations common extrinsic evaluations gkatzia mahamood van der lee et al increasingly van der lee et al attribute recent shift focus nlg subtasks systems extrinsic methods measure successful system downstream task success measured different perspectives user s success task system s success fullling purpose hastie belz extrinsic methods measure user s success task look user able away system e improved decision making higher comprehension accuracy gkatzia mahamood example young reiter belz point rst examples extrinsic evaluation generated text evaluate automatically generated instructions number mistakes subjects followed system success extrinsic evaluations hand measure nlg system s ability complete task designed example reiter et al generate personalized smoking cessation letters report recipients actually gave smoking extrinsic human evaluations commonly evaluating performance dialog deriu et al impact development dialog modeling systems approaches measure system s performance talking people measuring conversation length asking people rate system feedback collected real users dialog system black et al lamel et al zhou et al end conversation alexa follows similar strategy letting real users interact operational systems gathering user feedback span months commonly human evaluations dialog systems crowd sourcing platforms amazon mechanical turk amt serban et al peng et al li et al zhou et al jurccek et al suggest crowd sourced users yield good quality metric comparable human evaluations subjects interact system evaluate evaluators nlg evaluation tasks specic expertise required evaluators prociency language generated text especially true uency related aspects generated text focus evaluation target audience nlg system broad e summarization system want generate text interested amazon com alexaprize reading news articles chatbot needs carry conversation access cases human evaluations benet performed wide population possible typically evaluations settings performed person online person ation simply performed authors group evaluators recruited researchers come lab participate study benets person evaluation easier train interact participants easier detailed feedback study adapt needed researchers certainty control ipating study especially important trying work targeted set evaluators person studies expensive time consuming run reasons person evaluations tend include fewer participants set people imity research group accurately reect set potential users system person evaluations susceptible response biases adjusting decisions match believe researchers preferences expectations nichols maner orne mitigate drawbacks person studies online evaluations generated texts increasingly popular researchers independently recruit participants online work tasks common use crowdsourcing platforms users researchers recruit participate task paying fee e amazon chanical rewarding means e provides ticipants personalized feedback information based task results platforms allow researchers perform large scale evaluations time efcient manner usually expensive free run allow researchers reach wider range evaluators able recruit person e geographical diversity taining quality control online issue ipeirotis et al oppenheimer et al demographics evaluators heavily skewed depending user base platform difallah et al reinecke gajos furthermore disconnect evaluators online paid complete task want nlg system people end product want nlg evaluation tasks performed subset speakers given language tasks transfer platforms like amazon mechanical turk workers customed dealing large batches microtasks specialized groups evaluators useful testing system particular set users extrinsic evaluation settings researchers recruit people potential users system e students educational tools doctors bionlp systems cases require specialized human evaluation projects evaluator expertise important task source texts generated texts consist long documents collection documents consider task citation tion luu et al given scientic documents b task generate sentence document appropriately cites document b rate generated citations evaluator able read understand different scientic documents general expert knowledge style conventions academic writing reasons luu et al choose run human evaluations expert annotators case nlp researchers regular crowdworkers inter evaluator agreement evaluators undergo training standardize evaluations evaluating generated natural language include degree subjectivity evaluators disagree ratings level disagreement useful measure researchers high levels inter evaluator agreement generally mean task dened differences generated text consistently noticeable evaluators low agreement indicate poorly dened task reliable differences generated text measures inter evaluator agreement frequently included nlg papers generation papers reviewed amidei et al include agreement analysis positive note common recent papers studied mturk labinthewild ment measures included agreement usually low generated text evaluation tasks lower typically considered acceptable agreement scales amidei et al amidei et al point given richness variety natural language ing highest possible inter annotator agreement right choice comes nlg evaluation ways capture agreement annotators banerjee et al highlight common approaches nlg evaluation depth look annotator agreement measures natural language processing refer artstein poesio percent agreement simple way measure agreement report percent cases evaluators agree evaluating set generated texts x having people assign score text xi let ai agreement scores xi ai evaluators agree ai nt percent agreement task pa ai x pa means evaluators agree scores generated text pa means agreed common way people evaluate agreement nlg evaluations amidei et al account fact evaluators agree purely chance particularly cases number scoring categories low scoring categories likely artstein poesio need complex agreement measure capture cohen s cohen s cohen agreement measure capture evaluator agreements happen chance addition pa consider pc probability evaluators agree chance example evaluators scoring texts x score set s pc odds scoring text pc ss p s p s cohen s p s ei estimated frequency evaluator ei assigned scores task example scores assigns scores scores assigns pc pa pc cohen s calculated fleiss seen equation cohen s measures agreement annotators evaluators scored generated texts particularly tasks run crowdsourcing platforms fleiss fleiss measure agreement multiple evaluators looking pairs evaluators agree considering possible pairs related agreement measures e scott s scott differ cohen s estimate p described artstein poesio discuss commonly nlg evaluations amidei et al pa pc pc evaluators ai dened earlier agreement scores generated text xi calculated evaluator pairs ai ss evaluator pairs score xi s total evaluator pairs dene pa overall agreement probability dened equation average agreement texts calculate pc estimate probability judgment p s ei frequency score annotators assuming annotator equally likely draw randomly distribution rs proportion judgments assigned score s likelihood annotators assigning score s chance rs s overall probability chance agreement rs pc ss s values pa pc use equation calculate fleiss krippendorff s measures treats evaluator disagreements equally bad cases wish penalize disagreements harshly krippendorff s pendorff technically measure evaluator disagreement agreement allows different levels disagreement taken account like measures use frequency evaluator agreements odds agreeing chance state terms disagreement nd probability disagreement different possible score pairs sm sn weighted value wm n assign pair pd wm n evaluator pairs assign xi sm sn total evaluator pairs note m n e pair annotators agree wm n calculate expected disagreement similar assumption fleiss random likelihood evaluator assigning score si estimated overall frequency si rm n proportion evaluation pairs assign scores sm sn treat probability evaluators assigning scores sm sn generated text random pc finally calculate krippendorff s measures permit evaluator disagreements weighted differently example weighted cohen extends cohen s adding weights possible pair score ments nlg evaluation krippendorff s common weighted measures set nlg papers surveyed amidei et al weighted pc wm nrm n pd pc chapter untrained automatic evaluation metrics increase numbers nlg applications benchmark datasets evaluation nlg systems increasingly important today best evaluation automatic nlg system output human based evaluation human evaluation costly time consuming design run importantly results repeatable belz reiter automatic evaluation metrics employed alternative developing new models comparing state art survey group automatic metrics categories untrained automatic metrics require training chapter learned evaluation metrics based machine learned models chapter chapter review untrained automatic metrics different nlg applications discuss advantages drawbacks comparison approaches untrained automatic metrics nlg evaluation measure effectiveness models generate text machine translation image captioning question generation metrics compute score indicates similarity dissimilarity automatically generated text written reference gold standard text untrained automatic evaluation metrics fast efcient widely quantify day day progress model development e comparing model training different hyperparameters group untrained automatic evaluation methods table ve categories gram overlap metrics distance based metrics diversity metrics content overlap metrics grammatical feature based metrics n gram overlap metrics content selection n gram overlap metrics commonly evaluating nlg systems measure degree matching machine generated human authored ground truth texts section present n gram match features nlg tasks evaluate p l r e v o m r g n metric bleu nist f score wer rouge meteor hlepor ribes cider edit dist ter wmd smd p pyramid l spice r e v spider o e s e c n t s d t n e t n o c property n gram precision n gram precision precision recall insert delete replace n gram recall n gram synonym matching unigrams harmonic mean unigrams harmonic mean tf idf weighted n gram similarity cosine similarity translation edit rate earth mover distance words earth mover distance sentences mt scene graph similarity scene graph similarity ic sr sum dg qg rg table untrained automatic retrieval based metrics based string match string distance context overlap acronyms nlp sub research elds metric commonly evaluate text generation mt machine translation qg question tion sum summarization rg dialog response generation dg document story generation visual story generation ic image captioning f score f score called score f measure measure accuracy f score ances generated text s precision recall measuring harmonic mean measures f score dened precision recall precision recall precision specicity called positive predictive value fraction n grams model generated hypothesis text present reference human gold text recall called sensitivity fraction n grams reference text present candidate text f score reaches best value indicating perfect precision recall value worst f score means lowest precision lowest recall value text generation tasks machine translation summarization f score gives tion quality generated sequence model produce melamed et al aliguliyev specically machine translation f score based metrics shown effective evaluating translation quality metrics chrf character n gram f score uses character n grams instead word n grams compare machine translation model output reference translations popovic use character n grams helps better match morphological variations words recent work mathur et al empirically shown chrf high correlation human judgments compared commonly n gram based evaluation metrics bleu bilingual evaluation understudy bleu rst metrics measure larity sentences papineni et al originally proposed machine translation compares candidate translation text reference translations bleu weighted geometric mean n gram precision scores dened precn s y y s y y hypothesis sequence y ground truth sequence s n gram sequence y y number times s appears y bleu score brevity penalty penalize sequences short calculated bp bleu exp wn log precn bp n bp c t t t t t t prediction gold sequence length length candidate generated sequence r effective reference corpus length n total number n gram precision scores use wn weight precision score set n argued bleu signicant advantages ultimate sure improved machine translation quality callison burch osborne earlier work reported bleu correlates human judgments lee przybocki denoual age recent work argues good metric machine translation task zhang et al designed nt correlate human judgments generation tasks outside machine translation image captioning dialog response generation reiter report s good evidence support bleu best metric evaluating nlg systems machine translation caccia et al empirically demonstrated sample model outputs perfect bleu corpus generated sentences grammatically correct lacked semantic global coherence concluding generated text poor information content outside machine translation bleu text generation tasks ment summarization graham image captioning vinyals et al human machine versation gao et al language generation semeniuta et al graham concluded bleu achieves strongest correlation human assessment nicantly outperform best performing rouge variant hand recent study demonstrated n gram matching scores bleu insufcient potentially accurate metric unsupervised language generation semeniuta et al text generation research especially focused short text generation like sentence based chine translation question generation successfully bleu benchmark analysis models fast easy calculate enables comparison models task bleu drawbacks nlg tasks contextual understanding soning key e story generation fan et al martin et al long form question answering fan et al considers semantic meaning sentence structure handle morphologically rich languages map human judgments tatman recent work mathur et al investigated sensitive machine translation evaluation metrics outliers found outliers tasks like machine translation metrics like bleu lead high correlations yielding false conclusions reliability metrics report outliers removed metrics correlate adds evidence unreliablity bleu present metrics address shortcomings paper nist proposed national institute standards technology nist martin przybocki method similar bleu evaluating quality text unlike bleu treats n gram equally nist heavily weights n grams occur frequently co occurrences n grams informative common n grams doddington information weights computed n gram counts set reference translations according following equation wn wn wi n grams reference text c nist score indicates count formula calculating nist n co occur hyp sequence wn exp br log min lhyp lref lhyp average number words hypothesis generated translation averaged reference translations lref number words translation scored different bleu brevity penalty chosen number words reference output thirds average number words reference translation change minimize impact score small variation translation length goal preserve original motivation brevity penalty reducing contributions length variations score small variations shown nist metric superior bleu terms reliability quality doddington metric merits evaluating machine translation adopted recent neural nlg research bleu metric rouge recall oriented understudy gisting evaluation rouge lin set metrics evaluating automatic summarization long texts consisting multiple sentences paragraphs mainly designed evaluating multi document summarization evaluating short text generation machine translation lin och image captioning cui et al question generation nema khapra dong et al rouge includes large number distinct variants including different n gram counting ods measure n gram overlap generated ground truth human written text simplifying notation original paper lin rouge n dened rouge n n match r s count gramn r n sums n grams length n e n formula measures number times matching bigram found hypothesis model generated reference generated text reference summary outer summation r repeats process reference summaries explain commonly rouge metrics lin measures overlap unigrams single tokens reference hypothesis text e g summaries measures overlap bigrams reference hypothesis text measures overlap trigrams reference hypothesis text measures overlap grams reference hypothesis text rouge l measures longest matching sequence words longest common sequence lcs metric nt require consecutive matches requires sequence matches indicate sentence level word order n gram length need predened rouge l automatically includes longest common n grams shared reference hypothesis text rouge w commonly measures weighted lcs based statistics favor secutive lcss rouge s commonly measures skip based co occurrence statistics pair skip words sentence order considered skip bigram skip gram huang et al type n gram tokens e words nt need consecutive order sentence gaps tokens skipped nlp research overcome data sparsity issues rouge su commonly measures skip bigram unigram based co occurrence statistics rouge includes setting word stemming summaries option remove retain stop words additional congurations include use precision rouge p recall rouge r f score rouge f compute individual summary scores provides options computation overall score system computing mean median generated hypothesis text score distribution found bleu scores total rouge provide possible system level measure variants compared bleu rouge focuses recall precision interpretable bleu callison burch osborne additionally rouge includes mean median score individual output text allows signicance test differences system level rouge scores restricted bleu graham baldwin graham rouge evaluates adequacy generated output text counting n grams generated output text matches n grams reference human generated output text ered bottleneck measure especially long text generation tasks kilickaya et al nt provide information narrative ow grammar topical ow erated text evaluate factual correctness summary compared corpus generated meteor metric evaluation translation explicit ordering meteor lavie et al banerjee lavie metric designed address issues found bleu widely evaluating machine translation models models image captioning kilickaya et al question generation nema khapra du et al summarization et al chen bansal yan et al compared bleu measures precision meteor based harmonic mean unigram precision recall recall weighted higher precision metrics support property yields high correlation human judgments lavie agarwal meteor score reference hypothesis text measured follows let resent unigrams found hypothesis reference text total number unigrams hypothesis text total number unigrams reference text r mean f score computed unigram recall precision fmean precision precision recall recall alignment hypothesis reference calculated follows meteor fmean penalty penalty term called fragmentation penalty determines extent matched unigrams hypothesis reference ordered measured follows penalty frag sequence matched unigrams texts divided fewest possible number chunks matched unigrams chunk adjacent identical word order number chunks ch number matches m calculate fragmentation fraction rag ch m determines maximum penalty determines functional relation fragmentation penalty meteor scores range meteor variants extend exact word matching metrics gory include stemming synonym matching variants address problem reference translation variability allowing morphological variants synonyms ognized valid translations metric found produce good correlation human judgments sentence segment level agarwal lavie differs bleu meteor explicitly designed compare sentence level level harmonic mean enhanced length penalty precision n gram position difference penalty hlepor initially proposed machine translation metric designed morphologically complex languages like turkish czech han et al factors hlepor utilizes speech noun verb tags similarity capture syntactic information hlepor ribes rank based intuitive bilingual evaluation score ribes isozaki et al un trained automatic evaluation metric machine translation developed ntt communication ence labs designed informative asian languageslike japanese chinese nt rely word boundaries specically ribes based words generated text ordered uses rank correlation coefcients measured based word order hypothesis model generated translation reference translation correlation efcients ribes spearman s based distance difference ranks kendall s based direction difference rank earlier work evaluating correlation automatic metrics human judgments shown ribes tends lower correlation human evaluation scores indicating higher ribes nt necessary yield better translations tan et al cider consensus based image description evaluation cider automatic metric measuring similarity generated sentence set human written sentences consensus based protocol originally proposed image captioning vedantam et al cider shows high agreement consensus assessed humans enables comparison text generation els based human likeness having create arbitrary calls weighing content grammar saliency respect cider metric presents explanations hypothesis sentence contain n grams hypothesis sentence occur reference sentences n gram occur reference sentence nt hypothesis tence n grams commonly occur image caption pairs dataset signed lower weights potentially informative given intuitions term frequency inverse document frequency tf idf weight lated n gram specically given image list reference descriptive sentences image sij represent numbers times n gram wk occurs reference sentence sij hypothesis model generated sentence ci respectively tf idf score calculated follows sim si wl log ipi q set images vocabulary n grams cidern score particular n gram calculated cosine similarity generated candidate sentence reference sentence si m j vector containing n grams length n measures magnitude vector capture richer semantics grammatical properties cider use higher order longer n grams si si n vedantam et al nd uniform weights wn n work best n recent study kilickaya et al shows untrained automatic metrics image captioning evaluation cider robust correlates best human judgments distance based evaluation metrics content selection distance based metric nlg applications uses distance function measure similarity text units e words sentences represent text units vectors compute distance vectors smaller distance similar text units section reviews distance based similarity measures text vectors constructed discrete tokens bag words note embeddings metrics represent text vectors pre trained metrics trained mimic human judgments machine learned metrics summarize chapter embedding vectors edit distance based metrics edit distance commonly evaluation metrics natural language processing measures dissimilar text units based minimum number operations required transform text summarize known edit distance measures wer word error rate wer originally designed measuring performance speech nition systems commonly evaluate quality machine translation systems tomas et al specically wer percentage words need inserted deleted placed translated sentence obtain reference sentence e edit distance reference hypothesis sentences calculated wer substitutions insertions deletions reference sentence length substitution replaces word insertion adds new word deletion drops word main drawback wer dependency reference sentences machine translation exist multiple correct translations input metric considers correct variations wer sentence error rate ser measure percentage sentences translations exactly match reference sequence multi reference word error rate mwer ali et al calculates edit distance references sentence chooses smallest nieen et al drawback approach requires human effort obtain multiple references found effective measure reference word error rate awer tomas et al measures number words inserted deleted replaced sentence evaluation order obtain correct translation awer considered version mwer takes account possible references reference wer wer limitations instance value lower bounded zero indicates perfect match hypothesis reference text value upper bounded making hard evaluate absolute manner mccowan et al reported suffer weak correlation human evaluation example task spoken document retrieval wer automatic speech recognition system reported poorly correlate retrieval system performance kae huenerfauth med minimum edit distance med text strings minimum number ing operations e insertion deletion substitutions required transform string strings y length n m respectively dene distance metric j edit distance j e rst j characters string y distance entire strings y m med applied sentences longer text words units characters machine translation med minimum number insertions deletions substitutions words required order system translation equivalent meaning reference translation wer med based levenshtein distance med mainly measure text strings wer text speech e rst characters string ter translation edit rate ter snover et al dened minimum number edits needed change generated text exactly matches references normalized average length references terms minimum number edits ter measures number edits closest reference ter number edits average number reference words ter considers insertion deletion substitution single words shifts words possible edits word shifting moves contiguous sequence words hypothesis location hypothesis metric assigns edits equal cost ter shown correlate human judgments evaluating machine lation quality suffers limitations example capture similarity narrow sense uses single reference translation considers exact word matches hypothesis reference issue partly addressed constructing lattice reference translations technique combine output multiple translation systems rosti et al variants proposed improve original ter uses phrasal substitutions automatically generated paraphrases stemming onyms relaxed shifting constraints improvements iter panja naskar adds stem matching normalization ter cder leusch et al models block ordering edit operation tillmann et al computes position independent error rate recent variants character wang et al character based translation edit distance measure eed stanchev et al extension levenshtein distance shown correlate better human judgments languages vector similarity based evaluation metrics nlp embedding based similarity measures commonly addition n gram based ilarity metrics embeddings real valued vector representations character lexical units word tokens n grams allow tokens similar meanings similar representations embedding vectors learned supervised unsupervised neural network models vector similarity metrics summarize assume embeddings pre trained simply input calculate metric meant vector based similarity measure meant uses word embeddings shallow mantic parses compute lexical structural similarity lo evaluates translation quacy measuring similarity semantic frames role llers human references machine translations inspired meant score lo proposed evaluate accuracy yisi chine translation model outputs based weighted distributional lexical semantic similarity shallow semantic structures specically extracts longest common character string hypothesis reference translations measure lexical similarity terp named university maryland mascot terrapin romanization cantonese word translates meaning english word mover s distance wmd earth mover s distance emd known wasserstein metric rubner et al measure distance probability distributions word mover s distance wmd kusner et al discrete version emd calculates distance sequences e sentences paragraphs represented relative word frequencies combines item bag word bow histogram representations text goldberg et al word embedding similarity short wmd intriguing properties hyperparameter free easy use highly interpretable distance documents broken explained sparse distances individual words uses knowledge encoded word embedding space leads high retrieval accuracy documents b dene wmd minimum cost transforming document document represented relative frequencies words contains e ith word type equation total word count document db dened way da rm e m length dene distances representing ith word vi ith jth words j v vocabulary size kusner et al use euclidean distance j vj vi figure left illustration word mover s distance wmd picture source kusner et al right illustration sentence mover s distance smd picture source clark et al wmd calculated nding solution linear program b min j s t rv v non negative matrix j denotes word t tokens assigned word j b constraints ensure ow given word similarity dened cosine jaccard euclidean use pre trained type based contextual word embeddings j da j db j exceed weight specically wmd ensures entire outgoing ow word equals da e j da additionally incoming ow word j match db e j j db j empirically wmd instrumental improvement nlg tasks specically sentence level tasks image caption generation kilickaya et al natural language inference sulea wmd works short texts cost grows prohibitively length documents increases bow approach problematic ments large relation sentences lost measuring word distances metric capture information conveyed group words need higher level document representations dai et al wu et al sentence mover s distance smd sentence mover s distance smd automatic metric based wmd evaluate text continuous space sentence embeddings clark et al zhao et al smd compare generated texts reference texts tasks like machine translation summarization found correlated human evaluation smd represents document collection sentences words sentences seen figure sentence embedding weighted according length bag words sentences representing document normalized da word sentence like wmd smd tries solve linear program eq unlike wmd smd measures cumulative distance moving words document sentences match document vocabulary dened set sentences words documents summarization task smd found correlate better human judgments rouge clark et al recently zhao et al propose new version smd attains higher correlation human judgments similar smd use word sentence embeddings taking average token based embeddings mover s distance calculated investigate different contextual embeddings models including elmo bert taking power mean embedding aggregation method embeddings layer encoding model frechet inception distance extending inception score heusel et al propose new metric called frechet inception distance fid score similarity generated images real ones measures distance multivariate gaussians f id r g t r r g r g g r samples xr g hidden layer activations inception real generated samples respectively authors assume features extracted classier normally distributed semeniuta et al adapt fid nlg uation infersent text embedding model conneau et al compute sentence embeddings infersent supervised model bidirectional lstm max pooling r xg n n n gram based diversity metrics lexical diversity score measures breadth variety word usage writing inspector consider pieces texts class teaching rst repeatedly uses words teacher reads asks second avoids repetition different words expressions g lecturer instructor delivers teaches questions explains second text lexically diverse desirable nlg tasks conversational bots li et al story generation rashkin et al question generation du et al pan et al abstractive question answering fan et al section review metrics designed measure quality generated text terms lexical diversity type token ratio ttr type token ratio ttr measure lexical diversity richards linguistics determine richness writer s speaker s vocabulary computed number unique words types divided total number words tokens given segment language distinct tokens total tokens intuitive easy use ttr major problem sensitive text length longer document lower prospect replacement token new type eventually causes ttr drop words added remedy issue lexical diversity measures proposed discuss measuring diversity n gram repetitions generalized version ttr use text generation evaluation li et al shown modeling mutual information source targets signicantly decreases chance generating bland responses improves diversity responses use bleu distinct word unigram bigram counts evaluate proposed diversity promoting objective function dialog response generation self bleu zhu et al propose self bleu diversity evaluation metric measuring differences generated sentences references generated texts sense opposite bleu assesses similar sentences taking generated sentence evaluated hypothesis sentences references self bleu calculates bleu score generated sentence denes average bleu scores self bleu score evaluated text lower self bleu score implies higher diversity nlg papers reported self bleu achieves good generation diversity zhu et al chen et al lu et al reported weakness metric generating diverse output caccia et al detecting mode collapse semeniuta et al text generation gan goodfellow et al models self bleu mainly evaluating diversity generated sentences people exploring better evaluation metric evaluates quality diversity montahaei et al measure textual lexical diversity noted earlier chapter ttr metric sensitive length text remedy new diversity metric hd d hyper geometric distribution function proposed compare texts different lengths mccarthy jarvis mccarthy jarvis argue probabilities word occurrence modeled hyper geometric distribution hd hd discrete probability distribution expresses probability k successes drawing n items nite population size n containing m successes replacement hd measure lexical diversity entitled hd d d assumes text sample consists tokens specic word high probability drawing text sample contains token word measure require minimum tokens estimated hd d variants mccarthy jarvis measure diversity story generation mccarthy jarvis summarization tasks crossley et al explicit semantic content match metrics semantic content matching metrics dene similarity human written generated text extracting explicit semantic information units text n grams metrics operate semantic conceptual levels shown correlate human judgments summarize pyramid pyramid method semi automatic evaluation method nenkova passonneau evaluating performance document summarization models like untrained automatic metrics require references untrained metric requires human annotations identies summarization content units scus compare information human generated reference mary model generated summary create pyramid annotators begin model generated summaries source texts select sets text spans express meaning summaries set referred scu receives label mnemonic purposes scu weight corresponding number summaries express scu s meaning scus extracted corpus summaries annotators longer clause table annotation starts identifying similar sentences proceeds ne grained inspection identies related sub parts scus appear human generated summaries higher weights pyramid formed scu annotation human generated summaries scus appear summaries appear pyramid greatest weights lower pyramid scu appears lower weight occurs fewer summaries scus peer summary checked existing pyramid measure information agrees model generated human generated summaries scu cause airline crash nova scotia determined cause sept crash determined searched clues refrained naming cause determined specic cause tragedy determined e investigators remain unsure cause nal determination crashes cause far table overlay matching scus annotators summaries boldface indicates text selected annotators text spans italics labeled indicate annotator selected table source passonneau pyramid metric relies manual human labeling effort makes difcult automate recent study peak pyramid evaluation automated knowledge extraction yang et al presented fully automated variant pyramid model automatically assign pyramid weights peak identies relation triples subject predicate object triples open information extraction del corro gemulla triplets combined hypergraph based semantic similarity approach nodes triplets salient nodes graph later assigned potential scus determined based novel similarity metrics dened graph peak metric generates pyramid entirely automatically shown correlate human judgments yang et al spice sm semantic propositional image caption evaluation spice anderson et al image tioning metric measures similarity list reference human written captions image hypothesis caption c generated model instead s rectly comparing generated caption set references terms syntactic agreement spice parses reference derive abstract scene graph representation generated caption parsed compared scene graph capture semantic similarity spice shown strong correlation human ratings scene graph schuster et al encodes objects attributes relationships detected image captions representing image skeleton form shown figure stage process typically parse image caption scene graph schuster et al lin et al syntactic dependencies words generated reference captions extracted dependency parser klein manning second extracted dependency tree figure illustration scene graph extraction measuring spice metric scene graph right parsed set reference image captions left picture source anderson et al mapped scene graph rule based system schuster et al spice computes f score hypothesis reference scene graphs conjunction logical tuples representing semantic propositions scene graph semantic relations scene graph g represented conjunction logical propositions tuples t dened t tuple contains elements indicating objects o relations r attributes returns matching tuples scene graphs spice metric binary matching operator dened s s p c s s p c s s p c s s precision recall discussed previous subsections evaluation metrics based n gram matching bleu meteor higher number matched n grams nt cate higher generation quality sentences lot words common different semantically comparison spice desirable measures semantic similarity hypothesis reference text scene graphs spice lates human evaluations major drawback ignores uency generated captions sharif et al spider liu et al propose spider linear combination spice cider optimizing spice results captions wordy repetitive scene graph similarity good measuring semantic similarity captions account syntactical aspects texts combination semantic graph similarity like spice gram similarity measure like cider yields complete quality evaluation metric correlation spider human evaluation reported semantic similarity models evaluation metrics text generation work condence scores obtained semantic similarity ods evaluation metric models evaluate reference hypothesis text based task level semantics commonly methods based sentence level similarity follows semantic textual similarity sts concerned degree equivalence underlying semantics paired text agirre et al sts evaluation metric text generation tasks machine translation summarization dialogue sponse generation conversational systems ofcial score based weighted son correlation predicted similarity human annotated similarity higher score better similarity prediction result algorithm maharjan et al cer et al paraphrase identication pi considers sentences express meaning dolan brockett barzilay lee pi text generation ation score based textual similarity kauchak barzilay reference hypothesis nding paraphrase reference sentence closer wording hypothesis output instance given pair sentences reference israel s reply failed completely clear u s suspicions hypothesis israeli answer unable fully remove doubts pi concerned learning transform reference sentence paraphrase israel s answer failed completely remove u s suspicions closer wording hypothesis jiang et al new paraphrasing evaluation metric tiger image caption generation evaluation similarly sidering image captioning liu et al introduce different strategies select useful visual paraphrase pairs training designing variety scoring functions textual entailment te concerned hypothesis inferred premise requiring understanding semantic similarity hypothesis premise dagan et al bowman et al evaluate text generation tasks including machine translation pado et al document rization long et al language modeling liu et al video captioning pasunuru bansal machine comprehension mc concerned sentence matching sage question pointing text region contains answer rajpurkar et al mc tasks like improving question generation yuan et al du et al document summarization hermann et al syntactic similarity based metrics syntactic similarity metric captures similarity reference hypothesis text structural level capture overall grammatical sentence structure similarity corpus linguistics speech pos tagging process assigning speech tag e verb noun adjective adverb preposition word sentence based context morphological behaviour syntax pos tags commonly machine translation evaluation evaluate quality generated translations tesla dahlmeier et al introduced evaluation metric combine synonyms bilingual phrase tables pos tags use pos n grams combination morphemes lexicon abilities compare target source translations popovic et al han et al pos tag information text generation tasks story generation agirrezabal et al summarization suneetha fatima question generation zerr syntactic analysis studies arrangement words phrases formed sentences ample dependency parser extracts dependency tree sentence represent grammatical structure text generation tasks enriched evaluation criteria leveraging tic analysis machine translation liu gildea use constituent labels head modier dependencies extract structural information sentences evaluation use low parsers lo et al dependency parser yu et al yoshida et al combine sequential decoder tree based decoder neural architecture abstractive text summarization chapter machine learned evaluation metrics untrained evaluation metrics described chapter assume generated text signicant word gram overlap ground truth text assumption hold nlg tasks social chatbot permit signicant diversity allow multiple plausible outputs given input table shows examples dialog response generation image captioning tasks respectively tasks model generated outputs plausible given input share words ground truth output solution problem use embedding based metrics measure semantic ity word overlap section embedding based methods help situations generated output semantically different reference dialog example cases build machine learned models trained human judgment data mimic human judges measure quality metrics output factual correctness uralness uency coherence chapter survey nlg evaluation metrics computed machine learned models focus recent neural models context dialog response generation speaker hey john want tonight speaker b nt movie image captioning ground truth response nah hate stuff let s active model distorted output response oh sure heard lm turing rouge bleu wmd man wearing red life caption jacket sitting canoe lake caption guy wearing life vest small boat lake table demonstration issues automatic evaluation metrics rely n gram overlap short text generation tasks dialog response generation image captioning examples adapted liu et al kilickaya et al sentence semantic similarity based evaluation neural approaches sentence representation learning seek capturing semantic syntactic meanings sentences different perspectives topics map sentence bedding vector dnn models word embeddings nlg models evaluated embedding sentence generated reference texts figure illustration skip thoughts vectors model sentence representation learning image source kiros et al extending mikolov et al produce word phrase embeddings liest sentence embeddings models deep semantic similarity model dssm huang et al introduces series latent semantic models deep structure projects text streams query multiple documents common low dimensional space relevance text text computed vector distance thought vectors model kiros et al exploits encoder decoder architecture predict context sentences unsupervised manner skip thought vectors allow encode rich tual information taking account surrounding context slow train fastsent hill et al makes training efcient representing sentence sum word dings dropping knowledge word order simpler weighted sum word vectors arora et al weighs word vector factor similar tf idf score frequent terms weighted similar fastsent ignores word order surrounding tences extending dssm models infersent conneau et al effective model uses lstm based siamese networks additional advantages fastsent encodes word order trained high quality sentence inference dataset hand thought logeswaran lee based unsupervised model universal sentence embeddings trained consecutive sentences given input sentence context classier trained distinguish context sentence contrastive sentences based embeddings recent large scale pre trained language models plms elmo bert use tualized word embeddings represent sentences plms outperform lier models dssms computationally expensive use evaluating nlg systems example transformer based bert model devlin et al extension roberta liu et al designed learn textual similarities sentence pairs cosine similarities similar dssm computationally expensive dssm fact use deeper nn architecture need ne tuned different tasks remedy reimers gurevych propose use sentbert ne tuned bert general task optimize bert parameters cosine similarity erated sentence embeddings strongly related semantic similarity sentences ne tuned model evaluate nlg tasks recent study focusing chine translation task esim computes sentence representations bert embeddings ne tuning later computes similarity translated text reference metrics average recall reference chen et al mathur et al evaluating factual correctness figure illustration training strategy factually correct summarization model image source zhang et al latexit severecardiomegalyisseen nsubj pass background patientwithchestpain findings persistentlowlungvolumeswithenlargedheart latexit latexit ki radiographsshowseverecardiomegalywithpluraleffusions y latexit severecardiomegalyisseen y latexit latexit zhang et al propose way tackle problem factual correctness summarization models focusing summarizing radiology reports extend pointer networks abstractive summarization introducing reward based optimization trains generators obtain rewards generate summaries factually aligned original document ically design fact extractor module factual accuracy generated summary measured directly optimized reward policy gradient shown figure fact extractor based information extraction module extracts represents facts generated reference summaries structured format summarization model dated reinforcement learning combination nll negative log likelihood loss rouge based loss factual correctness based loss act work suggests domains generating factually correct text crucial carefully plemented information extraction system improve factual correctness neural summarization models reinforcement learning n l evaluate factual consistency text generation models eyal et al present question answering based parametric evaluation model named answering performance tion summaries apes evaluation model designed evaluate document summarization based hypothesis quality generated summary associated number questions set relevant ones answered reading summary figure apes evaluation ow image source hashimoto et al build evaluator assess quality generated summaries introduce nents set relevant questions source document question answering system rst generate questions reference summary masking named entities present reference based method described hermann et al ence summary results triplets form generated summary question answer question refers sentence containing masked entity answer refers masked entity generated summary generated summarization model erated summary metrics derived based accuracy question answering system retrieving correct answers associated triplets metric useful rizing documents domains contain lots named entities biomedical news article summarization regression based evaluation shimanaka et al propose segment level machine translation evaluation metric named ruse treat evaluation task regression problem predict scalar value indicate quality translating machine translated hypothesis t reference translation r rst forward pass gru gated recurrent unit based encoder generate t represent r dimensional vector apply different matching methods extract relations t r concatenating getting element wise product computing figure ruse demonstrated efcient absolute element wise distance metric machine translation shared tasks segment level metric correlates human judgements segment quality system level given metric correlates machine translation workshop ofcial manual ranking metrics figure sketch ruse metric image source logeswaran lee evaluation models human judgments creative open ended text generation tasks chit chat dialog story generation online review generation current evaluation methods useful degree mentioned beginning section word overlap metrics ineffective plausible references scenarios collecting impossible human evaluation methods useful scenarios evaluating aspects like coherency naturalness uency aspects like diversity creativity difcult human judges assess knowledge dataset model trained language models learn copy training dataset generate samples human judge rate high quality fail generating diverse samples e samples different training samples observed social chatbots li et al zhou et al discussed previous sections language model optimized perplexity generates coherent bland responses behaviours observed generic pre trained language models downstream tasks ne tuning domain datasets related downstream tasks commonly overlooked issue conducting human evaluation new generation task expensive easily generalizable calibrate human judgments automatic evaluation metrics model based approaches use human judgments attributes labels proposed lowe et al introduce based evaluation metric adem learned human judgments dialog system tion specically response generation chatbot setting collect human judgment scores chitchat dialog appropriateness metric satisfactory evaluate chitchat dialog model responses systems generate inappropriate responses train evaluation model twitter tweet response reference previous dialog turns context use different models rnns retrieval based methods human responses generate different responses ask humans judge appropriateness generated sponse given context evaluation use higher quality labeled twitter dataset ritter et al contains dialogs variety topics figure adem evaluation model image source lowe et al score labeled dataset adem evaluation model trained follows latent variational recurrent encoder decoder model vhred serban et al pre trained dialog dataset learn represent context dialog vhred encodes dialog context vector representation model generates samples initial vectors condition decoder model generate response pre trained vhred model encoder train adem follows dialog context c model generated response r reference response r fed vhred embedding vectors c r r embedding linearly projected model response r mapped spaces dialog context reference response calculate similarity score similarity score measures close model responses context reference response projection follows r r ct mr rt nr adem optimized squared error loss predicted score human judgment score regularization end end fashion trained evaluation model shown correlate human judgments adem found conservative lower scores plausible responses motivation good evaluation metric capture quality diversity generated text hashimoto et al propose new evaluation metric named human unied statistical evaluation huse focuses creative open ended text generation tasks dialogue story generation different adem metric relies human judgments training model huse combines statistical evaluation human evaluation metrics model shown figure figure huse identify samples defects quality sharon stroke stroke diversity cleared coach facing image source hashimoto et al huse considers conditional generation task given context sampled prior tribution outputs distribution possible sentences evaluation metric designed determine similarity output distribution pmodel human generation reference distribution pref similarity scored optimal discriminator determines sample comes reference hypothesis model distribution figure instance low quality text likely sampled model distribution discriminator implemented approximately probability measures probability sentence model estimated text generation model probability reference distribution estimated based human judgment scores summarization chitchat dialog tasks huse shown effective detect low diverse generations humans fail detect bert based evaluation given strong performance bert devlin et al tasks work uses bert similar pre trained language models evaluating nlg tasks tion dialog response generation summarize recent work ne tunes bert use evaluation metrics downstream text generation tasks bert based models semantic evaluation bertscore zhang et al illustrated figure leverages pre trained contextual embeddings bert matches referencemodel probability bows australian openagassi withdraws australian opensharon stroke strokecleared coach facing grilling british swim bossesmodel generationsreferencehuman judgment figure illustration bertscore metric image source zhang et al words candidate reference sentences cosine similarity shown correlate human judgments sentence level system level evaluations bertscore computes precision recall measures useful evaluating range nlg tasks kane et al present new bert based evaluation method called roberta sts detect sentences logically contradictory unrelated regardless grammatically plausible roberta liu et al pre trained language model roberta sts ne tuned sts b dataset learn similarity sentence pairs likert scale evaluation model ne tuned multi genre natural language inference corpus similar way learn predict logical inference sentence given model based tors shown robust correlate better human evaluation automatic evaluation metrics bleu rouge figure agreement bleurt human ratings different skew factors train test image source sellam et al recent bert based machine learned evaluation metric bleurt sellam et al proposed evaluate nlg systems evaluation model trained follows checkpoint bert taken ne tuned synthetically generated sentence pairs matic evaluation scores bleu rouge ne tuned system generated outputs human written references human ratings automatic metrics labels ne tuning bleurt synthetic pairs important step improves robustness quality drifts generation systems shown plots figure nlg task gets difcult ratings closer easier discriminate good bad systems rank good systems ensure robustness metric investigate training datasets different characteristics training data highly skewed domain report training skew disastrous effect bleurt pre training pre training makes bleurt signicantly robust quality drifts llllllllllllllllllllllllllllllllllllllllllllllllllbleurt pretrain bleurt w set skewkendall tau w human ratingslllllbertscorebleutrain sk sk sk sk sk figure composite metrics model architecture image source sharif al discussed chapter humans efciently evaluate performance models embedding based similarity metrics reviewed previous sections based idea inspired comparator evaluator zhou xu proposed evaluate nlg models learning compare pair generated sentences ne tuning bert text pair relation classier trained compare task specic quality sample hypothesis reference based win loss rate trained model skill rating system built system similar player vs player games players evaluated observing record wins losses multiple players player system infers value latent unobserved skill variable indicates records wins losses story generation open domain dialogue response generation tasks comparator evaluator metric demonstrates high correlation human evaluation composite metric scores quality nlg models like machine translation image captioning evaluated multiple aspects adequacy uency diversity composite metrics proposed capture multi dimensional sense quality sharif et al present machine learned composite metric evaluating image captions metric incorporates set existing metrics meteor wmd spice measure adequacy uency li chen propose composite reward function evaluate performance image captions approach based rened adversarial inverse reinforcement learning rairl eases reward ambiguity common reward based generation models decoupling reward word sentence proposed composite reward shown ms coco data achieve state art performance image captioning examples generated model uses composite reward function shown figure images example image captions different learning objectives mle maximum likelihood learning gan generative adversarial networks rl reward based reinforcement learning tom image example generations adversarial inverse reinforcement learning rairl image source li chen chapter case studies task specic nlg evaluation previous chapters reviewed wide range nlg evaluation metrics individually chapter presents metrics jointly evaluate nlg systems real world applications choose nlg tasks automatic document summarization long text ation case studies tasks sophisticated multiple metrics required gauge different aspects nlg quality case study automatic document summarization evaluation text summarization system aims extract useful content reference document generate short summary coherent uent readable concise consistent reference ment different types summarization approaches grouped tasks generic text summarization broad topics ii topic focused scientic article conversation meeting summarization query focused summary answers posed query approaches grouped method extractive mary composed subset sentences words input document abstractive summary generated contains text units occur input document depending number documents summarized approaches grouped single document multi document summarization evaluation text summarization regardless type measures system s ability generate summary based set criteria related references dusek et al ii set criteria measure closeness reference document set criteria measure closeness reference summary figure shows taxonomy evaluation metrics steinberger jezek categories intrinsic extrinsic intrinsic methods intrinsic evaluation generated summaries focus generated text s content text quality factual consistency discussed content content evaluation compares generated summary reference summary matic metrics widely metric summarization rouge metrics bleu f score rouge shown correlate human judgments generic text summarization correlation lower topic focused marization like extractive meeting summarization liu liu meetings transcripts spontaneous speech usually contain disuencies pauses e um uh discourse markers e know mean repetitions liu liu nd disuencies cleaned rouge score improved observed fair amounts figure taxonomy summarization evaluation methods extended steinberger jezek improvement correlation rouge score human judgments include speaker information extracted sentences source meeting form summary quality evaluating generated summaries based quality challenging tasks summarization researchers basic sounds denition good quality mary established nding suitable metrics evaluate quality remains open research area criteria text recent papers human evaluation metrics evaluate quality generated text comparison reference text coherence measures clearly ideas expressed summary lapata lay readability fluency associated non redundancy linguistic quality metrics measure repetitive generated summary spelling mar errors generated summary lapata focus indicates main ideas document captured avoiding superuous details informativeness evaluate question focused summarization sures summary answers question auto regressive generation models trained generate short summary text given longer yield shorter summaries reasons relating bias training data type decoding method e beam search yield coherent text compared k decoding yield shorter text large beam size huang et al comparing different model generations summary text length informativeness measure shorter text typically preserves information singh jin quality criterion widely evaluation metrics human evaluation document summarization compare system generated summary source text human generated summary system generated summary factual consistency thing usually overlooked document summarization tasks evaluating generated summaries based convey factual correctness discussed introduction section fact checking mainstream evaluation strategy automatic text generation emergence powerful language models zellers et al trained factually consistent write related prompt frequently generate factually incorrect text table shows sample marization model output claims consistent source document kryscinski et al imperative summarization models factually consistent conicts tween source document generated summary easily measured especially specic summarization tasks like patient doctor conversation summarization business meeting source article fragments cnn mother quadriplegic man police left woods days dited face charges philadelphia pletes unspecied treatment maryland police said monday montgomery county maryland department police took nyia parler tody sunday model generated claims quadriplegic man nyia parler left woods days extradited cnn classic video game space invaders developed japan late s real life counterparts topic earnest political discussion japan s corridors power luckily japanese sleep soundly beds tonight government s military ofcial earnestly revealed video game space invaders developed japan table examples factually incorrect claims output summarization models green text highlights support source documents generated claims red text highlights errors summarization models table source kryscinski et al summarization result factual consistency aware text generation research drawn lot attention community recent years kryscinski et al gunel et al kryscinski et al zhang et al wang et al common approach use model based approach separate component built summarization engine evaluate generated summary based factual consistency section discussed parametric fact checking models extrinsic summarization evaluation methods extrinsic evaluation metrics test generated summary text impacts performance downstream tasks relevance assessment reading comprehension question answering cohan goharian propose new metric sera summarization evaluation relevance analysis summarization evaluation based content relevance generated summary human written summary nd metric yields higher correlation human judgments compared rouge especially task scientic article summarization eyal et al wang et al measure performance summary answer set questions salient entities source document case study long text generation evaluation long text generation system aims generate multi sentence text single paragraph multi paragraph document common applications long form text generation document level machine translation story generation news article generation poem generation summarization image description generation research area presents particular challenge state art sota approaches based statistical neural models proven insufcient generate coherent long text example sota neural language models radford et al generate remarkably uent sentences paragraphs given topic prompt sentences generated text gets longer starts wander switching unrelated topics incoherent rashkin et al evaluating long text generation challenging task new criteria need implemented measure quality long generated text inter sentence inter paragraph coherence language style semantics human evaluation methods commonly focus discussion automatic evaluation methods case study evaluation discourse structure long text consists groups sentences structured linguistic elements known course jurafsky martin considering discourse structure generated text crucial evaluating system especially open ended text generation model needs termine topical ow structure entities events relations narrative ow coherent uent major tasks discourse plays important role level machine translation gong et al hajlaoui popescu belis present new metric called accuracy connective translation act meyer et al uses combination rules automatic metrics compare discourse connection source target uments joty et al hand compare source target documents based similarity discourse trees evaluation lexical cohesion lexical cohesion surface property text refers way textual units linked grammatically lexically lexical similarity lapata barzilay monly metrics story generation roemmele et al lter n grams based lexical semantics use adjectives adverbs interjections nouns pronouns proper nouns verbs lexical similarity measure commonly metrics compare reference source text mikolov et al sentence level kiros et al embedding similarity averaged entire document entity co reference metric measure herence elsner charniak entity referred properly text introduced roemmele et al capture proportion entities generated sentence co referred entity corresponding context metric entity co reference higher co reference score indicates higher coherence machine translation wong kit introduce feature identify lexical cohesion sentence level word level clustering wordnet miller stemming obtain score word token averaged sentence nd new score improves correlation bleu ter human judgments work gong et al uses topic modeling automatic metrics like bleu meteor evaluate lexical cohesion machine translation long text chow et al investigate position word tokens evaluating uency generated text modify wmd adding fragmentation penalty measure uency translation evaluating machine translation systems evaluation writing style gamon author writing consistent style particular work based nding roemmele et al propose measure quality generated text based presents consistent writing style capture category distribution individual words story context generated following sentence speech tags words e g adverbs adjectives conjunctions determiners nouns text style transfer reects creativity generation model generating new content style transfer help write text different style useful creative writing poetry generation ghazvininejad et al metric commonly style transfer classication score obtained pre trained style transfer model fu et al metric measures generated sentence style context evaluation multiple references issue evaluating text generation systems diversity generation especially text evaluate long generated text uent valid given input informative user lexical overlap reference text prompt constrain generation issue investigated extensively li et al haei et al holtzman et al welleck et al gao et al multiple references cover plausible outputs possible effective solution improving correlation automatic evaluation metrics adequacy uency human judgments demonstrated machine translation han laubli et al nlg tasks chapter conclusions future directions text generation central nlp tasks including machine translation dialog response eration document summarization recent advances neural language models research community signicant progress developing new nlg models systems challenging tasks like multi paragraph document generation visual story generation new system model comes new challenge evaluation paper surveys nlg evaluation methods categories human centric evaluation human evaluation important developing nlg systems considered gold standard developing automatic metrics expensive execute evaluation results difcult reproduce untrained automatic metrics untrained automatic evaluation metrics widely monitor progress system development good automatic metric needs correlate human judgments nlg tasks desirable use multiple metrics gauge different aspects system s quality machine learned evaluation metrics cases reference outputs complete train evaluation model mimic human judges pointed gao et al machine learned metrics lead potential problems overtting gaming metric conclude paper summarizing challenges evaluating nlg systems detecting machine generated text fake news language models stronger learning increasingly larger corpora human written text generate text easily distinguishable human authored text new systems evaluation methods developed detect piece text generated recent study schuster et al reports results fact verication system identify inherent bias training datasets cause fact checking issues attempt combat fake news vo lee present extensive analysis tweets new tweet generation method identify fact checking tweets tweets originally produced persuade posters stop tweeting fake news research focuses factually correct text generation goal providing users accurate information massarelli et al introduce new approach generating text factually consistent knowledge source kryscinski et al investigate methods checking consistency generated summary document summary generated making evaluation explainable explainable ai refers ai machine learning ods provide human understandable justications behaviour ehsan et al evaluation systems provide reasons decisions benecial ways instance explanation help system developers identify root causes system s quality problems unintentional bias repetition factual consistency eld explainable ai growing particularly generating explanations classier predictions nlp tasks ribeiro et al thorne et al text generation systems use evaluation methods provide justication tion decisions trusted users future nlg evaluation research focus developing easy use robust explainable evaluation tools improving corpus quality creating high quality datasets multiple reference texts essential improving reliability evaluation allowing ment new automatic metrics correlate human judgments belz reiter standardizing evaluation methods untrained automatic evaluation metrics standardized open source platforms like natural language toolkit platforms signicantly simplify process benchmarking different models nlg tasks use task specic evaluation rics metrics evaluate contextual quality informativeness generated text standard criteria human evaluation methods different nlg tasks important research community collaborate closely standardize evaluation metrics nlg tasks pursued research teams effective way achieve organize challenges shared tasks evaluating natural language generation shared task nlg developing effective human evaluations nlg tasks little consensus human evaluations conducted furthermore papers leave portant details human evaluations run evaluators people evaluated text van der lee et al clear reporting human evaluations important especially replicability purposes encourage nlg researchers design human evaluations carefully paying tention best practices described nlg crowdsourcing research include details studies data collected human evaluations possible papers allow new research consistent previous work enable direct comparisons nlg results human evaluation based shared tasks evaluation platforms provide evaluation consistency help researchers directly compare people perceive interact different nlg systems evaluating ethical issues lack systematic methods evaluating effectively nlg system avoid generating improper offensive language lem particularly challenging nlg system based neural language models output predictable result social chatbots aoice zhou et al resort hand crafted policies editorial responses system s behavior predictable pointed zhou et al completely deterministic function lead unpredictable behavior example simple answer yes perceived offensive given context encourage researchers working nlg nlg evaluation focus challenges moving forward help sustain broaden progress seen nlg far org io org sympa info eval gen chal com evanmiltenburg shared task nlg evaluation bibliography abhaya agarwal alon lavie meteor m bleu m ter evaluation metrics high correlation human rankings machine translation output proceedings workshop statistical machine translation statmt pp usa association tational linguistics isbn eneko agirre aitor gonzalez agirre inigo lopez gazpio montse maritxalar german rigau larraitz uria task interpretable semantic textual similarity pp manex agirrezabal bertol arrieta aitzol astigarraga mans hulden pos tag based poetry generation wordnet proceedings european workshop natural language generation pp soa bulgaria august association computational tics url aclweb org anthology jorge agnese jonathan herrera haicheng tao xingquan zhu survey taxonomy adversarial neural networks text image synthesis wires data mining knowledge discovery feb issn widm url widm ahmed ali walid magdy peter bell steve renais multi reference wer evaluating asr languages orthographic rules pp asru ramiz aliguliyev measure similarity measure automatic text summarization vychislitelnye tekhnologii jacopo amidei paul piwek alistair willis rethinking agreement human evaluation tasks coling jacopo amidei paul piwek alistair willis agreement overrated plea correlation assess human evaluation reliability inlg jacopo amidei paul piwek alistair willis use rating likert scales natural inlg language generation human evaluation tasks review recommendations url com assets pdf peter anderson basura fernando mark johnson stephen gould spice semantic tional image caption evaluation eccv url org erion c ano ondrej bojar keyphrase generation multi aspect survey sanjeev arora yingyu liang tengyu ma simple tough beat baseline sentence embeddings january international conference learning representations iclr conference date ron artstein massimo poesio inter coder agreement computational linguistics tional linguistics dzmitry bahdanau kyunghyun cho yoshua bengio neural machine translation jointly learning align translate iclr shuang bai shan va survey automatic image caption generation neuro computing pp mousumi banerjee michelle hopkins capozzoli laura mcsweeney debajyoti sinha yond kappa review interrater agreement measures satanjeev banerjee alon lavie meteor automatic metric mt evaluation proceedings acl workshop improved correlation human judgments trinsic extrinsic evaluation measures machine translation summarization pp ann arbor michigan june association computational linguistics url aclweb org anthology ellen gurman bard dan robertson antonella sorace magnitude estimation linguistic acceptability language issn url jstor org regina barzilay lillian lee learning paraphrase unsupervised approach sequence alignment hlt naacl main proceedings pp anja belz ehud reiter comparing automatic human evaluation nlg systems conference european chapter association computational linguistics trento italy april association computational linguistics url aclweb anthology alan black susanne burger alistair conkie helen hastie simon keizer oliver lemon nicolas merigaud gabriel parent gabriel schubiner blaise thomson jason williams kai yu steve young maxine eskenazi spoken dialog challenge comparison live control test results pp antoine bosselut asli celikyilmaz xiaodong jianfeng gao po sen huang yejin choi discourse aware neural rewards coherent text generation conference north american chapter association computational linguistics human language nologies naacl hlt july massimo caccia lucas caccia william fedus hugo larochelle joelle pineau laurent lin language gans falling short corr url org chris callison burch miles osborne evaluating role bleu machine translation research eacl pp chris callison burch cameron fordyce philipp koehn christof monz josh schroeder evaluation machine translation proceedings second workshop statistical machine translation pp prague czech republic june association computational linguistics url aclweb org anthology asli celikyilmaz antoine bosselut xiaodong yejin choi deep communicating agents abstractive summarization july daniel m cer mona t diab eneko agirre inigo lopez gazpio lucia specia task semantic textual similarity multilingual cross lingual focused evaluation corr url org liqun chen shuyang dai chenyang tao haichao zhang zhe gan dinghan shen yizhe zhang guoyin wang ruiyi zhang lawrence carin adversarial text generation feature mover s distance s bengio h wallach h larochelle k grauman n bianchi r garnett eds advances neural information processing systems pp curran associates inc url nips cc adversarial text generation feature movers distance pdf qian chen xiaodan zhu zhen hua ling si wei hui jiang diana inkpen enhanced lstm natural language inference proceedings annual meeting association computational linguistics volume long papers pp vancouver canada july association computational linguistics url https aclweb org anthology yen chun chen mohit bansal fast abstractive summarization reinforce selected sentence rewriting proceedings annual meeting association computational guistics volume long papers pp melbourne australia july association computational linguistics url aclweb anthology kyunghyun cho bart van merrienboer caglar gulcehre dzmitry bahdanau fethi bougares ger schwenk yoshua bengio learning phrase representations rnn encoder decoder statistical machine translation proceedings conference empirical methods natural language processing emnlp pp doha qatar october tion computational linguistics url aclweb org anthology julian chow lucia specia pranava madhyastha wmdo fluency based word mover s tance machine translation evaluation proceedings fourth conference machine translation volume shared task papers day pp florence italy august association computational linguistics url aclweb org elizabeth clark asli celikyilmaz noah smith sentence mover s similarity automatic evaluation multi sentence texts acl j clarke m lapata global inference sentence compression integer linear programming approach journal articial intelligence research arman cohan nazli goharian revisiting summarization evaluation scientic articles corr url org jacob cohen coefcient agreement nominal scales educational psychological surement jacob cohen weighted kappa nominal scale agreement provision scaled disagreement partial credit psychological bulletin url alexis conneau douwe kiela holger schwenk loc barrault antoine bordes supervised learning universal sentence representations natural language inference data ings conference empirical methods natural language processing pp copenhagen denmark september association computational linguistics url aclweb org anthology scott crossley minkyung kim laura allen danielle mcnamara automated articial intelligence tion evaluation ase natural language processing tools ucation international conference aied proceedings lecture notes computer science including subseries lecture notes articial intelligence lecture notes formatics pp springer verlag yin cui guandao yang andreas veit xun huang serge j belongie learning evaluate image captioning corr url org raj dabre chenhui chu anoop kunchukuttan comprehensive survey multilingual neural machine translation tunable metric daniel dahlmeier chang liu hwee tou ng tesla wmt translation evaluation andrew m dai christopher olah quoc v le document embedding paragraph vectors neurips deep learning workshop sumanth dathathri andrea madotto janice lan jane hung eric frank piero molino jason ski rosanne liu plug play language models simple approach controlled text generation iclr luciano del corro rainer gemulla clausie clause based open information extraction proceedings international conference world wide web www pp new york ny usa association computing machinery isbn doi url etienne denoual yves lepage bleu characters automatic mt evaluation guages word delimiters companion volume proceedings conference ing posters demos tutorial abstracts url aclweb org jan deriu alvaro rodrigo arantxa otegi guillermo echegoyen sophie rosset eneko agirre mark cieliebak evaluation metrics text summarization computing informatics url cai sk ojs index php cai article jan deriu alvaro rodrigo arantxa otegi guillermo echegoyen sophie rosset eneko agirre mark cieliebak survey evaluation methods dialogue systems corr url org jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language understanding corr url http org djellel eddine difallah elena filatova panagiotis g ipeirotis demographics dynamics mechanical turk workers proceedings eleventh acm international conference web search data mining george doddington automatic evaluation machine translation quality n gram occurrence statistics pp chris brockett paraphrases asia bill dolan sentential ing automatically constructing corpus sentential january microsoft com en research constructing international workshop automatically natural processing federation language url li dong nan yang wenhui wang furu wei xiaodong liu yu wang jianfeng gao ming zhou hsiao wuen hon unied language model pre training natural language understanding generation corr url org xinya du junru shao claire cardie learning ask neural question generation reading comprehension corr url org ondrej dusek jekaterina novikova verena rieser referenceless quality estimation ral language generation corr url org ondrej dusek jekaterina novikova verena rieser evaluating state art end end natural language generation nlg challenge corr url org upol ehsan pradyumna tambwekar larry chan brent harrison mark o riedl automated rationale generation technique explainable ai effects human perceptions ceedings international conference intelligent user interfaces mar doi url m elsner e charniak coreference inspired coherence modeling proceedings annual meeting association computational linguistics human language gies short papers matan eyal tal baumel michael elhadad question answering automatic evaluation metric news article summarization proceedings conference north url matan eyal tal baumel michael elhadad question answering automatic evaluation ric news article summarization proceedings conference north american chapter association computational linguistics human language technologies ume long short papers pp minneapolis minnesota june tion computational linguistics url aclweb org anthology angela fan mike lewis yann n dauphin hierarchical neural story generation corr url org angela fan yacine jernite ethan perez david grangier jason weston michael auli long form question answering corr url org angela fan mike lewis yann n dauphin strategies structuring story generation corr url org jl fleiss measuring nominal scale agreement raters psychological bulletin november issn url zhenxin fu xiaoye tan nanyun peng dongyan zhao rui yan style transfer text ploration evaluation thirty second aaai conference articial intelligence michael gamon linguistic correlates style authorship classication deep linguistic analysis features association computational linguistics jianfeng gao michel galley lihong li neural approaches conversational ai foundations trends r information retrieval cristina garbacea samuel carton shiyan yan qiaozhu mei judge judges large scale evaluation study neural language models online review generation corr url org albert gatt emiel krahmer survey state art natural language generation core tasks applications evaluation j artif intell res m ghazvininejad x shi y choi k knight generating topical poetry emnlp dimitra gkatzia saad mahamood snapshot nlg evaluation practices proceedings european workshop natural language generation enlg pp brighton uk september association computational linguistics url https aclweb org anthology yoav goldberg graeme hirst yang liu meng zhang neural network methods natural language processing computational linguistics volume zhengxian gong min zhang guodong zhou document level machine translation evaluation gist consistency text cohesion pp ian j goodfellow jean pouget abadie mehdi mirza bing xu david warde farley sherjil ozair aaron courville yoshua bengio generative adversarial networks arxiv cyril goutte automatic evaluation machine translation quality yvette graham evaluating automatic summarization bleu shades rouge proceedings conference empirical methods natural language processing pp lisbon portugal september association computational linguistics url aclweb org anthology yvette graham timothy baldwin testing signicance increased correlation human judgment proceedings conference empirical methods natural language processing emnlp pp doha qatar october association computational linguistics url aclweb org anthology alex graves generating sequences recurrent neural networks corr url org beliz gunel chenguang zhu michael zeng xuedong huang mind facts boosted coherent abstractive text summarization knowledge representation reasoning meets machine learning workshop neurips najeh hajlaoui andrei popescu belis assessing accuracy discourse connective lations validation automatic metric proceedings international conference computational linguistics intelligent text processing aaron l han derek wong machine translation evaluation survey org aaron l han derek wong lidia chao liangye yi lu unsupervised quality estimation model english german translation application extensive supervised evaluation scientic world journal aaron l han derek wong lidia chao liangye yi lu junwen xing xiaodong zeng mt language independent model machine translation evaluation reinforced factors lifeng han machine translation evaluation resources methods survey ireland postgraduate research conference tatsunori hashimoto hugh zhang percy liang unifying human statistical evaluation natural language generation proceedings conference north american ter association computational linguistics human language technologies volume long short papers pp minneapolis minnesota june association computational linguistics url aclweb org anthology helen hastie anja belz comparative evaluation methodology nlg interactive systems proceedings ninth international conference language resources evaluation pp reykjavik iceland european language resources sociation elra url lrec conf org proceedings paper pdf helen f hastie anja belz comparative evaluation methodology nlg interactive systems lrec karl moritz hermann tomas kocisky edward grefenstette lasse espeholt kay mustafa leyman phil blunsom teaching machines read comprehend corr url org martin heusel hubert ramsauer thomas unterthiner bernhard nessler gunter klambauer sepp hochreiter gans trained time scale update rule converge nash equilibrium corr url org felix hill kyunghyun cho anna korhonen learning distributed representations sentences unlabelled data corr url org sepp hochreiter jurgen schmidhuber long short term memory neural computation ari holtzman jan buys maxwell forbes yejin choi curious case neural text ation iclr md zakir hossain ferdous sohel mohd fairuz shiratuddin hamid laga comprehensive survey deep learning image captioning corr url arxiv org liang huang kai zhao mingbo ma nish optimal beam search neural text generation modulo beam size proceedings conference empirical methods natural language processing url po sen huang xiaodong jianfeng gao li deng alex acero larry heck acm cikm url microsoft com en research ing deep structured semantic models web search click data international conference information knowledge management tober learning deep structured semantic models web search clickthrough xuedong huang fileno alleva hsiao wuen hon mei yuh hwang ronald rosenfeld sphinx ii speech recognition system overview computer speech language text inspector measure lexical diversity url com lexical turk hcomp panagiotis g ipeirotis f provost jing wang quality management amazon mechanical hideki isozaki tsutomu hirao kevin duh katsuhito sudoh hajime tsukada automatic proceedings evaluation translation quality distant language pairs ference empirical methods natural language processing pp cambridge ma october association computational linguistics url aclweb anthology ming jiang qiuyuan huang lei zhang xin wang pengchuan zhang zhe gan jana diesner jianfeng gao tiger text image grounding image caption evaluation emnlp november shaq joty francisco guzman lluis marquez preslav nakov discourse structure machine translation evaluation computational linguistics daniel jurafsky james h martin asking answering questions evaluate factual sistency summaries filip jurccek simon keizer milica gasic francois mairesse blaise thomson kai yu steve young real user evaluation spoken dialogue systems amazon mechanical turk pp sushant kae matt huenerfauth evaluating usability automatically generated captions people deaf hard hearing proceedings international acm cess conference computers accessibility pp new york ny usa association computing machinery isbn hassan kane yusuf kocyigit pelkins ajanoh ali abdalla mohamed coulibali neural language evaluators neurips document intelligence workshop david kauchak regina barzilay paraphrasing automatic evaluation human language technology conference north american chapter association computational guistics mert kilickaya aykut erdem nazli ikizler cinbis erkut erdem evaluating automatic metrics image captioning proceedings conference european chapter association computational linguistics volume long papers url yoon kim sam wiseman alexander m rush tutorial deep latent variable models natural language corr url org svetlana kiritchenko saif m mohammad capturing reliable ne grained sentiment tions crowdsourcing best worst scaling proceedings conference north american chapter association computational linguistics human language technologies pp san diego california june association computational linguistics url aclweb org anthology ryan kiros yukun zhu ruslan salakhutdinov richard s zemel antonio torralba raquel tasun sanja fidler skip thought vectors corr url http org dan klein christopher d manning accurate unlexicalized parsing proceedings annual meeting association computational linguistics pp sapporo japan july association computational linguistics url aclweb anthology d knight k marcu statistics based summarization step sentence compression ceeding national conference american association articial intelligence pp rik koncel kedziorski dhanush bekal yi luan mirella lapata hannaneh hajishirzi text generation knowledge graphs graph transformers arxiv e krahmer m theune empirical methods natural language generation data oriented methods empirical evaluation lncs sublibrary articial intelligence springer isbn url google com klaus krippendorff estimating reliability systematic error random error interval data educational psychological measurement wojciech kryscinski bryan mccann caiming xiong richard socher evaluating factual consistency abstractive text summarization wojciech kryscinski nitish shirish keskar bryan mccann caiming xiong richard socher proceedings conference neural text summarization critical evaluation empirical methods natural language processing international joint ence natural language processing emnlp ijcnlp pp hong kong china november association computational linguistics url aclweb anthology m j kusner y sun n kolkin k q weinberger word embeddings document distances icml lori lamel sophie rosset jean luc gauvain samir bennacef matine garnier rizet bernard prouts limsi arise system speech communication pp weiyu lan xirong li jianfeng dong fluency guided cross lingual image captioning acl multimedia url org mirealla lapata probabilistic text structuring experiments sentence ordering proceedings annual meeting association computational linguistics association tational linguistics mirealla lapata regina barzilay automatic evaluation text coherence models sentations kaelbling l p safotti eds ijcai professional book center alex lascarides nicholas asher discourse relations defeasible knowledge nual meeting association computational linguistics pp berkeley california usa june association computational linguistics url aclweb anthology alon lavie abhaya agarwal meteor automatic metric mt evaluation high levels correlation human judgments proceedings second workshop statistical machine translation statmt pp usa association computational linguistics alon lavie kenji sagae shyamsundar jayaraman signicance recall automatic metrics mt evaluation amta audrey j lee mark przybocki nist machine translation evaluation ofcial results chris van der lee albert gatt emiel van miltenburg sander wubben emiel krahmer best practices human evaluation automatically generated text inlg url https com assets pdf gregor leusch nicola uefng hermann ney cder efcient mt evaluation block movements conference european chapter association computational linguistics trento italy april association computational linguistics url https aclweb org anthology jinchao li qi zhu baolin peng lars liden runze liang ryuichi takanobu shahin shayandeh swadheen shukla zheng zhang minlie huang jianfeng gao multi domain task oriented dialog challenge ii jiwei li michel galley chris brockett jianfeng gao bill dolan diversity promoting objective function neural conversation models proceedings conference north american chapter association computational linguistics human language technologies pp san diego california june association computational linguistics url aclweb org anthology nannan li zhenzhong chen learning compact reward image captioning arxiv sheng li zhiqiang tao yun fu visual text survey image video captioning ieee transactions emerging topics computational intelligence tetci zhongyang li xiao ding ting liu generating reasonable diversied story ending ing sequence sequence model adversarial training proceedings tional conference computational linguistics pp santa fe new mexico usa august association computational linguistics url aclweb anthology chin yew lin rouge package automatic evaluation summaries text summarization branches pp barcelona spain july association computational tics url aclweb org anthology chin yew lin franz josef och automatic evaluation machine translation quality proceedings annual longest common subsequence skip bigram statistics meeting association computational linguistics pp barcelona spain july url aclweb org anthology dahua lin sanja fidler chen kong raquel urtasun visual semantic search retrieving videos complex textual queries cvpr chia wei liu ryan lowe iulian serban mike noseworthy laurent charlin joelle pineau evaluate dialogue system empirical study unsupervised evaluation rics dialogue response generation proceedings conference empirical ods natural language processing pp austin texas november association computational linguistics url aclweb org anthology ding liu daniel gildea syntactic features evaluation machine translation proceedings acl workshop intrinsic extrinsic evaluation measures machine translation summarization pp ann arbor michigan june association tional linguistics url aclweb org anthology feifan liu yang liu correlation rouge human evaluation extractive meeting proceedings annual meeting association computational summaries linguistics human language technologies short papers hlt short pp usa association computational linguistics lixin liu jiajun tang xiaojun wan zongming guo generating diverse descriptive image captions visual paraphrases siqi liu zhenhai zhu ning ye sergio guadarrama kevin murphy improved image xiaodong liu ing policy gradient optimization spider pp pengcheng weizhu chen multi task june natural microsoft com en research deep neural networks multi task deep neural networks natural language yinhan liu myle ott naman goyal jingfei du mandar joshi danqi chen omer levy mike lewis luke zettlemoyer veselin stoyanov roberta robustly optimized bert pretraining approach corr url org language understanding acl jianfeng gao url chi kiu lo meant accurate semantic mt evaluation output language wmt chi kiu lo yisi unied semantic mt quality evaluation estimation metric languages different levels available resources proceedings fourth conference machine translation volume shared task papers day pp florence italy august association computational linguistics url aclweb org anthology chi kiu lo anand karthik tumuluru dekai wu fully automatic semantic mt evaluation hlt lajanugen logeswaran honglak lee efcient framework learning sentence international conference learning representations url https sentations net dang hoang long minh tien nguyen ngo xuan bach le minh nguyen tu minh phuong entailment based scoring method content selection document summarization ceedings ninth international symposium information communication technology pp new york ny usa association computing machinery jordan j louviere terry n flynn j marley best worst scaling theory methods applications cambridge university press ryan lowe michael noseworthy iulian vlad serban nicolas angelard gontier yoshua bengio joelle pineau automatic turing test learning evaluate dialogue responses acl url org sidi lu yaoming zhu weinan zhang jun wang yong yu neural text generation past present corr url org samuel laubli sheila castilho graham neubig rico sennrich qinlan shen antonio toral set recommendations assessing human machine parity language translation journal articial intelligence research kelvin luu rik koncel kedziorski kyle lo isabel cachola noah smith citation text generation arxiv nabin maharjan rajendra banjade dipesh gautam lasang j tamang vasile rus dt team task semantic similarity alignments sentence level embeddings gaussian mixture model output proceedings international workshop semantic evaluation vancouver canada august association computational linguistics url aclweb org anthology w c mann s thompson rhetorical structure theory description construction text kempen g eds natural language generation nato asi series series e structures applied sciences daniel marcu discourse structures text summaries proceedings workshop intelligent scalable text summarization pp martin m przybocki nist speaker recognition evaluation overview lara j martin prithviraj ammanabrolu william hancock shruti singh brent harrison mark o riedl event representations automated story generation deep neural nets corr url org luca massarelli fabio petroni aleksandra piktus myle ott tim rocktaschel vassilis plachouras fabrizio silvestri sebastian riedel decoding strategies affect veriability erated text nitika mathur timothy baldwin trevor cohn putting evaluation context proceedings annual tual embeddings improve machine translation evaluation meeting association computational linguistics pp florence italy july association computational linguistics url https aclweb org anthology nitika mathur timothy baldwin trevor cohn tangled bleu reevaluating evaluation automatic machine translation evaluation metrics association computational linguistics acl joshua maynez shashi narayan bernd bohnet ryan t mcdonald faithfulness tuality abstractive summarization arxiv p m mccarthy s jarvis mtld vocd d hd d validation study sophisticated approaces behaviour research methods volume pp lexical diversity assessment url springer com brm iain mccowan darren moore john dines daniel gatica perez mike flynn pierre wellner herve bourlard use information retrieval measures speech recognition evaluation kathleen r mckeown text generation discourse strategies focus constraints generate natural language text studies natural language processing melamed ryan green joseph turian precision recall machine translation thomas meyer andrei popescu belis najeh hajlaoui andrea gesmundo machine translation labeled discourse connectives proceedings tenth conference association machine translation americas tomas mikolov ilya sutskever kai chen greg corrado jeffrey dean distributed sentations words phrases compositionality corr url org george miller wordnet lexical database english association computing machinery november tanushree mitra clayton j hutto eric gilbert comparing process centric gies obtaining quality data amazon mechanical turk proceedings annual acm conference human factors computing systems ehsan montahaei danial alihosseini mahdieh soleymani baghshah jointly measuring versity quality text generation models corr url http org ehsan montahaei danial alihosseini mahdieh soleymani baghshah jointly measuring sity quality text generation models neuralgen workshop naacl url org shashi narayan shay b cohen mirella lapata ranking sentences extractive tion reinforcement learning july preksha nema mitesh m khapra better metric evaluating question generation systems corr url org ani nenkova rebecca passonneau evaluating content selection summarization pyramid method pp austin lee nichols jon k maner good subject effect investigating participant demand characteristics journal general psychology sonja nieen franz josef och gregor leusch hermann ney evaluation tool proceedings second chine translation fast evaluation mt research tional conference language resources evaluation athens greece european language resources association elra url lrec conf org proceedings pdf jekaterina novikova ondrej dusek amanda cercas curry verena rieser need new evaluation metrics nlg proceedings conference empirical methods ural language processing pp copenhagen denmark september association computational linguistics url aclweb org anthology jekaterina novikova ondrej dusek verena rieser rankme reliable human ratings ral language generation proceedings conference north american chapter association computational linguistics human language technologies volume short papers pp new orleans louisiana june association computational tics url aclweb org anthology kenji ono kazuo sumita seiji miike abstract generation based rhetorical structure tion proceedings international conference computational linguistics daniel m oppenheimer tom meyvis nicolas davidenko instructional manipulation checks detecting satiscing increase statistical power journal experimental social psychology martin t orne social psychology psychological experiment particular reference demand characteristics implications sebastian pado michel galley dan jurafsky christoper manning textual entailment features machine translation evaluation pp liangming pan wenqiang lei tat seng chua min yen kan recent advances neural tion generation url org joybrata panja sudip kumar naskar iter improving translation edit rate optimizable edit costs proceedings conference machine translation shared task papers pp association computational linguistics url aclweb org anthology kishore papineni salim roukos todd ward wei jing zhu bleu method automatic evaluation machine translation proceedings annual meeting association computational linguistics association computational linguistics jae sung park marcus rohrbach trevor darrell anna rohrbach adversarial inference multi sentence video description corr url rebecca passonneau measuring agreement set valued items masi semantic matic annotation proceedings fifth international conference language resources evaluation genoa italy european language resources association elra url lrec conf org proceedings pdf ramakanth pasunuru mohit bansal multi task video captioning video entailment generation corr url org tom pelsmaeker wilker aziz effective estimation deep generative language models corr url org baolin peng chenguang zhu chunyuan li xiujun li jianfeng gao february shot natural language generation task oriented jinchao li michael zeng task oriented dialog language generation url microsoft com en research shot natural jeffrey pennington richard socher christopher d manning glove global vectors word representation empirical methods natural language processing emnlp pp url aclweb org anthology matthew e peters mark neumann mohit iyyer matt gardner christopher clark kenton lee luke zettlemoyer deep contextualized word representations proc naacl maja popovic chrf character n gram score automatic mt evaluation proceedings tenth workshop statistical machine translation pp lisbon portugal september association computational linguistics url https aclweb org anthology maja popovic david vilar eleftherios avramidis aljoscha burchardt evaluation references scores evaluation metrics pp chris quirk chris brockett william dolan monolingual machine translation paraphrase generation emnlp alec radford karthik narasimhan tim salimans ilya sutskever improving language derstanding generative pre training url amazonaws com assets researchcovers languageunsupervised language understanding paper pdf alec radford jeff wu rewon child david luan dario amodei ilya sutskever language models unsupervised multitask learners pranav rajpurkar jian zhang konstantin lopyrev percy liang squad questions machine comprehension text proceedings conference empirical methods natural language processing emnlp association computational linguistics hannah rashkin asli celikyilmaz yejin choi jianfeng gao plotmachines conditioned generation dynamic plot state tracking arxiv nils reimers iryna gurevych sentence bert sentence embeddings siamese networks katharina reinecke krzysztof z gajos labinthewild conducting large scale online ments uncompensated samples cscw ehud reiter structured review validity bleu computational linguistics september url aclweb org anthology ehud reiter ehud reiter s blog url com blog ehud reiter anja belz investigation validity metrics automatically evaluating natural language generation systems computational linguistics ehud reiter anja belz investigation validity metrics automatically evaluating natural language generation systems comput linguist december url coli ehud reiter robert dale building applied natural language generation systems cambridge university press cambridge uk ehud reiter roma robertson liesl osman lessons failure generating tailored ing cessation letters artif intell marco tulio ribeiro sameer singh carlos guestrin trust explaining predictions classier corr url org marco tulio ribeiro sameer singh carlos guestrin anchors high precision model agnostic explanations aaai brian richards type token ratios tell journal child language alan ritter colin cherry cial media uary data driven response generation social data driven response generation empirical methods natural language processing emnlp url microsoft com en research bill dolan m roemmele gordon r swanson evaluating story generation systems automated linguistic analyses workshop machine learning creativity sigkdd ence knowledge discovery data mining kdd antti veikko rosti spyros matsoukas richard schwartz improved word level system bination machine translation proc acl pp y rubner c tomasi l j guibas metric distributions applications image databases ieee sebastian schuster ranjay krishna angel chang li fei fei christopher d manning erating semantically precise scene graphs textual descriptions improved image retrieval proceedings fourth workshop vision language pp lisbon portugal september association computational linguistics url aclweb anthology tal schuster darsh shah yun jie serene yeo daniel roberto filizzola ortiz enrico santus regina barzilay debiasing fact verication models proceedings conference empirical methods natural language processing international joint ence natural language processing emnlp ijcnlp url william scott reliability content analysis case nominal scale coding issn url http public opinion quarterly jstor org joao sedoc daphne ippolito arun kirubarajan jai thirani lyle ungar chris callison burch chateval tool chatbot evaluation abigail peter j liu christopher d manning point summarization proceedings annual meeting association pointer generator networks computational linguistics volume long papers pp vancouver canada july association computational linguistics url aclweb anthology thibault sellam dipanjan das ankur p parikh bleurt learning robust metrics text generation stanislau semeniuta aliaksei severyn sylvain gelly accurate evaluation gans guage generation corr url org stanislau semeniuta aliaksei severyn sylvain gelly accurate evaluation gans language generation iclr url net iulian vlad serban tim klinger gerald tesauro kartik talamadupula bowen zhou yoshua gio aaron c courville multiresolution recurrent neural networks application alogue response generation corr url org iulian vlad serban alessandro sordoni ryan lowe laurent charlin joelle pineau aaron c courville yoshua bengio hierarchical latent variable encoder decoder model ing dialogues corr url org naeha sharif lyndon white mohammed bennamoun syed afaq ali shah learning based composite metrics improved caption evaluation proceedings acl student search workshop pp melbourne australia july association computational linguistics url aclweb org anthology tian shi yaser keneshloo naren ramakrishnan chandan k reddy neural abstractive text summarization sequence sequence models corr url http org hiroki shimanaka tomoyuki kajiwara mamoru komachi ruse regressor sentence embeddings automatic machine translation evaluation proceedings conference machine translation shared task papers pp belgium brussels october association computational linguistics url aclweb org abhisek singh wei jin ranking summaries informativeness coherence withouth erence summaries proceedings ninth international florida artical intelligent research society conference matthew snover bonnie dorr richard schwartz linnea micciulla john makhoul study translation edit rate targeted human annotation pp m sporleder c lapata discourse chunking application sentence compression ceedings hlt emnlp pp peter stanchev weiyue wang hermann ney eed extended edit distance measure machine translation proceedings fourth conference machine translation volume shared task papers day pp florence italy august association computational linguistics url aclweb org anthology manfred stede carla umbach dimlex lexicon discourse markers text generation understanding proceedings annual meeting association computational linguistics international conference computational linguistics volume acl coling pp usa association computational linguistics josef steinberger karel jezek evaluation measures text summarization computing informatics k steinberger j jezek sentence compression lsa based summarizer proceedings international conference information systems implementation modelling pp octavia maria sulea recognizing textual entailment twitter word embeddings workshop evaluating vector space representations nlp yu sun shuohuan wang yu kun li shikun feng hao tian hua wu haifeng wang ernie continual pre training framework language understanding corr url org manne suneetha sheerin fatima extraction based automatic text summarization system hmm tagger international journal soft computing engineering issn ilya sutskever oriol vinyals quoc v le sequence sequence learning neural networks corr url org liling tan jon dehdari josef van genabith awkward disparity bleu ribes scores human judgements machine translation proceedings workshop asian translation pp kyoto japan october workshop asian lation url aclweb org anthology rachel evaluating text output nlp bleu risk tatman risk evaluating output url bleu nlp text james thorne andreas vlachos christos christodoulopoulos arpit mittal generating level explanations natural language inference corr url http org c tillmann s vogel h ney zubiaga h sawaf accelerated dp based search statistical translation european conf speech communication technology pp jesus tomas josep angel mas francisco casacuberta quantitative method machine proceedings eacl workshop evaluation initiatives translation evaluation natural language processing evaluation methods metrics resources reusable pp columbus ohio april association computational linguistics url https aclweb org anthology m turing computing machinary intelligence mind url mind lix chris van der lee albert gatt emiel van miltenburg sander wubben emiel krahmer best practices human evaluation automatically generated text proceedings international conference natural language generation url aclweb org anthology ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez neurips pp ukasz kaiser illia polosukhin attention need ramakrishna vedantam c lawrence zitnick devi parikh cider consensus based image description evaluation corr url org oriol vinyals alexander toshev samy bengio dumitru erhan tell neural image caption generator corr url org oriol vinyals meire fortunato navdeep jaitly pointer networks nguyen vo kyumin lee learning fact checkers analysis generation fact checking language proceedings international acm sigir conference research velopment information retrieval pp new york ny usa ation computing machinery isbn url alex wang kyunghyun cho mike lewis asking answering questions evaluate factual consistency summaries weiyue wang jan thorsten peter hendrik rosendahl hermann ney character translation proceedings conference machine translation edit rate character level volume shared task papers pp berlin germany august association computational linguistics url aclweb org anthology sean welleck ilia kulikov stephen roller emily dinan kyunghyun cho jason weston neural text generation unlikelihood training billy t m wong chunyu kit extending machine translation evaluation metrics lexical cohesion document level pp lingfei wu ian en hsu yen kun xu fangli xu avinash balakrishnan pin yu chen pradeep ravikumar michael j witbrock word mover s embedding document embedding emnlp yu yan weizhen qi yeyun gong dayiheng liu nan duan jiusheng chen ruofei zhang ming zhou prophetnet predicting future n gram sequence sequence pre training arxiv qian yang rebecca j passonneau gerard de melo peak pyramid evaluation automated knowledge extraction proceedings thirtieth aaai conference articial intelligence lili yao nanyun peng ralph m weischedel kevin knight dongyan zhao rui yan write better automatic storytelling corr url http org yasuhisa yoshida jun suzuki tsutomu hirao masaaki nagata dependency based proceedings conference course parser single document summarization empirical methods natural language processing emnlp pp doha qatar october association computational linguistics url aclweb anthology r michael young grice s maxim quantity select content plan descriptions artif intell hui yu xiaofeng wu jun xie wenbin jiang qun liu shouxun lin red reference proceedings coling dependency based mt evaluation metric tional conference computational linguistics technical papers pp dublin land august dublin city university association computational linguistics url aclweb org anthology hui yu xiaofeng wu wenbin jiang qun liu shouxun lin automatic machine translation evaluation metric based dependency parsing model xingdi yuan tong wang caglar gulcehre alessandro sordoni philip bachman saizheng zhang sandeep subramanian adam trischler machine comprehension text text neural tion generation proceedings workshop representation learning nlp pp association computational linguistics august url aclweb org anthology rowan zellers ari holtzman hannah rashkin yonatan bisk ali farhadi franziska roesner yejin choi defending neural fake news neurips rowan zellers ari holtzman elizabeth clark lianhui qin ali farhadi yejin choi evaluating machines real world language use arxiv jacob zerr question generation speech information final report reu program uccs url uccs work reu finalpapers zerr pdf qiuyun zhang bin guo hao wang yunji liang shaoyang hao zhiwen yu ai powered text generation harmonious human machine interaction current state future directions corr url org tianyi zhang varsha kishore felix wu kilian q weinberger yoav artzi bertscore ating text generation bert international conference learning representations url net ying zhang stephan vogel alex waibel interpreting bleu nist scores ment need better system proceedings proceedings language resources evaluation pp yuhao zhang derek merck emily bao tsai christopher d manning curtis p langlotz optimizing factual correctness summary study summarizing radiology reports arxiv wei zhao maxime peyrard fei liu yang gao christian m meyer steffen eger moverscore text generation evaluating contextualized embeddings earth mover distance emnlp li zhou jianfeng gao di li heung yeung shum design implementation xiaoice empathetic social chatbot computational linguistics wangchunshu zhou ke xu learning compare better training evaluation open domain natural language generation models yaoming zhu sidi lu lei zheng jiaxian guo weinan zhang jun wang yong yu texygen benchmarking platform text generation models corr url http org
