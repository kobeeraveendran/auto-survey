v o n l c s c v v i x r a generative adversarial network for abstractive text summarization linqing yao min qiang jia hongyan institutes of advanced technology chinese academy of sciences machine intelligence institute of computer science south china normal university key laboratory of machine perception peking university likicode min com ac scnu edu pku edu abstract in this paper we propose an adversarial process for tive text summarization in which we simultaneously train a generative model g and a discriminative model d in ticular we build the generator g as an agent of ment learning which takes the raw text as input and predicts the abstractive summarization we also build a discriminator which attempts to distinguish the generated summary from the ground truth summary extensive experiments strate that our model achieves competitive rouge scores with the state of the art methods on cnn daily mail dataset qualitatively we show that our model is able to generate more abstractive readable and diverse introduction abstractive text summarization is the task of generating a short and concise summary that captures the salient ideas of the source text the generated summaries tially contain new phrases and sentences that may not pear in the source text in the past decades a urry of studies have been conducted on abstractive text rization nallapati et al see liu and manning paulus xiong and socher despite the remarkable progress of previous studies abstractive summarization is still challenged by neural sequence to sequence models tend to generate trivial and generic summary often involving high frequency phrases the generated summaries have limited grammaticality and readability in most previous work the standard sequence to sequence models are trained to predict the next word in summary using the likelihood estimation mle objective function however this strategy has two major shortcomings first the ation metric is different from the training loss second the input of the decoder in each time step is often from the true summary during the training nevertheless in the testing phase the input of the next time step is the previous word the work was partially supported by cas pioneer hundred talents program and the moe key laboratory of machine ception at peking university under grant number q qu is the corresponding author copyright association for the advancement of articial intelligence www aaai org all rights reserved material com generated by the decoder this exposure bias leads to error accumulation at test time to address the above challenge in this paper we propose an adversarial framework to jointly train a generative model g and a discriminative model d specically the generator g takes the original text as input and generate the summary we use reinforcement learning i e policy gradient to mize g for a highly rewarded summary thus it effectively bypasses exposure bias and non differentiable task metrics issues we implement the discriminator d as a text classier that learns to classify the generated summaries as machine or human generated the generator g and the tor d are optimized with a minimax two player game the discriminator d tries to distinguish the ground truth maries from the generated summaries by the generator g while the training procedure of generator g is to maximize the probability of d making a mistake thus this ial process can eventually adjust g to generate plausible and high quality abstractive summaries to the training our model similar strategy standard goodfellow et al we simultaneously train two models in an adversarial manner a generative model g and a discriminative model d we rst pre train the generative model by generating summaries given the source text then we pre train the discriminator by providing positive examples from the human generated summaries and the negative examples produced from the pre trained generator after the pre training the generator and discriminator are trained alternatively generative model the generator takes the source text as input and predicts the summary y ym here the n is the length of the source text and m is the length of the predicted summary we use a text directional lstm encoder to convert the input into a sequence of hidden states hn lowing see liu and manning on time step t an attention based lstm decoder is then used to compute the hidden state st of the decoder and a context vector the reader can refer to the supplement of this paper or see liu and manning for the implementation tails the parameters of the generator g are collectively resented by the context vector ct is concatenated with the decoder state st and fed through a fully connected layer and a softmax layer to produce the probability of predicting word from target vocabulary at each time step t pvocab yt sof v st where v v are learnable parameters similar to the work of see liu and manning we incorporate a switching pointer generator network to use either word erator from xed vocabulary or pointer copying rare or seen from the input sequence finally we can get the nal probability p yt of each token yt in the summary discriminative model the discriminator is a binary classier and aims at guishing the input sequence as originally generated by mans or synthesized by machines we encode the input quence with a cnn as it shows great effectiveness in text classication kim we use multiple lters with ing window sizes to obtain different features and then apply a max over time pooling operation over the features these pooled features are passed to a fully connected softmax layer whose output is the probability of being original updating model parameters in the adversarial process using the discriminator as a ward function can further improve the generator iteratively by dynamically updating the discriminator once we obtain more realistic and high quality summaries generated by erator g we re train the discriminator as min ey pdata ey g when the discriminator d is obtained and xed we are ready to update the generator g the loss function of our generator g consists two parts the loss computed by policy gradient denoted by jpg and the maximum likelihood loss denoted by jml formally the objective function of g is j jpg where is the scaling factor to balance the magnitude difference between jpg and jml cording to the policy gradient theorem sutton et al we compute the gradient of jpg w t the parameters t t x x yt t t x jpg r g d x x eyt g rg d x log x where rg d x yt is the action value function and we have rg d x t t is the length of the text we update the parameters using stochastic gradient descent t is the generated summary up to time step t x is the source text to be condensed experiments cnn daily mail corpus the dataset dataset nallapati et al is widely used in abstractive summarization it comprises news stories in cnn and daily methods abs pgc deeprl pretrain ours rouge l human table quantitative evaluation results mail websites paired with multi sentence human generated abstractive summaries it contains training pairs validation pairs and test pairs experimental results we compare our approach including the abstractive model the pointer generator see liu and manning deeprl with three methods abs nallapati et al pgc erage and the abstractive deep reinforced model paulus xiong and socher version networks we rstly compare our model with the pre trained erator after adversarial training rouge l increase by and absolute points respectively in addition our model exhibits competitive rouge scores with the state of the art methods ically our approach achieves the best and scores we also perform human evaluation to evaluate the ability and quality of summaries we randomly select test examples from the dataset for each example two human evaluators are asked to rank each summary generated by all models based on their readability where indicates the lowest level of readability while indicates the highest level as we can observe from table our model contributes nicantly to improving the readability of summaries to evaluate the proposed model qualitatively we also port the generated summaries in supplementary les conclusion in this paper we proposed an adversarial process for tive text summarization experimental results showed that our model could generate more abstractive readable and verse summaries references goodfellow et al goodfellow i pouget abadie j mirza m xu b warde farley d ozair s courville a and bengio y generative adversarial nets in nips kim kim y convolutional neural networks for sentence classication arxiv preprint nallapati et al nallapati r zhou b gulcehre c xiang b et al abstractive text summarization ing sequence to sequence rnns and beyond arxiv preprint paulus xiong and socher paulus r xiong c and socher r a deep reinforced model for abstractive summarization arxiv preprint see liu and manning see a liu p j and to the point get arxiv preprint ning c d tion with pointer generator networks sutton et al sutton r s mcallester d a singh s p and mansour y policy gradient methods for inforcement learning with function approximation in nips
