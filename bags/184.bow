n a j r i s c v v i x r a structuring an unordered text document shashank yadav tejas shimpi c ravindranath chowdary prashant sharma deepansh agrawal shivang agarwal abstract segmenting an unordered text document into different sections is a very useful task in many text processing applications like multiple document summarization question answering this paper proposes structuring of an unordered text document based on the keywords in the document we test our approach on wikipedia documents using both statistical and predictive methods such as the textrank algorithm and google s use universal sentence encoder from our experimental results we show that the proposed model can effectively structure an unordered document into sections index terms ordering sentences text processing structuring document introduction t o structure an unordered document is an essential task in many applications it is a post requisite for tions like multiple document extractive text summarization where we have to present a summary of multiple ments it is a prerequisite for applications like question swering from multiple documents where we have to present an answer by processing multiple documents in this paper we address the task of segmenting an unordered text ment into different sections the input document summary that may have unordered sentences is processed so that it will have sentences clustered together clustering is based on the similarity with the respective keyword as well as with the sentences belonging to the same cluster keywords are identied and clusters are formed for each keyword we use textrank algorithm to extract the keywords from a text document textrank is a graph based ranking algorithm which decides the importance of a vertex within a graph by considering the global information recursively computed from the entire graph rather than focusing on local vertex specic information the model uses knowledge acquired from the entire text to extract the keywords a cluster is generated for every keyword while generating clusters the similarity between a tence and a topic keyword is calculated using the cosine similarity of embeddings generated using google s use universal sentence encoder use is claimed to have better performance of transfer learning when used with sentence level embeddings as compared to word level beddings alone this model is claimed to have better formance even if there is less task specic training data available we observed that the quality of clusters section is better if the similarity of a sentence with the keyword is considered along with the similarity of the sentence with the sentences already available in the respective section to test our approach we jumble the ordering of department of computer science and engineering iit bhu e mail jas nitin ac in rchowdary ac in prashant sharma ac in deepansh agrawal ac in shivanga rs ac in shashank yadav ac in tences in a document process the unordered document and compare the similarity of the output document with the original document related work several models have been performed in the past to retrieve sentences of a document belonging to a particular topic given a topic retrieving sentences that may belong to that topic should be considered as a different task than what we aim in this paper a graph based approach for extracting information relevant to a query is presented in where subgraphs are built using the relatedness of the sentences to the query an incremental integrated graph to represent the sentences in a collection of documents is presented in sentences from the documents are merged into a master sequence to improve coherence and ow the same ordering is used for sequencing the sentences in the extracted summary ordering of sentences in a document is discussed in in this paper we aim to generate the sections clusters from an unordered document to the best of our knowledge this is a rst attempt to address this problem formally proposed model our methodology is described in the figure the process starts by taking an unordered document as an input the next step is to extract the keywords from the input ument using textrank algorithm and store them in a list k the keywords stored in k act as centroids for the clusters note that the quality of keywords extracted will have a bearing on the nal results in this paper we present a model that can be used for structuring an unstructured document in the process we use a popular keyword traction algorithm our model is not bound to textrank and if a better keyword extraction algorithm is available it can replace textrank the next step is to nd the most relevant sentence for each keyword in k the most relevant sentence is mapped to the keyword and assigned in the respective cluster this similarity between the keyword and the sentence is lated by the cosine similarity of embeddings generated from google s use now we have a list of keywords k and a sentence mapped to each keyword the next step is to map the remaining sentences in the next step we go through all the sentences in the document that have not been mapped yet and nd the relevant keywords that can be mapped with them we do this by the following procedure y is the similarity between the current sentence and the keyword y y is the maximum similarity between the current sentence and the sentences that are already mapped with the keyword y if y has three tences mapped to it then the similarity between and the sentences mapped to y are computed and the maximum similarity among the three is assigned to the overall similarity y is calculated as y t y t y we map every other sentence to the keyword with which they have maximum similarity m y later we cluster the keywords along with the sentences mapped to them the value of t signies the importance to be given to the keyword and its associated sentences respectively in our experiments we empirically x the value of t to input document find keywords using textrank store them in k for each keyword in k find the most relevant sentence and map it map each sentence to the most appropriate cluster clusters with keword relevant sentences fig proposed methodology metrics to evaluate our algorithm to evaluate our algorithm we propose two similarity rics and these metrics compute the similarity of each section of the original document with all the tions clusters keyword and the sentences mapped to it of the output document and assign the maximum similarity between an input section and an output section is calculated as the number of sentences of the input section that are present in the output section divided by the total number of sentences in the input section to calculate the nal similarity similarity of the entire output document we take the weighted mean of similarity calculated responding to each input section between an input section and an output section is computed as the number of sentences of an input section that are present in an output set no average table results section divided by the sum of sentences in the input and output sections the nal similarity is computed in a similar manner experimental setup and results for our experiments we prepared ve sets of documents each set has wiki documents randomly chosen each document is restructured randomly sentences are ranged randomly this restructured document is the input to our model and the output document is compared against the original input document also we compare our results with the baseline being the results when we consider only the similarity between sentences and keywords the results are shown in table here both and are the mean of similarities of the entire set and are computed similar to and respectively but with the t value as in equation it is evident that the results are better if both similarities y and y are considered we proposed an efcient model to structure an unordered document we evaluated our model against the baseline and found that our proposed model has a signicant ment we observed that while ordering an unordered ment the initial sentences associated with a keyword topic play a signicant role references daniel cer yinfei yang sheng yi kong nan hua nicole limtiaco rhomni st john noah constant mario guajardo cespedes steve yuan chris tar yun hsuan sung brian strope and ray kurzweil universal sentence encoder corr c ravindranath chowdary and p sreenivasa kumar sentence dering for coherent multi document summary generation in ing data information and knowledge british national conference on databases bncod cardiff uk july proceedings pages c ravindranath chowdary and p sreenivasa kumar esum an efcient system for query specic multi document summarization in advances in information retrieval european conference on ir research ecir toulouse france april proceedings pages c ravindranath chowdary m sravanthi and p sreenivasa mar a system for query specic coherent text multi document international journal on articial intelligence tools summarization lun wei ku li ying lee tung ho wu and hsin hsi chen major topic detection and its application to opinion summarization in proceedings of the annual international acm sigir conference on research and development in information retrieval sigir pages new york ny usa acm for each sentence that has not been mapped yet loop through all the keywords in k find similarity between the sentence and the cluster belonging to that keyword conclusions rada mihalcea and paul tarau textrank bringing order into text in proceedings of the conference on empirical methods in natural language processing emnlp a meeting of sigdat a special interest group of the acl held in conjunction with acl july barcelona spain pages m sravanthi c ravindranath chowdary and p sreenivasa mar quests a query specic text summarization system in ceedings of the twenty first international florida articial intelligence research society conference may coconut grove florida usa pages aaai press
