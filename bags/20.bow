p e s r i s c v v i x r a beyond stemming and lemmatization ultra stemming to improve automatic text summarization juan manuel torres laboratoire informatique davignon bp avignon cedex france juan manuel avignon fr cole polytechnique montral cp succursale centre ville montral qubec canada abstract in automatic text summarization preprocessing is an important phase to reduce the space of textual representation classically stemming and lemmatization have been widely used for normalizing words however even using normalization on large texts the curse of dimensionality can disturb the performance of summarizers this paper describes a new method for normalization of words to further reduce the space of representation we propose to reduce each word to its initial letters as a form of ultra stemming the results show that ultra stemming not only preserve the content of summaries produced by this representation but often the performances of the systems can be dramatically improved summaries on trilingual corpora were evaluated automatically with fresa results conrm an increase in the performance regardless of summarizer system used keywords automatic text summarization lemmatization stemming ultra stemming introduction in natural language processing nlp pre processing aims to reduce the complexity of the vocabulary of the documents pre processing eliminates the punctuation lters the function words and normalizes the morphological variants in particular the lemmatization and ming are two commonly used techniques to normalize morphological variants the lexeme or word root is the part that does not change and contains its meaning the morpheme or variable part is added to the lexeme to form new words morphological analysis is a very important phase of pre processing of nlp systems because it allows to reduce the dimension of the vector space representation in systems of information retrieval several applications such as automatic summarization document indexing textual classication and question answering systems among utilize this reduction however the realization of this analysis may require the use of external resources dictionaries parsers rules which can be expensive and dicult to build depending on language or specic domain some algorithms are capable to detect statistically morphological families posed as a classication problem avoiding the utilization of external resources or a priori knowledge of a language automatic text summarization ats is the process to automatically generate a compressed version of a source document query oriented summaries focus on a user s request and extract the information related to the specied topic given explicitly in the form of a query generic mono document summarization tries to cover as much as possible the tion content multi document summarization is a task oriented to creating a summary from a heterogeneous set of documents on a focused topic over the past years extensive iments on query oriented multi document summarization have been carried out extractive summarization produces summaries choosing a subset of representative sentences from original documents sentences are ordered then assembled according to their relevance to generate the nal summary this article introduces a new method of normalization of words that reduces the textual representation space in order to improve the eciency of automatic text summarizers based on vector space model vsm we propose ultra stemming which reduces every to its results show that ultra stemming not only preserves the content of the summaries generated using this new representation but often surprisingly the performance can be dramatically improved to our knowledge in summary tasks no automatic stemming method has explored this extreme possibility ultra stemming could be an interesting alternative for ats of documents in languages where electronic linguistic resources are rare in these languages there are a notable absence of lemmatizers stemmers parsers dictionaries corpora and language resources in general such as nahuatl and other american indian languages our tests on trilingual corpora evaluated by the fresa algorithm conrm the increase of performance regardless of summarizer used and a big reduction of complexity in space and time required to generate summaries related work is given in section section presents our stemming strategies coupled with methods of automatic text summarization experiments are presented in section followed by a discussion and the conclusions in section related works there are several morphological analysis methods examples of these algorithms are the comparison of graphs the use of n grams the search for analogies the surface models based on rules the probabilistic models the segmentation by optimization the unsupervised learning of morphological families by ascending hierarchical cation the lemmatization using levenshtein distances or identifying suxes through entropy these methods are distinguished by the type of results obtained by the tion of lemmas stems or suxes is an analyzer for french which requires a text previously labeled by or by flemm produces among other results the lemma of each word of the input text treetagger is a multilingual tool that allows to annotate texts with information of parts of speech pos and with information of tization treetagger uses supervised machine learning and probabilistic methods it can be adapted to other languages as long as the lexical resources and manually labeled corpora are available freeling is another example of a popular multilingual stemming transforms the variants of words into truncated forms two popular stemming algorithms are the porter stemming algorithm and the paice algorithm the methods of stemming and lemmatization can be applied when the terms are morphologically similar otherwise when the similarity is semantic lexical search methods must be used to reduce mantic variation some systems use long dictionaries another systems use thesauri to associate words to entirely dierent morphological forms both methods are complementary since is available in web site univ fr pers namer htm is available in web site atilf fr scripts mep txt is available in web site ims uni stuttgart projekte corplex decisiontreetagger html types of words are for example nouns verbs innitives and particles is available in web site lsi upc the stemming veries similarities in the spelling level to infer lexical proximity while the lexical presents an algorithms use terminographic data with links to synonyms vised genetic algorithm for stemming inectional languages proposes using morphological merged families into a single term to reduce the linguistic variety of spanish indexed texts lexematization seeks morphological rearrangement of words belonging to the same ily using automatic acquisition of morphological knowledge directly from the texts although the constitution on morphological families may be interesting in itself its main interest lies in the benets it produces for use as normalization mechanism instead or in addition to stemming or lemmatization in specic application domains probably the most common application main is indexing terms in systems of information retrieval ir in recent years there have been numerous articles analyzing in dierent languages the eciency of stemming lemmatization in ir in addition signicant progress has been made in ir in european languages other than in particular have evaluated corpora of clef evaluation campaigns eight english european languages their results show that morphological normalization techniques increase the eciency of the ir systems and it can be used independently of the language reduction algorithms using syntactic and morphosyntactic variations have shown a signicant reduction of storage costs and management by storing lexemes rather than terms works on the impacts of compound words and standardization in ir nding no signicant performance dierences between stemming and lemmatization however the reality is that the linguistic resources necessary to establish morphological relationships without pre dened rules are not available for all languages and all domains without mention the constant creation of neologisms the proposed solution for the specic task of automatic summarization is the ultra stemming of letters research in ats was introduced by h p luhn in in the strategy proposed by luhn the sentences are scored for their component word values as determined by like weights scored sentences are then ranked and selected from the top until some summary length threshold is reached finally the summary is generated by assembling the selected sentences in original source order although fairly simple this extractive methodology is still used in current approaches later on extended this work by adding simple heuristic features of sentences such as their position in the text or some key phrases indicating the importance of the sentences as the range of possible features for source characterization widened choosing appropriate features feature weights and feature combinations have became a central issue a natural way to tackle this problem is to consider sentence extraction as a classication task to this end several machine learning approaches that uses document summary pairs have been proposed pre processing and ultra stemming the following subsections present formally the details of the corpora studied and the proposed text pre processing method summarization corpora description to study the impact of ultra stemming in automatic summary tasks we used corpora in three languages english spanish and french the corpora are heterogeneous and dierent tasks are representive of automatic summarization generic multi document summary and document guided by a subject language evaluation forum clef campaign corpus in english piloted by nist in document understanding duc the task of aims to produce a short summary of a cluster of related documents we studied generic multi document summarization in english using data from this corpus with k words is compound of clusters documents each corpus in spanish generic single document summarization using a corpus from the journal medicina which is composed of medical articles in spanish each one with its corresponding author abstract this corpus contains k words corpus in french we have studied generic single document summarization using the canadian french sociological articles corpus generated from the journal perspectives interdisciplinaires sur travail sant it contains sociological articles in french each one with its corresponding author abstract this corpus contains near k words table presents the basic statistics on tokens types and characters of the three rization corpora studied corpus medicina clnica pistes language tokens types english spanish french letters table basic statistics for the three summarization corpora additionally three large and heterogeneous corpora generated from novels newspaper ticles and news on the internet were created to measure statistics of each language these corpora contains several million tokens in english spanish and french table presents basic statistics on tokens and characters of the three generic corpora generic corpus english spanish french tokens letters table basic statistics for the three language generic corpora ultra stemming the rst step to represent documents in a suitable space is the pre processing as we use extractive summarization as task documents have to be chunked into cohesive textual segments that will be assembled to produce the summary pre processing is very important because the selection of segments is based on words or bigrams of words the choice was made to split documents into full sentences in this way obtaining textual segments that are likely to be grammatically correct afterwards sentences pass through several basic normalization steps in order to reduce computational complexity an example of document pre processing is given in table the process is composed by the following steps nist gov nlpir nist gov projects duc html elsevier revistas pistes uqam sentence splitting a simple rule based method is used for sentence splitting ments are chunked at the dot exclamation and question mark signs sentence ltering words are converted to lowercase and cleared up from sloppy tuation words with less than occurrences are eliminated hapax legomenon presents once in a document words that do not carry meaning such as functional or very common words are removed small stop lists depending of language are used in this step word normalization remaining words are replaced by their canonical form using lemmatization stemming ultra stemming or none of them raw text text vectorization documents are vectorized in a matrix of p sentences and n columns that represent the occurrences of a letter ultra stemming or a word tization stemming raw j j n in the sentence i i p summary generation each summary is generated by a summarizer based on vsm for ultra stemming using n the maximum dimension n may be up to letters this generates very compact and ecient matrices as discussed in l a n i g i r o a federal judge monday found president clinton in civil contempt of court for lying in a deposition about the nature of his sexual relationship with former white house intern monica s lewinsky clinton in a january deposition in the paula jones sexual harassment case swore that he did not have a sexual relationship with lewinsky clinton later explained that he did not believe he had lied in the case because the type of sex he had with lewinsky did not fall under the denition of sexual relations used in the case e t t i l s a federal judge monday found president clinton in civil contempt of court for lying in a deposition about the nature of his sexual relationship with former white house intern monica s lewinsky clinton in a january deposition in the paula jones sexual harassment case swore that he did not have a sexual relationship with lewinsky clinton later explained that he did not believe he had lied in the case because the type of sex he had with lewinsky did not fall under the denition of sexual relations used in the case g feder judg monday found presid clinton civil contempt court lying in deposit natur sexual n i m m e t s relationship former white hous intern monica lewinski clinton januari deposit paula jone sexual harass case swore sexual relationship lewinski clinton explain believ lie case type sex lewinski fall denit sexual relat case m f c c c c l n s f w h i m l c j p j s h c s s r l c l e l c t s f s r u c letter h i l m n p r s u w i f i r t a m table example of some pre processings stemming ultra stemming and matrix generation applied to the document from duc document is split in sentences punctuation and case are removed words are normalized for comparison four methods of normalization were applied after ltering lemmatization by simple dictionary of morphological families m words entries in spanish k words in english and k in french porter s stemming available at snowball site tartarus org stemmersoverview html for english spanish french among other languages raw text without normalization ultra stemming the n rst letters of each word for example in the case of stemming of n inected verbs sing song sings singing or proper names smith snowboard sex are all replaced by letter s why ultra stemming could work although this technique could be considered a brutal destruction of the lexicon ultra stemming is in fact an extreme stemming that is this truncation represents with minimum information what we call the stem of the stem in the case of ultra stemming with n the construction of the vectors phrases is performed in a space of j classes which produces a dense vector representation of course classes are not equally populated figures to show the ranking of letters of three corpora in english spanish and french the numbers and function words were previously removed in an automatic extractive summarizer the weight of phrases is represented in a suitable vector space however if the representation is too large the resulting representation is very sparse which can dicult the weighting of the sentences two hypotheses are the basic ideas for using ultra stemming in automatic summarization task figure scatter plot of rst letter ranking for the english corpus there are m of types after ltering of functional words and punctuation figure scatter plot of rst letter ranking for the spanish corpus there are m of types after ltering of functional words and punctuation figure scatter plot of rst letter ranking for the french corpus there are m of types after ltering of functional words and punctuation the rst hypothesis is that a more condensed but retaining important information of the original representation would enable a more eective weighting for phrases extraction stemming produces an extremely compact representation of documents in a vector space that can reach only thirty letters using the representation of one letter per word one way of evaluating the ecacity of a vector representation can be by calculating the density of the resulting matrix this point will be discussed in detail in the next section the other way is to show that two matrices a and b are equivalent in the sense that they contain a number of similar informations if a b and a and b represent approximately the same information then it may be preferable to use the representation given by a instead of b now how does one know that two matrices contain about the same information the second hypothesis is that if the matrices a and b are correlated then they probably represent similar information this point will be proved in section by the mantel statistic test matrix density pre processing and vectorization of documents will produce very sparse matrices however the density of matrices generated is directly dependent on pre processing algorithm used itively the density of matrices generated by ultra stemming must be much greater than those generated by classical normalizations we have calculated the density of a matrix of p phrases and a vocabulary of n words as a fraction of occurrences cw of the word w elements other than divided by the size of the matrix p n the equation calculates the density of s this density can be an indicator of the amount of information in relation to the volume of the matrix lower density implies a greater amount of computation for ranking sentences as shown in table the matrix produced by ultra stemming of letters produces a higher average density on the studied corpora the matrices generated by ultra stemming are lled approximately for english for spanish and for french the volume of the matrix generated by each pre processing method in relation to the size of the matrix in plain text is given by cw v this volume represents a small fraction between and depending on the language of the matrix equivalent of plain text in case of the corpus medicine clnica the standard matrices lemm stem are slightly larger than the matrix produced by the plain text raw this can be explained by the presence of hapax legomenon in the case of plain text a large number of hapax is eliminated and it can produce matrices slightly smaller pre processing lemmatization stemming raw medicina clnica pre processing lemmatization stemming raw pistes pre processing lemmatization stemming raw density density density size volume v size volume v size volume v table matrix density for three corpora data the mean dimension of matrix s density is calculated by equation and volume by equation statistics for summarization english medicina clnica spanish and pistes french corpora after removing stop words hapax legomenon and punctuation are shown in table the mode of letters per word is and and respectively for each language corpus words letters mean of letters mode on generic per word lemmatization stemming raw medicina clnica lemmatization stemming raw pistes lemmatization stemming raw sentences sentences sentences english spanish french table statistics for three summarization corpora after ltering and removing punctuation figures and show the average distribution of letters per word by the three summary corpora after the ltering described in curves are shown normalized between for the large generic and representative of the language corpora cf section and the corpora used in each of the summaries experiments figure scatter plot of mean length of words for two english corpora heterogeneous and summarization raw corpora after ltering figure scatter plot of mean length of words for two spanish corpora heterogeneous and summarization raw corpora after ltering figure scatter plot of mean length of words for two french corpora heterogeneous and summarization raw corpora after ltering matrix test correlation the test of mantel dierent methods of data analysis as ranking are based on distance matrices indicates in some cases researchers may wish to compare several distance matrices with one another in order to test a hypothesis concerning a possible relationship between these matrices however this is not always evident usually values in distance matrices are in some way correlated and therefore the usual assumption of independence between objects is violated in the classical tests approach furthermore often spurious correlations can be observed when comparing two distances matrices as shows in the mantel test the null hypothesis is that distances in a matrix a are independent of the distances for the same objects in another matrix b in other words we are testing the hypothesis that the process that has generated the data is or is not the same in the two sets then testing of the null hypothesis is done by a randomization procedure in which the original value of the statistic is compared with the distribution found by randomly reallocating the order of the elements in one of the matrices the measure used for the correlation between a and b is the pearson correlation coecient b p p p ai j a bi j b where p is the number of elements in the lower upper triangular part of the matrix is mean for a elements and a is the standard deviation of a elements coecient r measures the linear correlation and hence is subject to the same statistical assumptions consequently if non linear relationships between matrices exist they will be degraded or lost r the testing procedure for the simple mantel test goes is the same of and it is as follows assume two symmetric dissimilarity matrices a and b of size p p the rows and columns correspond to the same objects compute the pearson correlation coecient b between the corresponding elements of the lower triangular part of the a and b using equation permute randomly rows and the corresponding columns of the matrix a creating a new matrix a compute b between matrices a and b repeat steps and a great number of times this will constitute the reference bution under the null hypothesis the calculation of the correlation between the matrix generated by the ultra stemming and others normalization methods is not straightforward because the matrices are not square in general the matrix produced by the ultra stemming have a smaller number of columns than the other ones then to calculate a correlation between matrices of dierent number of columns each matrix must be converted in a symmetric matrix let p n of p rows and n columns be a matrix produced by ultra stemming and let of p rows and n columns be a matrix produced by a classic method of normalization such that stemming lemmatization we have the condition that n n let the new matrices be p s and p s they are square symmetrical a standard mantel test can indicate the degree of similarity between a and b if the similarity is high r with a high condence value p means that the information of the matrix a is substantially the same as that contained in the matrix b in other words we could replace for s for purposes of a vector representation of documents tables and show the correlation of the mantel test for the three summary corpora studied the correlation was calculated between the matrices s generated by lemmatization lemm stemming stem plain text raw and the matrix generated by ultra stemming using the initial letter in all cases the correlation is positive with p value which is signicant the calculations were performed with the zt program written in c of eric bonnet and yves van de lemm lemm stem raw stem raw table mantel test correlation for data english p a software tool for simple and partial mantel tests this program can be downloaded from the web site psb ugent be software details zt lemm medicina clnica lemm stem raw stem raw table mantel test correlation for medicina clnica data spanish p lemm pistes lemm stem raw stem raw table mantel test correlation for pistes data french p according to these correlations in english corpus the method is more related with stemming normalization in spanish and french corpora seems slightly correlated with the model lemmatization this is intuitively correct and according to the duced variability of english in relation to spanish or french experiments ultra stemming method described in the previous section has been implemented and evaluated in several corpora in english spanish and french languages the following subsections present details of the dierent experiments summarizers three summarization systems were used in our experiments cortex enertex and artex all systems have used the same text representation based on vector space model described in section cortex is a single document summarization system using several metrics and an optimal decision algorithm enertex is summarization system based in textual energy concept text is sented as a spin system where spins represents words that their occurrences are f spins if the word is not present artex another text summarizer is a single document summarization system that computes the score of a sentence by calculating a dot product between a sentence vector and a frequencies vector multiply by lexical used we have conducted our experimentation with the following languages summarization tasks summarizers and data sets generic multi document summarization in english with the corpus generic single document summarization in spanish with the medicina clnica and generic single document summarization in french with the pistes then we have applied the summarization algorithms following the pre processing algorithm and nally results have been evaluated using fresa summaries evaluation to evaluate the quality of a summary is not an easy task and remains an open question duc conferences have introduced the rouge evaluation wich measures the overlap of n grams between a candidate summary and reference summaries written by humans in other hand several metrics without references have been dened and experimented at duc and workshops fresa measure is similar to rouge evaluation but it does not uses reference summaries it calculates the divergence of probabilities between the candidate summary and the document source among these metrics kullback leibler kl and jensen shannon js divergences have been used to evaluate the informativeness of summaries in this paper we use fresa based in kl divergence with dirichlet smoothing like in the and inex edition to evaluate the informative content of summaries by comparing their n gram distributions with those from source documents fresa only considered absolute log di between frequencies let t be the set of terms in the source for every t t we denote by c t its t occurrences in the summary the fresa package computed the divergence between the source and the summaries as its occurrences in the source and by c s t log log tt c t c s t to evaluate the quality of generated summaries several automatic measures were computed unigrams of single stems after removing stop words bigrams of pairs of consecutive stems in the same sentence bigrams with gaps also made of pairs of consecutive stems but allowing the insertion between them of a maximum of two stems is the mean of fresa values and represents the nal score in our experiments the scores of fresa are normalized between and high values mean less divergence regarding the source document summary reecting a greater amount of information content all summaries produced by systems were evaluated automatically using fresa package results english corpus nist gov tac below we present separate results for the three languages linguistic phenomena specic to each language in this way we have analyzed results in gure show that ultra steming improves the score of the three automatic rizer systems this result is remarkable for whose average matrix represents only of the matrix volume in plain text figure histogram plot of content evaluation for duc task with measures for each summarizer and each normalization figure scatter plot of mean of ultra stemming using n rst letters duc task cortex summarizer as shown in figure the performance of the three summarizers is improved using the ultra stemming in relation to other normalizations so in particular using lemmatization the best score between the two classic normalizations the summarizer artex goes from to using normalization i e an increase of cortex increases of to an augmentation of and summarizer enertex increases of to an augmentation of a detailed analysis for a particular summarizer is shown in figure this gure shows the average score fresa obtained on english corpus in function of ultra stemming used of n letters for the automatic summarizer cortex by comparison the values fresa for lemmatization lemm stemming stem and plain text raw are shown in the graph spanish corpus spanish is a language with greater variability than english results in gure shown that steming improves the score of the three systems of automatic summarization utilized in the case of summarizers cortex and artex stemming and lemmatization substantially obtains the same scores which does not occur with enertex however comparing ultra stemming against stemming the three summarizers are beneting of an increased score artex enertex and cortex figure histogram plot of content evaluation for spanish medicina clnica with scores for each summarizer figure shows the mean score on the spanish corpus medicine clnica based on the ultra stemming n letters using automatic summarizer cortex values fresa for lemmatization lemm stemming stem and plain text raw are also shown figure scatter plot of mean vs ultra stemming using n rst letters medicina clnica cortex summarizer french corpus figure histogram plot of content evaluation for french pistes with fresa scores for each summarizer figure scatter plot of mean vs ultra stemming using n rst letters pistes cortex summarizer results in gure show that ultra stemming improves the score of the three automatic rization systems used in particular the summarizer enertex using a stemming representation obtains a score fresa of and using representation a score of i e an increase of more than finally figure shows the detailed mean score on french pistes as function of n letters using the automatic summarizer cortex as well it shows the values fresa for lemmatization lemm stemming stem and plain text raw overall for the three languages beyond a certain number of letters for english for the spanish and for french ultra stemming loses its eectiveness and lemmatization score is higher a view to the table shows that this limit has a relationship with the mean rather than the mode of letters per word in each language apparently using ultra stemming is interesting when using a number of characters less than the mode of the language in question discussion and conclusion in this paper we have introduced and tested a simple pre processing method suitable for tomatic summarization text ultra stemming is fast and simple it reduces the size of the matrix representation but it retains the information and charateristics of the document an important aspect of our approach is that it does not requires linguistic knowledge or resources which makes it a simple and ecient pre processing method to tackle the issue of automatic text summarization and what about times in general the processing times of ultra stemming are shorter compared to all others methods of course processing time depends of summarizer algorithm and pre processing algorithm in general processing time is function of in our experiments is independent of the summarizers and generally ing algorithm is very fast the depends on algorithm used stemming lemmatizaton extern resource dictionary of lemmatization the is intrinsic to each summarizer system by example cortex is a very fast summarizer with where p n and processing times for stemming raw and are close in other hand enertex summarizer has a complexity of then it needs more time to process the same corpus in this case ultra stemming is a very interesting alternative to summarize long corpora table shows processing times for each corpus following the normalization method for cortex artex and enertex summarizers all times are measured in a gb of ram computer core m cpu processor running under bits gnu linux ubuntu version corpus medicina clnica pistes mean all medicina clnica pistes mean all summarizer cortex lemmatization stemming raw artex lemmatization stemming raw enertex lemmatization stemming raw time medicina clnica pistes mean all table statistics of processing times in minutes of three summarizers over three corpora clearly the lemmatization of a large dictionary is the most time consuming strategy this is notable in the spanish corpus using a m dictionary entries lemmatization is at the same time the strategy that produces the best results after the ultra stemming fixn with n letters in the case of artex summarizer the gain in time is dramatic going from using lemmatization to using i e a gain of this gain is for cortex and for enertex from our point of view the ultra stemming of n letters has three important advantages a reduction of the space and the calculation time of automatic summarization algorithms based on the vector space model improving of summary content when using n mode in letters per word of each language applications on resource sparse languages typically languages where no lemmatizers stemmers or parsers neither corpora nor native linguist available the ultra stemming can be an attractive alternative for automatic document summarizers summarization using the ultra stemming representation for sentence scoring improve the identication of most relevant sentences from documents the results obtained on corpora in english spanish and french prove that ultra stemming can achieve good results for content quality tests with other corpora duc evaluation campaigns tac inex in mono and multi document guided by a subject and languages nahuatl maya somali interlingua using content evaluation with or without reference summaries still in progress references e airio word normalization and decompounding in and bilingual ir information trieval j atserias b casas e comelles m gonzlez l padr and m padr freeling syntactic and semantic services in an open source nlp library in fth international conference on language resources and evaluation elra r baeza yates and b ribeiro neto modern information retrieval addison wesley d bernhard apprentissage non familles morphologiques par classication ascendante hirarchique in volume pages eric bonnet and yves van de peer zt a software tool for simple and partial mantel tests journal eric bonnet and yves van de peer zt a sofware tool for simple and partial mantel tests journal of statistical software of statistical software and brooks monterey ca l breiman j friedman r olshen and c stone classication and regression trees wadsworth m t cabr castellv typology of neologisms a complex task alfa so paulo m creutz and k lagus unsupervised discovery of morphemes in workshop of the acl special interest group in computational phonology sigphon pages m creutz and k lagus unsupervised morpheme segmentation and morphology induction from text corpora using morfessor technical report publications in computer and information science helsinki university of technology harold daum iii practical structured learning techniques for natural language processing phd thesis los angeles ca d p lyras and k n sgarbas and n d fakotakis using the levenshtein edit distance for matic lemmatization a case study for modern greek and english in ieee international conference on tools with articial intelligence volume pages h p edmundson new methods in automatic extraction journal of the association for puting machinery f namer flemm un analyseur flexionnel de franais base rgles in christian jacquemin editor traitement automatique langues pour recherche dinformation pages mes silvia fernndez eric sanjuan and juan manuel torres moreno textual energy of tive memories performants applications of enertex algorithm in text summarization and topic segmentation in proceedings of the mexican international conference on articial intelligence pages aguascalientes mexique springer verlag c g figuerola r gmez daz and e lpez de san romn stemming and n grams in spanish an evaluation of their impact on information retrieval journal of information science a f gelbukh m alexandrov and s han detecting inection patterns in natural language by minimization of morphological model in sanfeliu a trinidad j f m and carrasco ochoa j a editors iberoamerican congress on pattern recognition progress in pattern recognition image analysis and applications volume pages lecture notes in computer science springer verlag berlin j a goldsmith unsupervised learning of the morphology of a natural language computational linguistics n grabar and p zweigenbaum acquisition automatique de connaissances morphologiques sur vocabulaire mdical in pages pascal amsili ed c hammarstrm unsupervised learning of morphology survey model algorithm and ments master s thesis department of computer science and engineering chalmers university h hammarstrm a naive theory of morphology and an algorithm for extraction in r towski and g kondrak editors sigphon acl special interest group on computational phonology pages s helmut probabilistic part of speech tagging using decision trees in international conference on new methods in language processing september v hollink j kamps c monz and m de rijke monolingual document retrieval for european languages information retrieval january c jacquemin and e tzoukermann nlp for term variant extraction synergy between ogy lexicon and syntax in tomek strzalkowski editor natural language information retrieval volume of text speech and language technology pages kluwer academic publishers dordrecht boston london t korenius j laurikkala k jarvelin and m juhola stemming and lemmatization in the clustering of nnish text documents in thirteenth acm conference on information and knowledge management pages acm press j kupiec j pedersen and f chen a trainable document summarizer in proceedings of the conference acm special interest group on information retrieval pages seattle wa etats unis acm press new york y lepage solving analogies on words an algorithm in coling pages chin yew lin rouge a package for automatic evaluation of summaries in marie francine moens and stan szpakowicz editors proceedings of the workshop text summarization branches out pages barcelone espagne july acl annie louis and ani nenkova automatic summary evaluation without human models in first text analysis conference gaithersburg md etats unis november h p luhn the automatic creation of literature abstracts ibm journal of research and development i mani and m mayburi advances in automatic text summarization mit press cambridge press c d manning and h schtze foundations of statistical natural language processing the mit nathan mantel and ranchhodbhai s valand a technique of nonparametric multivariate ysis biometrics sep juan manuel torres moreno reagrupamiento en familias y lexematizacin automtica dientes del idioma revista iberoamericana de inteligencia articial c d paice another stemmer sigir forum c d paice method for evaluation of stemming algorithms based on error counting journal of the american society for information science m f porter an algorithm for sux stripping program j ross quinlan programs for machine learning morgan kaufmann series in machine learning morgan kaufmann edition eric sanjuan patrice bellot vronique moriceau and xavier tannier overview of the inex question answering track in shlomo geva jaap kamps ralf schenkel and andrew trotman editors comparative evaluation of focused retrieval volume of lecture notes in computer science pages springer berlin heidelberg simone teufel and marc moens sentence extraction as a classication task in i mani and m maybury editors proceedings of the acl workshop on intelligent scalable text summarization madrid espagne juillet juan manuel torres moreno rsum automatique documents une approche statistique herms lavoisier paris juan manuel torres moreno horacio saggion iria da cunha and eric sanjuan summary ation with and without references polibits research journal on computer science and computer engineering with applications juan manuel torres moreno patricia velzquez morales and jean guy meunier cortex un in proceedings of the conference de algorithme pour la condensation automatique textes lassociation pour la recherche cognitive volume pages lyon france a medina urrea automatic discovery of axes by means of a corpus a catalog of spanish axes journal of quantitative linguistics j vilares m a alonso and m vilares extraction of complex index terms in non english ir a shallow parsing based approach information processing and management j vilares d cabrero and m a alonso applying productive derivational morphology to term indexing of spanish texts in alexander gelbukh editor computational linguistics and intelligent text processing volume of lecture notes in computer science pages springer verlag berlin heidelberg new york
