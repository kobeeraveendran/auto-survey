literature retrieval precision medicine neural matching faceted summarization jiho noh department computer science university kentucky kentucky usa jiho edu ramakanth kavuluru division biomedical informatics university kentucky kentucky usa ramakanth edu c e d l c s c v v x r abstract ir information retrieval precision medicine pm involves looking multiple pieces evidence characterize patient case typically includes condition genetic variation applies patient factors demographic attributes comorbidities social determinants pertinent retrieval problem formulated search multiple facets e disease mutation need incorporated paper present document reranking approach combines neural query document matching text summarization retrieval scenarios architecture builds basic bert model specic components reranking document query matching keyword extraction c facet conditioned abstractive summarization outcomes b c essentially transform candidate document concise summary compared query hand compute relevance score component directly generates matching score candidate document query architecture benets complementary potential document query matching novel document transformation approach based summarization pm facets evaluations nist s trec pm track datasets model achieves state art performance foster reproducibility code available com bionlproc t ext summ doc retrieval introduction u s nih s precision medicine pm tive collins varmus calls designing treatment preventative interventions ing genetic clinical social behavioral vironmental exposure variability patients initiative rests widely understood ing considering individual variability critical tailoring healthcare interventions achieve stantial progress reducing disease burden wide cancer chosen near term focus eventual aim expanding tions biomedical research enterprise strives fulll initiative s goals computing needs rise drug discovery predictive modeling disease onset progression building nlp tools curate information evidence base generated trec precision medicine series facet input disease genetic variation braf k demographics melanoma year old female disease genetic variation amplication demographics year old male gastric cancer table example cases trec pm dataset dovetailing u s nist s trec text retrieval conference running pm track focus cancer roberts et al goal trec pm task identify relevant biomedical articles clinical trials input patient case case composed disease gene genetic variation type demographic information sex age table shows ample cases track search sense free text input facet facets highlight pm related attributes ought ize retrieved documents believe style faceted retrieval going common medical ir tasks conditions pm initiative continues mission retriever solr index grainger potter corpora vocabulary mismatch neural ir vocabulary mismatch problem prominent issue medical ir given large variation expression medical concepts events example query potential effect tymlos drug referred brand relevant scientic literature contain generic abaloparatide frequently traditional document search engines clear limitations resolving mismatch issues ir community extensively explored methods address vocabulary mismatch problem ing query expansion based relevance feedback query term weighting query reconstruction optimizing query syntax recent studies highlight exploiting ral network models query renement ment retrieval dr settings nogueira cho address issue generating formed query initial query neural model use reinforcement learning rl train agent e reformulator learns reformulate initial query maximize pected return e retrieval performance actions e generating new query probability distribution different proach narayan et al use rl sentence ranking extractive summarization contributions paper building bert ture devlin et al focus different brid document scoring reranking setup ing components document relevance classication model predicts ently scores document relevant given query bert multi sentence setup b keyword extraction model spots tokens document likely seen pm lated queries c abstractive document marization model generates pseudo query given document context facet type e genetic variation bert encoder decoder setup keywords b query c compared original query generate score scores components combined rerank set documents returned basic okapi main innovation pivoting cus queries previous methods emphasis transforming candidate documents queries summarization additionally generating pseudo query let coder output concept codes biomedical nologies capture disease gene names embedding words concepts common semantic space letting decoder generate summaries include concepts overall architecture evaluated pm datasets dataset test set results absolute improvement compared prior best approaches obtaining small gain r prec qualitative analyses highlight summarization able focus document segments highly relevant patient cases background basic reranking architecture begin bidirectional encoder representations transformers bert devlin et al model bert trained masked language eling objective large text corpus wikipedia bookscorpus sequence eling method achieved state art sults wide range natural language standing nlu tasks including machine tion conneau lample text rization liu lapata additional layer pretrained bert model ne tune models specic nlu tasks study utilize framework ponents identied section starting bert base uncased pretrained huggingface model wolf et al text summarization plan leverage extractive tive candidate document summarization framework terms learning methodology view extractive summarization sentence token classication problem previously posed models include rnn based sequence model nallapati et al attention based neural encoder decoder model cheng lapata sequence model global ing objective e rouge ranking sentences optimized rl narayan et al paulus et al recently graph convolutional neural networks gcns adapted allow incorporation global information text summarization tasks sun et al prasad kan abstractive summarization cally cast sequence sequence learning lem encoder framework reads ument yields sequence continuous resentations decoder generates target summary token token rush et al lapati et al approaches merits generating comprehensive novel summaries systems leverage different models framework et al liu lapata use extractive ponent identify tokens candidate document relevant pm perspective use abstractive component identify potential terms necessarily document characterize pm purposes word entity embeddings neural text summarization models described previous section adopt encoder decoder framework popular chine translation vocabulary decoding encoding exploit design summarization trick pm decoder outputs regular english tokens entity codes standardized biomedical terminology captures semantic concepts discussed document trained easily ing textual queries training examples corresponding entity codes trick enhance ability handle vocabulary match different way abstractive framing created biomedical entity tagged bmet purpose bmet embeddings trained biomedical literature abstracts annotated entity codes medical subject headings mesh codes appended associated textual spans training examples regular tokens entity codes embedded semantic space pretraining fasttext architecture bojanowski et al com romanegloo bmet e mbeddings html nlm nih gov mesh meshhome regular english tokens vocabulary bmet includes mesh codes subset supplementary concepts dictionary mesh codes differentiated regular words unique prex example mesh code tion model translate sequence regular text tokens sequence biomedical entity codes vice versa use mesh new semantic facet provided trec pm organizers expected output mesh facet set codes capture entities disease gene variation facets models reranking effort document reranking aim measure relevance match ment faceted pm query training stance tuple d q yd q q query candidate document yd q boolean man adjudicated outcome relevant mentioned section ne tune bert query document relevance matching task modeled classication goal predict yd q rel ne tune bert token level relevance classication different rel token d deemed relevant training occurs q model ext keyword extraction lastly train bert model setting encoder initialized pretrained ext model encoder reads d decoder attends contextualized representations d generate facet specic pseudo query sentence qd compared original query q ceptualize process text summarization document query refer abs models rerank candidate d test time specic input query document relevance matching rel neural text matching recently carried siamese style networks mueller garajan adapted biomedicine noh kavuluru proach adapts bert architecture ing task multi sentence setting shown figure use bert s tokenizer textual note queries grammatically formed sentences essentially sequences generated marization model figure bert architecture document relevance matching task rel inputs tokens mapped token dings rel takes concatenated sequence document faceted query sentences tional symbols dened bert tokenizer e cls added input sequence input sequence starts cls token sentence document ends sep token segment input sequence set faceted query sentences end sep token encoding cess rst cls token collects features termining document relevance query bert uses segment embeddings distinguish tences use distinguish multiple sentences document sentence assign segment embedding b alternatively positional embeddings encode sequential nature inputs token embeddings segment sitional embeddings pass transformer layers finally use output logit cls token matching score input document query note nt demarcate boundaries different facets query keyword extraction ext ext model additional token classication layer pretrained bert output token logit indicates log odds token s occurrence query pm datasets expect logits words related different facets optimized ext test time unlike rel model input ext sequence words document sep delimiters model learns boundaries sentence ment inputs component essentially generates brief extractive summary candidate ment furthermore contextualized embeddings ext decoder abs ate faceted abstractive document summaries abstractive document summarization abs abs employs standard attention model similar nallapati et al shown figure initialize parameters encoder pretrained ext model decoder layer transformer self attention layers attend earlier positions output sequence typical auto regressive training phase step guage models decoder takes previous token ence query sentence generation process decoder uses token predicted step earlier facets disease genetic variations demographic info mesh terms document keywords unused unused unused unused unused table signals different facets patient cases differentiate facets special pairs tokens assigned topic typical eration process special tokens begin end indicate quence boundaries model use special tokens bert vocabulary x unused specically unused unused bos eos tokens respectively different facets facet sentencesquery label figure architecture abstractive document summarization abs model encoder left component initialized pretrained ext model class labels encoder identifying keywords document output sequences generated decoder right component build pseudo query later computing similarity scores user provided query signals latent variables abs optimized abs learns thematic aspects queries meta attributes length special tokens facets listed table row indicates new auxiliary facet introduce section faceted query enclosed assigned bos eos pair decoder abs learns facet signal encoder original transformer tecture vaswani et al add soidal positional embedding pt segment vector b token embedding et note dimension token embeddings encoder bert embeddings different decoder custom bmet beddings causes discrepancy ing context attentions target text source document add additional linear layer project constructed decoder beddings en j pi right hand portion figure space embeddings encoder projected embeddings fed decoder s transformer layers transformer layer applies multi head attention computing context attentions attention tion reads input masks preclude attending future tokens input padded tokens e source text attention functions apply residual connection et al lastly transformer layer ends position wise feedforward network final scores token computed linear layer transformer layers training scores consumed cross entropy loss tion generation process softmax function applied vocabulary yielding probability distribution sampling token finally generate pseudo query use beam search nd probable sentence predicted candidates scores nalized measures proposed wu et al equation length penalty rent target length length malization coefcient coverage penalty y pi j pi j attention score j word yj th source word xi source length coverage malization coefcient intuitively functions avoid favoring shorter predictions yielding plicate terms tune parameters penalty functions grid search validation set trec pm reranking rel ext abs main purpose models designed previous subsections come bined measure reranking query q let dr set r set candidate transformer transformer layersattendspredictor linear softmaxtoken wise class labelsoutput documents returned solr edismax query straightforward impose order dj rel output probability estimates relevance given q dj generate pseudo query summary qdj concatenating distinct words generated pseudo query sentences abs words selected ext repeating words special tokens removed faceted summaries erated abs end qdj essentially set unique terms abs ext dj scored comparing q qdj similarity metrics recall score srou ge lin cosine similarity based score computed qdj yq max xqdj denote vector representations bmet embeddings section overall compute different scores rankings document retrieval score returned solr document relevance score rel pseudo query based rouge score pseudo query similarity score scos end merge rankings reciprocal rank fusion cormack et al obtain nal ranked list documents results compared state art models trec pm task experimental setup data trec pm tasks tal patient cases qrels document relevance judgments shown table year queries documents rel irrel table number queries pooled relevance ments trec pm tracks create new auxiliary facets mesh terms keywords derived training query document pair covered mesh facet section keywords assigned authors biomedical article capture themes downloadable nih s ncbi website keywords assigned article use set preferred names mesh terms assigned articles trained nih coders example following list shows associated facets sample training instance disease prostate cancer genetic variations atm deletion demographics year old male mesh terms keywords aged ataxia telangiectasia tated proteins prostate neoplasms genetics model consumes data differently shown table rel takes document given query source input predicts document level relevance consider document human judgment score partially relevant totally relevant relevant study note include mesh terms query sentences rel ext reads ment source input predicts token level relevances training relevant token occurs given patient case query output abs taking document facet type model source target rel ext abs sentences doc relevance doc token relevances signal pseudo query table data inputs outputs model implementation details models begin trained bert base uncased huggingface model wolf et al encode source texts use bert s wordpiece schuster jima tokenizer source documents rel ext trained steps batch size maximum number tokens source texts limited loss tion models use weighted binary cross entropy given high imbalance irrelevant instances positive ones different weights classes puting loss according target distributions proportions negative examples rel ext loss y log rel ext adam mizer parameters starting learning rate lr xed weight decay learning rate reduced metric stopped improving reducelronplateau scheduler pytorch decoder abs multi head attention module opennmt klein et al tokenize target texts use nltk word tokenizer nltk org api n ltk tokenize html unlike encoder use customized word embeddings bmet embeddings section trained domain specic corpus ulary vocabulary size cludes mesh codes use layers decoder model dimension feed forward layer size use different initial learning rates encoder decoder encoder initialized pretrained ext model encoder decoder negative log likelihood loss tion abs ground truth faceted query sentences beam search abs beam size set test time select best dictions merge query sentence max length target sentence limited sequence incrementally generated abs outputs corresponding eos token facet parameter choices based best practices prior efforts experiments optimize validation subsets evaluations results conducted quantitative qualitative uations example outcomes nal tion trec pm dataset hyperparameter tuning training validation dataset split shufed combined set instances tracks validation rest training quantitative evaluations rst discuss performances constituent rel ext models evaluated train validation splits years table shows performance rel recover relevant documents ext identify tokens occur patient case information precisions nd learning model fying document token level relevance relatively straightforward imbalance rel ext p r p r train valid table retrieval performance rel ext discuss main results comparing teams rows track table proceed want highlight crucial evaluation consideration applies trec track trec evaluates tems craneld paradigm pooled documents participating teams judged relevance human experts participate original trec pm task retrieved results judged uments slight disadvantage comparing results teams participated trec pm believe relevant documents typically commonly retrieved models compare r prec relevant doc count measures model r prec julie mug faessler et al bitem pm caucheteur et al baseline solr edismax baseline solr mlt baseline rel baseline abs baseline table scores entries trec pm baseline solr query results shown row subsequent rows showing results additional components solr edismax document ranking function based jones et al probabilistic model evaluate edismax solr mlt morelikethis new query document facet signal summary title association braf mutation clinicopathological features solitary papillary thyroid microcarcinoma pmid papillary intrahepatic cholangiocarcinoma braf unused unused unused unused papillary thyroid braf clinicopathological title identication differential functionally active mirnas anaplastic lymphoma kinase anaplastic large cell lymphoma pmid lymphoma anaplastic lymphoma alk cell bradykinin unused unused unused unused lymphoma alk receptor tyrosine kinase table sample facet conditioned document summarizations abs erated adding interesting terms tf idf terms retrieved documents initial edismax query traditional relevance feedback method row method decreased performance baseline reranking methods models rows present stable line scores combined method tops list improvement prior best model faessler et al baseline rel best terms prec prior teams rely heavily query expansion external knowledge bases add synonyms hypernyms hyponyms terms found original query qualitative analysis table presents sample pseudo queries generated abs summaries rst document novel words intrahepatic cinoma occur given document title conciseness abstract contain words model learned close relationship cholangiocarcinoma braf genetic facet actual query pmid turns relevant embedding proximity intrahepatic cholangiocarcinoma introduced pseudo query central document s theme maybe tant retrieving documents indirect relevant link query query terms abs underperforms rel complements combined table table shows abs generate concepts domain specic nology example second document yields following mesh entity codes strongly related topics document cell transformation neoplastic phoma large cell anaplastic anaplastic lymphoma kinase qualitative exploration ext different facets abs capture refer reader appendix machine conguration runtime training testing single nvidia titan x gpu desktop gb ram corpus indexed biomedical tations titles abstracts biomedical trained models ve epochs training time epoch query doc pairs mins rel mins ext mins abs coming test time query solr edismax query returns results ms generating pseudo queries candidates ext abs takes seconds generating rel scores consumes seconds query takes nearly mins test time return ranked list documents facilitate real time retrieval commercial search engines given complexity queries believe near real time offering convenient way launch pm queries furthermore comes affordable conguration labs clinics smaller carbon footprint conclusion paper proposed ensemble document reranking approach pm queries builds trained bert models combine strategies document relevance matching extractive stractive text summarization arrive document copyright issues text trec pm conducted abstracts titles articles available pubmed rankings complementary eventual uations experiments demonstrate entity embeddings trained annotated domain specic corpus help document retrieval tings quantitative qualitative analyses throw light strengths approach scope advances lies improving summarizer generate better pseudo queries abs starts perform better high level training data hard generate large amounts ir tasks biomedicine holds trec pm datasets better train abs better adapt biomedical ir datasets example trec clinical decision support cds task ran related pm task roberts et al future goal apply neural transfer learning rios kavuluru domain adaptation rios et al efforts repurpose cds datasets pm task straightforward idea reuse ated pseudo query sentences edismax query solr form pseudo relevance feedback scos expression section focuses asymmetric formulation starts query term looks best match query considering symmetric formulation begin pseudo query terms average summands provide better estimate reranking additionally thorough exploration external biomedical knowledge bases wagner et al incorporated neural ir framework pm tant nguyen et al references piotr bojanowski edouard grave armand joulin tomas mikolov enriching word vectors subword information transactions tion computational linguistics deborah caucheteur emilie pasche julien gobeill anais mottaz luc mottin patrick ruch designing retrieval models contrast driven search vs recall driven treatment traction precision medicine jianpeng cheng mirella lapata neural marization extracting sentences words proceedings annual meeting sociation computational linguistics volume long papers pages francis s collins harold varmus new tiative precision medicine new england journal medicine alexis conneau guillaume lample lingual language model pretraining advances neural information processing systems pages gordon v cormack charles la clarke stefan buettcher reciprocal rank fusion outperforms condorcet individual rank learning methods proceedings international acm sigir conference research development tion retrieval pages jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language standing naacl hlt pages erik faessler michel oleynik udo hahn julie lab med uni graz trec precision medicine track trey grainger timothy potter solr action manning publications co kaiming xiangyu zhang shaoqing ren jian sun deep residual learning image nition proceedings ieee conference computer vision pattern recognition pages k sparck jones steve walker stephen e son probabilistic model information retrieval development comparative experiments information processing management guillaume klein yoon kim yuntian deng jean lart alexander m rush opennmt source toolkit neural machine translation ceedings acl system demonstrations pages chin yew lin rouge package matic evaluation summaries text tion branches pages barcelona spain association computational linguistics yang liu mirella lapata text proceedings tion pretrained encoders conference empirical methods ral language processing international joint conference natural language processing emnlp ijcnlp pages jonas mueller aditya thyagarajan siamese recurrent architectures learning sentence ity proceedings thirtieth aaai conference articial intelligence pages ramesh nallapati feifei zhai bowen zhou summarunner recurrent neural network based quence model extractive summarization ments thirty aaai conference articial intelligence ramesh nallapati bowen zhou cicero dos santos c aglar gulcehre bing xiang abstractive text summarization sequence sequence rnns proceedings signll conference computational natural language learning pages shashi narayan shay b cohen mirella lapata ranking sentences extractive tion reinforcement learning naacl hlt pages gia hung nguyen laure soulier lynda tamine nathalie bricon souf dsrim deep neural information retrieval model enhanced edge resource driven representation documents proceedings acm sigir international ference theory information retrieval pages rodrigo nogueira kyunghyun cho oriented query reformulation reinforcement learning proceedings conference empirical methods natural language processing pages jiho noh ramakanth kavuluru document trieval biomedical question answering neural sentence matching ieee international conference machine learning applications icmla pages ieee romain paulus caiming xiong richard socher deep reinforced model abstractive marization international conference learning representations animesh prasad min yen kan glocal porating global information local convolution keyphrase extraction naacl hlt pages anthony rios ramakanth kavuluru neural transfer learning assigning diagnosis codes emrs articial intelligence medicine anthony rios ramakanth kavuluru zhiyong lu generalizing biomedical relation classication neural adversarial domain adaptation matics kirk roberts dina demner fushman ellen m voorhees william r hersh steven bedrick der j lazar shubham pant funda bernstam overview trec sion medicine track kirk roberts matthew simpson dina fushman ellen voorhees william hersh state art biomedical literature retrieval clinical cases survey trec cds track information retrieval journal alexander m rush sumit chopra jason weston neural attention model abstractive tence summarization emnlp pages mike schuster kaisuke nakajima japanese korean voice search ieee international conference acoustics speech signal ing icassp pages ieee abigail peter j liu christopher d manning point summarization generator networks proceedings nual meeting association computational linguistics pages zhiqing sun jian tang pan du zhi hong deng jian yun nie divgraphpointer graph pointer network extracting diverse keyphrases proceedings international acm gir conference research development information retrieval pages ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser illia polosukhin attention need advances neural information cessing systems pages alex h wagner brian walsh georgia mayeld david tamborero dmitriy sonkin kilannin krysiak jordi deu pons ryan p duren jianjiong gao julie mcmurry al harmonized knowledgebase clinical interpretations matic genomic variants cancer nature genetics thomas wolf lysandre debut victor sanh julien chaumond clement delangue anthony moi ric cistac tim rault remi louf morgan towicz al transformers state arxiv preprint art natural language processing yonghui wu mike schuster zhifeng chen quoc v le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey et al google s neural machine translation system bridging gap human machine lation arxiv preprint attention heatmaps facet signals figure depicts words highlighted ext dently terms related regulations gene expressions proteins disease names turing prominently figure shows abs reads source document differently depending facet signal starts process query generation compared ease facet attention heat map genetic facet focuses words related gene regulations figure heatmap classication scores ext darker red indicates relatively higher probability token relevant theme trec pm datasets attention heatmap produced signal topic disease attention heatmap produced signal topic generic variants gene regulations figure comparison attention heatmaps sample document conditioned eld signals abs model
