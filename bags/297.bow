faithfulness factuality abstractive summarization joshua maynez shashi narayan bernd bohnet ryan mcdonald google research joshuahm shashinarayan bohnetbd com abstract known standard likelihood training approximate decoding objectives neural text generation models lead human like responses open ended tasks language modeling story ation paper analyzed tations models abstractive ment summarization found els highly prone hallucinate content unfaithful input document ducted large scale human evaluation eral neural abstractive summarization systems better understand types hallucinations produce human annotators found substantial amounts hallucinated content model generated summaries analysis pretrained models better summarizers terms raw metrics rouge generating faithful factual summaries evaluated humans furthermore textual tailment measures better correlate fulness standard metrics potentially ing way automatic evaluation metrics training decoding criteria introduction current state art conditional text generation models accomplish high level uency herence thanks advances sequence architectures attention copy sutskever bahdanau fully attention based transformer chitectures vaswani dai recently pretrained language modeling natural language understanding devlin radford yang liu growing interest rst authors contributed equally human annotated summaries faithfulness tuality released com google datasets xsum hallucination annotations understanding maximum likelihood training approximate beam search decoding models lead human like text open ended text generation language modeling story generation holtzman welleck paper investigate models prone ate hallucinated text conditional text generation specically extreme abstractive document rization narayan document summarization task ing shorter version document ing information content mani nenkova mckeown requires models ate text human like ful factual given document ple figure illustrates faithfulness factuality conquered conditional text generators article describes event conservative zac smith winning mary london mayoral election maries forge entities nigel goldsmith zac goldwin information ukip leader nigel goldsmith nigel goldsmith ning mayoral election sadiq khan london mayor zac goldwin labour candidate supported document factually wrong interestingly summaries topical uent perform terms rouge scores lin hovy conducted large scale human evaluation hallucinated content systems use current neural network rnn convolutional neural network cnn narayan transformers radford rothe human written summaries recently introduced extreme summarization task xsum narayan seek answer following questions frequently abstractive marizers hallucinate content models gold zac goldsmith contest london mayoral election conservatives announced document richmond park north kingston said honoured winning votes cast online primary system beat london assembly member andrew boff mep syed kamall london deputy mayor crime policing stephen greenhalgh goldsmith main rival likely labour sadiq khan sentences words abbreviated goldsmith favourite tory nomination balloted constituents earlier year seek permission stand point entry race london mayor zac goldsmith decision revealed big characteristics sentences words abbreviated goldsmith rst entered parliament told bbc daily politics hoped environmental record appeal green lib dem voters hoped reach ukip supporters frustrated politics usual relationship zac goldsmith born educated eton cambridge centre sixth form studies sentences words abbreviated goldsmith conrmed stand parliament mayor triggering election said wanted build current mayor boris johnson achievements sentences words abbreviated khan goldsmith oppose new runway heathrow airport fact described british chambers commerce depressing sentences words abbreviated current mayor boris johnson step year terms ofce currently uxbridge south ruislip having returned parliament conservatives called inquiry mayoral election process people voted compared turnout labour contest sentences words abbreviated ptgen ukip leader nigel goldsmith elected new mayor london elect new conservative london mayoral candidate zac goldsmith chosen stand london mayoral election london mayor sadiq khan chosen candidate mayor london gpt tuned conservative zac goldwin bid labour candidate london mayoral election zac goldsmith chosen contest london mayoral election figure hallucinations extreme document summarization abbreviated article gold summary abstractive model generated summaries ptgen narayan tuned rothe news article extreme summarization dataset narayan dataset abstractive models described section present rouge scores relative reference gold summary words red correspond hallucinated information whilst words blue correspond faithful information lucinate manipulating information present input document intrinsic hallucinations adding information directly inferable input document extrinsic hallucinations hallucinated content factual unfaithful automatic means measuring hallucinations main conclusions follows intrinsic extrinsic hallucinations happen quently single sentence maries second majority hallucinations extrinsic potentially valid tions use background knowledge study found extrinsic nations erroneous hallucinations pen summaries majority faithful factual models tialized pretrained parameters perform best automatic metrics human judgments faithfulness factuality furthermore highest percentage extrinsic hallucinations factual suggests studies argue large scale pretrained models merely better learning data specic regularities niven kao domain rization gains automatic metrics ized observable differences humans fourth rouge lin hovy bertscore zhang correlates ness factuality metrics derived automatic semantic inference systems specically degree summary entailed source ment presents opportunity improved automatic evaluation measures model training decoding objectives inary experiments direction hallucinations summarization open ended generation task generating text forms natural continuation input text requires model hallucinate text focus ensure model learns generate text human like repetitive dull content related words holtzman welleck contrast tasks document summarization nenkova mckeown paulus data text generation lebret wiseman open ended require models factual faithful source text despite recent improvements conditional text generation summarization systems trained maximize log likelihood erence summary word level necessarily reward models faithful models usually agnostic noises artifacts training data reference gence making vulnerable hallucinations kryscinski wiseman dhingra models ate texts consistent input likely reasonable model log likelihood intrinsic extrinsic hallucinations given document abstractive summary try identify hallucinations spect content regardless quality summary work dene summary hallucinated supported input document distinguish hallucinations context document summary categorize cinations information source intrinsic extrinsic hallucinations note paraphrases information inferred document categorized hallucinations intrinsic hallucinations consequences synthesizing content information present input document example ure london mayoral candidate abstract london mayor abstract hallucinations trinsic nature use terms concepts document misrepresent information document making unfaithful document article conrm zac goldsmith london mayoral candidate sadiq khan london mayor suspect model poor input ment representation fail document level inference required abstraction vulnerable errors extrinsic hallucinations model generations ignore source material altogether ample figure nigel ptgen abstract gold gpt tuned extrinsic hallucinations terms duced document model informed decoder agnostic vergence issue source target texts wiseman dhingra function open ended language model prone extrinsic hallucinations factual hallucinations summarization summary document contains factual hallucination contains information found factually correct factual tions composed intrinsic hallucinations extrinsic hallucinations denition abstractive summaries preserve salient information input document expressed words summary author opposed input ment author nenkova mckeown natural construct summaries grate author background knowledge van dijk kintsch brown day knowledge integration desirable real world applications instance gaging sports report reect understanding game provide color context example audience targeted summarization good summary reect understanding article domain desired audience nonetheless consensus research community summary faithful hallucinations input document tolerance factual hallucinations recent deep learning approaches abstractive summarization naturally learn integrate edge training data generating abstractive summary document gehrmann advanced trained text generators radford dong song khandelwal rothe better capturing world knowledge informed vast background text observed example shown figure input document mention discussed london mayoral election abstract generated pretrained text generator gpt tuned correctly predicts information similar human authored abstract correct extrinsic hallucination gpt tuned abstract overall factual incorrect extrinsic hallucination conservative zac goldwin conservative named zac goldwin paper stand favour tion abstractive systems integrate background knowledge generate rich ingful summaries concretely tions summarization acceptable lead better summaries factual respect document associated background knowledge assumption allows assess capability recent neural models tegrate background knowledge generate factual abstracts section extreme document summarization focus recently introduced extreme marization dataset xsum narayan comprises british broadcasting poration bbc articles paired sentence summaries provided journalists writing articles dataset split subsets training validation test sets models trained generate abstractive summaries trained evaluated standard split vided authors choose focus study extreme rization following reasons task aims create single sentence summary news article shorter summaries relatively ier annotate analyze longer summaries story highlights cnn dailymail dataset hermann abstracts times sandhaus wikisum liu dataset secondly gold summary extreme summarization dataset ductory sentence prefacing article virtue property extreme summarization task amenable extractive strategies requires abstractive modeling approach vides better benchmark assess abstractive models abilities produce abstractions faithful factual finally conclude hallucination problem dataset safely conclude problem tion datasets longer summaries modeling longer distance dependencies discourse tures task harder abstractive summaries evaluate summaries rnn cnn transformer based state art abstractive marization methods reference human com edinburghnlp xsum summaries appendix eter decoding details models human written reference summaries single sentence summaries contained treme summarization dataset xsum uated study summaries written journalists introductions news articles precede summaries true additional information found document divergence issue source target uncommon conditional text generation kryscinski wiseman dhingra rnn based use generator model ptgen introduced rnn based attention based sequence sequence model generates target vocabulary copy words source text topic aware convolutional topic aware convolutional sequence sequence model introduced narayan abstractive system conditioned article topics based entirely convolutional neural networks gehring better suited extreme summarization convolution layers capture long range dependencies words document effectively rnns simultaneously convolutional encoder associates word topic vector capturing representative document content transformer based abstractive methods experiment transformer based model variants layers hidden size lter size attention heads gpt tuned radford proposed transformer based generative pre trained gpt language models generate high quality text open ended generation setups proposed decoder architecture language modeling easily adapted abstractive summarization model rst sees document given prompt generates summary gpt tuned warm started publicly available gpt checkpoint radford tuned supervised training treme summarization dataset sequence sequence models models ptgen gpt tuned human eval test set bertscore table rouge bertscore scores pretrained block pretrained block models reported xsum dataset sults sampled human evaluation items dataset best results boldfaced encoder decoder composed transformer layers vaswani rothe weights randomly initialized encoder decoder initialized bert base checkpoints devlin parameter sharing encoder decoder following rothe variable initialized randomly decoder attention models trained extreme summarization dataset experiments results main focus work propose lution hallucination related issues achieve better understanding hallucinations tive summarization human ment randomly sampled articles test set facilitate study test set unfeasible given size cost man judgments trained annotators uent english specically assessment annotators went pilot studies better understanding intrinsic extrinsic hallucinations factuality summaries uments pilot studies nal annotation report rouge lin hovy scores bertscore zhang semantic inference metric textual entailment pasunuru bansal welleck falke kryscinski question answering arumae liu wang automatic evaluation summaries rouge lin hovy provides means quickly assess model ability generate maries closer human authored summaries report tiveness rouge uency like rouge bertscore zhang computes ilarity score token candidate figure human assessment system generated summary article figure annotation user interface shown shown raters mary token reference summary instead exact matches computes token similarity contextual embeddings sults presented table cases pretrained encoder decoder architecture performed far superior randomly initialized models gen architecture gpt tuned differences tween ptgen signicant differences signicant rouge bertscore indicators mativeness summaries sufcient metrics assess overall quality summaries evident human assessments following sections employ human annotators evaluate summaries generated ptgen human authored summaries excluded gpt tuned abstracts study poor performance automatic measures assessment hallucinations assessment human annotators sented article single sentence summary article stringently told assess hallucinations summary confuse assessment quality summary summaries containing tions annotators tasked identifying text spans unfaithful cle text span annotating hallucination intrinsic extrinsic elicited judgments different annotators document summary pairs figure shows example assessment mary article figure results assessment shown table shows percentage documents system annotated faithful hallucinated faithful hallucinated appendix provides annotator agreement hallucinations hallucinated span characteristics extrinsic hallucination divergence tween source target results comparisons models way anova post hoc tukey hsd tests models ptgen gold hallucinated faith fact table intrinsic extrinsic hallucinations numbers hallucinated columns age summaries word tated annotators intrinsic sic hallucination summary marked hallucination faithful umn faith nal fact column shows total percentage faithful factual summaries includes faithful summaries plus age non faithful summaries annotated notators factual higher numbers faithful factual lower numbers hallucinations boldfaced rmed bbc gold summaries trinsic hallucinations dataset artifact gold summaries introductory sentences acing article surprising models signicant extrinsic hallucinations intrinsic hallucination common stractive summaries gold summaries display intrinsic hallucinations example news article describe event related barack obama ofce president united states inferring obama president united states journalist knowledge event article write summary stating president obama percentage system summaries intrinsic hallucination higher gold summaries nomenon particularly revealed models dency misrepresent information document lack document level understanding inference copy mechanism ptgen good copying source showing percentage extrinsic hallucination mechanism lacks inference capability prone generate summary supported document intrinsic hallucination showed similar performance ptgen ranked second worst showed number intrinsic hallucination abstractive systems pretraining improves faithfulness tions result artifacts training data model shortcomings ptgen model copy mechanism lowest extrinsic hallucination reported highest number faithful summaries appears overall conservative abstractive systems getting closer reference summaries terms rouge training prepares aware domain document prone language model vulnerabilities consequently condent predicting tokens ment improving faithfulness assessment factual hallucinations hallucinations necessarily erroneous second human assessment measured tent case annotators presented single sentence summary hallucinations asked assess true false better explain context summary tors available source document external resources wikipedia google search source document particularly important generic summaries ter understand context external resources assisted evaluators validate grounded facts public knowledge bases annotators expected validate mary looking supporting evidence information found summary information summary contradicts document summary factual supporting evidence found information summary factual document useful mary information supported contradicted article example mary figure mentions conservative zac goldwin veried article figure annotators use wikipedia google search check conservative named zac goldwin tried change party labour date london mayoral election dropped human authored gold summaries evaluation presumably factual dropped abstracts faithful input documents previous study finally document summary pairs summaries marked intrinsic extrinsic hallucination elicited judgments different annotators results assessment sented table column labelled fact hallucination assessment pretraining helps generating factual maries total stracts faithful factual absolute better best model ptgen number ful factual summaries highest fact extrinsic tions ptgen hallucinates hallucinations factual compared ptgen consider factual tions valid means extrinsic cases hallucinates superior performance likely exposure vast text pretraining allowing integrate ground knowledge generation hallucinations erroneous finally carried pairwise comparisons tween models way anova post hoc tukey hsd tests sic hallucinations second column table gold signicantly different tems extrinsic hallucinations umn table signicant differences ptgen ptgen gold gold ity differences ptgen insignicant automatic measures hallucinations summaries proxy source documents assumption highlight important content assumption ther studied extent hallucinated content measured semantic inference related measures textual entailment question answering textual entailment trained entailment classier netuning bert large pretrained model devlin multi nli dataset williams calculated entailment probability score ment abstractive summaries note entailment classier optimal bbc article summary pairs multi nli dataset tains sentence sentence pairs ideally summary entail document neutral document contradict document seen table abstracts showed number appendix results models ptgen gold textual entailment neut entail cont table textual entailment question answering based measures summary evaluation tailment percentage times summary entails entail document neutral neut document contradicts cont document report percentage questions correctly answered system highest numbers entail neut lowest number cont boldfaced contradictions compared system generated abstracts par gold summaries similar performance extrinsic nation table abstracts displayed highest number contradictions terestingly gold summaries neutral documents maries entailed documents probably nature data journalists tend add color high ber extrinsic valid hallucinations question answering frameworks assess promote summary mativeness narayan arumae liu adapted framework sess hallucination model generated summaries faithful model generate summary information supported document assumption question answerable summary answerable source given abstractive summary round trip consistency method alberti combines question generation answer extraction models generate synthetic question answer pairs summary pairs generated question answer pairs ptgen gold spectively finally machine reading comprehension model answer questions document context alberti trained models question generation answer extraction reading comprehension els bert base pretrained model devlin netuned natural questions dataset kwiatkowski textual entailment similar results ptgen leeds united fought beat hudderseld town rst round efl cup team leeds united beat rst round efl cup hudderseld town coal south yorkshire collapsed result loss coal type collapsed coal star wars actor james davis said locked caravan caravan stolen break said locked caravan davis figure sample question answer pairs generated hallucinated summaries correctly swered source articles highlighted spans summaries marked extrinsic intrinsic lucinations annotators metric rouge bertscore entailment faithful factual table spearman correlation coefcient ferent metrics faithful factual annotations abstracts faithful source documents terms question answering gold abstracts accurate high number extrinsic hallucination spearman correlation estimate man correlation coefcients different metrics faithful factual human scores table found textual entailment scores best correlated faithful erate factual weak human scores comparatively rouge based metrics bertscore weak correlation ndings consistent recent studies goodrich ski wang surprisingly question answering scores showed weak correlation faithful factual human scores hypothesize compounding errors question generator generate questions systems generated abstracts instead human written text trained question generator susceptible generate questions hallucinated content fed hallucinated summaries tion summary faithful answers source summary match poor extreme summarization demonstrate issues figure irrespective questions hallucinated content reading comprehension models entail faith faith fact table rouge faithfulness factuality scores plus systems use textual entailment criteria tuned faithful annotations model fortuitously answer correctly source articles better ways generating questions narayan measuring tual consistency alleviate issues wang model selection entailment study suggests entailment automatic measure faithfulness point measure easily gamed rst tence source document entailed document based measures evaluation need coupled reference based measures like rouge major advantage measure reference use model selection objective decoding tested specically probability summary entailed document tion criteria select summary didates generated systems evaluated ptgen results shown entail row table strong metric optimize want faithful summaries absolute better trade terms rouge model select tems signicantly lower rouge best model experiment train model itly predict faithfulness order tuned entailment model faithful annotations generated tion summary document pairs marked faithful set associated class entailment set neutral allowed tune classication layers taking advantage correlation entailment faithfulness results fold cross idation shown entailfaith row table improve ability select faithful summaries set candidates slightly expect larger gains training data model signicantly better entail rouge based metrics like good balance rouge better faithfulness related work following document understanding ence duc dang majority work focused evaluating content linguistic quality summaries nenkova ular automatic metric rouge lin hovy measures unigram bigram overlap proxy assessing informativeness longest common subsequence rouge ency rouge misleading means assess ness summaries schluter rouge score complemented tive human assessment summaries tive measures proposed improve ment human annotators pyramid method nenkova passonneau requires maries annotated experts salient mation narayan answering based approach summary context answer questions written based reference summary hardy proposed reference approach summary assessed source document highlighted pertinent content work evaluating faithfulness truthfulness abstractive maries automatic evaluation rouge human evaluation saliency linguistic quality summaries sufcient complex nature task recently chen bansal asked human annotators assess summary relevance measuring saliency presence contradictory unrelated mation dhingra proposed new tomatic metric parent data text ation lebret wiseman aligns grams reference erated texts source table measure racy grams entailed source table goodrich proposed based automatic metric assess faithfulness wikipedia summaries trained end end model extract complete set openie style banko facts source text generated summary summary faithful precise generating facts source text experiments based measures found suited evaluating extreme summarization models models perform poorly metrics signicant differences like recent works parallel explored natural language inference question answering els detect factual consistency generated text welleck falke ski wang line ndings falke observed bert based nli models substantially improved summaries reranking terms correctness kryscinski proposed nli based fact checking model trained dataset tailored detecting factual inconsistencies erated text wang proposed question answering generation based automatic ation protocol designed identify factual inconsistencies generated summary future work likely investigate better ways ating questions measuring factual consistency address poor correlation faithfulness factuality annotations finally reinforcement ing improve informativeness reduce tradictory information abstractive summaries pasunuru bansal textual entailment based reward arumae liu question answering based reward approaches evaluate wards improve faithfulness summaries conclusion conducted large scale study hallucinations abstractive document summarization found tackling hallucination critical challenge abstractive summarization critical nlu driven pretraining neural text generators key generate informative coherent faithful factual abstracts far solving problem iii measures rouge bertscore sufcient studying problem semantic inference based automatic measures better representations true summarization quality acknowledgments thank ratish puduppully yova jhieva ankur parikh peter liu slav petrov reviewers action editor invaluable hard work muqthar mohammad mohd majeed ashwin kakarla man annotation possible references chris alberti daniel andor emily pitler jacob vlin michael collins synthetic pora generation roundtrip consistency ceedings annual meeting ciation computational linguistics pages florence italy kristjan arumae fei liu guiding extractive summarization question answering rewards proceedings conference north american chapter association tional linguistics human language technologies pages minneapolis minnesota dzmitry bahdanau kyunghyun cho yoshua gio neural machine translation jointly learning align translate tional conference learning representations san diego usa michele banko michael cafarella stephen land matt broadhead oren etzioni open information extraction web ceedings international joint conference artical intelligence pages abad india ann brown jeanne day macrorules summarizing texts development journal verbal learning verbal tise haviour yen chun chen mohit bansal fast tive summarization reinforce selected sentence rewriting proceedings annual ing association computational linguistics pages melbourne australia zihang dai zhilin yang yiming yang jaime bonell quoc ruslan salakhutdinov transformer attentive language models proceedings xed length context annual meeting association tional linguistics pages florence italy hoa trang dang overview duc proceedings document understanding ference pages jacob devlin ming wei chang kenton lee kristina toutanova bert pre training deep bidirectional transformers language proceedings conference standing north american chapter association computational linguistics human language technologies pages minneapolis nesota bhuwan dhingra manaal faruqui ankur parikh ming wei chang dipanjan das william hen handling divergent reference texts evaluating table text generation proceedings annual meeting association computational linguistics pages rence italy teun van dijk walter kintsch cognitive psychology discourse recalling ing stories wolfgang dressler editor current trends textlinguistics pages dong nan yang wenhui wang furu wei aodong liu wang jianfeng gao ming zhou hsiao wuen hon unied language model pre training natural language advances neural ing generation mation processing systems pages curran associates inc tobias falke leonardo ribeiro prasetya ajie utama ido dagan iryna gurevych ranking generated summaries correctness teresting challenging application natural guage inference proceedings annual meeting association computational guistics pages florence italy jonas gehring michael auli david grangier nis yarats yann dauphin tional sequence sequence learning ings international conference chine learning volume pages ney nsw australia sebastian gehrmann yuntian deng alexander rush abstractive summarization proceedings conference cal methods natural language processing pages brussels belgium ben goodrich vinay rao peter liu mad saleh assessing factual accuracy generated text proceedings acm sigkdd international conference knowledge discovery data mining pages new york usa jiatao zhengdong hang victor incorporating copying mechanism proceedings sequence sequence learning annual meeting association putational linguistics pages berlin germany hardy shashi narayan andreas vlachos highres highlight based reference evaluation proceedings summarization nual meeting association computational linguistics pages florence italy karl moritz hermann tomas kocisky edward stette lasse espeholt kay mustafa suleyman phil blunsom teaching machines read advances neural comprehend tion processing systems pages ran associates inc ari holtzman jan buys maxwell forbes yejin choi curious case neural text ation proceedings international ference learning representations virtual ference addis ababa ethiopia urvashi khandelwal kevin clark dan jurafsky lukasz kaiser sample efcient text marization single pre trained transformer corr wojciech kryscinski nitish shirish keskar bryan cann caiming xiong richard socher neural text summarization critical evaluation proceedings conference cal methods natural language processing international joint conference natural language processing pages hong kong china wojciech kryscinski bryan mccann caiming xiong richard socher evaluating tual consistency abstractive text summarization corr taku kudo john richardson sentencepiece simple language independent subword enizer detokenizer neural text processing corr tom kwiatkowski jennimaria palomaki olivia eld michael collins ankur parikh chris berti danielle epstein illia polosukhin jacob vlin kenton lee kristina toutanova llion jones matthew kelcey ming wei chang andrew dai jakob uszkoreit quoc slav petrov natural questions benchmark question swering research transactions association computational linguistics richard landis gary koch surement observer agreement categorical data biometrics remi lebret david grangier michael auli neural text generation structured data application biography domain ings conference empirical methods natural language processing pages austin texas chin yew lin eduard hovy automatic uation summaries gram occurrence statistics proceedings human guage technology conference north chapter association computational linguistics pages peter liu mohammad saleh etienne pot ben goodrich ryan sepassi lukasz kaiser noam shazeer generating wikipedia ing long sequences proceedings national conference learning representations vancouver canada yinhan liu myle ott naman goyal jingfei dar joshi danqi chen omer levy mike lewis luke zettlemoyer veselin stoyanov roberta robustly optimized bert pretraining approach corr inderjeet mani automatic summarization ume john benjamins publishing shashi narayan shay cohen mirella lapata details summary topic aware convolutional neural networks proceedings treme summarization conference empirical methods natural guage processing pages brussels gium shashi narayan shay cohen mirella lapata ranking sentences extractive tion reinforcement learning proceedings conference north american ter association computational linguistics human language technologies pages new orleans louisiana shashi narayan goncalo simoes hannah craighead ryan mcdonald ous question generation pretraining text eration corr ani nenkova automatic text summarization newswire lessons learned document proceedings understanding conference national conference articial intelligence volume pages ani nenkova kathleen mckeown matic summarization foundations trends information retrieval ani nenkova rebecca passonneau ing content selection summarization proceedings human mid method guage technology conference north chapter association computational linguistics pages boston massachusetts usa timothy niven hung kao probing ral network comprehension natural language guments proceedings annual ing association computational linguistics pages florence italy ramakanth pasunuru mohit bansal reward reinforced summarization saliency proceedings entailment ence north american chapter ation computational linguistics human guage technologies pages new orleans louisiana romain paulus caiming xiong richard socher deep reinforced model abstractive marization proceedings international conference learning representations ver canada alec radford karthik narasimhan tim salimans ilya sutskever improving language standing generative pre training technical port sean welleck jason weston arthur szlam kyunghyun cho dialogue natural language inference proceedings annual ing association computational linguistics pages florence italy adina williams nikita nangia samuel bowman broad coverage challenge corpus tence understanding inference ings conference north chapter association computational linguistics human language technologies pages new orleans louisiana sam wiseman stuart shieber alexander rush challenges data document generation proceedings conference cal methods natural language processing pages copenhagen denmark yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey jeff klingner apurva shah melvin son xiaobing liu lukasz kaiser stephan gouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wei wang cliff young jason smith jason riesa alex nick oriol vinyals greg corrado macduff hughes jeffrey dean google neural machine translation system bridging gap human machine translation corr zhilin yang zihang dai yiming yang jaime bonell ruslan salakhutdinov quoc xlnet generalized autoregressive pretraining language understanding corr tianyi zhang varsha kishore felix kilian weinberger yoav artzi bertscore evaluating text generation bert ings international conference ing representations virtual conference addis ababa ethiopia alec radford jeff rewon child david luan dario amodei ilya sutskever language models unsupervised multitask learners cal report sascha rothe shashi narayan aliaksei severyn leveraging pre trained checkpoints appear quence generation tasks tions association computational tics evan sandhaus new york times annotated corpus linguistic data consortium philadelphia natalie schluter limits automatic marisation according rouge proceedings conference european chapter sociation computational linguistics pages valencia spain abigail peter liu christopher manning point summarization generator networks proceedings nual meeting association computational linguistics pages vancouver canada abigail aneesh pappu rohun saxena akhila yerukola christopher manning massively pretrained language models better proceedings storytellers ence computational natural language learning pages hong kong china kaitao song tan tao qin jianfeng yan liu mass masked sequence quence pre training language generation ceedings international conference machine learning long beach california ilya sutskever oriol vinyals quoc sequence sequence learning neural networks advances neural information processing tems pages curran associates inc ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan gomez lukasz kaiser illia polosukhin attention need advances neural information cessing systems pages curran ciates inc alex wang kyunghyun cho michael lewis asking answering questions evaluate factual consistency summaries ings annual meeting association computational linguistics virtual conference seattle usa sean welleck ilia kulikov stephen roller emily nan kyunghyun cho jason weston ral text generation unlikelihood training proceedings international conference learning representations virtual conference merly addis ababa ethiopia model hyperparameters predictions ptgen model predictions vided narayan transformer model predictions gpt tuned rothe gen use stanford tokenized vocabulary size use vocabulary size wordpieces match bert pretrained cabulary gpt tuned vocabulary size sentencepieces kudo son match pretrained ulary models use uncased lary source target sides ptgen summaries generated beam search beam size transformer models use beam size narayan rothe details models models ptgen gold hall fleiss kappa fact rept inco table fleiss kappa scores measuring word level agreements annotators different annotation tasks hallucination hall factuality fact tion rept incoherence inco assessments inter annotator agreement estimated fleiss kappa assess ment raters categorizing word summary faithful intrinsically cinated extrinsically hallucinated results shown table models showed tial agreement landis koch annotations table shows fleiss kappa sess agreement raters factuality models showed perfect agreement landis koch annotations models ptgen gold intrinsic total avg extrinsic total avg avg length table total number spans average number spans document annotated intrinsic sic hallucinations document summary pairs annotators average span length system models ptgen gold repetition incoherence table repetition incoherence evaluation numbers percentage summaries word summary annotated annotators repetition ence related issue lowest numbers boldfaced metric rouge bertscore repetition incoherence entailment faithful factual table spearman correlation coefcient ferent metrics faithful factual annotations number extrinsically hallucinated spans document interestingly average span length ptgen summaries words higher words maries result demonstrates effect hallucination local observe ptgen despite lower number extrinsically hallucinated spans uments ptgen compared spans document documents total number words notated extrinsic hallucination higher ptgen words assessment linguistic highlighted span characteristics irregularities results table shed light teristics hallucinated spans observed different abstracts gold abstracts showed ber intrinsically hallucinated spans document ptgen abstracts showed following standard practice summarization document summary pairs annotated repetition incoherence related linguistic larities annotators presented sentence summary asked identify models faithful ptgen gold factual total hallucinated factual total factual total factual table intrinsic extrinsic hallucinations factuality numbers hallucinated columns percentage summaries word annotated annotators intrinsic extrinsic hallucination summary marked hallucination faithful factual columns hallucinated column type percentage summaries annotated annotators factual nal factual column shows total percentage factual summaries faithful iefactual highest numbers faithful factual lowest numbers hallucinations boldfaced spans text summary peated summary incoherent elicited judgments different annotators document summary pair results shown table overall neural text generation systems getting better generating repetition free herent single sentence summaries news cles transformer based models particular perform superior based ptgen cnn based els nonetheless table shows metrics fail correlate faithful hallucinated tual assessments summaries fleiss kappa values repetition incoherence assessments showed perfect agreement landis koch raters table hallucination results table results human study hallucinations
