word embedding based text processing comprehensive summarization distinct information extraction xiangpeng wan hakim ghazzai yehia massoud school systems enterprises stevens institute technology hoboken usa email hghazzai edu abstract paper propose automated text processing frameworks specically designed analyze online reviews objective rst framework summarize reviews dataset extracting essential sentence performed converting sentences numerical vectors clustering community detection algorithm based similarity levels correlation score measured sentence determine importance level cluster assign tag community second framework based question answering neural network model trained extract answers multiple different questions collected answers effectively clustered multiple distinct answers single question asked customer proposed frameworks shown comprehensive existing reviews processing solutions index terms customer reviews topic modeling text rization question answering model bert introduction modern life people likely trust peers advertising comes purchasing decisions service selections fact according global trust advertising report surveyed internet respondents countries customers reveal trust recommendations friends relatives forms advertising customers trust reviews users advertising indication service product reviews play integral role purchase decision making process thirds internet users check online customers reviews choosing article cases hundreds thousands reviews exist online single product service impossible customers read check worthwhile provide efcient review analyzer process lter classify extract essential information summarizing reviews natural language processing nlp new emerging technology process stand textual data application predicting paper accepted publication ieee technology engineering management society international conference metro troit michigan usa ieee personal use material permitted permission ieee obtained uses current future dia including reprinting republishing material advertising tional purposes creating new collective works resale redistribution servers lists reuse copyrighted component work works customers feelings certain service product detecting rumors wrong information social networks nlp limit output inaccurate results fact machines understand contextual meaning review potential solution tistical topic modeling approach aims discovering abstract topic occur collection documents paper context extracting topics reviews service product objective collect interpret topics positive points main issues highlighted reviewers hard apply approaches context reviews textual input usually short low frequency important words high number overlapped meaningless words finally text summarization methods employed extract main bullets outlining long documents shown performances remain limited usually proposed approaches lack common terminology linked input dataset cope aforementioned limitations existing proaches order efciently analyze reviews extract signicant information propose generic based frameworks rst framework unsupervised clustering approach classify summarize reviews ing similarities sentences submitted reviewers customers extract important feedbacks starts measuring sentences similarities combining textrank algorithm bidirectional encoder representations transformers bert model word embedding vector dimension matching algorithm word embedding words phrases converted continuous vector space pre trained large data sets similarities phrases sentences calculated distances bert model introduced google redened state art nlp tasks text classication question answering language translation apply louvain method detect communities sentences textrank algorithm identify meaningful sentences tag community generally provide customers summary reviews usually need specic details product service knowing effect cosmetic product second framework designed extract kind details fig framework review clustering summarization vide customers complete idea product service adopt question answering model rapidly provide answers given text large volume reviews fact recently published models including bert xlnet enable machines achieve performance close human challenging area tested stanford question answering dataset squad bert able accurately extract details thousands reviews service product selected questions adopted reviews context collected information ltered clustered summarized based similarity networks provide customers decent results finally apply proposed frameworks practical case study process google review data restaurant area manhattan nyc reviews clustering summarization section propose design review help customers ing summarization model overview feedback product service analyzing large volume reviews methodology owchart proposed framework review tering summarization shown fig consists major parts rst creates similarity network graph joining different sentences collected review dataset second assigns textual tags clustered community rst input constituted reviews split independent sentences denoted review index index sentence review sentence represented node graph edges connecting nodes represent similarity corresponding sentences order calculate similarity score denoted map sentences vector space word embedding algorithm compute cosine similarity value fig vector space word different context distance sentences instead traditional glove models use bert represent word vector having real numbers elements values depend context sentence word different vector resentations given word different contexts example provided fig notice word bank different vector representations contexts different cosine similarity score high meanings word similar consequently sentences words represented vector space length cosine similarity score sentences having dimension computed sentence words sliding window browsing longest sentence applied compare phrases number words comparisons highest obtained score fig procedure compare similarity sentences having different lengths fig example communities detected reviews sentences having highest correlation scores tags community corresponding node consequently sentences highest correlation score sentence similar tag detected community case study restaurant reviews section illustrate evaluate output proposed framework applied case restaurant reviews randomly select restaurant located manhattan nyc having reviews google website shown fig dataset pick recent reviews feed framework pipeline described earlier split review sentences case short phrases combine previous sentences avoid having inaccurate results computing similarities fig tractability provide graph representing tions sentences composing reviews isolated nodes sentences illustrated highlight different detected communities colored differently corresponding tags independent communities obtained louvain algorithm tagged sentence having highest correlation score communities positive comments rating restaurant words positive restaurant discussed reviews iii multiple distinct answers extraction mentioned introduction having main ideas product service sufcient certain customers care details require deeper information framework propose develop question answering model framework extract details pre dened questions answered processing reviews dataset methodology tackle problem propose second information extraction framework presented fig composed fig example reviews selected restaurant represent similarity sentences shown fig represents similarity sentence sentence step create network graph modeling similarities sentences vertices graphs phrases sentences edges connecting vertices indicate certain similarity note set certain threshold similarities edge exists similarity larger threshold similarity network objective cluster sentences different topics assign tags selecting meaningful sentences clustering based louvain method designed blondel greedy optimization method rapidly extract communities large networks clustering problem objective function maximize modularity metric dened lows sum weights edges attached nodes respectively sum weights graph kronecker delta function binary value communities nodes assign correlation score denoted sentence graph reects larity rest phrases nodes graph textrank algorithm counts number quality links sentence determine important fig proposed framework multiple distinct answers extraction major parts rst dedicated collect answers questions formulated according context product service apply swering question answering model trained squad dataset model batch trained epochs total questions batch consists questions shown model achieves matching score score close human performance respectively note score measures average overlap prediction ground truth question answering model provided bert valid multi responses questions overcome issue proceed formulating new different questions having meaning original questions possible answers rst outputs question set answers second adopt framework described section original question possible answers collected clustered communities tags assigned according correlation scores original question determine number distinct answers corresponding number detected communities optionally framework answer human entered questions returning relevant answers case study restaurant reviews employ restaurant reviews data pick recent thousand reviews table present examples answers extracted review text applying question answering model applied rst review text words given fig future study explore bert albert ensemble models expected achieve better performance human require large computational resources table example output question answering model applied rst review given fig questions eat try best food delicious dish recommended prefer service price long waiting time place clean answers appetizers tried chicken satay calamari salad pumpkin sticky rice appetizers mango delivery efcient slightly pricey table notice intentional selected questions able extract required information single review including delicious dish comments price quality service restaurant addition original question delicious food order restaurant use similar questions rst questions given table extract possible answers original question note need remove redundant answers appetizers fig present possible answers thousand reviews corresponding original question ltering clustering results obtain communities different tags representing different menus items recommended reviewers answer noodles pork crab highest correlation score recommended highest number reviewers reected community size finally compare results ask question service provided google shown fig original question service provides reviews seven provide useful details customers hardly comprehensive information deerwester dumais furnas landauer harshman indexing latent semantic analysis journal american society information science vol hofmann unsupervised learning probabilistic latent semantic analysis machine learning vol blei jordan latent dirichlet allocation journal machine learning research vol jan page brin motwani winograd pagerank citation ranking bringing order web tech rep stanford infolab barrios lopez argerich wachenchauzer variations similarity function textrank automated summarization arxiv preprint robertson zaragoza probabilistic relevance work foundations trends information retrieval vol pal saha approach automatic text summarization wordnet ieee international advance computing ference iacc ieee vodolazova lloret munoz palomar role statistical semantic features single document extractive rization mikolov sutskever chen corrado dean distributed representations words phrases ality advances neural information processing systems goldberg levy explained deriving mikolov negative sampling word embedding method arxiv preprint levy goldberg dagan improving distributional similarity lessons learned word embeddings transactions association computational linguistics vol dong chawla swami scalable resentation learning heterogeneous networks proceedings acm sigkdd international conference knowledge discovery data mining acm pennington socher manning glove global vectors word representation proceedings conference empirical methods natural language processing emnlp devlin chang lee toutanova bert pre training deep bidirectional transformers language understanding arxiv preprint kumar irsoy ondruska iyyer bradbury gulrajani zhong paulus socher ask dynamic memory networks natural language processing international conference machine learning zhang zhou duan zhao net syntax guided machine reading comprehension arxiv preprint rajpurkar zhang lopyrev liang squad text arxiv preprint comprehension machine questions mikolov chen corrado dean efcient estimation word representations vector space arxiv preprint blondel guillaume lambiotte lefebvre fast unfolding communities large networks journal statistical mechanics theory experiment vol wolf debut sanh chaumond delangue moi cistac rault louf funtowicz brew transformers state art natural language processing fig example clustered menu items extracted reviews fig snapshot example ask question service google exhaustive list requests information provided proposed framework specic directed customers need ease purchase decisions conclusion paper proposed text processing frameworks provide assistance customers reviewing previous users comments rst framework summarizes reviews providing important information clustering constants communities assigning tags second text processing framework aims extract detailed information product service adopting question answering neural network model applied proposed frameworks particular case study model provides comprehensive results existing solutions references paul chaney word mouth trusted resource says nielsen implications social commerce tech rep apr rimma kats surprise consumers look reviews liu sentiment analysis mining opinions sentiments emotions purchase tech rep feb cambridge university press zhang chen yeo lau lee detecting mors online social networks multi layer autoencoder ieee technology engineering management conference temscon june
