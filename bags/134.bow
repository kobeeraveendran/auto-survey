tone biased mmr text summarization chaudhari nelson mattukoyya graduate student of computer science information systems pilani birla goa campus goa india abstract text summarization is an interesting area for researchers to develop new techniques to provide human like summaries for vast amounts of information summarization techniques tend to focus on providing accurate representation of content and often the tone of the content is ignored tone of the content sets a baseline for how a reader perceives the content as such being able to generate summary with tone that is appropriate for the reader is important in our work we implement maximal marginal relevance mmr based multi document text summarization and propose a nave model to change tone of the summarization by setting a bias to specific set of words and restricting other words in the summarization output this bias towards a specified set of words produces a summary whose tone is same as tone of specified words keywords text summarization maximal marginal relevance tone bias introduction with vast amounts of information being generated every day automated text summarization is used to represent such vast information in compact form there are many techniques that have been developed over recent times to improve the accuracy of summary and provide summaries that are human like various features of sentences are used to rank the sentences which should be included in the summary the top ranked sentences are refined and reordered to form a coherent summary feature based ranking means that we try improving the query relevance of the sentences selected for summarization but this in turn might increase redundancy in summary as many query relevant sentences may have similar content in our work we implemented maximal marginal relevance mmr based text multi document summarization which along with sentence ranking considers the novelty of the sentence there by reducing the redundancy in final summarization current summarization techniques try to make sure that all information in content is accurately represented in the summary such summarization gives us accurate representation of data however the summarization is nt human like daily life human summaries usually tend to be customized for reader by using bias in the tone of summarization we propose a nave model for biasing the tone of summary by using a set of words which have defined polarity tag to decide whether to include or discard the sentence in the summary the rest of the paper is organized as follows section ii gives an overview of current work done in the proposed area section iii discusses our approach and implementation of mmr multi document text summarization and nave tone biasing section iv briefly discusses the applications of tone biasing section v we discuss the results and observations obtained by implementing our approach section vi describes future scope of our work and conclusions ii literature survey the ability to get deeper insights without having to manually read through huge amount of data has fueled research in field of text summarization carbonell and goldstein proposed maximal marginal relevance and discussed the mmr based text summarization in detail long al discuss ways to apply learning models for optimizing diversity evaluation measure in training and proposes a novel modelling approach perceptron xie and liu compare the various knowledge based similarity measures that can be used with mmr in summarization of large corpus of meeting recording according to their experimental rogue scores radev al present a multi document summarizer mead which uses cluster centroids produced by topic detection and tracking to generate summaries goldstein et al propose a new approach based on domain independent techniques for document text summarization which has few operations based on single document text summarization yulita and pribadi implemented with simple modifications such as using tf idf df for ranking sentences yadav and chatterjee discuss the application of sentiment analysis for text summarization using various summary techniques and compared them gupta et al surveyed the existing text summarization methods which integrate well with ml and ai techniques for sentiment analysis for online product reviews we see that most works in mmr text summarization work on augmenting mmr with other algorithms to improve accuracy iii approach our approach starts by data preprocessing then using mmr to fetch relevant sentences and remove redundancy to improve novelty now we have a content accurate novel text summary of the document but the tone of the summary just reflects the tone of the content we bias the tone of the generated summary using proposed nave approach following subsections describe the above mentioned approach step by step preprocessing firstly we must clean our data set to be able to run our algorithms efficiently and remove any unwanted unnecessary data in this step we scan through all the documents to remove stop words and xml tags which are unnecessary while processing the sentences are classified into separate entities as our next steps will process text as sentences lastly we reduce the words of each sentence into its stem word using the porter stemming algorithm sentence ranking using tf idf values tf idf values give us the relevance of a sentence with respect to the query vector so that we can pick the top k relevant sentences the query vector is generated by finding most frequent words in the document that reflect the subject of document since our query vector is based on frequent words the tf idf sentence ranking returns the sentences that are most close to the general summary of the document by using cosine similarity equation for calculation of tf idf is given below log wi j is the weight of the word i in the sentence j tfi j term frequency is the term frequency of word i in sentence j is the equation of inverse document frequency idf n is the number of the total sentences dfi document frequency is the number of sentences which contain the word i we can also vary the tf idf method to use tf idf df as used in or use other similarity measures like pearson s coefficient but the main objective of our work is to explore tone biasing and evaluate a nave approach maximal marginal relevance the maximal marginal relevance mmr technique tries to reduce the redundancy while maintaining relevance to the query when reordering sentences we calculate the relevance of the query and sentences using cosine similarity then we calculate the similarity of sentences among themselves and remove the similar sentences to remove redundancy the below equation shows the mmr as explained in last subsection is rank of sentence in terms of best word query is the cosine similarity of current sentence among the list of top n sentences s that we get from is the tunable parameter which allows the user to tune the mmr equation value ranges between to where indicated maximum similarity and indicates maximal diversity mmr works iteratively to get the best possible redundant summary mmr process stops when becomes less than zero we start by varying from to and observe that we get best accuracy when is between and for given dataset we used dataset for performing the text summarization tone biasing as discussed in the introduction we propose a nave approach for biasing the tone of summary we use textblob library in python which provides functions to compute the polarity of sentences and tag them as positive negative and neutral polarity of the sentence is calculated by summing the polarity of words in the sentence textblob internally does stemming and lemmatization to provide accurate polarity information we use this method to analyze the polarity of the sentence retrieved after tf idf sentence ranking then if the sentence has negative polarity we discard the sentence finally only the sentences with either neutral or positive polarity are populated in the n list passed to mmr this results in mmr producing positive summaries due to the positive bias we can also flip the tone by simply discarding positive polarity sentences instead of negative polarity sentences polarity is context sensitive and is referred abstractly in the paper it needs to be explicitly defined by the users according to their use case users can learn the polarity of the words and define the tone according to the context by tweaking their classifiers used to assign polarity tags in textblob we ve developed this nave approach as we are exploring the tone biasing approach we can make this approach more sophisticated and robust by augmenting other text summarization techniques and polarity tagging techniques we discuss a few such approaches in future work section iv applications system generated summaries are generally consistent and content accurate while these are desirable properties in the quest to make summaries as human like as possible we need bias the summary according to our audience tone biasing has lot of applications where text summaries should be modified to convey the same message in different flavor we could think of many applications of tone biasing here we present two such examples censoring content in a graceful manner if a similar content should be displayed to different age groups it might be beneficial to change the tone of summary accordingly apart from just adding removing sentences based on polarity we can work on an natural language processing approach to use similar words with less negativity as replacement for existing words to improve the polarity of sentence towards required direction summarizing product service reviews we can summarize reviews positively or critically for different audiences positive summary could be provided to prospective buyers while critical summary could be provided to backend teams as feedback to improve service we can also extend this approach by having a multiclass summary instead of just negative or positive summary the multiple classes would depend on the context and subject of the documents we re trying to summarize result we implemented the mmr approach described by carbonell and goldstein and experimental results were observed to be lower than the original paper as the original paper uses normalized recall and score we evaluated our implementation using the dataset which contains news articles on various topics dataset also provides words words and words summary of topics prepared by humans as a benchmark to evaluate the accuracy of our approaches we use rogue score which is the combination of recall precision and f score to measure the accuracy of our approach also we ve implemented our nave tone biasing approach for biasing the text and compared it with polarity of non biased summary we present our observations below figure rouge score of mmr summary of length words figure rouge score of mmr summary of length words figure rouge score of mmr summary of length words figures show plot of the rouge scores for document cluster of documents of dataset we see that mmr multi document text summarization technique provides an average recall of average precision of and average f score of average rouge score for our implementation of mmr summarization would be this is lower when compared to the average rouge score of original paper which was this is as the original paper uses normalized recall and f score to provide better accuracy and use tf idf id instead of tf idf for sentence ranking in best case scenario our approach has the rogue score of this is similar to the original paper s rogue score we also observe that as the length of summary increases from words to words the recall value and score decrease while precision increases recall value is the total number of correct words that are present in summary versus total correct words as the length of summary increases the probability of fetching incorrect words increases and as the number of sentences we pick to calculate mmr remains same the recall value is impacted the same goes for score however precision is the total number of correct words in the summary versus total words in the summary this means that when summary length increases most correct words could be included in summary this leads to increase in precision value figure polarity of document clusters with and without tone biasing figure is the plot comparing the polarity of sentences in mmr with nave tone biasing approach indicated in blue color and human summary without any tone bias dataset denoted in red color mmr was implemented using and summary chosen for evaluation was word length summary provided in dataset we see that few documents have negative polarity in human summary and mmr with nave tone biasing successfully changes the polarity of all documents to positive polarity we can observe that few document clusters find have negative polarity higher than positive polarity this indicates that the document has high negative polarity and converting such document to positive polarity meant dropping lot of negative sentences which results in loss of information vi conclusion and future work we observed that mmr based multi document text summarization provides good accuracy and is superior to other approaches removing redundant information in summary nave tone biasing approach works well but might result in information loss when the tones we do nt need are too high in the document such loss of information can be mitigated by rephrasing sentences with required tone instead of discarding them this is part of a larger nlp problem and there is future scope for us to work this area nave tone biasing approach does binary biasing either positive bias or negative bias and meaning of positive and negative might vary with the subject as such instead of having a static lexicon of polarity scores of words we need develop a model to dynamically generate a lexicon with polarities according the subject such a model would give us better accuracy as the lexicon is customized to the subject topic in point also in some subjects topics it might be better to have multiclass biasing instead of having only two classes we need to develop a model to identify different classes of information and construct a polarity lexicon references jaime carbonell and jade goldstein the use of mmr diversity based reranking for reordering documents and producing summaries in proceedings of the annual international acm sigir conference on research and development in information retrieval sigir acm new york ny usa long xia jun xu yanyan lan jiafeng guo and xueqi cheng learning maximal marginal relevance model via directly optimizing diversity evaluation measures in proceedings of the international acm sigir conference on research and development in information retrieval sigir acm new york ny usa shasha xie and yang liu using corpus and knowledge based similarity measure in maximum marginal relevance for meeting summarization ieee international conference on acoustics speech and signal processing las vegas nv pp dragomir radev hongyan jing and malgorzata budzikowska centroid based summarization of multiple documents sentence extraction based evaluation and user studies in proceedings of the naacl anlp workshop on automatic summarization naacl anlp autosum association for computational linguistics stroudsburg pa usa jade goldstein vibhu mittal jaime carbonell and mark kantrowitz multi document summarization by sentence extraction in proceedings of the naacl anlpworkshop on automatic summarization volume naacl anlp autosum vol association for computational linguistics stroudsburg pa usa yulita and pribadi the implementation of maximum marginal relevance method on online national and local news portal proceeding of international conference on green technology semarang indonesia yadav and chatterjee text summarization using sentiment analysis for duc data international conference on information technology icit bhubaneswar pp gupta tiwari and robert sentiment analysis and text summarization of online reviews a survey international conference on communication and signal processing iccsp melmaruvathur pp
