deep network model paraphrase detection short text messages basant agarwala heri ramampiaroa helge langsetha massimiliano ruoccoa adept computer science norwegian university science technology norway bswami keshvanand institute technology india ctelenor research trondheim norway abstract paper concerned paraphrase detection ability detect similar sentences written natural language crucial applications text mining text summarization plagiarism detection authorship authentication question answering given sentences objective detect semantically identical important insight work existing paraphrase systems perform applied clean texts necessarily deliver good performance noisy texts challenges paraphrase detection user generated short texts twitter include language irregularity noise cope challenges propose novel deep neural network based approach relies coarse grained sentence modeling convolutional neural network long short term memory model combined specic grained word level similarity matching model experimental results proposed approach outperforms existing state art approaches user generated noisy social media data twitter texts achieves highly competitive performance cleaner corpus keywords paraphrase detection sentence similarity deep learning lstm cnn introduction twitter time popular means expressing opinions variety subjects paraphrase detection user generated noisy texts twitter important task natural language processing nlp information retrieval text mining tasks including query ranking plagiarism detection question answering document summarization recently paraphrase detection task gained signicant interest applied nlp need deal pervasive problem linguistic variation paraphrase detection nlp classication problem given pair sentences system determines semantic similarity sentences sentences convey meaning labelled paraphrase non paraphrase existing paraphrase systems performed clean text corpora microsoft paraphrase corpus msrp detecting paraphrases user generated noisy tweets challenging issues like misspelling acronyms style structure little attention given paraphrase detection noisy short texts initial work reported benchmark semeval twitter dataset unfortunately best performing approaches dataset perform poorly evaluated discuss later paper state art approach semeval dataset proposed dey gives poor score evaluated msrp dataset similarly eisenstein corresponding author email addresses basant basant agarwal heri ramampiaro helge langseth massimiliano massimiliano ruocco referred tweets preprint submitted information processing management december best performing approach msrp dataset perform semeval dataset conclusion existing approaches generic instead highly dependant data training focusing problem discussed main goal work develop robust paraphrase detection model based deep learning techniques able successfully detect paraphrasing noisy clean texts specically propose hybrid deep neural architecture composed lutional neural network cnn long short term memory lstm model enhanced novel word pair similarity module proposed paraphrase detection model composed main nents pair wise word similarity matching sentence modelling pair wise similarity matching model extract grained similarity information pairs sentences use cnn learn patterns semantic correspondence pair words sentences intuitively useful paraphrase identication idea apply convolutions pair wise word word similarity matrix extract important word word similarity pairs motivated tions text extract important parts sentence sentence modelling architecture extract local region information form important grams text cnn long term dependency information lstm architecture able develop informative semantic representation sentence paper proposed model enhanced employing extra set statistical features extracted input text demonstrate robustness evaluated proposed approach compare state art models dierent datasets covering noisy user generated texts semeval twitter benchmark dataset clean texts microsoft paraphrase corpus msrp summary main contributions paper propose novel deep neural network architecture leveraging coarse grained sentence level features grained word level features detecting paraphrases noisy short text twitter model combines sentence level word level semantic similarity information capture semantic information level text grammatically irregular short level similarity model provide useful information semantic representation sentence provide useful information way model components compliment provide ecient overall performance proposed pair wise similarity model extract word level semantic mation demonstrate usefulness paraphrase detection task propose method combining statistical textual features features learned deep tecture present extensive comparative study paraphrase detection problem rest paper organized follows formally dene problem section discuss related word concerning paraphrase detection section section motivate work present proposed solution detail describe experimental setup section evaluate approach discuss results section finally section conclude paper outline plans future research problem statement let sentences said paraphrased convey meaning semantically equivalent assume collection annotated sentence pairs having annotations given indicates sentence pair paraphrased non paraphrased problem addressed paper develop model reliably annotate previously unseen sentence pair paraphrased non paraphrased methods proposed work clean texts failed provide satisfactory results applied noisy texts like tweets hand approaches recently developed paraphrase detection noisy texts work dey shown later approaches work clean texts conclusion strong need robust reliable method perform clean texts user generated noisy short texts addressing need main objective work presented paper related work use deep neural network natural language processing increased considerably recent years previous work sentence modelling focused feature like gram overlap features syntax features machine translation based features recently deep learning based methods shifted researchers attention semantically distributed representations variety deep neural network based architectures proposed sentence similarity strategy focus paper substantial work carried paraphrase detection clean text microsoft paraphrase corpus das smith present probabilistic model paraphrase detection based syntactic larity semantics hidden loose alignment syntactic trees given sentences heilman smith propose tree edit model paraphrase identication based syntactic relations words develop logistic regression model uses syntactic features edit sequences classify sentence pair socher present approach based recursive autoencoders paraphrase detection approach learns feature vectors phrases syntactic trees employs dynamic ing layer mechanism converts variable sized matrix xed sized representation parsing powerful tool identifying important syntactic structure text relying parsing makes approach exible approach use resources develop model oliva propose symss based syntactic structure sentences represent sentences syntactic dependence tree use wordnet extract meaning individual words use syntactic connections assess information similarity eisenstein use hand crafted features latent representation matrix factorization features train support vector machine arc model proposed convolutional siamese architecture weight convolutional sentence models trained alfy propose model considering set weak textual similarity metrics boost performance individual metrics abductive learning aim select optimal subset similarity measures construct composite score classication wang decompose sentence similarity matrix similar component matrix dissimilar component matrix train channel convolutional neural network compose components feature vectors ferreira propose supervised machine learning learning approach extract features based lexical syntactic semantic similarity measures use machine learning algorithms bayesian network rbf network decision tree support vector machines contributions reported detecting paraphrases noisy short text like tweets propose latent variable model jointly infer correspondence words sentences eyecioglu keller use support vector machine simple lexical word overlap character grams features paraphrase detection zhao lan use machine learning classiers employ variety features like string based corpus based syntactic features word distributional representations zarrella present ensemble approach based features mixtures string matching metrics distance measurements tweet specic distributed word representations recurrent neural networks modeling similarity karan present supervised approach combines semantic overlap word alignment features experiment sets features dierent classiers combination word gram word alignment meteor metric evaluation translation explicit ordering bleu bilingual evaluation understudy editdistance best feature set twitter paraphrase detection votedperceptron proved best machine learning algorithm dey use set lexical syntactic semantic pragmatic features paper focus deep learning algorithms develop robust reliable paraphrase detection system work clean text noisy short text tweets best knowledge rst work fully explore area including comprehensive comparative study exiting approaches table summarizes approaches discussed section table comparison related approaches work description resources classication dataset asobek word overlap character grams features pos tagger support vector chine svm twitter msrp mitre mixtures string matching metrics regularized logistic regression ecnu string based corpus based syntactic distributed word representation based features features machine translation edit distance sentiment features semantic overlap features word alignment features multi instance learning paraphrase model multip set lexical syntactic semantic pragmatic features combination word similarity measures weighted textual matrix factorization wtmf handling missing words probabilistic model syntactic gram overlap features pos tagger wordnet pre trained word embeddings svm random est gradient boosting pos tagger stump decision oner baysian logistic regression votedperceptron mlp pos tagger svm pos tagger similarity score wordnet pos tagger tags svm twitter dataset twitter dataset twitter dataset twitter dataset twitter dataset twitter msrp pos tagger wordnet similarity threshold matrix tion score msrp msrp wordnet dependency parser logistic regression svm msrp syntactic features edit sequences pos tagger parser wordnet logistic regression msrp similarity features based syntactic dependency tree wordnet dependency parser similarity threshold score msrp dependency parser representation feature vectors phrases syntactic trees matrix factorization supervised reweighting recursive coder dynamic pooling msrp svm linear kernel msrp continue page table comparison related works cont work description resources classication dataset pre trained word embeddings convolutional ral network msrp hierarchical structures sentences layer layer composition combination machine translation metrics wordnet boosting textual similarity metrics sentence similarity learning lexical decomposition composition represent pair sentence combination similarity measures pre trained word embeddings dependency parser work hybrid deep learning statistical features pos tagger pre trained word embeddings svm svm cnn svm rbf work bayesian network multi layer neural network msrp msrp msrp msrp msrp twitter dataset deepparaphrase architecture propose deep learning based approach detecting paraphrase sentences tweets rst convert sentence pair semantic representative vector cnn lstm semantic pair level vector computed taking element wise dierence vector sentence representations resulting dierence discriminating representative vector pair sentences feature vector learning similarity sentences addition coarse level semantic information extract grained important information similarity matrix contains word word similarity quantication convolutions applied pair wise similarity matrix learn similarity patterns words pair sentences aim convolution function extract grained similarity features finally set features extracted statistical analysis text concatenated rest learned features fully connected neural network produce classication concatenated feature vector rst layers activated relu function use sigmoid function transfer latent representation class decision rule train model optimize binary cross entropy proposed architecture depicted figure high level abstraction proposed model consists main components discussed sentence modelling cnn lstm component represent sentence joint cnn lstm architecture cnn able learn local features words phrases text lstm learns term dependencies text specically rstly word embedding input cnn model types convolutions pooling techniques applied capture maximum information text encoded features input lstm network finally long term dependencies learned lstm semantic sentence representation architecture proposed model mapping sentences feature vector shown figure main goal step learn good intermediate semantic representations sentences semantic similarity task input sentence model pair sentences transform matrices words embeddings word represented figure proposed deepparaphrase architecture vector size word embedding pre trained word embeddings section details sentence embedding matrices fed cnn result captures local region information input lstm aim convolutional layer extract patterns important word sequences input sentences motivation convolutions comes fact convolutional lters learn gram discriminating features useful sentence similarity analysis features generated convolutional layer form grams fed lstm model component able process sequential input aim learn long term dependencies sentences eventually latent layer lstm taken semantic representation sentence dierence element wise dierence representations semantic discrepancy measure level sentence pair pair wise word similarity matching pair wise similarity matrix construed computing similarity word word convolutions applied similarity matrix analyze patterns pair wise word word similarities figure illustrates process intuitive given sentences semantic correspondence words provide important mantic information detecting similar sentences pair wise word similarity matching model learns word level similarity patterns sentences important grams extracted applying convolutional neural network text obtain important word word similarity pairs similarity matrix similarity matrix features classication paraphrase detection problem goal pair wise word similarity matching model compare semantic embedding word sentence semantic embeddings words sentences means compute dot product similarity measure word embeddings sentences finally match sentences generate similarity matrix size denote lengths sentence respectively apply cnn similarity matrix learn patterns semantic correspondence sentences convolve directions left right gives lstmclassifierclassificationoutputdensedensecnncnnlstmconvolution max poolingmax poolingconvolution substructionfeature vectoradditional featuresconcatenationembeddingsembeddingssentnce matrixsentence matrix separate results convolution layer global max pooling applied obtain informative feature vectors nally concatenated produce output module figure pair wise word similarity matching model statistical features features consist following extracted set features enhance discriminating representation sentences idf similarity sentences cosine similarity vectors sentences average wordnet based similarity sentence average wordnet based similarity sentence average wordnet based similarity sentence cosine similarity semantic representation sentence pair gram overlap features computed number unigrams bigrams trigrams common given sentence pair divided total grams respectively use additional features experiments performed microsoft paraphrase corpus features experiments twitter evaluating proposed method paraphrase identication compare art approaches rst describe experiments set including datasets performance measures hyperparameter settings experimental setup datasets consider widely benchmark datasets briey describe following twitter paraphrase semeval dataset dataset provided semeval recent works paraphrase detection tweets consists noisy short text containing paraphrase non paraphrase pairs training dataset paraphrase non paraphrase sentence pairs development set tweets test set ignored debatable entries marked statistics dataset shown table implementation use nltk speech tagger extracts verbs nouns adjectives sentence sentence filtersn filtersconvolutionsmax poolingmax poolingsimilarity featurevector poolingsimilarity matrix table statistics twitter paraphrase corpus unique sent sent pair paraphrase non paraphrase debatable train dev test microsoft paraphrase dataset investigate empirical performance proposed model clean text corpus specically use microsoft paraphrase dataset considered evaluation standard paraphrase detection algorithms dataset comprises candidate paraphrase sentence pairs obtained web news sources corpus length sentence varied words average words sentence sentence pairs marked paraphrased furthermore data split training test sets containing samples respectively train test partitioning applied approaches evaluated paper despite widely datasets evaluating paraphrase detection models sizes small reliably train deep learning architecture applied simple augmentation scheme double number sentence pairs corpus pair sentences simply exchange order sentences obtain new pair add new pair corpus performance measures adopted standard performance measure widely literature paraphrase detection measures precision recall score accuracy precision dened number correctly classied paraphrase pairs total paraphrase sentence pairs extracted computed refers true positives number paraphrase pairs classied paraphrase refers false positives number non paraphrase pairs determined paraphrase recall ratio predicted sentence pairs actual paraphrases total true paraphrase pairs false negatives number paraphrase pairs classied non paraphrase pairs means true negatives number non paraphrases determined non paraphrases score combines precision recall finally accuracy fraction paraphrase sentence pairs classied correctly precision recall score precision recall precision recall accuracy hyperparameter setting hyperparameters chose rough investigations training data choose optimization rithm learning rates regularization size training dataset optimal settings rameters vary datasets choose separately twitter msrp datasets performance optimization algorithms performance learning rate performance dropout rate learning curve figure evaluation dierent hyperparameters semeval twitter dataset hyperparameter settings twitter dataset empirically experiment optimizers figure chose adadelta optimize learning process tune learning rate optimizer figure learning rate appearing optimal dropout regularization proposed model prevents feature adaptation randomly setting portion hidden units zero training applied dropout layer set dropout ratio figure finally investigate sensitivity approach wrt training data supplied figure shows learning curve learning quality function training data clearly increasing trend learning curve indicates training data improve performance proposed model absence large supervised training set common initialize word embeddings pretraining values obtained unsupervised neural language model follow strategy popular glove experiments twitter dataset chose embeddings pretrained billion tweets use dimensional version hyperparameter settings msrp dataset parameter selection process msrp dataset similar discussed twitter data figure results dataset chose adadelta optimizer learning rate set embeddings available stanford edu projects performance optimization algorithms performance learning rate performance dropout rate learning curve figure evaluation dierent hyperparameters msrp dataset dropout rate chosen examining eect size training data increasing trend respect accuracy somewhat pronounced respect score increase training dataset provide slight improvements nal performance model dataset dimensional version publicly google vectors initialize word embeddings vectors trained billion words google news continuous bag words architecture results discussion section present results datasets presented section results discussion twitter corpus train model training dataset development set tuning parameters test system provided testing dataset test entries ignoring debatable entries results provided table recall mainly components proposed approach sentence modelling cnn lstm pair wise word similarity matching intuition models google com archive coarse grained sentence level grained word level information important paraphrase detection task experiments rstly use sentence modelling architecture develop paraphrase detection model experiment sentmod architecture paraphrase detection seen results table sentmod architecture performs giving score use pair wise word similarity matching model extract word level similarity information based features use features train paraphrase model model provides score features pair wise features augment word level pair wise features sentence level features extracted sentmod architecture feed train proposed deep learning model paraphrase detection task architecture model deepparaphrase architecture experimental results signicant improvement performance paraphrase detection task specically gives score improvement percentage points shows pair wise word similarity information fusion sentence level similarity information provides good performance paraphrase detection task finally augment additional features overlap features similarity features items description section gives additional improvement performance model resulting score signicantly better existing methods paraphrase detection twitter dataset refer nal model augdeepparaphrase model table results semeval twitter dataset model sentmod architecture pair wise features deepparaphrase architecture augdeepparaphrase precision recall score comparison proposed method existing state art methods provided table firstly compare results proposed approach best methods clean text microsoft paraphrase dataset state art methods noisy twitter dataset guo diab proposed weighted textual matrix factorization method paraphrase detection based modeling semantic space words present absent sentences model uses wordnet ontonotes wiktionary brown corpus approach performed msrp dataset provide worse results twitter dataset das smith logistic regression based classier based simple gram features overlapping features shows competitive results msrp dataset eisenstein presented state art model paraphrase detection msrp dataset best known performance clean text seen results presented table method performed worse methods twitter data considering semeval twitter dataset table shows comparison approach state art methods observed results comparison approach outperforms related methods respect score main reason approach leverages semantic information coarse grained sentence level features grained word level features detecting paraphrases tweets ensemble based method proposed zarrella obtained higher recall compared results model gave higher overall score method suggested zhao lan got slightly higher precision compared proposed approach approach superior wrt score conclusion state art algorithms perform trained clean texts necessarily work noisy short texts vice versa contrast approach robust sense performs types datasets specically outperformed existing methods applied noisy texts produced competitive results state art table comparison state art results semeval twitter dataset model random guo diab das smith eisenstein eyecioglu keller zarrella zhao lan karan dey augdeepparaphrase precision recall score methods clean texts analyze misclassications test data proposed approach example tweets pairs including correct incorrect detection model reported table examples test data cases method correctly classify example proposed approach correctly identify tweet pair terrible things happening turkey children dying turkey paraphrase understand semantic meaning despite fact pair common word similarly proposed approach determine correct label paraphrase sentence pairs row table sentence pairs words common examples dicult provide correct classications sider example tweet pair table approach determines pair non paraphrase incorrect according gold standard annotation tweets share words common sense knowledge required understand person won lots trophies prizes respected hated similar example tweet pair gold standard annotation pair paraphrase correctly classify pair system needs know person genius obvious able write finally consider pair family guy reality family guy funny approach identies pair paraphrase wrong according gold standard annotation possible reason error misleading lexical overlap information sentences pair overshadowed dierent words summarize looking misclassied examples table cases cause system fail correctly classify pairs tweets includes cases common sense knowledge required learned examples proposed approach able capture semantic information short noisy texts turn help correctly classifying pairs dicult looking syntactic contents results discussions msrp dataset results experiments microsoft paraphrase dataset summarized table firstly extract coarse grained sentence level features sentmod architecture feed train paraphrase detection model observed table architecture gives accuracy score evaluate pair wise features train paraphrase detection model features individually provide score fuse pair wise features sentence level features extracted sentmod architecture train paraphrase detection model table examples tweet pairs twitter paraphrase corpus tweet tweet prediction remark gold annotation terrible things happening turkey children dying turkey trying earth soon son went earth night paraphrase paraphrase correct paraphrase paraphrase correct hahaha sounds like sounds totally reasonable paraphrase paraphrase correct understand hatred rafa benitez trophy respect benitez shonda freaking genius dang shonda knows write terrible things happening turkey stop violence turkey confess love star wars somebody watch star wars paraphrase incorrect paraphrase paraphrase incorrect paraphrase incorrect paraphrase paraphrase paraphrase paraphrase incorrect family guy reality family guy funny paraphrase paraphrase incorrect everybody watching family guy tonight watched family guy forever paraphrase paraphrase incorrect deepparaphrase architecture provides signicant improvement performance deep learning model obtain accuracy score nal paraphrase model augdeepparaphrase model built including additional features described section improvement score overall experimental results sentence level semantic information word level similarity information important paraphrase detection task table results msrp dataset model sentmod architecture pair wise features deepparaphrase architecture augdeepparaphrase accuracy twitter dataset compared approach related methods present results experiments table report measured accuracy scores experimental results proposed approach outperforms related methods recent method wang discussed section employ neural network based approach large number options introduced nal model semantic matching functions max global local decomposition operations rigid linear orthogonal lter types unigrams bigrams trigrams makes applicable implement scale datasets similar problems contrast developed approach robust generic easily applied datasets table experimental results paraphrase detection msrp accuracy model positive baseline socher eisenstein inductive setup arc madnani eyecioglu keller alfy wang dey ferreira augdeepparaphrase model authors reported best results accuracy score dataset achieve results relied testing data training dataset build model called form transductive learning assumed access test set contrast approach test data kept totally disjoint training process experimental setup applying inductive setup test data training model approach eisenstein gives accuracy score close results approach focusing performance approach relation existing methods experimental results approach produces competitive results achieving accuracy score importantly achieved extra annotated resources special training strategy compared current state art methods table shows examples sentence pairs approach classied correctly incorrectly sentence pair correctly classied paraphrase sentences words common sentence pair correctly classied non paraphrase sentences words common words share context conversely sentence pair incorrectly predicted paraphrase pair dicult classify correctly humans sentence pair incorrectly classied non paraphrase main reason misclassication presence possibly rare words incredulous jeopardize endanger sentence pair hard classify summary proposed approach able capture semantic information clean texts analyzing tweets turn help correctly classifying pairs dicult looking syntactic contents cases hard classify lack complete vocabulary common sense knowledge conclusions paper introduced robust generic paraphrase detection model based deep neural network model performs user generated noisy short texts tweets quality clean texts proposed pair wise word similarity model capture grained semantic table example sentence pairs msrp paraphrase corpus sentence sentence prediction remark gold annotation paraphrase paraphrase correct ricky clemons brief troubled missouri basketball career missouri kicked ricky clemons team ending troubled career people killed hundreds injured runners injured bulls killed talking positive numbers negative tech heavy nasdaq composite index shot percent week respected medical journal lancet called complete ban tobacco united kingdom mrs clinton said incredulous endanger marriage family talking high standards low standards nasdaq composite index advanced percent gaining percent week leading medical journal called friday complete ban tobacco prompting outrage smokers groups believed jeopardize marriage family paraphrase paraphrase correct paraphrase paraphrase correct paraphrase paraphrase incorrect paraphrase paraphrase incorrect paraphrase incorrect paraphrase corresponding information pair words given sentences addition hybrid deep neural network extracts coarse grained information developing best semantic representation given sentences based cnn lstm model developed consisted sentence modelling pair wise word similarity matching model discussed paper model proved useful paraphrase detection evaluation included comprehensive comparison state art approaches showed approach produced better results existing approaches terms score applied noisy short text twitter paraphrase corpus provided competitive results applied clean texts microsoft paraphrase corpus overall experimental results shown robustness eectiveness proposed method paraphrase detection future work plan investigate method works related tasks question answering sentence matching information retrieval study include close common sense knowledge model training references dolan quirk brockett unsupervised construction large paraphrase corpora exploiting massively allel news sources proceedings international conference computational linguistics coling association computational linguistics stroudsburg usa article ritter callison burch dolan extracting lexically divergent paraphrases twitter actions association computational linguistics callison burch dolan task paraphrase semantic similarity twitter pit proceedings international workshop semantic evaluation hlt denver colorado usa june dey shrivastava kaushik paraphrase semantic similarity detection system user generated text content microblogs coling eisenstein discriminative improvements distributional sentence similarity proceedings conference empirical methods natural language processing emnlp october grand hyatt seattle seattle washington usa meeting sigdat special interest group acl madnani tetreault chodorow examining machine translation metrics paraphrase identication proceedings conference north american chapter association computational linguistics human language technologies naacl hlt association computational linguistics stroudsburg usa isbn rus mccarthy lintean mcnamara graesser paraphrase identication lexico syntactic graph sumption proceedings international florida articial intelligence research society conference das smith paraphrase identication probabilistic quasi synchronous recognition proceedings joint conference annual meeting acl international joint conference natural language processing afnlp volume acl association computational linguistics stroudsburg usa isbn heilman smith tree edit models recognizing textual entailments paraphrases answers questions human language technologies annual conference north american chapter association computational linguistics hlt association computational linguistics stroudsburg usa isbn socher huang pennington manning dynamic pooling unfolding recursive autoencoders paraphrase detection proceedings international conference neural information processing systems curran associates inc usa isbn oliva serrano del castillo iglesias symss syntax based measure short text semantic similarity data knowledge engineering issn chen convolutional neural network architectures matching natural language sentences ghahramani welling cortes lawrence weinberger eds advances neural information processing systems mit press cambridge alfy abdel aal khatib alvi boosting paraphrase detection textual similarity metrics abductive networks appl soft comput issn wang ittycheriah sentence similarity learning lexical decomposition composition proceedings international conference computational linguistics coling technical papers ferreira cavalcanti freitas lins simske riss combining sentence similarities measures identify paraphrases computer speech language issn eyecioglu keller twitter paraphrase identication simple overlap features svms proceedings international workshop semantic evaluation hlt denver colorado usa june zhao lan ecnu leveraging word embeddings boost performance paraphrase twitter proceedings international workshop semantic evaluation hlt denver colorado usa june zarrella henderson merkhofer strickhart mitre seven systems semantic similarity tweets proceedings international workshop semantic evaluation hlt denver colorado usa june karan glavas snajder basic vulic moens tklbliir detecting twitter paraphrases tweetingjay proceedings international workshop semantic evaluation hlt denver colorado usa june magnolini popescu paraphrase identication semantic similarity twitter simple tures proceedings socialnlp hlt denver colorado june association computational linguistics mihalcea corley strapparava corpus based knowledge based measures text semantic similarity proceedings national conference articial intelligence volume aaai press guo diab modeling sentences latent space proceedings annual meeting association computational linguistics long papers volume acl association computational linguistics stroudsburg usa nair hinton rectied linear units improve restricted boltzmann machines proceedings international conference machine learning omnipress collobert weston bottou karlen kavukcuoglu kuksa natural language processing scratch mach learn res mikolov sutskever chen corrado dean distributed representations words phrases compositionality advances neural information processing systems
