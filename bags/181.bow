n a j v c s c v v i x r a demystifying multi faceted video summarization tradeoff between diversity representation coverage and importance vishal kaushal iit bombay ittb ac in rishabh iyer microsoft corporation com khoshrav doctor university of massachusetts amherst umass edu anurag sahoo aitoelabs com pratik dubal aitoelabs com suraj kothawade iit bombay iitb ac in rohan mahadev aitoelabs com kunal dargan aitoelabs com ganesh ramakrishnan iit bombay ittb ac in abstract this paper addresses automatic summarization of videos in a unied manner in particular we propose a framework for multi faceted summarization for extractive query base and entity summarization summarization at the level of tities like objects scenes humans and faces in the video we investigate several summarization models which ture notions of diversity coverage representation and portance and argue the utility of these different models pending on the application while most of the prior work on submodular summarization approaches has focused on combining several models and learning weighted mixtures we focus on the explainability of different models and turizations and how they apply to different domains we also provide implementation details on summarization tems and the different modalities involved we hope that the study from this paper will give insights into practitioners to appropriately choose the right summarization models for the problems at hand introduction visual data in the form of images videos and live streams have been growing at an unprecedented rate in the last few years while this massive data is a blessing to data science by helping improve predictive accuracy it is also a curse since humans are unable to consume this large amount of data moreover today machine generated videos via drones dash cams body cams security cameras go pro are being generated at a rate higher than what we as humans can process moreover majority of this data is plagued with redundancy given this data explosion chine learning techniques which automatically understand organize and categorize this data are of utmost importance video summarization attempts to provide a highlight of the most critical and important events in the video giving the viewer a quick glimpse of the entire video so they can cide which parts of the video is important what comprises of the most critical aspect of a video pends largely on the domain what is important in a lance video is very different from the highlights of a soccer game this work attempts to provide a better ing of different summarization models in different domains we try to make a case that the choice of the tion model really depends on the application and domain at hand this paper investigates several choices of rization models models which capture diversity tation importance or relevance and coverage we tively and qualitatively study this pattern in many different domains including surveillance footages dashcam cams and gopro footages movies and tv shows and sports events like soccer we argue how different characteristics are important for these domains and through extensive perimentation establish the benet of using the ing summarization models for example we show that for surveillance footages diversity is more important compared to representation or coverage while in a movie tion and coverage form a better t compared to diversity similarly in a sports event like soccer importance and vance signals are important aspects of summarization this paper also analyzes several choices of feature tions and concepts including faces scenes humans color information objects we study three variants of summarization one is tive summarization the second is query focused rization and the third is entity based summarization which we also call concept based summarization entity based summarization focuses on entities like objects scenes mans faces to provide a representative yet diverse subset of these entities this answers questions like who are the different people or what are the diverse objects and scenes in the video finally we discuss several implementational details on how to create a video summarization system cluding the preprocessing of features different tions of shots and tricks for speeding up the optimization for near real time response times existing work several papers in the past have investigated the problems of video and image collection summarization video marization techniques differ in the way they generate the output summary some of these extract a set of keyframes from the video while others focus on ing video summaries or skims from the long video other forms of video summarization include creating gif summaries from videos montages visual boards from videos video synopses and time lapses and hyperlapse summaries similarly image collection summarization involves choosing a subset of representative images from the collection another line of approach which is similar to what we call entity based tion was proposed in wherein the authors select resentative summaries of all objects in a video they do this by modeling the problem as that of sparse dictionary tion most video summarization techniques can be rized into methods trying to model one of three properties of summaries i interestingness how good is a given snippet as a summary representativeness how well the mary represents the entire video or image collection and iii diversity how non redundant and diverse is the mary examples of methods which model interestingness of snippets include that nd summary snippets through motion analysis and optical ow which uses humans and objects to determine interesting snippets and nally which models interestingness through a super frame mentation summarizes multiple videos collectively by looking at inter video frame similarity and posing a imal bi clique nding algorithm for nding summaries methods which only model the quality of the snippets or equivalently the interestingness of the summaries and do not model the diversity often achieve redundant frames and snippets within their summary hence a lot of recent work has focused on diversity els for video and image collection summarization used the facility location function with a diversity penalty for image collection summarization while dened a coverage function and a disparity function as a diversity model attempted to nd the candidate chain of sub shots that has the maximum score composed of measures of story progress between sub shots importance of vidual sub shots and diversity among sub shot transitions was among the rst to use a mixture of submodular functions learnt via human image summaries for this lem for video summarization proposed the imum marginal relevance mmr as a diversity model while used a determinantal point process based approach for selecting diverse summaries proposed an approach for video summarization based on dictionary based sparse coding and proposed using mixtures of submodular functions and supervised learning of these tures via max margin training an approach used for several other tasks including document summarization and age collection summarization our contributions the goal of this work is not to achieve the best results on video and image summarization tasks and datasets like tvsum and summe rather we attempt to vide insights into what it takes to build a real world video summarization system in particular we try to understand the role of different submodular functions in different mains and how to implement a video summarization tem in practice as observed in prior work several models for diversity representation coverage and uniformity can be unied within the class of submodular optimization we build upon this work as follows this paper studies the role and characteristics of ferent summarization models what constitutes a good summary depends on the particular domain at hand we investigate several diversity coverage and sentation models and demonstrate how different els are applicable in different kinds of video rization tasks we validate our claims by empirically showing the havior of these functions on different kinds of videos and quantitatively prove this on several videos in each domain for example we show that diversity models focus on getting outliers in the video which is tant in domains like surveillance on the other hand representation models capture the centroids and portant scenes which is useful in movies we also how coverage functions focus on achieving a good coverage of concepts similarly we show that in mains like soccer importance or relevance plays the most important role in the summary we also discuss the computational scalability of the optimization algorithms and point out some tional tricks including lazy evaluations and tion which enable optimized implementations for ious submodular functions as a result we show that once the important visual features have been extracted via a pre processing step we can obtain the summary subset of the video or frames in a few seconds this allows the user to interactively obtain summaries of various lengths types and queries in real time we pirically demonstrate the benet of memoization and lazy greedy implementations for various video marization problems most past work on video and image collection rization either use a subset of hand tuned submodular tions or a learnt mixture of submodular tions this work addresses the orthagonal aspect how do different subclasses of submodular functions model summarization and their performance in different video mains we believe the insights gathered from this work will help practitioners in choosing appropriate models for several real world video and image summarization tasks background and main ideas this section describes the building blocks of our work namely the submodular summarization framework and the basics of convolutional neural networks for age recognitions to extract all the objects scenes faces humans submodular summarization framework we assume we are given a set v n of items which we also call the ground set also dene a utility function r which measures how good of a summary a set x v is let c r be a cost function which describes the cost of the set for example the size of the subset the goal is then to have a summary set x which maximizes while simultaneously minimizes the cost function c in this paper we study a special class of set functions called submodular functions given two subsets x y v a set function is submodular if x x y j for y this is also called the diminishing returns property several diversity and coverage functions are submodular since they satisfy this diminishing returns property we also call a function monotone submodular if x y if x y v the ground set v and the items n depend on the choice of the task at hand we now dene a few relevant optimization problems which shall come up in our problem formulations problem max x xv problem is knapsack constrained submodular tion the goal here is to nd a summary with a xed cost and sn denotes the cost of each element in the ground set a special case is cardinality constrained submodular maximization when the individual costs are this a natural model for extracting xed length mary videos or a xed number of keyframes problem min this problem is called the submodular cover problem is the modular cost function and c is the age constraint the goal here is to nd a minimum cost set x such that the submodular coverage or representation function covers information from the ground set a special case of this is the set cover problem moreover problem can be seen as a dual version of problem submodular functions have been used for several marization tasks including image summarization video summarization document summarization training data summarization and active learning using a greedy algorithm to optimize a submodular tion for selecting a subset gives a lower bound mance guarantee of around of optimal and in tice these greedy solutions are often within of optimal this makes it advantageous to formulate or mate the objective function for data selection as a ular function cnns for image feature extraction convolutional neural networks are critical to feature traction in our summarization framework we pre process the video to extract key visual features including objects scenes faces humans convolutional neural networks have recently provided state of the art results for several recognition tasks including object recognition scene recognition face recognition and object detection and localization we next describe the end to end system in detail method the input to our system is a video our system then tracts all important features from the video and generates an analysis database the user can then interact with the system in several ways user can generate a video mary of a given length or extract a set of key frames or a montage describing the video similarly the user can search for a query and extract video snippets of frames which are relevant to the query finally the user can also view a mary of all objects scenes humans and faces in the video along with their statistics all these interactions are enabled on the y in a few seconds the user can also dene the summarization model of their choice we investigate and compare different submodular models and argue the utility of different models based on the use case problem formulation for the multi faceted sual summarization we now formulate problem statements across the ent summarization views extractive summarization siders the entire video we can generate a summary either in terms of key frames represent the video as a set of frames sampled at a frame rate or video snippets in either case we extract a ground set v with each individual element ther being a key frame or a video snippet we then solve problems or depending on the use case problem is the right formulation if we are interested in obtaining a summary of a xed budget problem is useful if we do nt care about the size of the video but we are interested in the summary capturing all the information of the video in the case of query based summarization we rst extract the set of frames or snippets relevant to that query q denote this by vq we then solve the submodular optimization problem on vq finally in the case of entity based summarization we extract all the entities in the video and denote the set of entities as ve ve represents for example all the faces of people in the video we can then run our summarization with ve as the groundset in the case of extractive or query based summarization the ground truth elements can be either frames of video snippets our video snippets can be either xed length pets or shots obtained from a shot detector if the pets are xed length snippets say or seconds we can use the cardinality constrained submodular maximization if the snippets are shots from the video the length of each shot can differ and we have the more general knapsack strained setting while our system can handle each of these modes we focus on the key frame based method for our experiments since we are interested in proving the utility of different summarization models the insights will carry over to the other modes as well submodular functions as summarization models this section describes the submodular functions used in our system we divide these into coverage functions representation functions and diversity functions modeling coverage this class of functions model notions of coverage i e try to nd a subset of the ground set x which covers a set of concepts below are instantiations of this set cover function denote v as the ground set and let x v be a subset of snippets or frames further u notes a set of concepts which could represent for example scenes or objects each frame or snippet i x contains a subset ui u set of concepts for example an image ers a table chair and person the set cover function then is x ui where wu denotes the weight of concept u probabilistic set cover this is a generalization of the set cover function to include probabilities piui for each object ui in image i x for example our convolutional neural network might output a condence of object ui in image i and we can use that in our function the probabilistic coverage function is dened as x pij iu ix the set cover function is a special case of this if pij if object j belongs to image i i e we use the hard labels instead of probabilities feature based functions finally we investigate the class of feature based functions here we denote an image i via a feature representation qi this could be for example the features extracted from the second last layer of a convnet denote f as the set of features the feature based function is dened as x if where jx qij and qij is the value of feature i in image j is a concave function examples of are square root log and inverse function modeling representation representation based functions attempt to directly model representation in that they try to nd a representative subset of items akin to centroids and mediods in clustering facility location function the facility location tion is closely related to k mediod clustering denote sij as the similarity between images i and j we can then dene x iv maxjx sij for each image i we compute the representative from x which is closest to i and add the similarities for all images note that this function requires computing a similarity function however as shown in we can approximate this with a nearest neighbor graph which will require much smaller space requirement and also can run much faster for large ground set sizes saturated coverage function saturated coverage function this function is similar to facility location and attempts to model representation this is also a kernel based function and requires computing the similarity matrix graph cut functions we dene the graph cut family of functions as f x i jx sij this function is similar to the facility location and rated coverage in terms of its modeling behaviour jx sij ix sij is dened as iv sij x the iv modeling diversity the third class of functions are diversity based ones which attempt to obtain a diverse set of key points dispersion disparity functions denote dij as a tance measure between images i and j dene a set tion x mini jx dij this function is not ular but can be efciently optimized via a greedy rithm it is easy to see that maximizing this function involves obtaining a subset with maximal minimum wise distance thereby ensuring a diverse subset of snippets or keyframes similar to the minimum disparity we can dene two more variants one is disparity sum which can be dened as f x i jx dij this is a supermodular function another model is what we call disparity sum which is a combination of the two forms of models dene this as f x ix minjx dij this function is submodular determinantal point processes another class of tions are determinantal point processes dened as where s is a similarity kernel matrix and sx notes the rows and columns instantiated with elements in x it turns out that x log is submodular and hence can be efciently optimized via the greedy algorithm like the other choices of submodular functions investigated so far this requires computing the determinant and is where n is the size of the ground set this function is not computationally feasible and hence we do not use it in our system since we require near real time results in rization figure illustration of the difference between diversity functions coverage functions and representation functions name facility location saturated coverage graph cut feature based set cover prob set cover dpp dispersion min dispersion sum dispersion min sum x iv maxkx sik iv iv jx sij i i jx sij jx sij if ui iu kx pik pf x maxkx sik i v jx sij i v jx sij i v i f ix ui t p t o kx pik i u log mink lx dkl lx dkl kx minlx dkl mink lx dkl kx dkl x minkx dkl x table list of submodular functions used with the precompute statistics pf x gain evaluated using the precomputed statistics pf x and nally t p as the cost with memoization it is easy to see that memoization saves an order of magnitude in computation o as the cost of evaluation the function without memoization and t f modeling importance and relevance to model importance or relevance we use modular terms given a specic task we train a supervised model to predict the important frames in that video for ample a goal might be considered important in a soccer video given this learnt model we can predict the score of each frame and rank the scores this is exactly equivalent to optimize the modular function dened with these scores understanding diversity representation and coverage figure demonstrates the intuition of using diversity sentation and coverage functions diversity based functions attempt to nd the most different set of images the most gure in fig demonstrates this it is easy to see that the ve most diverse images are picked up by the diversity function disparity min and moreover the summary also contains the image with a hand covering the camera the age on the right hand side bottom which is an outlier the middle gure demonstrates the summary obtained via a resentation function like facility location the summary does not include outliers but rather contains one tative image from each cluster the diversity function on the other hand does not try to achieve representation from every cluster the third gure demonstrates coverage tions the summary obtained via a coverage function like set cover or feature based function covers all the cepts contained in the images male car greenery beach instantiations of the submodular functions having discussed the choices of the submodular tions and features we go over the specic instantiations of submodular functions considered in our system first sider extractive and query based summarization for the facility location function and the disparity min function we dene the similarity kernel as sij i s f j s i o f j o i h j where fs represent normalized deep scene features tracted using googlenet on fo represents normalized deep object features using googlenet on agenet h represents the normalized color histogram features since the disparity min function uses a distance function we use dij sij for feature based tions the feature set f is a concatenation of the scene tures fs and object features fo in order to dene the set cover function we dene ui as the scene and yolo ject labels corresponding to the image recall that the labels for scenes and objects were chosen based on a pre dened threshold i e select scene and objects labels if the bility for the label is greater than a threshold the bilistic set cover function is dened via a concatenation of the probabilities from the scene and object models query based summarization for keyframes is identical to tive summarization except that we rst get a groundset vq which is related to the query the queries are either objects scenes faces humans with age and gender text in the video as well as meta data like subtitles finally for entity or concept based summarization we extract the entities from the videos entities we consider are objects faces for faces we use the vgg face model from pretrained on celeb face data for face recognition the objects are localized using yolo we extract features from googlenet along with color histogram the similarity kernel we use here is sij i i h j o f j next we discuss the choice of the submodular functions facility location disparity min sum graph cut rated coverage and dpps are instantiated using similarity kernels discussed above feature based functions are ned directly via features and we use the deep features as described above in the case of the set cover and tic set cover functions we use the labels and probabilities respectively from the deep models as the concepts optimization algorithms the previous sections describe the models used in our system we now investigate optimization algorithms which solve problems and variants of a greedy algorithm vide near optimal solutions with approximation guarantees for problems budget constrained submodular maximization for the budget constrained version problem the greedy gorithm is a slight variant where at every iteration we t quentially update x x t argmaxjv t this algorithm has near optimal guarantees submodular cover problem for the submodular cover problem problem we again resort to a greedy dure which is near optimal in this case the date is similar to that of problem i e choose x x t argmaxjv tf t we stop as soon as f x v or in other words we achieve a set which covers all the concepts lazy greedy implementations each of the greedy gorithms above admit lazy versions which run much faster than the worst case complexity above the idea is that instead of recomputing t j we maintain a ority queue of sorted gains j v initially is set to f j v the algorithm selects an element x t if t we add j to x t thanks to larity if t we update to f t and re sort the priority queue the complexity of this algorithm is roughly where nr is the average number of re sorts in each iteration note that nr n while in tice it is a constant thus offering almost a factor n speedup compared to the simple greedy algorithm function fac loc sat cov gr cut feat b set cov psc dpp dm ds memoization no memoization table timing results in seconds for summarizing a two hour video for various submodular functions implementational tricks this section goes over implementation tricks via ization one of the parameters in the lazy greedy algorithms is tf which involves evaluating x j x one tion is to do a nave implementation of computing x j and then x and take the difference however due to the greedy nature of algorithms we can use memoization and maintain a precompute statistics pf x at a set x using which the gain can be evaluated much more efciently at every iteration we evaluate f using pf x which we call pf we then update pf x j after adding ement j to x table provides the precompute statistics as well as the computational gain for each choice of a modular function denote t o as the time taken to navely compute x denote t p o as the time taken to evaluate this gain given the pre compute statistics we see from table that evaluating the gains using memoization is often an order of magnitude faster over notice that we also need to update the pre compute statistics px at every iteration for the functions listed in table the cost of updating the pre compute statistics is also t p hence every iteration of the lazy greedy rithm costs only t p instead of t o which is an order of magnitude larger in every case in our results section we evaluate empirically the benet of memoization in practice results our system is implemented in we use caffe and darknet for deep cnns and opencv for other computer vision tasks a graphical representation of our system is depicted in figure figure shows the results for extractive summarization as keyframes extractive summarization on concepts or tities and query based summarization on keyframes we compare the different summarization models under various scenarios and evaluation measures instead of comparing all the submodular functions described above we consider representatives from each class of functions we use ity location as a representative function disparity min for diversity and set cover as a choice for coverage functions we next create a dataset of videos from different egories we select videos from the following truth from these videos to dene various evaluation ria the annotation mechanism and evaluation criteria is described in each of the sections below the goal of this is to demonstrate the role of various summarization models extractive summarization representation the top figure in fig demonstrates the results of extractive marization on movies and tv shows diversity models tend to pick up outlier events which in this case include transition scenes and other outliers in contrast the resentation function facility location tends to pick the representative scenes the coverage function does thing in between in the case of a tv show tative shots are probably more important compared to the transition scenes to quantify this dene an evaluation measure as follows we divide a movie tv show into a set of scenes sk where each scene si is a tinuous shot of events we do not include the outliers we dene outliers as shots less than a certain length for example transition scenes given a summary x dene a summary with a large value of will not include the outliers and will pick only single representatives from each scene we ate this on different tv show and movie videos figure top left compares the representative diversity and age models and a random summary baseline we see the representative model facility location tends to perform the best as expected followed by the coverage model the diversity model does poorly since it picks a lot of outliers extractive summarization coverage next we dene an evaluation criteria capturing coverage for each frame in the video sampled at dene a set of concepts ered u denote as the set of concepts covered by a set x for each frame of the video we hand pick a set of cepts scenes and objects contained in the video dene the coverage objective as figure demonstrates the coverage objective for the different els we obtain this by creating a set of labeled videos of different categories surveillance tv shows movies and travel videos as expected the coverage function set cover achieves superior results compared to the other els extractive summarization outliers and diversity in the above paragraphs we dene two complementary uation criteria one which captures representation and other which measures coverage we argue how for ple representation is important in movies and tv shows we now demonstrate how the diversity models tend to lect outliers and anomalies to demonstrate this we select a set of surveillance videos most of our videos have tive events like no activity or people sitting working given this we mark all the different events what we call liers including for example people walking in the range of the camera or any other different activity we create a dataset of surveillance videos with different ios most of these videos have less activity given a set figure illustration of the results the top gure shows the results from extractive summarization on tv shows the ond demonstrates entity summary on a tv show the third ure shows the results of query based summarization on a query skyscraper while the fourth one shows the results of extractive summarization on surveillance videos in each case we compare representation diversity and coverage models see the text for more details figure comparison of diversity coverage and representation models for various domains and scenarios see the text for more details gories movies tv shows surveillance camera footage travel videos and sports videos like soccer in the ing sections we annotate various events of interest extractive summary tv shows friends season episode diversity function disparity min coverage function set cover representation function facility location entity summary faces tv shows how i met your mother diversity function disparity min representation facilty location coverage fn feature based query based summary skyscrapers travel video diversity function disparity min representation facilty location coverage fn feature based extractive summary surveillance videos diversity function disparity min representation facilty location coverage fn feature based quantitative evaluation of extractive query and entity based summarization figure end to end processing and summarization of a video sk of these events marked in the video dene note this measure is ilar to the representative evaluation criteria except that it is dened w t the outlier events figure middle left shows the comparison of the performance of different models on this dataset as expected the diversity measures outperforms the other models consistently extractive summarization importance to strate the benet of having the right importance or vance terms we take a set of videos where intuitively the relevance term should matter a lot examples include sports videos like soccer to demonstrate this we train a model to predict important events of the video e the goals red card we then dene a simple modular function where the score is the output of the classier we then test this out and compare the importance model to other summarization models the results are shown in figure middle right as we expect the model with the importance gets the est scores query summarization diversity we next look at query based summarization the goal of query based tion is to obtain a summary set of frames which satisfy a given query criteria figure third row qualitatively shows the results for the query sky scrapers the versity measure is able to obtain a diversity of the different scenes even if there is an over representation of a certain scene in the set of images satisfying the query the diversity measure tends to pick a diverse set of frames the tation measure however tends to focus on the representative frames and can pick more than one image in the summary from scenes which have an over representation in the query set we see this figure to quantify this we dene a measure m x by dividing the video into a set of clusters of frames sk where each cluster contains similar frames these are often a set of continuous frames in the video we evaluate this on a set of travel videos and compare the different models we see that the diversity and representation models tend to perform the best figure bottom left with the diversity model slightly ing the representative models we also observe that there are generally very few outliers in the case of query based summarization which is another reason why the diversity model tends to perform well entity summarization lastly we look at entity marization the goal here is to obtain a summary of the tities faces objects humans in the video figure second row demonstrates the results for entity summarization of faces we see the results for diversity coverage and resentation models the diversity model tends to pick up outliers many of which are false positives i e not faces the representation model skips all outliers and tends to pick representative faces to quantitavely evaluate this we ne a representation measure as follows we remove all the outliers and cluster the set of entities objects faces into a set of clusters ek where ei is a cluster of ilar entities we evaluate this again on a set of videos figure bottom right shows the results for objects the results for faces is similar and in the interest of space we do not include these we see that the representation model tends to outperform the other models and skips all the liers the diversity model focuses on outliers and hence does not perform as well scalability finally we demonstrate the computational scalability of our framework table shows the results of the time taken for summarization for a two hour video in seconds with and without memoization the groundset size is we see huge gains from using ization compared to just computing the gains using the acle models of the functions all our experiments were formed on cpu ghz dual cpu with gb ram we used a nvidia gtx gb gpu for the deep learning for the two hour video the preprocessing took around minutes on a gle gpu it would be much faster on multiple gpus and moreover this is typically done only once conclusion this paper presents a unied picture of multi faceted video summarization for extractive query based and entity based summarization in each case we take a closer look at the different summarization models and argue the benets of these models in different domains we qualitatively and quantitatively argue this by comparing the results on several domains finally we discuss various implementation tricks to build applications around video and image tion in production systems references s chakraborty o tickoo and r iyer adaptive keyframe selection for video summarization in cations of computer vision wacv ieee ter conference on pages ieee w chu y song and a jaimes video summarization video summarization by visual in proceedings of ieee cvpr pages occurrence a dasgupta r kumar and s ravi summarization in acl through submodularity and dispersion pages d b goldman b curless d salesin and s m seitz schematic storyboarding for video in acm transactions on graphics tion and editing tog volume pages acm b gong w chao k grauman and f sha verse sequential subset selection for supervised video in advances in nips pages summarization m gygli h grabner h riemenschneider and l van gool creating summaries from user videos in in proc eccv pages springer m gygli h grabner h riemenschneider and l van gool creating summaries from user videos in eccv m gygli h grabner and l van gool video marization by learning submodular mixtures of tives in proc cvpr pages m gygli y song and l cao automatic in in proc generation of animated gifs from video cvpr pages k he x zhang s ren and j sun deep ual learning for image recognition in proceedings of the ieee conference on computer vision and pattern recognition pages r k iyer and j a bilmes submodular tion with submodular cover and submodular knapsack constraints in advances in nips pages y jia e shelhamer j donahue s karayev j long r girshick s guadarrama and t darrell caffe convolutional architecture for fast feature embedding in proceedings of the acm international ence on multimedia pages acm j kopf m f cohen and r szeliski first person hyper lapse videos acm transactions on graphics tog a krause optimizing sensing theory and tions proquest a krizhevsky i sutskever and g e hinton agenet classication with deep convolutional neural in advances in nips pages networks y j lee j ghosh and k grauman discovering portant people and objects for egocentric video in in proc cvpr pages marization ieee y li and b merialdo multi video summarization based on video mmr in image analysis for dia interactive services wiamis national workshop on pages ieee h lin and j bilmes a class of submodular functions in proceedings of the for document summarization annual meeting of the association for tational linguistics human language volume pages association for tional linguistics h lin and j bilmes learning mixtures of ular shells with application to document in uncertainty in articial intelligence uai tion auai z lu and k grauman story driven summarization in proc cvpr pages for egocentric video j meng h wang j yuan and y tan from keyframes to key objects video summarization by in proc representative object proposal selection cvpr pages m minoux accelerated greedy algorithms for in optimization imizing submodular set functions techniques pages springer g l nemhauser l a wolsey and m l fisher an analysis of approximations for maximizing modular set functionsi mathematical programming o m parkhi a vedaldi and a zisserman deep face recognition in bmvc volume page d potapov m douze z harchaoui and c schmid in in proc category specic video summarization eccv pages springer y pritch a rav acha and s peleg cal video synopsis and indexing in proc ieee pami j redmon s divvala r girshick and a farhadi you only look once unied real time object tion in proceedings of the ieee conference on puter vision and pattern recognition pages i simon n snavely and s m seitz scene rization for online image collections in computer sion iccv ieee international ference on pages ieee p sinha and r jain extractive summarization of personal photos from life events in multimedia and expo icme ieee international conference on pages ieee y song j vallmitjana a stent and a jaimes sum summarizing web videos using titles in cvpr pages ieee computer society m sun a farhadi b taskar and s seitz salient in european montages from unconstrained videos conference on computer vision pages springer m sviridenko a note on maximizing a submodular set function subject to a knapsack constraint tions research letters m j swain and d h ballard color indexing ternational journal of computer vision c szegedy w liu y jia p sermanet s reed d anguelov d erhan v vanhoucke and a novich going deeper with convolutions in ings of the ieee conference on computer vision and pattern recognition pages s tschiatschek r k iyer h wei and j a bilmes learning mixtures of submodular functions for image collection summarization in advances in nips pages k wei r k iyer and j a bilmes fast multi stage in icml pages submodular maximization k wei r k iyer and j a bilmes submodularity in data subset selection and active learning in icml pages w wolf key frame selection by motion analysis in in proc icassp volume pages ieee l a wolsey an analysis of the greedy algorithm for the submodular set covering problem combinatorica k zhang w chao f sha and k grauman mary transfer exemplar based subset selection for in proceedings of the ieee video summarization conference on computer vision and pattern nition pages b zhao and e p xing quasi real time tion for consumer videos in proceedings of the ieee conference on computer vision and pattern tion pages b zhou a lapedriza j xiao a torralba and a oliva learning deep features for scene recognition using places database in advances in neural tion processing systems pages
