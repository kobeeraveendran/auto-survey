v o n l c
s c v
v i x r a generative adversarial network for abstractive text summarization linqing yao min qiang jia hongyan institutes of advanced technology chinese academy of sciences machine intelligence institute of computer science south china normal university key laboratory of machine perception peking university likicode min

com
ac

scnu
edu

pku
edu
abstract in this paper we propose an adversarial process for tive text summarization in which we simultaneously train a generative model g and a discriminative model d
in ticular we build the generator g as an agent of ment learning which takes the raw text as input and predicts the abstractive summarization
we also build a discriminator which attempts to distinguish the generated summary from the ground truth summary
extensive experiments strate that our model achieves competitive rouge scores with the state of the art methods on cnn daily mail dataset
qualitatively we show that our model is able to generate more abstractive readable and diverse
introduction abstractive text summarization is the task of generating a short and concise summary that captures the salient ideas of the source text
the generated summaries tially contain new phrases and sentences that may not pear in the source text
in the past decades a urry of studies have been conducted on abstractive text rization nallapati et al
see liu and manning paulus xiong and socher
despite the remarkable progress of previous studies abstractive summarization is still challenged by neural sequence to sequence models tend to generate trivial and generic summary often involving high frequency phrases the generated summaries have limited grammaticality and readability in most previous work the standard sequence to sequence models are trained to predict the next word in summary using the likelihood estimation mle objective function
however this strategy has two major shortcomings
first the ation metric is different from the training loss
second the input of the decoder in each time step is often from the true summary during the training
nevertheless in the testing phase the input of the next time step is the previous word the work was partially supported by cas pioneer hundred talents program and the moe key laboratory of machine ception at peking university under grant number
q
qu is the corresponding author
copyright association for the advancement of articial intelligence www
aaai
org
all rights reserved
material
com generated by the decoder
this exposure bias leads to error accumulation at test time
to address the above challenge in this paper we propose an adversarial framework to jointly train a generative model g and a discriminative model d
specically the generator g takes the original text as input and generate the summary
we use reinforcement learning i
e
policy gradient to mize g for a highly rewarded summary
thus it effectively bypasses exposure bias and non differentiable task metrics issues
we implement the discriminator d as a text classier that learns to classify the generated summaries as machine or human generated
the generator g and the tor d are optimized with a minimax two player game
the discriminator d tries to distinguish the ground truth maries from the generated summaries by the generator g while the training procedure of generator g is to maximize the probability of d making a mistake
thus this ial process can eventually adjust g to generate plausible and high quality abstractive summaries
to the training our model similar strategy standard goodfellow et al
we simultaneously train two models in an adversarial manner a generative model g and a discriminative model d
we rst pre train the generative model by generating summaries given the source text
then we pre train the discriminator by providing positive examples from the human generated summaries and the negative examples produced from the pre trained generator
after the pre training the generator and discriminator are trained alternatively
generative model the generator takes the source text


as input and predicts the summary y


ym
here the n is the length of the source text and m is the length of the predicted summary
we use a text directional lstm encoder to convert the input into a sequence of hidden states


hn
lowing see liu and manning on time step t an attention based lstm decoder is then used to compute the hidden state st of the decoder and a context vector
the reader can refer to the supplement of this paper or see liu and manning for the implementation tails
the parameters of the generator g are collectively resented by
the context vector ct is concatenated with the decoder state st and fed through a fully connected layer and a softmax layer to produce the probability of predicting word from target vocabulary at each time step t pvocab yt sof v st where v v are learnable parameters
similar to the work of see liu and manning we incorporate a switching pointer generator network to use either word erator from xed vocabulary or pointer copying rare or seen from the input sequence
finally we can get the nal probability p yt of each token yt in the summary
discriminative model the discriminator is a binary classier and aims at guishing the input sequence as originally generated by mans or synthesized by machines
we encode the input quence with a cnn as it shows great effectiveness in text classication kim
we use multiple lters with ing window sizes to obtain different features and then apply a max over time pooling operation over the features
these pooled features are passed to a fully connected softmax layer whose output is the probability of being original
updating model parameters in the adversarial process using the discriminator as a ward function can further improve the generator iteratively by dynamically updating the discriminator
once we obtain more realistic and high quality summaries generated by erator g we re train the discriminator as min ey pdata ey g when the discriminator d is obtained and xed we are ready to update the generator g
the loss function of our generator g consists two parts the loss computed by policy gradient denoted by jpg and the maximum likelihood loss denoted by jml
formally the objective function of g is j jpg where is the scaling factor to balance the magnitude difference between jpg and jml
cording to the policy gradient theorem sutton et al
we compute the gradient of jpg w

t
the parameters t t x x yt t t x jpg r g d x x eyt g rg d x log x where rg d x yt is the action value function and we have rg d x t t is the length of the text
we update the parameters using stochastic gradient descent t is the generated summary up to time step t x is the source text to be condensed
experiments cnn daily mail corpus
the dataset dataset nallapati et al
is widely used in abstractive summarization
it comprises news stories in cnn and daily methods abs pgc deeprl pretrain ours









rouge l human









table quantitative evaluation results mail websites paired with multi sentence human generated abstractive summaries
it contains training pairs validation pairs and test pairs
experimental results
we compare our approach including the abstractive model the pointer generator see liu and manning deeprl with three methods abs nallapati et al
pgc erage and the abstractive deep reinforced model paulus xiong and socher version
networks we rstly compare our model with the pre trained erator
after adversarial training rouge l increase by

and
absolute points respectively
in addition our model exhibits competitive rouge scores with the state of the art methods
ically our approach achieves the best and scores
we also perform human evaluation to evaluate the ability and quality of summaries
we randomly select test examples from the dataset
for each example two human evaluators are asked to rank each summary generated by all models based on their readability where indicates the lowest level of readability while indicates the highest level
as we can observe from table our model contributes nicantly to improving the readability of summaries
to evaluate the proposed model qualitatively we also port the generated summaries in supplementary les
conclusion in this paper we proposed an adversarial process for tive text summarization
experimental results showed that our model could generate more abstractive readable and verse summaries
references goodfellow et al
goodfellow i
pouget abadie j
mirza m
xu b
warde farley d
ozair s
courville a
and bengio y

generative adversarial nets
in nips
kim kim y

convolutional neural networks for sentence classication
arxiv preprint

nallapati et al
nallapati r
zhou b
gulcehre c
xiang b
et al

abstractive text summarization ing sequence to sequence rnns and beyond
arxiv preprint

paulus xiong and socher paulus r
xiong c
and socher r

a deep reinforced model for abstractive summarization
arxiv preprint

see liu and manning see a
liu p
j
and to the point get arxiv preprint ning c
d

tion with pointer generator networks


sutton et al
sutton r
s
mcallester d
a
singh s
p
and mansour y

policy gradient methods for inforcement learning with function approximation
in nips

