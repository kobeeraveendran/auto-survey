smart summarizer for blind people mona teja mohan sai
h s s s raviteja kushagra p student school of computer and engineering vit vellore india
com
com

com abstract in today s world time is a very important resource
in our busy lives most of us hardly have time to read the complete news so what we have to do is just go through the headlines and satisfy ourselves with that
as a result we might miss a part of the news or misinterpret the complete thing
the situation is even worse for the people who are visually impaired or have lost their ability to see
the inability of these people to read text has a huge impact on their lives
there are a number of methods for blind people to read text
braille script in particular is one of the examples but it is a highly inefficient method as it is really time taking and requires a lot of practice
so we present a method for visually impaired people based on the sense of which is obviously better and more accurate than the sense of touch
this paper deals with an efficient method to summarize a news into important keywords so as to save the efforts to go through the complete text every single time
this paper deals with many api s and modules like tesseract gtts and many algorithms have been discussed and implemented in detail such as luhn s algorithm latent semantic analysis algorithm text ranking algorithm
and the other functionality that this paper deals with is converting the summarized text to speech so that the system can aid even the blind people
keywords tesseract gtts luhn s algorithm latent semantic analysis algorithm text ranking algorithm text summary text to speech
i
introduction giving machines an ability to think has always been a fetched dream for humans since ancient times
but since the development of the concept of machine learning in the past few decades giving machines a brain is no longer a dream
yes the machines today can be made to learn and apply that learning to perform a lot of functions that only humans could do earlier
some of such applications of machine learning are generating the summary of a given piece of text and converting a piece of text to speech
so it s clear that this paper uses an approach based on the concepts of machine learning to brief the summary of a piece of text to deliver the content in very less time and in a clear cut way
and more over it contributes to different fields and can be attached or implemented in many other systems
another motive is to give visually impaired people the ability to get the news without anyone s help in a much more efficient manner
in this paper section ii will discuss about the importance of the proposed system and section iii discuss about the literature review and section iv shows the system architecture
section v gives the details of api s used and section vi shows the experiment
ii
importance of system the technique that we present in this paper is very useful for visually impaired people as well as the people who are not able to read newspapers because of their tight schedule
it acts as an interface to retrieve the content whatever it may be in textual form just by using ocr optical character recognition module which runs through image processing
after getting the text now by applying the luhn s algorithm the content is summarized important and self explanatory keywords thus saving the efforts to go through the complete news
in the next step this summarized content is converted to voice that can be directly perceived by for the visually impaired people
thus the content can be delivered to them accurately without anyone s help
into a few iii
literature reviews in paper it mainly comes with two problems one is searching for the relevant document and number of such documents available for that particular information
with that scenario it comes with a conclusion of creating a technique which automatically summarizes the text which is very important to overcome the above proposed problems by the paper
this paper tries to compress the content to a smaller information but keeping the meaning of the content alive
in it talks about the different methods to be followed for decreasing the content by using the centrality on the similarity graph method
it compares the difference between the based methods and the centroid based methods and finally concludes that the degree based methods are better
the main drawback in this method is that the technique used is insensitive to the noise in the data
in it shows and proves that the part of the text which are present in the content and which repeat a lot have a high probability to be present on the summarized content or they are the better terms to be present on the summarized content
this paper has coined a term weight on each content which is the frequency count of that particular text in the content which give good results when kept in the summarized content
j macqueen presents some methods for the classification of the multivariate observations describing a process for partitioning of n dimensional population into p sets depending upon the sample
the author explains how the concept of means has to be theoretically interesting apart from being applicable in many practical problems
according to him means clustering is a specific and one of the most widespread method of clustering
the major part of his research deals with k means and some results have been obtained on its asymptotic behavior along with their proofs
also several applications and some preliminary results from the conducted experiments to explore the potential inherent in the k means algorithm have been discussed
another unsupervised approach has been presented by regina barzilay and lillian lee to paraphrase using sequence alignment in which they have addressed the text text generation problem of sentence level paraphrasing that is even more difficult than or phrase level paraphrasing
they present an approach that applies multiple sequence alignment to sentences gathered from the unannotated corpora
the system is made to learn a set of paraphrasing patterns and then it automatically determines how to apply those patterns to paraphrase sentences
by using the machine learning concepts the authors have developed a system that accurately derives paraphrases thus outperforming the baseline systems
david yarowsky has presented another unsupervised approach for word sense disambiguation that excels in performance
the algorithm when trained on unannotated english text rivals supervised techniques that require time consuming hand annotations in performance and accuracy
the performance accuracy exceeds as tested by the author when exploited on an iterative bootstrapping procedure
the algorithm avoids the need for any kind of costly hand tagged training data as it exploits powerful properties of the human language namely one sense of collocation and one sense per discourse to reach the outcome
iv
system architecture figure i depicts the architecture of the proposed system
figure i v
apis and modules used is i the first module that has been used in the system is the tesseract google api which comes under optical character recognition ocr engine with support for unicode and moreover it has the ability to recognise over several languages out of the box
it is flexible and can further be trained for the recognition of other languages too
this module can be used to detect text on handheld devices and even to identify spam images from gmail and other common platforms
ii the next the luhn important module used algorithm
this algorithm is the well known check sum formula that is used to validate a variety of id numbers like imei and credit card numbers
this algorithm is freely available to the common public
the reason for its design was for the protection against accidental errors and not malicious attacks
iii another library we ve used is the gensim python library which is also an open source library used for natural language processing nlp with specification in topic modelling
it can also perform similarity detection and retrieval ir and document indexing when provided with large corpora
the target users are the nlp and the ir community
the task of summarization of the given piece of text is a classic one and has been studied from different perspectives from time to time
we followed the test ranking algorithm for this
the initial step is to pick a subset of a words from the text so that the summary determined by it is as close to the original text as possible
the subset named the summary should be logical and understandable
this does not mean that the system determines the most common words only but the most relevant words available

the task is not about picking the most common words or entities
we will use the naive way to perform the neural network training
and moreover gensim is an nlp natural language processing algorithm will also be implemented in python
the next algorithm used is the latent semantic in python
las us a analysis mathematical algorithm to determine latent relationships within a collection of the given documents thus looking at all the documents as a whole rather than looking at each document separately to identify the relationships
thus it determines sets of related words and include the relevant results from the complete set when we search for any word in the set
we have used this module to limit the number of words in the summary generated to keep it as compact as possible
v another important module we have used is the google text to search gtts module
this module alone handles one of the main functionalities of our model that is converting the text we provide to it to speech for the visually impaired people
by using the deep learning algorithms we lsa algorithm tries that can train the datasets which are then used to recognise the real objects using computer vision
vi
experiment in the first phase the image is given as input to optical character recogniser engine for this we have used tesseract an open source google api
and the text which is extracted at an accuracy of
which is pretty good enough for the proper text detail for the further process to maintain the details of the context
this has been pretrained from the data with lot of handwritten digits and with different fonts in different languages
in this case a sample image is given as input and the text is given as output is shown in fig the next phase is to recognize the object which is in front of impaired person and to notify the person the object is present
for this object recognition we use a deep learning model with the help of computer vision techniques
the dataset used is cifar dataset which consists of categories and this data for the feature extraction hog histogram of oriented gradients and these fed to fully neural network which is which are layers deep with neurons fully connected and the final layers with outputs and the predictions are for recognition we use opencv framework for the object detection and the prediction of the object with accuracy of
is shown in figure
figure of text extracted from the image in the next step of first phase is there might be a lot of data that might occur from the image and so we have used luhn s algorithm
this large sentence can be summarized using the parameters by finding the intersections of the paragraph and the content has been splitted into sentences and then the formating take place and the which is helpful for finding the ranks of the sentences which will be helpful for the text summarization based on the ranks of the sentences
in this the summary ratio maintfained is
and the orignal of length found is words which has been reduces to words and is shown in figure
figure summarization then after to maintain the context with the same proper meaning which is python framework for fast vector space modelling
genism is used for topic modelling document indexing and similarity retrieval with copra
the latent semantic model is the mathematical model which will search for identical latent relations which will help in summarizing
and next google api is used for converting the text to speech and which takes in the text document and output an format which can be simply heard by the user the whole text in summarized format
figure of object in front of an impaired person vii
conclusion the way people in the world are approaching to make the world a better place to live in is through optimization and automation
the model we present in this concept oriented paper can prove to be really useful to the blind people because of the results we obtained
the model summarizes the content presented to it based on neural network algorithms and that summarized content is finally converted to speech
this brings a major change in lives of the blind people a lot which is one step success for us
in the end we were able to extract the basic summary of any piece of text we presented to it
this summary was tested for correctness based on the number of keywords that were obtained as the output and their importance in the text and we were able to achieve a good efficiency and accuracy thus bringing the proposed system to the expected conclusion
viii
future scope the paper we have done we want to convert into a matured project by integrating the things we have done in the form of a mobile application
later we want to integrate with the google search so that if a person searches in the google with a particular keyword it gives the summarized content of the pages based on the keyword and then the summarized content will be generated to voice so that even blind people will be part of google search
references summarization an overview by samrat babar erkan g
radev d

lexrank graph based lexical centrality as salience in text summarization
journal of artificial intelligence research villatoro tello e
villaseor pineda l
montes gmez m
using word sequences for text summarization
in sojka p
kopeek i
pala k
eds
tsd
lncs lnai vol
pp

springer heidelberg mahajan m
nimbhorkar p
varadarajan k

the planar kmeans problem is np hard
lecture notes in computer science j
b
macqueen some methods for classification and analysis of multivariate observations proceedings of th berkeley symposium on mathematical statistics and probability berkeley university of california press kaliappan j
shreyansh j
singamsetti m
s
march
surveillance camera using face recognition for automatic attendance feeder and energy conservation in classroom
in international conference on vision towards emerging trends in communication and networking vitecon pp

ieee
sai s
m
gopichand g
reddy c
v
and teja k

high accurate unhealthy leaf detection
arxiv preprint

sai s
m
muppa s
k
teja k
m
natrajan p
december
advanced image processing techniques based model for brain tumour detection
in international conference on computing communication and automation iccca pp

ieee
h
wu and r
luk and k
wong and k
kwok
interpreting tf idf term weights as making relevance decisions
acm transactions on information systems

barzilay r
lee l

learning to paraphrase an unsupervised approach using multiple sequence alignment
in proceedings of hltnaacl yarowsky d

unsupervised word sense disambiguation rivaling supervised methods
in proceedings of the annual meeting of the association for computational linguistics
sai s
m
naresh k
rajkumar s
ganesh m
s
sai l
nav a
april
an infrared image detecting system model to monitor human with weapon for controlling smuggling of sandalwood trees
in second international conference on inventive communication and computational technologies icicct pp

ieee
mihalcea r
tarau p
textrank bringing order into texts
in proc
empirical methods in natural language processing emnlp barcelona spain sidorov g
gelbukh a
automatic detection of semantically primitive words using their reachability in an explanatory dictionary
in proc
int
workshop on natural language processing and knowledge engineering nlpke usa pp

