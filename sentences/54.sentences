g u a l c
s c v
v i x r a better summarization evaluation with word embeddings for rouge jun ping ng bloomberg l
p
new york usa
net viktoria abrecht bloomberg l
p
new york usa
net abstract rouge is a widely adopted automatic evaluation measure for text tion
while it has been shown to late well with human judgements it is ased towards surface lexical similarities
this makes it unsuitable for the tion of abstractive summarization or maries with substantial paraphrasing
we study the effectiveness of word dings to overcome this disadvantage of rouge
specically instead of ing lexical overlaps word embeddings are used to compute the semantic similarity of the words used in summaries instead
our experimental results show that our posal is able to achieve better correlations with human judgements when measured with the spearman and kendall rank efcients
introduction automatic text summarization is a rich eld of search
for example shared task evaluation shops for summarization were held for more than a decade in the document understanding ference duc and subsequently the text ysis conference tac
an important element of these shared tasks is the evaluation of ing systems
initially manual evaluation was ried out where human judges were tasked to sess the quality of automatically generated maries
however in an effort to make tion more scaleable the automatic sure lin was introduced in
rouge determines the quality of an automatic summary through comparing overlapping units such as n grams word sequences and word pairs with human written summaries
oriented understudy of gisting evaluation rouge is not perfect however
two problems with rouge are that it favors lexical larities between generated summaries and model summaries which makes it unsuitable to evaluate abstractive summarization or summaries with a signicant amount of paraphrasing and it does not make any provision to cater for the readability or uency of the generated summaries
in such as automatic of peers summaries tac there has been on going efforts summarization to prove on the automatically tion measures aesop evaluating dang and owczarzak task owczarzak owczarzak and dang
however rouge remains as one of the most popular metric of choice as it has repeatedly been shown to correlate very well with human judgements lin over and yen owczarzak and dang
in this work we describe our efforts to tackle the rst problem of rouge that we have tied above its bias towards lexical ties
we propose to do this by making use of word embeddings bengio et al

word dings refer to the mapping of words into a dimensional vector space
we can construct the mapping such that the distance between two word projections in the vector space corresponds to the semantic similarity between the two words
by corporating these word embeddings into rouge we can overcome its bias towards lexical ities and instead make comparisons based on the semantics of words sequences
we believe that this will result in better correlations with human assessments and avoid situations where two word sequences share similar meanings but get unfairly penalized by rouge due to differences in graphic representations
as an example consider these two phrases it is raining heavily and it is pouring
if we are performing a lexical string match as rouge does there is nothing in common between the terms raining heavily and pouring
ever these two phrases mean the same thing
if one of the phrases was part of a human written summary while the other was output by an matic summarization system we want to be able to reward the automatic system accordingly
in our experiments we show that word dings indeed give us better correlations with man judgements when measured with the man and kendall rank coefcient
this is a icant and exciting result
beyond just improving the evaluation prowess of rouge it has the tential to expand the applicability of rouge to abstractive summmarization as well
related work as we have while rouge is widely used there is a signicant body of noted earlier work studying the evaluation of automatic text summarization systems
a good survey of many of these measures has been written by steinberger and jezek
we will thus not tempt to go through every measure here but rather highlight the more signicant efforts in this area
elements hovy et al
has also been used be in the duc tac shared task evaluations
it is an automatic method which evaluates the content completeness of a generated summary by breaking up sentences into smaller more granular units of information referred to as basic elements
rouge besides basic the pyramid method originally proposed by staple in is another passonneau et al
duc tac
however is a semi automated it method where signicant human intervention is required to identify units of information called summary content units scus and then to map content within generated summaries recently however an to these scus
this method has been mated variant of posed passonneau et al

in this variant word embeddings are used as we are proposing in this paper to map text content within generated summaries to scus
however the scus still need to be manually identied limiting this variant s scalability and applicability
many systems have also been proposed in the aesop task in tac from to
the top system ported in owczarzak and dang for example meng giannakopoulos and karkaletsis is a graph based system which scores summaries based on the similarity between the graph tures of the generated summaries and model maries
methodology let us now describe our proposal to integrate word embeddings into rouge in greater detail
to start off we will rst describe the word embeddings that we intend to adopt
a word embedding is really a function w where w w rn and w is a word or word sequence
for our purpose we want w to map two words and such that their respective projections are closer to each other if the words are mantically similar and further apart if they are not
mikolov et al
describe one such ant called which gives us this sired
we will thus be making use of
we will now explain how word dings can be incorporated into rouge
there are several variants of rouge of which and rouge have often been used
this is because they have been found to correlate well with human lin over and yen judgements owczarzak and dang
sures the amount of unigram overlap between model summaries and automatic summaries and measures the amount of bigram overlap
rouge measures the amount of overlap of skip bigrams which are pairs of words in the same order as they appear in a sentence
in each of these variants overlap is computed by matching the lexical form of the words within the target pieces of text
formally we can dene this as a similarity function fr such that if otherwise where and are the words could be unigrams or n grams being compared
in our which we will refer to as rouge we we dene a new similarity function effectiveness of the learnt mapping is such that we can now compute analogies such as king man woman queen

com ng j p rouge we fw e such that fw if are oov otherwise where and are the words being compared and vx w wx
oov here means a situation where we encounter a word w that our word bedding function w returns no vector for
for the purpose of this work we make use of a set of million pre trained vector trained from part of google s news dataset for w
reducing oov terms for n grams
with our formulation for fw e we are able to compute variants of rouge we that correspond to those of rouge including rouge and rouge we
however despite the large number of vector mappings that we have there will still be a large number of oov terms in the case of rouge and rouge we where the basic units of comparison are bigrams
to solve this problem we can compose dividual word embeddings together
we follow the simple multiplicative approach described by mitchell and lapata where individual tors of constituent tokens are multiplied together to produce the vector for a n gram i
e
w w w


w wn where w is a n gram composed of individual word tokens i
e
w


wn
multiplication tween two vectors w wi


vik and w wj


vjk in this case is dened as


vik vjk experiments
dataset and metrics for our experiments we make use of the dataset used in aesop owczarzak and dang and the corresponding correlation measures
for clarity let us rst describe the dataset used in the main tac summarization task
the main summarization dataset consists of topics each of which is associated with a set of ments
there are also four human curated model summaries for each of these topics
each of the participating systems generated a summary for each of these topics
these automatically ated summaries together with the human curated model summaries dataset for aesop
then form the basis of the this as reviewed in section semi automated measure described in to assess how effective an automatic evaluation system is the system is rst tasked to assign a score for each of the summaries generated by all of the participating systems
each of these maries would also have been assessed by human judges using these three key metrics pyramid
is a passonneau et al

responsiveness
human judges are tasked to evaluate how well a summary adheres to the mation requested as well as the linguistic quality of the generated summary
readability
human judges give their judgement on how uent and readable a summary is
the evaluation system s scores are then tested to see how well they correlate with the human ments
the correlation is evaluated with a set of three metrics including pearson correlation p spearman rank coefcient s and kendall rank coefcient k

results we evaluate three different variants of our proposal rouge rouge and rouge we against their corresponding variants of rouge i
e
rouge
it is worth noting here that in sop in rouge was shown to late very well with human judgements especially for pyramid and responsiveness and out performs most of the participating systems
tables and show the correlation of the scores produced by each variant of rouge we with human assessed scores for pyramid siveness and readability respectively
the tables also show the correlations achieved by and rouge
the best result for each column has been bolded for readability
rouge is observed to correlate very well with the pyramid responsiveness and ability scores when measured with the man and kendall rank correlation
however rouge correlates better with human ments for the pearson correlation
the key ence between the pearson correlation and man kendall rank correlation is that the former assumes that the variables being tested are mally distributed
it also further assumes that the
google
com file sharing measure rouge rouge rouge we rouge p





s





k





measure rouge rouge rouge we rouge p





s





k





table correlation with pyramid scores sured with pearson r p spearman s and kendall k coefcients
table correlation with readability scores sured with pearson r p spearman s and kendall k coefcients
measure rouge rouge rouge we rouge p





s





k





table correlation with responsiveness scores measured with pearson r p spearman s and kendall k coefcients
variables are linearly related to each other
the ter two measures are however non parametric and make no assumptions about the distribution of the variables being tested
we argue that the tions made by the pearson correlation may be too constraining given that any two independent uation systems may not exhibit linearity
looking at the two bigram based variants rouge and rouge we we serve that rouge improves on most of the time regardless of the correlation ric used
this lends further support to our proposal to use word embeddings with rouge
however rouge we is only better than rouge when evaluating readability
it does consistently worse than rouge for pyramid and responsiveness
the reason for this is likely due to how we have chosen to compose unigram word vectors into bigram equivalents
the tiplicative approach that we have taken worked better for rouge which looks at ous bigrams
these are easier to interpret tically than skip bigrams the target of we
the latter by nature of their tion loses some of the semantic meaning attached to each word and thus may not be as amenable to the linear composition of word vectors
owczarzak and dang reports only the results of the top systems in aesop in terms of pearson s correlation
to get a more plete picture of the usefulness of our proposal it will be instructive to also compare it against the other top systems in aesop when sured with the spearman kendall correlations
we show in table the top three systems which correlate best with the pyramid score when measured with the spearman rank coefcient
c s kumar et al
is a based system which assess summaries based on differences in word co locations between ated summaries and model summaries
be hm baseline by the organizers of the aesop task is the be system hovy et al
where sic elements are identied using a head modier criterion on parse results from minipar
lastly oliveira is also a graph based system which frames the summary evaluation problem as a maximum bipartite graph matching problem
measure rouge c s be hm s



k



table correlation with pyramid scores of top systems in aesop measured with the spearman s and kendall k coefcients
we see that rouge displays better relations with pyramid scores than the top system in aesop i
e
c s when sured with the spearman coefcient
the latter does slightly better however for the kendall cient
this observation further validates that our proposal is an effective enhancement to rouge
references conclusion we proposed an enhancement to the lar rouge metric in this work rouge we
rouge is biased towards identifying lexical ilarity when assessing the quality of a generated summary
we improve on this by ing the use of word embeddings
this ment allows us to go beyond surface lexicographic matches and capture instead the semantic ities between words used in a generated summary and a human written model summary
menting on the tac aesop dataset we show that this proposal exhibits very good correlations with human assessments measured with the man and kendall rank coefcients
in particular rouge outperforms leading state of art systems consistently
looking ahead we want to continue building on this work
one area to improve on is the use of a more inclusive evaluation dataset
the aesop summaries that we have used in our periments are drawn from systems participating in the tac summarization task where there is a strong exhibited bias towards extractive rizers
it will be helpful to enlarge this set of maries to include output from summarizers which carry out substantial paraphrasing li et al
ng et al
liu et al

another immediate goal is to study the use of better compositional embedding models
the generalization of unigram word embeddings into bigrams or phrases is still an open lem yin and schutze yu et al

a better compositional embedding model than the one that we adopted in this work should help us improve the results achieved by bigram variants of rouge we especially rouge we
this is important because earlier works have strated the value of using skip bigrams for marization evaluation
an effective and accurate automatic evaluation measure will be a big boon to our quest for ter text summarization systems
word embeddings add a promising dimension to summarization uation and we hope to expand on the work we have shared to further realize its potential
bengio et al
yoshua bengio rejean ducharme pascal vincent and christian janvin

a ral probabilistic language model
the journal of machine learning research
dang and hoa trang dang and karolina owczarzak

overview of the tac summarization track
in proceedings of the text analysis conference tac
paulo c
f
de oliveira

catolicasc at tac
in proceedings of the text analysis conference tac
giannakopoulos and george annakopoulos and vangelis karkaletsis

autosummeng and memog in evaluating guided in proceedings of the text analysis summaries
conference tac
hovy et al
eduard hovy chin yew lin and liang zhou

evaluating duc using in proceedings of the document basic elements
understanding conference duc
kumar et al
niraj kumar kannan srinathan and vasudeva varma

using unsupervised system with least linguistic features for aesop task
in proceedings of the text analysis conference tac
et al
chen li fei liu fuliang weng and yang liu

document summarization via guided sentence compression
in proceedings of the conference on empirical methods in natural language processing emnlp pages
chin yew lin

looking for a few good metrics rouge and its evaluation
in ing notes of the ntcir workshop meeting
chin yew lin

rouge a age for automatic evaluation of summaries
in text summarization branches out proceedings of the workshop
liu et al
fei liu jeffrey flanigan sam son norman sadeh and noah a
smith

toward abstractive summarization using semantic representations
in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies naacl hlt pages
mikolov et al
tomas mikolov wen tau yih and geoffrey zweig

linguistic regularities in continuous space word representations
in ceedings of the conference of the north american chapter of the association for computational guistics human language technologies hlt pages
mitchell and jeff mitchell and mirella
vector based models of lapata
tic composition
in proceedings of the nual meeting of the association for computational linguistics human language technologies acl pages
et al
jun ping ng yan chen min yen kan and zhoujun li

exploiting timelines to enhance multi document summarization
in ceedings of the annual meeting of the ciation for computational linguistics acl pages
over and paul over and james yen

an introduction to duc intrinsic evaluation of generic new text summarization systems
in proceedings of the document understanding ference duc
owczarzak and karolina owczarzak and hoa trang dang

overview of the tac summarization track guided task and sop task
in proceedings of the text analysis ference tac
karolina owczarzak

overview of the tac summarization track
in proceedings of the text analysis conference tac
passonneau et al
rebecca j passonneau ani nenkova kathleen mckeown and sergey man

applying the pyramid method in duc
in proceedings of the document ing conference duc
passonneau et al
rebecca j passonneau emily chen weiwei guo and dolores perin

mated pyramid scoring of summaries using butional semantics
in proceedings of the nual meeting of the association for computational linguistics acl pages
steinberger and josef and steinberger karel jezek
evaluation measures for text summarization
computing and informatics

yin and wenpeng yin and hinrich

an exploration of embeddings for generalized phrases
in proceedings of the acl student research workshop pages
yu et al
mo yu matthew gormley and mark dredze

factor based compositional ding models
in proceedings of the nips deep learning and representation learning workshop

