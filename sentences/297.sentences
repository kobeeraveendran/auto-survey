on faithfulness and factuality in abstractive summarization joshua maynez shashi narayan bernd bohnet ryan mcdonald google research joshuahm shashinarayan bohnetbd
com a m l c
s c v
v i x r a abstract it is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human like responses for open ended tasks such as language modeling and story ation
in this paper we have analyzed tations of these models for abstractive ment summarization and found that these els are highly prone to hallucinate content that is unfaithful to the input document
we ducted a large scale human evaluation of eral neural abstractive summarization systems to better understand the types of hallucinations they produce
our human annotators found substantial amounts of hallucinated content in all model generated summaries
however our analysis does show that pretrained models are better summarizers not only in terms of raw metrics i
e
rouge but also in generating faithful and factual summaries as evaluated by humans
furthermore we show that textual tailment measures better correlate with fulness than standard metrics potentially ing the way to automatic evaluation metrics as well as training and decoding criteria
introduction current state of the art conditional text generation models accomplish a high level of uency and herence mostly thanks to advances in to sequence architectures with attention and copy sutskever et al
bahdanau et al
gu et al
fully attention based transformer chitectures vaswani et al
dai et al
and more recently pretrained language modeling for natural language understanding devlin et al
radford et al
yang et al
liu et al

there has been a growing interest in the rst two authors contributed equally
human annotated summaries for faithfulness and tuality will be released at
com google datasets xsum hallucination annotations
understanding how maximum likelihood training and approximate beam search decoding in these models lead to less human like text in open ended text generation such as language modeling and story generation holtzman et al
welleck et al
see et al

in this paper we investigate how these models are prone to ate hallucinated text in conditional text generation specically extreme abstractive document rization narayan et al

document summarization the task of ing a shorter version of a document while ing its information content mani nenkova and mckeown requires models to ate text that is not only human like but also ful factual given the document
the ple in figure illustrates that the faithfulness and factuality are yet to be conquered by conditional text generators
the article describes an event of conservative mp zac smith winning the mary for london mayoral election but maries often forge entities e

nigel goldsmith or zac goldwin or information e

ukip leader nigel goldsmith nigel goldsmith ning the mayoral election sadiq khan being the former london mayor or zac goldwin being the labour s candidate that are not supported by the document or are factually wrong
interestingly all summaries are topical and uent and perform well in terms of rouge scores lin and hovy
we conducted a large scale human evaluation of hallucinated content in systems that use current neural network rnn see et al
convolutional neural network cnn narayan et al
and transformers radford et al
rothe et al
as well as human written summaries for the recently introduced extreme summarization task xsum narayan et al

we seek to answer the following questions how frequently do abstractive marizers hallucinate content do models gold zac goldsmith will contest the london mayoral election for the conservatives it has been announced
document the richmond park and north kingston mp said he was honoured after winning of the votes cast using an online primary system
he beat london assembly member andrew boff mep syed kamall and london s deputy mayor for crime and policing stephen greenhalgh
mr goldsmith s main rival is likely to be labour s sadiq khan
sentences with words are abbreviated here
mr goldsmith who was the favourite for the tory nomination balloted his constituents earlier this year to seek permission to stand
at the very point of his entry into the race for london mayor zac goldsmith s decision revealed two big characteristics
sentences with words are abbreviated here
mr goldsmith who rst entered parliament in told the bbc s daily politics that he hoped his environmental record would appeal to green and lib dem voters and he also hoped to reach out to ukip supporters frustrated with politics as usual and the uk s relationship with the eu
zac goldsmith born in educated at eton and the cambridge centre for sixth form studies sentences with words are abbreviated here
mr goldsmith who has conrmed he would stand down from parliament if he became mayor triggering a by election said he wanted to build on current mayor boris johnson s achievements
sentences with words are abbreviated here
both mr khan and mr goldsmith oppose a new runway at heathrow airport a fact described by the british chambers of commerce as depressing
sentences with words is abbreviated here
current mayor boris johnson will step down next year after two terms in ofce
he is also currently the mp for uxbridge and south ruislip having been returned to parliament in may
some conservatives have called for an inquiry into the mayoral election process after only people voted compared with a turnout for the labour contest
sentences with words are abbreviated here
ptgen


ukip leader nigel goldsmith has been elected as the new mayor of london to elect a new conservative mp
former london mayoral candidate zac goldsmith has been chosen to stand in the london mayoral election
former london mayor sadiq khan has been chosen as the candidate to be the next mayor of london






gpt tuned conservative mp zac goldwin s bid to become labour s candidate in the


london mayoral election
zac goldsmith has been chosen to contest the london mayoral election



figure hallucinations in extreme document summarization the abbreviated article its gold summary and the abstractive model generated summaries ptgen see et al
narayan et al
and tuned and rothe et al
for a news article from the extreme summarization dataset narayan et al

the dataset and the abstractive models are described in section and
we also present the rouge l scores relative to the reference gold summary
words in red correspond to hallucinated information whilst words in blue correspond to faithful information
lucinate by manipulating the information present in the input document intrinsic hallucinations or by adding information not directly inferable from the input document extrinsic hallucinations how much hallucinated content is factual even when unfaithful and are there automatic means of measuring these hallucinations our main conclusions are as follows first intrinsic and extrinsic hallucinations happen quently in more than of single sentence maries
second the majority of hallucinations are extrinsic which potentially could be valid tions that use background knowledge
however our study found that over of extrinsic nations were erroneous
thus hallucinations pen in most summaries and the majority of these are neither faithful nor factual
third models tialized with pretrained parameters perform best both on automatic metrics and human judgments of faithfulness factuality
furthermore they have the highest percentage of extrinsic hallucinations that are factual
this suggests that while some studies argue that large scale pretrained models are merely better at learning data specic regularities niven and kao at least on in domain rization the gains in automatic metrics are ized in observable differences by humans
fourth rouge lin and hovy and bertscore zhang et al
correlates less with ness factuality than metrics derived from automatic semantic inference systems specically the degree to which a summary is entailed by the source ment
this presents an opportunity for improved automatic evaluation measures as well as model training and decoding objectives
we show inary experiments in this direction
hallucinations in summarization open ended generation the task of generating text that forms a natural continuation from the input text requires the model to hallucinate text hence the focus has been to ensure that the model learns to generate text that is more human like i
e
less repetitive or dull with more content related words holtzman et al
welleck et al
see et al

in contrast tasks such as document summarization nenkova and mckeown see et al
paulus et al
and data to text generation lebret et al
wiseman et al
which are not open ended require models to be factual faithful to the source text
despite recent improvements in conditional text generation most summarization systems are trained to maximize the log likelihood of the erence summary at the word level which does not necessarily reward models for being faithful
over models are usually agnostic to the noises or artifacts of the training data such as reference gence making them vulnerable to hallucinations kryscinski et al
wiseman et al
dhingra et al

thus models can ate texts that are not consistent with the input yet would likely have reasonable model log likelihood

intrinsic and extrinsic hallucinations given a document d and its abstractive summary s we try to identify all hallucinations in s with spect to the content of d regardless of the quality of the summary
in this work we dene a summary as being hallucinated if it has a wi


j i that is not supported by the input document
to distinguish hallucinations further in the context of a document and a summary we categorize cinations by the information source as intrinsic and extrinsic hallucinations
note paraphrases or any information that can be inferred from the document are not categorized as hallucinations
intrinsic hallucinations are consequences of synthesizing content using the information present in in the input document
for example ure former london mayoral candidate in the abstract and former london mayor in the abstract are hallucinations of trinsic nature both use terms or concepts from the document but misrepresent information from the document making them unfaithful to the document
the article does not conrm if zac goldsmith was a former london mayoral candidate or if sadiq khan was a former london mayor
one may suspect that a model with poor input ment representation will fail to do document level inference often required for abstraction and will be vulnerable to such errors
extrinsic hallucinations are model generations that ignore the source material altogether
for ample in figure nigel in the ptgen abstract and in both gold and gpt tuned are extrinsic hallucinations these terms are not duced in the document
a model with a informed decoder and that is agnostic to the vergence issue between the source and target texts wiseman et al
dhingra et al
will function more as an open ended language model and will be prone to extrinsic hallucinations

factual hallucinations in summarization a summary s of a document d contains a factual hallucination if it contains information not found in d that is factually correct
factual tions may be composed of intrinsic hallucinations or extrinsic hallucinations
by denition abstractive summaries are ten to preserve the salient information in the input document but they are expressed in the words of the summary author as opposed to the input ment author nenkova and mckeown
as such it is natural to construct summaries that grate with the author s background knowledge van dijk and kintsch brown and day
such knowledge integration can also be desirable in real world applications
for instance an gaging sports report will reect an understanding of the game to provide color and context
other example is audience targeted summarization where a good summary will reect understanding of both the article domain and the desired audience
nonetheless there is no consensus in the research community if the summary should be faithful out any hallucinations to the input document or if there is tolerance for factual hallucinations
recent deep learning approaches to abstractive summarization naturally learn to integrate edge from the training data while generating an abstractive summary for a document see et al
gehrmann et al

more advanced trained text generators radford et al
dong et al
song et al
khandelwal et al
rothe et al
are even better at capturing world knowledge as they are informed by a vast amount of background text
this can be observed in the example shown in figure as the input document does not mention that the discussed london mayoral election is from but the abstract generated by the pretrained text generator gpt tuned correctly predicts this information similar to the human authored abstract
the correct extrinsic hallucination the gpt tuned abstract overall is still not factual due to the incorrect extrinsic hallucination in conservative mp zac goldwin
there is no conservative mp named zac goldwin
in this paper we stand in favour of the tion that abstractive systems may integrate with the background knowledge to generate rich and ingful summaries
more concretely tions in summarization are acceptable if they lead to better summaries that are factual with respect to the document and the associated background knowledge
this assumption also allows us to assess the capability of recent neural models to tegrate with the background knowledge to generate factual abstracts see section

extreme document summarization we focus on the recently introduced extreme marization dataset xsum narayan et al
which comprises british broadcasting poration bbc articles paired with their sentence summaries provided by the journalists writing the articles
the dataset is split into three subsets training validation and test sets
all models in trained to generate abstractive summaries are trained and evaluated using this standard split vided by the authors
we choose to focus our study on extreme rization for the following reasons first this task aims to create a single sentence summary of a news article these shorter summaries are relatively ier to annotate and analyze than longer summaries such as story highlights from the cnn dailymail dataset hermann et al
or abstracts from the ny times sandhaus or the wikisum liu et al
dataset
secondly the gold summary in the extreme summarization dataset is an ductory sentence prefacing each article
by virtue of this property the extreme summarization task is not amenable to extractive strategies and requires an abstractive modeling approach
hence it vides us a better benchmark to assess abstractive models abilities to produce abstractions which are faithful and factual
finally since we conclude that hallucination is a problem on this dataset then we can safely conclude it is a problem for tion datasets with longer summaries as modeling longer distance dependencies and discourse tures make the task harder
abstractive summaries we evaluate summaries from rnn cnn and transformer based state of the art abstractive marization methods and the reference human
com edinburghnlp xsum ten summaries
see the appendix for eter and decoding details for all models
human written reference summaries
the single sentence summaries contained in the treme summarization dataset xsum are also uated as part of this study
these summaries were written by journalists as introductions to the news articles they precede
these summaries therefore often have true additional information not found in the document
such divergence issue between source and target is not uncommon in conditional text generation kryscinski et al
wiseman et al
dhingra et al

rnn based
we use the generator model ptgen introduced by see et al
an rnn based attention based sequence to sequence model which not only generates from the target vocabulary but can copy words from the source text
topic aware convolutional
the topic aware convolutional sequence to sequence model introduced by narayan et al
is an abstractive system which is conditioned on the article s topics and based entirely on convolutional neural networks gehring et al

is better suited for extreme summarization as convolution layers capture long range dependencies between words in the document more effectively than rnns
simultaneously the convolutional encoder associates each word with a topic vector capturing whether it is representative of the document s content
transformer based abstractive methods
we experiment with three transformer based model variants all of which have layers a hidden size of lter size of and attention heads
gpt tuned radford et al
proposed transformer based generative pre trained gpt language models that can generate high quality text in open ended generation setups
the proposed decoder only architecture for language modeling can be easily adapted to abstractive summarization where the model rst sees the document and given a prompt such as generates its summary
our gpt tuned is warm started with a publicly available gpt checkpoint radford et al
but ne tuned with supervised training on the treme summarization dataset
and and are sequence to sequence models models ptgen gpt tuned human eval test set









rl




bertscore




table rouge and bertscore scores for pretrained the top block and pretrained the bottom block models reported on the xsum dataset
these sults are on the sampled human evaluation items dataset
the best results are boldfaced
where both encoder and decoder are composed of transformer layers vaswani et al
rothe et al

all weights in are randomly initialized but in both encoder and decoder are initialized with the bert base checkpoints devlin et al
with parameter sharing between the encoder and decoder following rothe et al

the only variable that is initialized randomly is the decoder attention in
both models are then trained on the extreme summarization dataset
experiments and results the main focus of this work is not to propose a lution to hallucination related issues but to achieve a better understanding of hallucinations in tive summarization through their human ment
we randomly sampled articles from the test set to facilitate our study
using the full test set was unfeasible given its size and the cost of man judgments
we have trained annotators uent in english specically for our assessment
our annotators went through two pilot studies to have a better understanding of intrinsic and extrinsic hallucinations and factuality of summaries
uments used in the pilot studies were not used in the nal annotation
we also report on rouge lin and hovy scores bertscore zhang et al
and semantic inference metric such as textual entailment pasunuru and bansal welleck et al
falke et al
kryscinski et al
and question answering arumae and liu wang et al


automatic evaluation of summaries rouge lin and hovy provides a means to quickly assess a model s ability to generate maries closer to human authored summaries
we report on and for tiveness and rouge l for uency
like rouge bertscore zhang et al
computes a ilarity score for each token in the candidate figure human assessment of a system generated summary for the article in figure
the annotation user interface is shown as it was shown to raters
mary with each token in the reference summary
however instead of exact matches it computes token similarity using contextual embeddings
sults are presented in table
for both cases the pretrained encoder decoder architecture performed far superior to any other randomly initialized models such as gen and and the only architecture gpt tuned
the differences tween ptgen and are not signicant all other differences are signicant
rouge and bertscore are indicators of mativeness of summaries but they are not sufcient metrics to assess the overall quality of summaries
this becomes evident from our human assessments in the following sections where we employ human annotators to evaluate summaries generated with ptgen and and the human authored summaries
we excluded gpt tuned abstracts from our study after their poor performance on the automatic measures

assessment of hallucinations in this assessment human annotators were sented an article and a single sentence summary for the article
they were stringently told to only assess the hallucinations in the summary and to not confuse their assessment with the quality of the summary
for summaries containing tions annotators were tasked with identifying those text spans that were unfaithful to the cle and for each text span annotating whether the hallucination was intrinsic or extrinsic
we elicited judgments from three different annotators for each of document summary pairs
figure shows an example assessment of a mary of an article from figure
results from the full assessment are shown in table which shows the percentage of documents per system that were annotated as faithful or hallucinated faithful hallucinated
the appendix provides annotator agreement of hallucinations as well as hallucinated span characteristics
extrinsic hallucination due to divergence tween source and target
our results comparisons between all models using a way anova with post hoc tukey hsd tests p

models ptgen gold hallucinated e




i e




i




faith
fact









table intrinsic vs
extrinsic hallucinations
the numbers in hallucinated columns show the age of summaries where at least one word was tated by all three annotators as an intrinsic i or sic e hallucination
when a summary is not marked with any hallucination it is faithful ie umn faith

the nal fact
column shows the total percentage of faithful factual summaries which includes all faithful summaries plus the age of non faithful summaries annotated by all three notators as factual
higher numbers for faithful factual and lower numbers for hallucinations are boldfaced
rmed that the bbc gold summaries often have trinsic hallucinations due to the dataset artifact that gold summaries are introductory sentences acing each article
it was not surprising that most models also had signicant extrinsic hallucinations
intrinsic hallucination is also common in stractive summaries
gold summaries can also display intrinsic hallucinations
for example a news article could describe an event related to barack obama and the ofce of the president of the united states without inferring that obama is the president of the united states
a journalist with the knowledge of the event in the article could write a summary stating president obama
however the percentage of system summaries with intrinsic hallucination was much higher than in gold summaries
vs others
this nomenon particularly revealed the models dency to misrepresent information in the document due to the lack of document level understanding and inference
the copy mechanism in ptgen is good at copying from the source showing the least percentage of extrinsic hallucination of
but the mechanism lacks the inference capability and is prone to generate a summary that is not supported by the document
intrinsic hallucination
showed similar performance to ptgen and ranked second worst
the showed the least number of intrinsic hallucination
among all four abstractive systems
pretraining improves faithfulness
tions do not result from the artifacts in the training data only but also due to model shortcomings
the ptgen model with the copy mechanism gu et al
see et al
had the lowest extrinsic hallucination
but reported the highest number of faithful summaries
it appears that is overall most conservative among all four abstractive systems while getting closer to reference summaries in terms of rouge
the training prepares to be more aware of the domain of the document and less prone to language model vulnerabilities
consequently is more condent in predicting tokens from the ment than hence improving faithfulness

assessment of factual hallucinations
hallucinations are not necessarily erroneous
in our second human assessment we measured to what tent this is the case
our annotators were presented a single sentence summary with hallucinations and were asked to assess whether it is true or false
to better explain the context of the summary tors were made available the source document as well as the external resources such as wikipedia or google search
the source document can be particularly important for generic summaries to ter understand context
external resources assisted the evaluators to validate grounded facts in public knowledge bases
annotators were expected to validate the mary by looking for supporting evidence for the information found on the summary
if information in the summary contradicts the document then the summary is not factual
if supporting evidence is found for all the information then the summary is factual
the document is not useful when the mary has information that is neither supported nor contradicted in the article
for example the mary in figure mentions conservative mp zac goldwin which can not be veried from the article in figure
here annotators could use wikipedia or google search to check that there had not been a conservative mp named zac goldwin who tried to change their party and become a labour s date in the london mayoral election
we dropped the human authored gold summaries from this evaluation they were presumably factual
we also dropped the abstracts that were faithful to their input documents from the previous study
finally there were document summary pairs where the summaries were marked with at least one intrinsic or extrinsic hallucination
we elicited judgments from three different annotators for each of them
results from this assessment are also sented in table see the column labelled fact
along with the hallucination assessment

pretraining helps generating factual maries
in total
of the stracts were faithful factual

this is
absolute better than the next best model ptgen
the number of ful yet factual summaries for
was also the highest
in fact for extrinsic tions even though ptgen hallucinates less than
vs


of hallucinations were factual compared to
of ptgen
thus if we consider factual tions to be valid this means that even for extrinsic cases hallucinates the least
the superior performance of is most likely due to its exposure to vast amount of text through pretraining allowing it to integrate ground knowledge with generation
even so over of hallucinations are erroneous
finally we carried out pairwise comparisons tween all models using a one way anova with post hoc tukey hsd tests p

for sic hallucinations the second column in table gold is signicantly different from all other tems
for extrinsic hallucinations the third umn in table there were signicant differences between ptgen and ptgen and gold and and gold
for ity the differences between ptgen and were insignicant

automatic measures for hallucinations summaries are a proxy for their source documents under the assumption that they highlight the most important content
with this assumption we ther studied the extent to which the hallucinated content can be measured by semantic inference related measures such as textual entailment and question answering
textual entailment
we trained an entailment classier by netuning a bert large pretrained model devlin et al
on the multi nli dataset williams et al

we calculated the entailment probability score between the ment and its abstractive summaries
note that this entailment classier is not optimal for the bbc article summary pairs the multi nli dataset tains sentence sentence pairs
ideally a summary should entail the document or perhaps be neutral to the document but never contradict the document
as can be seen in table the abstracts showed the least number of appendix for full results
models ptgen gold textual entailment neut





entail





cont





qa




table textual entailment and question answering qa based measures for summary evaluation
for tailment we show the percentage of times a summary entails entail
the document is neutral neut
to the document and contradicts cont
the document
for qa we report the percentage of questions that were correctly answered by a system
the highest numbers for entail
neut
and qa and the lowest number for cont
are boldfaced
contradictions compared to other system generated abstracts and was at par with the gold summaries
similar to the performance on extrinsic nation in table the abstracts also displayed the highest number of contradictions
terestingly the gold summaries are more neutral to their documents whereas the maries are more entailed by their documents
this is probably due to the nature of the data and that journalists tend to add color and have a high ber of extrinsic but valid hallucinations
question answering
qa frameworks have been used to assess or promote summary mativeness narayan et al
arumae and liu
we adapted the qa framework to sess hallucination in model generated summaries a faithful model will generate a summary that only has information that is supported by its document
under this assumption any question answerable by the summary should also be answerable by the source
given an abstractive summary we used the round trip consistency method of alberti et al
which combines question generation and answer extraction models to generate synthetic question answer pairs
for the summary pairs we generated and question answer pairs for ptgen and gold spectively
finally we used a machine reading comprehension model to answer these questions using the document as context
as in alberti et al
we trained all models question generation answer extraction and reading comprehension els using a bert base pretrained model devlin et al
netuned on the natural questions dataset kwiatkowski et al

to textual entailment similar results the ptgen leeds united fought back from down to beat hudderseld town in the rst round of the efl cup
q what team did leeds united beat in the rst round of the efl cup a hudderseld town a coal mine in south yorkshire has collapsed as a result of the loss of a coal mine
q what type of mine has collapsed a coal star wars actor james davis said he was locked in a caravan and had his caravan stolen during a break in
q who said he was locked in a caravan a davis figure sample of question answer pairs generated from hallucinated summaries that are correctly swered by their source articles
highlighted spans in the summaries are marked as extrinsic or intrinsic lucinations by our annotators
metric rouge l bertscore qa entailment faithful





factual





table spearman s correlation coefcient of ferent metrics with faithful and factual annotations
abstracts were the most faithful to their source documents in terms of question answering
the gold abstracts were the least accurate due to a high number of extrinsic hallucination in them
spearman s correlation
we estimate man s correlation coefcients of different metrics with the faithful and factual human scores see table
we found that the textual entailment scores are best correlated with both faithful erate

and factual weak

human scores
comparatively rouge based metrics and bertscore have very weak correlation our ndings are consistent with the recent studies goodrich et al
ski et al
wang et al

surprisingly the question answering scores showed a very weak correlation

with faithful and factual human scores
we hypothesize that this is due to a compounding of errors where i the question generator is used to generate questions from the systems generated abstracts instead of human written text on which they were trained the question generator is susceptible to generate questions with hallucinated content when fed in with hallucinated summaries and our tion that a summary is faithful if the answers from the source and the summary match is rather poor for extreme summarization
we demonstrate these issues in figure
irrespective of questions with hallucinated content our reading comprehension models entail faith





rl


faith



fact



table rouge and faithfulness factuality scores for plus systems that use textual entailment as a criteria or ne tuned on faithful annotations
model can fortuitously answer them correctly from their source articles
better ways of generating questions narayan et al
and measuring tual consistency may alleviate some of these issues wang et al


model selection with entailment our study suggests that entailment could be used as an automatic measure for faithfulness
however we should point out that this measure is less
thus it can easily be gamed i
e
the rst tence of any source document is always entailed by the whole document
because of this based measures for evaluation need to be coupled with reference based measures like rouge
however one major advantage of the measure being reference less is that we can use it as a model selection objective or during decoding
we tested the former
specically we used the probability that a summary is entailed by a document as a tion criteria to select a summary between four didates generated by systems evaluated ptgen and
results are shown in the entail row of table
we can see that indeed this is a strong metric to optimize towards if we want faithful summaries almost absolute better
there is a trade off in terms of rouge but this model must select amongst tems of which have signicantly lower rouge than the best model
a further experiment is to train a model itly to predict faithfulness
in order to do this we further ne tuned the entailment model using the faithful annotations generated during our tion
for all summary document pairs marked as faithful we set the associated class to entailment otherwise we set it to neutral
this allowed for us to also ne tune the last classication layers taking advantage of the correlation between entailment and faithfulness
results using fold cross idation are shown in the entailfaith row of table
we see here that indeed this does improve the ability to select faithful summaries from a set of candidates though slightly
we would expect to see larger gains with more training data
ever this model is signicantly better than entail on rouge based metrics and seems like a good balance between rouge and better faithfulness
related work following the document understanding ence duc dang a majority of work has focused on evaluating the content and the linguistic quality of summaries nenkova
most ular among them is the automatic metric rouge lin and hovy that measures the unigram and bigram overlap and as a proxy for assessing informativeness and the longest common subsequence rouge l for ency
rouge however can be misleading when used as the only means to assess the ness of summaries schluter
hence the rouge score is often complemented with tive human assessment of summaries
more tive measures have been proposed to improve ment among human annotators
pyramid method nenkova and passonneau requires maries to be annotated by experts for salient mation
narayan et al
used a answering based approach where a summary is used as context to answer questions which were written based on its reference summary
hardy et al
proposed a reference less approach where a summary is assessed against the source document highlighted with its pertinent content
there has not been much work on evaluating faithfulness and truthfulness of abstractive maries
the automatic evaluation such as rouge and the human evaluation of saliency and linguistic quality of summaries are not sufcient due to the complex nature of the task
recently chen and bansal asked human annotators to assess the summary relevance measuring both the saliency and the presence of contradictory unrelated mation
dhingra et al
proposed a new tomatic metric parent for data to text ation lebret et al
wiseman et al
which aligns n grams from the reference and erated texts to the source table to measure the racy of n grams that are entailed from the source table
goodrich et al
proposed a based automatic metric to assess the faithfulness of wikipedia summaries they trained an end to end model to extract a complete set of openie style banko et al
facts from both the source text and the generated summary
the summary is faithful if it is precise in generating facts from the source text
in our experiments with based measures we found that they are not suited for evaluating extreme summarization models all models perform poorly on these metrics without any signicant differences
like ours few recent works some in parallel have explored natural language inference and question answering els to detect factual consistency in generated text welleck et al
falke et al
ski et al
wang et al

in line with our ndings falke et al
observed that the bert based nli models substantially improved summaries reranking in terms of their correctness
kryscinski et al
proposed an nli based fact checking model that is trained on a dataset tailored for detecting factual inconsistencies in erated text
wang et al
proposed a question answering and generation based automatic ation protocol that is designed to identify factual inconsistencies in a generated summary
future work will likely investigate better ways of ating questions and measuring factual consistency to address poor correlation with faithfulness and factuality annotations
finally others have used reinforcement ing to improve informativeness and reduce tradictory information in abstractive summaries e

pasunuru and bansal used a textual entailment based reward and arumae and liu a question answering based reward
ever these approaches do nt evaluate if these wards improve faithfulness of summaries
conclusion we conducted a large scale study of hallucinations in abstractive document summarization
we found that i tackling hallucination is a critical challenge for abstractive summarization perhaps the most critical nlu driven pretraining in neural text generators is key to generate informative coherent faithful and factual abstracts but it is still far from solving the problem and iii measures such as rouge or bertscore will not be sufcient when studying the problem semantic inference based automatic measures are better representations of true summarization quality
acknowledgments we thank ratish puduppully yova jhieva ankur parikh peter liu slav petrov the reviewers and the action editor for invaluable back
the hard work of muqthar mohammad mohd majeed and ashwin kakarla made our man annotation possible
references chris alberti daniel andor emily pitler jacob vlin and michael collins

synthetic qa pora generation with roundtrip consistency
in ceedings of the annual meeting of the ciation for computational linguistics pages florence italy
kristjan arumae and fei liu

guiding extractive summarization with question answering rewards
in proceedings of the conference of the north american chapter of the association for tional linguistics human language technologies pages minneapolis minnesota
dzmitry bahdanau kyunghyun cho and yoshua gio

neural machine translation by jointly in learning to align and translate
tional conference on learning representations san diego ca usa
michele banko michael j
cafarella stephen land matt broadhead and oren etzioni

open information extraction from the web
in ceedings of the international joint conference on artical intelligence pages abad india
ann l
brown and jeanne d
day

macrorules for summarizing texts the development of journal of verbal learning and verbal tise
haviour
yen chun chen and mohit bansal

fast tive summarization with reinforce selected sentence rewriting
in proceedings of the annual ing of the association for computational linguistics pages melbourne australia
zihang dai zhilin yang yiming yang jaime bonell quoc le and ruslan salakhutdinov

transformer xl attentive language models beyond in proceedings of the a xed length context
annual meeting of the association for tional linguistics pages florence italy
hoa trang dang

overview of duc
in proceedings of the document understanding ference pages
jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language in proceedings of the conference standing
of the north american chapter of the association for computational linguistics human language technologies pages minneapolis nesota
bhuwan dhingra manaal faruqui ankur parikh ming wei chang dipanjan das and william hen

handling divergent reference texts when evaluating table to text generation
in proceedings of the annual meeting of the association for computational linguistics pages rence italy
teun a
van dijk and walter kintsch

cognitive psychology and discourse recalling and ing stories
in wolfgang u
dressler editor current trends in textlinguistics pages
li dong nan yang wenhui wang furu wei aodong liu yu wang jianfeng gao ming zhou and hsiao wuen hon

unied language model pre training for natural language in advances in neural ing and generation
mation processing systems pages
curran associates inc
tobias falke leonardo f
r
ribeiro prasetya ajie utama ido dagan and iryna gurevych

ranking generated summaries by correctness an teresting but challenging application for natural guage inference
in proceedings of the annual meeting of the association for computational guistics pages florence italy
jonas gehring michael auli david grangier nis yarats and yann n
dauphin

in tional sequence to sequence learning
ings of the international conference on chine learning volume pages ney nsw australia
sebastian gehrmann yuntian deng and alexander rush

bottom up abstractive summarization
in proceedings of the conference on cal methods in natural language processing pages brussels belgium
ben goodrich vinay rao peter j
liu and mad saleh

assessing the factual accuracy of generated text
in proceedings of the acm sigkdd international conference on knowledge discovery and data mining pages new york ny usa
jiatao gu zhengdong lu hang li and victor o
k
incorporating copying mechanism in li

in proceedings of sequence to sequence learning
the annual meeting of the association for putational linguistics pages berlin germany
hardy shashi narayan and andreas vlachos

highres highlight based reference less evaluation in proceedings of the of summarization
nual meeting of the association for computational linguistics pages florence italy
karl moritz hermann tomas kocisky edward stette lasse espeholt will kay mustafa suleyman and phil blunsom

teaching machines to read in advances in neural and comprehend
tion processing systems pages
ran associates inc
ari holtzman jan buys maxwell forbes and yejin choi

the curious case of neural text ation
in proceedings of the international ference on learning representations virtual ference formerly addis ababa ethiopia
urvashi khandelwal kevin clark dan jurafsky and lukasz kaiser

sample efcient text marization using a single pre trained transformer
corr

wojciech kryscinski nitish shirish keskar bryan cann caiming xiong and richard socher

neural text summarization a critical evaluation
in proceedings of the conference on cal methods in natural language processing and the international joint conference on natural language processing pages hong kong china
wojciech kryscinski bryan mccann caiming xiong and richard socher

evaluating the tual consistency of abstractive text summarization
corr

taku kudo and john richardson

sentencepiece a simple and language independent subword enizer and detokenizer for neural text processing
corr

tom kwiatkowski jennimaria palomaki olivia eld michael collins ankur parikh chris berti danielle epstein illia polosukhin jacob vlin kenton lee kristina toutanova llion jones matthew kelcey ming wei chang andrew m
dai jakob uszkoreit quoc le and slav petrov

natural questions a benchmark for question swering research
transactions of the association for computational linguistics
j
richard landis and gary g
koch

the surement of observer agreement for categorical data
biometrics
remi lebret david grangier and michael auli

neural text generation from structured data with in application to the biography domain
ings of the conference on empirical methods in natural language processing pages austin texas
chin yew lin and eduard hovy

automatic uation of summaries using n gram co occurrence statistics
in proceedings of the human guage technology conference of the north can chapter of the association for computational linguistics pages
peter j
liu mohammad saleh etienne pot ben goodrich ryan sepassi lukasz kaiser and noam shazeer

generating wikipedia by ing long sequences
in proceedings of the national conference on learning representations vancouver canada
yinhan liu myle ott naman goyal jingfei du dar joshi danqi chen omer levy mike lewis luke zettlemoyer and veselin stoyanov

roberta a robustly optimized bert pretraining approach
corr

inderjeet mani

automatic summarization ume
john benjamins publishing
shashi narayan shay b
cohen and mirella lapata

do nt give me the details just the summary topic aware convolutional neural networks for in proceedings of the treme summarization
conference on empirical methods in natural guage processing pages brussels gium
shashi narayan shay b
cohen and mirella lapata

ranking sentences for extractive tion with reinforcement learning
in proceedings of the conference of the north american ter of the association for computational linguistics human language technologies pages new orleans louisiana
shashi narayan goncalo simoes ji ma hannah craighead and ryan t
mcdonald

ous question generation pretraining for text eration
corr

ani nenkova

automatic text summarization of newswire lessons learned from the document in proceedings of the understanding conference
national conference on articial intelligence volume pages
ani nenkova and kathleen mckeown

matic summarization
foundations and trends in information retrieval
ani nenkova and rebecca passonneau

ing content selection in summarization the in proceedings of the human mid method
guage technology conference of the north can chapter of the association for computational linguistics pages boston massachusetts usa
timothy niven and hung yu kao

probing ral network comprehension of natural language guments
in proceedings of the annual ing of the association for computational linguistics pages florence italy
ramakanth pasunuru and mohit bansal

reward reinforced summarization with saliency and in proceedings of the entailment
ence of the north american chapter of the ation for computational linguistics human guage technologies pages new orleans louisiana
romain paulus caiming xiong and richard socher

a deep reinforced model for abstractive marization
in proceedings of the international conference on learning representations ver bc canada
alec radford karthik narasimhan tim salimans and ilya sutskever

improving language standing by generative pre training
technical port
sean welleck jason weston arthur szlam and kyunghyun cho

dialogue natural language inference
in proceedings of the annual ing of the association for computational linguistics pages florence italy
adina williams nikita nangia and samuel bowman

a broad coverage challenge corpus for tence understanding through inference
in ings of the conference of the north can chapter of the association for computational linguistics human language technologies pages new orleans louisiana
sam wiseman stuart shieber and alexander rush

challenges in data to document generation
in proceedings of the conference on cal methods in natural language processing pages copenhagen denmark
yonghui wu mike schuster zhifeng chen quoc v
le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey jeff klingner apurva shah melvin son xiaobing liu lukasz kaiser stephan gouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wei wang cliff young jason smith jason riesa alex nick oriol vinyals greg corrado macduff hughes and jeffrey dean

google s neural machine translation system bridging the gap between human and machine translation
corr

zhilin yang zihang dai yiming yang jaime g
bonell ruslan salakhutdinov and quoc v
le

xlnet generalized autoregressive pretraining for language understanding
corr

tianyi zhang varsha kishore felix wu kilian q
weinberger and yoav artzi

bertscore evaluating text generation with bert
in ings of the international conference on ing representations virtual conference formerly addis ababa ethiopia
alec radford jeff wu rewon child david luan dario amodei and ilya sutskever

language models are unsupervised multitask learners
cal report
sascha rothe shashi narayan and aliaksei severyn

leveraging pre trained checkpoints for to appear in quence generation tasks
tions of the association for computational tics

evan sandhaus

the new york times annotated corpus
linguistic data consortium philadelphia
natalie schluter

the limits of automatic marisation according to rouge
in proceedings of the conference of the european chapter of the sociation for computational linguistics pages valencia spain
abigail see peter j
liu and christopher d
manning

get to the point summarization with generator networks
in proceedings of the nual meeting of the association for computational linguistics pages vancouver canada
abigail see aneesh pappu rohun saxena akhila yerukola and christopher d
manning

do massively pretrained language models make better in proceedings of the storytellers ence on computational natural language learning pages hong kong china
kaitao song xu tan tao qin jianfeng lu and yan liu

mass masked sequence to quence pre training for language generation
in ceedings of the international conference on machine learning long beach california
ilya sutskever oriol vinyals and quoc v le

sequence to sequence learning with neural networks
in advances in neural information processing tems pages
curran associates inc
ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez lukasz kaiser and illia polosukhin

attention is all you need
in advances in neural information cessing systems pages
curran ciates inc
alex wang kyunghyun cho and michael lewis

asking and answering questions to evaluate in the factual consistency of summaries
ings of the annual meeting of the association for computational linguistics virtual conference formerly seattle usa
sean welleck ilia kulikov stephen roller emily nan kyunghyun cho and jason weston

in ral text generation with unlikelihood training
proceedings of the international conference on learning representations virtual conference merly addis ababa ethiopia
a model hyperparameters and predictions ptgen and model predictions are vided by narayan et al
and transformer model predictions from gpt tuned and by rothe et al

both gen and use a stanford tokenized vocabulary size of
and use a vocabulary size of around wordpieces wu et al
to match bert pretrained cabulary and gpt tuned a vocabulary size of around sentencepieces kudo and son to match the pretrained ulary
all models use the same uncased lary on both source and target sides
both ptgen and summaries were generated using beam search with beam size the transformer models use beam size of
see narayan et al
and rothe et al
for more details on these models
models ptgen gold hall





fleiss kappa fact
rept









inco





table fleiss s kappa scores measuring word level agreements among annotators for different annotation tasks hallucination hall
factuality fact
tion rept
and incoherence inco
assessments
b inter annotator agreement we estimated fleiss s kappa k to assess the ment among our raters when categorizing a word in the summary as one of faithful intrinsically cinated and extrinsically hallucinated
the results are shown in table
all models showed tial agreement
k
landis and koch among their annotations
table also shows fleiss s kappa k to sess the agreement among our raters for factuality
all models showed almost perfect agreement
k
landis and koch among their annotations
models ptgen gold intrinsic total avg





extrinsic total avg





avg
length




table total number of spans and the average number of spans per document annotated as intrinsic or sic hallucinations for all document summary pairs by three annotators
we also show the average span length for each system
models ptgen gold repetition




incoherence




table repetition and incoherence evaluation
the numbers show the the percentage of summaries where at least one word in a summary was annotated by all three annotators with the repetition or ence related issue
the lowest numbers are boldfaced
metric rouge l bertscore repetition incoherence qa entailment faithful







factual







table spearman s correlation coefcient of ferent metrics with faithful and factual annotations
least number of extrinsically hallucinated spans
per document
interestingly the average span length for ptgen summaries was
words much higher than
words for maries
our result demonstrates that i the effect of hallucination in is more local than what we observe in ptgen and despite a lower number of extrinsically hallucinated spans or uments in ptgen compared to that in
vs
spans per document
vs
documents the total number of words that were notated as extrinsic hallucination is much higher in ptgen than in vs words
d assessment of linguistic c highlighted span characteristics irregularities
results in table shed some light on the teristics of hallucinated spans observed in different abstracts
gold abstracts showed the least ber of intrinsically hallucinated spans
per document whereas ptgen abstracts showed the following standard practice in summarization all document summary pairs were annotated for repetition and incoherence related linguistic larities
annotators were presented only a sentence summary and were asked to identify all models faithful ptgen gold




i factual



total




hallucinated e factual



total




i e factual total




factual







table intrinsic vs extrinsic hallucinations and their factuality
the numbers in hallucinated columns show the percentage of summaries out of where at least one word was annotated by all three annotators as an intrinsic i or extrinsic e hallucination
when a summary is not marked with any hallucination it is faithful ie
the factual columns within the hallucinated column show for each type i e and ie the percentage of summaries out of annotated by all three annotators as factual
the nal factual column shows the total percentage of factual summaries faithful iefactual
the highest numbers for faithful and factual and the lowest numbers for hallucinations are boldfaced
spans of text in the summary that were either peated or made the summary incoherent
we again elicited judgments from three different annotators for each document summary pair
results are shown in table
overall all neural text generation systems are getting better in generating repetition free and herent single sentence summaries of news cles
transformer based models and in particular perform superior to based ptgen and cnn based els
nonetheless table shows that these metrics fail to correlate with faithful hallucinated and tual assessments of summaries
fleiss s kappa k values for repetition and incoherence assessments showed almost a perfect agreement
k
landis and koch among our raters see table
e full hallucination results table has the full results from our human study of hallucinations

