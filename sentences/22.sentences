jadt journes internationales danalyse statistique donnes textuelles condenss de textes par des mthodes numriques juan manuel patricia velzquez jean guy cole polytechnique dgi cp succ
centre ville montral canada ermetis univ
du qubec boul
luniversit chicoutimi canada lanci univ
du qubec cp succ
centre ville montral canada abstract since information in electronic form is already a standard and that the variety and the quantity of information become increasingly large the methods of summarizing or automatic condensation of texts is a critical phase of the analysis of texts
this article describes cortex a system based on numerical methods which allows obtaining a condensation of a text which is independent of the topic and of the length of the text
the structure of the system enables it to nd the abstracts in french or spanish in very short times
rsum tant donn que la varit quantit linformation sous forme lectronique deviennent plus en plus grandes mthodes dobtention rsums ou de condensation automatique textes constituent une phase critique textes
cet article dcrit cortex un systme bas sur mthodes numriques qui permet lobtention dun condens dun texte indpendant thme lampleur du texte faon do nt il crit
la structure du systme lui permet la condensation textes multilangues dans des temps trs courts
des applications en franais ou espagnol sont prsentes et analyses
keywords condenss textes rsums automatiques analyse textes catgorisation mthodes statistiques

introduction linformation textuelle lectronique saccumule trs grande quantit
alors documents sont catgoriss dune faon trs sommaire
le manque standards critique tous analyses textes dpistage exploration rcupration rsums
sont taches extrmement difciles torres moreno et al

cest pourquoi mthodes dobtention rsums automatique textes constituent une phase cruciale textes
les mthodes linguistiques sont pertinentes dans ces tches mais leur utilisation crte demeure encore difcile en raison plusieurs facteurs comme lampleur dynamique ou limite domaines restreints saggion and lapalme
dun autre ct mthodes statistique neuronales sont plus en plus utilises dans plusieurs domaines traitement linformation textuelle salton salton and mcgill deerwester et al
leloup veronis et al
balpe et al
torres moreno et al
mi et al
meunier and nault memmi and meunier
cet article prsente un tude sur lapproche vectorielle textes salton and mcgill pour obtenir denss pertinents de documents
la forme la plus connue et la plus visible condensation textes rsum reprsentation abrge et exacte du contenu dun document ansi
tant donn que lart ne permet dobtenir que rsums informatifs morris et al
nos recherches porteront sur lobtention ce type de condenss
nous allons ter un algorithme rcemment dvelopp
il sagit dune chane de traitement numrique qui jadt journes internationales danalyse statistique donnes textuelles combine plusieurs traitements statistiques informationnels comme calculs dentropie poids frquentiel segments mots plusieurs mesures dhamming parmi dautres avec un algorithme optimal dcision pour phrases pertinents texte
lensemble ces phrases rendent ce quon appelle document

pr traitement dans lapproche vectorielle on traite textes dans leur ensemble en passant par une tation numrique trs diffrente dune analyse structurale linguistique mais qui permet traitements performants memmi
consiste reprsenter les textes dans un espace appropri et appliquer traitements vectoriels
la chane conterm seffah and nier comporte un ensemble processus ltrage segmentation et lemmatisation
par opposition lanalyse symbolique classique ces processus sont trs performants et peuvent tre appliqus gros corpus
nous avons adapt les processus de conterm a nos besoins ainsi un module pre traitement a t dvelopp gravel et al

le original comporte nm mots mots fonctionnels noms ou verbes chis composs
on emploie la notion de pour designer un mot plus abstrait memmi
pour rduire complexit processus ltrage du lexique sont
la lemmatisation verbes langues morphologie variable langues romances savre trs important pour rduction lexique consiste trouver la racine verbes chis et ramener au singulier culin
ce processus permet diminuer la maldiction dimensionnelle qui pose srieux problmes dans grandes dimensions
nous explorons aussi dautres voies pour rduction du lexique en processus synonimisation tionnaires
la segmentation faite en sparateurs

un indice reprage importante dinformation titre dun document
toutefois nous expriences ont t ralises sur textes bruts donc titres sous titres et sections ne sont pas plicitement comme cas formats html ou xml
aprs pr traitement nouveau texte comporte p segments avec nf termes totaux

condensation du texte la segmentation transforme un document dans un ensemble vecteurs nm
chaque segment est reprsent par un vecteur composantes binaires
la dimension nm nombre total mots diffrents
lensemble segments do nt on dispose consiste en p vecteurs matrice p reprsente texte
seulement les termes frquence suprieure ont t utiliss torres moreno et al
donc un lexique nl termes est obtenu
on la relation nl nf nm
nous avons donc dni nl nm suppression mots fonctionnels haute et trs basse frquence dapparition suivi par la suppression entre parenthses chiffres symboles
on pourra ramener mme forme chanter mots chantaient chant chanteront et eventuellement chante chanteur critre segments taille xe a t cart car on cherchait lextraction phrases compltes
jadt journes internationales danalyse statistique donnes textuelles comme ratio rduction lexique ltr lemmatis
la matrice terme segment p drive de reprsente lexique rduit texte





p





p





p nl nl


nl





p nl i ou labsence dans cette matrice chaque composante montre la prsence mot i dans un segment
de faon analogue matrice frquentielle du p o chaque composante nl contient frquence i du terme i dans un ment
cette matrice contient linformation frquentielle essentielle texte
la condensation texte sur ces deux matrices qui constituent lespace au systme
nous avons dni la rduite matrices comme p nl proportion p de segments par rapport la dimension nl du lexique rduit lentre
les segments possdent une quantit htrogne du lexique employ il y a segments plus importants que dautres qui seront extraits par lalgorithme pour obtenir un condens

algorithme

mtriques la mthode cortex de rsums automatiques est compose deux algorithmes une mthode construction mtriques informationnelles indpendantes combine avec un algorithme pour la rcupration linformation code
ce dernier prendra une dcision sur les segments en fonction dune stratgie votes
des informations mathmatiques et statistiques importantes sont calcules partir matrices et sous forme mtriques
elles mesurent la quantit dinformation contenue dans chaque segment plus importante plus il comporte valeurs levs
mesures frequentielles
frquence mots
la somme frquences mots par segment calcule un poids spcique dun segment utilisant lexpression i frquence du mot i dans segment
lexpression f i nl t p nl i jadt journes internationales danalyse statistique donnes textuelles corresponde a lexique frquentiel contenue
nous introduisons ici la quantit dnie comme ratio rduction du lexique frquentiel
interaction de segments
dans chaque segment un mot i qui prsent au mme temps dans un ou plusieurs autres segments on dit qui interaction
la somme toutes les interactions chaque segment constitue alors linteraction entre segments
nous la comptabilisons la faon suivante t nm i nl p j j i pi t p i pi i i nl nl e i x x i x i i nl i somme frquentielle probabilits
calculons dabord
soit pi probabilit dapparition du terme i dans texte la somme probabilits calcul mesures entropiques
lentropie dun segment nous la calculons en utilisant avec mesures dhamming
une distance de minskowski a t utilise comme base
les distances dhamming
cette quantit la distance entre paires i et j dans lespace des segments
chaque mot tant reprsente par un vecteur binaire i
il faut dabord calculer la matrice dhamming h qui une matrice diagonale suprieure dimension n
ensuite on calcule somme distances dhamming h j i autrement j nl nl h j i si i j j le poids dhamming des segments
chaque segment possde un poids qui gal la somme termes prsentes dans le segment cest dire dans chaque matrice i i nl jadt journes internationales danalyse statistique donnes textuelles la somme poids dhamming
de la mme manire on peut mesurer poids spcique sur chaque colonne matrice p ce qui donne un poids dhamming ensuite on calcule somme poids dhamming par segments i i i nl p nl i i mesures mixtes
des mesures de distances combins avec mesures frequentielles ont t aussi considrs
le poids dhamming lourd
obtenu la multiplication du poids dhamming du segment par poids dhamming shm somme poids dhamming par frquence
ceci corresponde somme poids dhamming mots i existantes dans chaque segment pli par frquence correspondante
hm i i nl

algorithme de dcision nous avons dvelopp un algorithme pour rcuprer linformation code par les mtriques
est simple tant les votes pour un vnement particulier qui provient dun semble de k votants indpendants chaquun avec une certaine probabilit davoir raison trouver la dcision optimale
la mthode que nous avons dveloppe sappelle algorithme de dcision ad torres moreno et al

lalgorithme dcision utilise probabilits ment exclusives et
on prsente les k votants en modiant et en fonction sorties j k sur chaque segment
toutes les valeurs mtriques ont t normalises avant dtre utilises dans lad
cet algorithme de dcision possde deux proprits intressantes convergence et amplication

expriences et rsultats nous avons test notre algorithme articles de vulgarisation scientique
les textes extraits presse sur internet sont petite taille
lobjectif a t dobtenir un condens du du nombre segments
nous avons compar avec logiciels minds arizer c et avec word c
dans les cas de minds et word paramtre utilis a t dobtenir une synthse du taille texte
nous avons aussi demand personnes un la main choisir phrases du qui sembleraient plus pertinentes
probabilits et sont modies en tout temps de faon mutuellement exclusive lcart entre de lamliorer
on ampli car un et chang toujours avec une probabilit segment pertinent j meilleur votant branch ce moment

nmsu
edu minds summarizerdemomain
html
copernic
com les sujets ont un niveau dtudes universitaire habitus rsums
jadt journes internationales danalyse statistique donnes textuelles i n o s c d i i n o s c d i segment a segment b figure choix desegments pertinents pour letexte cortex lessegments choisis
humains


textes en franais nous avons tudi puces articiellement ambigu et compos dun mlange non homogne textes sujets puces biologiques et puces informatiques dans classication de segments par leur contenu torres moreno et al

les segments plus importantes slectionns par les humains sont le et gure
nous reproduisons sur gure nos rsultats o on voit que les segments importants ont t bien reprs
cortex montre un rsum quilibr du mme que celui obtenu par minds mme si ce dernier ne trouve ni segment ni le sur gure
par contre rsultats de word sont biaiss et peu pertinents comme on voit sur gure torres moreno et al

pour ftes les rsultats prliminaires montrent que cortex trouve rsums acceptables gure
nous avons effectu comparaisons avec summarizer huot nos condenss sont comparables voire meilleure qualit
dans dautres tests condenss trouvs par cortex semblent tre assez cohrentes
nous avons constat toujours que les condenss obtenus par sujets humains dpendent personne et ses capacits dabstraction ce qui donne fois rsultats assez carts gure et gure
malgr cela choix fait par humains semble tre une rfrence sur les segments importants mais notre mthode comparable


textes en espagnol nous avons travaill sur deux textes en espagnol nopal et tabaco
les rsultats de cortex sur nopal sont montrs sur gures et
on constate la bonne qualit du condens mme dans textes trs petit lexique
nopal possde seulement nl mots p segments et word est incapable traiter

gegi
polymtl
ca info jmtomore pvm cortex textos puces
html
quebecmicro

html
invdes
com
mx suplemento anteriores htm espina
html
invdes
com
mx suplemento anteriores htm tabaco
html jadt journes internationales danalyse statistique donnes textuelles segment a segment b figure choix de segments pour puces a par systme minds et b par synthtiseur word
i n o s c d i i n o s c d i i n o s c d i i n o s c d i segment a segment b figure choix de segments pertinents pour ftes a par systme cortex plusieurs segmentsimportants onttchoisis
humains
jadt journes internationales danalyse statistique donnes textuelles i n o s c d i i n o s c d i segment a segment b figure choix de segments pour nopal fait par cortex
les segments et qui ont une importance particulire onttbienreprs
humains

discussion

taille du lexique nous savions que grce au processus pre traitement lexique tait plus en plus rduit cest dire nl nf nm
des tudes sur ratios de rduction moyens du lexique ont t effectus sur lensemble de textes franais et espagnol
ceci nous a permis dtablir exprimentalement estimateurs l et pour lexique ltr lemmatis rduit l lexique frquentiel respectivement
si nous introduisons nm nm i nf i nl nli t ti alors f l nm t nm nl nm nous avons calcul pour textes en franais f l et
sur gures et nous montrons les valeurs de ces ratios et leurs moyennes sur lensemble textes en franais
la rduction taille lexique tr lemmatis l suit un comportement linaire par rapport au nombre original donc pour obtenir un condens dun texte avec nos mthodes on utilise seulement un seizime volume termes totaux du document
toutes ces rductions permettent diminuer maldiction dimensionnelle
finalement sur gure on montre une courbe qui modle comportement du lexique essentiel nl en fonction originale nm
de faon similaire nous avons calcul rduction du lexique pour deux textes en espagnol
nous avons constat un comportement semblable textes en franais
jadt journes internationales danalyse statistique donnes textuelles o i t a r f l p nl s e e n n e y o m f l figure textes franais
ratios de rduction lexique fonction de
f rduction aprs ltrage lemmatisation l rduction lexiquefrequentiel lafractionde par rapport au texte original moyennes ratios de rduction lexique franais calculs sur lensemble de textes
l ln e i n e s s e e u q i e l taille du figure lexique essentiel nl comme fonction taille nm
laxe horizontale rithmique
onobserve unecroissance parcimonieuse dulexique essentiel
jadt journes internationales danalyse statistique donnes textuelles e y t t r a c s e e n n e y o m i f e mtrique figure moyenne dupouvoir dediscrimination desmtriques


ordre prsentation mtriques un tude a montr prsentation mtriques a un certain impact sur mances de lad
initialement prsentation mtriques a t arbitraire puis un tude statistique a t effectu
leur pouvoir discriminatoire a t mesur comme fonction types mtriques par rapport chaque segment
en effet il y a mtriques que sont plus discriminantes que dautres
la distances dhamming entre mots lintrieur dun segment est trs discriminante
par contre les mtriques calculs dentropie ou dune valeur frquentielle semblent ltre moins
la gure montre les moyennes discriminatoire mtriques
prsentation a t
les distances dhamming
les poids dhamming lourd
le poids dhamming segments
la somme probabilits par frquence
les interactions i
la somme poids dhamming
la frquence f
lentropie e et
la somme poids dhamming
nous avons dcid donc dutiliser cette ordre prsentation mtriques lalgorithme dcision ce qui permet dobtenir un segments pertinents stable et cohrent


ordre prsentation segments nos expriences ont montr prsentation segments na aucune inuence sur choix nal lalgorithme de dcision
nous avons dcoup textes en segments et nous les avons mlang au hasard pour obtenir un nouveau texte
ce texte a t prsent nouveau cortex et mmes rsultats ont t retrouvs aussi bien en espagnol
par contre tests sur minds et word montrent que ces mthodes sont parfois dpendantes prsentation segments
en effet la segmentation phrases par sparateur a tendance perturber la pertinence ces mthodes mais pas dans notre
jadt journes internationales danalyse statistique donnes textuelles
conclusion lalgorithme cortex est un condensateur textes trs performant
cette technologie permet vastes multi langues franais espagnol sans prparation avec une taine quantit bruit manire dynamique un court lapse de temps
de plusieurs tests faits comparaison avec sujets humains ou dautres mthodes de condensation ont montr que notre algorithme capable retrouver les segments plus pertinents taille sujets abords
on obtient ainsi un rsum balanc car la plupart des thmes sont abords dans le condens nal
le logiciel summarizer munique avec demandant concepts retenir dans rsume
ceci est une approche intressant qui pourrait tre intgr dans notre algorithme de dcision bas sur votes de mtriques dj robuste convergente amplicateur indpendant prsentation segments
nous pensons que lajout dautres mtriques entropie rsiduelle dtection des changements dentropie maximum dentropie et dun identicateur automatique langues pourraient amliorer des condensations
remerciements references les auteurs tiennent remercier luniversit du qubec chicoutimi crsng canada pour leur soutien nancier
ansi
american national standards for writing abstracts
ansi inc
usa
balpe j
lelu a
papy f
and saleh i

techniques avances pour lhypertexte
ditions herms deerwester s
dumais d
furnas t
launder g
and harshman t

indexing by latent semantic analysis
journal of the amer
soc for infor
science
gravel j
martel p
and harvey l

un module pre traitement pour latao
rapport de stage huot f

copernic summarizer ou la tentation limpossible
qubec micro

leloup c

moteurs dindexation recherche
eyrolles
memmi d

le modle vectoriel pour traitement documents
cahiers leibniz paris
uqac
inpg
memmi d
gabi k
and meunier j


dynamical knowledge extraction from texts by art networks
in proc
of the marseille
memmi d
and meunier j

may
proc
of
in using competitive networks for text mining berlin
meunier j

and nault g

approche connexioniste au problme in les techniques dintelligence articielle appliques sances terminologiques partir textes
aux technologies de linformation pages
les cahiers scientiques acfas
morris a
kasper g
and adams d

the effects and limitations of automated text condensing on reading comprehension performance
in advances in automatic text summarization pages
the mit press u
s
a
saggion h
and lapalme g

concept identication and presentation in the context of technical text summarization
in automatic summarization workshop pages seattle
anlp naacl
salton g

the smart retrieval system experiments un automatic document processing
englewood cliffs
jadt journes internationales danalyse statistique donnes textuelles salton g
and mcgill m

introduction to modern information retrieval
mcgraw hill
seffah a
and meunier j


aladin an integrated object oriented environment for computer assited text analisys
cahiers recherche
lanci uqam
torres moreno j

velazquez morales p
and meunier j

cortex un algorithme pour la condensation automatique textes
in actes des colloque interdisciplinaire en sciences cognitives arco lyon
a paraitre
torres moreno j

velazquez morales p
and meunier j
mars
classphres un rseau incrmental pour lapprentissage non supervis appliqu la classication de textes
in jadt pages lausanne
epfl m
rajman j

chappelier diteurs
veronis j
ide n
and harie s

very large neural networks as a model of semantic relations
in proc
of the cognitiva symposium madrid

