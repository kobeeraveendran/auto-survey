q learning with language model for edit based unsupervised summarization ryosuke kohita ibm research akifumi wachi ibm research kohi akifumi
wachi
com yang zhao ibm research ryuki tachibana ibm research
ibm
com t c o l c
s c v
v i x r a abstract far unsupervised methods are promising for stractive textsummarization in that the lel corpora is not required
however their from being performance is still therefore research on promising ed tions is on going
in this paper we pose a new approach based on q learning with an edit based summarization
the method combines two key modules to form an torial agent and language model converter ealm
the agent predicts edit actions e
t
delete keep and replace and then the lm converter deterministically generates a mary on the basis of the action signals
learning is leveraged to train the agent to duce proper edit actions
experimental results show that ealm delivered competitive mance compared with the previous decoder based methods even with truly zero paired data i
e
no validation set
dening the task as q learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization
we also conduct qualitative analysis providing sights into future study on unsupervised marizers
introduction automatic text is an attractive nique for helping humans to grasp the content of documents effortlessly
while supervised neural methods have shown good performances see et al
zhang et al
the unsupervised proach is starting to attract interest due to its tage of not requiring costly parallel corpora
ever the empirical performance of unsupervised methods is currently behind that of state of art supervised models zhao et al
baziotis codes are available at
kohilin ealm figure overview of previous left and proposed right approaches on cr learning paradigm
et al

unsupervised text summarization is still developing and is now at the stage where various solutions should be actively explored
one previous unsupervised approach extends neural encoder decoder modeling to the zero paired data scenario where a model is trained with a paradigm called compression reconstruction cr learning miao and blunsom fevry and phang zhao et al

the mechanism is similar to that of the back translation sennrich et al
the model consists of a compressor i
e
summarizer and a reconstructor and they are co trained so that the reconstructor can recover the original sentence from the summary generated by the compressor miao and blunsom the left side of figure
experimental results showed that such an unsupervised encoder decoder based summarizer is able to learn the mapping from a tence to a summary without paired data baziotis et al
yang et al

refer to abstractive summarization in this paper
reinforcement learning rl is also a potential reconstruction evaluationcompression evaluationcompression encoder decodereditorial agentreconstructionencoder decodereditorial actions for each replace keep language model converterq learning approach with language modelconventional approach with two generatorsmachine learning is not perfectai is imperfectmachine learning is not perfectai is imperfectmachine learning is not perfectcompressionreconstructionmachine learning is not perfect solution for the no paired data situation
in related elds for example there are unsupervised ods for text simplication and text compression with policy gradient learning zhang and lapata zhao et al

recent rl techniques take a value based approach e

q learning such as dqn mnih et al
or the tion of policy and value based approaches such as asynchronous advantage actor critic mnih et al

a critical requirement to leverage a based method is a value function that represents the goodness of an action on a given state sutton et al

we can naturally dene the value tion by utilizing the cr learning paradigm and it makes the latest value based approaches available for unsupervised text summarization
in this paper we propose a new method based on q learning and an edit based summarization gu et al
malmi et al
right side of ure
the edit based summarization generates a summary by operating an edit action e

keep remove or replace for each word in the input tence
our method implements the editing cess with two modules an editorial agent that predicts edit actions and a language mmodel lm converter that deterministically decodes a sentence on the basis of action signals which we call ealm
the cr learning is dened on the learning framework to train the agent to predict edit actions that instruct the lm converter to produce a good summary
although a vast action space causing sparsity in reward such as the word eration of an encoder decoder model is generally difcult to be learned in rl our method mitigates this issue thanks to its fewer edit actions and the deterministic decoding of a language model
over the formulation by q learning enables us to incorporate the latest techniques in rl
the main contribution of this paper is that we provide a new solution in the form of an pervised edit based summarization leveraging learning and a language model
experimental sults show that our method achieved a competitive performance with encoder decoder based methods even with truly no paired data i
e
no tion set and qualitative analysis brings insights as to what current unsupervised models are ing
also the problem formulation on q learning enables us to import the latest techniques in rl which leads to potential improvements in future research
task denition we begin by formally dening the problem of supervised summarization with the cr learning
the goal of the task is to produce an informative summary y consisting of m words


ym for a given input sentence consisting of n words


xn where m
the challenge in this task is to learn the transformation from to y with only the input sentence
to tackle this the cr learning introduces an ditional transformation called reconstruction
the reconstruction requests to reproduce the input tence x from the generated summary y where x is the reproduced sentence consisting of n words


xn
in terms of the generated sentences and x let c be the compression function and r be the reconstruction function y c x r where c and r are their respective parameters
thus the task can be written as the following mization problem c r arg max y x c r where y and x are functions to return a higher value for favorable y and x in regard to the input sentence
according to the cr ing s hypothesis that the summary should contain enough information to guess the original contents y becomes favorable when the difference between and x is smaller while y maintains the essential aspects of a summary e

shortness uency
previous method the previous approaches use a generative decoder model sutskever et al
for the pression and reconstruction functions miao and blunsom fevry and phang wang and lee baziotis et al

although the jective functions and implementation details differ depending on the study the underlying motivation entails the same hypothesis as the cr learning
for example baziotis et al
introduced four objective functions discrepancy of y from a trained language model topical distance of and and the length of y and probability difference of xi and xi where the former threes can be regarded as f y and the nal one as x
while such an encoder decoder model has formed well on many generation tasks it suffers from inherent difculties related to repetition see et al
length control kikuchi et al
and exposure bias ranzato et al

it also runs into convergence problems when co training multiple generators salimans al

proposed method our proposed method which we call ealm sists of two essential modules the editorial agent and the lm converter
the agent sends action nals keep remove or replace each word in a tence to the conveter which then deterministically transforms the input sentence according to the nals
we train the agent to nd action signals so that the lm converter produces sentences demanded by the cr learning
in the following sections we rst share the background of q learning
and then present how to put the task and our approach on the q learning framework

we next explain the core algorithmic details
and nish with explanations about training and inference


preliminaries q learning is a popular approach in rl as sented by deep q networks dqn mnih et al

q learning leverages an action value tion to estimate the value of a pair of state and action with respect to a policy
the action value function i
e
q function is represented as the pected reward for the state action pair e at s a where s is a state a is an action r is a reward tion for the state action pair and is the discount factor
hence to solve a text summarization task via q learning we rst need to appropriately dene the state action and reward function

unsupervised edit based summarization with q learning in our approach given an input sentence we dene a state si in regard to each word xi
an action ai for the state is chosen from among the three options a remove keep replace
the goal of the editorial agent is to provide the timal action sequence a


an by iteratively making action decisions on each word


to obtain y and x we propose a ministic transformation algorithm based on a and the lm converter


finally we dene the reward function r to evaluate the action and action sequence in terms of the produced sentences y and x


the reward function is designed to align with the cr learning paradigm and leads the agent into bringing the action sequence that generates an appropriate y and x

algorithms in this section we describe three principle rithms how to create and to predict ai how to generate and x by means of a and the lm converter and how to compute the reward
iterative action prediction

the overall ow of iteratively predicting an action for each word is shown in figure
the agent predicts an action for a state i
e
a word one by one so we call one prediction a step and express it with a subscription t
for example and respectively denote the state and action for xi at the t th step
note that has a predicted action if the agent has already done the prediction on xi by the step otherwise is keep
also we prepare a boolean vector of length n representing the prediction statuses at the t th step is if the prediction on the i th word has been nished otherwise
the order to predict an action is determined by q values
let s and a be a action pair to be operated next which comes from the maximum q values over unoperated states where s is dened as s
the agent then reiterates the predictions until it nishes determining an action on all words
by dening the state in regard to a single word instead of a whole sentence and asking the agent to mine the prediction order we can handle variable sentence lengths in natural language
note that this is not a left to right process the agent conducts the prediction in the order of condence
next we explain how to encode
to send the agent contextual information such as the previous decisions the prediction statuses and the whole sentence we dynamically create a state with a concatenation of two encodings local encoding and global encoding
to create the two encodings rst we map xi to a xed sized vector ei with an arbitrary encoder we s a arg max a figure algorithmic visualization of iterative action prediction use bert devlin et al
and ei is repeatedly used throughout the process regardless of the steps
then we dene the local encoding as ei where and are learnable bias vectors for the action and prediction status of the i th word respectively
next we create the global encoding in a self attention fashion as j where is computed with k
figure deterministic compression and tion with masked language model thanks to the bias terms in and the attention in is aware of the previous cisions for each word and the interactions between those decisions
in addition bert encoding ei enables us to take a whole sentence into account


deterministic decoding by language model with action signals in this section we explain how to compress and reconstruct sentences in a deterministic manner used relu instead of the conventional exp cause exp caused the exploding gradient in our case
with the lm converter
for the lm converter we use bert devlin et al
which is a masked language model mlm trained to dict masked portions in a sentence
mlm can estimate the probability distribution of i th word xi in a sentence as where is the same as except that it has a mask at the i tion


mask


wang and cho
denotes a function to return a word with the highest probability for the i th position
the procedure to obtain y and x by using a



encodingglobal

















context machine learning is not perfectmachinelearningis context ai is imperfectabpreprocess conversionc and mlm is shown in figure
first we vert to a skeleton sequence consisting of n tokens


zn where zi is xi if ai is keep otherwise a null token
we then dene our pression and reconstruction functions c and r as ai l zi xi ai l zi ai replace otherwise remove replace otherwise
a word is predicted only for given by replace in compression but it does so for all in reconstruction
also we set the original tence as a prexed context which comes from in compression and in reconstruction to make mlm aware of a former meaning
an example is shown in figure where mlm receives machine learning is not perfect
mask is
as the compression input and predicts words for the
if there are multiple masks we conduct the prediction in an autoregressive fashion see pendix a

note that while any language model can be used for the lm converter mlm is geous because it utilizes before and after contexts and there is no restriction on looking ahead at coming words


stepwise reward computation in this section we explain the reward computation of the chosen action by referring to y and x
as stated in

we have an action sequence for every step t
when we apply c and r to all the we can obtain a list of tuples s a r y
a tuple let us say ence enables us to evaluate a state action pair with respect to a single transition
in this section we propose three techniques step reward olation penalty and summary assessment to evaluate the agent s behavior with the stepwise periences
refer to table to see how these work in reward computation with an actual example
before moving on to the details let us dene two important notions throughout this section sion rate cr and reconstruction rate rr xi
the cr learning assumes that the higher values of cr and rr are better
we use these for calculating rewards and pruning experiences
step reward
the task of the agent is to duce an action sequence with which the lm verter generates an appropriately compressed tence while keeping the reconstruction successful
as such we dene the reward function r as a y x rsr rsa where rsr is the step reward that are designed to encourage the agent to improve the compression and reconstruction rate respectively
rsa is an additional score from the qualitative assessment of y which we explain later
returning to the step reward rsr it is a multiplication of rc and rr dened as rsr rc rr rc rr otherwise where is a minimum requirement for the construction rate at the t th step and is dened as t n with the hyperparameter
if we set that requests perfect reconstruction then regardless of t
however we need to forgive reconstruction failure to some extent cause of the information loss in compression and adjusts the allowed number of failures
for ample
requests the model to recover at least half of the original sentence correctly
let us describe the behavior of the step reward rsr
first the reward is when the agent chooses keep or replace because rc due to there being no change in the length of y
second the ward gets a positive value when the agent chooses remove and satises the requirement for the construction rate
third the ward gets a negative value when the agent chooses remove but the reconstruction rate is less than the requirement
in short the step reward recommends remove as long as the agent can recover the nal word and otherwise keep or replace
violation penalty
sequential modeling ing that performed by our agent essentially suffers from error propagation caused by incorrect tions at an earlier stage collins and roark
the violation penalty mitigates this issue by giving a negative reward to the latest problematic action and excluding experiences after the mistake
the experiences from the beginning to t steps as dened in the step reward paragraph
let us explain the terms inside the square ets rst
the rst term which is the multiplication of and aims for shortness and mativeness
it gets a higher value when the agent achieves the right balance of compression and construction
the second term sim aims to uate informativeness brought about by replace
concretely sim returns a semantic similarity score in the range of through the sentence vectors of and rather than just checking exact matches of words
the last term llh represents uency via the log likelihood of given by a pre trained language model zhao et al

we use bert for the computation of sim and llh devlin et al
wang and cho see appendix a

nally t is the ratio of the number of operated words
it becomes closer to when the agent is reaching a termination i
e
nishing the tion on all words by avoiding the violation penalty which makes rsa larger
in contrast the agent who fails at an earlier stage gets a small value of rsa

training and inference the in the replay buffer training
leveraging experiences s a r y x lin the agent learns the policy for summarizing a sentence within the q learning framework
specically we utilize dqn mnih et al
to learn the q function q corresponding to the optimal policy by minimizing the loss es a r a where r and q is a get q function whose parameters are periodically updated in accordance with the latest network rameters
during the collection of experiences rl requires the agent to explore an action on a given state for nding a better policy
as a unique point in this work the agent must explore not only the action but also the order to predict
for both rations we use the algorithm watkins that stochastically forces the agent to ignore q values and to behave randomly see appendix a

inference
our modeling that provides y and x for each step has another advantage in terms of the inference
for the nal output we use y at the step that achieves the best balance of the compression and reconstruction ratios where t figure violation penalty for compression left and reconstruction right
the axis is step and the y axis is each ratio
the horizontal lines in the middle are and and the dashed lines represent and
the circles represent a step where the agent breaks the constraints
here in addition to we introduce the parameter which represents a minimum ment for the compression rate
denotes its threshold at the t step dened as t n and the agent must satisfy the condition
as the penalty we forcibly assign reward for the state action pair at the t step when the agent breaks either constraint of or
in tion we ignore experiences from step t and onward
if the agent keeps predicting until the end we dene t n
figure shows how these constraints work for the experience sequence
summary assessment
although the step ward considers the compression and reconstruction ratios it ignores the critical aspects of the generated summary such as replacement with a shorter onym and uency as a sentence
here we explain the rsa mentioned in the previous paragraph and describe how to reect such qualitative assessments to the reward given to the agent
as the essential properties for y we take three perspectives into account informativeness ness and uency
the informativeness refers to how much y retains the original meaning of x and the shortness and uency are self explanatory
to reect these perspectives onto the agent s decision we dene rsa as rsa t n where sim computes a similarity score of and and llh computes a log likelihood of y
and are hyperparameters to adjust the importance of sim and llh
in addition to rsr we give rsa to not used in trainingagent breaks the constraint action remove may remove the remove force type may the the may the force force force force i will always be be be be be be with with with with with with you you you you you you cr rr



t n sim llh rsr rsa







r












no experiences due to the violation occurred at the step
t table an example of stepwise reward computation
it breaks the reconstruction constraint at the step when removing force so rsr
rsa is computed at the step by






and it is used for the step and as well
the settings of hyperparameters are


and

arg
this is based on the off relationship of compression and reconstruction as seen in the precision recall curve
experiment baselines
we compare our proposed approach with three baselines lead n which simply takes the beginning n words as the summary a cent encoder decoder model baziotis et al
and cmatch a new approach without explicit reconstruction learning zhou and rush
to conduct qualitative analysis on generated maries we ran the baselines ourselves with a cated model for and the provided model for cmatch
also we test two types of els one tuned with a validation set and the other with parameters at the last iteration in the training
this is because ealm and cmatch do not need paired data even for tion
proposed method
we implemented ealm as follows
the q network of the agent consists of a two layered mlp with units per layer and relu
we used the adam optimizer with the ing rate of
and apply gradient clipping by
for the epsilon greedy strategy we rst set the exploring probability to
and decay it by plying by
every updates until it reaches the minimum exploration rate of

we set the discount factor to

the size of the replay buffer is and we sample experiences as
com cbaziotis
we ran the training script with the same conguration as the inal paper except for decreasing the batch size from to due to our gpu limitation
we trained three models and obtained slightly lower scores than the ones reported in the original paper
we report the averaged score among the three models

com unsupervised sentence summarization a batch for one update
as the nal model we use parameters at a time when the averaged score of reward in the replay buffer is maximum i
e
our model does not need a validation set
the parameters of step reward

are set to
and
respectively
the hyperparameters of summary assessment

are both set to

we train three models with the same tion and report their averaged score as q learning inherently contains randomness in training
dataset
the same as baziotis et al
we train our model on the gigaword corpus giga rush et al

however we used only k sentences randomly picked from sentences with less than words for the training of ealm
this is because the whole data
m sentences is too large to expose the agent to different ences from the same sentence
note that we used the entirety of sentences for the training of the models
we followed baziotis et al
in the uation as well using the test set consisting of the giga sentences and duc datasets with sentences with tences over et al

all models follow the same tokenization policy the default tokenization in giga and
although bert which ealm uses has its own vocabulary based on subwords we do not apply subwording to go along with a single tokenization policy
therefore words not in the bert ulary are interpreted as unknown words and the ratio of unknown words was around in giga
can be trained with the large dataset but it takes long time due to the exploitation and exploration learning strategy of q learning
k was better in the balance of the required time and the model performance
data model giga



































r l

















len

















nw











cm el cm el cm el table rouge scores averaged lengths len and averaged occurrences of new words nw
and are lead n
represent models
cm is cmatch and el is ealm
rouge scores are puted with summaries capped at the rst bytes
evaluation
in our quantitative analysis we amine the rouge scores
to mitigate the bias to longer sentences in rouge calculation we capped all summaries at the rst bytes
note that the averaged sentence length of gold summaries after the capping were

and
for giga and respectively
also we examine sentence length len and count of new words nw number of words that are used in a ated summary but do not appear in the input tence
additionally we show qualitative isons with a manual check of generated summaries
although a questionnaire survey is often conducted to assess the deeper quality of summaries such as informativeness and readability this still hides the exact points of model s strengths and weaknesses
we consider that specic indications provide sights on future work for the current unsupervised summarizers
we manually checked more than summaries for each model and each dataset and include a few samples in appendix a

results
table lists the results of rouge scores averaged lengths and averaged counts of new words
ealm showed a better performance in and with respect to and r l
in giga it performed competitively with the lines
however the original length of the generated summaries tended to be longer and the occurrence used
pltrdy following baziotis et al

cm el copy words from the top as it is grammatical informative meaningless rephrasing grammatical fluent in successful cases in giga select words from the whole input contain keywords less grammatical lack of rephrasing lack of information in and too much short in and table pros and cons found in the generated summaries of cmatch and ealm
of new words was the lowest
cmatch achieved the highest scores of rouge and meaningful length in giga
the scores of and r l were superior to others by about two points which means cmatch captured not only salient words but also word co occurrences
ever for generating summaries cmatch uses a language model trained with gold summaries in giga
in other words it may just internally store the probable word distributions in summary tences on giga
actually the results on and were not better than those on giga
even though cmatch does not require paired data it is not practical to collect enough summaries to train a language model for each domain
showed a competitive performance with other models but its scores dropped when no idation set was available
the requirement of a validation set is a keen disadvantage because ating input summary pairs comes at a signicant human labor cost
while almost all of the best scores were given by the statistical models also performed petitively
this result indicates that unsupervised summarization methods can not yet overcome the trivial baseline
one signicant barrier preventing the progress of unsupervised methods is ably the difculty of rephrasing
for writing a good summary condensing a longer expression into a shorter form is essential
as seen in the nw column in table the number of new words was less than one in cmatch and ealm
the current models tend to operate just by and paste which is consistent with the report by baziotis et al

finally we manually assess the summaries duced by each model and sum up their pros and cons in table
also actual examples are shown in input japan s nec corp
and unk computer corp
of the united states said wednesday they had agreed to join forces in puter sales
mechanical that lems threaten to shut down the astronomical vations of the hubble space telescope may prompt repair a mission six months earlier than planned to the
billion spacecraft nasa ofcials told congress on wednesday
s endeavour nauts connected the two building rst blocks of the tional space station on sunday creating a seven story tower in the shuttle cargo bay
human nec unk in computer sales tie up japan s nec corp
and her computer corp
of the united states said cmatch nec agrees to join forces in puter sales ealm nec computer united states said agreed to join forces in sales problems may stop hubble astronomical observations nasa may accelerate pair mission mechanical problems that threaten to shut down the her the vations of ble space telescope threaten nasa observes that threaten to shut down astronomical servations of space telescope may prompt repair mission six lier than planned lion spacecraft nasa ofcials told congress on building first blocks of tional space station successfully joined
s endeavour nauts connected the building two rst blocks the of ternational space station endeavour tronauts shuttle s create a connected rst ing blocks of tional space on ating tower in shuttle bay table summaries by human gold reference cmatch and ealm from giga top center and buttom
table
first we found that a summary of was likely to be an exact copy of the input sentence from the top but it kept sentences grammatical and informative
rephrasing by did not meet our expectation in most cases such as changing a week of the day e

wednesday to thursday or a common adjective to a pronoun adjective e

astronomical to her
cmatch stably generated uent summaries in giga as seen in the rouge scores
it also generated grammatically correct tences such as number agreement e

nec agrees



in the duc datasets however meaningless summaries increased such as containing no tant information e

nasa observes
relatedly cmatch s summaries on and were too short and we found that more than half of the maries consisted of less than or qeual to words
finally ealm s outputs tended to be longer due to containing non informative portions e

nasa ofcials told



it was also likely to be matical due to leaving only a functional word e

mechanical problems that threaten


or deleting required prepositions e




agreed to join



those failures resulted in lower readability
ever ealm tried to keep keywords from the whole input even though they exist at latter positions in a sentence which is also supported by the tively higher score of and r l
although this challenge caused low readable and ungrammatical summaries it is an interesting research direction to sophisticate such ealm s behavior
conclusion we brought the q learning framework into pervised text summarization and proposed a new method ealm that is an edit based unsupervised summarizer leveraging a q learning agent and a language model
the experments showed that ealm performed competitively with the previous encoder decoder based methods
however in itative analysis we found that the quality of the erated summaries of any unsupervised model was not sufcient and there are individual limitations for each model
these issue must be overcome as the step forward to generating practically available summaries without paired data
in particular for ealm there is room for improvement by ing the latest techniques in rl
our work paves the way for further research on bridging q learning and unsupervised text summarization
references christos baziotis ion androutsopoulos ioannis konstas and alexandros potamianos

differentiable sequence to sequence to sequence autoencoder for unsupervised abstractive sentence in proceedings of the compression
ference of the association for computational linguistics human language technologies pages
the north american chapter of michael collins and brian roark

incremental parsing with the perceptron algorithm
in ings of the annual meeting of the association for computational linguistics pages
jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language standing
in proceedings of the conference of the north american chapter of the association for computational linguistics human language nologies pages
thibault fevry and jason phang

vised sentence compression using denoising encoders
in proceedings of the conference on computational natural language learning pages
jiatao gu changhan wang and junbo zhao

levenshtein transformer
in proceedings of ternational conference on neural information cessing systems pages
yuta kikuchi graham neubig ryohei sasano hiroya takamura and manabu okumura

ling output length in neural encoder decoders
in proceedings of the conference on empirical methods in natural language processing pages
long ji lin

self improving reactive agents based on reinforcement learning planning and ing
machine learning
eric malmi sebastian krause sascha rothe daniil mirylenka and aliaksei severyn

encode tag realize high precision text editing
in ings of the conference on empirical methods in natural language processing and the national joint conference on natural language cessing emnlp ijcnlp pages hong kong china
association for computational guistics
yishu miao and phil blunsom

language as a latent variable discrete generative models for tence compression
in proceedings of the ference on empirical methods in natural language processing pages
volodymyr mnih badia mehdi mirza alex graves tim harley timothy p
lillicrap david silver and koray kavukcuoglu

asynchronous methods for deep ment learning
in proceedings of the tional conference on international conference on machine learning pages
volodymyr mnih koray kavukcuoglu david silver andrei a
rusu joel veness marc g
bellemare alex graves martin riedmiller andreas k
jeland georg ostrovski stig petersen charles beattie amir sadik ioannis antonoglou helen king dharshan kumaran daan wierstra shane legg and demis hassabis

human level trol through deep reinforcement learning
nature
paul over hoa dang and donna harman

duc in context
information processing management
marcaurelio ranzato sumit chopra michael auli and wojciech zaremba

sequence level ing with recurrent neural networks
in proceedings of international conference on learning sentations
alexander m
rush sumit chopra and jason weston

a neural attention model for abstractive in proceedings of the tence summarization
conference on empirical methods in natural guage processing pages
tim salimans ian goodfellow wojciech zaremba vicki cheung alec radford xi chen and xi chen

in proceedings of the neural information ing systems pages
improved techniques for training gans
abigail see peter j
liu and christopher d
manning

get to the point summarization with generator networks
in proceedings of the nual meeting of the association for computational linguistics pages
rico sennrich barry haddow and alexandra birch
improving neural machine translation
in proceedings of the els with monolingual data
annual meeting of the association for tational linguistics volume long papers pages berlin germany
association for tional linguistics
ilya sutskever oriol vinyals and quoc v
le

sequence to sequence learning with neural networks
in proceedings of the international conference on neural information processing systems pages
richard s sutton andrew g barto al

troduction to reinforcement learning volume
mit press cambridge
alex wang and kyunghyun cho

bert has a mouth and it must speak bert as a markov in proceedings of the dom eld language model
workshop on methods for optimizing and ing neural language generation pages
yaushian wang and hung yi lee

learning to encode text as human readable summaries using generative adversarial networks
in proceedings of the conference on empirical methods in ral language processing pages
christopher john cornish hellaby watkins

thesis learning from delayed rewards
king s college cambridge uk
ph
d
ziyi yang chenguang zhu robert gmyr michael zeng xuedong huang and eric darve

ted a pretrained unsupervised summarization model with theme modeling and denoising
haoyu zhang jingjing cai jianjun xu and ji wang

pretraining based natural language tion for text summarization
in proceedings of the conference on computational natural guage learning conll pages hong kong china
association for computational guistics
xingxing zhang and mirella lapata

sentence simplication with deep reinforcement learning
in proceedings of the conference on empirical methods in natural language processing pages copenhagen denmark
association for computational linguistics
yang zhao zhiyuan luo and akiko aizawa

a language model based evaluator for sentence pression
in proceedings of the annual ing of the association for computational linguistics pages
jiawei zhou and alexander rush

simple supervised summarization by contextual matching
in proceedings of the annual meeting of the association for computational linguistics pages florence italy
association for tational linguistics
a appendices a
autoregressive prediction with mlm algorithm describes the autoregressive prediction with mlm which we used when an input contains multiple masks
algorithm autoregressive prediction with mlm a sentence after replacing all input a sentence that includes outpit with predicted words i xi while i do for j i do wj end for j arg max ji xj wj i end while p a
exploration of prediction order as explained in section
in the main paper the editorial agent explores the order to predict
while the agent basically chooses a state with a maximum q value as the next state we sometimes pick a most uncertain state instead
we dene the uncertainty of a state by the entropy of action probabilities as aa a log a and then s and a are selected as s arg max a arg max
sst aa a
semantic similarity and log likelihood computation in summary assessment semantic similarity
we use a pre trained model to predict the semantic similarity of sentences with their bert encodings
the model is trained in a supervised manner with a pair of sentences and their similarity score
the original library outputs a real valued score in the range of whereas we normalize it to
log likelihood
we compute the log likelihood of a compressed sentence by using bert as lows wang and cho m im yi

com semantic text similarity however our llh function performs thresholding namely it returns if the score is beyond a old otherwise because the raw log likelihood score is not scaled with the other rewards
we empirically set the threshold to

a
relaxations in calculation the calculation of the reconstruction rate duced in section

is based on an exact match of each word of and x
given the ambiguity of natural language this is very strict so the agent rarely acquires rewards
we relax this situation by excluding stop words in the calculation and comparing with top k candidates
therefore the equation of rr can be formally re written as xi xi w xi w where returns top k probable words for the i th position and w is a pre dened set of words
we set k
we used common stopwords e

him the and infrequent words in giga for w
a
experimental details computing infrastructure
we run the models on a machine with the below specications ubuntu

ram gb nvidia tesla model size
in ealm the number of trainable parameters was in our experimental setting which is all for the editorial agent
there are no trainable parameters for the language model
hypperparameter search
we did not conduct a hyperparameter search
we empirically mined the values described in the main paper the proposed method paragraph in
runtime speed
ealm processes a sentence in three seconds pm average on the above gpu
a
generated summaries samples of the summaries generated by each model are listed in the tables on the following next pages
these examples are taken from the rst sentences for giga and randomly picked for and
we also include human generated maries i
e
gold reference
input japan s nec corp
and unk computer corp
of the united states said wednesday they had agreed to join forces in puter sales
the sri lankan ernment on day announced the sure of government schools with ate effect as a tary campaign against tamil separatists lated in the north of the country
police arrested ve anti nuclear protesters thursday after they sought to disrupt ing of a french tic research and supply vessel a spokesman for the protesters said
factory orders for ufactured goods rose
percent in ber the commerce department said here thursday
the bank of japan appealed to nancial markets to remain calm friday following the us decision to bank order daiwa to close its us ltd
operations
croatian president franjo tudjman said friday croatian and negotiators serb would meet saturday an to thrash agreement the last serb held area in croatia under a deal reached at us brokered talks
japan s toyota team europe were banned from the world rally championship for one year here on friday in a crushing ruling by the world council of the international bile federation a
out on human nec unk in computer sales tie up japan s nec corp
and her computer corp
of the united states said cmatch nec agrees to join forces in puter sales ealm nec computer united states said agreed join forces in sales lanka sri schools escalates as closes war the sri lankan ment on thursday nounced the closure of government schools with immediate tary country sri lankan government announces military campaign against tamil separatists sri lankan government closure announced schools government as military effect campaign escalated north country protesters french research ship target police arrest ve nuclear protesters police arrested ve anti nuclear protesters tuesday they sought to disrupt her of antarctic protesters after factory orders for ufactured goods rose
percent in ber the bank of japan appealed to nancial markets to remain calm thursday ing decision us september factory orders up
percent factory orders rise
percent in september bank of unk unk for calm in nancial markets the bank of daiwa ltd
to close its us tions police arrested after sought disrupt loading of french antarctic search supply vessel spokesman for said factory orders factured goods rose september commerce said here bank japan appealed nancial markets to main calm following us decision order bank to close us operations rebel serb talks to sume saturday man by peter unk croatian president franjo tudjman said thursday croatian and serb negotiators would meet saturday to agreement talks croatian president franjo tudjman says serb negotiators will meet croatian said ian serb would meet thrash out an ment on last area tia under deal reached at talks toyota are banned for a year japan s toyota team europe were banned from the world rally championship for one here a europe banned is from the world one pionship year for japan team toyota europe banned from world rally onship for year here in ruling council international automobile
crushing table summaries by human gold reference cmatch and ealm from giga space input mechanical problems that threaten to shut down the astronomical the observations of hubble scope may prompt repair mission a six months earlier than planned to the
billion craft nasa ofcials told on congress wednesday
perhaps no city offers a more public ple of the problems of homelessness than san francisco the biggest complaint itors lodge about the city concerns the gressive panhandling and other tions of homelessness that they experience say city tourist cials
atlanta maybe just maybe customers who pay to use bank atm machines are ginning to ght back or maybe they re just getting smarter
the head of turkey s pro islamic party said thursday he would not insist on his rightful chance to lead turkey s next government heading off a frontation with the itary that would only deepen the nation s political crisis
bombers suicide targeted a crowded market open air setting off friday blasts killed that the two assailants injured shoppers and passersby and prompted the israeli cabinet to put off action on the new peace accord
president nelson dela acknowledged saturday the african congress national violated human rights during apartheid ting him at odds with his deputy president over a report that has divided much of south africa
human problems may stop hubble astronomical observations nasa may accelerate repair mission mechanical problems that threaten to shut down the her vations of the ble space telescope threaten
cmatch nasa observes lack of affordable housing basic to san francisco s homeless crisis
perhaps no city offers a more public example of the problems of her than san offers more public tourist francisco city san lidge bank customers ning to resist double charges on atm use
atlanta maybe just maybe customers who pay to use bank machines getting atlanta gets smarter broad based ist coalition likely in turkey
the head of turkey s her party said tuesday he would not insist on rightful turkey s crisis
the head of turkey s pro islamic party possible early tion of car bomb still injures bombers killed suicide bombers geted a crowded air market tuesday setting off blasts that killed assailants cord
israeli cabinet puts off accord on nelson president mandela edges anc rights other violations
leaders disagree
president clinton dela acknowledged saturday the african congress national violated human rights during apartheid setting africa nelson mandela knowledges human rights ealm that threaten to shut down astronomical servations of space telescope may prompt repair mission six lier than planned lion spacecraft nasa cials told congress on perhaps no city fers more public ample of problems of than san francisco complaint lodge about city concerns sive and other of that experience say city tourist ofcials atlanta maybe just maybe customers who pay to use bank atm machines beginning ght or maybe getting smarter head of turkey party said he would insist rightful chance to lead turkey next ment heading off frontation with tary that would only nation political crisis suicide bombers geted crowded market setting off blasts that killed two injured and and prompted the israeli cabinet to put off action on new peace accord mandela national edged congress violated human during setting at odds with deputy president over report that divided much of south table summaries by human gold reference cmatch and ealm from
input two endeavour s nauts connected the building blocks of the tional space station on sunday creating a seven story tower in the shuttle cargo bay
in a cocoon of loyal and wealthy ers president clinton said friday that he must live with the consequences of his mistakes although that he contended should democrats in the take pride achievements of his presidency and take heart from its possibilities
on the eve of a holiday that has been linked to antiabortion violence the authorities on day were investigating whether a picture of an aborted fetus sent to a canadian newspaper was connected to last month s fatal shooting of a buffalo n

tor who provided tions or four similar tacks in western new york and canada since
famine threatened north korea s harvest will be no better this year than last and could be worse a senior u
n
aid ofcial said saturday
matthew wayne ard the gay student who was beaten in the dead of night tied to a fence and left to die alone was mourned at his funeral friday by people cluding many who had never met him
a delegation of chilean lobbying legislators against the possible extradition of augusto pinochet to spain to warned face trial thursday that chile was on the brink of political turmoil
human first building blocks of international space station successfully joined
clinton supports candidates speaks at fundraisers edges mistakes
endeavour s nauts connected the building two rst blocks the of space ternational station in a her of loyal and wealthy supporters president clinton said tuesday that must of loyal and wealthy porters clinton
cmatch s create endeavour tronauts shuttle a ealm connected rst ing blocks of tional space on ing tower in shuttle bay democrats take pride in presidency anti abortion yer in canada may be related to buffalo clinic ing on the eve of a holiday that has been linked to her violence ties of holiday that has been linked to her lence on the eve of a holiday loyal and in a of supporters wealthy clinton president live said that must with consequences of mistakes although he that should pride in achievements of presidency and heart from possibilities on eve of holiday that has been linked to olence on ing picture of an sent to canadian newspaper was connected to last month fatal shooting of buffalo doctor who provided or similar tacks in western new york and canada since world food program reports famine may have killed million north koreans her north korea s vest will be no ter this year than last worse south korea s zhan north korea harvest better last could worse senior aid ofcial said matthew shepard logized as one who wanted to make ple s lives better matthew wayne her the gay student who was beaten in the dead of night gay student who was beaten him us ceos gay who beaten in dead of night tied to fence and left to die alone was at funeral by including who had met legislators chilean protest in madrid against extradition of pinochet a delegation of chilean legislators lobbying against the possible extradition of augusto face pinochet turmoil to delegation of chilean legislators faces trial delegation of chilean legislators lobbying against possible of augusto spain to trial warned chile on brink of political turmoil table summaries by human gold reference cmatch and ealm from

