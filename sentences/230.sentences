vizseq a visual analysis toolkit for text generation tasks changhan wang anirudh danlu chen and jiatao gu facebook ai research stanford university changhan danluchen
com
edu p e s l c
s c v
v i x r a abstract automatic evaluation of text generation tasks e

machine translation text tion image captioning and video description usually relies heavily on task specic metrics such as bleu papineni et al
and rouge lin
they however are stract numbers and are not perfectly aligned with human assessment
this suggests specting detailed examples as a complement to identify system error patterns
in this paper we present vizseq a visual analysis toolkit for instance level and corpus level system uation on a wide variety of text generation tasks
it supports multimodal sources and tiple text references providing visualization in jupyter notebook or a web app interface
it can be used locally or deployed onto public servers for centralized data hosting and ing
it covers most common n gram based metrics accelerated with multiprocessing and also provides latest embedding based metrics such as bertscore zhang et al

introduction many natural language processing nlp tasks can be viewed as conditional text generation lems where natural language texts are generated given inputs in the form of text e

machine translation image e

image captioning dio e

automatic speech recognition or video e

video description
their automatic ation usually relies heavily on task specic rics
due to the complexity of natural language expressions those metrics are not always perfectly aligned with human assessment
moreover rics only produce abstract numbers and are limited in illustrating system error patterns
this suggests the necessity of inspecting detailed evaluation amples to get a full picture of system behaviors as figure an overview of vizseq
vizseq takes modal sources text references as well as model tions as inputs and analyzes them visually in jupyter notebook or in a web app interface
it can also be used without visualization as a normal python package
well as seek improvement directions
a bunch of softwares have emerged to tate calculation of various metrics or ing examples with sentence level scores in an tegrated user interface ibleu madnani mteval mt compareval klejch et al
nlg eval sharma et al
vis eval ric viewer steele and specia mt neubig et al

quite a few of them are collections of command line scripts for ric calculation which lack visualization to ter present and interpret the scores
some of them are able to generate static html reports to present charts and examples but they do not low updating visualization options interactively
mt compareval is the only software we found that has an interactive user interface
it is ever written in php which unlike python lacks a complete nlp eco system
the number of rics it supports is also limited and the software is no longer being actively developed
support of multiple references is not a prevalent dard across all the softwares we investigated and work carried out during an internship at facebook

com odashi mteval sourcestextimageaudioreferencestext n predictionsmodel textmodel textmodel k text vizseqweb appjupyter notebookvideoevaluate
pymulti processscorers source type example tasks text image audio video multimodal machine translation text summarization dialog generation grammatical error rection open domain question answering image captioning visual question ing optical character recognition speech recognition speech translation video description multimodal machine translation table example text generation tasks supported by vizseq
the sources can be from various modalities
metrics vizseq mt eval eval bleu chrf meteor ter ribes gleu nist rouge cider wer laser bertscore table comparison of vizseq and its counterparts on n gram based and embedding based metric coverage
none of them supports multiple sources or sources in non text modalities such as image audio and video
almost all the metric implementations are single processed which can not leverage the tiple cores in modern cpus for speedup and better scalability
with the above limitations identied we want to provide a unied and scalable solution that gets rid of all those constraints and is enhanced with a user friendly interface as well as the nlp technologies
in this paper we present vizseq a visual analysis toolkit for a wide riety of text generation tasks which can be used for instance level and corpus level system ror analysis exploratory dataset analysis public data hosting and system benchmarking
it provides visualization in jupyter notebook or a web app interface
a system overview can be found in figure
we open source the software at
com facebookresearch vizseq
figure vizseq implements metrics with cessing speedup
speed test is based on a tion set for bleu meteor and chrf and a one for cider
cpu intel core
main features of vizseq
multimodal data and task coverage vizseq has built in support for multiple sources and references
the number of references is lowed to vary across different examples and the sources are allowed to come from different ities including text image audio and video
this exibility enables vizseq to cover a wide range of text generation tasks and datasets far beyond the scope of machine translation which previous wares mainly focus on
table provides a list of example tasks supported by vizseq

metric coverage and scalability table shows the comparison of vizseq and its counterparts on metric coverage
n gram based metrics to the extent of our knowledge vizseq has the best coverage of mon n gram based metrics including bleu ineni et al
nist doddington teor banerjee and lavie ter snover et al
ribes isozaki et al
chrf popovic and gleu wu et al
for machine translation rouge lin for summarization and video description cider vedantam et al
for image ing and word error rate for speech recognition
embedding based metrics n gram based rics have difculties in capturing semantic ilarities since they are usually based on act word matches
as a complement vizseq also integrates latest embedding based metrics such as bertscore zhang et al
and laser artetxe and schwenk
this is rarely seen in the counterparts
scalability we re implemented all the n based metrics with multiprocessing allowing from vizseq
scorers import name def hypothesis references int verbose bool false return figure vizseq metric api
users can dene and ister their new metric by implementing this function
users to fully utilize the power of modern core cpus
we tested our multi process versions on large evaluation sets and observed signicant speedup against original single process ones see figure
vizseq s embedding based metrics are implemented using pytorch paszke et al
framework and their computation is automatically parallelized on cpu or gpu by the framework
versatility vizseq s rich metric collection is not only available in jupyter notebook or in the web app it can also be used in any python scripts
a typical use case is periodic metric calculation during model training
vizseq s implementations save time especially when evaluation sets are large or evaluation is frequent
to allow dened metrics we designed an open metric api whose denition can be found in figure

user friendly interface given the drawbacks of simple command line terface and static html interface we aim at alized and interactive interfaces for better user perience and productivity
vizseq provides alization in two types of interfaces jupyter book and web app
they share the same visual analysis module figure
the web app interface additionally has a data uploading module ure and a task dataset browsing module ure while the jupyter notebook interface gets data directly from python variables
the analysis module includes the following parts
example grouping vizseq uses sentence tags to manage example groups data subsets of ent interest can be overlapping
it contains both user dened and machine generated tags e

bels for identied languages long sentences tences with rare words or code switching
rics will be calculated and visualized by different figure vizseq example viewing
keyword search box tag and model lters sorting and page size tions left example index right user dened tags blue and machine generated tags grey modal sources and google translate integration model predictions with highlighted matched blue and unmatched red n grams sentence level scores highest ones among models in boldface lowest ones in italics with underscore
example groups as a complement to scores over the entire dataset
example viewing vizseq presents examples with various sentence level scores and visualized alignments of matched unmatched reference it also has google grams in model predictions
translate integration to assist understanding of text sources in unfamiliar languages as well as providing a baseline translation model
ples are listed in multiple pages bookmarkable in web app and can be sorted by various orders for example by a certain metric or source sentence lengths
tags or n gram keywords can be used to lter out examples of interest
statistics vizseq provides various dataset including counts of corpus level statistics sentences tokens and characters source and reference length distributions token frequency distribution list of most frequent n grams with links to associated examples distributions of sentence level scores by models figure and
statistics are visualized in zoomable charts with hover text hints
data export statistics in vizseq are one click exportable charts into png or svg images with figure vizseq dataset statistics
sentence ken and character counts for source and reference tences length distributions of source and reference sentences token frequency distribution
plots are zoomable and exportable to svg or png images
figure vizseq corpus level metric viewing
tributions of sentence level scores by models click export of tabular data to csv and latex copied to clipboard corpus level and group level by tence tags scores highest ones among models in face lowest ones in italics with underscore
figure vizseq dataset statistics most frequent grams
each listed n gram is clickable to show associated examples in the dataset
users zooming applied and tables into csv or latex copied to clipboard

data management and public hosting vizseq web app interface gets new data from the data uploading module figure or a ful api
besides local deployment the web app back end can also be deployed onto public servers and provide a general solution for hosting public benchmarks on a wide variety of text generation tasks and datasets
in vizseq data is organized by special folder structures as follows which is easy to maintain
txt zip
txt
txt
txt
json when new data comes in scores n grams and machine generated tags will be pre computed and cached onto disk automatically
a le monitoring and versioning system based on le hashes sizes or modication timestamps is employed to detect figure vizseq sentence tag distribution view
in this example tags are source target language directions in a multilingual machine translation dataset
le changes and trigger necessary updates on computed results
this is important for ing evaluation during model training where model predictions change over training epochs
example use cases of vizseq we validate the usability of vizseq with multiple tasks and datasets which are included as examples in our github repository english a classic size dataset for bilingual machine translation
a text summarization dataset
coco captioning lin et al
a classic image captioning dataset where vizseq can present source images with text targets

statmt
org translation task
html
com harvardnlp sent summary scriptions with presence of video contents
related work with the thrive of deep learning task agnostic visualization toolkits such as and have emerged in need of monitoring model statistics and debugging model training
model interpretability is another vation for visualization
in nlp softwares have been developed to interpret model parameters e

attention weights and inspect prediction tion process lm rong and adar nmt visualization tool klein et al
and strobelt et al

for machine lation toolkits are made to perform metric lation and error analysis ibleu madnani mteval mt compareval klejch et al
nlg eval sharma et al
vis eval metric viewer steele and specia and mt neubig et al

conclusion in this paper we present vizseq a visual ysis toolkit for text image audio text generation system evaluation dataset analysis and benchmark hosting
it is accessible as a web app or a python package in jupyter notebook or python scripts
vizseq is currently under active development and our future work includes abling image to text and video to text alignments adding human assessment modules tion with popular text generation frameworks such as and
acknowledgments we thank the anonymous reviewers for their ments
we also thank ann lee and pratik shia for helpful discussions on this project
references mikel artetxe and holger schwenk

sively multilingual sentence embeddings for arxiv shot cross lingual preprint

transfer and beyond

com tensorow tensorboard
com facebookresearch visdom
com microsoft tensorwatch
com odashi mteval
com pytorch fairseq
com opennmt opennmt py
com tensorow figure vizseq data uploading
users need to nize the les by given folder structures and pack them into a zip le for upload
vizseq will unpack the les to the data root folder and perform integrity checks
figure vizseq task dataset browsing
users need to select a dataset and models of interest to proceed to the analysis module
multimodal machine translation task english german translation with an image the sentences describe
vizseq can present both text and image sources and calculate the ofcial bleu meteor and ter metrics
multilingual machine translation on ted talks dataset ye et al
translation from languages into english
vizseq can use guage directions as sentence tags to generate score breakdown by languages
the test set has as many as examples where vizseq process scorers run signicantly faster than single process ones
the integrated google translate can help with understanding source sentences in unfamiliar languages
english german speech vizseq can present english audios with english transcripts and german text translations
youcook das et al
video description vizseq enables inspecting generated text
statmt
org multimodal task
html
google
com site satanjeev banerjee and alon lavie

meteor an automatic metric for mt evaluation with improved correlation with human judgments
in proceedings of the acl workshop on intrinsic and extrinsic ation measures for machine translation marization pages
pradipto das chenliang xu richard f doell and son j corso

a thousand frames in just a few words lingual description of videos through latent topics and sparse object stitching
in proceedings of the ieee conference on computer vision and pattern recognition pages
george doddington

automatic evaluation of machine translation quality using n gram occurrence statistics
in proceedings of the second international conference on human language nology research pages
morgan mann publishers inc
hideki isozaki tsutomu hirao kevin duh katsuhito sudoh and hajime tsukada

automatic uation of translation quality for distant language in proceedings of the conference on pairs
empirical methods in natural language ing pages
association for computational linguistics
guillaume klein yoon kim yuntian deng vincent nguyen jean senellart and alexander m
rush

opennmt neural machine translation toolkit
ondrej klejch eleftherios avramidis aljoscha chardt and martin popel

mt compareval graphical evaluation interface for machine tion development
the prague bulletin of matical linguistics
chin yew lin

rouge a package for matic evaluation of summaries
text summarization branches out
tsung yi lin michael maire serge belongie james hays pietro perona deva ramanan piotr dollar and c lawrence zitnick

microsoft coco in european common objects in context
ence on computer vision pages
springer
nitin madnani

ibleu interactively debugging and scoring statistical machine translation systems
in ieee fifth international conference on mantic computing pages
ieee
graham neubig zi yi dou junjie hu paul michel danish pruthi and xinyi wang

compare mt a tool for holistic comparison of language tion systems
arxiv preprint

kishore papineni salim roukos todd ward and jing zhu

bleu a method for automatic in proceedings of uation of machine translation
the annual meeting on association for tational linguistics pages
association for computational linguistics
adam paszke sam gross soumith chintala gory chanan edward yang zachary devito ing lin alban desmaison luca antiga and adam lerer

automatic differentiation in pytorch
in nips autodiff workshop
maja popovic

chrf character n gram score for automatic mt evaluation
in proceedings of the tenth workshop on statistical machine translation pages
xin rong and eytan adar

visual tools for bugging neural language models
in proceedings of icml workshop on visualization for deep ing
shikhar sharma layla el asri hannes schulz and jeremie zumer

relevance of unsupervised metrics in task oriented dialogue for evaluating ural language generation
corr

matthew snover bonnie dorr richard schwartz nea micciulla and john makhoul

a study of translation edit rate with targeted human annotation
in proceedings of association for machine tion in the americas volume
david steele and lucia specia

vis eval metric viewer a visualisation tool for inspecting and uating metric scores of machine translation output
in proceedings of the conference of the north american chapter of the association for tional linguistics demonstrations pages
hendrik strobelt sebastian gehrmann michael behrisch adam perer hanspeter pster and alexander m rush

a visual debugging tool for sequence to sequence models
ieee transactions on visualization and computer graphics
ramakrishna vedantam c lawrence zitnick and devi parikh

cider consensus based image in proceedings of the ieee scription evaluation
conference on computer vision and pattern nition pages
yonghui wu mike schuster zhifeng chen quoc v le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey et al

google s neural chine translation system bridging the gap between arxiv preprint human and machine translation


qi ye sachan devendra felix matthieu han sarguna and neubig graham

when and why are pre trained word embeddings useful for neural machine translation
in hlt naacl
tianyi zhang varsha kishore felix wu kilian q weinberger and yoav artzi

bertscore arxiv preprint uating text generation with bert



