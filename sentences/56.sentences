p e s
p a

t a t s
v
v i x r a large scale analysis of zipf s law in english texts isabel moreno sanchez francesc font clos alvaro recerca edici c campus bellaterra barcelona spain
facultat de universitat de barcelona barcelona spain dated september despite being a paradigm of quantitative linguistics zipf s law for words suers from three main problems its formulation is ambiguous its validity has not been tested rigorously from a statistical point of view and it has not been confronted to a representatively large number of texts
so we can summarize the current support of zipf s law in texts as anecdotic
we try to solve these issues by studying three dierent versions of zipf s law and tting them to all available english texts in the project gutenberg database consisting of more than texts
to do so we use state of the art tools in tting and goodness tests carefully tailored to the peculiarities of text statistics

remarkably one of the three versions of zipf s law consisting of a pure power law form in the complementary cumulative distribution function of word frequencies is able to t more than of the texts in the database at the signicance level for the whole domain of frequencies
from to the maximum value and with only one free parameter the exponent
pacs numbers introduction
zipf s law constitutes a striking quantitative regularity in the usage of language

it states that for a large enough piece of text the frequency of use n of any word decreases with its rareness r in the text in an r where the symbol mately hyperbolic way n denotes proportionality
technically r is called the rank and the most common less rare word is signed r the second most common r and so on
a slightly more general formulation includes a parameter in the form of an exponent then the rank frequency relation takes the form of a power law n r

with the value of close to one

this pattern has been found across dierent guages literary styles time periods and levels of phological abstraction

more fascinatingly the same law has been claimed in other codes of tion as in music or for the timbres of sounds and also in disparate discrete systems where individual units or agents gather into dierent classes for example employees into rms believers into religions sects into plants units of mass into animals present in ecosystems visitors or links into web pages telephone calls to users or abundance of proteins
in a single cell

the attempts to nd an tion have been diverse but no solution has raised consensus


despite its quantitative character zipf s law has been usually checked for in a qualitative way plotting the arithm of the frequency n versus the logarithm of the rank r and looking for some domain with a roughly
a more ear behavior with slope more or less close to rened approach consists in tting a straight line to the double logarithmic plot by linear regression
but several authors have recently pointed out the limitations of this method when applied to probability distributions
and the advantages of using an cally unbiased and minimum variance procedure such as maximum likelihood ml estimation whose tions moreover are invariant under reparameterizations

one should consider then ml estimation as the most reliable procedure of estimation for parametric models when a maximum of the likelihood does exist and the number of data is large

furthermore for the particular case of linguistics the search for zipf s law has been traditionally performed in very limited sets of texts less than a dozen in a typical research article
more recently however large corpora have been considered these are representative collections of dierent texts aggregated together into a single bag so instead of many separated texts one deals with one enormous mixed text
when rare words are not considered for high frequencies it seems that
zipf s law still holds in these large collections

at present there is agreement that zipf s law is a rough approximation in lexical statistics but its range of lidity is totally unknown we ignore how good zipf s law is in order to account for the appearance of words and for which texts it should work and with which level of precision and for which texts it should fail

an extra diculty emerges when one recognizes the dened nature of zipf s law

in fact the law has two formulations with the rst one being eq
which just counts the frequency of words
for the sake of clarity the words that are counted are referred to as word types in order to distinguish them from each repetition which is called a token
the second formulation of zipf s law arises when after counting the frequency of word types one performs a second statistics and counts how many values of the frequency are repeated that is how many word types have the same frequency
this means that the frequency n is considered the random variable
one can realize that the rank when normalized by its imum value in text is just the empirical estimation of the complementary cumulative distribution function of n and then the derivative of the expression for
the inverse of eq
yields a continuous approximation for the probability mass function of the frequency
from here one obtains another power law n with the new exponent fullling which yields values of close to
the expression given by eq
was in fact the rst approach followed by zipf s himself
and is usually considered as equivalent to eq

however as it is derived in the continuum limit both expressions can only be lent asymptotically for large n
consequently if one wants to be precise a natural question follows which one is the true zipf s law if any

we can not know a priori which of the two zipf s laws better describes real texts but we can argue which of the two representations that of or that of n is better for statistical purposes dently of the functional dependency they provide
it is clear that the rank frequency representation given by presents several diculties due to the peculiar ture of the rank variable
first in ref
zipf like texts were randomly generated following eq

ing the original ranks hidden as it happens in the real situation and it was found that the rank reconstructed from the sample deviated considerably from the original ranks when these were taking large values which for a power law happens with a high probability
the ing ml estimations of the exponent were highly biased and the kolmogorov smirnov test rejected the power law hypothesis although the original ranks were power law indeed

one might argue that the problem could be escaped by using an upper truncated power law distribution ducing then an additional parameter for the truncation in order to avoid the inconsistency of the rank sentation for high values
but a second problem is that the rank is not a true random variable as its values are assigned a posteriori once the sample the text is analyzed
this means that the rank does not show enough statistical uctuations that is if ra rb then the frequency of a is always larger by construction than the frequency of
this does not necessarily happen for a true random variable
the negative correlation tween the variable and its frequency of occurrence makes the power law hypothesis harder to reject

in fact ated p values not uniformly distributed between and have been found when tting truncated power laws to simulated power law rank frequency representations

this problem could still be avoided by choosing a low enough upper truncation parameter yielding a very short range of ranks for which the uctuations would be very little but at the expense of disregarding an tant part of the data

a third inconvenience is the impossibility due to ization that a non truncated power law comprises values of the exponent smaller than
this yields the sity of introducing a truncation parameter that may be artifactual not present in the real system
all this leads to the conclusion that the most reliable method of parameter estimation ml in a frequentist framework can not be directly applied to the rank frequency sentation
in contrast the representation in terms of the distribution of frequencies is devoid of these problems
as n is a well dened random variable and this will be the representation used in this paper for statistical ference
nevertheless for alternative arguments see ref


the purpose of this paper is to quantify at a large big data scale dierent versions of zipf s law and their ranges of validity
in the next section we present and tify the three zipf like distributions we are going to and we briey explain the selected tting method and the goodness test
the corpus of texts under ation is also detailed
the following section presents the results with special attention to their statistical cance and their dependence with text length
finally we end with the conclusions and some technical appendices
zipf like distributions n changing as implicit in the introduction and in contrast with continuous random variables in the discrete case a power law in the probability mass function does not lead to a power law in the complementary lative distribution or survival function and versa
let us specify our denition for both functions
n as usual and
for convenience the usual strict inequality sign by the non strict inequality

then the relation between both is and
we consider that the values the random variable takes given by n are discrete starting at the integer value a taking values then n a a
up to innity
in this study we will x the parameter a to a in order to
t the whole distribution and not just the tail
then though for large n and smooth we may approximate
this simplication which lies in the n equivalence between eqs
and is clearly wrong for small
for the rst distribution that we consider the power law

form is in f n then whereas
n

this is just the normalized version of eq
and then n
a with and

a denotes the hurwitz zeta function which ensures normalization of both expressions
a preliminary analysis in terms of this distribution was done in ref

in contrast when the power law is in this leads to our second case a n a n and and a n with again
note that this corresponds to a power law in the empirical rank frequency relation

finally it is interesting to consider also the frequency distribution derived by mandelbrot when ranks are generated independently from a power law in eq
which is
with and
denotes the gamma function
in this case the power law is the derlying theoretical rank frequency relation
note that can be written as using the beta function

y with an analogous expression for but do not confuse this distribution with the beta distribution

in all three cases it is easy to show that we have dened normalized probability distributions when n takes values n a a
with a being a positive integer
moreover in the limit n all of them yield n so will be referred to as a power law tail
the power law exponent
indeed it is easy to show that n n using stirling s formula
the main dierence tween the three distributions is in the smaller values of n taking a convex shape in log scale as seen from above a concave one and being somehow in between as it is neither concave nor convex
methodology and data
in order to t these three distributions to the dierent texts and test the goodness of such ts we use maximum likelihood estimation followed by the smirnov ks test
the procedure seems similar to the one proposed in ref
but as a is xed here the problems resulting from the search of the optimum a
do not arise in this case

the method of ml estimation proceeds in the following simple way
given a set of data with i
n and a probability mass function parameterized by noted as f n
n the log likelihood function is obtained as ni
ln ni
n a
we are assuming that the data points ni are

dent from each other in other words we are calculating the likelihood that the data are generated independently from f n
the ml estimation of is obtained as the value of which maximizes we undertake this
in the case of numerically using brent s method
the distribution the log likelihood function takes the ln g with g the simple form
geometric mean of the set
for the other
ni tions no closed form expression is possible and we use eq

directly

as mentioned the goodness test is done through the kolmogorov smirnov statistic in the discrete case for which the value is calculated from
monte
carlo simulations due to the fact that as the value of the exponent is calculated from the same data is going to be tested the theoretically computed p value would be positively biased
in this paper we use monte carlo simulations for each test
the proper simulation of the distributions is explained in the appendix

ber that a small enough value leads to the rejection of the t
although we perform multiple testing we do not incorporate any bonferroni like correction due to the fact that these corrections increase the number of non rejected null hypothesis that is decrease the
ber of type i errors inating the performance of the ts in the case of goodness tests
without like corrections our acceptance non rejection of the ts is more strict

in order to apply this methodology we consider a set of texts stored in encoding in the project gutenberg database accessed july

these texts correspond to dierent languages styles and time periods although most of them are works of literature from the western cultural tradition
first of all parts of text that do not pertain to the piece under sideration copyright notes headers are removed by an automatized process
books that have not been tered in this step mainly because they do not have dard delimiters are discarded
after this we still keep of the total
to perform our study we restrict ourselves to the subset of texts in english which represent the of these

an important characteristic of each text is its length l counting the number of word tokens it contains
it turns out to be that in the database l expands from very small values up to tokens with a distribution that is shown in fig

observe the roughly uniform tion up to about l and the decay afterwards

we consider only the english texts that consist of more than word tokens as smaller texts would not have statistical value
for each of these texts we select then actual word types punctuation signs numbers and any character dierent from letters are not considered to count their frequencies n which will be our primary object of study

the values of these frequencies for each text are able on in order to facilitate the reproducibility of our results

in summary we apply the above described tting and goodness procedure using ml estimation and the kolmogorov smirnov test to a total of texts from the english project gutenberg database using three ferent possibilities for the distribution of frequencies
eq
eq
and eq

this yields a ts and associated p values which we total of analyze and interpret in what follows
results contrary to previous studies where the number of texts considered was at most in the order of tens the scale approach taken in this work requires a statistical analysis of the tting results as a case by case tation is out of hand
we rst focus on the distribution of p values see fig and fig

if all texts were truly generated by a mechanism following a given distribution the corresponding p values for that distribution would be uniformly distributed between zero and one
as seen in fig
this is not the case and furthermore most texts have rather small p values for the three ts nevertheless fig
estimation of the probability density function of text length l in the english project gutenberg database using logarithmic binning bins per decade
texts with less than tokens are not considered
a power law t of the tail yields an exponent
for distributions and there are still many texts that yield high enough p values
this implies that although we can not conclude that the whole database is generated by any of these distributions these can not be rejected as good descriptions for large subsets of the database
garding distribution it is clear from the histogram of p values that it can be discarded as a good description of the distribution of frequencies in any non negligible subset of texts
so from now on we will concentrate on the remaining options and to eventually quantify
which of these better describes our corpus
in essence what we are interested in is which version of zipf s law either distribution or ts better a reasonable ber of texts and which range of validity these simple one parameter distributions have

the outcome is that independently of the signicance level as long as this is not below our resolution of given the number of monte carlo simulations the tio between the number of texts tted by distribution and those tted by is nearly constant taking a value around
for example considering signicance level minimum p value equal to fig
shows that distribution ts about of all texts whereas tribution ts just
both percentages include a of texts that are tted by both distributions taneously although this number does not keep a stant ratio with the other two rather it decreases when the signicance level is increased as it is implicit in the values of fig

given that the aforementioned ratio of is independent of the signicance level it is fair to say that distribution provides compared to a better description of our database
as a visual tion of the performance of the ts we display in fig
the word frequency distribution of the longest texts that have p for distributions and fig

histograms of p values obtained when the like distributions and are tted to the texts of the english project gutenberg
the histograms just count the number of texts in each bin of width
note the poor performance of distribution and the best performance of
power law approximations to the histograms for and with respective exponents and are shown as a guide to the eye
fig
complementary cumulative distributions vival functions of p values obtained when our three tions are tted to the texts of the english project gutenberg

this corresponds except for normalization to the integral of the previous gure but we have included a fourth curve for the fraction of texts whose p values for ts and are both higher than the value marked in the abscissa
note that the values of p can play the role of the signicance level
the value for p is not shown in order to have higher resolution

the next question we address is the dependence of the performance of ts on text length
in order to asses this note that from the shape of the histograms in fig
we can distinguish two groups of texts those that lie in fig
complementary cumulative distribution and bility mass function of texts a chronicle of london from to
the letters of charles and mary lamb edited by lucas a popular history of france from
i by guizot
these texts are the earliest times vol

the ones with the largest length l and respectively of those that fulll p for ts and respectively
the exponent takes values and in each case
numberoftextsp the zero bin whose p value is strictly less than and the rest
taking the last group texts with p and partitioning it into dierent subsets according to text length looking at the distribution of p conditioned to p for dierent ranges of l it holds that the shape of the resulting distribution of p does not strongly depend on l as shown in fig

in contrast the number of texts that yield p value near zero certainly varies with l see fig

therefore in order to compare the performances of and as a function of the text length l it is enough to consider a single value of the signicance level greater than zero as the results for any other signicance level will be the same in relative terms
indeed fig shows how distribution ts some more texts than distribution for small values of l up to about tokens
but for larger texts distribution clearly outperforms distribution which becomes relevant for l beyond at signicance level whereas distribution is able to t many texts with l larger than
the gure shows that this is the case no matter if the signicance level is or the collapse of the curves in fig
conrms this fact
from fig
one could infer the same for signicance level equal to
this stability of the performance of the ts for dierent signicance levels arises from the served fact that the distributions of p values conditioned to p are nearly identical for dierent l as shown in fig


in order to check the consistency of our tting procedure we also perform a direct comparison of models through the likelihood ratio lr test

we apply this test to all texts that have been tted considering as signicance level by at least one of the two tions and
then the log likelihood ratio between distributions and is ln n and under the null hypothesis that both models are equally good to describe the data should be mally distributed with zero mean and a variance that can be estimated as n with the variance of the random ln
large absolute values of variable ln will lead to the rejection of the null hypothesis

table i merges the results of the lr test and our ous procedure based on ml estimation plus the ks test

the total number of texts previously tted by or and is displayed depending on the sign of the ing log ratio
however we must take into account that the sign of the obtained value of could be a product of just statistical uctuations if the true value were zero and thus the sign of can not be trusted in order to discriminate between two models
the bility under the null hypothesis of obtaining an absolute value of the log ratio greater than the empirical value fig
estimated probability density functions of p values conditioned to p separating for dierent ranges of text length values correspond to the tting of word cies to a distribution and distribution
we vide the distribution of text length into intervals of texts each
for distribution only the rst seven groups up to length are displayed beyond this value we do not have enough statistics to see the distribution of p values greater than as displayed in fig
for distribution this happens only in the last two groups
the intervals li range from
to

is computed through
where erfc is the complementary error function
we will take as statistically signicant those that yield plr
equivalently at signicance level is signicant if its absolute value is greater than rc

the results are shown in table ii
note that the lr test can not conclude if a t is good or bad as it only compares the relative performance of two ts in other words if the lr test selects a particular distribution that distribution can still yield a bad t in absolute terms
anyway there is no mismatch between fig
number of texts with p value near zero p in dierent ranges of l divided by the number of texts in the same ranges for the ts of distributions and
values of
l denote the geometric mean of ranges containing texts each
the higher value for t except for l below about tokens denotes its worst performance
the results of both tests any time the ml ks method selects one distribution over the other the lr test

ther supports the selection or does not give signicant results but it never selects the other option as shown in table ii
exclusively
exclusively
and
total lr
total ml ks table
i
the number of texts that are tted by or or both at signicance level of the ml ks procedure separated into two columns according to the sign of

positive means that the likelihood for is greater than that for and conversely for negative
nevertheless the sign of is not an indication of signicance for signicant lr tests see table ii
taking now those texts whose frequency distributions could be approximated by or we draw attention to the distribution of the estimated exponents the parameter
the original formulation of zipf s law plies and fig
shows that is certainly tributed around with a bell like shape
if we check the eect of the text length l in the distribution of we nd a decreasing trend of with l as can be seen in fig


we have tested that this observation is not an artifact fig

histograms showing the fraction of accepted texts by the three distributions as a function of their text length for three dierent signicance levels upper curves middle lower
to be concrete for each range of l the ratio between the number of texts with p and the number of texts in that range is calculated
same curves removing those for distribution under rescaling

we rescale the yaxis by the number of p in each case showing that the relative performance of each t with regard l is independent on the signicance level
bins are selected to contain texts each
exclusively
exclusively
and
total lr test
none neither nor
rc rc


table ii number of texts with a signicant lr test at
the level either favouring distribution rc or distribution rc for dierent outcomes of the ml ks procedure at the level also
note that these cases correspond to a subset of the previous table
an tional row shows the number of texts that are tted neither by distribution nor notice that in this case a signicant lr test does not guarantee a good t

fig
estimation of the probability density of the nent for texts yielding p in t and t
curves have been calculated from the histograms via normal nel smoothing method as implemented in matlab ksdensity function
estimated mean and standard deviation are and respectively for and and for t
of the tting method as synthetic texts generated with xed do not show this behavior
we have no cal explanation for this fact but notice that this trend is not in disagreement with the claims of ref
where the stability of the exponent was demonstrated for a single growing text comparing small parts of a text with the whole conclusions
zipf s law is probably the most intriguing and at the same time well studied experimental law of quantitative linguistics and extremely popular in its wider sense in the science of complex systems
although the previous literature is vast as far as we know our work constitutes the rst large scale analysis of zipf s law in single aggregated texts
thus we are in a position to make a well grounded statement about the validity of zipf s law in such texts

let us rst briey summarize however some key nical points of our study
first we have analyzed a total of english texts from the project
database using rigorous tting procedures and have tested how well they are described by three zipf like tributions
our choice of distributions has not been
haustive rather we have limited ourselves to dierent terpretations of what can be understood as zipf s law in the sense of having a perfect power law either in the probability mass function of word frequencies or in the complementary cumulative distribution function whose empirical estimation leads to the rank frequency relation of the sample or in the rank frequency relation of an fig
estimated probability density of for ts with in dierent length ranges
we have divided both groups of accepted texts into percentiles according to as in the previous gure the normal kernel smoothing method is applied

for distribution
for distribution
underlying population
remarkably the resulting butions have a unique parameter which in all cases is the exponent of an asymptotic power law in the bility mass function of the frequency
it is left to explore how other more complicated extensions of zipf s law
form on this large corpus but it is obvious that by cluding additional parameters one might provide good ts to a larger number of texts although in this case proper model selection will require to balance number of parameters and parsimony
our aim in this paper has not been to t as many texts as possible but to test the performance of the simplest like distributions within a very strict conservative work
indeed by requiring the three versions of zipf s law to hold on the full range of frequencies n

and not only on the tail of the distribution we put selves in the strictest range of demands
it is hence markable that at the standard signicance level of and for text lengths between and word kens more than of the considered texts are cally compatible with the pure power law in the mentary cumulative distribution function represented by distribution see fig
so we can state that for the corpus under consideration the most appropriate version of zipf s law is given by a probability mass function
n n or equivalently by a complementary cumulative bution function
n
due to the broad coverage of the project gutenberg corpus
we speculate that this distribution should t a large fraction of generic non technical english texts

of course testing this speculation in front of all possible corpora is an impossible task

we have also shown that our conclusions regarding the relative performance of a pure power law in the ability mass function given by distribution distribution are robust with respect to changes in the signicance level about twice as many texts are tically compatible with distribution than those
patible with at any signicance level obviously in absolute terms the number of accepted texts varies with the signicance level
hence we can conclude that tribution gives a better description of english texts than distribution at least for the corpus considered in this work
we also conclude that distribution rst derived by mandelbrot is irrelevant for the tion of texts in this corpus
finally we have corroborated that the exponent of zipf s law certainly varies from text to text as had been previously claimed using other approaches for dening what zipf s law is
ingly the value originally proposed by zipf himself is among the most frequent ones

we believe that our analysis constitutes a major ment in the understanding of zipf s law
it is astonishing how good the simplest one parameter zipf like tions perform on such a large set of texts particularly with the strict set of requirements we have imposed
this is in sharp contrast for instance with zipf s law in raphy and in the distribution of income where the power law seems to be valid only for the tail sponding to the largest sizes as it happens also for the distribution of word frequency in large text corpora as mentioned above

zipf s law has been subject to much debate and will probably continue to be so for many years
indeed one can always cast doubt on its validity on the basis of some particular examples
yet it seems clear to us that in our modern times of big data and large computational pabilities more eorts should be put towards large scale analysis of zipf s law
we hope this paper constitutes a rst step in this direction
appendix simulation of discrete
zipf like distributions
as part of the testing procedure we need simulated ples from and which are discrete distributions dened for n a a
we will give the recipe of simulation for an arbitrary positive integer value of the lower cut o it is simpler to start with as this is used as an auxiliary distribution in the simulation of the other two

simulation of
fixed a and given the parameter we want a set of random numbers whose cumulative tion function is a discrete power law
a

for that we rst generate a random number u from a uniform distribution in the interval umax with umax

if we take it turns out to be that the values of yield a continuous power law with sc
a where the script c distinguishes the continuous distribution from its discrete analogous one
so taking n equal to the integer part of x n yields a discrete distribution with

as desired
this is so because for any x n for n integer
in a recipe
for n is equivalent to x generate u from a uniform distribution in calculate take n

by means of the so called rejection method lated integers distributed following can be used for the simulation of integers following or
the key point to achieve a high performance in the rejection method is to use a good auxiliary function one that leads to a low rejection rate
this is certainly the case in our framework as explained below

simulation of
in this case the steps are generate n from generate v from a uniform distribution in the unit interval n is accepted if v and rejected otherwise where c is the rejection constant given by c it is easy to check that the maximum of is reached at n a as this is a decreasing function
the acceptance condition above can be simplied by taking and then the dition becomes
which is devoid of the calculation of the hurwitz zeta function
this is a generalization for a of the method of ref

the choice of as the auxiliary distribution function is justied by the small value that c takes as
this is the expected number of generated values of n until we accept one
for instance for and a we get c
simulation of
proceeding similarly we get in this case low values of c as well we get c in the limit for a
the maximum of is numerically seen to be reached at n
in summary the steps are generate n from generate v from a uniform distribution in the unit interval n is accepted if
a
a a

a and rejected otherwise
acknowledgments
we are grateful to the project gutenberg initiative and to those who help maintain it alive
pueyo provided bibliographic wisdom for zipf s law in ecology and serra assistance for ml estimation
enjoys a tract from the collaborative mathematics project of la caixa foundation
research projects in which this work is included are from spanish mineco and from agaur
baayen
word frequency distributions
kluwer drecht

baroni
distributions in text

in ludeling and kyto editors corpus linguistics an international handbook volume pages
mouton de gruyter berlin
zanette
statistical patterns in written language
arxiv
piantadosi
zipf s law in natural language a ical review and future directions
psychon
bull


zanette and montemurro
dynamics of text eration with realistic zipf s distribution
quant
guist
corral boleda and ferrer i cancho
zipf s law for word frequencies word forms versus lemmas in long texts
plos one
corral boguna haro and ll

cos
measuring the evolution of contemporary western popular music
sci

haro herrera and corral
zipf s law in short time timbral codings of speech music and environmental sound signals
plos one

li
zipf s law everywhere
glottom


axtell
zipf distribution of rm sizes
science
clauset shalizi and newman
law distributions in empirical data
siam
pueyo and jovani
comment on a keystone
tualism drives pattern in a power function
science

camacho and sole
scaling in ecological size spectra
europhys
lett

adamic and huberman
zipf s law and the internet
glottometrics
newman
power laws pareto distributions and zipf s law
cont
phys
furusawa and kaneko
zipf s law in gene sion
phys
lett
simon
on a class of skew distribution functions
biomet
miller
some eects of intermittent silence
am
psychol
ferrer i cancho and sole
least eort and the origins of scaling in human language
proc
natl
acad

sci


mitzenmacher
a brief history of generative els for power law and lognormal distributions
internet
math
saichev malevergne and sornette
theory of
zipf s law and of general power law distributions with gibrat s law of proportional growth
lecture notes in economics and mathematical systems
springer verlag berlin

corominas murtra fortuny and sole
gence of zipf s law in the evolution of communication

phys
e

peterson dixit and dill
a maximum tropy framework for nonexponential distributions
proc

natl
acad
sci
usa

corominas murtra hanel and thurner


derstanding scaling through history dependent processes with collapsing sample space
proc
natl
acad
sci
usa

ferrer i cancho and elvevag
random texts do not exhibit the real zipf s law like rank distribution
plos
one
dickman moloney and altmann

sis of an information theoretic model for communication
stat
mech theory exp page
li miramontes and cocho
fitting ranked linguistic data with two parameter functions
entropy

goldstein morris and yen
problems with tting to the power law distribution
eur
phys
b
bauke
parameter estimation for power law
tions by maximum likelihood methods
eur
phys
b
white enquist and green
on ing the exponent of power law frequency distributions

ecol
casella and berger
statistical inference
duxbury pacic grove ca edition
deluca and corral
fitting and goodness test of non truncated and truncated power law distributions

acta geophys

font clos boleda and corral
a scaling law beyond zipf s law and its relation with heaps law
new phys
ferrer i cancho and sole
two regimes in the frequency of words and the origin of complex lexicons
zipf s law revisited
quant
linguist


petersen
tenenbaum havlin ley and perc
languages cool as they expand lometric scaling and the decreasing need for new words

sci

gerlach and altmann
stochastic model for the vocabulary growth in natural languages
phys
x

williams bagrow danforth and dodds
text mixing shapes the anatomy of frequency distributions a modern zipan mechanics for natural language
arxiv

mandelbrot
on the theory of word frequencies and on related markovian models of discourse
in son editor structure of language and its mathematical aspects pages
american mathematical society providence ri
corral and ferrer i cancho
in preparation
kolmogorov
foundations of the theory of bility
chelsea pub
new york edition
altmann and gerlach
statistical laws in guistics
arxiv
font clos and corral
log log convexity of type token growth in zipf s systems
phys
lett

abramowitz and stegun editors
handbook of mathematical functions
dover new york
pawitan
in all likelihood statistical modelling and inference using likelihood
oxford up oxford

press teukolsky vetterling and flannery
numerical recipes in cambridge university press cambridge edition
corral font and camacho
non characteristic half lives in radioactive decay
phys
e

corral deluca and ferrer i cancho
a cal recipe to t discrete power law distributions
arxiv
abdi
bonferroni and sidak corrections for multiple comparisons

in salkind editor encyclopedia of measurement and statistics pages
sage sand oaks

bland and altman
multiple signicance tests the bonferroni method
brit
med


benjamini and hochberg
controlling the false covery rate a practical and powerful approach to tiple testing
roy
stat
roc
b
project gutenberg


wikipedia accessed august
gutenberg

vuong
likelihood ratio tests for model selection and non nested hypotheses
econometrica

malevergne pisarenko and sornette
testing
the pareto against the lognormal distributions with the uniformly most powerful unbiased test applied to the tribution of cities
phys
e

dragulescu and yakovenko
exponential and power law probability distributions of wealth and income in the united kingdom and the united states
physica
a
devroye
non uniform random variate generation

springer verlag new york

