p e s p a
t a t s v
v i x r a large scale analysis of zipf s law in english texts isabel moreno sanchez francesc font clos alvaro recerca edici c campus bellaterra barcelona spain
facultat de universitat de barcelona barcelona spain dated september despite being a paradigm of quantitative linguistics zipf s law for words suers from three main problems its formulation is ambiguous its validity has not been tested rigorously from a statistical point of view and it has not been confronted to a representatively large number of texts
so we can summarize the current support of zipf s law in texts as anecdotic
we try to solve these issues by studying three dierent versions of zipf s law and tting them to all available english texts in the project gutenberg database consisting of more than texts
to do so we use state of the art tools in tting and goodness tests carefully tailored to the peculiarities of text statistics
remarkably one of the three versions of zipf s law consisting of a pure power law form in the complementary cumulative distribution function of word frequencies is able to t more than of the texts in the database at the
signicance level for the whole domain of frequencies from to the maximum value and with only one free parameter the exponent
pacs numbers introduction zipf s law constitutes a striking quantitative regularity in the usage of language
it states that for a large enough piece of text the frequency of use n of any word decreases with its rareness r in the text in an r where the symbol mately hyperbolic way i
e
n denotes proportionality
technically r is called the rank and the most common i
e
less rare word is signed r the second most common r and so on
a slightly more general formulation includes a parameter in the form of an exponent then the rank frequency relation takes the form of a power law n r
with the value of close to one
this pattern has been found across dierent guages literary styles time periods and levels of phological abstraction
more fascinatingly the same law has been claimed in other codes of tion as in music or for the timbres of sounds and also in disparate discrete systems where individual units or agents gather into dierent classes for example employees into rms believers into religions sects into plants units of mass into animals present in ecosystems visitors or links into web pages telephone calls to users or abundance of proteins in a single cell
the attempts to nd an tion have been diverse but no solution has raised consensus
despite its quantitative character zipf s law has been usually checked for in a qualitative way plotting the arithm of the frequency n versus the logarithm of the rank r and looking for some domain with a roughly
a more ear behavior with slope more or less close to rened approach consists in tting a straight line to the double logarithmic plot by linear regression
but several authors have recently pointed out the limitations of this method when applied to probability distributions and the advantages of using an cally unbiased and minimum variance procedure such as maximum likelihood ml estimation whose tions moreover are invariant under reparameterizations
one should consider then ml estimation as the most reliable procedure of estimation for parametric models when a maximum of the likelihood does exist and the number of data is large
furthermore for the particular case of linguistics the search for zipf s law has been traditionally performed in very limited sets of texts less than a dozen in a typical research article
more recently however large corpora have been considered these are representative collections of dierent texts aggregated together into a single bag so instead of many separated texts one deals with one enormous mixed text
when rare words are not considered i
e
for high frequencies it seems that zipf s law still holds in these large collections
at present there is agreement that zipf s law is a rough approximation in lexical statistics but its range of lidity is totally unknown i
e
we ignore how good zipf s law is in order to account for the appearance of words and for which texts it should work and with which level of precision and for which texts it should fail
an extra diculty emerges when one recognizes the dened nature of zipf s law
in fact the law has two formulations with the rst one being eq
which just counts the frequency of words
for the sake of clarity the words that are counted are referred to as word types in order to distinguish them from each repetition which is called a token
the second formulation of zipf s law arises when after counting the frequency of word types one performs a second statistics and counts how many values of the frequency are repeated that is how many word types have the same frequency
this means that the frequency n is considered the random variable
one can realize that the rank when normalized by its imum value in text is just the empirical estimation of the complementary cumulative distribution function of n and then the derivative of the expression for the inverse of eq
yields a continuous approximation for the probability mass function of the frequency n
from here one obtains another power law n with the new exponent fullling which yields values of close to
the expression given by eq
was in fact the rst approach followed by zipf s himself and is usually considered as equivalent to eq
however as it is derived in the continuum limit both expressions can only be lent asymptotically for large n
consequently if one wants to be precise a natural question follows which one is the true zipf s law if any we can not know a priori which of the two zipf s laws better describes real texts but we can argue which of the two representations that of eq
or that of n eq
is better for statistical purposes dently of the functional dependency they provide
it is clear that the rank frequency representation given by presents several diculties due to the peculiar ture of the rank variable
first in ref
zipf like texts were randomly generated following eq
ing the original ranks hidden as it happens in the real situation and it was found that the rank reconstructed from the sample deviated considerably from the original ranks when these were taking large values which for a power law happens with a high probability
the ing ml estimations of the exponent were highly biased and the kolmogorov smirnov test rejected the power law hypothesis although the original ranks were power law indeed
one might argue that the problem could be escaped by using an upper truncated power law distribution ducing then an additional parameter for the truncation in order to avoid the inconsistency of the rank sentation for high values
but a second problem is that the rank is not a true random variable as its values are assigned a posteriori once the sample i
e
the text is analyzed
this means that the rank does not show enough statistical uctuations that is if ra rb then the frequency of a is always larger by construction than the frequency of b
this does not necessarily happen for a true random variable
the negative correlation tween the variable and its frequency of occurrence makes the power law hypothesis harder to reject
in fact ated p values not uniformly distributed between and have been found when tting truncated power laws to simulated power law rank frequency representations
this problem could still be avoided by choosing a low enough upper truncation parameter yielding a very short range of ranks for which the uctuations would be very little but at the expense of disregarding an tant part of the data
a third inconvenience is the impossibility due to ization that a non truncated power law comprises values of the exponent smaller than
this yields the sity of introducing a truncation parameter that may be artifactual i
e
not present in the real system
all this leads to the conclusion that the most reliable method of parameter estimation ml in a frequentist framework can not be directly applied to the rank frequency sentation
in contrast the representation in terms of the distribution of frequencies is devoid of these problems as n is a well dened random variable and this will be the representation used in this paper for statistical ference
nevertheless for alternative arguments see ref

the purpose of this paper is to quantify at a large big data scale dierent versions of zipf s law and their ranges of validity
in the next section we present and tify the three zipf like distributions we are going to and we briey explain the selected tting method and the goodness test
the corpus of texts under ation is also detailed
the following section presents the results with special attention to their statistical cance and their dependence with text length
finally we end with the conclusions and some technical appendices
zipf like distributions n changing as implicit in the introduction and in contrast with continuous random variables in the discrete case a power law in the probability mass function does not lead to a power law in the complementary lative distribution or survival function and versa
let us specify our denition for both functions n as usual and for convenience the usual strict inequality sign by the non strict inequality
then the relation between both is and we consider that the values the random variable takes given by n are discrete starting at the integer value a taking values then n a a


up to innity
in this study we will x the parameter a to a in order to t the whole distribution and not just the tail
then though for large n and smooth we may approximate this simplication which lies in the n equivalence between eqs
and is clearly wrong for small n
for the rst distribution that we consider the power law
form is in f n then whereas
n this is just the normalized version of eq
and then n a with and a denotes the hurwitz zeta function which ensures normalization of both expressions
a preliminary analysis in terms of this distribution was done in ref

in contrast when the power law is in this leads to our second case a n a n and and a n with again
note that this corresponds to a power law in the empirical rank frequency relation
finally it is interesting to consider also the frequency distribution derived by mandelbrot when ranks are generated independently from a power law in eq
which is with and denotes the gamma function
in this case the power law is the derlying theoretical rank frequency relation
note that can be written as using the beta function y with an analogous expression for but do not confuse this distribution with the beta distribution
in all three cases it is easy to show that we have dened normalized probability distributions when n takes values n a a


with a being a positive integer
moreover in the limit n all of them yield n so will be referred to as a power law tail the power law exponent
indeed it is easy to show that n n using stirling s formula
the main dierence tween the three distributions is in the smaller values of n taking a convex shape in log scale as seen from above a concave one and being somehow in between as it is neither concave nor convex
methodology and data in order to t these three distributions to the dierent texts and test the goodness of such ts we use maximum likelihood estimation followed by the smirnov ks test
the procedure seems similar to the one proposed in ref
but as a is xed here the problems resulting from the search of the optimum a do not arise in this case
the method of ml estimation proceeds in the following simple way
given a set of data with i


n and a probability mass function parameterized by noted as f n n the log likelihood function is obtained as ni ln ni
n a we are assuming that the data points ni are dent from each other in other words we are calculating the likelihood that the data are generated independently from f n
the ml estimation of is obtained as the value of which maximizes we undertake this in the case of numerically using brent s method
the distribution the log likelihood function takes the ln g with g the simple form geometric mean of the set
for the other ni tions no closed form expression is possible and we use eq
directly
as mentioned the goodness test is done through the kolmogorov smirnov statistic in the discrete case for which the value is calculated from monte carlo simulations due to the fact that as the value of the exponent is calculated from the same data is going to be tested the theoretically computed p value would be positively biased
in this paper we use monte carlo simulations for each test
the proper simulation of the distributions is explained in the appendix
ber that a small enough value leads to the rejection of the t
although we perform multiple testing we do not incorporate any bonferroni like correction due to the fact that these corrections increase the number of non rejected null hypothesis that is decrease the ber of type i errors inating the performance of the ts in the case of goodness tests
without like corrections our acceptance i
e
non rejection of the ts is more strict
in order to apply this methodology we consider a set of texts stored in encoding in the project gutenberg database accessed july
these texts correspond to dierent languages styles and time periods although most of them are works of literature from the western cultural tradition
first of all parts of text that do not pertain to the piece under sideration copyright notes headers


are removed by an automatized process
books that have not been tered in this step mainly because they do not have dard delimiters are discarded
after this we still keep
of the total i
e

to perform our study we restrict ourselves to the subset of texts in english which represent the of these i
e

an important characteristic of each text is its length l counting the number of word tokens it contains
it turns out to be that in the database l expands from very small values up to tokens with a distribution that is shown in fig

observe the roughly uniform tion up to about l and the decay afterwards
we consider only the english texts that consist of more than word tokens as smaller texts would not have statistical value
for each of these texts we select then actual word types punctuation signs numbers and any character dierent from letters are not considered to count their frequencies n which will be our primary object of study
the values of these frequencies for each text are able on



gshare
in order to facilitate the reproducibility of our results
in summary we apply the above described tting and goodness procedure using ml estimation and the kolmogorov smirnov test to a total of texts from the english project gutenberg database using three ferent possibilities for the distribution of frequencies eq
eq
and eq

this yields a ts and associated p values which we total of analyze and interpret in what follows
results contrary to previous studies where the number of texts considered was at most in the order of tens the scale approach taken in this work requires a statistical analysis of the tting results as a case by case tation is out of hand
we rst focus on the distribution of p values see fig
and fig

if all texts were truly generated by a mechanism following a given distribution the corresponding p values for that distribution would be uniformly distributed between zero and one
as seen in fig
this is not the case and furthermore most texts have rather small p values for the three ts nevertheless fig
estimation of the probability density function of text length l in the english project gutenberg database using logarithmic binning bins per decade
texts with less than tokens are not considered
a power law t of the tail yields an exponent


for distributions and there are still many texts that yield high enough p values
this implies that although we can not conclude that the whole database is generated by any of these distributions these can not be rejected as good descriptions for large subsets of the database
garding distribution it is clear from the histogram of p values that it can be discarded as a good description of the distribution of frequencies in any non negligible subset of texts
so from now on we will concentrate on the remaining options and to eventually quantify which of these better describes our corpus
in essence what we are interested in is which version of zipf s law either distribution or ts better a reasonable ber of texts and which range of validity these simple one parameter distributions have
the outcome is that independently of the signicance level as long as this is not below our resolution of
given the number of monte carlo simulations the tio between the number of texts tted by distribution and those tted by is nearly constant taking a value around

for example considering signicance level i
e
minimum p value equal to
fig
shows that distribution ts about of all texts whereas tribution ts just
both percentages include a
of texts that are tted by both distributions taneously although this number does not keep a stant ratio with the other two rather it decreases when the signicance level is increased as it is implicit in the values of fig

given that the aforementioned ratio of
is independent of the signicance level it is fair to say that distribution provides compared to a better description of our database
as a visual tion of the performance of the ts we display in fig
the word frequency distribution of the longest texts that have p
for distributions and
fig
histograms of p values obtained when the like distributions and are tted to the texts of the english project gutenberg
the histograms just count the number of texts in each bin of width

note the poor performance of distribution and the best performance of
power law approximations to the histograms for and with respective exponents
and
are shown as a guide to the eye
fig
complementary cumulative distributions i
e
vival functions of p values obtained when our three tions are tted to the texts of the english project gutenberg
this corresponds except for normalization to the integral of the previous gure but we have included a fourth curve for the fraction of texts whose p values for ts and are both higher than the value marked in the abscissa
note that the values of p can play the role of the signicance level
the value for p is not shown in order to have higher resolution
the next question we address is the dependence of the performance of ts on text length l
in order to asses this note that from the shape of the histograms in fig
we can distinguish two groups of texts those that lie in fig
complementary cumulative distribution and bility mass function of texts a chronicle of london from to the letters of charles and mary lamb edited by e
v
lucas a popular history of france from i by f
guizot
these texts are the earliest times vol
the ones with the largest length l and respectively of those that fulll p for ts and respectively
the exponent takes values

and
in each case
numberoftextsp

















massfunctionts the zero bin whose p value is strictly less than
and the rest
taking the last group i
e
texts with p
and partitioning it into dierent subsets according to text length i
e
looking at the distribution of p conditioned to p
for dierent ranges of l it holds that the shape of the resulting distribution of p does not strongly depend on l as shown in fig

in contrast the number of texts that yield p value near zero certainly varies with l see fig

therefore in order to compare the performances of and as a function of the text length l it is enough to consider a single value of the signicance level greater than zero as the results for any other signicance level will be the same in relative terms
indeed fig
shows how distribution ts some more texts than distribution for small values of l up to about tokens
but for larger texts distribution clearly outperforms distribution which becomes relevant for l beyond at
signicance level whereas distribution is able to t many texts with l larger than
the gure shows that this is the case no matter if the signicance level is

or
the collapse of the curves in fig
conrms this fact
from fig
one could infer the same for signicance level equal to

this stability of the performance of the ts for dierent signicance levels arises from the served fact that the distributions of p values conditioned to p
are nearly identical for dierent l as shown in fig

in order to check the consistency of our tting procedure we also perform a direct comparison of models through the likelihood ratio lr test
we apply this test to all texts that have been tted considering
as signicance level by at least one of the two tions and
then the log likelihood ratio between distributions and is ln n and under the null hypothesis that both models are equally good to describe the data should be mally distributed with zero mean and a variance that can be estimated as n with the variance of the random ln
large absolute values of variable ln will lead to the rejection of the null hypothesis
table i merges the results of the lr test and our ous procedure based on ml estimation plus the ks test
the total number of texts previously tted by or and is displayed depending on the sign of the ing log ratio
however we must take into account that the sign of the obtained value of could be a product of just statistical uctuations if the true value were zero and thus the sign of can not be trusted in order to discriminate between two models
the bility under the null hypothesis of obtaining an absolute value of the log ratio greater than the empirical value fig
estimated probability density functions of p values conditioned to p
separating for dierent ranges of text length l
values correspond to the tting of word cies to a distribution and distribution
we vide the distribution of text length into intervals of texts each
for distribution only the rst seven groups up to length are displayed beyond this value we do not have enough statistics to see the distribution of p values greater than
as displayed in fig
for distribution this happens only in the last two groups
the intervals li range from to
is computed through where erfc is the complementary error function
we will take as statistically signicant those that yield plr

equivalently at
signicance level is signicant if its absolute value is greater than rc

the results are shown in table ii note that the lr test can not conclude if a t is good or bad as it only compares the relative performance of two ts in other words if the lr test selects a particular distribution that distribution can still yield a bad t in absolute terms
anyway there is no mismatch between







fig
number of texts with p value near zero p
in dierent ranges of l divided by the number of texts in the same ranges for the ts of distributions and
values of l denote the geometric mean of ranges containing texts each
the higher value for t except for l below about tokens denotes its worst performance
the results of both tests any time the ml ks method selects one distribution over the other the lr test ther supports the selection or does not give signicant results but it never selects the other option as shown in table ii
exclusively exclusively and total lr total ml ks table i the number of texts that are tted by or or both at
signicance level of the ml ks procedure separated into two columns according to the sign of
positive means that the likelihood for is greater than that for and conversely for negative
nevertheless the sign of is not an indication of signicance for signicant lr tests see table ii
taking now those texts whose frequency distributions could be approximated by or we draw attention to the distribution of the estimated exponents i
e
the parameter
the original formulation of zipf s law plies and fig
shows that is certainly tributed around with a bell like shape
if we check the eect of the text length l in the distribution of we nd a decreasing trend of with l as can be seen in fig

we have tested that this observation is not an artifact fig
histograms showing the fraction of accepted texts by the three distributions as a function of their text length for three dierent signicance levels
upper curves
middle
lower
to be concrete for each range of l the ratio between the number of texts with p and the number of texts in that range is calculated
same curves removing those for distribution under rescaling
we rescale the yaxis by the number of p in each case showing that the relative performance of each t with regard l is independent on the signicance level
bins are selected to contain texts each
exclusively exclusively and total lr test none neither nor rc rc table ii number of texts with a signicant lr test at the
level either favouring distribution rc or distribution rc for dierent outcomes of the ml ks procedure at the
level also
note that these cases correspond to a subset of the previous table
an tional row shows the number of texts that are tted neither by distribution nor notice that in this case a signicant lr test does not guarantee a good t














fig
estimation of the probability density of the nent for texts yielding p
in t and t
curves have been calculated from the histograms via normal nel smoothing method as implemented in matlab ksdensity function
estimated mean and standard deviation are
and
respectively for and
and
for t
of the tting method as synthetic texts generated with xed do not show this behavior
we have no cal explanation for this fact but notice that this trend is not in disagreement with the claims of ref
where the stability of the exponent was demonstrated for a single growing text i
e
comparing small parts of a text with the whole
conclusions zipf s law is probably the most intriguing and at the same time well studied experimental law of quantitative linguistics and extremely popular in its wider sense in the science of complex systems
although the previous literature is vast as far as we know our work constitutes the rst large scale analysis of zipf s law in single aggregated texts
thus we are in a position to make a well grounded statement about the validity of zipf s law in such texts
let us rst briey summarize however some key nical points of our study
first we have analyzed a total of english texts from the project database using rigorous tting procedures and have tested how well they are described by three zipf like tributions
our choice of distributions has not been haustive rather we have limited ourselves to dierent terpretations of what can be understood as zipf s law in the sense of having a perfect power law either in the probability mass function of word frequencies or in the complementary cumulative distribution function whose empirical estimation leads to the rank frequency relation of the sample or in the rank frequency relation of an fig
estimated probability density of for ts with
in dierent length ranges
we have divided both groups of accepted texts into percentiles according to l
as in the previous gure the normal kernel smoothing method is applied
for distribution
for distribution
underlying population
remarkably the resulting butions have a unique parameter which in all cases is the exponent of an asymptotic power law in the bility mass function of the frequency
it is left to explore how other more complicated extensions of zipf s law form on this large corpus but it is obvious that by cluding additional parameters one might provide good ts to a larger number of texts although in this case proper model selection will require to balance number of parameters and parsimony
our aim in this paper has not been to t as many texts as possible but to test the performance of the simplest like distributions within a very strict conservative work
indeed by requiring the three versions of zipf s law to hold on the full range of frequencies n


and not only on the tail of the distribution we put selves in the strictest range of demands
it is hence markable that e

at the standard signicance level of
and for text lengths between and word

















kens more than of the considered texts are cally compatible with the pure power law in the mentary cumulative distribution function represented by distribution see fig

so we can state that for the corpus under consideration the most appropriate version of zipf s law is given by a probability mass function n n or equivalently by a complementary cumulative bution function n
due to the broad coverage of the project gutenberg corpus we speculate that this distribution should t a large fraction of generic non technical english texts
of course testing this speculation in front of all possible corpora is an impossible task
we have also shown that our conclusions regarding the relative performance of a pure power law in the ability mass function given by distribution distribution are robust with respect to changes in the signicance level about twice as many texts are tically compatible with distribution than those patible with at any signicance level obviously in absolute terms the number of accepted texts varies with the signicance level
hence we can conclude that tribution gives a better description of english texts than distribution at least for the corpus considered in this work
we also conclude that distribution rst derived by mandelbrot is irrelevant for the tion of texts in this corpus
finally we have corroborated that the exponent of zipf s law certainly varies from text to text as had been previously claimed using other approaches for dening what zipf s law is
ingly the value originally proposed by zipf himself is among the most frequent ones
we believe that our analysis constitutes a major ment in the understanding of zipf s law
it is astonishing how good the simplest one parameter zipf like tions perform on such a large set of texts particularly with the strict set of requirements we have imposed
this is in sharp contrast for instance with zipf s law in raphy and in the distribution of income where the power law seems to be valid only for the tail sponding to the largest sizes as it happens also for the distribution of word frequency in large text corpora as mentioned above
zipf s law has been subject to much debate and will probably continue to be so for many years
indeed one can always cast doubt on its validity on the basis of some particular examples
yet it seems clear to us that in our modern times of big data and large computational pabilities more eorts should be put towards large scale analysis of zipf s law
we hope this paper constitutes a rst step in this direction
appendix simulation of discrete zipf like distributions as part of the testing procedure we need simulated ples from and which are discrete distributions dened for n a a



we will give the recipe of simulation for an arbitrary positive integer value of the lower cut o a
it is simpler to start with as this is used as an auxiliary distribution in the simulation of the other two
simulation of
fixed a and given the parameter we want a set of random numbers whose cumulative tion function is a discrete power law a
for that we rst generate a random number u from a uniform distribution in the interval umax with umax
if we take it turns out to be that the values of yield a continuous power law with sc a where the script c distinguishes the continuous distribution from its discrete analogous one
so taking n equal to the integer part of x i
e
n yields a discrete distribution with as desired
this is so because for any x n for n integer
in a recipe for n is equivalent to x generate u from a uniform distribution in calculate take n
by means of the so called rejection method lated integers distributed following can be used for the simulation of integers following or
the key point to achieve a high performance in the rejection method is to use a good auxiliary function i
e
one that leads to a low rejection rate
this is certainly the case in our framework as explained below
simulation of
in this case the steps are generate n from generate v from a uniform distribution in the unit interval n is accepted if v and rejected otherwise where c is the rejection constant given by c
it is easy to check that the maximum of is reached at n a as this is a decreasing function
the acceptance condition above can be simplied by taking and then the dition becomes which is devoid of the calculation of the hurwitz zeta function
this is a generalization for a of the method of ref

the choice of as the auxiliary distribution function is justied by the small value that c takes as this is the expected number of generated values of n until we accept one
for instance for and a we get c

simulation of
proceeding similarly we get in this case low values of c as well we get c in the limit for a
the maximum of is numerically seen to be reached at n a
in summary the steps are generate n from generate v from a uniform distribution in the unit interval n is accepted if a a a a and rejected otherwise
acknowledgments we are grateful to the project gutenberg initiative and to those who help maintain it alive
s
pueyo provided bibliographic wisdom for zipf s law in ecology and i
serra assistance for ml estimation
i
m

enjoys a tract from the collaborative mathematics project of la caixa foundation
research projects in which this work is included are from spanish mineco and from agaur
h
baayen
word frequency distributions
kluwer drecht
m
baroni
distributions in text
in a
ludeling and m
kyto editors corpus linguistics an international handbook volume pages
mouton de gruyter berlin
d
zanette
statistical patterns in written language
arxiv

s
t
piantadosi
zipf s law in natural language a ical review and future directions
psychon
bull
rev

d
zanette and m
montemurro
dynamics of text eration with realistic zipf s distribution
j
quant
guist

a
corral g
boleda and r
ferrer i cancho
zipf s law for word frequencies word forms versus lemmas in long texts
plos one
j
a
corral m
boguna m
haro and j
ll
cos
measuring the evolution of contemporary western popular music
sci
rep

m
haro j
p
herrera and a
corral
zipf s law in short time timbral codings of speech music and environmental sound signals
plos one
w
li
zipf s law everywhere
glottom

r
l
axtell
zipf distribution of u
s
rm sizes
science
a
clauset c
r
shalizi and m
e
j
newman
law distributions in empirical data
siam rev

s
pueyo and r
jovani
comment on a keystone tualism drives pattern in a power function
science
j
camacho and r
v
sole
scaling in ecological size spectra
europhys
lett

l
a
adamic and b
a
huberman
zipf s law and the internet
glottometrics
m
e
j
newman
power laws pareto distributions and zipf s law
cont
phys

c
furusawa and k
kaneko
zipf s law in gene sion
phys
rev
lett

h
a
simon
on a class of skew distribution functions
biomet

g
a
miller
some eects of intermittent silence
am
j
psychol

r
ferrer i cancho and r
v
sole
least eort and the origins of scaling in human language
proc
natl
acad
sci
u
s
a

m
mitzenmacher
a brief history of generative els for power law and lognormal distributions
internet math

a
saichev y
malevergne and d
sornette
theory of zipf s law and of general power law distributions with gibrat s law of proportional growth
lecture notes in economics and mathematical systems
springer verlag berlin
b
corominas murtra j
fortuny and r
v
sole
gence of zipf s law in the evolution of communication
phys
rev
e
j
peterson p
d
dixit and k
a
dill
a maximum tropy framework for nonexponential distributions
proc
natl
acad
sci
usa
b
corominas murtra r
hanel and s
thurner
derstanding scaling through history dependent processes with collapsing sample space
proc
natl
acad
sci
usa
r
ferrer i cancho and b

random texts do not exhibit the real zipf s law like rank distribution
plos one
r
dickman n
r
moloney and e
g
altmann
sis of an information theoretic model for communication
j
stat
mech theory exp
page
w
li p
miramontes and g
cocho
fitting ranked linguistic data with two parameter functions
entropy
m
l
goldstein s
a
morris and g
g
yen
problems with tting to the power law distribution
eur
phys
j
b
h
bauke
parameter estimation for power law tions by maximum likelihood methods
eur
phys
j
b
e
p
white b
j
enquist and j
l
green
on ing the exponent of power law frequency distributions
ecol

g
casella and r
l
berger
statistical inference
duxbury pacic grove ca edition
a
deluca and a
corral
fitting and goodness test of non truncated and truncated power law distributions
acta geophys

f
font clos g
boleda and a
corral
a scaling law beyond zipf s law and its relation with heaps law
new j
phys

r
ferrer i cancho and r
v
sole
two regimes in the frequency of words and the origin of complex lexicons zipf s law revisited
j
quant
linguist

a
m
petersen j
n
tenenbaum s
havlin h
e
ley and m
perc
languages cool as they expand lometric scaling and the decreasing need for new words
sci
rep

m
gerlach and e
g
altmann
stochastic model for the vocabulary growth in natural languages
phys
rev
x
j
r
williams j
p
bagrow c
m
danforth and p
s
dodds
text mixing shapes the anatomy of frequency distributions a modern zipan mechanics for natural language
arxiv

b
mandelbrot
on the theory of word frequencies and on related markovian models of discourse
in r
son editor structure of language and its mathematical aspects pages
american mathematical society providence ri
a
corral and r
ferrer i cancho
in preparation
a
n
kolmogorov
foundations of the theory of bility
chelsea pub
co
new york edition
e
g
altmann and m
gerlach
statistical laws in guistics
arxiv

f
font clos and a
corral
log log convexity of type token growth in zipf s systems
phys
rev
lett

m
abramowitz and i
a
stegun editors
handbook of mathematical functions
dover new york
y
pawitan
in all likelihood statistical modelling and inference using likelihood
oxford up oxford
w
h
press s
a
teukolsky w
t
vetterling and b
p
flannery
numerical recipes in c
cambridge university press cambridge edition
a
corral f
font and j
camacho
non characteristic half lives in radioactive decay
phys
rev
e
a
corral a
deluca and r
ferrer i cancho
a cal recipe to t discrete power law distributions
arxiv
h
abdi
bonferroni and sidak corrections for multiple comparisons
in n
j
salkind editor encyclopedia of measurement and statistics pages
sage sand oaks
j
m
bland and d
g
altman
multiple signicance tests the bonferroni method
brit
med
j

y
benjamini and y
hochberg
controlling the false covery rate a practical and powerful approach to tiple testing
j
roy
stat
roc
b
project gutenberg

gutenberg
org
wikipedia accessed august

wikipedia
org wiki project gutenberg
q
h
vuong
likelihood ratio tests for model selection and non nested hypotheses
econometrica
y
malevergne v
pisarenko and d
sornette
testing the pareto against the lognormal distributions with the uniformly most powerful unbiased test applied to the tribution of cities
phys
rev
e
a
dragulescu and v
m
yakovenko
exponential and power law probability distributions of wealth and income in the united kingdom and the united states
physica a
l
devroye
non uniform random variate generation
springer verlag new york

