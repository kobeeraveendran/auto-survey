dialect diversity in text summarization on twitter l
elisa celis and vijay keswani yale university l u j y c
s c v
v i x r a abstract extractive summarization algorithms can be used on twitter data to return a set of posts that succinctly capture a topic
however twitter datasets have a signicant fraction of posts written in dierent english dialects
we study the dialect bias in the summaries of such datasets generated by common summarization algorithms and observe that for datasets that have sentences from more than one dialect most summarization algorithms return summaries that under represent the minority dialect
to correct for this bias we propose a framework that takes an existing summarization algorithm as a blackbox and using a small set of dialect diverse sentences returns a summary that is relatively more dialect diverse
crucially our approach does not need the sentences in the dataset to have dialect labels ensuring that the diversication process is independent of dialect classication and language identication models
we show the ecacy of our approach on twitter datasets containing posts written in dialects used by dierent social groups dened by race region or gender in all cases our approach leads to improved dialect diversity compared to the standard summarization approaches
introduction the popularity of social media has led to a centralized discussion on a variety of topics
this has encouraged the participation of people from dierent communities on online discussions helping induce a more diverse and robust dialogue and giving voice to marginalized communities
twitter for example receives around million posts per day with posts written in more than languages
within english twitter sees a large number of posts from dierent dialects this diversity has even encouraged linguists to use twitter posts to study dialects for example to map regional dialect variation or to construct parsing tools for minority dialects
yet automated language tools are often unable to handle the dialect diversity in twitter leading to issues like disparate accuracy of language identication between posts written in african american english aae and standard english or dialect based discrepancies in abusive speech detection
summarization algorithms for social media platforms like twitter perform the task of condensing a large number of posts into a small representative sample
they are useful because they provide the users with a synopsis of long discussions on these platforms
at the same time it is important to ensure that a synopsis suciently represents posts written in dierent dialects as the dialects are representative of the participating communities
studies have shown that the lack of representational diversity can exacerbate negative stereotypes and lead to downstream biases
summarization algorithms in particular can aggravate negative stereotypes by providing a false perception of the ground truth
hence it is crucial for automatically generated text summaries to be diverse

our contributions we analyze standard summarization algorithms that represent the range of paradigms used for extractive summarization on platforms such as twitter this includes frequency based algorithms idf hybrid tf idf graph based algorithms lexrank textrank algorithms that reduce summary redundancy centroid and pre trained supervised approaches summarunner
all algorithms use dierent structural properties of the documents twitter posts in our case to score them on their importance
our primary evaluation datasets are the twitteraae dataset and the crowdower gender ai dataset
we observe that for random and topic specic collections from the twitteraae dataset most algorithms return summaries that under represent the aae dialect
for the crowdower ai dataset all algorithms other than tf idf return gender biased summaries section
this trend is observed even for datasets that have posts written by users from dierent regions crises nlp dataset
to address the dialect bias and utilize the eectiveness of the existing summarization algorithms we propose a framework that takes any existing summarization algorithm as a blackbox and returns a summary that is more dialect diverse than the one the summarization algorithm would return without intervention
along with the blackbox algorithm our approach needs a small dialect diverse control set of posts as part of the input the generated summary is diverse in a similar manner as the control set section
importantly and in contrast to existing work by using similarity metrics with items in the control set the framework bypasses the need for dialect labels in the training or test data
empirically we show that our framework improves the dialect diversity of the generated summary for all twitter datasets and discuss the deviation of the summaries generated by our framework from those generated by the blackbox algorithms section

related work bias in nlp
recent studies have explored the presence of social biases in various language processing models
pre trained encoders have been shown to exhibit gender racial and intersectional biases
even downstream tasks can suer from social biases this includes gender and racial bias in sentiment analysis systems image captioning models language identication hate abusive speech detection and even speech recognition
considering the signicance of these language tasks techniques to mitigate biases in some of the above nlp applications have been proposed
our work aims to identify and mitigate dialect bias in the application of text summarization which has to the best of our knowledge not been addressed in prior work
existing text summarization algorithms
the importance of a sentence in a collection can be quantied in many dierent ways
algorithms such as tf idf rank sentences based on word and document frequencies
to improve the performance of tf idf for summarization over twitter posts propose a hybrid tf idf algorithm which calculates word frequency over the entire collection
other unsupervised algorithms such as lexrank textrank centroid based approaches quantify the importance of a sentence based on how well it represents the collection
lexrank and textrank dene a graph over the posts quantifying the edges using pairwise similarity and score sentences based on their centrality in the graph
to ensure a diverse summary many algorithms also dene non redundancy a secondary goal of summarization i
the sentences in the summary should be representative of the entire original collection
this includes maximum marginal relevance score mmr algorithm maximum coverage minimum redundant mcmr models determinantal point processes and latent variable based approaches
however reducing redundancy has been shown to be ineective in ensuring diversity with respect to specic attributes such as gender or race in a variety of applications
in a similar vein we show that non redundancy also does not lead to dialect diversity by evaluating the algorithm proposed by rossiello et al
centroid
this approach uses pre trained encoders and scores sentences based on the distance of their features from the centroid of the collection
while adding the sentences with the highest scores to the summary the algorithm also checks for redundancy if a candidate sentence is very similar to a sentence already present in the summary it is discarded similar to the greedy mmr approach
we choose textrank and hybrid tf idf for our diversity analysis because they have been shown to produce better summaries as evaluated using rouge metrics and manually generated summaries for twitter datasets compared to other frequency graph and latent variable based approaches
we analyze centroid to show the ineectiveness of non based approaches
further rossiello et al
observe that centroid performs better than other approaches on the task
tf idf and lexrank are also commonly used for twitter datasets and serve as baselines for our analysis
the original papers for most of these algorithms primarily focused on evaluation on duc tasks or cnn dailymail datasets however the documents in these datasets correspond to news articles and do not usually have signicant dialect diversity within them
beyond unsupervised approaches supervised techniques classify whether a sentence is important or not
these models are trained on datasets for which summaries are available such news articles and the models pre trained on these datasets do not always generalize well to other domains
we will evaluate the diversity of one such pre trained model summarunner
as twitter posts usually have metadata associated with them some algorithms use this metadata to return summaries that are also diverse with respect to time of posts user network
however since our goal is to analyze the impact of dialect variation on summarization we focus on techniques that aim to summarize using only the collection of posts
prior algorithms that aim to ensure unbiased summarization usually assume the existence of labels or partitions with respect to a given attribute in this case dialect
for example use labels to construct fairness constraints or scoring functions to guarantee appropriate diversity in the output summary
however dialect labels are not always available or even desirable and automated dialect classication is a dicult task
with the rapidly evolving nature of dialects on social media it is not reasonable to depend on robust dialect classication models for diversity in summarization
using a dialect diverse set of examples helps us skirt around this issue
this approach of using a visibly diverse control set has also been employed for image summarization
dialect diversity analysis of standard text summarization approaches we rst examine the dialect diversity of tf idf hybrid tf idf lexrank textrank and summarunner
all algorithms take as input a collection of twitter posts and the desired summary size and return a summary of the given size for the given collection
will use embeddings pre trained on a large twitter dataset for this algorithm
work focuses on extractive summarization only i
e
algorithms that use the sentences from the collection to create a summary
abstractive summarization on the other hand aims to capture the semantic information of the dataset and the summary creation can involve paraphrasing the sentences in the dataset
automated diversity evaluation for abstractive summarization algorithms is therefore more dicult since sentences in the summary are not necessarily from the original collection hence we focus on extractive summarization only
and implementation details of all algorithms are given in appendix a

datasets twitteraae dataset our primary dataset of evaluation is the large twitteraae dataset curated by blodgett et al

the dataset overall contains around million twitter posts from and for each post the timestamp user id and geo location are available as well
blodgett et al
used the census data to learn demographic language models for the following population categories non hispanic whites non hispanic blacks hispanics and asians using the learned models they report the probability of each post being written by a user of a given population category
we pre process the dataset to lter and remove posts for which the probability of belonging to non hispanic african american english language model or non hispanic white english language model is less than

the smaller dataset contains around posts belonging to non hispanic african american english language model and
million posts belonging to non hispanic white english language model for simplicity we will refer to the two groups of posts as aae and whe posts in the rest of the paper
we also isolate keywords that occur in a non trivial fraction of posts in both aae and whe partitions to study topic based summarization
the keywords and the fraction of aae posts in the subset of the dataset containing them are given in figure
crowdflower ai gender dataset dialect variation with respect to gender has been received relatively less academic attention nevertheless prior studies have established that there is a nizable dierence between posts by men and posts by women on twitter
correspondingly we look at the diversity of summarization algorithms with respect to the fraction of posts by men and women in the generated summaries
the crowdflower ai gender dataset has around posts along with some user information
the dataset contains the posts along with whether the user is male female or a brand and location
we remove the posts with a location outside us to maintain certain regional uniformity in posts
the ltered dataset contains posts with from male accounts posts from female accounts and the rest are labeled as posts by brands or unknown
for all datasets we also perform additional pre processing such as removing urls representing all posts in lower case replacing user mentions with the term atmention and special character handling
however we do not remove hashtags since they are semantically part of the posts

evaluation details despite the ltering twitteraae dataset is prohibitively large for graph based algorithms due to the infeasibility of graph construction for large datasets
hence we limit our simulations to collections of size and generate summaries of sizes upto for these collections
twitteraae evaluation we sample collections of posts from the twitteraae dataset changing the fraction of aae posts in the collection everytime
the percentage of aae posts in the collection is varied from
i
e
percentage of aae posts in the entire dataset to
we run the standard summarization algorithms for each sampled collection and record the fraction of aae
cs
umass
edu twitteraae
world crowdflower gender classifier data we also evaluate the algorithms with respect to crises nlp dataset to assess the dialect diversity of generated summaries in case of region based dialect variation
this dataset contains crisis related tweets from dierent crisis eg earthquakes oods
around the world that took place to
the analysis with respect to this dataset is presented in appendix e
collection has
aae posts collection has aae posts fixed summary size figure twitteraae evaluation
plot a b presents the dialect diversity of generated summaries when the collection being summarized has
and aae posts respectively
each point represents to the mean fraction of aae posts in summary of the given size with standard error as errorbars
plot c presents the dialect diversity in summary of size vs original collection
posts in the generated summary
for each fraction we repeat the process times and report the mean and standard error of the fraction of aae posts in the generated summaries
twitteraae evaluation next using the common keywords in this dataset we extract the subset of posts containing any given keyword
once again we use the summarization algorithms on the extracted subsets and report the dierence between the fraction of aae posts in the generated summary and fraction of aae posts in the subset of the dataset containing the keyword
this evaluation aims to assess the dialect diversity of summaries generated for topic specic collections and also lets us verify whether the observations of evaluation extends to non random collections
crowdower gender evaluation for this dataset since the size is relatively small we use the summarization algorithms on the entire dataset and report the fraction of posts written by men amongst posts written by non brands for dierent summary sizes
remark

for the crowdflower ai gender dataset the evaluation is with respect to the presented gender of the user who created the post while for the twitteraae dataset the evaluation is with respect to the dialect label of the post
the evaluation methods for both datasets are dierent but the goal is the same i
e
to assess the representational diversity of the generated summaries
the dialects we consider in this paper are those adopted by social groups and the disparate treatment of these dialects is closely related to the disparate treatment of the groups using these dialects
while the aae dialect is not necessarily only used by african americans it is primarily associated with them and studies have shown disparate treatment of aae dialect can lead to racial bias

results the results for twitteraae evaluation are presented in figure
plots show that for small summary sizes less than all algorithms mostly return summaries that have a smaller fraction of aae posts than the original collection
for larger summary sizes summaries generated by hybrid tf idf are relatively more dialect diverse
even when the fraction of aae posts in the original collection is increased beyond
the fraction of aae posts in size summaries from all algorithms is less than the fraction of aae posts in the original collection as evident from figure
mean dialect diversity vs summary size dialect diversity for dierent keywords figure twitteraae evaluation
figure a reports the mean and standard deviation of the dierence between aae fraction in summary and aae fraction in the collection of posts that contain the keyword
figure b presents fraction of aae posts in size summaries for dierent keywords as well as the fraction of aae posts in the subset of posts containing the keyword
the results for twitteraae evaluation are presented in figure
for many keywords the summaries generated by all algorithms have lower dialect diversity than the original collection
for example for funny and blessed the aae fraction in summaries generated by all algorithms is less than the aae fraction in the collection containing the keyword
there are also keyword specic collections where the summaries are relatively more diverse

for keywordmorning summaries generated by hybrid tf idf and textrank have better dialect diversity than the original collection
however overall the high variance in plot shows that the summaries generated by all algorithms are not guaranteed to be suciently diverse for all keywords
for crowdower gender evaluation figure summaries generated by all algorithms other than tf idf have an unbalanced fraction of posts from male and female accounts
lexrank textrank hybrid tf idf centroid return summaries with a larger fraction of posts from female users while summarunner returns summaries with a larger fraction of posts from male users

discussion this dialect bias in the generated summaries in many cases is likely due to the fact that the scoring mechanism of all algorithms is aected by structural aspects of the dialect like vocabulary length connectivity
which can be dierent for dierent dialects
frequency based algorithms weight each word in a post according to its frequency however given that dierent dialects have dierent vocabulary sizes and dierent average post lengths quantifying the importance of a word by its frequency can favor one dialect over other
similarly for graph based approaches on twitteraae datasets the subgraph of whe posts seem to have better clustering properties than the subgraph of aae posts see appendix c
for more discussion on the structural dierence between the dialects
scoring sentences based on structural properties in this case leads to representational disparities since the algorithms do not take into account the structural dierences across the dialects
the performance of centroid shows that ensuring non redundancy does necessarily not lead to dialect diversity and the lack of diversity of summarunner summaries also demonstrates that pre trained supervised models do not necessarily generalize to other domains
furthermore even aae fraction vs summary size aae fraction vs f score vs aae fraction vs summary size e aae fraction vs f score vs figure the rst row presents the evaluation of our model on collections containing
aae posts using centroid as algorithm a
the second row present the same evaluation on collections containing aae posts
figures a present the fraction of aae posts in the summary for dierent summary sizes
figures b e plot the diversity variation with respect to and gures c plot score between summary generated using our model and centroid
though the diversity of frequency based approaches seems relatively better than other algorithms in some cases they still are not completely reliable for dialect diversity hybrid tf idf does not return suciently diverse summaries for the crowdower gender dataset and tf idf does not return suciently diverse summaries for the twitteraae dataset
it is also important to note that summaries generated by centroid have been shown to correlate better to human generated summaries than those generated by frequency based algorithms
hence it is important to explore ways to exploit the utility of algorithms like centroid and at the same time ensure that the generated summaries are dialect diverse
our model to mitigate dialect bias we propose a simple framework to correct for the dialect bias in standard summarization algorithms
let s denote a collection of sentences
our approach uses any standard summarization algorithm denoted by a as a blackbox to return a score for each s
this score represents the importance of sentence in the collection and we assume that the larger the score the more important is the sentence
we also need a function to measure the pairwise similarity between sentences we will call this function sim
an example of such a similarity function is presented later
to implicitly ensure dialect diversity in the results we use a diversity control set t i
e
a small set of sentences that has sucient representation from each dialect for example an equal number of posts from all relevant dialects
we return a diverse and relevant summary by appropriately combining the importance score from the blackbox a and the diversity with respect to the control set t in the following manner
given a hyper parameter for each z t let ds s t r denote the following score function
let dsz represent the sorted list and let dsz i denote the sentence with the i largest score in dsz
based on these scores we rank the sentences in s in the following order rst we return sentences that have the largest score for each z i
e

next we return the set and so on
sentences within each set dsz can be ranked by their scores from algorithm a
at every step for each z we check if a sentence has already been returned if so we replace it with the sentence with next highest score for that z
a summary based on this ranking can then be generated
the complete implementation of this algorithm is provided in appendix a
our primary choice of will be

we will call our algorithm with
and blackbox a as a balanced
for example our algorithm with a as centroid and
will be called centroid balanced
the idea of summarization based on a linear combination of scores that correspond to dierent goals has been used in other contexts
for topic focused summarization vanderwende et al
score each word by linearly adding its frequency and topic relevance score
even mmr computes a linear combination of the importance and non redundancy score measured as the maximum similarity to an existing summary sentence
using a small set of diverse examples to generate a diverse summary has also been been shown to be eective for image summarization
empirical analysis of our model we repeat the evaluations proposed in section for our framework
recall that twitteraae evaluation assesses the diversity of the summaries generated for random collections of the twitteraae dataset with a varying fraction of aae posts in the collections twitteraae evaluation assesses the diversity of the summaries generated for keyword specic collections and crowdflower gender evaluation assesses the diversity of the summaries generated for the crowdower gender ai dataset
to construct diversity control sets we sample small sets from the same domain as the evaluation dataset and assess their performance on a dialect clustering task
the sets that perform well on this task are chosen as diversity control sets the control set used for twitteraae evaluations contains posts with an equal number of aae and whe posts and the set used for crowdower gender evaluations contain posts with an equal number of posts written by male and female user accounts
details of the construction process and the exact control sets used are provided in appendix c d
we use the following similarity function for a given pair of sentences cosine where vx denotes the feature vector of sentence
to obtain feature vectors for the sentences we use a publicly available model pre trained on a corpus of million twitter posts
first we use the model to get feature vectors for the words in a sentence and then aggregate them by computing a weighted average where the weight assigned to a word is proportional to the smooth inverse frequency of the word see arora et al
for details
we also compare the summaries generated by standard algorithms and our framework using rouge recall precision and scores
we report scores which quanties the amount of unigram overlap between the generated summary and the reference summary and rouge l scores which looks at the longest co occurring sequence in the generated and reference summary
table twitteraae evaluation
the performance of our model for keywords twitter and funny using dierent blackbox algorithms
the size of generated summary is
the rouge scores are computed for summaries generated by our model a balanced against summaries generated by a
aae fraction in summary rouge l recall precision f score recall precision f score method collection containing keyword tf idf tf idf balanced hybrid tf idf hybrid tf idf balanced lexrank lexrank balanced textrank textrank balanced summrunner summrunner balanced centroid centroid balanced collection containing keyword tf idf tf idf balanced hybrid tf idf hybrid tf idf balanced lexrank lexrank balanced textrank textrank balanced summrunner summrunner balanced centroid centroid balanced y n n u r o w y e k r e t t i w t r o w y e k
results





















































































the performance of our model for twitteraae evaluation using centroid as the blackbox algorithm is presented in figure
plots show that using our model with
centroid balanced leads to improved dialect diversity in the summary
for the case when the initial collection has aae posts centroid balanced generates summaries that have aae posts in the summary to achieve better dialect diversity in summary value needs to be increased plot
the comparison using other algorithms is presented in appendix c

the performance on twitteraae evaluation for two keywords twitter and funny is presented in table
we see that our model leads to a higher fraction of aae posts in summary in most cases compared to just the blackbox algorithm
however
is not always the ideal choice eg for keyword funny and hybrid tf idf or textrank as the blackbox the dialect diversity of our model is less than the dialect diversity of the summary from just hybrid tf id or textrank
in this case either or the fraction of aae posts in the diversity control set can be made larger the variation with respect to these parameters is presented in appendix c
along with the results











performance of standard summarization algorithms performance of our model for
figure crowdower gender evaluation
fraction of non brand posts by male user accounts in summaries generated by standard summarization algorithms a and our framework
for other keywords
the performance of our model for crowdower gender evaluation is presented in figure
once again centroid balanced returns summaries that have are relatively more balanced with respect to male and female users than the summaries generated by just centroid
the results using other blackbox algorithms and dierent values are presented in appendix d
the rouge scores for twitteraae evaluation are presented in figure
as expected the similarity between the summary generated by our model and summary generated by decreases as the value increases
for summary size the f score between the compared summaries is greater than
implying signicant word overlap between the two summaries
rouge scores in table shows that for twitteraae evaluation if the diversity correction required is small then the recall scores tend to be large
for centroid the recall is greater than
implying that the summary from our algorithm covers atleast of the words in the summary of the blackbox algorithm
however in the cases when the summaries generated by blackbox algorithm originally have low dialect diversity the recall scores tend to be small for example lexrank balanced
in these cases a larger deviation from the original summaries is necessary to ensure sucient dialect diversity
with respect to the rouge assessment note that this does not necessarily quantify the usability or the accuracy of the summaries generated by our model this measure simply looks at the amount of deviation from summaries of standard algorithms
conclusion this paper addresses the issue of dialect diversity in automatically generated summaries for twitter datasets
we show that standard summarization algorithms often return summaries that are dialect biased
to address this bias we propose a framework that uses a small set of dialect diverse posts to improve the diversity of the generated summaries
by using state of the art summarization algorithms as blackbox we seek to exploit the utility of these algorithms and by using diverse set of examples we ensure that the fairness framework is independent of the dialect labels and classication tools
the context of our analysis is however limited to extractive algorithms over twitter datasets future work along this direction should inspect diversity for domains beyond twitter and ways to evaluate the diversity of summaries from abstractive summarization algorithms
finally the construction of benchmark dialect diverse collections and manually generated summaries for these collections would also help better assess the accuracy of the summaries generated by our algorithm and future work
broader impact using a small set of examples of dialect diverse twitter posts to improve the dialect diversity of the summaries generated by standard summarization algorithms seems to be eective in our framework
considering the importance of the diversity control set to our framework the societal and policy impact of the composition of the control set requires careful deliberation
while we provide a mechanism to construct such a diversity control set for the datasets in the appendix in general the choice of such a set will be context dependent and the ability of framework to mitigate bias in the summary will depend on whether the control set is appropriately chosen or not
dialects represent communities and the composition of the diversity control set should ensure sucient representation of all the user dialects and participating communities of the application correspondingly to guarantee that the control set is suciently diverse the decisions regarding the composition of this set should be made in a responsible manner
this could involve additional steps such as a regular public audit of these sets as well as ways to obtain and incorporate community feedback on its composition
summarization algorithms are often implemented by organizations and engineers that collect the data for example twitter and users impacted by these algorithms usually have little inuence on the design decisions
by ensuring that the design of control sets takes into account community feedback our framework lets the user have a say in the representational diversity of the generated summaries
such a participatory design has been encouraged in fairness literature as it leads to a more cooperative framework
finally it is important to note that using a misrepresentative control set can lead to worse diversity results for example using sentences in the control set that do not belong to the same domain as the dataset will lead to an overall worse summary
the fairness accuracy tradeo in our case dialect diversity vs rouge scores should be taken into account while deciding the composition of the control set
an ideal implementation of our framework would involve an active dialogue between the users and engineers with the user feedback ensuring representational diversity in the control set and the engineers quantifying and discussing the feasibility of various control sets
references twitter usage statistics

internetlivestats
com twitter statistics
rasim m alguliev ramiz m aliguliyev makrufa s hajirahimova and chingiz a mehdiyev
mcmr maximum coverage and minimum redundant text summarization model
expert systems with applications
nasser alsaedi pete burnap and omer rana
automatic summarization of real world events using twitter
in tenth international aaai conference on web and social media
sanjeev arora yingyu liang and tengyu ma
a simple but tough to beat baseline for sentence embeddings

camiel j beukeboom and christian burgers
how stereotypes are shared through language a review and introduction of the aocial categories and stereotypes communication scsc framework
review of communication research
su lin blodgett solon barocas hal daum iii and hanna wallach
language technology is power a critical survey of bias in nlp
in proceedings of the conference of the association for computational linguistics acl
su lin blodgett lisa green and brendan oconnor
demographic dialectal variation in social media a case study of african american english
arxiv preprint

su lin blodgett and brendan oconnor
racial disparity in natural language processing a case study of social media african american english
arxiv preprint

su lin blodgett johnny wei and brendan oconnor
twitter universal dependency parsing for african american and mainstream american english
in proceedings of the annual meeting of the association for computational linguistics volume long papers pages
piotr bojanowski edouard grave armand joulin and tomas mikolov
enriching word vectors with subword information
transactions of the association for computational linguistics
tolga bolukbasi kai wei chang james y zou venkatesh saligrama and adam t kalai
man is to computer programmer as woman is to homemaker debiasing word embeddings
in advances in neural information processing systems pages
aylin caliskan joanna j bryson and arvind narayanan
semantics derived automatically from language corpora contain human like biases
science
jaime carbinell and jade goldstein
the use of mmr diversity based reranking for reordering documents and producing summaries
in acm sigir forum volume pages
acm new york ny usa
l elisa celis amit deshpande tarun kathuria and nisheeth k vishnoi
how to be fair and diverse arxiv preprint

l elisa celis and vijay keswani
implicit diversity in image summarization
arxiv preprint

l elisa celis vijay keswani damian straszak amit deshpande tarun kathuria and arxiv preprint nisheeth k vishnoi
fair and diverse dpp based data summarization


stevie chancellor shion guha josh kaye jen king niloufar salehi sarita schoenebeck and elizabeth stowell
the relationships between data power and justice in cscw research
in conference companion publication of the on computer supported cooperative work and social computing pages
abdelhamid chellal and mohand boughanem
optimization framework model for retrospective tweet summarization
in proceedings of the annual acm symposium on applied computing pages
vivian t chou leanna kent joel a gngora sam ballerini and carl d hoover
towards automatic extractive text summarization of single audit reports with machine learning
arxiv preprint

jacob devlin ming wei chang kenton lee and kristina toutanova
bert pre training of deep bidirectional transformers for language understanding
arxiv preprint

yue dong yikang shen eric crawford herke van hoof and jackie chi kit cheung
banditsum extractive summarization as a contextual bandit
arxiv preprint

gabriel doyle
mapping dialectal variation by querying social media
in proceedings of the conference of the european chapter of the association for computational linguistics pages
yajuan duan zhumin chen furu wei ming zhou and heung yeung shum
twitter topic summarization by ranking tweets using social inuence and content quality
in proceedings of coling pages
gnes erkan and dragomir r radev
lexrank graph based lexical centrality as salience in text summarization
journal of articial intelligence research
frderic godin
improving and interpreting neural networks for word level prediction tasks in natural language processing
phd thesis ghent university belgium
ruifang he and xingyi duan
twitter summarization based on social network and sparse reconstruction
in thirty second aaai conference on articial intelligence
lisa anne hendricks kaylee burns kate saenko trevor darrell and anna rohrbach
women also snowboard overcoming bias in captioning models
in european conference on computer vision pages
springer
karl moritz hermann tomas kocisky edward grefenstette lasse espeholt will kay mustafa suleyman and phil blunsom
teaching machines to read and comprehend
in advances in neural information processing systems pages
yuan huang diansheng guo alice kasako and jack grieve
understanding us regional linguistic variation with twitter data analysis
computers environment and urban systems
muhammad imran carlos castillo ji lucas patrick meier and sarah vieweg
aidr articial intelligence for disaster response
in proceedings of the international conference on world wide web pages
muhammad imran prasenjit mitra and carlos castillo
twitter as a lifeline human annotated twitter corpora for nlp of crisis related messages
arxiv preprint

david inouye and jugal k kalita
comparing twitter summarization algorithms for multiple post summaries
in ieee third international conference on privacy security risk and trust and ieee third international conference on social computing pages
ieee
aishwarya jadhav and vaibhav rajan
extractive summarization with swap net sentences and words from alternating pointer networks
in proceedings of the annual meeting of the association for computational linguistics volume long papers pages
taylor jones jessica rose kalbfeld ryan hancock and robin clark
testifying while black an experimental study of court reporter accuracy in transcription of african american english
language
anna jrgensen dirk hovy and anders sgaard
challenges of studying and processing dialects in social media
in proceedings of the workshop on noisy user generated text pages
matthew kay cynthia matuszek and sean a munson
unequal representation and gender stereotypes in image search results for occupations
in proceedings of the annual acm conference on human factors in computing systems pages
svetlana kiritchenko and saif m mohammad
examining gender and race bias in two hundred sentiment analysis systems
arxiv preprint

alex kulesza and ben taskar
determinantal point processes for machine learning
arxiv preprint

makeba lavan
the negro tweets his presence black twitter as social and political watchdog
modern language studies pages
ju hong lee sun park chan min ahn and daeho kim
automatic generic document rization based on non negative matrix factorization
information processing management
chin yew lin and eduard hovy
automatic evaluation of summaries using n gram co occurrence statistics
in proceedings of the human language technology conference of the north american chapter of the association for computational linguistics pages
hui lin and je bilmes
a class of submodular functions for document summarization
in proceedings of the annual meeting of the association for computational linguistics human language technologies volume pages
association for computational linguistics
hui lin and vincent ng
abstractive summarization a survey of the state of the art
in proceedings of the aaai conference on articial intelligence volume pages
xiaohua liu yitong li furu wei and ming zhou
graph based multi tweet summarization using social signals
in proceedings of coling pages
yang liu and mirella lapata
text summarization with pretrained encoders
arxiv preprint

kaiji lu piotr mardziel fangjing wu preetam amancharla and anupam datta
gender bias in neural natural language processing
arxiv preprint

hans peter luhn
a statistical approach to mechanized encoding and searching of literary information
ibm journal of research and development
teresa lynn kevin scannell and eimear maguire
minority language twitter part of speech tagging and analysis of irish tweets

chandler may alex wang shikha bordia samuel r bowman and rachel rudinger
on measuring social biases in sentence encoders
arxiv preprint

rada mihalcea and paul tarau
textrank bringing order into text
in proceedings of the conference on empirical methods in natural language processing pages
tomas mikolov kai chen gregory s corrado and jerey a dean
computing numeric representations of words in a high dimensional space may
us patent
derek miller
leveraging bert for extractive text summarization on lectures
arxiv preprint

zachary miller brian dickinson and wei hu
gender prediction on twitter using stream algorithms with n gram character features

n moratanch and s chitrakala
a survey on abstractive text summarization
in tional conference on circuit power and computing technologies iccpct pages
ieee
moin nadeem anna bethke and siva reddy
stereoset measuring stereotypical bias in pretrained language models
arxiv preprint

ramesh nallapati feifei zhai and bowen zhou
summarunner a recurrent neural network in thirty first aaai based sequence model for extractive summarization of documents
conference on articial intelligence
minh tien nguyen dac viet lai huy tien nguyen and minh le nguyen
tsix a involved creation dataset for tweet summarization
in proceedings of the eleventh international conference on language resources and evaluation lrec
margaret ott
tweet like a girl a corpus analysis of gendered language in social media
yale university apr
makbule gulcin ozsoy ferda nur alpaslan and ilyas cicekli
text summarization using latent semantic analysis
journal of information science
aishwarya padmakumar and akanksha saran
unsupervised text summarization using sentence embeddings
technical report technical report university of texas at austin
ji ho park jamin shin and pascale fung
reducing gender bias in abusive language detection
arxiv preprint

john r rickford
raciolinguistics how language shapes our ideas about race
oxford university press
andrew rosenberg and julia hirschberg
v measure a conditional entropy based external cluster evaluation measure
in proceedings of the joint conference on empirical methods in natural language processing and computational natural language learning emnlp conll pages
gaetano rossiello pierpaolo basile and giovanni semeraro
centroid based text summarization through compositionality of word embeddings
in proceedings of the multiling workshop on summarization and summary evaluation across source types and genres pages
evan sandhaus
the new york times annotated corpus
linguistic data consortium philadelphia
maarten sap dallas card saadia gabriel yejin choi and noah a smith
the risk of racial bias in hate speech detection
in proceedings of the annual meeting of the association for computational linguistics pages
hannah sassaman jennifer lee jenessa irvine and shankar narayan
creating based tech policy case studies lessons learned and what technologists and communities can do together
in proceedings of the conference on fairness accountability and transparency pages
mark snyder elizabeth decker tanke and ellen berscheid
social perception and interpersonal behavior on the self fullling nature of social stereotypes
journal of personality and social psychology
tony sun andrew gaut shirlyn tang yuxin huang mai elsherief jieyu zhao diba mirza elizabeth belding kai wei chang and william yang wang
mitigating gender bias in natural language processing literature review
arxiv preprint

yi chern tan and l elisa celis
assessing social and intersectional biases in contextualized word representations
in advances in neural information processing systems pages
rachael tatman
gender and dialect bias in youtube s automatic captions
in proceedings of the first acl workshop on ethics in natural language processing pages
lucy vanderwende hisami suzuki chris brockett and ani nenkova
beyond sumbasic task focused summarization with sentence simplication and lexical expansion
information processing management
jieyu zhao tianlu wang mark yatskar vicente ordonez and kai wei chang
men also like shopping reducing gender bias amplication using corpus level constraints
arxiv preprint

jieyu zhao yichao zhou zeyu li wei wang and kai wei chang
learning gender neutral word embeddings
arxiv preprint

a details of summarization algorithms explored in section we rst examine the dialect diversity of standard text summarization approaches we limit our analysis to algorithms that have either previously been employed for twitter datasets or the ones that represent recent eective approaches for extractive summarization
the algorithms we consider take as input a collection of twitter posts and return a summary of the collection
tf idf
this is a well known baseline for information retrieval and uses frequency of the words in a sentence to quantify their weight in the sentence
at the same time if a word is very common and occurs in a lot of sentences then it is likely that the word is part of the grammar structure and hence inverse of document frequency is also taken into account while calculating its score
for any sentence in collection s let w denote the set of words in the sentence
then the weight assigned to this sentence is ww tf w log idf w s where tf w is the number of times w occurs in and w s is the number of sentences in which w occurs
hybrid tf idf
the standard tf idf has been noted to have poor performance for twitter posts primarily due to lack of generalization of twitter posts as documents
correspondingly a hybrid tf idf approach is proposed
the primary dierence is that the hybrid tf idf approach calculates word frequency considering the entire collection as a single document
for any sentence in collection s the weight assigned to is ww tf w s log idf w s where tf w s is the number of times w occurs in
lexrank
this unsupervised summarizer constructs a graph over the dataset with similarity between sentences quantifying the edge weights of the graph
the similarity between a pair of sentences is measured using cosine distance between their tf idf word vectors
using the pagerank algorithm sentences are ranked based on how central or well connected they are within the graph
textrank
an extension of the lexrank approach textrank quanties the similarity between using a modied score of word document frequency
textrank also uses the pagerank algorithm to rank the sentences in the collection however it has been shown to achieve slightly better performance for some standard datasets
centroid rossiello et al
propose a centroid based summarization algorithm that scores sentences based on the distance of their tf idf features from the centroid of the dataset also similar to
while adding the sentences with the highest scores to the summary the internally implemented using the python sklearn and networkx libraries

com crabcamp lexrank algorithm also checks for redundancy based on similarity of features extracted from a pretrained model if a candidate sentence is very similar to the sentences already added to the summary it is discarded similar to the mmr approach
we will use embeddings pre trained on a large twitter dataset for this algorithm
for our framework we need the algorithm to return scores for all sentences hence to eciently incorporate non redundancy we add to the score of each sentence a non redundancy score as well
the non redundancy score is calculated as the minimum cosine distance between the feature of the current sentence and the feature of any sentence that had a better importance score
by comparing to this algorithm we will also show that algorithms that just ensure non redundancy are not sucient to ensure dialect diversity
summarunner finally we use a recent recurrent neural network based method marunner that considers summarization to be a sequential classication problem over the sequence of sentences in the dataset and generates summaries comparable to state of the art for the cnn dailymail dataset
since it is not possible to train this model over the twitter datasets we consider due to non availability of dataset summary pairs for our setting we use the model pre trained on a standard summarization evaluation dataset
the dialect diversity of summaries from this algorithm will also show that pre trained algorithms do not necessarily generalize well to other domains
inouye and kalita empirically analyze the performance of tf idf hybrid tf idf lexrank and textrank on small twitter datasets containing only around tweets for trending topics not sucient for a diversity analysis
their ndings suggest that simple frequency based summarizers such as hybrid tf idf produce better results for twitter summarization than tf idf lexrank and textrank as evaluated using rouge metrics and manually generated summaries
for larger and more recent twitter datasets nguyen et al
found that textrank and hybrid tf idf have similar performance
similarly rossiello et al
showed that the centroid based approach performs better than lexrank frequency and rnn based models on the task
the original papers for most of these algorithms primarily focussed on evaluation of these methods on duc tasks or cnn dailymail datasets however the documents in these datasets correspond to news articles from a particular agency and do not usually have signicant dialect diversity within them

com textsummarizer textsummarizer
com hpzhao summarunner algorithm algorithm for our model in section input dataset of sentences s query q blackbox algorithm a similarity function sim diversity control set t parameter number of sentences to be returned m for all s t do end for r while m do r score for all t do y arg maxxs if r then r r y end if end for if m then r r r else end if end while return r b full algorithm m images from r with lowest values of r r find images for each z checking duplicates scores used for tie breaks if all of r can be added tie break when m is not a multiple of r the full algorithm for the model proposed in section is presented in algorithm
our framework is similar to the query based image summarization framework used in
b
time complexity of the algorithm let t denote the time taken by blackbox algorithm a to score all elements of s
since the algorithm needs to create a matrix of size there will be an additive factor of atleast size of the matrix
furthermore selecting the best element in each dsz can be done in two ways i
e
either by sorting each dsz or using a max heap over each dsz
in both cases this results in an additional factor of m log
overall the time complexity of algorithm is t m log
b
machine specications for simulations the machine used for running the simulations has the following specications cores gb ram gb disk space and amazon linux ami
c other details and results for twitteraae dataset c
structural properties of aae and whe dialects as mentioned earlier the posts written in dierent dialects can dier structurally
in this section we list certain structural dierences between the posts written in aae and whe dialects
the pairwise similarity between vectors u v is calculated using cosine distance i
e
cosine v
the smaller the distance the more similar are the vectors
we calculate the average pairwise distance between the set of randomly selected aae posts and the set of randomly selected whe posts
to quantify how well the graphs based on pairwise similarity are connected we also report the spectral gap i
e
dierence between largest and second largest eigenvalues of the weighted adjacency matrix of the graph
the larger the spectral gap the better connected is graph based on the set of posts of that dialect
once again the spectral gap is calculated for the set of randomly selected aae posts and the set of randomly selected whe posts
table structural dierences between aae and whe posts
for average metrics the standard error is given in parentheses
features number of posts in dataset vocabulary sizes average length of post average pairwise similarity between tfidf vectors average pairwise similarity between vectors graph based metrics aae whe






million





average spectral gap for graph using tfidf vectors average spectral gap for graph using vectors







the structural dierences can lead to summarization disparities
for frequency based methods quantifying importance of a word just by its frequency in a post can favor one dialect over other
indeed the vocabulary size of all aae posts is around while the vocabulary size of all whe posts is around and the average length of an aae post is
while the average length of an whe post is

similarly for the graph based approaches on twitteraae datasets the subgraph of whe posts seem to have better clustering properties than the subgraph of aae posts leading to better representation of whe dialect in the summary of graph based approaches
we observe that the spectral gap of sub graph for aae posts always has a smaller value than the spectral gap of sub graph for whe posts i
e
the sub graph of whe posts is better connected than the sub graph of aae posts
this implies that a summarization algorithm like pagerank when choosing the next sentence for the summary is more likely to choose a whe tweet than an aae tweet
while scoring sentences based on structural properties of the language is eective in case of uniform dialect in this case it leads to representational disparities since the algorithm does not take into account the structural dierences across the dialects
maximum auc score vs control set size mean auc score score vs control set size maximum v measure score vs trol set size figure ecacy of using diversity control set to identify posts from dierent dialects
the gure presents how eective the diversity control set of a particular size is in clustering posts of the dierent dialects in dierent clusters
figure a presents the average maximum auc score achieved by a control set across folds for dierent summary sizes while figure b presents the mean auc score achieved by a control set across folds
as an alternative measure figure presents the mean v measure across folds
c
choice and ecacy of diversity control set before we empirically analyze our model we need to look at methods to construct a diversity control set
for this analysis we limit ourselves to assessing diversity with respect to aae and whe dialects
we employ a smaller processed version of twitteraae dataset containing aae posts and whe provided by blodgett et al
to develop tools for aae language parsing
we will use this small dataset to select diversity control sets and evaluate at the ecacy of our model
c

evaluation details the size of the diversity control set should ideally be much smaller than the evaluation dataset this will assist in better selection and curation of the control sets
correspondingly we restrict the size of the control sets for our simulations to be atmost
we use a fold cross validation setup for this simulation
for each fold we have a validation partition of posts containing equal number of aae and whe posts and a train partition of posts containing equal number of aae and whe posts we use the train partition to construct a diversity control set
we randomly block sample a set of posts from the train partition making sure that the set has equal number of aae and whe posts and use it as diversity control set let t denote this set of posts and let s denote the validation partition
then for each z t and s we calculate the score and to each s we assign to it the label of the tweet arg max
finally for this task we report the auc score and v measure between the assigned and true labels for posts in s
auc refers to the area under the receiver operating characteristic roc curve
it is measure commonly used to evaluate how the performance of a binary learning task
v measure on the other hand is to evaluate clustering tasks
this measure combines homogeneity the extent to which aae clusters contain aae posts and completeness all aae posts are assigned to aae clusters
this process is repeated times for each fold and we record the max mean and standard deviation of auc scores and v measures across all repetitions
to calculate similarity between two sentences we will use pre trained word and sentence embeddings to nd the feature vectors for these sentences and then measure the similarity as cosine distance between the feature vectors
we employ the following popular and robust pre trained embeddings for this task
embeddings
is a popular model to encode and decode words
introduced by mikolov et al
they ve been used to improve performances for various nlp tasks as well as to provide robust encodings of vocabularies of dierent domains
to obtain sentence embeddings using representations we use the aggregation method suggested by arora et al

the word representations are aggregated by computing weighted average of the embeddings of the words in the sentence where the weight assigned to a word is proportional to the smooth inverse frequency of the word
we will use a publicly available model pre trained on a corpus of million posts
fasttext embeddings
fasttext model is an extension of the model that incorporates character level information as well while encoding a word
in particular it is useful in settings where the word in consideration is not in the vocabulary is but is close to a word in the vocabulary i
e
within a few characters or a slang representation of the vocabulary word making it useful for social media settings
to obtain sentence embeddings we use the same aggregation method described above
for fasttext we will also use publicly available model pre trained on a corpus of million posts
bert sentence embeddings
bert or bidirectional encoder representations from formers is also a pre trained language representation model
output from hidden states of pre trained bert models can also be used to directly obtain sentence embeddings and we use these as well for our task
c

results the results for this task are presented in figure
the plots show that diversity control sets are indeed suitable for dierentiating between posts of dierent dialects certain control sets are able to achieve auc scores greater than

furthermore the average auc score is also greater than
for diversity control set sizes greater than implying that small diversity control sets are indeed suitable for this task as well
the max auc score evaluation also gives us certain choices of diversity control sets to use for the empirical evaluation of our model
these diversity control sets are provided in the supplementary material
given that the diversity control sets do perform fairly well on this clustering task they should be able to improve the diversity of standard summarization algorithms when used in our framework
in terms of word representations using model seems to achieve slightly better mance than fasttext and bert representations
correspondingly we will use tions for the empirical analysis of our model as well
and fasttext have relatively better performance than bert primarily because they have been trained on twitter datasets making them more suitable for the datasets we consider
table diversity control set for simulations on twitteraae dataset aae tweets atmention yea dats more like it i make a trip up der these talmbout money but
really ai nt getting no money

i be laughing at these cause that shit funny atmention me and pay got matching coupes me and kid fucked ya boo atmention he bites his lips and manages to kick o his remaining clothes our dog is a big baby and a wanna be thug emoji its a damn shame iont gangbang but i beat a n blue black atmention yes my amazon
lol i m good
pop a lock came by
thx atmention atmention you talking now right i m typing nd texting not talking soon as u think you gotcha you nd out she fckin erbody atmention lmaooooooooooooooooooooooo that was the funniest shit ever to hit twitter dawg swearrr

but y all do y all thang yea ill be good in bed but ill be bad to ya atmention nope tell her get dressed i m bouta come get her lol now omw to get my hair done for coronation tomorrow ohhhh hell naw dis bitch shay got my last name johnson whe tweets you do nt have to keep on smiling that smile that s driving me wild atmention it s probably dead because he has nt texted me back either atmention amen
honestly have trouble watching that movie
just because of her
i need to get on a laptop so i can change my tumblr bio shout out to the blue collar workers
got ta love it jax keeps curling up on my bed and tossing and turning repeatedly
like he ca nt get comfy
soocute puppylove atmention you just ca nt go wrong with chili s
they serve a mean chips and salsa atmention tenuta has nt been good since he left gt and he hates recruiting atmention probably the coolest thing i can do atmention yeah pretty frickin sweet thanks atmention you said we were hanging all day


lol i do nt have a car alslo i want a love like o the vow

perfect oneday philosophy is the worst thing to ever happen to the world how come i can never get in a gunning ght with anyone jealous poor poor merle bravo for michael rooker and norman reedus s performance on last night s show
c
evaluation of our model on random collections of twitteraae datasets for random collections of twitteraae dataset with dierent fraction of aae tweets in them we use our model to generate summaries of dierent sizes
the results for tf idf are given in figure and for hybrid tf idf see figure and for lexrank see figure and for textrank see figure and for summarunner see figure and
in certain cases the value of had to be larger than
to ensure sucient diversity in the generated summary
the captions of the gures mention the value if it is anything other than

aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing
aae tweets using tf idf as algorithm a
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing aae tweets using tf idf as algorithm a
c
evaluation of our model on keyword specic collections of twitteraae datasets next we also present the results for our model on collections of twitteraae dataset containing the keywords used in section
the results for tf idf are given in figure for hybrid tf idf see figure for lexrank see figure for textrank see figure for centroid see figure for summarunner see figure
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing
aae tweets using hybrid tf idf as algorithm a
here
for balanced algorithm aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing aae tweets using hybrid tf idf as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing
aae tweets using lexrank as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing aae tweets using lexrank as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing
aae tweets using textrank as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing aae tweets using textrank as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing
aae tweets using summarunner as algorithm a
aae fraction vs summary size aae fraction in summary vs f score vs figure evaluation of our model on datasets containing aae tweets using summarunner as algorithm a
aae fraction vs summary size aae fraction in summary vs f score vs aae fraction for dierent keywords and summary size figure evaluation of our model on keyword specic datasets using centroid as algorithm a
aae fraction vs summary size aae fraction in summary vs f score vs aae fraction for dierent keywords and summary size figure evaluation of our model on keyword specic datasets using tf idf as algorithm a
aae fraction vs summary size aae fraction in summary vs f score vs aae fraction for dierent keywords and summary size figure evaluation of our model on keyword specic datasets using hybrid tf idf as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs aae fraction for dierent keywords and summary size figure evaluation of our model on keyword specic datasets using lexrank as algorithm a
aae fraction vs summary size aae fraction in summary vs f score vs aae fraction for dierent keywords and summary size figure evaluation of our model on keyword specic datasets using textrank as algorithm a
here
for balanced algorithm
aae fraction vs summary size aae fraction in summary vs f score vs aae fraction for dierent keywords and summary size figure evaluation of our model on keyword specic datasets using summarunner as algorithm a
c
evaluation of our model using dierent diversity set compositions we also present the evaluation for the setting where the diversity control set has unequal fraction of aae and whe posts
for random collections where the fraction of aae posts in collection is figure
as expected the fraction of aae posts in summary increases as fraction of aae posts in control set increases
this is another parameter that can be tuned to adjust and obtain the desired fraction of aae posts in the summary
aae fraction in summary vs control set f score vs control set figure evaluation of our model using dierent control set compositions
d other details and results for crowdower gender ai dataset d
diversity control set used for crowdower gender ai dataset the diversity control set used for crowdower gender evaluation is presented in table
d
evaluation of our model with dierent blackbox algorithms the performance of our model using dierent blackbox algorithms is presented here
the results for hybrid tf idf are given in figure for lexrank see figure for textrank see figure for centroid see figure
table diversity control set for simulations on crowdower gender ai dataset tweets by female user accounts jameslykins haha man the struggle is reeeeeal red lips and rosy cheeks mood spirit of jezebel control revelation a war goes on in todays church and the where the hell did october go halloween is already this weekend
my lipstick looked like shit and my hair is usually a mess but i m still cute tho so say she gon ride for me ill buy the tires for you so excited to start the islam section in my religions class wow blessed my kate spade bag is ripping and i ve only used it twice a week since the end of september
all i ve done today is lie around and homework tbh of course you want to blame me for not nishing college and thus bringing this debt to myself of course misskchrista everyone was obsessed with rhys though no one really knew the other two xxx papisaysyes at rst i thought this said my dick is on drugs and i still do nt know which is worse lol huge announcement and career change for
goals dreams nymakeupartist practice random acts of kindness and make it a habit aldubpredictions sammanthae glad i can make you laugh i miss you and love you too nba i play basketball to escape reality
between the exercise and the di personalities memories are made please let me attend the future now vip party tonight i love demi and nick win random jumbies stued animals giveaway us only bassgirae daynachirps that s a great point
thanks for the reminder
contentchat i ve told bri all this time it would happen and it nally did tweets by male user accounts warrenm ill be using my new mbp
i do see dells line needs thunderbolt connections to make it a true display
not the case here salute on the new visuals my g dope as fuck i liked a youtube video ocial somewhere over the rainbow israel iz kamakawiwoole laughs and cries at the same time cause true akeboshi night and day now you all know the monster mash but now for something really scary the climate mash i hate when u tell someone u love them and they ignore u the nger hahsah the corruption of the wash
d

crowd is now of epic proportions
enlist gt join us i wish i went to school closer to mark a schwab
beating up doors and walls looks like a lot of fun
keepherwarm kobrakiddlng aimhbread now ill let you know that i ve known a guy my whole life who dated several girls and then later on xavierleon fr like wtf are they taking that they just ca nt fucking dye and busting through doors heh i just remember people actually think that and hp are intentionally sabotaging the football team
we must lessen the auditory deprivation i agree earlier the implantation the better repost seekthetruth with repostapp
repost ugly by nature of the tampons cotton and the ceo needs to embrace and sell social to the team or else is goes nowhere
bernieborges ibminsight if you scored a touchdown on sunday and did nt dab hit them folks or do that hotline bling dance it should nt have counted
zbierband zbb played our last seasonal gig at st
jude
good times had by all
remember the more you drink the better we sound i hate writing on the rst page of a notebook i feel like i m ruining something so perfect we schools should be given credit for growth in the apr but growth is not the destination
michael jones moboe
gender fraction vs summary size gender fraction vs f score vs figure evaluation of our model on crowdower gender ai dataset using hybrid tf idf as algorithm a
gender fraction vs summary size gender fraction vs f score vs figure evaluation of our model on crowdower gender ai dataset using lexrank as algorithm a
gender fraction vs summary size gender fraction vs f score vs figure evaluation of our model on crowdower gender ai dataset using textrank as algorithm a
gender fraction vs summary size gender fraction vs f score vs figure evaluation of our model on crowdower gender ai dataset using centroid as algorithm a
e other datasets crises nlp dataset this dataset contains crisis related tweets from dierent crisis eg earthquakes oods
around the world that took place to
the tweets were collected using aidr open source platform articial intelligence for disaster response
most of the rows in the original dataset just contain tweet ids for the corresponding crises many of which are dicult to retrieve
however for around tweets the text of the tweet along with some additional information is available
this includes the user id the crisis corresponding to the posts categories to which the posts belongs human annotated
for example whether the post has information on missing trapped or found people or is regarding infrastructure and utilities damage
overall there are annotation categories
we use this dataset because the posts are from locations around the world that often discuss a common kind of crises and are usually in a regional english dialect
to restrict our analysis to a single topic we only use posts corresponding to earthquakes
in total there are posts for the following earthquakes distribution given in parentheses earthquake in nepal earthquake in chile earthquake in california and earthquake in pakistan
evaluation and results once again we use all algorithms to rst evaluate the diversity of the generated summaries
here we report the fraction of posts in the summary from dierent regions
figure shows that the summaries generated by all algorithms under or over represent posts from some regions
our model using
and centroid as blackbox once again returns summaries in which the fraction of posts from dierent regions is closer to the fraction of posts from dierent regions in the original collection figure for all regions
figure evaluation of all algorithms on crises nlp dataset
figure evaluation of our model on crises nlp dataset using centroid as algorithm a

