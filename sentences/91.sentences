detecting content dense news texts combining lexical and syntactic features for detecting content dense texts in news yinfei yang redn inc
avenue seattle wa usa ani nenkova university of pennsylvania walnut street philadelphia pa usa
com
upenn
edu abstract content dense news report important factual information about an event in direct cinct manner
information seeking applications such as information extraction question answering and summarization normally assume all text they deal with is content dense
here we empirically test this assumption on news articles from the business u
s
national relations sports and science journalism domains
our ndings clearly indicate that about half of the news texts in our study are in fact not content dense and motivate the development of a supervised content density detector
we heuristically label a large training corpus for the task and train a two layer classifying model based on lexical and unlexicalized syntactic features
on manually annotated data we compare the mance of domain specic classiers trained on data only from a given news domain and a general classier in which data from all four domains is pooled together
our tion and prediction experiments demonstrate that the concept of content density varies depending on the domain and that naive annotators provide judgement biased toward the stereotypical domain label
domain specic classiers are more accurate for domains in which content dense texts are typically fewer
domain independent classiers duce better naive crowdsourced judgements
classication prediction is high across all conditions around

in submission to jair
we reported our initial work on detection of information dense text in a paper published at aaai yang nenkova in this manuscript we have further extended the work by using much larger samples of new york times articles for training and by analyzing the performance of a larger number of two layer classiers
here we also introduce a new collection of manually annotated test data for both domain dependent and general content density of texts
we make use of this collection for detailed evaluation of the content density classiers
with the publication of this manuscript we will make the classiers and data available for use by others in our aaai paper we use the term information dense to describe the types of text we wish to detect
here we switch the terminology to content dense to avoid confusion with work in the intersection of cognitive science and computational linguistics that uses the term information density in information theoretic sense to describe the change in surprise in the linear processing of sentences jaeger pate goldwater
r a l c
s c v
v i x r a yinfei yang ani nenkova
introduction news articles are written with dierent goals in mind
some aim to inform the reader about an important event focusing on specic details such as who did what to whom where and when
others aim to provide background information facts related to an event and necessary to understand an event but not newsworthy by themselves
yet others seek to entertain the reader or to showcase the brilliant mastery of language and the wit of the author
in this paper we introduce the task of detecting if a text is content dense or not
content dense news report important factual information about an event in direct and succinct manner
prototypical examples of content dense texts are newswire articles which are usually perfect answers to a what happened question grounded in a specic event
in general news however newswire like content dense text is not the norm
we base our analysis on the opening paragraph called the lead or lede of news articles drawn from the new york times
news reports often adhere to the inverted pyramid ture in which the lead conveys what happened when and where followed by more details in the body
information that is not essential is included in the nal tail
when writers adhere to this style of writing the leads are informative and provide positive examples of content dense texts
alternatively the lead may be creative provocative or entertaining rather than informative providing examples of non content dense texts
consider the leads below from the politics and sports section of the new york times
the rst two are content dense leads
the other two are non content dense leads that do not focus on events they contain few key facts and which are much richer stylistically
content dense politics evo morales a candidate for president who has pledged to reverse a campaign nanced by the united states to wipe out coca growing scored a decisive victory in general elections in bolivia on sunday
mr
morales an aymara indian and former coca farmer who also promises to roll back american prescribed economic changes had garnered up to percent of the vote according to televised quick count polls which tally a sample of votes at polling places and are considered highly accurate
sports north carolina and duke of the atlantic coast conference received no
seedings yesterday in the team women s n
c
a
a
tournament along with ohio state and louisiana state
the top ranked tar heels received the no
overall seeding but were placed in what appears to be the most dicult regional
non content dense when the denitive history of the iraq war is written future historians will surely want to ask saddam hussein and george w
bush each one big question
to saddam the question would be what were you thinking if you had no weapons of mass detecting content dense news texts destruction why did you keep acting as though you did for mr
bush the question would be what were you thinking if you bet your whole presidency on succeeding in iraq why did you let donald rumsfeld run the war with just enough troops to lose why did nt you establish security inside iraq and along its borders how could you ever have thought this would be easy the answer to these questions can be found in what was america s greatest intelligence failure in iraq and that was not about w
m
d
sports with his silver pants and dark blue jersey covered by a mottled mix of grass stains paint and mud new england patriots running back corey dillon sat on an minum bench on the sideline at gillette field on sunday looking exhausted and frozen
only a few minutes remained in the patriots victory over the indianapolis colts and dillon was resting
he stared at the eld snowakes swirling around his head as the realization of his rst playo victory swirled inside it
below we propose an approach for labeling short news texts as content dense or not
our analysis of manual annotations reveals that uninformative article leads are common
we investigate several types of lexical and non lexicalized syntactic features for ing content dense texts from other more general or creatively written texts
we present a two layer ensamble classier model which signicantly outperforms a baseline ing that all news leads are content dense
we also study the robustness of the denition of content density across domains as well as the performance of domain dependent and domain independent general classiers

corpus the data for our experiments comes from the new york times nyt annotated corpus ldc catalog no

the corpus contains years worth of nyt editions along with rich meta data about the newspaper section in which the article appeared and summaries produced by information scientists for many of the articles
the leads of articles are explicitly marked in the corpus so extracting the relevant text for further analysis is straightforward
in our previous proof of concept work yang nenkova we selected a subcorpus of articles published in or from four dierent genres business u
s
international relations science and sports
given the selection criteria the data in that prior work contained considerably fewer articles from the science and the sports domains compared to the other two domains
moreover the performance of the content dense classiers in the science and sports domains was notably worse than the other two domains which could be explained either by the fact that these classiers were trained on smaller datasets or by the intrinsic dicult of predicting content density in these two domains
to denitively resolve this question and to benet from the largest training dataset possible we extend the corpus to the full nyt corpus in the experiments reported in this manuscript
yinfei yang ani nenkova we also expect that the degree to which a text would be judged to be content dense reporting on important event in a direct manner is inuenced by the domain of the article
it is reasonable to expect that typical events in science or sports would not be considered of the same importance as international political or business events
to study the domain dierences we analyze four news domains business sports and us international relations or politics for short

training set heuristic to automatically label leads as content dense or not we make use of the manual summaries which accompany many articles in the nyt corpus
for the articles with content dense leads the manual summary will be very similar to the lead itself as this type of lead by denition provides a fact focused summary of the article
for leads that simply seek to engage the reader via more creative devices the manual summary will dier considerably from the lead
overall the similarity between the lead and the manual summary provides a strong indication of the importance and factual event oriented nature of the information expressed in the lead
for articles with manual summaries of at least words we calculate an content dense score
for each word in the summary a tuple pos is created containing the word and its part of speech
the score is computed as score of pos also in leads of pos
label analysis table shows details about the number of all nyt articles from each of the four domains
the rst column shows the number of articles in the nyt from the given domain
the second column shows the number of articles used for training domain dependent classiers we explain the selection procedure below
overall only about one third of articles have associated manual summaries
the distribution of content dense scores assigned as a function of the overlap with the human summaries is shown in figure
in the business domain the distribution of scores is almost uniform reecting the fact that in that section there are articles about tant events company mergers unexpected stock price changes product announcements and lawsuits but also non event specic analysis of current trends minor events such as auctions and people centered pieces about prominent business men and women
in sports and science the distribution of content dense scores is clearly skewed towards the non content dense end of the spectrum
in these domains there are fewer intrinsically
the science articles are from the cats louis nenkova which only contains articles published after
detecting content dense news texts table number of articles in the corpus
total number of articles articles used in training percentage business science sports politics overall




important events to begin with and writers more often resort to the use of creative and indirect language meant to provoke readers interest
the content dense scores in politics is almost normally distributed with mean roughly in the middle of the possible range and much higher than any of the other domains
the non content dense leads in this domain usually provide a commentary on an ongoing event rather than reports of a specic new development
in the rest of the paper we focus on the binary classication task of predicting if a lead is content dense or not
however it is reasonable to expect that our indirect labeling scores are noisy
to obtain cleaner data for training our model we label only the leads with most extreme scores we assign the label non content dense to the leads with scores that fall below the percentile and label content dense to leads that score above the percentile for their domain
the percentile sets are colored red in gure
in the general domain independent model the data is pooled together and again the leads with lowest scores are assigned to the non content dense class and the leads with highest scores are considered content dense

methodology in this section we introduce the features and models we used in our experiments
in our prior experiments yang nenkova we found that lexical features are well suited for the task particularly lexical representations determined independently of the training data
along with these unlexicalized syntactic representations also lead to remarkably good results
a number of other representations we experimented with did not appear to be that benecial for the task
motivated by these ndings here we study in depth the lexical representations and the unlexicalized syntactic representation and explore ways to combine the predictions of these models to achieve even better accuracy

features we compare and combine two lexical and one syntactic representation
for the lexical representation we use the vocabulary from the mrc which is pendent of our training set and a vocabulary derived from the training set and weighted yinfei yang ani nenkova figure score histograms for the four genres top left business top right science bottom left sports bottom right politics
and percentiles are colored red
red star indicates the average content dense score for each genre
by mutual
the syntactic representation is simply the list of duction from the constituency parse of the sentences in the lead
mrc the mrc psycholinguistic database wilson is an electronic dictionary containing words dierent subsets of which are annotated for linguistic and psycholinguistic attributes
we select a subset of words normed for age of acquisition imagery concreteness familiarity and ambiguity
in wilson the words were chosen among those with medium frequency in a large corpus and experiment subjects were asked to rate on a scale the degree to which each word has one of these properties
the mrc dictionary is a compilation of results from dierent studies run by dierent research groups with dierent criteria for selecting the list of words for which to solicit norms
we use the list of words which have at least one of above ratings
the value detecting content dense news texts of each feature is equal to the number of times it appeared in the lead divided by the number of words in the lead
about of the mrc vocabulary words appears at least once in the training data
about appear more than ve times
mutual the lexical representation described above is domain dependent determined without any knowledge about the data which will be used for training and testing of our classication models
we also introduce a domain dependent lexical representation derived from the training data for the classiers and using mutual information to measure the association between particular words and the content dense and non content dense writing styles
for each genre we compute the mutual information between words and lead type in the training data as mic log c here c is either the content dense or the non content dense class
we only compute the mi scores for words that appear at least times in the training set
we select the top words with highest associations with each of the writing styles for a total of features
the value of the feature is if the word occurs in the lead and otherwise
the words with highest mutual with the content dense classes and non content dense classes are listed in table
the words with high mutual information with the content dense class are distinctly domain specic
content dense leads in the business domain are more likely to talk about companies and their executives deals agreements and oers
content dense leads in ence are more likely to discuss a specic study or drug since they are overwhelming biased towards health related topics
sports content dense leads are associated with specic sport events or deals
in politics content dense leads discuss american involvement and attacks
in addition the words yesterday and today also appear among those associated with content dense leads providing a strong indicator that the news is focused on a cic recent event rather than a general discussion or personal aspects story
the words associated with the non content dense class in contrast tend to be related to non specic activities nd feel hear smile remember sit wait and focused on personal aspects rather than on the professional people friend husband guy kid child friend
only about half of the words in the mutual information representation also appear in the mrc

we ran fold cross validation in the experiments
the mutual information is computed separately based on the training set of each fold
the words listed in table are from fold but high mutual information words from other folds are very similar
yinfei yang ani nenkova table top selected words for each domain and overall data content dense company yesterday million billion today percent group announce executive plan share corporation york part deal agree largest unit court agency inc
commission bank include rm chief agreement chairman oer service study health today yesterday report drug ocial research federal state scientist administration disease researcher company government accord human virus university group million expert announce cell include cancer united agency issue yesterday today league team national million season association ocial die cup contract race year deal tonight game conference major president round lead charge announce committee victory win woman world series ocial united today american states administration mr
clinton military government weapon international eort attack security nuclear force report intelligence group court defense nations program include china agency secretary nato plan yesterday today company million ocial billion group united percent announce states plan administration york include american agency government federal report accord court executive national drug part state international corporation deal non content dense day stock ago work thing good investor year nd turn long man economy job people home street room time rate lot index city sit mr
market wall money ms
life day mr
ms
ago feel hear room sit walk home eye life friend thing run talk live game stand back family hand foot good morning husband hour night town son fan ago watch back stand ball day question good turn moment room smile feel hand time wear people knicks hear remember n

a
net guy sit thing stadium shot kid walk man day world war people time u
s
ago back sit thing front live city child street room stand saddam morning america word year wait car kerry young friend watch hour day ago thing man good stock time room sit back stand turn watch street hear home feel people long life lot ms
walk town wall word friend live moment eye business science sports politics overall production finally we use production rules as the syntactic tion louis nenkova ganjigunte ashok feng choi post bergsma malmasi dras
we view each sentence as the set of grammatical productions lhs rhs which appear in the syntactic parse tree of the sentence
we keep only non terminal nodes detecting content dense news texts excluding all lexical information so the lexical and syntactic representations capture overlapping aspects of writing style
all production rules from the training set are used in the representation
the numbers of production rules vary for the four domains from rules science to rules business

classier combination the three feature representations we introduced capture domain independent lexical clues for content density domain dependent indicators for important events and general style of writing captured by the structure of sentences in the text
we train a support vector logistic regression classier with each class of features individually
furthermore in this section we examine two approaches for combining the predictions from the three classes of features
feature level combination first we examine the performance of feature level nation to develop a system that makes use of all three types of indicators of content density
we concatenate the three feature representations together in a feature vector
the number of entries in the feature vector is equal to the sum of the number of features of the mrc mutual information and production rule representations
then we train a logistic regression model based on the concatenated feature representation
this way of combining evidence lead to overall improvements in our early work
however much work on ensemble learning has demonstrated that for variety of tasks this method of combination is not as powerful as decision level combination for example see raaijmakers truong wilson van halteren zavrel daelemans metallinou lee narayanan bertolami bunke
we treat the feature level combination as the baseline for our experiments
figure shows the structure of feature level combination classier
decision level combination classier combination has been shown to outperform ture combination in a single classier tulyakov jaeger govindaraju doermann
there are multiple reasons why this may be the case especially for a linear classier like the one we use
concatenating all features in a single representation makes the system prone to as the number of features becomes closer to the number of training examples
if the number of features of a given type is considerably smaller for example there are many more features in the production rule representation compared to the mutual information representation the signal contributing to the nal decision may be dominated by the larger class defeating the purpose of evidence combination
it could also lead to the presence of correlated features for example in the combination of the two types of lexical features
we propose a two layer classier combination system
we rst train a logistic regression classier with each of the three feature representations individually
then another model
stanford corenlp package manning surdeanu bauer finkel bethard mcclosky is used to extract production rules
yinfei yang ani nenkova is trained in which the features are the probabilities of the content dense class from the rst layer classiers
in the experiment the corpus is split into training set development set and testing set
the rst layer classiers is trained on the training set and the second layer classier is trained on development set
figure b illustrates the structure of the decision level combination system
feature level combination decision level combination figure illustration of feature level combination and decision level combination
evaluation on automatic annotations
classier evaluation in the feature level combination system we train the binary classier using liblinear r
e
fan lin with linear kernel and regularized logistic regression model setting
in the decision level combination experiments we rst train binary classiers based on each feature representation using liblinear with the same settings
using the probability outputs for the content dense class of the rst stage classiers as features we then train a nal binary classier using libsvm chang lin with linear kernel
grid search is used to nd the best hyper parameters in all models
we perform fold cross validation experiments on the entire heuristically labeled data where ve folds are used for training rst stage classiers and the feature level combination classier
four folds are used for training the second stage combination classier which uses only the probabilities of the content dense class from the rst stage classiers
one fold is used for testing the classiers
we evaluate the two combination models on the automatically labeled data but also analyze the performance when only a single class of feature is used
the results are presented in table
because of the way the data was labeled the two classes are of equal size with accuracy as the random baseline
the top three rows in the table corresponds to a system trained with only one class of features
the last two rows shows the results for the two combination systems
the columns correspond to the domains we study business science sports and politics
the domain specic models detecting content dense news texts were trained and tested only on the data from the given domain and the results are shown in the rst four columns
the general domain independent model is trained and tested on the combined dataset and the last column shows its performance
depending on the domain accuracies are high ranging between
for business and
for politics
of the individual feature classes the production rules representation leads to the best overall accuracy
combining the representations at the feature level leads to improvement over the production rule classier for the business and politics domain as well as in the general domain independent classier but not for science and sports where performance using all features is in fact worse than using production rules alone
in line with our previous work all single feature classiers have very good performances
the production rules pr syntactic representations lead to the best performance for all domains with accuracies over or close to for all domains
the most important rules are quite dierent in each genre but the discovered patterns are mostly aligned with our intuition
for example vp np prt advp is often associated with content dense leads in business the example text like vp czech currency
the rule np cd nns however is usually associated with non content dense leads e

np april
the production rules with highest weights are listed in appendix b
of the lexical representations the mrc representation leads to better results with accuracies varying from
for the business domain to
for the sports domain
the corpus dependent lexical representations based on mutual information has a slightly lower performance the accuracies range between
for business and
for politics
the results for the general classier which is trained and tested on data from the four domains pooled together are similar
for this classier leads may change their labels for example a sports article whose content dense score is in the percentile of scores for sports may fall below the percentile when all data is combined
the fact that the representations designed independently of the training data can lead to such good results is a positive nding indicating that the results are likely to be robust
for all the domains and general domain independent data decision level combination considerably improves the performance compared to classiers trained with only one of the representations
it is the most accurate among the ve classiers that we compare with up to
performance gain in politics compared to the best single feature classier
the baseline combination system feature level combination performs worse than the decision level combination
one of the possible reasons is that given the increased number of features this model may require more training data to reach its performance potential
we study this aspect of model development in section

yinfei yang ani nenkova table binary classication of fold cross validation on the automatically labeled set for dierent classes of features and two fusion models mrc database mrc mutual information mi production rules pr feature level fusion decision level fusion business science sports politics general

























combining classiers with dierent representations here we evaluate dierent possible combinations of feature types
we compare these sibilities for decision level combination which we already established works better than feature level combination
the motivation to examine combinations of features is that not all features are able in all applications
moreover concerns about run time may make syntactic features undesirable in certain settings where syntactic parsing may not be feasible
mutual formation representations also require larger training data for each domain of interest to compute the mutual weights for each feature
so we examine the eectiveness of combining dierent feature classes
the multilayer structure makes the decision level fusion easier to add or remove features
developers can simply train a classier based on new features then add them to the second layer without aecting existing single feature classiers
we show the results from evaluating three dierent classier combinations lexical features only domain independent features only and all features together
the results are shown in table
the top row in the table corresponds to the baseline feature level combination model with all three classes of features
rows correspond to decision level models with the three dierent classier combinations
as in previous tables the rst four columns correspond to domain specic models and the last column shows the results for the general domain independent model
combination classiers based on all three features in decision level combination still has the highest accuracy showing that each of the three representations contributes to the improved performance of the classier
the domain independent features with decision level combination shows a competitive results too suggesting that the mutual information representation is the one that could be removed with least degradation in performance
the accuracies are just slightly lower than the best
lower for the business domain for example
the decision level combination of lexical representations has lower performance then the other two decision level combination models
the accuracies range between
for the business domain and
for the politics domain
the combination of the two lexical representation leads to better performance than using either of the individual features detecting content dense news texts classes suggesting that combination at the decision level is a good alternative when syntactic features are not available
table binary classication of fold cross validation on the automatically labeled set for dierent combinations of features feature level fusion business science sports politics general




















is the training data enough we now discuss the impact of the training set size on classier performance
we evaluate the relationship between classier accuracy and the increasing of the number of training instances for each domain
we start with a training set of articles growing to instances in the training data increasing the training set with randomly selected articles in each step
accuracy is computed on the same testing set for each domain
as in our previous experiments fold cross validation is performed
for each fold there is a dedicated test set which means all cross validation iterations used the same test set
the reported results are an average of the accuracies on the xed test set in each fold
figure shows the accuracy size curve for each domain
among the four genres decision level combination of all three features has the highest accuracy
the accuracy increases rapidly with the increase of training data when the number of training articles is less than
when the size is larger than it continues to increase but very slowly
the decision level combination of features which is the second best model for all domains behaves similarly
the accuracy of the decision level combination is the worst of the combination systems and exhibits the slowest increase
the accuracies of decision level combination with training article are already very close to the nal numbers with full training set shown in table
increasing the number of training instances barely changes the performance after this point
the baseline feature level combination has the lowest accuracies
yet we still see increase in accuracy as the training set size increases
for three of the domains its formance becomes the same as that of the combination with a large enough training set
the results also indicate that decision level combination is able to achieve better formance with less training data
the graphs suggest that the dierence in performance of the content density predictor in the four domains likely reects the diculty of the domain rather than the dierence in training data size
yinfei yang ani nenkova figure accuracy by changing size of training set for the four genres top left business top right science bottom left sports bottom right politics
evaluation on human annotations so far we have established that recognition of content dense texts can be done very curately when the label for the lead is determined by intuitive heuristics on the available article summary resources
we would like however to test the models on manually notated data as well in order to verify that the predictions indeed conform to reader perception of the style of the article
we selected a total of articles and split them into two sets
for the rst set of articles the authors of the paper annotated the content dense labels and provided a value score for the domain dependent content density of each text
then a second set of articles was selected and annotated on amazon mechanic turk amt
all annotated articles were randomly picked from the nyt data and did not appear in the training data for the classiers that we evaluate here
detecting content dense news texts
human annotated dataset

basic set in the basic human annotation set the authors of the paper annotated nyt articles from each domain with judgements of their perceived informativeness
similar to prior work on grammatically judgements bard robertson sorace the annotation was done with respect to a reference lead that fell around the middle of the content dense spectrum
leads were labeled by domain the question was if a specic article from domain d is content dense compared to the reference lead for that domain
all leads from the same domain were grouped together and displayed in random order with the annotators seeing leads only from the same domain until they completed the annotation for that domain
the reference lead in each case was drawn from the respective domain
the annotator gave both a categorical label for the lead less content dense or more dense than the reference and a real value score ranging between to via a sliding bar
the categorical labels were used to test the binary classiers
the real valued annotations were used to compute correlations with classication scores produced by the classier
inter annotator agreement all test leads were annotated as being content dense or not and with a real value indicator of the extent to which they are content dense
table shows the percent agreement between the two annotators on the binary level task as well as the correlation of the real value annotation
for the binary annotations we also report the kappa statistic
table inter annotator agreement on manual annotations
percent agreement is puted on the binary annotation correlation is computed on the real value degree of density of the leads
all correlations are highly signicant with p

business science sports politics agreement kappa correlation











as table shows the agreement for all domains is considerably high but not perfect
agreement is highest almost for the politics domain
the agreement is lowest in the business domain
the correlations of content density scores exceed
and are highly signicant p
for all domains
the high correlations of real valued scores especially for the politics and business domains suggest that the task may be more amenable to annotation and automation as a real value prediction task rather than as a binary distinction
kappa however is relatively low indicating that the annotation task is rather dicult
to rene our instructions for annotation we adjudicated all leads for which there was no yinfei yang ani nenkova initial agreement on the label
both authors sat together reading the reference lead and each of the leads to be annotated discussing the reasons why the lead should be labeled content dense or not
in many cases the nal decision was made by taking into account the domain from which the lead was drawn i
e
there is nt much important information in a sports lead but it could be considered content dense in the context of sports news reporting as well as the reference lead for the specic genre i
e
the lead is not that content dense but appears to contain more important facts or reports the news in a more direct style than the reference lead
we study further the way domain and perception of content density interact in the next section where independent annotators rated density both in in domain and in domain independent general settings
below is an example on whose label the authors initially disagreed
in this lead the rst paragraph is non informative and the second paragraph is informative providing partial justication for either overall label
example of labelling disagreement many elderly people are already distressed by the increasing numbers of drugs they are taking including painkillers and heart medication
now those who are also battling depression may be wondering where it all will end
last week researchers at the university of pittsburgh presented ndings from a large study suggesting that antidepressants are more eective in warding o a recurrence of late life depression than periodic sessions of interpersonal therapy a standardized form of talk treatment


amt annotation set we also compiled a second set of nyt articles for each domain
in an attempt to provide more guidance to the annotators we gave four reference leads for each domain two as examples of prototypical content dense leads and two as example of leads that are clearly not content dense
the reference leads for each domain are shown in appendix a
the annotators saw the four prototypical leads as well as a group of leads that they had to annotate
they provided both a categorical label for each target lead content dense or not and a real value score for the degree to which it can be considered content dense range between and
the annotation was partitioned into groups of ve leads an annotator had to label at least ve leads and then request more data for annotation in groups of ve
to embed some quality control one of the ve leads in each group is a lead from the dataset annotated by the authors for which they agreed in independent annotation before the adjudication
as we will shortly see the classier is impressively accurate on instances in which the annotators agreed in their initial annotation and quite poorly on the leads that required adjudication
these ndings suggest that in future work in may be benecial to develop a classier for sentence level prediction of content density which would be helpful for characterizing leads that mix informative and entertaining sentences
another clear alternative is to develop a classier to predict that a text is ambiguous in terms of its content density status
detecting content dense news texts step
this data allowed us to asses the quality of annotations after problematic annotators were ltered out
here we also study the dierences in how the content density of a text would be ceived in domain and in general setting
for each lead text two tasks were published separately for labeling content density in domain or in general
for the in domain task annotators are given domain information i
e
here are articles drawn from the sports section of a newspaper


and the reference leads are selected from that domain
in the general task workers are not told the domain of the lead and the reference leads were selected without regard to domain
ten annotators annotated each lead in each of the two conditions
amt annotation renement we use two rules to lter out unqualied annotators
we ltered out all annotations by annotators who annotated too quickly or were inconsistent
the rst rule is that annotator s average annotation time per task should be longer than seconds
for reference the average annotation time per task among all annotators is around two minutes
the second rule is that labeled category and score should be consistent for each lead text
if an annotator labels a lead as content dense but gives a very low content dense score or vice versa we know something in their understanding of the task is amiss
there are on average annotators for each item after ltering out unqualied words
for each lead we use the majority category as the nal category label and the average score as the nal score label
if there is a tie for a lead we label it content dense
table shows the agreements and kappas between the majority label from amt workers and the authors agreed labels
we compute these only for the in domain labels because our initial annotation was domain dependent
agreement for the business and sports category is high but only moderate for science and politics
we are unsure about the exact reasons why this is the case
table agreement of embedded baseline leads between amt workers and authors of the paper
business science sports politics kappa







amt workers annotated leads in two conditions in domain where the judgements were specic to the domain from which the lead was drawn and general domain independent
the content dense example was from business and science and the non content dense from business and politics
yinfei yang ani nenkova table number and percentage of content dense leads annotated by amt workers for each domain
the same data is annotated with respect to in domain and general criteria and the statistics for each condition are shown in the rst and last column respectively
the two middle columns show the number of leads that changed labels from content to non content cd or vice versa between the in domain and general condition broken down according to the direction of the change
label changes cd non cd non cd cd in domain




business science sports politics overall general




where a domain was not specied and text from all four domains were randomly mixed in the annotation tasks
table shows the number of content dense leads for each domain for both conditions along with the number of leads whose labels changed across conditions
the rst and the forth column correspond respectively to the number percentage of content dense leads among all in domain and general labels for the same data
the second and third columns show the number of labels that changed their labels from to non content cd or vice versa between the domain dependent and the domain independent labelling
clearly the domain context plays a large role in the perception of content density
the change is most clear for the politics and sports domain in the domain independent labeling a large number of sports leads which appeared content dense for their domain are considered non content dense in general
similarly many of the politics leads considered non content dense for the standards of the politics domain are considered as such in the independent setting
there are virtually no changes in label in the opposite direction which conforms to our expectations and provides an additional conrmation of the reasonable quality of the crowdsourced annotations
overall the in domain annotators have a more balanced number of content dense and non content dense labels

are leads informative in automatic summarization research the article leads are generally considered to be formative or content dense
the beginning of the article is known to be a strong summary baseline mani klein house hirschman firmin sundheim nenkova and many features for identifying important content in articles are based on overlap with the detecting content dense news texts opening paragraph
our annotations allow us to directly examine to what extent this general intuition holds across domains of journalistic writing in the new york times
table shows the number of leads in each domain labeled as content dense in the manually annotated dataset described above
it is clear that the prevailing assumption that the lead of the articles is always content dense is not supported in the data we analyze here
the majority of articles in the politics domain which are representative of the data on which large scale evaluations of summarization system tend to be performed and which focus on specic current events are indeed content dense
more than of leads in this domain are labeled as content dense in the authors annotation
the trend is similar in the amt annotations
conforming to intuition the second largest proportion of content dense leads is in the business domain
there the articles are often triggered by current events but here is more analysis humor and creativity
in these leads important information can often be inferred but is not directly stated in factual form
business leads also tend to have the same labels regardless of whether they are annotated with respect to the domain standard or in general
for the business domain only out of labels changed across conditions cf
rst line in table which corresponds to at least half the rate of label change for any of the other domains
in sports the factual information that has to be conveyed is not much and it is lished and presented in a verbose and entertaining manner
particularly amt annotators consider less than a third of the sports leads to be content dense across domains
in the science journalism section many leads only establish a general topic or an issue or include a human interest story
overall there is only a small portion of science leads labeled as content dense
the perception of content density is certainly inuenced by the context of the domain
there are politics leads that changed labels from in domain to the general condition and of them are changed from non content dense to content dense indicating that in that setting annotators followed their domain bias in deciding the label
similarly sports in domain content dense leads are non content dense across domains but only leads changed in the opposite direction
these ndings have two important implications for language processing applications and summarization in particular
it is unrealistic to expect that all newspaper text has high informational value
finding valuable content has been addressed as a standalone problem in social media becker naaman gravano and user generated data agichtein castillo donato gionis mishne but generally has been ignored in news analysis
in addition our analysis casts doubt on the practicality of requiring summarization systems to produce summaries of xed length
many of the articles with leads that are not content dense do not discuss even in the body of the article an event readers would consider important
an appropriate summary should simply indicate this or a summary should not yinfei yang ani nenkova be even attempted
automatic systems are anyhow not particularly good at summarizing articles that deal with opinion or discussion rather than a specic event nenkova louis
in information access applications tagging the genre of the article as event centered or not similar to earlier work in distinguishing opinion pieces from factual reporting yu hatzivassiloglou may be most helpful with preview snippet summaries produced only for the event centered articles

classier evaluation here we evaluate the combined two layer classier trained on heuristically labeled data on the manual annotations
note that the manual annotated leads are used for evaluation only no additional training is performed at this stage
baselines following the assumption prevailing in summarization research that the lead of the article is always content dense the rst baseline always considers the lead of the article content dense
the second baseline is established based on the length of the entire news article not only the lead
the intuition is that longer articles may have uninformative leads designed to draw the reader into the subject while short articles need to start out with a more focused presentation of the event so are likely to have an content dense lead
we train a regularized logistic regression model based on this single feature
as table shows the single feature classier achieve reasonable accuracy of for the science domain
classication results on the basic set table shows the results from applying the domain dependent and the general domain independent models on the basic human notation set
accuracy computed against each of the two individual annotators is shown in the last two columns
sports and politics domains have higher prediction accuracies on the data labeled by the rst annotator and business and science domains have higher prediction accuracies for the second annotator s labels
also the prediction accuracies have smaller variances on the data labeled by the rst annotator between for the politics domain and for science the domain compared with the accuracies on data labeled by the second annotator between for business and for sports
overall however the prediction accuracy on the nal combined data after disagreements have been adjudicated is highest demonstrating that the adjudication procedure did lead to more internally sistent labels
as in the heuristically labeled data recognition accuracies are higher for the business and science domains and lower for the sports and politics domains around
we also evaluate the prediction accuracy separately on the subsets of the data for which the two annotators agreed on the label in the rst stage of independent annotation corresponding to the presumably clear cut cases and those for which adjudication was needed
clearly the classier captures characteristics of content dense leads quite well
detecting content dense news texts the accuracy on the subset of the data for which the annotators agree is much higher than that for individual annotators indicating that when the text has mixed characteristics leading to disagreement in annotation it is more likely that the classier makes more errors as well
on the agreed subset marked with the same label by both annotators during dent annotation accuracies are around for the business and science domains for sports and politics domains
the classier accuracies are much higher than the baselines for all domains
table binary classication on basic human annotated datasets for models trained on heuristically labeled data
combined agreed adjudicated anno anno business domain model overall model science domain model overall model sports domain model overall model politics domain model overall model combined agreed adjudicated anno anno combined agreed adjudicated anno anno















combined agreed adjudicated anno anno table shows the correlations between the classication score from the nal classier and the real value score of content dense by the two annotators
all correlations are highly statistically signicant
in line with what we have seen in the analysis of other results the correlation is the highest for the business domain
similarly we compute the prediction accuracy stratied according to the classier dence in that prediction
figure shows the plot on all four genres
the accuracy of












yinfei yang ani nenkova table correlation between predicted probabilities and human annotated scores
all correlations are highly signicant with p

annotator annotator domain models overall models domain models overall models business science sports politics















high condence predictions is much higher than the overall accuracy
the article length baseline however has lower accuracy in its high condence predictions
figure prediction accuracy based on probability ranking on basic human annotation set
top left business top right science bottom left sports bottom right politics classication results on the amt annotations table shows the accuracy of the domain dependent and the general domain independent models on the amt annotations
as in previous tables row and represent the results from domain models and the domain independent models respectively
rows to show results for the two baselines
detecting content dense news texts our classiers outperform the baselines by a large margin except for politics in the independent labels where the baseline that considers all leads to be content dense works best
overall however the results show that the baseline of assuming all leads are dense performs poorly and the proposed approaches signicantly improve the accuracies
comparing the accuracies of prediction for data drawn from the same newspaper tion it is evident that business and science have the most stable prediction and the accuracy of the domain dependent and the domain independent classiers does not dier much on these subsets of the test data
the classier trained on domain independent labels achieves
accuracy on the domain specic labels in which the annotators were explicitly told the news section from which the article was drawn and used this information in judging if the lead is content dense or not
this accuracy is less than lower than the prediction on domain independent labels
similarly in the science domain the dierence in performance for the two types of labels is as low as

in stark contrast there is large dierence in performance for the in domain and domain independent labels for sports and politics where the dierence between the two reaches
the crowdsources annotations were performed both in domain judging the content density with respect to the expectation for the given domain politics for example and in domain independent setting
here domain models are on average worse than the domain independent models
for the sports domain training a domain specic classier helps most in improving the detection of content dense sports leads but for the other domains the advantage is less clear
this result is reassuring
if the domain models were clearly superior one would have needed accurate domain predictors for practical applications
the analysis presented here demonstrates that a domain independent classier may be sucient for many applications
the accuracies of the domain models drop considerably compared to their respective accuracies on the author annotated set
for example there is around
drop in the politics domain
there are several possible reasons for this dierence
the articles in the initial set that the authors annotated were selected only from the articles published in and while the amt set is selected from the entire nyt dataset from to
the annotation instructions also diered for the two sets
the amt annotators were presented with prototypical content dense and non content dense leads as references while the authors had only one lead in the middle of the range of content density as ence
finally the general domain independent classier on average works best predicting both the in domain and general labels in the test set better than the domain dependent classiers
this trend indicates that amt workers were likely more inuenced by eral domain expectations when labeling the data
it is plausible that domain dependent annotation is requires more detailed instructions that are not as readily passed on in the crowdsourced setting
we further compute the correlations coecients between predicted probabilities and erage scores annotated by amt workers
the results are shown in table
domain models have better correlations than general models in three of domains for domain dependent yinfei yang ani nenkova table binary classication on amt annotated datasets for models trained on heuristically labeled data




in domain domain model general model business science sports politics average







domain indep
business science sports politics average
domain model general model


























domain labels but with small absolute dierence in correlation
the domain independent models are much better in predicting content dense in the general domain independent condition
all correlations are highly signicant range from
to
against domain labels and from
to
against domain independent labels
as in the binary prediction task the domain independent label appear to be easier for the system to predict
the correlation coecients are in line with our intuition and much closer to the numbers we have seen based on the basic author annotated set shown in table
this trend implies that predicting content density in terms of real value scores may be more suitable for this task
table correlation between predicted probabilities and average scores annotated by amt workers in the domain specic and general condition
all correlations are highly signicant with p

in domain labels domain independent labels domain models general model domain models general model business science sports politics















for the amt annotated test set we also compute the prediction accuracy stratied according to percentiles of data ranked by the classier condence in that prediction
ures and show the plots on all four domains for the two types of annotated labels domain specic or domain independent
again the accuracy of high condence tions is much higher than the overall accuracy
the article length baseline however has much lower accuracies
detecting content dense news texts figure prediction accuracy based on probability ranking on amt annotated data
the axis represents the percentile of data used to calculate the accuracy according to the predication condence
in domain top left business top right science bottom left sports bottom right politics
recognizing better summaries so far we have demonstrated that detector of content denisty can be developed using tically labeled data and that it can achieve respectable accuracy in intrinsic evaluation on human labeled leads
ultimately however the goal would be to integare the content denisty prediction in information seeking applications such as summarization and news browsing
testing the impact of the content density prediction in such extrinsic evaluations will be the main focus of future work
here however we show a feasibility study to verify the potential for development of more informed summarization methods that exploit the concept of content density
specically we demonstrate that the content density detector is able to recognize when an automatic summary of a single news article is better than the lead of the article
this is an important open problem in summarization where the lead paragraph baseline is very strong and few systems outperform it over dang harman
moreover all of the proof of concept experiments from the previous section were performed on data drawn yinfei yang ani nenkova figure prediction accuracy based on probability ranking on amt annotated data
the axis represents the percentile of data used to calculate the accuracy according to the predication condence
domain independent top left business top right science bottom left sports bottom right politics from the nyt
we would like to verify that the usefulness of the prediction remains when data from other sources is considered
motivated by these goals we perform our experiments on detecting if a machine mary is more informative than the lead on two datasets nyt and on data from the document understanding conference which has data from a variety of sources
we randomly selected articles with manual summaries from the nyt for each genre
we generated automatic summaries for the article using two systems
the rst system leadsumm is the strong lead baseline which picks the rst words as the summary
the second system is icsisumm gillick favre which is one of the state of the art multi document summarization systems gillick riedhammer favre hakkani tur berg kirkpatrick gillick klein
we performed human evaluation to determine which of the two summaries in the pair leadsumm and icsisumm is better
we asked annotators to rst read the manual mary from nyt then read the two summaries generated by the systems
then we asked the annotators to indicate which of the two system summaries covers better the detecting content dense news texts tion expressed in the nyt goldstandrd
thel were also provided with an option to indicate that the two system summaries cover the information expressed in the goldstandard equally well
the ow between the sentences in the leadsumm summaries is better than those in the automatic summaries because this is a snippet of professionally written discourse
here our goal is to study the content density of the two summaries independently of the linguistic quality of the summary which we know favors the lead system
for this reason we randomized the order of the sentences in both of the leadsumm and icsisumm summaries
the order of presenting the leadsumm and icsisumm to annotators is also randomized during judgement collection
the tasks are published on amazon mechanical turk amt and each task is assigned to annotators with one summary per task hit
icsisumm generated empty summaries for out of the randomly selected articles and two of its summaries were identical to the lead baseline
we removed those tasks so there are total tasks are published
the majority vote of the annotators is used as the nal label
the human annotations are used as ground truth in the following steps
next we apply the content dense detector on the generated icsisumm and leadsumm to get content dense probability scores for each
the summary with higher content dense score is predicted to be the better summary
as expected from prior manual shared task evaluations leadsumm is better then icsisumm for most of the articles
the condence in the prediction that one summary is better than another is controlled by the content dense score dierence
the larger the dierence between the content density scores of the icsisumm and leadsumm is the more condent we can be that the summary is indeed better
we track how the summarization performance varies with the dierence in content density scores
in cases when the dierence between the two content denisty scores is lower than a set value we consider that the lead summary is better
by dening the score dif erence scoreicsisumm scoreleadsumm we cuto the evaluations samples by score dif erence compute the metrics for dierent cuto levels
table shows the results of detecting when icsisumm produces better summaries than the lead baseline on the nyt articles
this is equivalent to a combination system which uses lead summaries unless it is condent that the automatic summary is better in which case it uses the icsisumm summary
each show shows the metrics values for a cuto
the rst column represents the cuto threshold
the second and third columns show the number of total samples and number of positive samples within this cuto repectively
the last row of the table shows the total number of judgements and the number of times assessors indicated that a given summary either the lead or that produced by the icsi summarizer provides more information about the described event
the lead was better for of the test articles the icsi summarizer produced the more informative summary for of the test articles
the two summaries were considered equally informative in the rest of the cases
yinfei yang ani nenkova clearly as expected from past duc evaluations the lead baseline summary is better than the automatic summarizer
however even an extractive summarizer can signicantly outperform the lead baseline if we had a reliable way in which to predict when an alternative summary would be more informative this could improve one out of each three summaries produced by the summarizer
in table we also show the performance of a combination system using density scores to decide which of the two available summaries is superior
whenever at least some threshold is used to decide when the automatic summary is better the combination system s output is preferred by the assessors considerably more often than the output for the lead baseline
particularly for thresholds between
and
the output of the combination system is preferred between and of the time compared to the
for the lead baseline
these improvements would be statistically signicant according to a binomial test with expected probability of producing better summary of
corresponding to the human preference for the baseline lead summaries
table performance of combination system with dierent cutos on nyt articles
the last column shows the number percentage of correct predicted samples of the combination system
cuto of samples human judgement leadsumm combination system nyt




all icsisumm
tie






n a next we verify that the proposed model works with reasonable accuracy on sources other than the nyt
we run the same leadsumm and icsisumm systems on the duc dataset over et al

we only perform the experiments on the data from which is the last year nist provides single document human summaries
there are total of articles from various sources in including associated press ap wall street journal wsj los angeles magazine la ft magazine ft san jose mercury news sjmn and foreign broadcast information service daily reports fbis
ap is a newswirse service providing high quality news reporting used by many media outlets
by the nature of newswire services the ap articles and leads are expected to be contain a larger proportion of content dense texts
the other article sources are drawn from newspapers so are much more likely to include leads that are not content dense
detecting content dense news texts by ltering out those articles have no icsisumm generated or the two generated maries are identical
again we exclude from considerations articles for which icsisumm did not generate a summary or for which icsisumm produced a summary consisting of the lead of the article
after ltering these we obtain articles for the evaluation
as with the nyt experiment we use amt to obtain judgements about which of the two summaries of the article is better
all the annotation settings are exactly the same with the nyt annotations described above
table performance of combination system with dierent cutos on cles
the last column shows the number percentage of correct predicted samples of the combination system
cuto of samples human judgement leadsumm combination system duc ap duc other




all




all icsisumm tie









n a





n a again we then apply content dense detector on the generated icsisumm and leadsumm to detect which summary is better based on their content dense scores
table shows the results of detecting better icsisumm on the articles
the judgements on data drawn from sources dierent from the nyt allows us to get a sense about the extent to which the content density detector we developed to the news genre in general rather than specically to the nyt
the observation that bears special mention is that here the percentage of articles for which the icsi summarizer is able to produce more informative summaries than the lead summarizer is considerably smaller than in the randomly selected sample of nyt articles
for the ap articles the automatic summaries are judged as better than the lead baseline for of the test articles
this conforms with expectations that the ap articles and leads will be overall more dense than regular newspaper sources
for the other sources newspaper the percentage yinfei yang ani nenkova of automatic summaries that are better than the lead is
for comparison in the nyt sample the system produced a more informative summary in of the cases
this larger percentage may reect the style of the new york times or the fact that the articles from nyt were randomly drawn so covers a broader range of domains than the duc data
the numbers indicate that the style of ap is the most typically informational while the nyt is the most stylistically rich with leads that are often not content dense
if this is the case the room for expediting news search and browsing via automatic summarization has been underestimated in duc evaluations
for all three types of sources ap nyt other newspapers we examine the ability of the content dense predictor we developed to guide system combination
as described above we rst ran icsisumm and leadsumm systems on each article and then apply the content density detector on the generated summaries
let scoreicsi and scorelead denote the content dense scores for icsisumm and leadsumm respectively and scoredif scoreicsi scorelead
the combination system picks the icsisumm mary as ouput summary if scoredif cutof otherwise the leadsumm is picked
we evaluate the performance for dierent cuto thresholds
the system which always picks the icsisumm summary and the system always picking lead summary are employed as baselines
the results of are show in table and
the rst column represents the cuto value and the second column shows the number of total samples within this cuto
column to are the statistics of human judgements
the last column shows the number percentage of correctly predicted samples of the combination system
each row shows the results of the system with a cuto value
the last row shows the statistics for the entire dataset and two baselines one that picks icsisumm summaries only and another that picks lead summaries only
not surprisingly the system always picking lead summary is better than the system picking icsi summary in all three type of sources
which is aligned with early studies that lead summary is a hard to beat baseline
the combination system performs better than baseline systems when we pick the right cuto
the choice of cuto depends on the source types and the reason is the writing styles can be very dierent in dierent sources as discussed above
for nyt and duc other newspapers the combination system is able the achieve better performance when setting cuto as
and achieve highest accuracy when setting cuto as

for the ap however it is rather harder to nd a cut o in which the combination system would outperfrom the lead baseline
the cuto has to be set to
to get the best performance so the general ability to produce a better summary with ap data is dubious


conclusion and future work in this paper we introduced the task of detecting content dense news article leads
we use article summary pairs from the nyt corpus to heuristically label a large set of articles as detecting content dense news texts content dense when the lead of the article overlaps highly with the human summary and as non content dense when the overlap is low
we present experiments with two lexical representations and one syntactic tion
the production rule syntactic representation is the best predictor of lead density among the three
the corpus independent lexical representation from a vocabulary dened by the mrc lexicon proved to be the more useful lexical representation
we pared a feature level combination model and a two layer decision level combination model
the latter performs best in all our experiments
our analysis reveals that there is a large variation across news domains in the fraction of content dense leads and in the prediction accuracy that can be achieved
contrary to popular assumptions in news summarization we nd that a large fraction of leads are in fact not content dense and thus do not provide a satisfactory summary
overall domain specic models are more accurate than in domain labels from trained annotators
the general model trained on all data pooled together achieves better mance on crowdsourced annotations in both domain dependent and domain independent annotation conditions
our experiments indicate that predicting content dense in terms of real value scores may be more accurate and benecial for applications than simply fying a lead as content dense or not
in this work we have established the feasibility of the task of detecting content dense texts
we have conrmed that the automatic annotation of data captures distinctions in informativeness as perceived by people
we also show proof of concept experiments that show how the approach can be used to improve single document summarization of news and the generation of summary snippets in news browsing applications
in future work the task can be extended to more ne grained levels with predictions on sentence level and the predictor will be intergared in a fully functioning summarization system
all data for the work presented in this paper and the domain dependent and general classiers will be made publicly with the publication of this article
references agichtein e
castillo c
donato d
gionis a
mishne g

finding quality content in social media
in proceedings of the international conference on web search and data mining pp

acm
bard e
g
robertson d
sorace a

magnitude estimation of linguistic ceptability
language pp

becker h
naaman m
gravano l

beyond trending topics real world event identication on twitter

icwsm
berg kirkpatrick t
gillick d
klein d

jointly learning to extract and press
in proceedings of the annual meeting of the association for computational yinfei yang ani nenkova linguistics human language technologies volume pp

association for computational linguistics
bertolami r
bunke h

early feature stream integration versus decision level combination in a multiple classier system for text line recognition
in pattern nition
icpr
international conference on vol
pp

chang c

lin c


libsvm a library for support vector machines
acm transactions on intelligent systems and technology
software available at
csie
ntu
edu
cjlin libsvm
ganjigunte ashok v
feng s
choi y

success with style using writing style to predict the success of novels
in proceedings of the conference on empirical methods in natural language processing pp

gillick d
favre b

a scalable global model for summarization
in proceedings of the workshop on integer linear programming for natural langauge processing pp

association for computational linguistics
gillick d
riedhammer k
favre b
hakkani tur d

a global optimization framework for meeting summarization
in ieee international conference on acoustics speech and signal processing pp

ieee
jaeger t
f

redundancy and reduction speakers manage syntactic information density
cognitive psychology
louis a
nenkova a

a coherence model based on syntactic patterns
in proceedings of joint conference on empirical methods in natural language processing pp

association for computational linguistics
louis a
nenkova a

what makes writing great rst experiments on article quality prediction in the science journalism domain
tacl
malmasi s
dras m

chinese native language identication
in proceedings of eacl vol
pp

mani i
klein g
house d
hirschman l
firmin t
sundheim b

summac a text summarization evaluation
natural language engineering
manning c
d
surdeanu m
bauer j
finkel j
bethard s
j
mcclosky d

the stanford corenlp natural language processing toolkit
in association for computational linguistics acl system demonstrations pp

metallinou a
lee s
narayanan s

decision level combination of multiple modalities for recognition and analysis of emotional expression
in proceedings of the ieee international conference on acoustics speech and signal processing icassp march sheraton dallas hotel dallas texas usa pp

nenkova a

automatic text summarization of newswire lessons learned rom the document understanding conference
in aaai pp

detecting content dense news texts nenkova a
louis a

can you summarize this identifying correlates of input diculty for multi document summarization
in acl proceedings of the annual meeting of the association for computational linguistics pp

over p
dang h
harman d

duc in context
inf
process
manage

pate j
k
goldwater s

talkers account for listener and channel characteristics to communicate eciently
journal of memory and language
post m
bergsma s

explicit and implicit syntactic features for text tion
in proceedings of the annual meeting of the association for computational linguistics volume short papers pp

r

fan k

chang c

h
x

w
lin c


liblinear a library for large linear classication


raaijmakers s
truong k
wilson t

multimodal subjectivity analysis of multiparty conversation
in proceedings of the conference on empirical methods in natural language processing emnlp pp

tulyakov s
jaeger s
govindaraju v
doermann d

review of classier bination methods
in in machine learning in document analysis and recognition
informatica s
vemulapalli et al
van halteren h
zavrel j
daelemans w

improving data driven wordclass tagging by system combination
in proceedings of the annual meeting of the sociation for computational linguistics and international conference on putational linguistics volume acl pp

wilson m

the mrc psycholinguistic database machine readable dictionary
havioural research methods instruments and computer version
yang y
nenkova a

detecting information dense texts in multiple news mains
in proceedings of twenty eighth aaai conference on articial intelligence
yu h
hatzivassiloglou v

towards answering opinion questions separating facts from opinions and identifying the polarity of opinion sentences
in proceedings of the conference on empirical methods in natural language processing emnlp pp

appendix a
reference leads used in amt annotations here we present all the references leads annotators saw in amt human intelligent
yinfei yang ani nenkova a
in domain reference leads in in domain annotations annotators labeled a group of ve leads from same domain in each hit
two content dense leads and two non content dense leads from the same domain are displayed at the beginning
reference leads for business domain content dense ref securities regulators charged one of the richest men in mexico ricardo b
salinas pliego with fraud yesterday in a lawsuit that seeks to have him barred as a director or ocer of any company whose shares trade on an american exchange
the securities and exchange commission also sought to have mr
salinas pliego the chairman of tv azteca the second biggest spanish language broadcaster give up more than million he made from trading in the company s stock and debt
content dense ref in a rare move microsoft said yesterday that it had agreed to pay a percentage of the sales of its new portable media player to the universal music group
universal music a unit of vivendi will receive a royalty on the zune player in exchange for licensing its recordings for microsoft s new digital music service the companies said
non content dense ref looking for some thong underwear or perhaps a leather jacket and do nt know where to nd them try logging on to a restaurant web site
small restaurateurs are increasingly using the internet to sell goods that go far beyond the usual array of branded t shirts and hats in hopes of not just building the bottom line but also cultivating possible new markets for expansion
non content dense ref what stresses me most the chief executive of vartis daniel l
vasella said is that we are getting new regulations from abroad without any consultation
this has been the world economic forum that the united states government largely passed by
in a world that both respects and fears american power there is worry that the united states does not care what others think
reference leads for science domain content dense ref scientists have decoded the chimp genome and compared it with that of humans a major step toward dening what makes people human and developing a deep insight into the evolution of human sexual behavior
the comparison pinpoints the genetic dierences that have arisen in the two species since they split from a common ancestor some six million years ago
content dense ref a popular class of drugs for high blood pressure ace hibitors may cause birth defects if taken during the rst three months of pregnancy doctors detecting content dense news texts are reporting
pregnant women and those who are planning to become pregnant should avoid the drugs the researchers and ocials at the food and drug administration warn
ace inhibitors have long been known to cause birth defects if taken later in pregnancy but until now were considered safe if taken in the rst trimester
non content dense ref to gauge the potential consumer impact of the dation sweeping the telephone industry look no further than the silver toned plastic phone gathering dust on the desk in justin martikovic s studio apartment
mr
martikovic a junior architect who relies on a cellphone for his normal calling says he never uses the desk phone but he pays a year to keep it hooked up
non content dense ref as the horror of the south asian tsunami spread and people gathered online to discuss the disaster on sites known as web logs or blogs those of a political bent naturally turned the discussion to their favorite topics
to some in the blogosphere it simply had to be the government s fault
reference leads for sports domain content dense ref ivor g
balding one of three british brothers who gained international fame as polo stars in the s when the sport attracted large crowds and wide press coverage died on thursday at his home in camden s
c
he was
his death was announced by his family
content dense ref finally the deal is done
laveranues coles the wide receiver from the washington redskins passed a physical examination by the jets medical sta yesterday clearing the way for the team to reacquire him in a trade for wide receiver santana moss
non content dense ref nearly years ago when it was his turn to interview the prospective employee the estimable james reston onetime traveling secretary for the cincinnati reds but then the executive editor of this newspaper asked how a political science major had wound up writing about sports
i answered the question but i have a better answer now
the political science classes prepared me for the nonsense that will pass for a hearing about steroids use in baseball next thursday in washington
non content dense ref three years ago as he stood in the rubble of the st
bonaventure basketball program ahmad smith had a decision to make
one of his teammates center jamil terrell had been declared ineligible after it was learned that he had been admitted to the franciscan university in the hills of southwestern new york with a welding certicate and the approval of st
bonaventure s president
reference leads for politics domain yinfei yang ani nenkova content dense ref at least american service members were killed in iraq in nearly matching s total of according to information released by the united states government and a nonprot organization that tracks casualties in iraq
the deaths of two americans announced by the united states military on friday a marine killed by gunre in falluja and a soldier killed by a roadside bomb in baghdad brought the total killed since the war in iraq began in march to
the total wounded since the war began is
content dense ref seventeen people died in two separate violent incidents on sunday and monday that underscored an increasing sense of lawlessness in mexico
a former soldier went on a rampage in a pacic coast town on sunday killing people before local residents chased him down and the police shot him in the town square
thirteen hours later gunmen attacked gamblers at an illegal cockght at a guadalajara racetrack killing and wounding when they tossed two grenades into the crowd
non content dense ref president bush on tuesday pressed senate republican leaders to continue ghting to conrm john r
bolton as ambassador to the united nations even though senator bill frist the majority leader said his options had been exhausted and some republicans urged the appointment of mr
bolton when congress recesses
the president made it very clear that he expects an up or down vote dr
frist told reporters after meeting with the president
back in the capitol he added i do nt want to close that door yet
non content dense ref are things getting better or worse in iraq that is the basic question on which much hinges for the united states and the world
here are some impressionistic answers
just over a year ago on my last visit to the country i was able to drive north to tikrit saddam hussein s home town and south to the shiite holy city of najaf
these were not excursions for sitting back and enjoying the scenery
but they were feasible at high speed and with some risk
a
domain independent annotation in domain independent annotations annotators are given a group of ve leads randomly selected from all domains
two informative leads and two uninformative leads are given as references
content dense ref securities regulators charged one of the richest men in mexico ricardo b
salinas pliego with fraud yesterday in a lawsuit that seeks to have him barred as a director or ocer of any company whose shares trade on an american exchange
the securities and exchange commission also sought to have mr
salinas pliego the chairman of tv azteca the second biggest spanish language broadcaster give up more than million he made from trading in the company s stock and debt
detecting content dense news texts content dense ref in a rare move microsoft said yesterday that it had agreed to pay a percentage of the sales of its new portable media player to the universal music group
universal music a unit of vivendi will receive a royalty on the zune player in exchange for licensing its recordings for microsoft s new digital music service the companies said
non content dense ref looking for some thong underwear or perhaps a leather jacket and do nt know where to nd them try logging on to a restaurant web site
small restaurateurs are increasingly using the internet to sell goods that go far beyond the usual array of branded t shirts and hats in hopes of not just building the bottom line but also cultivating possible new markets for expansion
non content dense ref as the horror of the south asian tsunami spread and people gathered online to discuss the disaster on sites known as web logs or blogs those of a political bent naturally turned the discussion to their favorite topics
to some in the blogosphere it simply had to be the government s fault
appendix b
production rules with highest weights in this section we list the production rules with highest weights for each genre
we also show two example for each production rule
the examples are extracted from lead texts using stanford corenlp package
yinfei yang ani nenkova table top production rules with examples for business positive rules np prt advp vp over again vp czech currency pp s vp line about their incentive packages attract companies to relocate to their areas vp facts about dierent regions get information that only used to be available if at all through the mail and in person visits np np vbg np pp vp industry unfair trading practices vp heated members of a house subcommittee nnp np
m
f
np
d
a
negative rules cd nns np april np pp np tmp pp vp a car crash in peru a third weathered np summer pakistan in brutal degree heat vp the wet black runway at the alexander mcqueen fashion show last thursday np an ominous disco rb pp advp not advp not np vp newsweek s time finally come vp what advp np tmp np vp np fourth consecutive decline as concerns about ination and interest rates grew before today s report on producer prices vp np sign of how companies all over the world are still rushing to do business in china detecting content dense news texts table top production rules with examples for science positive rules in np qp vast majority qp jubilant return sbar adjp likely than others to have children and those who do give birth run an increased risk of bearing a child with the same birth defect they themselves have adjp less successful expected nnp nns nn np np np vp
s the scientic evidence for past lives simon and schuster tom shroder a washington post editor reviews the year old clinical psychiatrist s research on reincarnation and nds it hard to refute

s when from lincoln center a concert by the new york philharmonic on pbs stations across the country the announcer will not be saying anything about the personal story of the bass baritone thomas quastho who will sing four concert arias by mozart

nns nn np np negative rules np pp pp vp cup of coee starbucks an olympic challenge vp crack his plays the form of faithful revivals or loose interpretations np advp sbar vp his legs though they had been perfectly healthy vp niece s card she does nt live in westchester np advp pp vp the dozens vp cases of leprosy in this country over the previous three years more than the past np cc np np x rays rail thin women who had attained the exalted status that comes from being married to a master of the universe investment banker np new book s rainbow diversity gender and sexuality in nature rb sbar sbar about whom we could persuade to hire us we would deign to work for sbar they are ne they are mucked up or obscure yinfei yang ani nenkova table top production rules with examples for sports positive rules nn nn whnp whnp prt s vp winning the featured copley cup race of the annual san diego crew classic yesterday for the second consecutive year vp the league of racism jj jj nn nn np np round vbd np pp sbar vp seconds into the rst round and golota arena an ambulance he lost consciousness in his locker room after the ght vp second base chuck knoblauch could not throw straight advp advp negative rules cc np pp np brenly s use curt schilling np
number of players still participating in the world cup gretzky who has been team canada s best player but is also the rangers biggest question mark md cd nn np np jj nnp nn nn np s
c
c
np year np np in xs xs detecting content dense news texts table top production rules with examples for politics positive rules nnp nnp nnp np np vbg nnp nnp np np np prt sbar vp civic debate to change the way americans experience and ultimately build urban public spaces vp debate american courts would repeat the kinds of rulings that restricted the civil rights of japanese americans during world war ii cc vp s vp being held in banco delta asia in macao be transferred to a north korean account at the bank of china vp the contacts were informal no bearing on the eorts help him settle in panama cc advp advp least another week longer advp enough enough negative rules cc rb jj adjp adjp rp advp advp nn pp s np ali janbaz s the american military helicopters over this isolated mountain valley last thursday afternoon np chinese government s military force suppress the tiananmen demonstrations s sbar what were doing when you heard that franklin d
roosevelt had died or that john f
kennedy had been shot or that martin luther king jr
was dead sbar delightful must be these days to be a member of the chinese communist politburo nnp nns np np
