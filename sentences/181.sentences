n a j v c
s c v
v i x r a demystifying multi faceted video summarization tradeoff between diversity representation coverage and importance vishal kaushal iit bombay
ittb
ac
in rishabh iyer microsoft corporation
com khoshrav doctor university of massachusetts amherst
umass
edu anurag sahoo aitoelabs
com pratik dubal aitoelabs
com suraj kothawade iit bombay
iitb
ac
in rohan mahadev aitoelabs
com kunal dargan aitoelabs
com ganesh ramakrishnan iit bombay
ittb
ac
in abstract this paper addresses automatic summarization of videos in a unied manner
in particular we propose a framework for multi faceted summarization for extractive query base and entity summarization summarization at the level of tities like objects scenes humans and faces in the video
we investigate several summarization models which ture notions of diversity coverage representation and portance and argue the utility of these different models pending on the application
while most of the prior work on submodular summarization approaches has focused on combining several models and learning weighted mixtures we focus on the explainability of different models and turizations and how they apply to different domains
we also provide implementation details on summarization tems and the different modalities involved
we hope that the study from this paper will give insights into practitioners to appropriately choose the right summarization models for the problems at hand

introduction visual data in the form of images videos and live streams have been growing at an unprecedented rate in the last few years
while this massive data is a blessing to data science by helping improve predictive accuracy it is also a curse since humans are unable to consume this large amount of data
moreover today machine generated videos via drones dash cams body cams security cameras go pro
are being generated at a rate higher than what we as humans can process
moreover majority of this data is plagued with redundancy
given this data explosion chine learning techniques which automatically understand organize and categorize this data are of utmost importance
video summarization attempts to provide a highlight of the most critical and important events in the video giving the viewer a quick glimpse of the entire video so they can cide which parts of the video is important
what comprises of the most critical aspect of a video pends largely on the domain
what is important in a lance video is very different from the highlights of a soccer game
this work attempts to provide a better ing of different summarization models in different domains
we try to make a case that the choice of the tion model really depends on the application and domain at hand
this paper investigates several choices of rization models models which capture diversity tation importance or relevance and coverage
we tively and qualitatively study this pattern in many different domains including surveillance footages dashcam cams and gopro footages movies and tv shows and sports events like soccer
we argue how different characteristics are important for these domains and through extensive perimentation establish the benet of using the ing summarization models
for example we show that for surveillance footages diversity is more important compared to representation or coverage while in a movie tion and coverage form a better t compared to diversity
similarly in a sports event like soccer importance and vance signals are important aspects of summarization
this paper also analyzes several choices of feature tions and concepts including faces scenes humans color information objects
we study three variants of summarization one is tive summarization the second is query focused rization and the third is entity based summarization which we also call concept based summarization
entity based summarization focuses on entities like objects scenes mans faces to provide a representative yet diverse subset of these entities
this answers questions like who are the different people or what are the diverse objects and scenes in the video
finally we discuss several implementational details on how to create a video summarization system cluding the preprocessing of features different tions of shots and tricks for speeding up the optimization for near real time response times


existing work several papers in the past have investigated the problems of video and image collection summarization
video marization techniques differ in the way they generate the output summary
some of these extract a set of keyframes from the video while others focus on ing video summaries or skims from the long video
other forms of video summarization include creating gif summaries from videos montages visual boards from videos video synopses and time lapses and hyperlapse summaries
similarly image collection summarization involves choosing a subset of representative images from the collection
another line of approach which is similar to what we call entity based tion was proposed in wherein the authors select resentative summaries of all objects in a video
they do this by modeling the problem as that of sparse dictionary tion
most video summarization techniques can be rized into methods trying to model one of three properties of summaries i interestingness how good is a given snippet as a summary representativeness how well the mary represents the entire video or image collection and iii diversity how non redundant and diverse is the mary
examples of methods which model interestingness of snippets include that nd summary snippets through motion analysis and optical ow which uses humans and objects to determine interesting snippets and nally which models interestingness through a super frame mentation
summarizes multiple videos collectively by looking at inter video frame similarity and posing a imal bi clique nding algorithm for nding summaries
methods which only model the quality of the snippets or equivalently the interestingness of the summaries and do not model the diversity often achieve redundant frames and snippets within their summary
hence a lot of recent work has focused on diversity els for video and image collection summarization
used the facility location function with a diversity penalty for image collection summarization while dened a coverage function and a disparity function as a diversity model
attempted to nd the candidate chain of sub shots that has the maximum score composed of measures of story progress between sub shots importance of vidual sub shots and diversity among sub shot transitions
was among the rst to use a mixture of submodular functions learnt via human image summaries for this lem
for video summarization proposed the imum marginal relevance mmr as a diversity model while used a determinantal point process based approach for selecting diverse summaries
proposed an approach for video summarization based on dictionary based sparse coding and proposed using mixtures of submodular functions and supervised learning of these tures via max margin training an approach used for several other tasks including document summarization and age collection summarization


our contributions the goal of this work is not to achieve the best results on video and image summarization tasks and datasets like tvsum and summe
rather we attempt to vide insights into what it takes to build a real world video summarization system
in particular we try to understand the role of different submodular functions in different mains and how to implement a video summarization tem in practice
as observed in prior work several models for diversity representation coverage and uniformity can be unied within the class of submodular optimization
we build upon this work as follows

this paper studies the role and characteristics of ferent summarization models
what constitutes a good summary depends on the particular domain at hand

we investigate several diversity coverage and sentation models and demonstrate how different els are applicable in different kinds of video rization tasks

we validate our claims by empirically showing the havior of these functions on different kinds of videos and quantitatively prove this on several videos in each domain
for example we show that diversity models focus on getting outliers in the video which is tant in domains like surveillance
on the other hand representation models capture the centroids and portant scenes which is useful in movies
we also how coverage functions focus on achieving a good coverage of concepts
similarly we show that in mains like soccer importance or relevance plays the most important role in the summary

we also discuss the computational scalability of the optimization algorithms and point out some tional tricks including lazy evaluations and tion which enable optimized implementations for ious submodular functions
as a result we show that once the important visual features have been extracted via a pre processing step we can obtain the summary subset of the video or frames in a few seconds
this allows the user to interactively obtain summaries of various lengths types and queries in real time
we pirically demonstrate the benet of memoization and lazy greedy implementations for various video marization problems
most past work on video and image collection rization either use a subset of hand tuned submodular tions or a learnt mixture of submodular tions
this work addresses the orthagonal aspect how do different subclasses of submodular functions model summarization and their performance in different video mains
we believe the insights gathered from this work will help practitioners in choosing appropriate models for several real world video and image summarization tasks

background and main ideas this section describes the building blocks of our work namely the submodular summarization framework and the basics of convolutional neural networks for age recognitions to extract all the objects scenes faces humans


submodular summarization framework we assume we are given a set v n of items which we also call the ground set
also dene a utility function r which measures how good of a summary a set x v is
let c r be a cost function which describes the cost of the set for example the size of the subset
the goal is then to have a summary set x which maximizes while simultaneously minimizes the cost function c
in this paper we study a special class of set functions called submodular functions
given two subsets x y v a set function is submodular if x x y j for y
this is also called the diminishing returns property
several diversity and coverage functions are submodular since they satisfy this diminishing returns property
we also call a function monotone submodular if x y if x y v
the ground set v and the items n depend on the choice of the task at hand
we now dene a few relevant optimization problems which shall come up in our problem formulations problem max x xv problem is knapsack constrained submodular tion
the goal here is to nd a summary with a xed cost and sn denotes the cost of each element in the ground set
a special case is cardinality constrained submodular maximization when the individual costs are
this a natural model for extracting xed length mary videos or a xed number of keyframes
problem min this problem is called the submodular cover problem
is the modular cost function and c is the age constraint
the goal here is to nd a minimum cost set x such that the submodular coverage or representation function covers information from the ground set
a special case of this is the set cover problem
moreover problem can be seen as a dual version of problem
submodular functions have been used for several marization tasks including image summarization video summarization document summarization training data summarization and active learning
using a greedy algorithm to optimize a submodular tion for selecting a subset gives a lower bound mance guarantee of around of optimal and in tice these greedy solutions are often within of optimal
this makes it advantageous to formulate or mate the objective function for data selection as a ular function


cnns for image feature extraction convolutional neural networks are critical to feature traction in our summarization framework
we pre process the video to extract key visual features including objects scenes faces humans
convolutional neural networks have recently provided state of the art results for several recognition tasks including object recognition scene recognition face recognition and object detection and localization
we next describe the end to end system in detail

method the input to our system is a video
our system then tracts all important features from the video and generates an analysis database
the user can then interact with the system in several ways
user can generate a video mary of a given length or extract a set of key frames or a montage describing the video
similarly the user can search for a query and extract video snippets of frames which are relevant to the query
finally the user can also view a mary of all objects scenes humans and faces in the video along with their statistics
all these interactions are enabled on the y in a few seconds
the user can also dene the summarization model of their choice
we investigate and compare different submodular models and argue the utility of different models based on the use case


problem formulation for the multi faceted sual summarization we now formulate problem statements across the ent summarization views
extractive summarization siders the entire video
we can generate a summary either in terms of key frames represent the video as a set of frames sampled at a frame rate or video snippets
in either case we extract a ground set v with each individual element ther being a key frame or a video snippet
we then solve problems or depending on the use case
problem is the right formulation if we are interested in obtaining a summary of a xed budget
problem is useful if we do nt care about the size of the video but we are interested in the summary capturing all the information of the video
in the case of query based summarization we rst extract the set of frames or snippets relevant to that query q
denote this by vq
we then solve the submodular optimization problem on vq
finally in the case of entity based summarization we extract all the entities in the video and denote the set of entities as ve
ve represents for example all the faces of people in the video
we can then run our summarization with ve as the groundset
in the case of extractive or query based summarization the ground truth elements can be either frames of video snippets
our video snippets can be either xed length pets or shots obtained from a shot detector
if the pets are xed length snippets say or seconds we can use the cardinality constrained submodular maximization
if the snippets are shots from the video the length of each shot can differ and we have the more general knapsack strained setting
while our system can handle each of these modes we focus on the key frame based method for our experiments since we are interested in proving the utility of different summarization models
the insights will carry over to the other modes as well


submodular functions as summarization models this section describes the submodular functions used in our system
we divide these into coverage functions representation functions and diversity functions


modeling coverage this class of functions model notions of coverage i
e
try to nd a subset of the ground set x which covers a set of concepts
below are instantiations of this
set cover function denote v as the ground set and let x v be a subset of snippets or frames
further u notes a set of concepts which could represent for example scenes or objects
each frame or snippet i x contains a subset ui u set of concepts for example an image ers a table chair and person
the set cover function then is x ui where wu denotes the weight of concept u
probabilistic set cover this is a generalization of the set cover function to include probabilities piui for each object ui in image i x
for example our convolutional neural network might output a condence of object ui in image i and we can use that in our function
the probabilistic coverage function is dened as x pij
iu ix the set cover function is a special case of this if pij if object j belongs to image i i
e
we use the hard labels instead of probabilities
feature based functions finally we investigate the class of feature based functions
here we denote an image i via a feature representation qi
this could be for example the features extracted from the second last layer of a convnet
denote f as the set of features
the feature based function is dened as x if where jx qij and qij is the value of feature i in image j
is a concave function
examples of are square root log and inverse function


modeling representation representation based functions attempt to directly model representation in that they try to nd a representative subset of items akin to centroids and mediods in clustering
facility location function the facility location tion is closely related to k mediod clustering
denote sij as the similarity between images i and j
we can then dene x iv maxjx sij
for each image i we compute the representative from x which is closest to i and add the similarities for all images
note that this function requires computing a similarity function
however as shown in we can approximate this with a nearest neighbor graph which will require much smaller space requirement and also can run much faster for large ground set sizes
saturated coverage function saturated coverage function this function is similar to facility location and attempts to model representation
this is also a kernel based function and requires computing the similarity matrix
graph cut functions we dene the graph cut family of functions as f x i jx sij
this function is similar to the facility location and rated coverage in terms of its modeling behaviour
jx sij ix sij is dened as iv sij
x the iv

modeling diversity the third class of functions are diversity based ones which attempt to obtain a diverse set of key points
dispersion disparity functions denote dij as a tance measure between images i and j
dene a set tion x mini jx dij
this function is not ular but can be efciently optimized via a greedy rithm
it is easy to see that maximizing this function involves obtaining a subset with maximal minimum wise distance thereby ensuring a diverse subset of snippets or keyframes
similar to the minimum disparity we can dene two more variants
one is disparity sum which can be dened as f x i jx dij
this is a supermodular function
another model is what we call disparity sum which is a combination of the two forms of models
dene this as f x ix minjx dij
this function is submodular
determinantal point processes another class of tions are determinantal point processes dened as where s is a similarity kernel matrix and sx notes the rows and columns instantiated with elements in x
it turns out that x log is submodular and hence can be efciently optimized via the greedy algorithm
like the other choices of submodular functions investigated so far this requires computing the determinant and is where n is the size of the ground set
this function is not computationally feasible and hence we do not use it in our system since we require near real time results in rization
figure
illustration of the difference between diversity functions coverage functions and representation functions name facility location saturated coverage graph cut feature based set cover prob
set cover dpp dispersion min dispersion sum dispersion min sum x iv maxkx sik iv iv jx sij i i jx sij jx sij if ui iu kx pik pf x maxkx sik i v jx sij i v jx sij i v i f ix ui t p t o kx pik i u log mink lx dkl lx dkl kx minlx dkl mink lx dkl kx dkl x minkx dkl x table
list of submodular functions used with the precompute statistics pf x gain evaluated using the precomputed statistics pf x and nally t p as the cost with memoization
it is easy to see that memoization saves an order of magnitude in computation
o as the cost of evaluation the function without memoization and t f

modeling importance and relevance to model importance or relevance we use modular terms
given a specic task we train a supervised model to predict the important frames in that video for ample a goal might be considered important in a soccer video
given this learnt model we can predict the score of each frame and rank the scores
this is exactly equivalent to optimize the modular function dened with these scores


understanding diversity representation and coverage figure demonstrates the intuition of using diversity sentation and coverage functions
diversity based functions attempt to nd the most different set of images
the most gure in fig
demonstrates this
it is easy to see that the ve most diverse images are picked up by the diversity function disparity min and moreover the summary also contains the image with a hand covering the camera the age on the right hand side bottom which is an outlier
the middle gure demonstrates the summary obtained via a resentation function like facility location
the summary does not include outliers but rather contains one tative image from each cluster
the diversity function on the other hand does not try to achieve representation from every cluster
the third gure demonstrates coverage tions
the summary obtained via a coverage function like set cover or feature based function covers all the cepts contained in the images male car greenery beach



instantiations of the submodular functions having discussed the choices of the submodular tions and features we go over the specic instantiations of submodular functions considered in our system
first sider extractive and query based summarization
for the facility location function and the disparity min function we dene the similarity kernel as sij i s f j s i o f j o i h j where fs represent normalized deep scene features tracted using googlenet on fo represents normalized deep object features using googlenet on agenet h represents the normalized color histogram features
since the disparity min function uses a distance function we use dij sij
for feature based tions the feature set f is a concatenation of the scene tures fs and object features fo
in order to dene the set cover function we dene ui as the scene and yolo ject labels corresponding to the image
recall that the labels for scenes and objects were chosen based on a pre dened threshold i
e
select scene and objects labels if the bility for the label is greater than a threshold
the bilistic set cover function is dened via a concatenation of the probabilities from the scene and object models
query based summarization for keyframes is identical to tive summarization except that we rst get a groundset vq which is related to the query
the queries are either objects scenes faces humans with age and gender text in the video as well as meta data like subtitles
finally for entity or concept based summarization we extract the entities from the videos
entities we consider are objects faces
for faces we use the vgg face model from pretrained on celeb face data for face recognition
the objects are localized using yolo
we extract features from googlenet along with color histogram
the similarity kernel we use here is sij i i h j
o f j next we discuss the choice of the submodular functions
facility location disparity min sum graph cut rated coverage and dpps are instantiated using similarity kernels discussed above
feature based functions are ned directly via features and we use the deep features as described above
in the case of the set cover and tic set cover functions we use the labels and probabilities respectively from the deep models as the concepts


optimization algorithms the previous sections describe the models used in our system
we now investigate optimization algorithms which solve problems and
variants of a greedy algorithm vide near optimal solutions with approximation guarantees for problems
budget constrained submodular maximization for the budget constrained version problem the greedy gorithm is a slight variant where at every iteration we t quentially update x x t argmaxjv t
this algorithm has near optimal guarantees
submodular cover problem for the submodular cover problem problem we again resort to a greedy dure which is near optimal
in this case the date is similar to that of problem i
e
choose x x t argmaxjv tf t
we stop as soon as f x v or in other words we achieve a set which covers all the concepts
lazy greedy implementations each of the greedy gorithms above admit lazy versions which run much faster than the worst case complexity above
the idea is that instead of recomputing t j we maintain a ority queue of sorted gains j v
initially is set to f j v
the algorithm selects an element x t if t we add j to x t thanks to larity
if t we update to f t and re sort the priority queue
the complexity of this algorithm is roughly where nr is the average number of re sorts in each iteration
note that nr n while in tice it is a constant thus offering almost a factor n speedup compared to the simple greedy algorithm
function fac loc sat cov gr cut feat b set cov psc dpp dm ds memoization no memoization























table
timing results in seconds for summarizing a two hour video for various submodular functions
implementational tricks this section goes over implementation tricks via ization
one of the parameters in the lazy greedy algorithms is tf which involves evaluating x j x
one tion is to do a nave implementation of computing x j and then x and take the difference
however due to the greedy nature of algorithms we can use memoization and maintain a precompute statistics pf x at a set x using which the gain can be evaluated much more efciently
at every iteration we evaluate f using pf x which we call pf
we then update pf x j after adding ement j to x
table provides the precompute statistics as well as the computational gain for each choice of a modular function
denote t o as the time taken to navely compute x
denote t p o as the time taken to evaluate this gain given the pre compute statistics
we see from table that evaluating the gains using memoization is often an order of magnitude faster
over notice that we also need to update the pre compute statistics px at every iteration
for the functions listed in table the cost of updating the pre compute statistics is also t p
hence every iteration of the lazy greedy rithm costs only t p instead of t o which is an order of magnitude larger in every case
in our results section we evaluate empirically the benet of memoization in practice

results our system is implemented in
we use caffe and darknet for deep cnns and opencv for other computer vision tasks
a graphical representation of our system is depicted in figure
figure shows the results for extractive summarization as keyframes extractive summarization on concepts or tities and query based summarization on keyframes
we compare the different summarization models under various scenarios and evaluation measures
instead of comparing all the submodular functions described above we consider representatives from each class of functions
we use ity location as a representative function disparity min for diversity and set cover as a choice for coverage functions
we next create a dataset of videos from different egories
we select videos from the following truth from these videos to dene various evaluation ria
the annotation mechanism and evaluation criteria is described in each of the sections below
the goal of this is to demonstrate the role of various summarization models
extractive summarization representation the top figure in fig
demonstrates the results of extractive marization on movies and tv shows
diversity models tend to pick up outlier events which in this case include transition scenes and other outliers
in contrast the resentation function facility location tends to pick the representative scenes
the coverage function does thing in between
in the case of a tv show tative shots are probably more important compared to the transition scenes
to quantify this dene an evaluation measure as follows
we divide a movie tv show into a set of scenes sk where each scene si is a tinuous shot of events
we do not include the outliers we dene outliers as shots less than a certain length for example transition scenes
given a summary x dene
a summary with a large value of will not include the outliers and will pick only single representatives from each scene
we ate this on different tv show and movie videos
figure top left compares the representative diversity and age models and a random summary baseline
we see the representative model facility location tends to perform the best as expected followed by the coverage model
the diversity model does poorly since it picks a lot of outliers
extractive summarization coverage next we dene an evaluation criteria capturing coverage
for each frame in the video sampled at dene a set of concepts ered u
denote as the set of concepts covered by a set x
for each frame of the video we hand pick a set of cepts scenes and objects contained in the video
dene the coverage objective as
figure demonstrates the coverage objective for the different els
we obtain this by creating a set of labeled videos of different categories surveillance tv shows movies and travel videos
as expected the coverage function set cover achieves superior results compared to the other els
extractive summarization outliers and diversity in the above paragraphs we dene two complementary uation criteria one which captures representation and other which measures coverage
we argue how for ple representation is important in movies and tv shows
we now demonstrate how the diversity models tend to lect outliers and anomalies
to demonstrate this we select a set of surveillance videos
most of our videos have tive events like no activity or people sitting working
given this we mark all the different events what we call liers including for example people walking in the range of the camera or any other different activity
we create a dataset of surveillance videos with different ios
most of these videos have less activity
given a set figure
illustration of the results
the top gure shows the results from extractive summarization on tv shows the ond demonstrates entity summary on a tv show
the third ure shows the results of query based summarization on a query skyscraper while the fourth one shows the results of extractive summarization on surveillance videos
in each case we compare representation diversity and coverage models
see the text for more details
figure
comparison of diversity coverage and representation models for various domains and scenarios
see the text for more details
gories movies tv shows surveillance camera footage travel videos and sports videos like soccer
in the ing sections we annotate various events of interest extractive summary tv shows friends season episode diversity function disparity min coverage function set cover representation function facility location entity summary faces tv shows how i met your mother diversity function disparity min representation facilty location coverage fn feature based query based summary skyscrapers travel video diversity function disparity min representation facilty location coverage fn feature based extractive summary surveillance videos diversity function disparity min representation facilty location coverage fn feature based quantitative evaluation of extractive query and entity based summarization figure
end to end processing and summarization of a video sk of these events marked in the video dene
note this measure is ilar to the representative evaluation criteria except that it is dened w

t the outlier events
figure middle left shows the comparison of the performance of different models on this dataset
as expected the diversity measures outperforms the other models consistently
extractive summarization importance to strate the benet of having the right importance or vance terms we take a set of videos where intuitively the relevance term should matter a lot
examples include sports videos like soccer
to demonstrate this we train a model to predict important events of the video e

the goals red card
we then dene a simple modular function where the score is the output of the classier
we then test this out and compare the importance model to other summarization models
the results are shown in figure middle right
as we expect the model with the importance gets the est scores
query summarization diversity we next look at query based summarization
the goal of query based tion is to obtain a summary set of frames which satisfy a given query criteria
figure third row qualitatively shows the results for the query sky scrapers
the versity measure is able to obtain a diversity of the different scenes
even if there is an over representation of a certain scene in the set of images satisfying the query the diversity measure tends to pick a diverse set of frames
the tation measure however tends to focus on the representative frames and can pick more than one image in the summary from scenes which have an over representation in the query set
we see this figure
to quantify this we dene a measure m x by dividing the video into a set of clusters of frames sk where each cluster contains similar frames
these are often a set of continuous frames in the video
we evaluate this on a set of travel videos and compare the different models
we see that the diversity and representation models tend to perform the best figure bottom left with the diversity model slightly ing the representative models
we also observe that there are generally very few outliers in the case of query based summarization which is another reason why the diversity model tends to perform well
entity summarization lastly we look at entity marization
the goal here is to obtain a summary of the tities faces objects humans in the video
figure second row demonstrates the results for entity summarization of faces
we see the results for diversity coverage and resentation models
the diversity model tends to pick up outliers many of which are false positives i
e
not faces
the representation model skips all outliers and tends to pick representative faces
to quantitavely evaluate this we ne a representation measure as follows
we remove all the outliers and cluster the set of entities objects faces into a set of clusters ek where ei is a cluster of ilar entities
we evaluate this again on a set of videos
figure bottom right shows the results for objects
the results for faces is similar and in the interest of space we do not include these
we see that the representation model tends to outperform the other models and skips all the liers
the diversity model focuses on outliers and hence does not perform as well
scalability finally we demonstrate the computational scalability of our framework
table shows the results of the time taken for summarization for a two hour video in seconds with and without memoization
the groundset size is
we see huge gains from using ization compared to just computing the gains using the acle models of the functions
all our experiments were formed on cpu
ghz dual cpu with gb ram
we used a nvidia gtx gb gpu for the deep learning
for the two hour video the preprocessing took around minutes on a gle gpu
it would be much faster on multiple gpus and moreover this is typically done only once

conclusion this paper presents a unied picture of multi faceted video summarization for extractive query based and entity based summarization
in each case we take a closer look at the different summarization models and argue the benets of these models in different domains
we qualitatively and quantitatively argue this by comparing the results on several domains
finally we discuss various implementation tricks to build applications around video and image tion in production systems
references s
chakraborty o
tickoo and r
iyer
adaptive keyframe selection for video summarization
in cations of computer vision wacv ieee ter conference on pages
ieee
w

chu y
song and a
jaimes
video summarization video summarization by visual in proceedings of ieee cvpr pages occurrence

a
dasgupta r
kumar and s
ravi
summarization in acl through submodularity and dispersion
pages
d
b
goldman b
curless d
salesin and s
m
seitz
schematic storyboarding for video in acm transactions on graphics tion and editing
tog volume pages
acm
b
gong w

chao k
grauman and f
sha
verse sequential subset selection for supervised video in advances in nips pages summarization

m
gygli h
grabner h
riemenschneider and l
van gool
creating summaries from user videos
in in proc
eccv pages
springer
m
gygli h
grabner h
riemenschneider and l
van gool
creating summaries from user videos
in eccv
m
gygli h
grabner and l
van gool
video marization by learning submodular mixtures of tives
in proc
cvpr pages
m
gygli y
song and l
cao
automatic in in proc
generation of animated gifs from video
cvpr pages
k
he x
zhang s
ren and j
sun
deep ual learning for image recognition
in proceedings of the ieee conference on computer vision and pattern recognition pages
r
k
iyer and j
a
bilmes
submodular tion with submodular cover and submodular knapsack constraints
in advances in nips pages
y
jia e
shelhamer j
donahue s
karayev j
long r
girshick s
guadarrama and t
darrell
caffe convolutional architecture for fast feature embedding
in proceedings of the acm international ence on multimedia pages
acm
j
kopf m
f
cohen and r
szeliski
first person hyper lapse videos
acm transactions on graphics tog
a
krause
optimizing sensing theory and tions
proquest
a
krizhevsky i
sutskever and g
e
hinton
agenet classication with deep convolutional neural in advances in nips pages networks

y
j
lee j
ghosh and k
grauman
discovering portant people and objects for egocentric video in in proc
cvpr pages
marization
ieee
y
li and b
merialdo
multi video summarization based on video mmr
in image analysis for dia interactive services wiamis national workshop on pages
ieee
h
lin and j
bilmes
a class of submodular functions in proceedings of the for document summarization
annual meeting of the association for tational linguistics human language volume pages
association for tional linguistics
h
lin and j
bilmes
learning mixtures of ular shells with application to document in uncertainty in articial intelligence uai
tion
auai
z
lu and k
grauman
story driven summarization in proc
cvpr pages for egocentric video

j
meng h
wang j
yuan and y

tan
from keyframes to key objects video summarization by in proc
representative object proposal selection
cvpr pages
m
minoux
accelerated greedy algorithms for in optimization imizing submodular set functions
techniques pages
springer
g
l
nemhauser l
a
wolsey and m
l
fisher
an analysis of approximations for maximizing modular set functionsi
mathematical programming
o
m
parkhi a
vedaldi and a
zisserman
deep face recognition
in bmvc volume page
d
potapov m
douze z
harchaoui and c
schmid
in in proc
category specic video summarization
eccv pages
springer
y
pritch a
rav acha and s
peleg
cal video synopsis and indexing
in proc
ieee pami
j
redmon s
divvala r
girshick and a
farhadi
you only look once unied real time object tion
in proceedings of the ieee conference on puter vision and pattern recognition pages
i
simon n
snavely and s
m
seitz
scene rization for online image collections
in computer sion
iccv
ieee international ference on pages
ieee
p
sinha and r
jain
extractive summarization of personal photos from life events
in multimedia and expo icme ieee international conference on pages
ieee
y
song j
vallmitjana a
stent and a
jaimes
sum summarizing web videos using titles
in cvpr pages
ieee computer society
m
sun a
farhadi b
taskar and s
seitz
salient in european montages from unconstrained videos
conference on computer vision pages
springer
m
sviridenko
a note on maximizing a submodular set function subject to a knapsack constraint
tions research letters
m
j
swain and d
h
ballard
color indexing
ternational journal of computer vision
c
szegedy w
liu y
jia p
sermanet s
reed d
anguelov d
erhan v
vanhoucke and a
novich
going deeper with convolutions
in ings of the ieee conference on computer vision and pattern recognition pages
s
tschiatschek r
k
iyer h
wei and j
a
bilmes
learning mixtures of submodular functions for image collection summarization
in advances in nips pages
k
wei r
k
iyer and j
a
bilmes
fast multi stage in icml pages submodular maximization

k
wei r
k
iyer and j
a
bilmes
submodularity in data subset selection and active learning
in icml pages
w
wolf
key frame selection by motion analysis
in in proc
icassp volume pages
ieee
l
a
wolsey
an analysis of the greedy algorithm for the submodular set covering problem
combinatorica
k
zhang w

chao f
sha and k
grauman
mary transfer exemplar based subset selection for in proceedings of the ieee video summarization
conference on computer vision and pattern nition pages
b
zhao and e
p
xing
quasi real time tion for consumer videos
in proceedings of the ieee conference on computer vision and pattern tion pages
b
zhou a
lapedriza j
xiao a
torralba and a
oliva
learning deep features for scene recognition using places database
in advances in neural tion processing systems pages

