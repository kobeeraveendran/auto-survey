l u j l c
s c v
v i x r a text summarization techniques a brief survey mehdi allahyari computer science department university of georgia athens ga
edu saeid safaei computer science department university of georgia athens ga
edu mehdi asse computer science department university of georgia athens ga
edu juan b
gutierrez department of mathematics institute of bioinformatics university of georgia athens ga
edu seyedamin pouriyeh computer science department university of georgia athens ga
edu elizabeth d
trippe institute of bioinformatics university of georgia athens ga
edu krys kochut computer science department university of georgia athens ga
uga
edu abstract in recent years there has been a explosion in the amount of text data from a variety of sources
this volume of text is an invaluable source of information and knowledge which needs to be eectively summarized to be useful
in this review the main approaches to automatic text summarization are described
we review the ent processes for summarization and describe the eectiveness and shortcomings of the dierent methods
ccs concepts information systems document topic models tion extraction summarization keywords text summarization knowledge bases topic models acm reference format mehdi allahyari seyedamin pouriyeh mehdi asse saeid safaei beth d
trippe juan b
gutierrez and krys kochut

text tion techniques a brief survey
in proceedings of arxiv usa july pages


nnnnnnn
nnnnnnn introduction with the dramatic growth of the internet people are overwhelmed by the tremendous amount of online information and documents
permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page
copyrights for third party components of this work must be honored
for all other uses contact the owner
arxiv july usa copyright held by the owner
acm isbn xxxx xxxx yy mm





nnnnnnn
nnnnnnn this expanding availability of documents has demanded tive research in the area of automatic text summarization
ing to radef et al
a summary is dened as a text that is duced from one or more texts that conveys important information in the original and that is no longer than half of the original and usually signicantly less than that
automatic text summarization is the task of producing a concise and uent summary while preserving key information content and overall meaning
in recent years numerous approaches have been developed for automatic text summarization and applied widely in various domains
for example search engines generate snippets as the previews of the documents
other examples include news websites which produce condensed descriptions of news ics usually as headlines to facilitate browsing or knowledge tive approaches
automatic text summarization is very challenging because when we as humans summarize a piece of text we usually read it entirely to develop our understanding and then write a summary ing its main points
since computers lack human knowledge and language capability it makes automatic text summarization a very dicult and non trivial task
automatic text summarization gained attraction as early as the
an important research of these days was for ing scientic documents
luhn et al
introduced a method to extract salient sentences from the text using features such as word and phrase frequency
they proposed to weight the sentences of a document as a function of high frequency words ignoring very high frequency common words
edmundson et al
described a paradigm based on key phrases which in addition to standard quency depending weights used the following three methods to determine the sentence weight cue method the relevance of a sentence is calculated based on the presence or absence of certain cue words in the cue dictionary
arxiv july usa allahyari m
et al title method the weight of a sentence is computed as the sum of all the content words appearing in the title and headings of a text
location method this method assumes that sentences pearing in the beginning of document as well as the ning of individual paragraphs have a higher probability of being relevant
since then many works have been published to address the problem of automatic text summarization see for more information about more advanced techniques until
in general there are two dierent approaches for automatic marization extraction and abstraction
extractive summarization ods work by identifying important sections of the text and ating them verbatim thus they depend only on extraction of tences from the original text
in contrast abstractive tion methods aim at producing important material in a new way
in other words they interpret and examine the text using advanced natural language techniques in order to generate a new shorter text that conveys the most critical information from the original text
even though summaries created by humans are usually not extractive most of the summarization research today has focused on extractive summarization
purely extractive summaries often times give better results compared to automatic abstractive maries
this is because of the fact that abstractive rization methods cope with problems such as semantic tation inference and natural language generation which are tively harder than data driven approaches such as sentence tion
as a matter of fact there is no completely abstractive rization system today
existing abstractive summarizers often rely on an extractive preprocessing component to produce the abstract of the text
consequently in this paper we focus on extractive tion methods and provide an overview of some of the most inant approaches in this category
there are a number of papers that provide extensive overviews of text summarization techniques and systems
extractive summarization as mentioned before extractive summarization techniques produce summaries by choosing a subset of the sentences in the original text
these summaries contain the most important sentences of the input
input can be a single document or multiple documents
in order to better understand how summarization systems work we describe three fairly independent tasks which all summarizers perform construct an intermediate representation of the put text which expresses the main aspects of the text
score the sentences based on the representation
select a summary prising of a number of sentences

intermediate representation every summarization system creates some intermediate tation of the text it intends to summarize and nds salient content based on this representation
there are two types of approaches based on the representation topic representation and indicator resentation
topic representation approaches transform the text into an intermediate representation and interpret the discussed in the text
topic representation based summarization techniques dier in terms of their complexity and representation model and are divided into frequency driven approaches topic word approaches latent semantic analysis and bayesian topic models
we rate topic representation approaches in the following sections
dicator representation approaches describe every sentence as a list of features indicators of importance such as sentence length sition in the document having certain phrases

sentence score when the intermediate representation is generated we assign an importance score to each sentence
in topic representation approaches the score of a sentence represents how well the sentence explains some of the most important topics of the text
in most of the cator representation methods the score is computed by ing the evidence from dierent indicators
machine learning niques are often used to nd indicator weights

summary sentences selection eventually the summarizer system selects the top most tant sentences to produce a summary
some approaches use greedy algorithms to select the important sentences and some approaches may convert the selection of sentences into an optimization lem where a collection of sentences is chosen considering the straint that it should maximize overall importance and coherency and minimize the redundancy
there are other factors that should be taken into consideration while selecting the important sentences
for example context in which the summary is created may be ful in deciding the importance
type of the document e

news article email scientic paper is another factor which may impact selecting the sentences
topic representation approaches in this section we describe some of the most widely used topic representation approaches

topic words the topic words technique is one of the common topic tation approaches which aims to identify words that describe the topic of the input document
was one the earliest works that leveraged this method by using frequency thresholds to locate the descriptive words in the document and represent the topic of the document
a more advanced version of luhn s idea was presented in in which they used log likelihood ratio test to identify planatory words which in summarization literature are called the topic signature
utilizing topic signature words as topic sentation was very eective and increased the accuracy of document summarization in the news domain
for more mation about log likelihood ratio test see
there are two ways to compute the importance of a sentence as a function of the number of topic signatures it contains or as the proportion of the topic signatures in the sentence
both sentence scoring functions relate to the same topic representation however they might assign dierent scores to sentences
the rst method may assign higher scores to longer sentences because they have text summarization techniques a brief survey arxiv july usa more words
the second approach measures the density of the topic words

frequency driven approaches when assigning weights of words in topic representations we can think of binary or or real value continuous weights and cide which words are more correlated to the topic
the two most common techniques in this category are word probability and tfidf term frequency inverse document frequency


word probability
the simplest method to use frequency of words as indicators of importance is word probability
the ability of a word w is determined as the number of occurrences of the word w divided by the number of all words in the input which can be a single document or multiple documents w n vanderwende et al
proposed the sumbasic system which uses only the word probability approach to determine sentence portance
for each sentence sj in the input it assigns a weight equal to the average probability of the words in the sentence wi sj sj where is the weight of sentence sj
in the next step it picks the best scoring sentence that contains the highest probability word
this step ensures that the highest probability word which represents the topic of the document at that point is included in the summary
then for each word in the chosen sentence the weight is updated pnew wi pold wi pold wi this word weight update indicates that the probability of a word appearing in the summary is lower than a word occurring once
the aforementioned selection steps will repeat until the desired length summary is reached
the sentence selection approach used by sumbasic is based on the greedy strategy
yih et al
used an optimization approach as sentence selection strategy to imize the occurrence of the important words globally over the tire summary
is another example of using an optimization proach


tfidf
since word probability techniques depend on a stop word list in order to not consider them in the summary and because deciding which words to put in the stop list is not very straight forward there is a need for more advanced techniques
one of the more advanced and very typical methods to give weight to words is tfidf term frequency inverse document frequency
this weighting technique assesses the importance of words and identies very common words that should be omitted from sideration in the by giving low weights to words pearing in most documents
the weight of each word w in ment d is computed as follows fd lo fd w where fd is term frequency of word w in the document d fd w is the number of documents that contain word w and is the number of documents in the collection d
for more mation about tfidf and other term weighting schemes see
tfidf weights are easy and fast to compute and also are good measures for determining the importance of sentences therefore many existing summarizers have utilized this technique or some form of it
centroid based summarization another set of techniques which has become a common baseline is based on tfidf topic tation
this kind of method ranks sentences by computing their salience using a set of features
a complete overview of the based approach is available in but we outline briey the basic idea
the rst step is topic detection and documents that describe the same topic clustered together
to achieve this goal tfidf tor representations of the documents are created and those words whose tfidf scores are below a threshold are removed
then a clustering algorithm is run over the tfidf vectors consecutively adding documents to clusters and recomputing the centroids cording to c j cj where c j is the centroid of the jth cluster and cj is the set of uments that belong to that cluster
centroids can be considered as pseudo documents that consist of those words whose tfidf scores are higher than the threshold and form the cluster
the second step is using centroids to identify sentences in each cluster that are central to topic of the entire cluster
to accomplish this goal two metrics are dened cluster based relative utility cbru and cross sentence informational subsumption csis
cbru decides how relevant a particular sentence is to the general topic of the entire cluster and csis measure redundancy among sentences
in order to approximate two metrics three features i
e
central value positional value and rst sentence overlap are used
next the nal score of each sentence is computed and the selection of sentences is determined
for another related work see

latent semantic analysis latent semantic analysis lsa which is introduced by is an unsupervised method for extracting a representation of text tics based on observed words
gong and liu initially proposed a method using lsa to select highly ranked sentences for single and multi document summarization in the news domain
the lsa method rst builds a term sentence matrix n by m matrix where each row corresponds to a word from the input n words and each column corresponds to a sentence m sentences
each entry ai j of the matrix is the weight of the word i in sentence j
the weights of the words are computed by tfidf technique and if a sentence does not have a word the weight of that word in the sentence is zero
then singular value decomposition svd is used on the trix and transforms the matrix a into three matrices a u v t
matrix u n m represents a term topic matrix having weights of words
matrix is a diagonal matrix m m where each row arxiv july usa allahyari m
et al i corresponds to the weight of a topic i
matrix v t is the sentence matrix
the matrix d v t describes how much a tence represent a topic thus j shows the weight of the topic i in sentence j
gong and liu s method was to choose one sentence per each topic therefore based on the length of summary in terms of tences they retained the number of topics
this strategy has a drawback due to the fact that a topic may need more than one sentence to convey its information
consequently alternative lutions were proposed to improve the performance of lsa based techniques for summarization
one enhancement was to leverage the weight of each topic to decide the relative size of the mary that should cover the topic which gives the exibility of having a variable number of sentences
another advancement is described in
steinberger et al
introduced a lsa based method which achieves a signicantly better performance than the original work
they realized that the sentences that discuss some of important topics are good candidates for summaries thus in order to locate those sentences they dened the weight of the tence as follows let be the weight function then vut m i j for other variations of lsa technique see

bayesian topic models many of the existing multi document summarization methods have two limitations they consider the sentences as dent of each other so topics embedded in the documents are garded
sentence scores computed by most existing approaches typically do not have very clear probabilistic interpretations and many of the sentence scores are calculated using heuristics
bayesian topic models are probabilistic models that uncover and represent the topics of documents
they are quite powerful and appealing because they represent the information i
e
topics that are lost in other approaches
their advantage in describing and representing topics in detail enables the development of rizer systems which can determine the similarities and dierences between documents to be used in summarization
apart from enhancement of topic and document representation topic models often utilize a distinct measure for scoring the tence called kullbak liebler kl
the kl is a measure of ence divergence between two probability distributions p and q
in summarization where we have probability of words the kl divergence of q from p over the words w is dened as dk l p log w where and are probabilities of w in p and q
kl divergence is an interesting method for scoring sentences in the summarization because it shows the fact that good summaries are intuitively similar to the input documents
it describes how the importance of words alters in the summary in comparison with the input i
e
the kl divergence of a good summary and the input will be low
probabilistic topic models have gained dramatic attention in cent years in various domains
latent dirichlet allocation lda model is the state of the art unsupervised nique for extracting thematic information topics of a collection of documents
a complete review for lda can be found in but the main idea is that documents are represented as a random mixture of latent topics where each topic is a probability tion over words
lda has been extensively used for multi document tion recently
for example daume et al
proposed bayesum a bayesian summarization model for query focused summarization
wang et al
introduced a bayesian sentence based topic model for summarization which used both term document and term sentence associations
their system achieved signicance performance and outperformed many other summarization methods
celikyilmaz et al
describe multi document summarization as a prediction problem based on a two phase hybrid model
first they propose a hierarchical topic model to discover the topic structures of all sentences
then they compute the similarities of candidate tences with human provided summaries using a novel tree based sentence scoring function
in the second step they make use of these scores and train a regression model according the lexical and structural characteristics of the sentences and employ the model to score sentences of new documents unseen documents to form a summary
knowledge bases and automatic summarization the goal of automatic text summarization is to create summaries that are similar to human created summaries
however in many cases the soundness and readability of created summaries are not satisfactory because the summaries do not cover all the cally relevant aspects of data in an eective way
this is because many of the existing text summarization techniques do not sider the semantics of words
a step towards building more curate summarization systems is to combine summarization niques with knowledge bases semantic based or ontology based summarizers
the advent of human generated knowledge bases and various ontologies in many dierent domains e

wikipedia yago pedia has opened further possibilities in text summarization and reached increasing attention recently
for example henning et al
present an approach to sentence extraction that maps tences to concepts of an ontology
by considering the ontology tures they can improve the semantic representation of sentences which is benecial in selection of sentences for summaries
they experimentally showed that ontology based extraction of sentences outperforms baseline summarizers
chen et al
introduce a user query based text summarizer that uses the umls medical tology to make a summary for medical text
baralis et al
pose a yago based summarizer that leverages yago ontology to identify key concepts in the documents
the concepts are uated and then used to select the most representative document sentences
sankarasubramaniam et al
introduce an approach text summarization techniques a brief survey arxiv july usa that employs wikipedia in conjunction with a graph based ing technique
first they create a bipartite sentence concept graph and then use an iterative ranking algorithm for selecting summary sentences
the impact of context in summarization summarization systems often have additional evidence they can utilize in order to specify the most important topics of
for example when summarizing blogs there are discussions or comments coming after the blog post that are good sources of formation to determine which parts of the blog are critical and teresting
in scientic paper summarization there is a considerable amount of information such as cited papers and conference mation which can be leveraged to identify important sentences in the original paper
in the following we describe some the contexts in more details

web summarization web pages contains lots of elements which can not be summarized such as pictures
the textual information they have is often scarce which makes applying text summarization techniques limited
less we can consider the context of a web page i
e
pieces of mation extracted from content of all the pages linking to it as tional material to improve summarization
the earliest research in this regard is where they query web search engines and fetch the pages having links to the specied web page
then they alyze the candidate pages and select the best sentences ing links to the web page heuristically
delort et al
extended and improved this approach by using an algorithm trying to select a sentence about the same topic that covers as many aspects of the web page as possible
for blog summarization proposed a method that rst derives representative words from comments and then selects important sentences from the blog post ing representative words
for more related works see

scientic articles summarization a useful source of information when summarizing a scientic per i
e
citation based summarization is to nd other papers that cite the target paper and extract the sentences in which the ences take place in order to identify the important aspects of the target paper
mei et al
propose a language model that gives a probability to each word in the citation context sentences
they then score the importance of sentences in the original paper using the kl divergence method i
e
nding the similarity between a tence and the language model
for more information see
email summarization email has some distinct characteristics that indicates the aspects of both spoken conversation and written text
for example marization techniques must consider the interactive nature of the dialog as in spoken conversations
nenkova et al
presented early research in this regard by proposing a method to generate a summary for the rst two levels of the thread discussion
a thread consists of one or more conversations between two or more ipants over time
they select a message from the root message and from each response to the root considering the overlap with root context
rambow et al
used a machine learning technique and included features related to the thread as well as features of the email structure such as position of the sentence in the tread number of recipients
newman et al
describe a system to summarize a full mailbox rather than a single thread by clustering messages into topical groups and then extracting summaries for each cluster
indicator representation approaches indicator representation approaches aim to model the tion of the text based on a set of features and use them to directly rank the sentences rather than representing the topics of the put text
graph based methods and machine learning techniques are often employed to determine the important sentences to be cluded in the summary

graph methods for summarization graph methods which are inuenced by pagerank algorithm represent the documents as a connected graph
sentences form the vertices of the graph and edges between the sentences indicate how similar the two sentences are
a common technique employed to connect two vertices is to measure the similarity of two sentences and if it is greater then a threshold they are connected
the most often used method for similarity measure is cosine similarity with tfidf weights for words
this graph representation results in two outcomes
first the partitions sub graphs included in the graph create discrete ics covered in the documents
the second outcome is the cation of the important sentences in the document
sentences that are connected to many other sentences in the partition are bly the center of the graph and more likely to be included in the summary
graph based methods can be used for single as well as document summarization
since they do not need specic linguistic processing other than sentence and word ary detection they can also be applied to various languages
nonetheless using tfidf weighting scheme for similarity sure has limitations because it only preserves frequency of words and does not take the syntactic and semantic information into count
thus similarity measures based on syntactic and semantic information enhances the performance of the summarization tem
for more graph based approaches see

machine learning for summarization machine learning approaches model the summarization as a cation problem
is an early research attempt at applying chine learning techniques for summarization
kupiec et al
develop a classication function naive bayes classier to classify the tences as summary sentences and non summary sentences based on the features they have given a training set of documents and their extractive summaries
the classication probabilities are learned statistically from the training data using bayes rule arxiv july usa allahyari m
al


fk


fk s


fk where s is a sentence from the document collection


fk are features used in classication and s is the summary to be erated
assuming the conditional independence between the tures


fk i s i the probability a sentence to belongs to the summary is the score of the sentence
the selected classier plays the role of a sentence scoring function
some of the frequent features used in summarization include the position of sentences in the document sentence length presence of uppercase words similarity of the tence to the document title
machine learning approaches have been widely used in summarization by to name a few
naive bayes decision trees support vector machines hidden markov models and conditional random fields are among the most common machine learning techniques used for summarization
one fundamental dierence between classiers is that sentences to be included in the summary have to be decided independently
it turns out that methods explicitly assuming the dependency between tences such as hidden markov model and conditional dom fields often outperform other techniques
one of the primary issues in utilizing supervised learning ods for summarization is that they need a set of training documents labeled data to train the classier which may not be always ily available
researchers have proposed some alternatives to cope with this issue annotated corpora creation creating annotated pus for summarization greatly benets the researchers cause more public benchmarks will be available which makes it easier to compare dierent summarization approaches together
it also lowers the risk of overtting with a limited data
ulrich et al
introduce a publicly available tated email corpus and its creation process
however ating annotated corpus is very time consuming and more critically there is no standard agreement on choosing the sentences and dierent people may select varied sentences to construct the summary
semi supervised approaches using a semi supervised technique to train a classier
in semi supervised ing we utilize the unlabeled data in training
there is ally a small amount of labeled data along with a large amount of unlabeled data
for complete overview of supervised learning see
wong et al
proposed a semi supervised method for extractive summarization
they co trained two classiers iteratively to exploit beled data
in each iteration the unlabeled training ples sentences with top scores are included in the labeled training set and the two classiers are trained on the new training data
specically in class specic summarization where classiers are trained to locate particular type of information such as scientic paper summarization and biographical summaries
evaluation evaluation of a summary is a dicult task because there is no ideal summary for a document or a collection of documents and the inition of a good summary is an open question to large extent
it has been found that human summarizers have low agreement for evaluating and producing summaries
additionally prevalent use of various metrics and the lack of a standard evaluation metric has also caused summary evaluation to be dicult and challenging

evaluation of automatically produced summaries there have been several evaluation campaigns since the late in the us
they include summac duc the document understanding conference and more recently tac the text analysis conference present
these conferences have primary role in design of evaluation standards and evaluate the summaries based on human as well as automatic scoring of the summaries
in order to be able to do automatic summary evaluation we need to conquer three major diculties it is fundamental to cide and specify the most important parts of the original text to preserve
ii evaluators have to automatically identify these pieces of important information in the candidate summary since this formation can be represented using disparate expressions
the readability of the summary in terms of grammaticality and ence has to be evaluated

human evaluation the simplest way to evaluate a summary is to have a human assess its quality
for example in duc the judges would evaluate the erage of the summary i
e
how much the candidate summary ered the original given input
in more recent paradigms in ular tac query based summaries have been created
then judges evaluate to what extent a summary answers the given query
the factors that human experts must consider when giving scores to each candidate summary are grammaticality non redundancy tegration of most important pieces of information structure and coherence
for more information see

automatic evaluation methods there has been a set of metrics to automatically evaluate maries since the early
rouge is the most widely used ric for automatic evaluation


rouge
lin introduced a set of metrics called oriented understudy for gisting evaluation rouge to ically determine the quality of a summary by comparing it to man reference summaries
there are several variations of rouge see and here we just mention the most broadly used ones machine learning methods have been shown to be very tive and successful in single and multi document summarization
nist
gov tac about index
html text summarization techniques a brief survey arxiv july usa rouge n this metric is recall based measure and based on comparison of n grams
a series of n grams mostly two and three and rarely four is elicited from the ence summaries and the candidate summary cally generated summary
let p be the number of mon n grams between candidate and reference summary and q be the number of n grams extracted from the ence summary only
the score is computed as rouge n p q rouge l this measure employs the concept of longest common subsequence lcs between the two sequences of text
the intuition is that the longer the lcs between two summary sentences the more similar they are
although this metric is more exible than the previous one it has a drawback that all n grams must be consecutive
for more information about this metric and its rened metric see
rouge su this metric called skip bi gram and uni gram rouge and considers bi grams as well as uni grams
this metric allows insertion of words between the rst and the last words of the bi grams so they do not need to be secutive sequences of words
conclusions the increasing growth of the internet has made a huge amount of information available
it is dicult for humans to summarize large amounts of text
thus there is an immense need for automatic summarization tools in this age of information overload
in this paper we emphasized various extractive approaches for single and multi document summarization
we described some of the most extensively used methods such as topic representation approaches frequency driven methods graph based and machine learning techniques
although it is not feasible to explain all verse algorithms and approaches comprehensively in this paper we think it provides a good insight into recent trends and gresses in automatic summarization methods and describes the state of the art in this research area
acknowledgments this project was funded in part by federal funds from the us tional institute of allergy and infectious diseases national tutes of health department of health and human services under contract which supports the malaria pathogen interaction center mahpic
conflict of interest the that there is no conict of interest ing the publication of this article
references amjad abu jbara and dragomir radev

coherent citation based rization of scientic papers
in proceedings of the annual meeting of the sociation for computational linguistics human language technologies volume
association for computational linguistics
rasim m alguliev ramiz m aliguliyev makrufa s hajirahimova and chingiz a mehdiyev

mcmr maximum coverage and minimum redundant text marization model
expert systems with applications
rasim m alguliev ramiz m aliguliyev and nijat r isazade

multiple uments summarization based on evolutionary optimization algorithm
expert systems with applications
mehdi allahyari and krys kochut

automatic topic labeling using ontology based topic models
in machine learning and applications icmla ieee international conference on
ieee
mehdi allahyari and krys kochut

discovering coherent topics with entity topic models
in web intelligence wi ieee wic acm international conference on
ieee
mehdi allahyari and krys kochut

semantic context aware tion via topic models leveraging linked open data
in international conference on web information systems engineering
springer
mehdi allahyari and krys kochut

semantic tagging using topic models exploiting wikipedia category network
in semantic computing icsc ieee tenth international conference on
ieee
m
allahyari s
pouriyeh m
asse s
safaei e
d
trippe j
b
gutierrez and k
kochut

a brief survey of text mining classication clustering and extraction techniques
arxiv e prints

einat amitay and ccile paris

automatically summarising web sites is there a way around it
in proceedings of the ninth international conference on information and knowledge management
acm
elena baralis luca cagliero saima jabeen alessandro fiori and sajid shah

multi document summarization based on the yago ontology
expert tems with applications
taylor berg kirkpatrick dan gillick and dan klein

jointly learning to extract and compress
in proceedings of the annual meeting of the ciation for computational linguistics human language technologies volume
association for computational linguistics
david m blei andrew y ng and michael i jordan

latent dirichlet tion
the journal of machine learning research
asli celikyilmaz and dilek hakkani tur

a hybrid hierarchical model for multi document summarization
in proceedings of the annual meeting of the association for computational linguistics
association for computational linguistics
yllias chali and shaq r joty

improving the performance of the random walk model for answering complex questions
in proceedings of the annual meeting of the association for computational linguistics on human language technologies short papers
association for computational linguistics
olivier chapelle bernhard schlkopf alexander zien and others

supervised learning
vol

mit press cambridge
ping chen and rakesh verma

a query based medical information rization system using ontology knowledge
in computer based medical systems
cbms
ieee international symposium on
ieee
freddy chong tat chua and sitaram asur

automatic summarization of events from social media

in icwsm
john m conroy and dianne p oleary

text summarization via hidden markov models
in proceedings of the annual international acm sigir ference on research and development in information retrieval
acm
hal daum iii and daniel marcu

bayesian query focused summarization
in proceedings of the international conference on computational linguistics and the annual meeting of the association for computational linguistics
sociation for computational linguistics
scott c
deerwester susan t dumais thomas k
landauer george w
furnas and richard a
harshman

indexing by latent semantic analysis
jasis
j y delort bernadette bouchon meunier and maria rifqi

enhanced web document summarization using hyperlinks
in proceedings of the fourteenth acm conference on hypertext and hypermedia
acm
ted dunning

accurate methods for the statistics of surprise and dence
computational linguistics
harold p edmundson

new methods in automatic extracting
journal of the acm jacm
gnes erkan and dragomir r radev

lexrank graph based lexical trality as salience in text summarization
j
artif
intell
res
jair
yihong gong and xin liu

generic text summarization using relevance measure and latent semantic analysis
in proceedings of the annual national acm sigir conference on research and development in information trieval
acm
vishal gupta and gurpreet singh lehal

a survey of text summarization extractive techniques
journal of emerging technologies in web intelligence
ben hachey gabriel murray and david reitter

dimensionality reduction aids term co occurrence based multi document summarization
in proceedings of arxiv july usa allahyari m
al the workshop on task focused summarization and question answering
association for computational linguistics
john hannon kevin mccarthy james lynch and barry smyth

alized and automatic social summarization of events in video
in proceedings of the international conference on intelligent user interfaces
acm
sanda harabagiu and finley lacatusu

topic themes for multi document summarization
in proceedings of the annual international acm sigir ference on research and development in information retrieval
acm
leonhard hennig winfried umbrath and robert wetzker

an based approach to text summarization
in web intelligence and intelligent agent technology
wi
ieee wic acm international conference on vol

ieee
meishan hu aixin sun and ee peng lim

comments oriented blog marization by sentence extraction
in proceedings of the sixteenth acm ence on conference on information and knowledge management
acm
meishan hu aixin sun and ee peng lim

comments oriented document summarization understanding documents with readers feedback
in ings of the annual international acm sigir conference on research and velopment in information retrieval
acm
kevin knight and daniel marcu

statistics based summarization step one sentence compression
in aaai iaai

solomon kullback and richard a leibler

on information and suciency
the annals of mathematical statistics
julian kupiec jan pedersen and francine chen

a trainable document summarizer
in proceedings of the annual international acm sigir ence on research and development in information retrieval
acm
chin yew lin

rouge a package for automatic evaluation of summaries
in text summarization branches out proceedings of the workshop

elena lloret and manuel palomar

text summarisation in progress a erature review
articial intelligence review
hans peter luhn

the automatic creation of literature abstracts
ibm journal of research and development
inderjeet mani and eric bloedorn

summarizing similarities and ences among related documents
information retrieval
inderjeet mani gary klein david house lynette hirschman therese firmin and beth sundheim

summac a text summarization evaluation
natural language engineering
qiaozhu mei and chengxiang zhai

generating impact based summaries for scientic literature

in acl vol

citeseer
rada mihalcea and paul tarau

textrank bringing order into texts
ciation for computational linguistics
single and multiple document summarization

liu na li ming xia lu ying tang xiao jun wang hai wen and xiao peng

mixture of topic model for multi document summarization
in control and decision conference ccdc the chinese
ieee
ani nenkova and amit bagga

facilitating email thread access by tive summary generation
recent advances in natural language processing iii selected papers from ranlp
ani nenkova and kathleen mckeown

a survey of text summarization techniques
in mining text data
springer
paula s newman and john c blitzer

summarizing archived discussions a beginning
in proceedings of the international conference on intelligent user interfaces
acm
you ouyang wenjie li sujian li and qin lu

applying regression els to query focused multi document summarization
information processing management
paul over hoa dang and donna harman

duc in context
inf
process
manage
nov



j
ipm


makbule gulcin ozsoy ilyas cicekli and ferda nur alpaslan

text marization of turkish texts using latent semantic analysis
in proceedings of the international conference on computational linguistics
association for putational linguistics
vahed qazvinian and dragomir r radev

scientic paper summarization using citation summary networks
in proceedings of the international ference on computational linguistics volume
association for computational linguistics
vahed qazvinian dragomir r radev saif m mohammad bonnie dorr david zajic michael whidby and taesun moon

generating extractive maries of scientic paradigms
arxiv preprint

dragomir r radev eduard hovy and kathleen mckeown

introduction to the special issue on summarization
computational linguistics
dragomir r radev hongyan jing and malgorzata budzikowska

based summarization of multiple documents sentence extraction utility based evaluation and user studies
in proceedings of the naacl anlp workshop on automatic summarization
association for computational linguistics
dragomir r radev hongyan jing magorzata sty and daniel tam

information processing centroid based summarization of multiple documents
management
owen rambow lokesh shrestha john chen and chirsty lauridsen

marizing email threads
in proceedings of hlt naacl short papers
ciation for computational linguistics
zhaochun ren shangsong liang edgar meij and maarten de rijke

sonalized time aware tweets summarization
in proceedings of the national acm sigir conference on research and development in information trieval
acm
horacio saggion and thierry poibeau

automatic text summarization in multi source multilingual information extraction past present and future
and summarization
springer
gerard salton and christopher buckley

term weighting approaches in automatic text retrieval
information processing management
yogesh sankarasubramaniam krishnan ramanathan and subhankar ghosh

text summarization using wikipedia
information processing ment
guergana k savova james j masanz philip v ogren jiaping zheng sunghwan sohn karin c kipper schuler and christopher g chute

mayo clinical text analysis and knowledge extraction system ctakes architecture ponent evaluation and applications
journal of the american medical informatics association
barry schiman inderjeet mani and kristian j concepcion

producing ographical summaries combining linguistic knowledge with corpus statistics
in proceedings of the annual meeting on association for computational guistics
association for computational linguistics
beaux shari mark anthony hutton and jugal kalita

summarizing croblogs automatically
in human language technologies the annual ference of the north american chapter of the association for computational guistics
association for computational linguistics
beaux p shari david i inouye and jugal k kalita

summarization of twitter microblogs
comput
j

dou shen jian tao sun hua li qiang yang and zheng chen

document summarization using conditional random fields

in ijcai vol


srgio soares bruno martins and pavel calado

extracting biographical sentences from textual documents
in proceedings of the portuguese ence on articial intelligence epia lisbon portugal

karen sprck jones

automatic summarising the state of the art
josef steinberger massimo poesio mijail a kabadjov and karel jeek

information processing two uses of anaphora resolution in summarization
management
mark steyvers and tom griths

probabilistic topic models
handbook of latent semantic analysis
fabian m suchanek gjergji kasneci and gerhard weikum

yago a core of semantic knowledge
in proceedings of the international conference on world wide web
acm
simone teufel and marc moens

summarizing scientic articles iments with relevance and rhetorical status
computational linguistics
e
d
trippe j
b
aguilar y
h
yan m
v
nural j
a
brady m
asse s
safaei m
allahyari s
pouriyeh m
r
galinski j
c
kissinger and j
b
gutierrez

a vision for health informatics introducing the sked framework
an extensible architecture for scientic knowledge extraction from data
arxiv e prints

andrew turpin yohannes tsegay david hawking and hugh e williams

fast generation of result snippets in web search
in proceedings of the annual international acm sigir conference on research and development in information retrieval
acm
jan ulrich gabriel murray and giuseppe carenini

a publicly available annotated corpus for supervised email summarization
in proc
of aaai workshop chicago usa
lucy vanderwende hisami suzuki chris brockett and ani nenkova

yond sumbasic task focused summarization with sentence simplication and information processing management lexical expansion

xiaojun wan and jianwu yang

multi document summarization using cluster based link analysis
in proceedings of the annual international acm sigir conference on research and development in information retrieval
acm
dingding wang shenghuo zhu tao li and yihong gong

document summarization using sentence based topic models
in proceedings of the acl ijcnlp conference short papers
association for computational rada mihalcea and paul tarau

a language independent algorithm for mation processing management
text summarization techniques a brief survey arxiv july usa linguistics
kam fai wong mingli wu and wenjie li

extractive summarization ing supervised and semi supervised learning
in proceedings of the tional conference on computational linguistics volume
association for putational linguistics
wen tau yih joshua goodman lucy vanderwende and hisami suzuki

multi document summarization by maximizing informative content words

in ijcai vol


liang zhou and eduard hovy

a web trained extraction summarization system
in proceedings of the conference of the north american chapter of the association for computational linguistics on human language volume
association for computational linguistics
liang zhou miruna ticrea and eduard hovy

multi document biography summarization
arxiv preprint

