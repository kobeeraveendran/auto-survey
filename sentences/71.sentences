fuzzy sets across the natural language generation pipeline a
ramos soto a
bugarn s
barro centro singular de investigacion en tecnoloxas informacion citius universidade santiago de compostela santiago de compostela spain alejandro
ramos alberto
bugarin
diz senen

a m i a
s c v
v i x r a we explore the implications of using fuzzy techniques mainly those commonly used in the linguistic description summarization of data discipline from a natural language generation perspective
for this we provide an extensive discussion of some general convergence points and an exploration of the relationship between the different tasks involved in the standard nlg system pipeline architecture and the most common fuzzy approaches used in linguistic summarization description of data such as fuzzy quantied statements evaluation criteria or aggregation operators
each individual discussion is illustrated with a related use case
recent work made in the context of cross fertilization of both research elds is also referenced
fuzzy sets computing with words linguistic description of data natural language generation data to text systems abstract index terms i
introduction data science has traditionally relied on analytics and visualization techniques to make sense of large volumes of data
data scientists employ different techniques such as statistics signal processing pattern recognition data mining or machine learning among others to extract relevant information from such amounts of data
however communication of the extracted information after the analytics process is usually made through graphics or visualization techniques that in general demand interpretation efforts from the user side and sometimes require a rather extensive academic development or expertise for its actual comprehension fig
shows an example of this problem
this issue arises the interest of using other kind of complementary descriptive techniques which help ll the gap between data and users in a more human friendly way so that the obtained information can be grasped by a wider range of people regardless of their expertise
in this regard approaches such as linguistic description of data ldd or natural language generation nlg which provide information expressed in terms of natural language have emerged as feasible complements which while still exploiting the full potential of standard data science analytics allow for a better understanding of what underlies in such data
in this regard recent studies indicate that non specialized users actually strongly demand textual descriptions of data as a means for better understanding of graphics and visualizations
the discipline of linguistic description or summarization of data ldd has become in recent times a very promising approach to capture the essential information residing in numerical data
it allows to easily obtain linguistic information structured in protoforms able to describe relationships between the values of the different input variables along time and even space dimensions
linguistic description of data is based primarily on the use of fuzzy quantied sentences and its main contribution is that it allows to manage the uncertainty and vagueness present in the human language concepts which are used to summarize data
this has led to an apparition of a very diverse collection of use cases in very different domains a rather representative review of such approaches can be found in
at the same time the natural language generation nlg eld which addresses the creation of systems able to automatically deliver texts indistinguishable from those produced by humans is currently experiencing a bursting scientic technical and commercial expansion in its data to text t specialty due to the rise of the big data era
the more data is available the more time experts and users need to make sense of it and while it may be a mundane task the creation of reports that describe in a few paragraphs what in origin were huge amounts of data is usually necessary in any organization
in this regard t solutions help analysts experts and users in general in saving time by performing data analysis and deliver relevant information as high quality texts
it is safe to assume that the t solutions provided by nlg companies do not include any uncertainty or vagueness management
in fact although nlg and t by extension excels in terms of generating texts whose quality is optimal paper encompasses general ideas that emerged as part of the phd thesis application of fuzzy sets in data to text systems
it does not present a specic application or a formal approach but rather discusses current high level issues and potential usages of fuzzy sets focused on linguistic summarization of data in natural language generation
fig

snapshot of the learning analytics dashboard softlearn which displays metrics and data plots a teacher must interpret to assess how students perform in a course
from a linguistic perspective the problem of how to address vagueness is still an open issue which is being actively researched in this discipline
in this context the current state of both ldd and nlg elds has led to a climate of mutual interest
ldd approaches may use nlg techniques to convert linguistic protoforms into information in an even more human friendly state which allows the delivery of high quality texts
likewise nlg systems may use ldd and other fuzzy related techniques to address the problem of uncertainty at different levels within the distinct tasks involved in an nlg process
examples from both trends include the galiweather system conceived as a ldd approach but made use of several nlg techniques to generate short term weather forecasts and the model presented in that involves fuzzy temporal constraint networks and experimental data from three languages to address the problem of generating uncertain temporal expressions from an nlg point of view
the previous examples show that collaboration between both elds is slowly but steadily starting to take place
however it is yet unclear which and how many forms this potential cross fertilization process will take
in this situation the aim of this paper is to study from a detailed and practical perspective several potential convergence points for ldd and nlg which may open new research lines in the context of such collaboration
furthermore we will also resume the discussion opened by kacprzyk and zadrozny in where a relationship between ldd and nlg was discussed for the rst time at a conceptual level and which was later expanded by which provided additional insights and state of the art reviews for both elds
this paper is organized in three main sections
section ii explores the challenges that ldd currently faces and how its usage together with nlg can help in addressing them
section iii studies in depth how the use of ldd techniques namely fuzzy quantied statements relate to the nlg tasks described by the well known and widely accepted nlg system architecture proposed by reiter and dale in as well as potential implications derived from such usage
finally section iv provides further insights into some of the topics of most interest in the context of the collaboration between ldd and nlg and summarizes the main contributions of this paper
linguistic descriptions of data can be used to extract relevant information from numeric input data sets
such descriptions are usually based on the concept of fuzzy quantied statement which is usually classied using zadeh s notion of protoform
in this regard two basic protoforms are distinguished ii
ldd and nlg main challenges q xs are a q dxs are a where q is a fuzzy quantier a is a summarizer and d is a qualier
these protoforms are also a representation of fuzzy quantied statements commonly referred to as eq
a few researchers are young or some of the humidity values were high and eq
most of the cold days were very humid
although protoforms have also been used in the context of fuzzy queries we will focus on their application in the automatic extraction of relevant linguistic information that is approaches applied to practical use cases in particular knowledge domains where the structure of the linguistic descriptions which are obtained is known a priori
following this denition fuzzy quantied statements in the literature have been used to a great extent as a means to summarize and describe time series of data
in this sense ldd emerges as a discipline with a similar purpose to that of t approaches to provide an understandable interface between the data and the human users in the form of information expressed in terms of natural language
however data to text is aimed at the production of actual texts while linguistic description of data remains in a more conceptual level
figure illustrates this contrast between both elds while it is feasible to obtain a linguistic description which summarizes a data set properly it is arguably useful for a human user if such linguistic information is not given in a way that matches the language used in the user s specic application domain
fig

contrast between protoform like linguistic information and an actual natural language text ready for human comsumption by general public
thus the main downside of linguistic descriptions of data is that they are restricted to protoform structures and although they are exible enough to be extended into more sophisticated forms including time and spatial dimensions for instance their usage in real applications is not feasible when provided as is
this issue was identied by kacprzyk and zadrozny in where they stated that zadeh s protoforms are very powerful and convenient in cww but may be a limiting factor in many real world applications as their structure is too restricted notably as compared to the richness of natural language
at the same time this necessity for a means to effectively use the fuzzy techniques developed in ldd in practical application domains has also opened up the possibility of resorting to nlg
in this regard kacprzyk and zadrozny proposed in to dene new types of protoforms to make a full use of the power of nlg tools
in their opinion to be able to generate statements that provide distinct and richer expressiveness than standard protoforms would expand the potential usages of ldd q xs are amost of coming days are cloudymost of the coming days will be cloudythe skies will be predominantly cloudy for the coming short term periodcontentlanguage and at a general level nlg techniques could be used to merge the best candidate statements obtained by a search algorithm into a proper text
in our opinion expanding the current collection of protoforms would entail a signicant advance for ldd in terms of expressiveness which in turn could probably bring ldd a step closer to nlg but not necessarily closer to its usage in real systems
in this regard the idea of nlg systems producing texts solely based on fuzzy protoforms however complex these may be seems unrealistic for the needs of actual systems
for instance the textual weather forecast generator galiweather employs fuzzy quantied sentences to perform a global description of the cloud coverage variable but it also uses different crisp approaches to extract the relevant information from other variables such as precipitation or temperature
the usage of such distinct techniques responds to the needs of the domain experts who provided both the linguistic specications and most of the domain knowledge required to build the system
thus ldd provides powerful tools to manage uncertainty and imprecision in the generation of linguistic expressions but rst it should be determined when their usage is appropriate
this issue is directly related to a relevant concept also noted in namely the domain modeling
table i main challenges in ldd and proposed solutions through its integration into nlg
challenge solution when to use fuzzy ldd techniques as part of an nlg system how to build fuzzy sets based on empirical knowledge corpus analysis determine which expressions in the language ments can be modeled with protoforms
determine if there is imprecision or uncertainty in the provided domain knowledge
distinct approaches analysis of parallel corpora of texts and corresponding data
alternatively automatically learn such denitions for instance as it is done in tsk rule based systems
perform experiments to obtain empirical denitions from experts or human users
thus the perspective should shift from how to use standalone ldd in real applications to when and how to use ldd as part of real nlg or t systems
in a general sense the analysis of the texts of a specic application domain or the linguistic requirements of the experts if no example texts are available will shed light on this
if certain expressions in the language requirements match directly or indirectly from a content perspective any of the protoforms currently dened and the linguistic terms to be used in such expressions allow for a fuzzy numerical denition the domain experts can not provide specic crisp denitions of such terms or there is not a consensus denition then ldd could be properly applied
this directly leads to another challenge that restricts the usage of ldd in real applications and which has not been previously considered namely the problem of building fuzzy denitions of linguistic terms based on expert knowledge
in general the problem of mapping the intuitive notion of a subjective concept from the application domain into a fuzzy set or relationship has not been a primary concern in the literature in ldd as theory and use cases had to be developed rst in order to show the potential applications of this kind of techniques
even in more recent applied approaches which generate actual texts linguistic variables were dened by authors and the quality of each solution as a whole was checked through an evaluation process by experts e


while to impersonate an expert domain in order to ll knowledge gaps for the application of ldd techniques can be considered admissible and plausible to a certain extent this practice seems to be in conict with the purpose of a modeling process in order to be able to use ldd the author creates fuzzy denitions for linguistic terms based on judgments about the application domain rather than capturing this meaning from the domain itself
in this sense nlg has traditionally used empirical techniques to assess the meaning of words and terms in an as accurate as possible way
for instance for the development of the nlg system sumtime mousan reiter et al
analyzed a parallel set of textual wind forecasts by ve different experts and their corresponding data in order to achieve a coherent denition of temporal expressions such as by evening or by midday
subsequent evaluations of the system showed that overall forecast readers preferred the wind texts generated by the system over human written wind texts
in other cases experiments were run in order to study how human subjects use linguistic expressions in different domains e


in this regard the main challenge resides in bringing such empirical approaches into ldd and adapting them for achieving a proper denition of fuzzy linguistic terms
this depending on the kind of ldd statements which could be used also opens up the possibility of performing experimentation to determine for instance which operators could be used effectively for combining different summarizers or properties e

as in most of the students are short and fast such as the compensatory technique is commonly known in nlg as analysis and is performed systematically in the early conception stages of an nlg system
operators proposed by zimmermman or the owa operators by yager
in a general sense this would imply the instantiation of the theoretical models developed in fuzzy sets based on standard nlg empirical approaches for different application domains
although ldd faces important challenges table i summarizes the main aforementioned issues and hints for addressing them there is an important consensus in this eld about its practical viability based on the use of nlg tools
this trend has been reinforced in recent years as more work in ldd has adopted the use of template based nlg approaches to generate actual texts e


the remaining question now it is clear how ldd should be approached effectively in conjunction with nlg resides in clarifying what benets and implications ldd and fuzzy sets in general may bring to nlg systems
this was also noted by kacprzyk and zadrozny in


it seems that nlg can benet from the approach and solutions that are adopted in our approach by nding the conceptually and numerically operational means to grasp and handle the problem of imprecision of meaning that is so characteristic for natural language but has not been appropriately considered in nlg despite an urgent need
imprecision and uncertainty in nlg have not been fully addressed but it is a subject of interest and research as stated in section i e


however it is not clear why fuzzy sets and derived disciplines such as ldd have not been considered by the nlg community until very recently despite being intuitively appropriate for this task
this unawaraness may be partially explained by the opposition between the traditional theoretical nature of the fuzzy eld more focused on its logical aspects and the more applied nature of nlg focused on linguistic problems of a more empirical weight
nowadays thanks to the effort and work made from both elds we have a better understanding of where ldd ts in an nlg process and what benets this relationship may bring in the task of textually describing large data sets while also taking into account the management of uncertainty and imprecision
in this regard section iii deals with this question in a thorough way from an nlg perspective
a
the nlg pipeline iii
fuzzy sets and ldd across the nlg pipeline nlg systems can be generally depicted as systems tasked with the conversion of some input data into an output text
the most widely accepted classication of this task division is the architecture proposed by reiter and dale in where nlg systems are characterized as a pipeline composed of several parts which deal with different aspects of the nlg process
in this pipeline nlg systems are informally structured as a process divided into three principal modules text or document planning ii microplanning and iii realization
document planning is focused in the production of a specication of the text s content and structure microplanning addresses the problem of choosing appropriate expressions for the content and other ne grained tasks and realization produces the actual text by applying grammatical syntactical and ortographical rules
fig

natural language generation task pipeline according to reiter and dale and potential ldd connections
a more detailed division of such architecture distinguishes six different activities see fig

these subtasks focus alternatively on two different dimensions of the nlg process namely content and structure content determination
as the name indicates this process identies and isolates the relevant information which will be communicated in the text from the source input data in the form of input messages
document structuring
organizes the set of messages according to a certain order and structure including how to group messages together thematically their order or their correspondence to high level document structures such as paragraphs and sections
realizationmicroplanningmicroplanningdocument planningcontent determinationdocument structuringlexicalizationlinguistic realizationstructure realizationaggregationreferring expression generationcontent taskstructure taskldd connection lexicalization
this process involves deciding which specic words and expressions shall be used to express the aggregation
similar to document structuring this task is concerned with deciding how the information is mapped into mation obtained in the content determination task
low level structures such as sentences
referring expression generation
this task deals with the identication of entities in a discourse
this implies selecting the words or expressions that allow to identify such entities
linguistic realization
converts sentence representations into actual text
structure realization
converts the high level structures into mark up symbols understood by the document presentation component for instance if paragraphs or sections are part of an html le which is used to display the output text
of all the subtasks described in by reiter and dale content determination emerges as the more intuitively related to ldd
in this sense the current consensus in ldd is that this kind of techniques allow to perform a fuzzy content determination task
kacprzyk and zadrozny in introduced this notion in terms of the more general concept of text planning while explored in more detail the role of ldd as a means to perform content determination while managing at the same time the problem of imprecision in natural language
this has opened up new ways for further exploration of the relationship between both elds which allow to consider an even wider usage of fuzzy sets and ldd beyond content determination
in this regard we are also considering lexicalization aggregation and referring expression generation as subtasks which can be addressed or inuenced by means of ldd fig

we will illustrate this through a use case inspired by both the weatherreporter design study provided in and the ldd example presented in where a generic model to approach ldd in the context of performing content determination tasks was proposed
b
an illustrative use case let us suppose there is a meteorology agency which provides weather reports based on observational data series obtained from several meteorological sensor stations spread across different locations in a specic region
this agency is interested in automatizing the creation of reports as this task involves a lot of analysis time and effort from the meteorologists due to the high number of reports which must be produced one per location
fig

a fuzzy knowledge base for the use case in section iii including linguistic variables and a partition of fuzzy quantiers
a team composed of nlg experts is then tasked with the development of a system which generates meteorological textual reports
after a few preliminary meetings and studying some examples of parallel human produced texts and corresponding data the experts determine that the specications provided by the meteorologists are incomplete and imprecise in some cases there is not a clear semantic denition of the linguistic terms to be used in the text generation process and meteorologists seem to diverge in their denitions
a few experts in fuzzy sets and their application in ldd join the nlg system development team to help them address and model the imprecision found during the initial stages of the domain modeling process
the team then designs several experiments which are performed by the meteorologists focused on the semantics of the terms related to the meteorological variables of interest namely the temperature humidity and precipitation and other terms such as quantiers
based on the obtained empirical data the team is able to build a fuzzy knowledge base such as the one shown in fig

this allows to start the design and development of the nlg system which will include expressions produced through the use of fuzzy and ldd techniques
fig

example of a report which should be generated by the nlg system and its structure
in a general sense the nlg system will receive as input a data set composed of time series data for several variables from a given meteorological station in a given time period and generate a textual report as output
the reports generated by the system will include both general facts and more specic details about the behavior of the variables of interest see fig

in this context we will study how fuzzy sets and ldd may interact with the nlg tasks
c
across the nlg pipeline content determination this task is tied to the specic application domain as it involves employing different techniques to extract relevant information from the source data
the problem of which techniques to use depends on the nature of the source data and the content requirements of the texts to be produced
for instance in the present use case the nlg system development team could apply signal processing or pattern recognition techniques as the system will have to deal with time series data for several variables see fig

although the content requirements in this use case are more restricted for illustration purposes actual nlg systems do include a wide variety of this kind of approaches
this is especially true in the case of t systems such as babytalk or sumtime turbine
if we focus on the content which must be included in the general information part of the meteorological report three main elements can be identied fig

the rst and second ones provide information about the predominant trend for temperature and rain in a given time period while the third one is just a count of the number of days where precipitation was registered
following the concept of message described in fig
shows a possible content determination message for the rainy days count
let us suppose then that the rst two elements which describe the temperature and rain trends in the human produced reports are a vague description based on a subjective quantication performed by the meteorologists
the fuzzy experts determine that based on the fuzzy denitions shown in fig
these elements can be modeled using type i fuzzy quantied statements such general informationextended informationtemperature periodshumidity infotemperaturerainnumber of rainy daysthe period was warm and dry in general with only days of precipitation
there was a coldish interval from the to the of january and precipitations from the to the
relative humidity was low across the whole period
fig

meteorological observation data for this use case
as most of the days the temperature was cold or a few days were wet
this increases both the exibility and complexity of the content determination task for temperature and rain which is developed by the fuzzy experts using the following strategy all posible combinations of fuzzy quantiers and labels are computed for each content element e

from few very cold to nearly all very hot
this involves determining the fulllment degree fd of each quantied statement and additional criteria such as the coverage degree cov of the quantiers
the best candidate statements are selected based on the chosen criteria
in our use case the fuzzy experts decide to choose the minimum number of candidate statements with a high fulllment degree while covering as much data as possible at the same time
more than one statement can be selected depending on the computed criteria
for instance a nearly all cold statement with a
fulllment degree would sufce to describe the temperature since nearly all is the quantier with highest coverage and the fulllment degree is high
however both some almost dry with a
fulllment degree and some wet with a
fulllment degree would be selected as content messages since the sum of both fulllment degrees is the highest and the added coverage of both quantiers is compatible with of the data
fig

example of a content determination message for the rainy days count element
the chosen fuzzy quantied statements are then included as part of the content determination messages such as the rainy days count message fig

this process is illustrated by fig
which also shows an example of a content determination message produced as a result of the fuzzy quantication algorithm
in general terms such kind of messages should include at least the fulllment degree associated to the obtained piece of content as well as any other element which characterizes this content e

linguistic quantier and label in the case of type i quantied sentences as these will play an important role in subsequent nlg tasks see section iii
type count there are also further additional ne grain issues which must be considered
in this use case for instance to choose a fuzzy quantication model is another decision the fuzzy experts had to make in order to calculate the fulllment degree of the fuzzy quantied sentences
particularly in the previous calculations zadeh s proposal was used f xs are a q n n where q is the function associated to the fuzzy quantier q e

nearly all a is a function associated to the fuzzy label a e

cold and x is the input time series data
fig

calculated using zadeh s approach from the data shown in fig
according to the labels dened in fig

illustration of a content determination process based on type i fuzzy quantied statements for the temperature element
fulllment degrees were however it is not clear which models might be the most appropriate for usage in real applications
although we are aware of their theoretical properties which can be useful in this regard this remains an open problem which should be solved in each specic case
this issue also applies to t norm or t conorm operators which can be used to aggregate different properties e

as in most of the days were cold and wet
minimum and maximum are perhaps the most commonly used but there is a wide variety of operators which make such decisions harder to make this will be further discussed in section iii
in general terms using ldd or fuzzy approaches in content determination will imply creating a higher number of content messages which account for the imprecision dened in the fuzzy knowledge base a discourse element such as the temperature or the rain will not be necessarily characterized by just one piece of information but by several which contain fuzzy related information e

fulllment degree quantier coverage
and which must be carried on to the following subtasks of the pipeline in order to be properly exploited
particularly lexicalization will be highly inuenced by the decisions made in this initial task
lexicalization if content determination focuses on obtaining relevant information from the input data the purpose of the lexicalization task is to move such content closer to an actual text
it is in this stage where the imprecision modeled with fuzzy techniques in content determination can actually show its highest usage potential
resuming our use case the content determination task has now been succesfully developed by the fuzzy and nlg experts
as a result the current system is able to extract content messages which contain both the general and extended information for the target reports fig

furthermore the nlg experts have implemented the document structuring stage and the system is also able to organize the content messages into different high level structures such as paragraphs according to the general structure described in the report sample fig

the current challenge for the nlg system developers is to decide how to lexicalize the content messages i
e
which words and expressions should be used to communicate the information contained in the content determination messages
for some content parts this should be rather direct such as the rainy days count message fig
but the introduction of the fuzzy content messages expands the possibilities and choices which can be made in this regard
for instance retaking the general temperature message from the content determination example in fig
which essentially consists in a type i quantied sentence the system developers may choose several alternatives
the rst and most direct alternative is if we obviate the domain language requirements to express it as nearly all the days of the period were cold
type temperaturetrendmsgperiod quantiedstatement startdate few very coldalmost none very coldfd



coldnearly all coldfd



warmsome warmfd

very hotnearly all very hotfd

quantier nearly alllabel coldfulllmentdegree

possible candidatesselect the most appropriate in this sense a fuzzy quantied statement which follows a standard protoform can easily be matched with a natural language expression whose subject is q of xs and predicate is are a
thus fuzzy quantied statements can also be considered as proto lexicalization messages since they are built using linguistic concepts which can already be directly expressed as natural language sentences
however as it was shown in fig
in section ii in real applications the expressions must be adapted to the domain language requirements and converting a protoform like statement into an actual appropriate natural language expression is not trivial in many cases
thus the nlg system developers of our use case decide to lexicalize the general temperature message as the period was predominantly
moreover the lexicalization task is implemented so that every time a nearly all quantier appears in the temperature message the expression was predominantly is used systematically as long as the fulllment degree of the message is high which is usually determined by establishing a certain threshold
in fact without taking into account the fulllment degree the lexicalization task in our use case would not be too different from standard lexicalization approaches
the semantics of the general content messages for temperature and rain is a combination of the linguistic terms which characterize the fuzzy quantied statements and their associated fulllment degrees and everything must be taken into account when performing lexicalization
another simpler but perhaps more illustrative example of this is the lexicalization process for exceptional temperature periods which deviate from the general trend in the extended information part of the report in fig

let us suppose that the nlg system development team has implemented as part of the content determination task a fuzzy algorithm which extracts relevant temperature periods from the input data
each period is characterized by its start and end dates a temperature label and the average fulllment degree calculated by evaluating the label against the input data
suppose now that for a given input data set the system obtains two messages for a same temperature label as fig
shows
fig

content determination messages for the temperature periods element
although they share the same linguistic label the semantics of the messages are inuenced by their fulllment degree
the most obvious solution in this case would be to lexicalize both messages as warm periods
however this way we would be omitting the semantic contribution of the fulllment degree and nullifying the exibility that fuzzy sets provide
once more to grasp the contribution of a fulllment degree to the semantics of a linguistic term such as warm is a problem the nlg system experts have to solve
for instance warm periods with an average fulllment degree in the range

could be lexicalized as warmish not entirely warm while periods in the range
are lexicalized as warm
content messages with an average fulllment degree lower than
would already be discarded as part of the content determination task algorithm
it is also possible that additional criteria should be taken into account in the case of fig
such as the fulllment degree of contiguous labels for each message
focusing on the warm f d
message one could consider computing the fulllment degrees for contiguous cold and hot fuzzy labels for the same temporal period
this increases the possibilities as a cold f d
or a hot f d
could be used in conjuction with warm f d
to produce expressions such as warm coldish or warm hottish
the previous examples show how individual messages can be lexicalized in the context of using fuzzy approaches and illustrate some of the possibilities these techniques open in this regard
however to simply convert single messages into natural language expressions is not enough in most cases to produce actual texts
for instance if the nlg system experts fed the linguistic realizer with the current lexicalization structures the system would generate something similar to the period was cold in general
the period was wet in general
there were days with rain
there was a warm period from the to the of december
there was a warmish period from the to the of january


which is perfectly correct in that we are using actual natural language expressions to illustrate lexicalization but this task actually involves creating new sets of structures which dene an intermediate syntax between the original content messages and the actual text
type temperatureperiodmsgperiod label warmaveragefulllmentdegree
type temperatureperiodmsgperiod label warmaveragefulllmentdegree
terms of ortography syntax and grammar but is repetitive and still lacks readability
the aggregation task plays an important role in addressing this issue
aggregation in general the aggregation task in nlg systems involves the creation of more complex sentences by merging simple phrase specications
this task is usually depicted from a structural perspective see fig
and is usually addressed by using mechanisms such as simple conjunction conjunction via shared participants conjunction via shared structures
for instance the nlg experts in our use case may add several aggregation rules in order to merge some of the sentences which have been lexicalized e

the general temperature and rain descriptions
thus the period was predominantly cold and the period was predominantly wet could be merged via shared participants they share the same subject the period as the period was predominantly cold and predominantly wet
alternatively the previous messages could also be merged through a shared structure mechanism as the period was predominantly cold and wet
fig

content determination messages for single temperature and rain content elements and possible denition of a message which represents the logical aggregation of both properties by means of a fuzzy t norm
while these mechanisms operate at an strictly syntactical or structural level they resemble similar content aggregation mechanisms which are present in fuzzy sets theory and ldd
these are usually modeled by means of t norm operators such as the minimum or the product
for example if we backtrack the generation of the the period was predominantly cold and wet sentence two alternatives now emerge
the rst one which has already been described is a conjuctive aggregation operation via shared structures
the second one however could have been performed during the content determination task by obtaining a single quantied sentence which aggregates both temperature and rain properties q xs are a and b such as near all the period days were cold and wet
however and in this case would not be a simple conjunction which merges two sentences but rather a t norm operator
this arises some questions
consider the case where the sentence the period was predominantly cold and wet is generated using the two distinct aforementioned approaches see fig

to which extent their meaning would be equivalent and to which extent does using a specic fuzzy aggregation operator inuence the semantics of the obtained stamement and its equivalence with the other sentence again to decide which specic operator to use will be a non trivial decision the experts will have to make if they choose to aggregate properties using fuzzy operators especially when other kind of standard operators have been shown to better resemble the way humans aggregate information
thus using such fuzzy aggregation techniques at a content determination level may imply additional issues but this can also help alleviate the complexity of the subsequent lexicalization and aggregation subtasks
another interesting case of aggregation is also introduced by the use of ldd techniques within the nlg pipeline
let us consider a situation in our use case where the general temperature trend message is composed of two submessages which means that the fulllment degree is spread among more than one quantier as fig
shows
the second message in fig
is composed of two different statements namely some of the period days were cold and many of the period days were cold
although they are not incompatible from a fuzzy logic perspective both fulllment degrees are close to
to lexicalize both independently would probably lead the reader to an important confusion state
likewise if we aggregate them using the aforementioned conjunctive linguistic mechanisms a sentence like some and many of the period days were cold would be generated which does not improve the situation much
in this problem the key lies in providing an expression which reects the semantics of the message in a proper way
intuitively the whole message could be expressed as between some and many of the period days were cold or some or many period days were cold among others which are far from the domain language requirements
thus in order to cut corners the experts in our use case decide to lexicalize it as the period was cold in general
other semantic interpretations are possible since it can also be considered that the quantier some is more inespecic than many and in terms of their fuzzy sets interpretation it should hold that some many
under these considerations consistent lexicalizations can be either to state the more inespecic quantier some some many if the aim is to cover as much data as possible or type temperaturetrendmsgperiod quantiedstatement startdate quantier nearly alllabel coldfulllmentdegree

raintrendmsgperiod quantiedstatement startdate quantier nearly alllabel

generaltrendmsgperiod quantiedstatement startdate quantier nearly wetfulllmentdegree

xs are aq xs are bq xs are a and b fig

content determination messages for the general temperature description
the one on the right depicts a situation where more than one quantied statement is considered
many some many if providing the most specic information is preferred to data covering
one could say that this latter specic problem is more related to lexicalization choosing a natural language expression for a given more complex message than aggregation but even the well dened nlg architecture by reiter and dale admits a high exibility of opinions in similar task placement issues
referring expression generation the task of generating referring expressions emerges as a beast of its own and may well be the less understood and most actively researched subtask within nlg
although it is directly to related to lexicalization it focuses on a more specic problem
in short its purpose is to identify entities thing being event


within a discourse and generate expressions which provide such identication referring expressions
these are usually expressed in the form of noun phrases or surrogates for a noun phrase
fig

report example from fig including highlighted referring expressions
if we follow the previous denition some referring expressions can be identied in the report example from fig
such as the period or a coldish interval from the to the of january fig

the case of the period is perhaps one of the simplest referring expression examples which can be found as the reader of the report will certainly know which time interval the report is referring to there is only one period and thus no features are needed to further identify such entity
however in a coldish interval from the to the of january we nd a more interesting referring expression which identies an specic event by means of a fuzzy property cold expressed as coldish and a temporal expression which in this case is crisply dened but could also be a fuzzy temporal expression in other situations e

towards the beginning of january
fuzzy sets and ldd allow for the inclusion of fuzzy properties which can be used for the task of referring expression generation
in this regard another interesting open research problem in nlg is the generation of geographical referring expressions which help identify within a single discourse relevant events through the use of geographical descriptors
for instance consider the highlighted region in fig
a
could this region be described as nw spain galicia asturias and part of castilla y leon to the north of portugal or simply near galicia such geographical referring expressions have been generated through crisp approaches classically such as the ones produced by the roadsafe system which is able to generate complex expressions from geographical data like in some far southern and southwestern places
however the use of crisp boundaries between the descriptors leads to situations where even if one data point is only slightly below another point one could be computed as north and the other one as south
fuzzy sets and ldd can help address such problems by modeling fuzzy geographical descriptors which can be combined to generate similar geographical referring expressions which consider the graduality of such geographical concepts
to characterize discourse entities using fuzzy properties for the task of generating referring expressions will also have a type temperaturetrendmsgperiod quantiedstatement startdate quantier nearly alllabel coldfulllmentdegree

temperaturetrendmsgperiod quantiedstatement startdate quantier somelabel coldfulllmentdegree

manylabel coldfulllmentdegree

expressionnearly all the period days were coldsome of the period days were coldmany of the period days were coldthe period was predominantly coldthe period was cold in generalthe period was warm and dry in general with only days of precipitation
there was a coldish interval from the to the of january and precipitations from the to the
relative humidity was low across the whole period
fig

example of a geographical region in the problem of generating geographical referring expressions
example of referring expression generation problem in an image
which set of fuzzy properties would allow to generate an expression which distinguishes the circle within the blue square in an as unambiguously as possible manner needless to say supposing the blue square does not exist deep impact in how referring expression algorithms should be approached in a similar manner to how the other tasks within the nlg pipeline are affected by this since increasing exibility by using gradual properties also increases the complexity which must be managed
it must also be noted that this complexity will be given by the kind of domain entities which must be referred to
for instance in t systems which generate texts from time series data language tends to be simpler and relevant information such as events can be clearly identied through the use of temporal expressions
in others such as the aforementioned geographical nlg systems or visual systems in general this complexity will be higher see fig
b
a
additional remarks iv
discussion and conclusions we have studied how fuzzy sets and ldd can play an important role in bringing imprecision and uncertainty management to nlg systems
while they seem to be directly usable for content related tasks we have also explored how a structure related task such as aggregation could also be approached in some cases through fuzzy means
in this regard we would like to retake the idea proposed by kacprzyk and zadrozny in about the creation of new kinds of protoforms which was discussed in sec
ii
although we did not describe in this paper document structuring as an nlg task which could be directly approached by ldd or fuzzy means we believe that this could serve as inspiration to design richer protoforms
while document structuring deals with the organization of content messages into higher level structures such as paragraphs this sorting operation also takes into account other kind of relationships among these messages namely discourse relations such as contrast elaboration or narrative sequences
it is not difcult to imagine extended protoforms which model somehow these discourse relations
consider for instance the following protoforms q xs are a but r y s are b q xs are a especially r y s are b which model a contrast and an emphasizing relation between two basic protoforms
to obtain protoform like statements such as most of the days in were warm but most of the days in november were very cold or most places in southern france suffered from strong precipitations especially most of the sw coast suffered from intense oods
such kind of protoforms would also have an impact in how the text should be structured as a relation holds between their more basic elements
although this kind of contrast and emphasizing relationships between different content elements were considered in from a fuzzy perspective further research could be made to adapt this kind of discourse relations into new types of protoforms
this would also mean that the semantics of such relations could be approached in a fuzzy way e

a fuzzy measure of contrast among different labels of a same linguistic variable based for instance on a standard measure of antonimy
b
evaluation of nlg systems using fuzzy approaches the evaluation of nlg systems which include uncertainty management through fuzzy sets will be another interesting research scope as the exibility such techniques provide implies that additional decisions will have to be taken e

as in the examples shown in sections iii iii and iii
to assess all these design decisions during the conception and development of an nlg system will probably be unfeasible which opens the possibility of including such assessment during the subsequent standard evaluation process of the system
in this regard we would like to differentiate the concept of evaluation used in a ldd perspective from the one used in an nlg context
evaluation of ldd approaches has traditionally consisted in the usage of different criteria such as the fulllmente degree or coverage used in the use case in sec
iii c which allow to rank and select the most appropriate candidate statements generated by an ldd algorithm
thus such evaluation would be performed as part of the content determination process
to evaluate an nlg system is a task which is usually done once the system is fully functional and is able to generate actual texts
in this regard two different types of evaluations may be performed intrinsic evaluations which focus on the quality and appropriateness of the texts generated by the system and ii extrinsic evaluations which try to measure the extent to which the system is actually useful and impactful for its users
in our opinion many of the decisions taken as part of the nlg system development process due to the use of fuzzy approaches could be assessed inherently through intrisinc evaluations which usually consist in obtaining feedback from the domain experts in the form of questionnaires or text free comments
in some cases it could also be interesting to create different versions of a same nlg system and assess their differences for instance to study the problem of aggregation at a content determination level using fuzzy operators and the aggregation at a structural level
c
terminology another issue which is indirectly related to the research questions explored here but may very well become a problem in the future is the terminology used in the literature to refer to each discipline involved in the tasks here described
we have tried to keep here a clear distinction between ldd nlg and t and although the two latter terms are well established in terms of usage ldd has been named differently or used with distinct meanings in the literature
ldd was originally conceived as linguistic summarization of data and this name is still used in many fuzzy sets research papers
while we believe that it represents well the purpose of the eld which represents this terminology may confuse readers from other disciplines as summarization is a well known discipline in nlg and nlp generating texts which summarize larger documents which is totally unrelated to ldd
other authors are considering ldd as an alternate approach which actually reunites nlg t and what we understand as ldd
this is an interesting proposal which ts well the idea of reuniting both paradigms but a consensus should be achieved to avoid further confusion
perhaps the most surprising fact in this terminology discussion is that none of the names used until now linguistic summarization of data linguistic description of data explicitly emphasizes the fuzzy nature of the techniques and operations that this discipline encompasses
d
conclusions the use of fuzzy sets and linguistic descriptions of data to provide imprecision and uncertainty management capabilities in nlg systems is a promising research line which as we have discussed in this paper has many ramications
although this kind of techniques seem to t primarily in content related tasks the diversity of problems involved in such tasks allows for many possibilities
furthermore even more structure focused nlg tasks such as aggregation or document structuring could also benet from fuzzy sets and ldd
table ii summarizes the most relevant potential applications of these techniques in nlg
likewise the research on nlg systems will also help bring fuzzy sets and ldd closer to real applications where uncertainty plays a key role
in this regard as discussed in section ii one of the main challenges will be to embrace and adapt the empirical approaches usually performed during the conception of nlg systems
the nal purpose of this strong collaboration between these both major elds in the articial intelligence community is to provide better systems which in the context of data science produce more human friendly information in the form of natural language texts while managing the vagueness and imprecision included in the semantics underlying such information
within this context nlg systems either alone or as a complementary support to visualization will allow to improve the understanding of large data sets in many application domains and bring data closer to people
empiric studies show that visual information alone is not always capable of adequately communicating relevant information about data to users
in this regard nlg and t are descriptive approaches that combined with sound analysis techniques are starting to prove to be valuable complementary informative tools in the data science realm
as future work the authors will follow the tips here provided and research the use of fuzzy sets in the research and development of nlg systems
particularly we will focus on i researching the generation of geographical referring expressions by means of fuzzy sets exploring how to better integrate ldd within t in terms of content determination and lexicalization tasks and iii identifying new potential application domains where the use of may prove useful
table ii summary table of potential applications of fuzzy sets and ldd in nlg nlg task application of fuzzy sets and ldd content determination document structuring lexicalization aggregation use of fuzzy quantied statements and fuzzy properties to obtain imprecise information e

most of the period days were dry or temperatures were high during the rst fortnight
modeling discourse relations through complex protoforms for instance contrast or emphasizing relationships e

the month was predominantly warm but there was a cold period towards the end
based on the obtained fuzzy information decide how to express it in natural language fig

how does a fulllment degree inuence the semantics of a given expression could be performed in some cases by using standard aggregation operators at a content determination level e

the month was cold and dry
however research should be made to determine the equivalence of structural aggregation and the use of fuzzy operators
referring expression generation dene fuzzy properties which allow to identify certain entities in the discourse fuzzy referring expression generation algorithms
no apparent applications
no apparent applications
linguistic realization structure realization this work was supported by the spanish ministry for economy and competitiveness grant r and by the european regional development fund erdf feder and the galician ministry of education grants and
alejandro ramos soto a
ramos soto is supported by the spanish ministry for economy and competitiveness fpi fellowship program under grant
acknowledgments references s
g
sripada n
burnett r
turner j
mastin and d
evans a case study nlg meeting weather industry demand for quality and quantity of textual weather forecasts in proceedings june
softlearn demo
citius
usc
last visited february

available
citius
usc
b
vazquez barreiros m
lama m
mucientes and j
c
vidal softlearn a process mining platform for the discovery of learning paths in international conference on advanced learning technologies icalt
ieee press pp

r
r
yager a new approach to the summarization of data information sciences vol
no
pp

a
ramos soto a
bugarn and s
barro on the role of linguistic descriptions of data in the building of natural language generation systems fuzzy n
marn and d
sanchez on generating linguistic descriptions of time series fuzzy sets and systems vol
pp
special issue on e
reiter and r
dale building natural language generation systems
cambridge university press
e
reiter an architecture for data to text systems in proceedings of the european workshop on natural language generation s
busemann sets and systems vol
pp

linguistic description of time series
ed
pp

k
van deemter generating referring expressions that involve gradable properties comput
linguist
vol
no
pp
jun

utility and language generation the case of vagueness journal of philosophical logic vol
no
pp

r
power and s
williams generating numerical approximations comput
linguist
vol
no
pp
mar

f
portet and a
gatt towards a possibility theoretic approach to uncertainty in medical data interpretation for text generation in knowledge representation for health care
data processes and guidelines ser
lecture notes in computer science d
riano a
ten teije s
miksch and m
peleg eds
springer berlin heidelberg vol
pp

a
ramos soto a
bugarn s
barro and j
taboada linguistic descriptions for automatic generation of textual short term weather forecasts on real prediction data fuzzy systems ieee transactions on vol
no
pp
feb
a
gatt and f
portet multilingual generation of uncertain temporal expressions from data a study of a possibilistic formalism and its consistency with human subjective evaluations fuzzy sets and systems vol
pp
special issue on linguistic description of time series

available
sciencedirect
com science article pii j
kacprzyk and s
zadrozny protoforms of linguistic database summaries as a human consistent tool for using natural language in data mining international journal of software science and computational intelligence ijssci vol
no
pp

computing with words is an implementable paradigm fuzzy queries linguistic data summaries and natural language generation fuzzy systems ieee transactions on vol
no
pp
june
l
a
zadeh a prototype centered approach to adding deduction capability to search engines the concept of protoform in intelligent systems
proceedings
first international ieee symposium vol
pp

e
reiter s
sripada j
hunter and i
davy choosing words in computer generated weather forecasts articial intelligence vol
pp

i
rodriguez fdez m
mucientes and a
bugarin reducing the complexity in genetic learning of accurate regression tsk rule based systems in fuzzy systems fuzz ieee ieee international conference on aug pp

r
de oliveira y
sripada and e
reiter proceedings of the european workshop on natural language generation enlg
association for computational linguistics ch
designing an algorithm for generating named spatial references pp

l
eciolaza m
pereira farina and g
trivino automatic linguistic reporting in driving simulation environments applied soft computing vol
h

zimmermann and p
zysno latent connectives in human decision making fuzzy sets and systems vol
no
pp

r
yager on ordered weighted averaging aggregation operators in multicriteria decisionmaking systems man and cybernetics ieee transactions no
pp

on vol
no
pp
jan
n
marn and d
sanchez fuzzy sets and systems natural language generation a step forward in the linguistic description of issue on linguistic description of time series
time
available series fuzzy sets and systems vol
pp
special
sciencedirect
com science article pii k
van deemter e
krahmer and m
theune real versus template based natural language generation a false opposition computational linguistics vol
no
pp
mar

a
ramos soto m
pereira farina a
bugarin and s
barro a model based on computational perceptions for the generation of linguistic descriptions of data in fuzzy systems fuzz ieee ieee international conference on pp

f
portet e
reiter a
gatt j
hunter s
sripada y
freer and c
sykes automatic generation of textual summaries from neonatal intensive care data articial intelligence vol
no
pp
may
j
hunter y
freer a
gatt e
reiter s
sripada and c
sykes automatic generation of natural language nursing shift summaries in neonatal intensive care bt nurse articial intelligence in medicine vol
no
pp

j
yu j
hunter e
reiter and s
sripada an approach to generating summaries of time series data in the gas turbine domain in proceedings of ieee international conference on info tech info net beijing pp

j
yu e
reiter j
hunter and s
sripada sumtime turbine a knowledge based system to communicate gas turbine time series data in developments springer berlin heidelberg in applied articial intelligence ser
lecture notes in computer science p
chung c
hinde and m
ali eds
vol
pp

f
daz hermida a
ramos soto and a
bugarn on the role of fuzzy quantied statements in linguistic summarization in proceedings of international conference on
intelligent systems design and applications isda pp

l
zadeh a computational approach to fuzzy quantiers in natural languages comput
math
appl
vol
pp

m
delgado m
d
ruiz d
sanchez and m
a
vila fuzzy quantication a state of the art fuzzy sets and systems vol
no
pp
theme quantiers and logic
f
diaz hermida m
pereira farina j
c
vidal and a
ramos soto characterizing quantier fuzzication mechanisms a behavioral guide for practical applications

available
org
r
turner s
sripada e
reiter and i
p
davy using spatial reference frames to generate grounded textual summaries of georeferenced data in proceedings of the fifth international natural language generation conference ser
inlg
stroudsburg pa usa association for computational linguistics pp

selecting the content of textual descriptions of geographically located events in spatio temporal weather data applications and innovations in intelligent systems vol
xv pp

r
turner s
sripada and e
reiter generating approximate geographic descriptions in empirical methods in natural language generation ser
lecture notes in computer science e
krahmer and m
theune eds
springer berlin heidelberg vol
pp

i
glockner and a
knoll application of fuzzy quantiers in image processing a case study in proceedings of the third international conference on knowledge based intelligent information engineering systems pp

r
castillo ortega j
chamorro martnez n
marn d
sanchez and j
m
soto hidalgo describing images via linguistic features and hierarchical segmentation in fuzzy systems fuzz ieee international conference on pp

a
wilbik and u
kaymak information processing and management of uncertainty in knowledge based systems international conference ipmu montpellier france july proceedings part ii
cham springer international publishing ch
gradual linguistic summaries pp


available


a
ramos soto a
bugarn s
barro and f
diaz hermida automatic linguistic descriptions of meteorological data a soft computing approach for converting open data to open information in iberian conference on information systems and technologies june pp

a
gatt and a
belz introducing shared tasks to nlg the tuna shared task evaluation challenges in empirical methods in natural language generation ser
lecture notes in computer science e
krahmer and m
theune eds
springer berlin heidelberg vol
pp


