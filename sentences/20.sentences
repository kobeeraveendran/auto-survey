p e s r i
s c v
v i x r a beyond stemming and lemmatization ultra stemming to improve automatic text summarization juan manuel torres laboratoire informatique davignon bp avignon cedex france juan manuel
avignon
fr cole polytechnique montral cp
succursale centre ville montral qubec canada abstract in automatic text summarization preprocessing is an important phase to reduce the space of textual representation
classically stemming and lemmatization have been widely used for normalizing words
however even using normalization on large texts the curse of dimensionality can disturb the performance of summarizers
this paper describes a new method for normalization of words to further reduce the space of representation
we propose to reduce each word to its initial letters as a form of ultra stemming
the results show that ultra stemming not only preserve the content of summaries produced by this representation but often the performances of the systems can be dramatically improved
summaries on trilingual corpora were evaluated automatically with fresa
results conrm an increase in the performance regardless of summarizer system used
keywords automatic text summarization lemmatization stemming ultra stemming introduction in natural language processing nlp pre processing aims to reduce the complexity of the vocabulary of the documents
pre processing eliminates the punctuation lters the function words and normalizes the morphological variants
in particular the lemmatization and ming are two commonly used techniques to normalize morphological variants
the lexeme or word root is the part that does not change and contains its meaning
the morpheme or variable part is added to the lexeme to form new words
morphological analysis is a very important phase of pre processing of nlp systems because it allows to reduce the dimension of the vector space representation in systems of information retrieval
several applications such as automatic summarization document indexing textual classication and question answering systems among utilize this reduction
however the realization of this analysis may require the use of external resources dictionaries parsers rules
which can be expensive and dicult to build depending on language or specic domain
some algorithms are capable to detect statistically morphological families posed as a classication problem avoiding the utilization of external resources or a priori knowledge of a language
automatic text summarization ats is the process to automatically generate a compressed version of a source document
query oriented summaries focus on a user s request and extract the information related to the specied topic given explicitly in the form of a query
generic mono document summarization tries to cover as much as possible the tion content
multi document summarization is a task oriented to creating a summary from a heterogeneous set of documents on a focused topic
over the past years extensive iments on query oriented multi document summarization have been carried out
extractive summarization produces summaries choosing a subset of representative sentences from original documents
sentences are ordered then assembled according to their relevance to generate the nal summary
this article introduces a new method of normalization of words that reduces the textual representation space in order to improve the eciency of automatic text summarizers based on vector space model vsm
we propose ultra stemming which reduces every to its
results show that ultra stemming not only preserves the content of the summaries generated using this new representation but often surprisingly the performance can be dramatically improved
to our knowledge in summary tasks no automatic stemming method has explored this extreme possibility
ultra stemming could be an interesting alternative for ats of documents in languages where electronic linguistic resources are rare
in these languages there are a notable absence of lemmatizers stemmers parsers dictionaries corpora and language resources in general such as nahuatl and other american indian languages
our tests on trilingual corpora evaluated by the fresa algorithm conrm the increase of performance regardless of summarizer used and a big reduction of complexity in space and time required to generate summaries
related work is given in section
section presents our stemming strategies coupled with methods of automatic text summarization
experiments are presented in section followed by a discussion and the conclusions in section
related works there are several morphological analysis methods
examples of these algorithms are the comparison of graphs the use of n grams the search for analogies the surface models based on rules the probabilistic models the segmentation by optimization the unsupervised learning of morphological families by ascending hierarchical cation the lemmatization using levenshtein distances or identifying suxes through entropy
these methods are distinguished by the type of results obtained by the tion of lemmas stems or suxes
is an analyzer for french which requires a text previously labeled by or by
flemm produces among other results the lemma of each word of the input text
treetagger is a multilingual tool that allows to annotate texts with information of parts of speech pos and with information of tization
treetagger uses supervised machine learning and probabilistic methods
it can be adapted to other languages as long as the lexical resources and manually labeled corpora are available
freeling is another example of a popular multilingual
stemming transforms the variants of words into truncated forms
two popular stemming algorithms are the porter stemming algorithm and the paice algorithm
the methods of stemming and lemmatization can be applied when the terms are morphologically similar
otherwise when the similarity is semantic lexical search methods must be used
to reduce mantic variation some systems use long dictionaries
another systems use thesauri to associate words to entirely dierent morphological forms
both methods are complementary since is available in web site
univ
fr pers namer
htm is available in web site
atilf
fr scripts mep

txt is available in web site
ims
uni stuttgart
projekte corplex decisiontreetagger
html types of words are for example nouns verbs innitives and particles
is available in web site
lsi
upc
the stemming veries similarities in the spelling level to infer lexical proximity while the lexical presents an algorithms use terminographic data with links to synonyms
vised genetic algorithm for stemming inectional languages
proposes using morphological merged families into a single term to reduce the linguistic variety of spanish indexed texts

lexematization seeks morphological rearrangement of words belonging to the same ily using automatic acquisition of morphological knowledge directly from the texts
although the constitution on morphological families may be interesting in itself its main interest lies in the benets it produces for use as normalization mechanism instead or in addition to stemming or lemmatization in specic application domains
probably the most common application main is indexing terms in systems of information retrieval ir
in recent years there have been numerous articles analyzing in dierent languages the eciency of stemming lemmatization in ir
in addition signicant progress has been made in ir in european languages other than in particular have evaluated corpora of clef evaluation campaigns eight english
european languages
their results show that morphological normalization techniques increase the eciency of the ir systems and it can be used independently of the language
reduction algorithms using syntactic and morphosyntactic variations have shown a signicant reduction of storage costs and management by storing lexemes rather than terms
works on the impacts of compound words and standardization in ir nding no signicant performance dierences between stemming and lemmatization
however the reality is that the linguistic resources necessary to establish morphological relationships without pre dened rules are not available for all languages and all domains without mention the constant creation of neologisms
the proposed solution for the specic task of automatic summarization is the ultra stemming of letters
research in ats was introduced by h
p
luhn in
in the strategy proposed by luhn the sentences are scored for their component word values as determined by like weights
scored sentences are then ranked and selected from the top until some summary length threshold is reached
finally the summary is generated by assembling the selected sentences in original source order
although fairly simple this extractive methodology is still used in current approaches
later on extended this work by adding simple heuristic features of sentences such as their position in the text or some key phrases indicating the importance of the sentences
as the range of possible features for source characterization widened choosing appropriate features feature weights and feature combinations have became a central issue
a natural way to tackle this problem is to consider sentence extraction as a classication task
to this end several machine learning approaches that uses document summary pairs have been proposed
pre processing and ultra stemming the following subsections present formally the details of the corpora studied and the proposed text pre processing method

summarization corpora description to study the impact of ultra stemming in automatic summary tasks we used corpora in three languages english spanish and french
the corpora are heterogeneous and dierent tasks are representive of automatic summarization generic multi document summary and document guided by a subject
language evaluation forum
clef campaign
corpus in english
piloted by nist in document understanding duc the task of aims to produce a short summary of a cluster of related documents
we studied generic multi document summarization in english using data from
this corpus with k words is compound of clusters documents each
corpus in spanish
generic single document summarization using a corpus from the journal medicina which is composed of medical articles in spanish each one with its corresponding author abstract
this corpus contains k words
corpus in french
we have studied generic single document summarization using the canadian french sociological articles corpus generated from the journal perspectives interdisciplinaires sur travail sant
it contains sociological articles in french each one with its corresponding author abstract
this corpus contains near k words
table presents the basic statistics on tokens types and characters of the three rization corpora studied
corpus medicina clnica pistes language tokens types english spanish french letters table basic statistics for the three summarization corpora
additionally three large and heterogeneous corpora generated from novels newspaper ticles and news on the internet were created to measure statistics of each language
these corpora contains several million tokens in english spanish and french
table presents basic statistics on tokens and characters of the three generic corpora
generic corpus english spanish french tokens letters table basic statistics for the three language generic corpora

ultra stemming the rst step to represent documents in a suitable space is the pre processing
as we use extractive summarization as task documents have to be chunked into cohesive textual segments that will be assembled to produce the summary
pre processing is very important because the selection of segments is based on words or bigrams of words
the choice was made to split documents into full sentences in this way obtaining textual segments that are likely to be grammatically correct
afterwards sentences pass through several basic normalization steps in order to reduce computational complexity
an example of document pre processing is given in table
the process is composed by the following steps
nist
gov nlpir
nist
gov projects duc
html
elsevier
revistas
pistes
uqam

sentence splitting a simple rule based method is used for sentence splitting
ments are chunked at the dot exclamation and question mark signs

sentence ltering words are converted to lowercase and cleared up from sloppy tuation
words with less than occurrences are eliminated hapax legomenon presents once in a document
words that do not carry meaning such as functional or very common words are removed
small stop lists depending of language are used in this step

word normalization remaining words are replaced by their canonical form using lemmatization stemming ultra stemming or none of them raw text

text vectorization documents are vectorized in a matrix of p sentences and n columns that represent the occurrences of a letter ultra stemming or a word tization stemming raw j j


n in the sentence i i


p

summary generation each summary is generated by a summarizer based on vsm
for ultra stemming using n the maximum dimension n may be up to letters
this generates very compact and ecient matrices as discussed in

l a n i g i r o a federal judge monday found president clinton in civil contempt of court for lying in a deposition about the nature of his sexual relationship with former white house intern monica s
lewinsky
clinton in a january deposition in the paula jones sexual harassment case swore that he did not have a sexual relationship with lewinsky
clinton later explained that he did not believe he had lied in the case because the type of sex he had with lewinsky did not fall under the denition of sexual relations used in the case
e t t i l s a federal judge monday found president clinton in civil contempt of court for lying in a deposition about the nature of his sexual relationship with former white house intern monica s
lewinsky
clinton in a january deposition in the paula jones sexual harassment case swore that he did not have a sexual relationship with lewinsky
clinton later explained that he did not believe he had lied in the case because the type of sex he had with lewinsky did not fall under the denition of sexual relations used in the case
g feder judg monday found presid clinton civil contempt court lying in deposit natur sexual n i m m e t s relationship former white hous intern monica lewinski clinton januari deposit paula jone sexual harass case swore sexual relationship lewinski clinton explain believ lie case type sex lewinski fall denit sexual relat case m f c c c c l n s f w h i m l c j p j s h c s s r l c l e l c t s f s r u c letter h i l m n p r s u w i f i r t a m table example of some pre processings stemming ultra stemming and matrix generation applied to the document
from duc
document is split in sentences punctuation and case are removed words are normalized
for comparison four methods of normalization were applied after ltering lemmatization by simple dictionary of morphological families
m words entries in spanish k words in english and k in french
porter s stemming available at snowball site
tartarus
org stemmersoverview
html for english spanish french among other languages
raw text without normalization
ultra stemming the n rst letters of each word
for example in the case of stemming of n inected verbs sing song sings singing


or proper names smith snowboard sex


are all replaced by letter s

why ultra stemming could work although this technique could be considered a brutal destruction of the lexicon ultra stemming is in fact an extreme stemming
that is this truncation represents with minimum information what we call the stem of the stem
in the case of ultra stemming with n the construction of the vectors phrases is performed in a space of j


classes which produces a dense vector representation
of course classes are not equally populated
figures to show the ranking of letters of three corpora in english spanish and french
the numbers and function words were previously removed
in an automatic extractive summarizer the weight of phrases is represented in a suitable vector space
however if the representation is too large the resulting representation is very sparse which can dicult the weighting of the sentences
two hypotheses are the basic ideas for using ultra stemming in automatic summarization task
figure scatter plot of rst letter ranking for the english corpus
there are
m of types after ltering of functional words and punctuation
figure scatter plot of rst letter ranking for the spanish corpus
there are
m of types after ltering of functional words and punctuation
figure scatter plot of rst letter ranking for the french corpus
there are
m of types after ltering of functional words and punctuation
the rst hypothesis is that a more condensed but retaining important information of the original representation would enable a more eective weighting for phrases extraction
stemming produces an extremely compact representation of documents in a vector space that

can reach only thirty letters using the representation of one letter per word
one way of evaluating the ecacity of a vector representation can be by calculating the density of the resulting matrix
this point will be discussed in detail in the next section
the other way is to show that two matrices a and b are equivalent in the sense that they contain a number of similar informations
if a b and a and b represent approximately the same information then it may be preferable to use the representation given by a instead of b
now how does one know that two matrices contain about the same information the second hypothesis is that if the matrices a and b are correlated then they probably represent similar information
this point will be proved in section by the mantel statistic test

matrix density pre processing and vectorization of documents will produce very sparse matrices
however the density of matrices generated is directly dependent on pre processing algorithm used
itively the density of matrices generated by ultra stemming must be much greater than those generated by classical normalizations
we have calculated the density of a matrix of p phrases and a vocabulary of n words as a fraction of occurrences cw of the word w elements other than divided by the size of the matrix p n
the equation calculates the density of s
this density can be an indicator of the amount of information in relation to the volume of the matrix lower density implies a greater amount of computation for ranking sentences
as shown in table the matrix produced by ultra stemming of letters produces a higher average density on the studied corpora
the matrices generated by ultra stemming are lled approximately for english for spanish and for french
the volume of the matrix generated by each pre processing method in relation to the size of the matrix in plain text is given by cw v this volume represents a small fraction between and depending on the language of the matrix equivalent of plain text
in case of the corpus medicine clnica the standard matrices lemm stem are slightly larger than the matrix produced by the plain text raw
this can be explained by the presence of hapax legomenon
in the case of plain text a large number of hapax is eliminated and it can produce matrices slightly smaller
pre processing lemmatization stemming raw medicina clnica pre processing lemmatization stemming raw pistes pre processing lemmatization stemming raw density



density



density






















size volume v



size volume v



size volume v










table matrix density for three corpora data
the mean dimension of matrix s
density is calculated by equation and volume by equation
statistics for summarization english medicina clnica spanish and pistes french corpora after removing stop words hapax legomenon and punctuation are shown in table
the mode of letters per word is and and respectively for each language
corpus words letters mean of letters mode on generic per word lemmatization stemming raw medicina clnica lemmatization stemming raw pistes lemmatization stemming raw sentences sentences sentences











english spanish french table statistics for three summarization corpora after ltering and removing punctuation
figures and show the average distribution of letters per word by the three summary corpora after the ltering described in

curves are shown normalized between for the large generic and representative of the language corpora cf section
and the corpora used in each of the summaries experiments
figure scatter plot of mean length of words for two english corpora heterogeneous and summarization raw corpora after ltering
figure scatter plot of mean length of words for two spanish corpora heterogeneous and summarization raw corpora after ltering
figure scatter plot of mean length of words for two french corpora heterogeneous and summarization raw corpora after ltering
matrix test correlation the test of mantel dierent methods of data analysis as ranking are based on distance matrices
indicates in some cases researchers may wish to compare several distance matrices with one another in order to test a hypothesis concerning a possible relationship between these matrices
however this is not always evident
usually values in distance matrices are in some way correlated and therefore the usual assumption of independence between objects is violated in the classical tests approach
furthermore often spurious correlations can be observed when comparing two distances matrices
as shows in the mantel test the null hypothesis is that distances in a matrix a are independent of the distances for the same objects in another matrix b
in other words we are testing the hypothesis that the process that has generated the data is or is not the same in the two sets
then testing of the null hypothesis is done by a randomization procedure in which the original value of the statistic is compared with the distribution found by randomly reallocating the order of the elements in one of the matrices
the measure used for the correlation between a and b is the pearson correlation coecient b p p p ai j a bi j b where p is the number of elements in the lower upper triangular part of the matrix is mean for a elements and a is the standard deviation of a elements
coecient r measures the linear correlation and hence is subject to the same statistical assumptions
consequently if non linear relationships between matrices exist they will be degraded or lost r
the testing procedure for the simple mantel test goes is the same of and it is as follows assume two symmetric dissimilarity matrices a and b of size p p
the rows and columns correspond to the same objects

compute the pearson correlation coecient b between the corresponding elements of the lower triangular part of the a and b using equation

permute randomly rows and the corresponding columns of the matrix a creating a new matrix a

compute b between matrices a and b

repeat steps and a great number of times
this will constitute the reference bution under the null hypothesis
the calculation of the correlation between the matrix generated by the ultra stemming and others normalization methods is not straightforward because the matrices are not square
in general the matrix produced by the ultra stemming have a smaller number of columns than the other ones
then to calculate a correlation between matrices of dierent number of columns each matrix must be converted in a symmetric matrix
let p n of p rows and n columns be a matrix produced by ultra stemming and let of p rows and n columns be a matrix produced by a classic method of normalization such that stemming lemmatization
we have the condition that n n
let the new matrices be p s and p s
they are square symmetrical
a standard mantel test can indicate the degree of similarity between a and b
if the similarity is high r with a high condence value p means that the information of the matrix a is substantially the same as that contained in the matrix b
in other words we could replace for s for purposes of a vector representation of documents
tables and show the correlation of the mantel test for the three summary corpora studied
the correlation was calculated between the matrices s generated by lemmatization lemm stemming stem plain text raw and the matrix generated by ultra stemming using the initial letter
in all cases the correlation is positive with p value
which is signicant
the calculations were performed with the zt program written in c of eric bonnet and yves van de
lemm lemm stem
raw

stem


raw





table mantel test correlation for data english p

a software tool for simple and partial mantel tests
this program can be downloaded from the web site
psb
ugent
be software details zt lemm medicina clnica lemm stem
raw stem
raw
table mantel test correlation for medicina clnica data spanish p

lemm pistes lemm stem
raw
stem

raw




table mantel test correlation for pistes data french p

according to these correlations in english corpus the method is more related with stemming normalization
in spanish and french corpora seems slightly correlated with the model lemmatization
this is intuitively correct and according to the duced variability of english in relation to spanish or french
experiments ultra stemming method described in the previous section has been implemented and evaluated in several corpora in english spanish and french languages
the following subsections present details of the dierent experiments

summarizers three summarization systems were used in our experiments cortex enertex and artex
all systems have used the same text representation based on vector space model described in section

cortex is a single document summarization system using several metrics and an optimal decision algorithm
enertex is summarization system based in textual energy concept text is sented as a spin system where spins represents words that their occurrences are f spins if the word is not present
artex another text summarizer is a single document summarization system that computes the score of a sentence by calculating a dot product between a sentence vector and a frequencies vector multiply by lexical used
we have conducted our experimentation with the following languages summarization tasks summarizers and data sets generic multi document summarization in english with the corpus generic single document summarization in spanish with the medicina clnica and generic single document summarization in french with the pistes
then we have applied the summarization algorithms following the pre processing algorithm and nally results have been evaluated using fresa

summaries evaluation to evaluate the quality of a summary is not an easy task and remains an open question
duc conferences have introduced the rouge evaluation wich measures the overlap of n grams between a candidate summary and reference summaries written by humans
in other hand several metrics without references have been dened and experimented at duc and workshops
fresa measure is similar to rouge evaluation but it does not uses reference summaries
it calculates the divergence of probabilities between the candidate summary and the document source
among these metrics kullback leibler kl and jensen shannon js divergences have been used to evaluate the informativeness of summaries
in this paper we use fresa based in kl divergence with dirichlet smoothing like in the and inex edition to evaluate the informative content of summaries by comparing their n gram distributions with those from source documents
fresa only considered absolute log di between frequencies
let t be the set of terms in the source
for every t t we denote by c t its t occurrences in the summary
the fresa package computed the divergence between the source and the summaries as its occurrences in the source and by c s t log log tt c t c s t to evaluate the quality of generated summaries several automatic measures were computed unigrams of single stems after removing stop words
bigrams of pairs of consecutive stems in the same sentence
bigrams with gaps also made of pairs of consecutive stems but allowing the insertion between them of a maximum of two stems
is the mean of fresa values and represents the nal score in our experiments
the scores of fresa are normalized between and
high values mean less divergence regarding the source document summary reecting a greater amount of information content
all summaries produced by systems were evaluated automatically using fresa package

results

english corpus
nist
gov tac below we present separate results for the three languages
linguistic phenomena specic to each language
in this way we have analyzed results in gure show that ultra steming improves the score of the three automatic rizer systems
this result is remarkable for whose average matrix represents only of the matrix volume in plain text
figure histogram plot of content evaluation for duc task with measures for each summarizer and each normalization
figure scatter plot of mean of ultra stemming using n rst letters duc task cortex summarizer
as shown in figure the performance of the three summarizers is improved using the ultra stemming in relation to other normalizations
so in particular using lemmatization the best score between the two classic normalizations the summarizer artex goes from
to
using normalization i
e
an increase of
cortex increases of
to
an augmentation of
and summarizer enertex increases of
to
an augmentation of

a detailed analysis for a particular summarizer is shown in figure
this gure shows the average score fresa obtained on english corpus in function of ultra stemming used of n


letters for the automatic summarizer cortex
by comparison the values fresa for lemmatization lemm stemming stem and plain text raw are shown in the graph


spanish corpus spanish is a language with greater variability than english
results in gure shown that steming improves the score of the three systems of automatic summarization utilized
in the case of summarizers cortex and artex stemming and lemmatization substantially obtains the same scores which does not occur with enertex
however comparing ultra stemming against stemming the three summarizers are beneting of an increased score artex enertex
and cortex

figure histogram plot of content evaluation for spanish medicina clnica with scores for each summarizer
figure shows the mean score on the spanish corpus medicine clnica based on the ultra stemming n


letters using automatic summarizer cortex
values fresa for lemmatization lemm stemming stem and plain text raw are also shown
figure scatter plot of mean vs
ultra stemming using n rst letters medicina clnica cortex summarizer


french corpus figure histogram plot of content evaluation for french pistes with fresa scores for each summarizer
figure scatter plot of mean vs
ultra stemming using n rst letters pistes cortex summarizer
results in gure show that ultra stemming improves the score of the three automatic rization systems used
in particular the summarizer enertex using a stemming representation obtains a score fresa of
and using representation a score of
i
e
an increase of more than
finally figure shows the detailed mean score on french pistes as function of n


letters using the automatic summarizer cortex
as well it shows the values fresa for lemmatization lemm stemming stem and plain text raw
overall for the three languages beyond a certain number of letters for english for the spanish and for french ultra stemming loses its eectiveness and lemmatization score is higher
a view to the table shows that this limit has a relationship with the mean rather than the mode of letters per word in each language
apparently using ultra stemming is interesting when using a number of characters less than the mode of the language in question
discussion and conclusion in this paper we have introduced and tested a simple pre processing method suitable for tomatic summarization text
ultra stemming is fast and simple
it reduces the size of the matrix representation but it retains the information and charateristics of the document
an important aspect of our approach is that it does not requires linguistic knowledge or resources which makes it a simple and ecient pre processing method to tackle the issue of automatic text summarization
and what about times in general the processing times of ultra stemming are shorter compared to all others methods
of course processing time depends of summarizer algorithm and pre processing algorithm
in general processing time is function of in our experiments is independent of the summarizers and generally ing algorithm is very fast
the depends on algorithm used stemming lemmatizaton extern resource dictionary of lemmatization
the is intrinsic to each summarizer system
by example cortex is a very fast summarizer with where p n and processing times for stemming raw and are close
in other hand enertex summarizer has a complexity of then it needs more time to process the same corpus
in this case ultra stemming is a very interesting alternative to summarize long corpora
table shows processing times for each corpus following the normalization method for cortex artex and enertex summarizers
all times are measured in a
gb of ram computer core m cpu
processor running under bits gnu linux ubuntu version

corpus medicina clnica pistes mean all medicina clnica pistes mean all summarizer cortex lemmatization stemming raw artex lemmatization stemming raw enertex lemmatization stemming raw











time



































medicina clnica pistes mean all table statistics of processing times in minutes of three summarizers over three corpora
clearly the lemmatization of a large dictionary is the most time consuming strategy
this is notable in the spanish corpus using a
m dictionary entries
lemmatization is at the same time the strategy that produces the best results after the ultra stemming fixn with n


letters
in the case of artex summarizer the gain in time is dramatic going from
using lemmatization to
using i
e
a gain of
this gain is for cortex and for enertex
from our point of view the ultra stemming of n letters has three important advantages
a reduction of the space and the calculation time of automatic summarization algorithms based on the vector space model

improving of summary content when using n mode in letters per word of each language

applications on resource sparse languages
typically languages where no lemmatizers stemmers or parsers neither corpora nor native linguist available the ultra stemming can be an attractive alternative for automatic document summarizers
summarization using the ultra stemming representation for sentence scoring improve the identication of most relevant sentences from documents
the results obtained on corpora in english spanish and french prove that ultra stemming can achieve good results for content quality
tests with other corpora duc evaluation campaigns tac inex
in mono and multi document guided by a subject and languages nahuatl maya somali interlingua
using content evaluation with or without reference summaries still in progress
references e
airio
word normalization and decompounding in and bilingual ir
information trieval
j
atserias b
casas e
comelles m
gonzlez l
padr and m
padr
freeling
syntactic and semantic services in an open source nlp library
in fth international conference on language resources and evaluation elra
r
baeza yates and b
ribeiro neto
modern information retrieval
addison wesley
d
bernhard
apprentissage non familles morphologiques par classication ascendante hirarchique
in volume pages
eric bonnet and yves van de peer
zt a software tool for simple and partial mantel tests
journal eric bonnet and yves van de peer
zt a sofware tool for simple and partial mantel tests
journal of statistical software
of statistical software
and brooks monterey ca

l
breiman j
friedman r
olshen and c
stone
classication and regression trees
wadsworth m
t cabr castellv
typology of neologisms a complex task
alfa so paulo m
creutz and k
lagus
unsupervised discovery of morphemes
in workshop of the acl special interest group in computational phonology sigphon pages
m
creutz and k
lagus
unsupervised morpheme segmentation and morphology induction from text corpora using morfessor

technical report publications in computer and information science helsinki university of technology
harold daum iii
practical structured learning techniques for natural language processing
phd thesis los angeles ca
d
p
lyras and k
n
sgarbas and n
d
fakotakis
using the levenshtein edit distance for matic lemmatization a case study for modern greek and english
in ieee international conference on tools with articial intelligence volume pages
h
p
edmundson
new methods in automatic extraction
journal of the association for puting machinery
f
namer
flemm un analyseur flexionnel de franais base rgles
in christian jacquemin editor traitement automatique langues pour recherche dinformation pages
mes
silvia fernndez eric sanjuan and juan manuel torres moreno
textual energy of tive memories performants applications of enertex algorithm in text summarization and topic segmentation
in proceedings of the mexican international conference on articial intelligence pages aguascalientes mexique
springer verlag
c
g
figuerola r
gmez daz and e
lpez de san romn
stemming and n grams in spanish an evaluation of their impact on information retrieval
journal of information science
a
f
gelbukh m
alexandrov and s

han
detecting inection patterns in natural language by minimization of morphological model
in sanfeliu a
trinidad j
f
m
and carrasco ochoa j
a
editors iberoamerican congress on pattern recognition progress in pattern recognition image analysis and applications volume pages
lecture notes in computer science springer verlag berlin
j
a
goldsmith
unsupervised learning of the morphology of a natural language
computational linguistics
n
grabar and p
zweigenbaum
acquisition automatique de connaissances morphologiques sur vocabulaire mdical
in pages
pascal amsili ed

c
hammarstrm
unsupervised learning of morphology survey model algorithm and ments
master s thesis department of computer science and engineering chalmers university
h
hammarstrm
a naive theory of morphology and an algorithm for extraction
in r
towski and g
kondrak editors sigphon acl special interest group on computational phonology pages
s
helmut
probabilistic part of speech tagging using decision trees
in international conference on new methods in language processing september
v
hollink j
kamps c
monz and m
de rijke
monolingual document retrieval for european languages
information retrieval january
c
jacquemin and e
tzoukermann
nlp for term variant extraction synergy between ogy lexicon and syntax
in tomek strzalkowski editor natural language information retrieval volume of text speech and language technology pages
kluwer academic publishers dordrecht boston london
t
korenius j
laurikkala k
jarvelin and m
juhola
stemming and lemmatization in the clustering of nnish text documents
in thirteenth acm conference on information and knowledge management pages
acm press
j
kupiec j
pedersen and f
chen
a trainable document summarizer
in proceedings of the conference acm special interest group on information retrieval pages seattle wa etats unis
acm press new york
y
lepage
solving analogies on words an algorithm
in coling pages
chin yew lin
rouge a package for automatic evaluation of summaries
in marie francine moens and stan szpakowicz editors proceedings of the workshop text summarization branches out pages barcelone espagne july
acl
annie louis and ani nenkova
automatic summary evaluation without human models
in first text analysis conference gaithersburg md etats unis november
h
p
luhn
the automatic creation of literature abstracts
ibm journal of research and development
i
mani and m
mayburi
advances in automatic text summarization
mit press cambridge
press
c
d
manning and h
schtze
foundations of statistical natural language processing
the mit nathan mantel and ranchhodbhai s
valand
a technique of nonparametric multivariate ysis
biometrics sep

juan manuel torres moreno
reagrupamiento en familias y lexematizacin automtica dientes del idioma
revista iberoamericana de inteligencia articial
c
d
paice
another stemmer
sigir forum
c
d
paice
method for evaluation of stemming algorithms based on error counting
journal of the american society for information science
m
f
porter
an algorithm for sux stripping
program
j
ross quinlan

programs for machine learning morgan kaufmann series in machine learning
morgan kaufmann edition
eric sanjuan patrice bellot vronique moriceau and xavier tannier
overview of the inex question answering track
in shlomo geva jaap kamps ralf schenkel and andrew trotman editors comparative evaluation of focused retrieval volume of lecture notes in computer science pages
springer berlin heidelberg
simone teufel and marc moens
sentence extraction as a classication task
in i
mani and m
maybury editors proceedings of the acl workshop on intelligent scalable text summarization madrid espagne juillet
juan manuel torres moreno
rsum automatique documents une approche statistique
herms lavoisier paris
juan manuel torres moreno horacio saggion iria da cunha and eric sanjuan
summary ation with and without references
polibits research journal on computer science and computer engineering with applications
juan manuel torres moreno patricia velzquez morales and jean guy meunier
cortex un in proceedings of the conference de algorithme pour la condensation automatique textes
lassociation pour la recherche cognitive volume pages lyon france
a
medina urrea
automatic discovery of axes by means of a corpus a catalog of spanish axes
journal of quantitative linguistics
j
vilares m
a
alonso and m
vilares
extraction of complex index terms in non english ir a shallow parsing based approach
information processing and management
j
vilares d
cabrero and m
a
alonso
applying productive derivational morphology to term indexing of spanish texts
in alexander gelbukh editor computational linguistics and intelligent text processing volume of lecture notes in computer science pages
springer verlag berlin heidelberg new york

