attend to medical ontologies content selection for clinical abstractive summarization sajad nazli and ross w
lab georgetown university washington dc usa sajad
cs
georgetown
edu georgetown university hospital washington dc usa ross


net a m l c
s c v
v i x r a abstract sequence to sequence network is a well established model for text summarization it can learn to produce readable task
tent however it falls short in effectively tifying key regions of the source
in this per we approach the content selection lem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer
our experiments on two licly available clinical data sets ports of mimic cxr and reports of openi show that our model statistically icantly boosts state of the art results in terms of rouge metrics with improvements


rg l in the care domain where any range of improvement impacts patients welfare
introduction radiology reports convey the detailed observations along with the signicant ndings about a medical encounter
each radiology report contains two portant findings that encompasses diologist s detailed observations and interpretation of imaging study and impression summarizing the most critical ndings
impression usually couple of lines and thrice smaller than nding is considered as the most integral part of report ware et al
as it plays a key role in communicating critical ndings to referring clinicians
previous studies have reported that clinicians mostly read the impression as they have less time to review ings particularly those that are lengthy or intricate flanders and lakhani xie et al

in clinical setting generating impression from findings can be subject to errors gershanik et al
brady
this fact is especially crucial when it comes to healthcare domain where even on institution radiology reports may or may not include other elds such as background
the smallest improvement in generating sion can improve patients well being
ing the process of impression generation in ology reporting would save clinicians read time and decrease fatigue flanders and lakhani kovacs et al
as clinicians would only need to proofread summaries or make minor edits
previously macavaney et al
showed that augmenting the summarizer with entire tology i
e
clinical terms within the findings can improve the content selection and summary generation to some noticeable extent
our ndings further suggest that radiologists select signicant ontology terms but not all such terms to write the impression
following this paradigm we pothesize that selecting the most signicant clinical terms occurring in the findings and then rating them into the summarization would improve the nal impression generation
we further amine if rening findings word representations according to the identied clinical terms would result in improved impression generation
overall the contributions of this work are twofold we propose a novel based model to incorporate the salient clinical terms into the summarizer

we pose copying likelihood of a word as an indicator of its saliency in terms of forming impression which can be learned via a sequence tagger
our model statistically signicantly improves over the competitive lines on mimic cxr publicly available clinical dataset
to evaluate the cross organizational ferability we further evaluate our model on another publicly available clinical dataset openi
related work few prior studies have pointed out that although models can effectively produce readable content they perform poorly at selecting salient content to include in the summary gehrmann et al
lebanoff et al

many attempts have been made to tackle this problem zhou et al
lin et al
hsu et al
lebanoff et al
you et al

for example zhou et al
used sentence representations to lter ondary information of word representation
our work is different in that we utilize ontology resentations produced by an additional encoder to lter word representations
gehrmann et al
utilized a data efcient content selector by aligning source and target to restrict the model s attention to likely to copy phrases
in contrast we use the content selector to nd domain knowledge ment between source and target
moreover we do not focus on model attention here but on rectifying word representations
extracting clinical ndings from clinical reports has been explored previously hassanpour and glotz nandhakumar et al

for marizing radiology reports zhang et al
recently used a separate rnn to encode a section of radiology report
subsequently macavaney et al
extracted clinical ontologies within the findings to help the model learn these useful signals by guiding decoder in generation process
our work differs in that we hypothesize that all of the ontological terms in the findings are not equally important but there is a notion of odds of saliency for each of these terms thus we focus on rening the findings representations
model our model consists of two main components a content selector to identify the most salient logical concepts specic to a given report and a summarization model that incorporates the tied ontology terms within the findings into the summarizer
the summarizer renes the findings word representation based on salient ontology word representation encoded by a separate encoder

content selector the content selection problem can be framed as a word level extraction task in which the aim is to identify the words within the findings that are likely to be copied into the impression
we tackle this problem through a sequence labeling approach
we align findings and impression to obtain required data for sequence labeling task
eld
to this end let


bn be the binary tags over the findings terms


xn with n being the length of the findings
we tag word xi with if it meets two criteria simultaneously it is an ontology term it is directly copied into impression and otherwise
at inference we characterize the copying likelihood of each ings term as a measure of its saliency
recent studies have shown that ized word embeddings can improve the labeling performance devlin et al
peters et al

to utilize this improvement for the content selection we train a bi lstm network on top of the bert embeddings with a softmax vation function
the content selector is trained to maximize log likelihood loss with the maximum likelihood estimation
at inference the content selector calculates the selection probability of each token in the input sequence
formally let o be the set of ontological words which the content selector predicts to be copied into the impression o fu poi where fu is a mapping function that takes in findings tokens and outputs word sequences from input tokens if they appear in the ontology i
e
radlex and otherwise skips them
poi notes the selection probability of ontology word oi and is the copying threshold

summarization model

encoders we exploit two separate encoders ndings coder that takes in the findings and ontology encoder that maps signicant ontological terms identied by the content selector to a x vector known as ontology vector
the ndings encoder is fed with the embeddings of findings words and generates word representations h
then a separate encoder called ontology encoder is used to cess the ontology terms identied by the content selector and produce associated representations ho
bi ho where is the findings text o is the set of ogy terms occurring in the findings and identied by the content selector ho ho l is the


ho ho version

radlex
files

xlsx at training or previously generated tokens at ference and is the previous decoder state
the decoder also computes an attention tion a with being the ontology aware word representations
the tion weights are then used to compute the context vector ct i where n is the length of the findings
finally the context vector and decoder output are used to either generate the next token from the vocabulary or copy it from the findings
i experiments
dataset and ontologies mimic cxr
this collection johnson et al
is a large publicly available dataset of diology reports
following similar report processing as done in zhang et al
we obtained radiology reports
for tion we used scispacy neumann et al

we randomly split the dataset into train dev test splits
openi
a public dataset from the indiana work for patient care demner fushman et al
with reports
due to small size it is not suitable for training we use it to evaluate the cross organizational transferability of our model and baselines
ontologies
we use radlex a comprehensive diology lexicon developed by radiological society of north america rsna including logical terms organized in hierarchical structure

baselines we compare our model against both known and state of the art extractive and abstractive models
lsa steinberger and jezek an tive vector based model that employs sigular value decomposition svd concept
figure overview of our summarization model
as shown bilateral in the findings is a signicant tological term which has been encoded into the ogy vector
after rening findings word tion the decoder computes attention weight highest on bilateral and generates it in the impression
word representations yielded from the ontology coder
note that ho l called ontology vector is the last hidden state containing summarized tion of signicant ontologies in the findings


ontological information filtering although frameworks implicitly model the information ow from encoder to coder the model should benet from explicitly modeling the selection process
to this end we implement a ltering gate on top of the ndings coder to rene the findings word representations according to the signicant ontology terms within the findings and produce ontology aware word representations
specically the ltering gate ceives two vectors the word hidden representation hi that has the contextual information of word xi and the ontology vector ho l including the overal formation of signicant ontology words within the findings
the ltering gate processes these two vectors through a liner layer with sigmoid tion function
we then compute the ontology aware word hidden representation i given the source word hidden representation hi and the associated ltering gate fi
fi ho i hi fi neusum zhou et al
a state of the art extractive model that integrates the process of source sentence scoring and selection
where wh is the weight matrix denotes the bias term and denotes element wise multiplication
impression decoder

we use an lstm network as our decoder to erate the impression iteratively
in this sense the decoder computes the current decoding state st where is the put to the decoder human written summary tokens pointer generator pg see et al
an abstractive summarizer that extends works by adding a copy mechanism that allows for directly copying tokens from the source
ontology aware pointer generator ont
pg macavaney et al
an extension of use open code at
neusum with default hyper parameters
lstmlstmlstmlstm lstmlstm attentionlstm
newtl bilateral bilateralnew small method lsa neusum pg ont
pg bus ours this work











rg l





table rouge results on mimic cxr
shows the statistical signicance paired t test p

pg model that rst encodes entire ontological concepts within findings then uses the encoded vector to guide decoder in summary decoding process
bottom up summarization bus gehrmann et al
an abstractive model which makes use of a content selector to constrain the model s attention over source terms that have a good chance of being copied into the target

parameters and training we use scibert model beltagy et al
which is pre trained over biomedical text
we ploy layer bi lstm encoder with hidden size of upon bert model
the dropout is set to

we train the network to minimize cross entropy loss function and optimize using adam optimizer kingma and ba with learning rate of
for the summarization model we extended on the open base code by zhang et al
for plementation
we use layer bi lstm layer lstm as ndings encoder ontology encoder and decoder with hidden sizes of and tively
we also exploit glove embeddings pretrained on a large collection of
million diology reports zhang et al

we train the network to optimize negative log likelihood with adam optimizer and a learning rate of

results and discussion
experimental results table
shows the rouge scores of our model and baseline models on mimic cxr with written impressions as the ground truth
our model signicantly outperforms all the baselines re implemented the bus model

com summarize radiology findings method rg l bus ours this work





table rouge results on open i dataset comparing our model with the best performing baseline
shows the statistical signicance paired t test p

setting rg l cont
sel
cont
sel






table rouge results showing the impact of content selector in summarization model
shows the cal signicance paired t test p

on all rouge metrics with

and
improvements for and rg l tively
while neusum outperforms the non neural lsa in extractive setting the extractive models lag behind the abstractive methods considerably gesting that human written impressions are formed by abstractively selecting information from the ings not merely extracting source sentences
when comparing ont
pg with our model it turns out that indeed our hypothesis is valid that a pre step of identifying signicant ontological terms can prove the summary generation substantially
as pointed out earlier we dene the saliency of an ontological term by its copying probability
as expected bus approach achieves the best results among the baseline models by constraining decoder s attention over odds on copied terms but still underperforms our model
this may suggest that the intermediate stage of rening word resentations based on the ontological word would lead to a better performance than supercially stricting attention over the salient terms
table
shows the effect of content selector on the marization model
for the setting without content selector we encode all ontologies within the ings
as shown our model statistically cantly improves the results on and
to further evaluate the transferability of our model across organizations we perform an uation on openi with our best trained model on mimic cxr
as shown in table
our model signicantly outperforms the top performing stractive baseline model suggesting the promising cross organizational transferability of our model
figure histograms and arrow plots showing differences between impression of manually scored radiology reports
although challenges remain to reach human parity for all metrics a b and c of our system generated impressions are as good as human written impressions across different metrics
c
expert evaluation while our approach achieves the best rouge scores we recognize the limitation of this ric for summarization task cohan and goharian
to gain a better understanding of ties of our model we conducted an expert human evaluation
to this end we randomly sampled system generated impressions with their associated gold from evenly spaced bins sorted by our system s of mimic cxr dataset
the pressions were shufed to prevent potential bias
we then asked three experts to score the given pressions independently on a scale of worst to best for three metrics readability
understandable or nonsense accuracy
fully accurate or ing critical errors completeness
having all major information or missing key points
figure
presents the human evaluation sults using histograms and arrow plots as done in macavaney et al
comparing our tem s impressions versus human written sions
the histograms indicate the distribution of scores and arrows show how the scores changed between ours and human written
the tail of each arrow shows the score of human written sion and its head indicates the score of our system s impression
the numbers next to the tails express the count of impressions that gained score of by ours and s by gold
we observed that while there is still a gap between the generated and human written impressions over of our system generated impressions are as good as the associated human written radiologists and one medical student
tied or improved
sions
specically readability and accuracy of our system generated impressions ties with human written impressions both ing full score of nonetheless this percentage is for completeness metric
the most likely planation of this gap is that deciding which ndings are more important i
e
should be written into pression is either subjective or highly correlates with the institutional training purposes
hence we recognize cross organizational evaluations in terms of impression completeness as a challenging task
we also evaluated the inter rater agreement using fleiss kappa fleiss for our system s scores and obtained for readability for accuracy and for completeness all of which are characterized as moderate agreement rate
conclusion we proposed an approach to content selection for abstractive text summarization in clinical notes
we introduced our novel approach to augment standard summarization model with signicant ontological terms within the source
content selection problem is framed as a word level sequence tagging task
the intrinsic evaluations on two publicly available real life clinical datasets show the efcacy of our model in terms of rouge metrics
furthermore the extrinsic evaluation by domain experts further reveals the qualities of our system generated maries in comparison with gold summaries
acknowledgement we thank arman cohan for his valuable comments on this work
we also thank additional domain expert evaluators phillip hyuntae kim and ish talati
references iz beltagy kyle lo and arman cohan

scibert a pretrained language model for scientic text
in emnlp
adrian p
brady

error and discrepancy in in insights into diology inevitable or avoidable imaging
arman cohan and nazli goharian

ing summarization evaluation for scientic articles
proc
of conference on lrec pages
dina demner fushman marc d
kohli marc b
rosenman sonya e
shooshan laritza rodriguez sameer k
antani george r
thoma and clement j
mcdonald

preparing a collection of ology examinations for distribution and retrieval
journal of the american medical informatics ciation jamia
jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language ing
in naacl hlt
adam e
flanders and paras lakhani

ogy reporting and communications a look forward
neuroimaging clinics of north america
joseph l
fleiss

measuring nominal scale ment among many raters
sebastian gehrmann yuntian deng and alexander m
rush

bottom up abstractive summarization
in emnlp
esteban f gershanik ronilda lacson and ramin rasani

critical nding capture in the sion section of radiology reports
in amia
saeed hassanpour and curtis p
langlotz

mation extraction from multi institutional radiology reports
articial intelligence in medicine
wan ting hsu chieh kai lin ming ying lee kerui min jing tang and min sun

a unied model for extractive and abstractive summarization using inconsistency loss
in acl
alistair e
w
johnson tom j
pollard seth j
berkowitz nathaniel r
greenbaum matthew p
lungren chih ying deng roger g
mark and steven horng

mimic cxr a large licly available database of labeled chest radiographs
arxiv

diederik p
kingma and jimmy ba

adam a method for stochastic optimization
in iclr
logan lebanoff kaiqiang song franck dernoncourt doo soon kim seokhwan kim walter chang and fei liu

scoring sentence singletons and pairs for abstractive summarization
in acl
logan lebanoff kaiqiang song and fei liu

adapting the neural encoder decoder framework from single to multi document summarization
in emnlp
junyang lin xu sun shuming ma and qi su

global encoding for abstractive summarization
in acl
sean macavaney sajad sotudeh arman cohan nazli goharian ish talati and ross w
filice

ontology aware clinical abstractive summarization
sigir
nidhin nandhakumar ehsan sherkat evangelos e
milios hong gu and michael butler

ically signicant information extraction from ogy reports
in doceng
mark neumann daniel king iz beltagy and waleed ammar

scispacy fast and robust els for biomedical natural language processing
in
matthew e
peters mark neumann mohit iyyer matt gardner christopher clark kenton lee and luke zettlemoyer

deep contextualized word sentations
in proc
of naacl
abigail see peter j
liu and christopher d
manning

get to the point summarization with generator networks
in acl
josef steinberger and karel jezek

using latent semantic analysis in text summarization and mary evaluation
in isim
jeffrey b ware saurabh w
jha jenny k hoang stephen r baker and jill wruble

effective radiology reporting
journal of the american lege of radiology jacr
zhe xie yuanyuan yang mingqing wang ming hui li haozhe huang dezhong zheng rong shu and tonghui ling

introducing information tion to radiology information systems to improve the efciency on reading reports
methods of tion in medicine
yongjian you weijia jia tianyi liu and wenmian yang

improving abstractive document in marization with salient information modeling
acl
mark d
kovacs maximilian y cho philip f
burchett and michael a
trambert

benets of grated ris pacs reporting due to automatic tion of templated reports
current problems in agnostic radiology
yuhao zhang daisy yi ding tianpei qian pher d
manning and curtis p
langlotz

learning to summarize radiology ndings
in emnlp workshop on health text mining and mation analysis
qingyu zhou nan yang furu wei shaohan huang ming zhou and tiejun zhao

neural ment summarization by jointly learning to score and select sentences
in acl
qingyu zhou nan yang furu wei and ming zhou

selective encoding for abstractive sentence summarization
in acl

