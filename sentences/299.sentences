text recognition in the wild a survey c e d v c
s c v
v i x r a xiaoxue chen lianwen jin yuanzhi zhu canjie luo and tianwei wang the college of electronic and information engineering south china university of technology china the history of text can be traced back over thousands of years
rich and precise semantic information carried by text is important in a wide range of vision based application scenarios
therefore text recognition in natural scenes has been an active research field in computer vision and pattern recognition
in recent years with the rise and development of deep learning numerous methods have shown promising in terms of innovation practicality and efficiency
this paper aims to summarize the fundamental problems and the state of the art associated with scene text recognition introduce new insights and ideas provide a comprehensive review of publicly available resources point out directions for future work
in summary this literature review attempts to present the entire picture of the field of scene text recognition
it provides a comprehensive reference for people entering this field and could be helpful to inspire future research
related resources are available at our github repository
com hciilab scene text recognition
ccs concepts computer systems organization embedded systems redundancy robotics works network reliability
additional key words and phrases scene text recognition end to end systems deep learning acm reference format xiaoxue chen lianwen jin yuanzhi zhu canjie luo and tianwei wang

text recognition in the wild a survey
j
acm december pages


nnnnnnn
nnnnnnn introduction text is a system of symbols used to record communicate or inherit culture
as one of the most influential inventions of humanity text has played an important role in human life
specifically rich and precise semantic information carried by text is important in a wide range of vision based application scenarios such as image search intelligent inspection industrial automation robot navigation and instant translation
therefore text recognition in natural scenes has drawn the attention of researchers and practitioners as indicated by the emergence of recent icdar robust reading competitions
recognizing text in natural scenes also known as scene text recognition str is usually ered as a special form of optical character recognition ocr i
e
camera based ocr
although ocr in scanned documents is well developed str remains challenging because of many factors such as complex backgrounds various fonts and imperfect imaging conditions
figure compares the following characteristics of str and ocr in scanned documents
both authors contributed equally to this research
authors address xiaoxue chen
com lianwen jin lianwen

com yuanzhi zhu
foxmail
com canjie luo canjie

com tianwei wang
com the college of electronic and information engineering south china university of technology guangzhou china
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page
copyrights for components of this work owned by others than acm must be honored
abstracting with credit is permitted
to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission a fee
request permissions from
org
association for computing machinery
art


nnnnnnn
nnnnnnn j
acm vol
no
article
publication date december
chen and jin al
fig

comparison of str and ocr in scanned documents
background unlike ocr in scanned documents text in natural scenes can appear on anything e

signboards walls or product packagings
therefore scene text images may contain very complex backgrounds
moreover the texture of the background can be visually similar to text which causes additional challenges for recognition
form text in scanned documents is usually printed in a single color with regular font consistent size and uniform arrangement
in natural scenes text appears in multiple colors with irregular fonts different sizes and diverse orientations
the diversity of text makes str more difficult and challenging than ocr in scanned documents
noise text in natural scenes is usually distorted by noise interference such as nonuniform illumination low resolution and motion blurring
imperfect imaging conditions cause failures in str
access scanned text is usually frontal and occupies the main part of the image
however scene text is captured randomly which results in irregular deformations such as perspective distortion
various shapes of text increase the difficulty of recognizing characters and predicting text strings
recognizing text in natural scenes has attracted great interest from academia and industry in recent years because of its importance and challenges
early research mainly relied on hand crafted features
low capabilities of these features limited the recognition performance
with the development of deep learning ral networks significantly boosted the performance of str
several primary factors are driving deep learning based str algorithms
the first factor is the advances in hardware systems
performance computing systems can train large scale recognition networks
moreover modern mobile devices are capable of running complex algorithms in real time
the second is automatic feature learning in deep learning based str algorithms which not only frees researchers from the exhausting work of designing and selecting hand crafted features but also significantly proves recognition performance
the third is the growing demand for str applications j
acm vol
no
article
publication date december
ocr inscanned documentsscene text recognition imagetext instance background
color regular font consistent size and uniform arrangement
and frontal
the main part of the images
background
colors irregular fonts different sizes and diverse orientations
by nonuniform illumination low resolution and motion blurring
randomly in its native environment
text recognition in the wild a survey fig

typical classifications of text in images

text in natural scenes can provide rich and precise information which is cial for understanding the scene
automatic recognition of text in natural scenes is economically viable in the era of big data which attracts researchers and practitioners
this paper attempts to comprehensively review the field of str and establish a baseline for a fair comparison of algorithms
we present the entire picture of str by summarizing fundamental problems and the state of the art introducing new insights and ideas and looking ahead into future trends
hence this paper aims to serve as a reference for researchers and can be helpful in future work
moreover we provide a comprehensive review of publicly available resources including the standard benchmark datasets and related code
there are several str reviews in the literature
however most of the above mentioned surveys are outdated
many recent advances such as the algorithms developed in are not included in these surveys
we refer the readers to these papers for a more comprehensive historical literature review
moreover zhu et al
and long et al
reviewed methods for both scene text detection and nition
yin et al
surveyed algorithms for text detection tracking and recognition in video
unlike these surveys our paper mainly focuses on str and aims to provide a more detailed and comprehensive overview of this field
the remainder of this paper is organized as follows
section presents the background mental problems and special issues associated with text
section introduces new insights and ideas developed for str in recent years
section summarizes the standard benchmark datasets and evaluation protocols and compares the performance of recognition algorithms
finally section concludes the paper and identifies potential directions for future work in str
background to comprehensively understand the field of str we will describe the fundamental problems and special issues associated with text
moreover some representative applications of str will be listed and analyzed in this section

text in images text can appear differently in the images
figure shows examples and typical classifications
for example if classified by the text form handwritten text and printed text are two basic classes
notably classification methods may overlap
handwritten text recognition is more challenging than printed text recognition because of various handwriting styles and character touching problem
depending on the scripts languages text in images may comprise different characters j
acm vol
no
article
publication date december
text in imagesby formbyscript languageby generationprinted texthandwritten textlatin textchinese textscene textgraphic text chen and jin al
such as latin chinese or hindi
text characteristics such as text categories and the reading order vary greatly in different languages
following the definition in text in images can also be divided into graphic text and scene text
the former refers to text that is digitally added as an overlay on videos or images
the latter refers to text on objects captured in its native environment
scene text has diverse styles and can appear on any surface which makes it difficult to distinguish text from complex backgrounds
typically most approaches summarized in this paper deals with printed latin scene text

fundamental problems and special issues with text fig

illustration of an end to end system which defines various fundamental problems at various stages text detection text localization text verification text segmentation and text recognition
some stages are not considered in an end to end system
rich and precise information carried by text is important in many vision based application scenarios
however extracting text from natural scenes and using it in another application is a complex process
as illustrated in figure various fundamental problems were defined at various stages of this task in the literature text localization text verification text detection text segmentation text recognition and end to end systems
moreover special text related issues exist because of the unique challenges of text
text enhancement text tracking and natural language processing nlp are also briefly introduced
a clear understanding of these common concepts can help researchers to analyze the differences and connections between different tasks


fundamental problems
text localization the objective of text localization is to localize text components precisely and to group them into candidate text regions with as little background as possible
early text localization methods are based on low level features such as color gradient stroke width transform maximally stable extremal regions mser canny detector and connected component analysis
most of current methods are based on deep neural networks
text verification text verification aims at verifying the text candidate regions as text or non text
it is usually used after text localization to filter the candidate regions because text localization sometimes introduces false positives
approaches to text verification include prior knowledge support vector machine svm classifier and conditional random fields crfs
recent works used a convolution neural network cnn to improve text non text discrimination
j
acm vol
no
article
publication date december
text localizationtext verificationtext detectiontext recognitiontext segmentationnatural language processingfull imagemulti text strings text recognition in the wild a survey text detection the function of text detection is to determine whether text is present using localization and verification procedures
as a basis of an end to end system it provides precise and compact text instance images for text recognition
text detection approaches can be roughly categorized as regression based methods and instance segmentation based methods
text segmentation text segmentation has been identified as one of the most challenging problems
it includes text line segmentation and character segmentation
the former refers to splitting a region of multiple text lines into multiple regions of single text lines
the latter refers to separating a text instance into multiple regions of single characters
character segmentation was typically used in early text recognition approaches
text recognition text recognition translates a cropped text instance image into a target string sequence
it is an important component of an end to end system which vides credible recognition results
traditional text recognition methods rely on hand crafted features such as histogram of oriented gradients descriptors connected components and stroke width transform
most recent studies have used deep learning decoder frameworks
end to end system given a scene text image an end to end system can directly convert all text regions into the target string sequences
it usually includes text detection text recognition and postprocessing
the construction of a real time and efficient end to end systems has become a new trend in recent years
some researchers interpret text detection and text recognition as two independent subproblems which are combined to construct an end to end system
another approach is to jointly optimize text detection and text recognition by sharing information


special issues
script identification script identification aims to predict the script of a given text image
it plays a increasingly important role in multilingual systems
detecting the script and language helps text recognition to select the correct language model
script identification can be interpreted as an image classification problem where discriminative representations are usually designed such as mid level features convolutional features and stroke parts representations
text enhancement text enhancement can recover degraded text improve text tion remove the distortions of text or remove the background which reduces the difficulty of text recognition
many algorithms have been investigated for text ment and achieved promising results such as the deconvolution learning based methods and sparse reconstruction
text tracking the purpose of text tracking is to maintain the integrity of text location and track text across adjacent frames in the video
unlike static text in an image tracking algorithms for moving text must identify precise text region at pixel level or sub pixel level because false tracking may blend text with its background or noise text
spatial temporal analysis is usually used for text tracking in the video
a recent study also predicts movement to track characters
natural language processing natural language processing nlp explores how to use computers to understand and manipulate natural language text or speech
nlp is a bridge for human computer communication
text as the most important type of unstructured data is the main object of nlp
there is a wide range of text based applications of nlp including j
acm vol
no
article
publication date december
chen and jin al
machine translation automatic summarization question answering and relationship extraction

applications text as the most important carrier of communication and perception of the world enriches our lives
numerous applications of scene text recognition across various industries and in our daily life intelligent transportation
constructing automatic geocoding systems is not only convenient to travel but also enables users to overcome language barriers e g
automatically recognizing the road signs and translating text into another language
ii information extraction
although text in the pictures contains precise information it is almost impossible to type in massive data by human alone in the era of big data
for example the number of china s express delivery business has exceeded billion in
automatically recognizing text in natural scenes can save huge resources as well as protect customer privacy
iii visual input and access
according to the world health at least
billion people live in the world with a vision impairment or blindness
in addition to advanced medical methods scene text recognition technology can also improve their life e

developing text to speech devices to help understand books atm instructions and pharmaceutical labels
apart from the applications we have mentioned above there have been some specific str application scenarios such as text visual question answering text vqa e discovery multimedia retrieval automatic identity authentication which are also quietly changing our life quality
methodologies in early research hand crafted features were used for text recognition such as histogram of ented gradients descriptors connected components and stroke width transform
however the performances of these methods are limited by low capacity features
with the rise and development of deep learning the community has witnessed substantial advancements in vation practicality and efficiency of various methods
comparing with traditional methods deep learning methods have the following advantages automation automatic feature representation learning can free researchers from empirically designing the hand crafted features
ii effectiveness excellent recognition performance far exceeds traditional algorithms
generalization algorithms can be easily applied to similar vision based problems
in this section we introduce new insights and ideas proposed for str and end to end systems in the era of deep learning
the primary contribution of each approach is reviewed
in the case of multiple contributions we analyze them separately

cropped scene text image recognition the objective of str is to translate a cropped text instance image into a target string sequence
there are two types of scene text in nature i
e
regular and irregular
two main str categories exist segmentation based methods and segmentation free methods
for segmentation free methods they can be roughly classified into ctc based methods and attention based methods
besides other promising ideas are also introduced in this section such as label embedding
table gives a comprehensive list and categorization of these recognition methods
segmentation based methods
one category of str approaches is based on segmentation

which usually includes three steps image preprocessing character segmentation and character recognition
segmentation based methods attempt to locate the position of each
who
int health topics blindness and vision loss j
acm vol
no
article
publication date december
text recognition in the wild a survey fig

overview of segmentation free str approach
image preprocessing and sequence modeling stages are not necessarily required
moreover elements of image preprocessing can be combined to further improve recognition performance
character from the input text instance image apply a character classifier to recognize each character and group characters into text lines to obtain the final recognition results
an early successful str system based on deep learning was developed by wang et al
which used a pictorial model that took the scores and locations of characters as input to determine an optimal configuration of a particular word from a small lexicon
the proposed recognition algorithm outperformed a leading commercial ocr engine abbyy which is a baseline for str
later inspired by the success of the deep convolutional neural network in visual understanding wang et al
mishra et al
and liu et al
combined a multilayer neural network with unsupervised feature learning to train a highly accurate character recognizer module
for postprocessing the character responses with character spacings the beam search algorithm or the weighted finite state transducer based representation were applied to recognize target words in a defined lexicon
to further improve recognition performance researchers explored robust word image representations such as scale invariant feature transform sift descriptors strokelets and mid level features
all of the aforementioned methods rely on lexicons to obtain the final recognition results
however the query time linearly depends on the size of the lexicon
with an open lexicon these strategies are impractical because of the large search space
to address this issue lexicon free attempts had been made for str
some researchers overcame the need for restricted word lists by adopting large dictionaries as higher order statistical language models
others solved str in a lexicon free manner by leveraging larger scale data and more complex neural networks e

convolutional maxout network
recently wan et al
built a recognition system based on semantic segmentation which could predict the class and geometry information of characters with two separate branches and further improve recognition performance
although significant progress has been made in segmentation based methods for str there are critical shortcomings all these pipelines require accurate detection of individual characters which has been identified as one of the most challenging problems in the
therefore the quality of character detectors segmentors usually constrains the recognition performance
ii segmentation based recognizers fail to model contextual information beyond individual characters which may result in poor word level results during the training
segmentation free methods
the second category is segmentation free methods


the approach is to recognize the text line as a whole and focus on mapping the
abbyy
com j
acm vol
no
article
publication date december
chen and jin al
table
summary of the existing recognition approaches
sk st expu expr and un indicate the approaches that use k dataset synthtext dataset extra public data extra private data and unknown data respectively
regular indicates the objective is regular datasets where most text instances are frontal and horizontal
irregular indicates the objective is irregular datasets where most of the text instances are low resolution perspective distorted or curved
indicates the methods that use the extra datasets other than and synthtext
method year regular irregular segmentation ctc attention source code wang et al
abbyy wang et al
mishra et al
wang et al
goel et al
wdtw bissacco et al
photoocr phan et al
alsharif et al
hmm maxout almazan et al kcsr yao et al
strokelets r
et al
label embedding jaderberg et al
su and lu gordo mid features jaderberg et al
jaderberg et al
shi bai and yao crnn shi et al
rare lee and osindero liu et al
star net liu et al
mishra et al
su and lu yang et al
yin et al
wang et al
grcnn cheng et al
fan cheng et al
aon liu et al
char net liu et al
squeezedtext zhan et al
bai et al
ep fang et al
liu et al
enesctc liu et al
wang et al
maan sheng et al
nrtr gao et al
shi et al
aster luo et al
moran luo et al
moran chen et al
aeg xie et al
can liao et al
ca fcn li et al
sar zhan el at
esir zhang et al
ssdan yang et al
scrn yang et al
wang et al
gcam jeonghun et al
huang et al
epan gao et al
qi et al
ccl wang et al
reelfa zhu et al
hatn zhan et al
sf gan liao et al
sam liao et al
seg sam wang et al
dan wang et al
wan et al
textscanner hu et al
gtc luo et al
litman et al
yu et al
qiao et al
data un expr expu expr un expr expu expu expu expu expu expu expu expu expr sk expr sk sk sk sk expr expu expu sk expu expu sk sk sk st pixel level sk st sk expr million sk st pixel level sk st sk sk sk sk sk sk st sk st sk st sk st sk sk expr sk st expr sk st sk sk level word level sk st expu sk st sk st sk st sk sk level word level level word level sk pu million sk st sk st char level sk st sk st sk st char level sk st expu sk st sk st expu sk st sk st
com almazan watts
org jaderberg src
robots
ox
ac
research
com bgshih crnn
com meijieru crnn
pytorch
com grcnn for ocr
com fnzhan verisimilar image synthesis accurate detection and recognition of texts in scenes
com fangshancheng conv ensemble str
com liuhu bigeye enctc
crnn
com bgshih aster
com canjie luo
com canjie luo
com sar strong baseline for text recognition
com clovaai deep text recognition benchmark
com mhliao masktextspotter
com mhliao masktextspotter
com wang tianwei decoupled attention network
com xieenze textsr
com seed entire text instance image into a target string sequence directly by a encoder decoder framework thus avoiding character segmentation
figure shows a typical segmentation free method which contains the four stages of image preprocessing feature representation sequence modeling and prediction
image preprocessing stage j
acm vol
no
article
publication date december
text recognition in the wild a survey image preprocessing aims to improve the image quality by mitigating the interferences from imperfect imaging conditions which may improve feature representation and recognition
background removal
text may appear in various scenes with complex backgrounds
texture features of backgrounds can be visually similar to the text which causes additional difficulties in recognition
instead of complicated feature representations and synthesis approaches an intuitive but rarely noticed solution is to separate the text content from complex backgrounds
although traditional binarization methods work well on document images they fail to handle substantial variations in text appearance and noise in natural images
recently luo et al
used generative adversarial networks gans to remove the background while retaining the text contents which reduced recognition difficulties and dramatically boosted performance
text image super resolution textsr
scene text is usually distorted by various noise interferences such as low resolution
low resolution can lead to misrecognized characters or words
text image super resolution textsr can output a plausible high resolution image that is consistent with a given low resolution image
this approach can help with text recognition in low resolution images
classical approaches such as bilinear bicubic or designed filtering aim to reconstruct the detailed texture of natural images but are not applicable to blurred text
instead of simply treating super resolution as a regression problem wang et al
first combined textsr methods with recognition task which significantly improved the performance of the text recognizer
rectification
the function of rectification is to normalize the input text instance image remove the distortion and reduce the difficulty of irregular text recognition
specifically irregular text refers to text with perspective distortion or arbitrary curving shape which usually causes additional challenges in recognition
the spatial transformer network stn was used as an early rectification module to rectify the entire text image or individual character regions
later shi et al
and jeonghun et al
adopted thin plate spline tps to handle more complex distortions
recently some well designed rectification networks were proposed
for example a multi object rectification network was developed to rectify irregular text by predicting the offsets of each part of an input image
zhan et al
designed a novel line fitting transformation and an iterative tps based rectification framework for optimal scene text rectification
based on local attributes such as center line scale and orientation yang et al
proposed a symmetry constrained rectification network
to handle a variety of distortions complex rectification modules are required and become a new trend
however these affect the speed and memory consumption of recognition algorithms
practitioners should choose the best trade offs depending on their needs under different application scenarios
moreover with the development of irregular text detection it is worth reconsidering whether a rectification module is required for a str system
image preprocessing includes but is not limited to the aforementioned types
it can significantly reduce the difficulties of recognition by improving image quality
various methods can be used in combination
although many recognition algorithms exist these auxiliary preprocessing approaches for text are not often used in the community especially for background removal and textsr
moreover most general off the shelf algorithms focus on the style of a single object whereas scene text images usually contain multiple characters
therefore elaborate and dedicated design preprocessing algorithms for str deserve the attention of researchers in future work
j
acm vol
no
article
publication date december
chen and jin al
feature representation stage feature representation maps the input text instance image to a representation that reflects the attributes relevant for character recognition while suppressing irrelevant features such as font color size and background
motivated by the successes of su et al
used the histogram of oriented gradients hog feature in their str system to construct sequential features of word images
later cnns have been widely used for feature representation stage such as the vggnet
for more powerful feature representation some complex neural networks were applied in str algorithms such as resnet and densenet
recently some attempts have been made to improve the feature representation module from different perspectives
recursive cnns were used by lee et al
for parametrically efficient and effective image feature representation which can increase the depth of traditional cnns under the same parametric capacity and produce much more compact feature response
inspired by the recurrent convolution neural network rcnn in image classification wang et al
designed a gated recurrent convolution layer for feature sequence representation by introducing a gate to control the context modulation in rcnn
liu et al
focused on real time str and proposed a novel binary convolutional layer
they claimed that the binary representation remarkably speeds up run time inference and reduces memory usage
some researchers argued that directly processing the source image by cnns would introduce extra noise
therefore they combined cnns with the attention mechanism to enhance the representation of foreground text and suppress background noise
a deeper and more advanced feature extractor usually results in a better representation power which is suitable for improving str with complex backgrounds
however the performance provement comes at the cost of memory and computation consumption
a combination of the background removal technique with simple feature extractors may be an alternative in future research
sequence modeling stage sequence modeling as a bridge between visual features and predictions can capture the tual information within a sequence of characters for the next stage to predict each character which is more stable and helpful than treating each symbol independently
multiple bidirectional long short term memory bilstm model was introduced in and widely used in as the sequence modeling module because of its ability to capture long range dependencies
litman et al
added intermediate supervisions along the network layers and successfully trained a deeper bilstm model to improve the encoding of contextual dependencies
however some researchers considered that bilstm was not an essential part of str algorithms
they argued that although the bilstm was effective to model the context its structure was computationally intensive and time consuming
moreover it could cause gradient vanishing exploding during the training
therefore a sliding window or deep one dimensional cnn was used instead of bilstm
in particular although cnns were widely used for feature extraction of individual characters in early research the context can also be modeled by cnns by precisely controlling the receptive field
recently yu et al
and qiao et al
focused on introducing global semantic information to model the context
therefore yu et al
designed a global semantic reasoning module to capture global semantic context through multi way parallel transmission while qiao et al
predicted an additional global semantic information supervised by the word embedding from a pre trained language model
j
acm vol
no
article
publication date december
text recognition in the wild a survey contextual cues are beneficial for image based sequence recognition
although recurrent neural networks rnns based structures such as bilstm or lstm can model character sequences there are some inherent limitations
in contrast cnns or transformer can not only effectively deal with long sequences but also be parallelized efficiently
modeling language sequences using cnns or transformer structure may be a new trend for sequence modeling because of its intrinsic superiority
prediction stage the objective of the prediction stage is to estimate the target string sequence from the identified features of the input text instance image
connectionist temporal classification ctc and the attention mechanism are two major techniques
moreover other potential ideas regarding the prediction stage are also introduced in this section
connectionist temporal classification ctc was proposed by graves et al
for training rnns to label unsegmented sequences directly
ctc has achieved significant ments in many fields such as speech recognition and online handwritten text recognition
ctc is typically used in str as a prediction module i
e
the transcription layer that converts the input features made by cnns or rnns into a target string sequence by calculating the conditional probability
in particular ctc can maximize the likelihood of an output sequence by efficiently summing over all possible input output sequence alignments and allow the classifier to be trained without any prior alignment between the input and target sequences
the formulation of the conditional probability can be briefly described as follows
the input features are denoted by


where is the sequence length
each is a probability distribution over l
specifically l represents a set of all labels including all characters and an extra blank symbol that represents an invalid output
a ctc path is a sequence of length which consists of the blank symbol and label indices
as there are many possible ways to map these paths to transcription a ctc mapping function b is defined to remove repeated labels and delete the blank symbol from each path
then the conditional probability is calculated by summing the probabilities of all paths mapped onto by b and b where the probability of is defined as is the probability of having label at time step t
as directly computing the above equation is computationally expensive most researchers adapt the forward backward algorithm to compute it efficiently
inspired by the success of ctc in speech processing su et al
he et al
and shi et al
first applied it to str
since then numerous ctc based prediction algorithms have showed promising transcription performance
however liu et al
argued that ctc tended to produce highly peaky and overconfident distributions which was a symptom of over fitting
to address this issue they proposed a regularization method based on maximum conditional entropy to enhance generalization and exploration capabilities of ctc
feng et al
modified the traditional ctc by fusing focal loss to solve the recognition of extremely unbalanced samples
recently hu et al
improved the accuracy and robustness of ctc by using graph convolutional networks gcns in str
ctc enjoys remarkable transcription performance and stability
however it faces some inherent limitations the underlying methodology of ctc is sophisticated which results in a large computational cost for long text sequences
ii ctc suffers from the peaky distribution problems and its performance usually degrades for repeated patterns
ctc can hardly be applied to two dimensional prediction problems such as irregular scene text recognition where characters in the input text instance image are distributed in a spatial structure
to handle j
acm vol
no
article
publication date december
chen and jin al
this issue wan et al
extended the vanilla ctc by adding another dimension along the height direction
although the recognition performance is improved to some extent the proposed ctc model has not completely solved prediction problems
therefore applying ctc to solve the prediction problem could be a potential direction for future research
attention mechanism the attention mechanism was proposed by bahdanau et al
in the field of neural machine translation which can automatically search for the predicted word that are vant to parts of a given source sentence
many approaches based on the attention mechanism have achieved significant improvements in various fields such as image caption text recognition and scene classification of remote sensing images
for str the attention mechanism is often combined with the rnn structure as a prediction module
in particular the attention mechanism learns the alignment between the input instance image and the output text sequences by referring to the history of the target characters and the encoded feature vectors
let the output prediction sequence be denoted as


where indicates the maximum decoding step size
at the step the output prediction is given by where is the hidden state of rnn at time step
typically a gated recurrent unit gru is used to update and model the longterm dependencies
hence is computed as where is the embedding vector of the previous output
moreover represents the glimpse vector computing as the weighted sum of features


where is the feature length
here is the vector of attention weights which is computed as follows where is the alignment score which represents the degree of correlation between the high level feature representation and the current output
in the above equations and are all trainable parameters
inspired by the development of neural machine translation systems a large number of based methods have emerged in str field
moreover some attempts have been made to improve the vanilla attention from different perspectives applying to prediction problems
for the irregular scene text recognition the various character placements significantly increase the difficulty of recognition
the vanilla attention was applied to perform feature selection and decoding
there is the significant conflict between text distribution and feature representation by applying the vanilla attention directly
therefore yang et al
li et al
and huang et al
proposed attention mechanism for irregular text recognition
ii improving the construction of implicit language model
chen et al
and wang et al
argued that the generated glimpse vector was not powerful enough to represent the predicted characters
therefore chen et al
introduced high order character language models to the vanilla attention while wang et al
constructed a memory augmented attention model by feeding a part of the character sequence already generated and the all attended alignment history
shi et al
noted that a vanilla attention based prediction module captured output dependencies in only one direction and j
acm vol
no
article
publication date december
text recognition in the wild a survey missed the other
thus they proposed a bidirectional attention based decoder with two decoders in opposite directions
improving parallelization and reducing complexity
although the vanilla attention mechanism based on the rnn structure can capture long range dependencies it is computationally intensive and time consuming
a recent attention variant namely transformer was widely employed in to improve parallelization and reduce complexity for str
addressing attention drift
the attention drift phenomenon means that attention models can not accurately associate each feature vector with the corresponding target region in the input image
some researchers added extra information to solve this problem by focusing the deviated attention back onto the target areas such as localization supervision and encoded coordinates
others increased the alignment precision of attention in a cascade way
specifically wang et al
argued that a serious alignment problem is caused by its recurrence alignment mechanism
therefore they decoupled the alignment operation from using historical decoding results
in recent years the attention based prediction approaches have become the mainstream method in the field of str and have outperformed ctc in decoding because of its ability to focus on informative areas
moreover the attentional methods can be easily extended to complex diction problems
however the attention mechanism has some shortcomings as this method relies on the attention module for label alignment it requires more storage and computations
for long text sequences the attention mechanism is difficult to train from scratch owing to the misalignment between the input instance image and the output text sequences i
e
the attention drift phenomenon
the current research of attention mechanism mainly focuses on languages which involve only a few character categories e

english french
to the best of our best knowledge there is no public report on effectively applying the attention mechanism to deal with the large scale category text recognition tasks such as chinese text recognition
discussion both ctc and the attention mechanism have their strengths and limitations
recently some researchers applied both ctc and the attention mechanism to achieve accurate prediction and maintain a fast inference speed
cong et al
comprehensively compared these two prediction approaches on large scale real world scene text sentence recognition tasks
based on extensive experiments they provided practical advice for researchers and practitioners
for example the attention based approaches can achieve higher recognition accuracy on isolated word recognition tasks but perform worse on sentence recognition tasks compared with based approaches
therefore the right prediction methods should be chosen according to different application scenarios and constraints
moreover it is valuable to explore alternative prediction strategies in future work
for example the aggregation cross entropy function was designed to replace ctc and the attention mechanism it achieves competitive performance with a much quicker implementation reduced storage requirements and convenient employment


other potential approaches
other approaches have been considered and explored with a different view
motivated by the whole is greater than the sum of parts goel et al
recognized text in natural scenes by matching the scene and synthetic image features with weighted dynamic time warping wdtw approach
later almazn et al
and rodriguez et al
interpreted the task of recognition and retrieval as a nearest neighbor problem
they embedded both word images and text strings in a common vectorial subspace or euclidean space combining label embedding with attributes learning
specifically images and strings that represent the same word would be close together
recently jaderberg et al
formulated str as a multi class classification problem
they trained a deep cnn classifier solely on synthetic data approximately million images from a words dictionary
as each word corresponds to an output neuron the proposed text classifier j
acm vol
no
article
publication date december
chen and jin al
can not recognize out of dictionary words
further they combined cnns with a crf graphical model for unconstrained text recognition
table
summary of the existing end to end system approaches
method detection recognition source code wang et al
wang et al
jaderberg et al
alsharif et al
yao et al
neumann et al
jaderberg et al
liao et al
textboxes b usta et al
deep textspotter li et al
lyu et al
mask textspotter he et al
liu et al
fots liao et al
liao et al
mask textspotter xing et al
charnet feng et al
textdragon qin et al
wang et al
boundary qiao et al
text perceptron liu et al
abcnet year sliding windows and random ferns cnn based cnn based and saliency maps cnn and hybrid hmm maxout models random forest extremal regions region proposal mechanism ssd based framework yolo text proposal network fast r cnn with mask branch east framework east framework ssd based framework mask rcnn east framework textsnake mask rcnn rpn based framework resnet and feature pyramid network bezier curve detection pictorial structures sliding windows for classification cnn classifier segmentation based component linking and word partition clustering algorithm to group characters word level classification crnn ctc attention character segmentation attention ctc crnn character segmentation spatial attention module cnn classifier sliding convolution character models with ctc attention attention attention ctc
com mhliao textboxes
com lvpengyuan masktextspotter

com textspotter
com jiangxiluning fots
pytorch
com mhliao
com mhliao masktextspotter
com malongtech research charnet
com yuliang liu
end to end systems given a text image with a complex background as input an end to end system aims to directly convert all text regions into string sequences
typically it includes text detection text recognition and postprocessing
in the past text detection and recognition have been interpreted as two independent subproblems that are combined to retrieve text from images
recently the construction of real time and efficient end to end systems has become a new trend in the community
table compares the characteristics of these end to end methods
several factors promote the emergence of end to end systems errors can accumulate in a cascade way of text detection and recognition which may lead to a large fraction of garbage predictions while an end to end system can prevent errors from being accumulated during the training
ii in an end to end system text detection and recognition can share information and can be jointly optimized to improve overall performance
an end to end system is easier to maintain and adapt to new domains whereas maintaining a cascaded pipeline with data and model dependencies requires substantial engineering efforts
an end to end system exhibits competitive performance with faster inference and smaller storage requirements
many recent studies have shown the effectiveness of a joint optimized end to end model which usually includes a detection branch and a recognition branch
bartz et al
integrated and jointly learned a stn to detect text regions of an image
corresponding image regions were directly cropped and fed into a simple neural network to recognize text content
advanced detection and recognition algorithms were then used to build joint end to end systems
both branches were bridged by cropping region of interests rois features of the detection branch and feeding them to the recognition branch
typically roipool was proposed by girshick to convert rois of different scales and aspect ratios into fixed size feature maps for object detection
however this approach may lead to significant distortion because of the large variation of text length
to address this issue li et al
proposed varying size roipool to accommodate the original aspect ratios
as quantizations performed by roipool would introduce misalignments between the rois and the extracted features many methods used bilinear interpolation to extract text instance features such as bilinear sampling roirotate and the text alignment layer
recent j
acm vol
no
article
publication date december
text recognition in the wild a survey end to end systems have focused on curved text of arbitrary shapes
for example liao et al
and their extended work used roialign to preserve more accurate location information retrieved each character as a generic object and composed the final text with character level annotations
feng et al
generated dense detection quadrangles and used the proposed roislide to transform features cropped from each quadrangle into rectified features
all text features were then fed into a ctc based recognizer making the framework free from character level annotations
instead of formulating the text detection branch as a bounding box extraction or instance segmentation task wang et al
localized a set of points on the boundary and adopted tps transformation to flatten features of each text
qiao et al
proposed the shape transform module which iteratively generated potential fiducial points and used tps to transform the detected text regions into regular morphologies without extra parameters
liu et al
introduced parameterized bezier curve to adaptively fit arbitrarily shaped text and designed a novel bezieralign layer to precisely calculate convolutional features of text instances in curved shapes
the purpose of the aforementioned bilinear interpolation methods is to rectify the features of irregular shapes into axis aligned features for text recognizer where the difference is the way of generating the sampling grid
however qin et al
argued that the feature rectification was a key bottleneck in generalizing to irregular shaped text
they introduced roi masking to filter out the neighboring text and the background which made rectification unnecessary for the recognizer
xing et al
directly performed character detection and recognition on the full features without any roi operations
although the current end to end systems work fairly well in many real world scenarios they contain limitations
the following difficulties should be considered how to efficiently bridge and share information between text detection and recognition ii how to balance the significant differences in learning difficulty and convergence speed between text detection and recognition iii how to improve joint optimization moreover a simple compact and powerful end to end system is yet to be developed
evaluations and protocols diverse datasets and unified evaluation protocols bring new challenges and fair comparison to the community respectively but both are necessary to advance the field of str
in this section we examine the standard benchmark datasets and evaluation protocols
table and table compare the performance of the current advanced algorithms in str and end to end systems

datasets several primary reasons justify the need for additional datasets most deep learning approaches are data driven
large scale datasets are important and crucial to train a good text recognizer
advanced str algorithms have been overused on previous datasets indicating that more challenging aspects could be investigated
new datasets usually represent potential directions for future work such as lexicon free text recognition irregular text recognition unsupervised or weakly supervised text recognition and large scale category text recognition
depending on the type of dataset collection we divide the standard benchmark datasets into two categories synthetic datasets and realistic datasets
in particular realistic datasets include regular latin datasets irregular latin datasets and multilingual datasets
table describes the panorama of these datasets and figures show representative samples
synthetic datasets
most deep learning algorithms rely on sufficient data
however the

existing realistic datasets are relatively small for training a highly accurate scene text recognizer because they only contain thousands of data samples
moreover manually collecting and annotating j
acm vol
no
article
publication date december
chen and jin al
large amount of real world data will involve huge efforts and resources
therefore synthetic and artificial data generation has been a popular research topic
table
comparison of the benchmark datasets
and full are the lexicon sizes
datasets language lexicon char level label type source code synthtext verisimilar synthesis unrealtext k svt svhn svt p coco text total text ctw scut lsvt art mlt english english english english english english english english english digits english english english english english chinese english chinese english chinese english chinese english chinese english chinese english multilingual images instances total train test total train test and and full and full mtwi chinese english regular regular regular regular regular regular regular regular regular regular irregular irregular irregular irregular irregular regular regular regular irregular irregular irregular irregular irregular
robots
ox
ac
vgg data
com ankush me synthtext
com fnzhan verisimilar image synthesis accurate detection and recognition of texts in scenes
github
io
iiit
ac
in research projects projects the word dataset
ucsd
kai
iapr
org mediawiki index
php title
cvc
uab
downloads
cvc
uab
downloads
stanford
edu
baidu
com vnis chan
com
html
cvc
uab
downloads
cornell
edu coco
com cs chan total text dataset
vlrlab
net
baidu
com list
github

com yuliang liu curve text detector
cvc
uab
downloads
cvc
uab
downloads
cvc
uab
downloads
cvc
uab
downloads
the dataset contains million synthetic text instance images from a set of common english words
words are rendered onto natural images with random transformations and effects such as random fonts colors blur and noises
dataset can emulate the distribution of scene text images and can be used instead of real world data to train data hungry deep learning algorithms
besides every image is annotated with a ground truth word
synthtext
the synthtext dataset contains images with million synthetic text instances
as in the generation of dataset the text sample is rendered using a randomly selected font and transformed according to the local surface orientation
moreover each image is annotated with a ground truth word
verisimilar synthesis
the verisimilar synthesis dataset contains million synthetic text instance images
given background images and source texts a semantic map and a saliency map are first determined which are then combined to identify semantically sensible and apt locations for text embedding
the color brightness and orientation of the source texts are further determined adaptively according to the color brightness and contextual structures around the embedding locations within the background image
unrealtext
the unrealtext dataset contains k synthetic images with million cropped text instances
it is developed upon unreal engine and the unrealcv plugin
text instances are regarded as planar polygon meshes with text foregrounds loaded as texture
these meshes are placed in suitable positions in world and rendered together with the scene as a whole
the same font set from google and the same text corpus i
e
are used as synthtext does


realistic datasets
most of current realistic datasets contain only thousands of text instance images
therefore for str realistic datasets are typically used to evaluate recognition algorithms under real world conditions
subsequently we will list and briefly describe the existing realistic datasets regular latin datasets irregular latin datasets and multilingual datasets

google
j
acm vol
no
article
publication date december
text recognition in the wild a survey fig

synthetic sample images of text from synthtext verisimilar synthesis and unrealtext datasets
regular latin datasets part of them is distorted
for the regular latin datasets most text instances are frontal and horizontal whereas a small words k
the k dataset contains text instance images for training and for testing
it contains words from street scenes and from digital images
every image is associated with a word lexicon and a word lexicon
specifically the lexicon consists of a ground truth word and some randomly picked words
street view text svt
the svt contains images for training and for testing
some images are severely corrupted by noise blur and low resolution
each image is associated with a word lexicon
icdar
the dataset contains images for training and for testing
specifically it contains cropped text instances after discarding images that contain non alphanumeric characters or less than three characters
every image is associated with a word lexicon and a full word lexicon
moreover the full lexicon combines all lexicon words
fig

realistic sample images of regular latin text from k svt and svhn datasets
j
acm vol
no
article
publication date december
textverisimilar chen and jin al
fig

realistic sample images of irregular latin text from svt p coco text and total text datasets
icdar
the dataset contains images
this is an extension of the dataset used for the text locating competitions of icdar
icdar
the dataset contains images for training and for testing
it inherits data from the dataset and extends it with new images
similar to dataset the dataset contains cropped text instance images after removing the words with non alphanumeric characters
no lexicon is associated with
notably duplicate text instance images exist between the training dataset and the testing dataset
therefore care should be taken regarding the overlapping data when evaluating a model on the testing data
street view house number svhn
the svhn dataset contains more than digits of house numbers in natural scenes
it is obtained from a large number of street view images using a combination of automated algorithms and the amazon mechanical turk amt
the svhn dataset was typically used for scene digit recognition
irregular latin datasets for the irregular benchmark datasets most of the text instances are low resolution perspective distorted or curved
various fonts and distorted patterns of irregular text bring additional challenges in str
streetviewtext perspective svt p
the svt p dataset contains images with cropped text instances
it is specifically designed to evaluate perspective distorted text recognition
it is built based on the original svt dataset by selecting the images at the same address on google street view but with different view angles
therefore most text instances are heavily distorted by the non frontal view angle
moreover each image is associated with a word lexicon and a full word lexicon
cute
the cute dataset contains high resolution images with cropped text instances
it focuses on curved text recognition
most images in cute have a complex background perspective distortion and poor resolution
no lexicon is associated with cute
icdar
the dataset contains images for training and for testing
specifically it contains cropped text instances including more than
mturk
com mturk welcome j
acm vol
no
article
publication date december
svt textcoco text text recognition in the wild a survey irregular text samples
as text images were taken by google glasses without ensuring the image quality most of the text is very small blurred and multi oriented
no lexicon is provided
coco text
the coco text dataset contains images with cropped text instances
it is the first large scale dataset for text in natural images and also the first dataset to annotate scene text with attributes such as legibility and type of text
however no lexicon is associated with coco text
total text
the total text contains images with cropped text instance images
it focuses on curved scene text recognition
images in total text have more than three different orientations including horizontal multi oriented and curved
no lexicon is associated with total text
multilingual datasets multilingual text can be found in modern cities where representatives of multiple cultures live and communicate
bilingual datasets are the simplest form
subsequently some bilingual or multilingual scene text datasets are introduced below
the bilingual datasets introduced in this paper are mainly composed of latin and chinese
the reason for choosing chinese as the second language of bilingual scene text datasets are three fold
first chinese is one of the most widely used languages in the world
second although many str algorithms exist most of them focus on latin characters
the problem of recognition of chinese scene text has not been solved well
third chinese text has unique characteristics compared with latin text chinese is a large scale category text with a much larger character set than in latin text
ii the imbalanced class problem of chinese characters is more obvious owing to the larger character set
many confusing characters with similar structures exist in chinese which makes them hard to distinguish
therefore reading chinese in the wild is an important and challenging problem
reading chinese text in the wild
the dataset contains images for training and for testing
most are natural images collected by cameras or mobile phones whereas others are digital born
text instances are annotated with labels fonts languages
multi type web images mtwi
the mtwi contains images
this is the first dataset constructed by chinese and latin web text
most images in mtwi have a relatively high resolution and cover diverse types of web text including multi oriented text tightly stacked text and complex shaped text
chinese text in the wild ctw
the ctw includes high resolution street view images with character instances
all images have character level annotations the underlying character the bounding box and six other attributes
scut
the scut dataset contains images for ing and for testing
in particular it provides cropped text instance images including with curved text
the images are manually harvested from the internet image libraries such as google open image or phone cameras
the dataset contains a lot of horizontal and multi oriented text
large scale street view text lsvt
the lsvt contains ing samples fully annotated training samples and training samples with weak annotations i
e
with partial labels
all images are captured from streets and reflect a large variety of complicated real world scenarios e

store fronts and landmarks
arbitrary shaped text art
the contains images for training and for testing
art is a combination of total text scut and baidu j
acm vol
no
article
publication date december
chen and jin al
fig

realistic sample images of multilingual scene text from mtwi ctw scut lsvt art and mlt datasets
curved scene which was collected to introduce the arbitrary shaped text problem
moreover all existing text shapes i
e
horizontal multi oriented and curved have multiple occurrences in the art dataset
reading chinese text on signboard
the contains images for training and for testing
all the text lines and characters are annotated with locations and transcriptions
all the images are from the meituan dianping group collected by meituan business merchants using phone cameras under uncontrolled conditions
specifically dataset mainly contains images of chinese text on boards
multi lingual text
the dataset contains images for training per language and for testing
the dataset includes ten languages representing seven different scripts arabic bangla chinese devanagari english french german italian japanese and korean
the number of images per script is equal
subset of lsvt j
acm vol
no
article
publication date december
ctwartmltrects text recognition in the wild a survey
evaluation protocols in this section we summarize the evaluation protocols for latin text and multilingual text


evaluation protocols for latin text
recognition protocols the word recognition accuracy and word error rate are two widely used tion evaluation protocols for latin text
wra
is defined by where is the total number of words and represents the number of correctly recognized words
wer
is defined by
end to end protocols widely used evaluation protocols for latin end to end are defined in where the recognition algorithms are evaluated in two modalities end to end recognition and word spotting
in particular all words in the scene text images should be detected and recognized under end to end recognition
under word spotting only words provided in the vocabulary should be detected and recognized
moreover three different vocabularies are provided for candidate transcriptions strongly contextualised weakly contextualised and generic denoted as s w and g in short respectively
strongly contextualised s
the per image vocabulary consists of words including all words in the corresponding image as well as distractors selected from the rest of the training testing set which follows the setup of
weakly contextualised w
the vocabulary includes all words in the training testing set
generic g
the generic vocabulary contains approximately k words derived from the of jaderberg et al



evaluation protocols for multilingual text
in this section we briefly introduce the evaluation protocols for multilingual text widely used in recent competitions such as rctw mtwi lsvt art rects and mlt competitions
recognition protocols most competitions measured the algorithm recognition performance by a tional evaluation metric the normalized edit distance ned where
stands for the levenshtein distance
and denote the predicted text and the responding ground truth respectively
furthermore and are their text length
is the total number of text lines
the ned protocol measures the mis matching between the predicted text and the corresponding ground truth
therefore the recognition score is usually calculated as ned
end to end protocols two main evaluation protocols for end to end systems have been used during recent tions
cvc
uab
files
pdf at
robots
ox
ac
j
acm vol
no
article
publication date december
chen and jin al
table
performance comparison of recognition algorithms on benchmark datasets
and full are lexicon sizes
none means lexicon free
indicates the methods that use the extra datasets other than and synthtext
the bold represents the best recognition results
denotes the best recognition performance of using extra datasets
k svt svt p coco text k none none full none none full none method wang et al
abbyy wang et al
mishra et al
wang et al
goel et al
wdtw bissacco et al
photoocr phan et al
alsharif et al
hmm maxout almazn et al kcsr yao et al
strokelets r
et al
label embedding jaderberg et al
su and lu gordo mid features jaderberg et al
jaderberg et al
shi bai and yao crnn shi et al
rare lee and osindero liu et al
star net liu et al
mishra et al
su and lu yang et al
yin et al
cheng et al
fan cheng et al
aon liu et al
char net liu et al
squeezedtext zhan et al
bai et al
ep fang et al
liu et al
enesctc liu et al
wang et al
maan sheng et al
nrtr gao et al
shi et al
aster luo et al
moran luo et al
moran chen et al
xie et al
can liao et al
ca fcn li et al
sar zhan el at
esir zhang et al
ssdan yang et al
scrn yang et al
wang et al
gcam jeonghun et al
huang et al
epan gao et al
qi et al
ccl wang et al
reelfa zhu et al
hatn zhan et al
sf gan liao et al
sam liao et al
seg sam wang et al
dan wang et al
wan et al
textscanner hu et al
gtc luo et al
litman et al
yu et al
qiao et al










































































































































































































































































































































































































































































none




























none






























none

the first protocol evaluates the algorithm performance in several aspects including precision recall and f score based on ned
according to the matching relationship between the dicted and ground truth bounding boxes the ned of the predicted text and ground truth text serves as precision and recall score
the f score is the harmonic average of the score of precision and recall
this is a mainstream metric to evaluate detection and recognition performance simultaneously
the protocol is widely used in
the second protocol measures the algorithm performance by the average ned namely aed
in particular the ned between the predicted text and the corresponding ground truth are calculated
then all the neds are summed and divided by the number of test images j
acm vol
no
article
publication date december
text recognition in the wild a survey table
performance comparison of end to end system algorithms on benchmark datasets
and full are lexicon sizes
none means lexicon free
s w and g stand for three different vocabularies i
e
strongly contextualised weakly contextualised and generic
represents testing with multiple scales
the bold represents the best results
method end to end spotting end to end spotting svt total text none full none g s g s g s g full none wang et al
wang et al
jaderberg et al
alsharif et al
yao et al
neumann et al
jaderberg et al
liao et al
textboxes b usta et al
deep textspotter li et al
lyu et al
mask textspotter he et al
liu et al
fots liao et al
liao et al
mask textspotter xing et al
charnet feng et al
textdragon qin et al
wang et al
boundary qiao et al
text perceptron



























s









w





























w






























w
































w





























table
performance comparison for competitions
ned stands for the normalized edit distance
competition detection end to end team name protocol result team name protocol result rctw mtwi lsvt art rects mlt foo bar tencent dppr team sanhl tencent dppr team f score f score f score f score f score f score





tencent dppr team
tencent dppr tencent dppr team ustb prir ned f score f score f score ned f score





and the result is called aed
specifically a lower aed means a better performance
this protocol evaluation was introduced in to improve the fairness for long text detection and recognition which is practical useful for real world systems
these two types of evaluation protocols evaluate the algorithm from different perspectives
as lustrated in table the performances of winning systems of several recent end to end competitions indicate that the problem of end to end recognition remains unsolved

discussion various new challenging datasets inspire new research that promotes the progress in the field
however it is hard to assess whether and how a newly proposed algorithm improves upon the current art because of the varieties of different datasets priors evaluation protocols and testing environments
therefore a holistic and fair comparison is necessary for future work
recent datasets and competitions show that the community is moving toward more challenging text recognition tasks e

from horizontal text to irregular text and from latin text to multilingual text
beyond the challenges high quality annotations are also critical for a good dataset
moreover new datasets and competitions may bridge the gap between academia and industry
discussion and future directions text has played an important role in human lives
automatically reading text in natural scenes has a great practical value
therefore scene text recognition has become an important and vibrant research area in computer vision and pattern recognition
this paper summarizes the fundamental j
acm vol
no
article
publication date december
chen and jin al
problems and the state of the art methods associated with scene text recognition introduces new insights and ideas and provides a comprehensive review of publicly available resources
in the past decades there have been substantial advancements in innovation practicality and efficiency of recognition methods
however there is ample room remaining for future research generalization ability
generalization ability refers to the ability of recognition algorithms to be effective across a range of inputs and applications
although the recognition algorithms trained by the synthetic datasets achieve good performance on several realistic evaluation datasets they fail to adapt to varying inputs such as text instances with longer characters smaller sizes and unseen font styles
moreover most recognition algorithms are sensitive to environmental interferences and hard to deal with real world complexity e

the poor performance reported on the coco text dataset
therefore researchers and practitioners have to train models from scratch based on specific inputs and scenarios
in contrast humans are adept at recognizing different styles of text under complex scenarios with little supervision learning which indicates that there still exists a giant gap between the current understanding level of machines and human level performance
in addition to simply employing rich and diverse data as training samples a feasible solution might be to explore the unique and essential representation of text such as visual level and semantic level
evaluation protocols
numerous approaches proposed in recent years claimed to have pushed the boundary of the technology
however the inconsistency of datasets priors and testing environments makes it difficult to fairly evaluate the reported numbers at face value in table and table
researchers and practitioners have to confirm and compare the experimental settings in newly proposed algorithms
for example which training datasets were used e

synthetic datasets realistic datasets or a mixture of both which annotations were used e

word level character level or pixel level considering this a fair comparison is required in the community
for example future work might report recognition performance on the unified training testing datasets or even report recognition performance on a single model i
e
evaluate the performance of the same model across different datasets
moreover clear and detailed experimental settings introduced in papers are also important in advancing research progress
data issues
most deep learning algorithms highly depend on a sufficient amount of high quality data
the existing realistic datasets only contains thousands of data samples which is relatively small for training a accurate scene text recognizer
moreover manually collecting and annotating large amount of real world data will involve huge efforts and resources
therefore there are two aspects to be considered
on one hand synthesizing as realistic and effective data as possible has a potential in the community
compared with realistic datasets multi level annotation information i
e
word level character level and pixel level can be easily obtained during synthesizing which can be used to train data hungry algorithms
for example some researchers are working to synthesis realistic text instances by a engine
on the other hand approaches of using unlabeled real world data are worth considering in the future
it is valuable to explore how to use the existing data efficiently
for example with the emergence of many realistic datasets we should reconsider whether unified synthetic datasets are the only choice for training models and then evaluated with realistic datasets
such strategy is widely adopted in most of current researches
the balance between realistic datasets and synthetic datasets needs to be further developed
moreover developing efficient data augmentation approaches for text might be a feasible and promising solution which should focus more on the style of multi objects
j
acm vol
no
article
publication date december
text recognition in the wild a survey scenarios
the research aims to improve human quality of life
however for str the gap between the research and applications still exists
in practical applications text usually appears with worse image quality more complex backgrounds and more noise which requires the recognition systems with the ability to deal with real world complexity
meanwhile for simple but private vision based scenarios such as bank cards recognition performance is especially important
thus researchers and practitioners should not be limited to several standard benchmarks
challenges in real world applications may provide new research opportunities and advance research progress in the future such as multilingual text recognition in modern cities ultra high precision recognition in private scenarios and fast text recognition for mobiles
image preprocessing
to improve the recognition performance of algorithms increasingly complex recognizers have become a new trend in the community
however this is not the only perspective worth considering
some potential image preprocessing issues deserve the attention of researchers such as textsr and background removal which can significantly reduce the difficulties of str and improve performance from a new perspective
end to end systems
constructing a real time and efficient end to end system has attracted the interest of researchers and practitioners
however the performance of end to end systems remains far behind compared with that of ocr in scanned documents
some difficulties should be considered such as efficiently bridging and sharing information between text detection and recognition balancing the significant differences in learning difficulty and convergence speed between text detection and recognition and improving joint optimization
in this area there is much work to be done
furthermore it is worth considering whether end to end solutions are necessary for industrial applications
languages
representatives of multiple cultures live and communicate in modern cities
multilingual text recognition is critical to human communication as well as smart city development
in addition to construct large scale synthetic realistic multilingual training datasets a feasible solution might be combined with script identification
moreover although many recognition algorithms exist most of them focus on latin text only
recognition of latin has not been extensively investigated such as chinese scene text which is large scale category text and has unique characteristics compared with latin text
existing recognition algorithms can not be well generalized to different languages
developing language dependent recognition algorithms for specific language might be a feasible solution
security
as str algorithms can be adapted to many private vision based scenarios such as bank cards id cards and driver licenses the security of recognition approaches is very important
despite high performance most deep learning based text recognizers are highly vulnerable to adversarial examples
strengthening the security of str algorithms will be a potential direction in the future
str nlp
nlp is a bridge in human computer communication
meanwhile text is the most important carrier of communication and perception in the world
a combination of nlp and str may be an important trend in various fields such as text vqa document understanding and information extraction
references of iclr workshop
jon almazn albert gordo alicia forns and ernest valveny

word spotting and recognition with embedded attributes
ieee trans
pattern anal
mach
intell
ouais alsharif and joelle pineau

end to end text recognition with hybrid hmm maxout models
in proceedings peter anderson xiaodong he chris buehler damien teney mark johnson stephen gould and lei zhang

bottom up and top down attention for image captioning and visual question answering
in proceedings of cvpr
j
acm vol
no
article
publication date december

chen and jin al
jeonghun baek geewook kim junyeop lee sungrae park dongyoon han sangdoo yun seong joon oh and hwalsuk lee

what is wrong with scene text recognition model comparisons dataset and model analysis
in proceedings of iccv

youngmin baek bado lee dongyoon han sangdoo yun and hwalsuk lee

character region awareness for dzmitry bahdanau kyunghyun cho and yoshua bengio

neural machine translation by jointly learning to text detection
in proceedings of cvpr

align and translate
in proceedings of iclr
dzmitry bahdanau jan chorowski dmitriy serdyuk philemon brakel and yoshua bengio

end to end attention based large vocabulary speech recognition
in proceedings of icassp

fan bai zhanzhan cheng yi niu shiliang pu and shuigeng zhou

edit probability for scene text recognition
in proceedings of cvpr

xiang bai mingkun yang pengyuan lyu yongchao xu and jiebo luo

integrating scene text and visual appearance for fine grained image classification
ieee access
simon baker and takeo kanade

limits on super resolution and how to break them
ieee trans
pattern anal
christian bartz haojin yang and christoph meinel

see towards semi supervised end to end scene text alessandro bissacco mark cummins yuval netzer and hartmut neven

photoocr reading text in uncontrolled mach
intell
recognition
in proceedings of aaai

conditions
in proceedings of iccv

ali furkan biten ruben tito andres mafla lluis gomez maral rusinol ernest valveny cv jawahar and thenis karatzas

scene text visual question answering
in proceedings of iccv

thodore bluche

joint line segmentation and transcription for end to end handwritten paragraph recognition
in proceedings of nips

michal busta lukas neumann and jiri matas

deep textspotter an end to end trainable scene text localization and recognition framework
in proceedings of iccv

gulcin caner and ismail haritaoglu

shape dna effective character restoration and enhancement for arabic text documents
in proceedings of icpr

john canny

a computational approach to edge detection
ieee trans
pattern anal
mach
intell
richard g casey and eric lecolinet

a survey of methods and strategies in character segmentation
ieee trans
pattern anal
mach
intell
rui chen bipin c desai and cong zhou

cindi robot an intelligent web crawler based on multi level inspection
in eleventh international database engineering and applications symposium ideas

xiaoxue chen tianwei wang yuanzhi zhu lianwen jin and canjie luo

adaptive embedding gate for attention based scene text recognition
neurocomputing
xilin chen jie yang jing zhang and alex waibel

automatic detection and recognition of signs from natural scenes
ieee transactions on image processing
changxu cheng qiuhui huang xiang bai bin feng and wenyu liu

patch aggregator for scene text script identification
in proceedings of icdar

yong cheng

semi supervised learning for neural machine translation
in joint training for neural machine translation

zhanzhan cheng fan bai yunlu xu gang zheng shiliang pu and shuigeng zhou

focusing attention towards accurate text recognition in natural images
in proceedings of iccv

zhanzhan cheng yangliu xu fan bai yi niu shiliang pu and shuigeng zhou

aon towards oriented text recognition
in proceedings of cvpr

chee kheng chng chee seng chan and cheng lin liu

total text toward orientation robustness in scene text detection
international journal on document analysis and recognition ijdar
chee kheng chng yuliang liu yipeng sun chun chet ng canjie luo zihan ni chuanming fang shuaitao zhang junyu han errui ding al

robust reading challenge on arbitrary shaped text rrc art
in proceedings of icdar

hojin cho myungchul sung and bongjin jun

canny text detector fast and robust scene text localization algorithm
in proceedings of cvpr

kyunghyun cho bart van merrinboer caglar gulcehre dzmitry bahdanau fethi bougares holger schwenk and yoshua bengio

learning phrase representations using rnn encoder decoder for statistical machine translation
in proceedings of emnlp

j
acm vol
no
article
publication date december
text recognition in the wild a survey gobinda g chowdhury

natural language processing
annual review of information science and technology fuze cong wenping hu huo qiang and li guo

a comparative study of attention based encoder decoder approaches to natural scene text recognition
in proceedings of icdar

andrea corbelli lorenzo baraldi costantino grana and rita cucchiara

historical document digitization through layout analysis and deep content classification
in proceedings of icpr

pengwen dai hua zhang and xiaochun cao

deep multi scale context aware feature aggregation for curved scene text detection
ieee transactions on multimedia
navneet dalal and bill triggs

histograms of oriented gradients for human detection
in proceedings of cvpr


tuan anh nguyen dang and dat nguyen thanh

end to end information extraction by character level embedding and multi stage attentional u net
in proceedings of bmvc

abhishek das samyak datta georgia gkioxari stefan lee devi parikh and dhruv batra

embodied question answering
in proceedings of cvpr workshops

jeffrey dean greg corrado rajat monga kai chen matthieu devin mark mao marcaurelio ranzato andrew senior paul tucker ke yang al

large scale distributed deep networks
in proceedings of nips

guilherme n desouza and avinash c kak

vision for mobile robot navigation a survey
ieee trans
pattern anal
mach
intell
chao dong chen change loy kaiming he and xiaoou tang

image super resolution using deep convolutional networks
ieee trans
pattern anal
mach
intell
shireen y elhabian khaled m el sayed and sumaya h ahmed

moving object detection in spatial domain using background removal techniques state of art
recent patents on computer science
boris epshtein eyal ofek and yonatan wexler

detecting text in natural scenes with stroke width transform
in proceedings of cvpr
ieee
nobuo ezaki kimiyasu kiyota bui truong minh marius bulacu and lambert schomaker

improved detection methods for a camera based text reading system for blind persons
in proceedings of icdar

shancheng fang hongtao xie jianjun chen jianlong tan and yongdong zhang

learning to draw text in natural images with conditional adversarial networks
in proceedings of ijcai

shancheng fang hongtao xie zheng jun zha nannan sun jianlong tan and yongdong zhang

attention and language ensemble for scene text recognition with convolutional sequence modeling
in acm multimedia conference on multimedia conference

wei feng wenhao he fei yin xu yao zhang and cheng lin liu

textdragon an end to end framework for arbitrary shaped text spotting
in proceedings of iccv

xinjie feng hongxun yao and shengping zhang

focal ctc loss for chinese optical character recognition on unbalanced datasets
complexity
yunze gao yingying chen jinqiao wang ming tang and hanqing lu

dense chained attention network for scene text recognition
in proceedings of icip

yunze gao yingying chen jinqiao wang ming tang and hanqing lu

reading scene text with fully tional sequence modeling
neurocomputing
ross girshick

fast r cnn
in proceedings of iccv

vibhor goel anand mishra karteek alahari and cv jawahar

whole is greater than sum of parts recognizing lluis gomez and dimosthenis karatzas

a fine grained approach to scene text script identification
in iapr scene text words
in proceedings of icdar

workshop on document analysis systems das

lluis gomez anguelos nicolaou and dimosthenis karatzas

improving patch based scene text script tion with ensembles of conjoined networks
pattern recognition
ian goodfellow jean pouget abadie mehdi mirza bing xu david warde farley sherjil ozair aaron courville and yoshua bengio

generative adversarial nets
in proceedings of nips

ian j goodfellow david warde farley mehdi mirza aaron courville and yoshua bengio

maxout networks
in albert gordo

supervised mid level features for word image representation
in proceedings of cvpr

alex graves

supervised sequence labelling
in supervised sequence labelling with recurrent neural networks
proceedings of icml


alex graves santiago fernndez faustino gomez and jrgen schmidhuber

connectionist temporal tion labelling unsegmented sequence data with recurrent neural networks
in proceedings of icml

alex graves and navdeep jaitly

towards end to end speech recognition with recurrent neural networks
in proceedings of icml

j
acm vol
no
article
publication date december
chen and jin al
alex graves marcus liwicki santiago fernndez roman bertolami horst bunke and jrgen schmidhuber

a novel connectionist system for unconstrained handwriting recognition
ieee trans
pattern anal
mach
intell
alex graves abdel rahman mohamed and geoffrey hinton

speech recognition with deep recurrent neural networks
in proceedings of icassp

qiang guo fenglei wang jun lei dan tu and guohui li

convolutional feature learning and hybrid cnn hmm for scene number recognition
neurocomputing
ankush gupta andrea vedaldi and andrew zisserman

synthetic data for text localisation in natural images
in proceedings of cvpr

young kug ham min seok kang hong kyu chung rae hong park and gwi tae park

recognition of raised characters for automatic classification of rubber tires
optical engineering
dafang he xiao yang chen liang zihan zhou alexander g ororbi daniel kifer and c lee giles

multi scale fcn with cascaded instance aware segmentation for arbitrary oriented word spotting in the wild
in proceedings of cvpr

kaiming he georgia gkioxari piotr dollr and ross girshick

mask r cnn
in proceedings of iccv

kaiming he xiangyu zhang shaoqing ren and jian sun

deep residual learning for image recognition
in proceedings of cvpr

mengchao he yuliang liu zhibo yang sheng zhang canjie luo feiyu gao qi zheng yongpan wang xin zhang and lianwen jin

contest on robust reading for multi type web images
in proceedings of icpr

pan he weilin huang tong he qile zhu yu qiao and xiaolin li

single shot text detector with regional pan he weilin huang yu qiao chen change loy and xiaoou tang

reading scene text in deep convolutional attention
in proceedings of iccv

sequences
in proceedings of aaai

tong he zhi tian weilin huang chunhua shen yu qiao and changming sun

an end to end textspotter with explicit alignment and attention
in proceedings of cvpr

xinwei he yang yang baoguang shi and xiang bai

vd san visual densely semantic attention network for image caption generation
neurocomputing
sepp hochreiter and jrgen schmidhuber

long short term memory
neural computation
wenyang hu xiaocong cai jun hou shuai yi and zhiping lin

gtc guided training of ctc towards efficient and accurate scene text recognition
in proceedings of aaai
gao huang zhuang liu laurens van der maaten and kilian q weinberger

densely connected convolutional networks
in proceedings of cvpr

hu huang ya zhong shiying yin junlin xiang lijun he yu lv and peng huang

express delivery system based on fingerprint identification
in proceedings of itnec
ieee
yunlong huang zenghui sun lianwen jin and canjie luo

epan effective parts attention network for scene text recognition
neurocomputing
max jaderberg karen simonyan andrea vedaldi and andrew zisserman

synthetic data and artificial neural networks for natural scene text recognition
in proceedings of nips w
max jaderberg karen simonyan andrea vedaldi and andrew zisserman

reading text in the wild with convolutional neural networks
int
j
comput
vis
max jaderberg karen simonyan and andrew zisserman

deep structured output learning for unconstrained text recognition
in proceedings of iclr
max jaderberg karen simonyan andrew zisserman al

spatial transformer networks
in proceedings of max jaderberg andrea vedaldi and andrew zisserman

deep features for text spotting
in proceedings of eccv
nips


dimosthenis karatzas lluis gomez bigorda anguelos nicolaou suman ghosh andrew bagdanov masakazu icdar iwamura jiri matas lukas neumann vijay ramaseshan chandrasekhar shijian lu al

competition on robust reading
in proceedings of icdar

dimosthenis karatzas faisal shafait seiichi uchida masakazu iwamura lluis gomez i bigorda sergi robles mestre joan mas david fernandez mota jon almazan almazan and lluis pere de las heras

icdar robust reading competition
in proceedings of icdar

anoop raveendra katti christian reisswig cordula guder sebastian brarda steffen bickel johannes hhne and jean baptiste faddoul

chargrid towards understanding documents
in proceedings of emnlp

wonjun kim and changick kim

a new approach for overlay text detection and extraction from complex video scene
ieee transactions on image processing
j
acm vol
no
article
publication date december
text recognition in the wild a survey thomas n kipf and max welling

semi supervised classification with graph convolutional networks
in proceedings of iclr
hyung il koo and duck hoon kim

scene text detection via connected component clustering and nontext filtering
ieee transactions on image processing
ivan krasin tom duerig neil alldrin vittorio ferrari sami abu el haija alina kuznetsova hassan rom jasper uijlings stefan popov andreas veit al

openimages a public dataset for large scale multi label and multi class image classification
dataset available from
com openimages
john d
lafferty andrew mccallum and fernando c
n
pereira

conditional random fields probabilistic models for segmenting and labeling sequence data
in proceedings of icml

yann lecun lon bottou yoshua bengio patrick haffner al

gradient based learning applied to document chen yu lee and simon osindero

recursive recurrent nets with attention modeling for ocr in the wild
in seonghun lee min su cho kyomin jung and jin hyung kim

scene text extraction with edge constraint and recognition
proc
ieee
proceedings of cvpr

text collinearity
in proceedings of icpr

networks
in proceedings of iccv

hui li peng wang and chunhua shen

towards end to end text spotting with convolutional recurrent neural hui li peng wang chunhua shen and guyu zhang

show attend and read a simple and strong baseline for irregular text recognition
in proceedings of aaai

minhua li and chunheng wang

an adaptive text detection approach in images and video frames
in proceedings peipei li haixun wang hongsong li and xindong wu

employing semantic context for sparse information extraction assessment
acm transactions on knowledge discovery from data tkdd
ming liang and xiaolin hu

recurrent convolutional neural network for object recognition
in proceedings of of ijcnn

cvpr

minghui liao pengyuan lyu minghang he cong yao wenhao wu and xiang bai

mask textspotter an end to end trainable neural network for spotting text with arbitrary shapes
ieee trans
pattern anal
mach
intell
minghui liao baoguang shi and xiang bai

a single shot oriented scene text detector
ieee transactions on image processing
minghui liao baoguang shi xiang bai xinggang wang and wenyu liu

textboxes a fast text detector with a single deep neural network
in proceedings of aaai

minghui liao jian zhang zhaoyi wan fengming xie jiajun liang pengyuan lyu cong yao and xiang bai

scene text recognition from two dimensional perspective
in proceedings of aaai

rainer lienhart and axel wernicke

localizing and segmenting text in images and videos
ieee transactions on circuits and systems for video technology
ron litman oron anschel shahar tsiper roee litman shai mazor and r
manmatha

scatter selective context attentional scene text recognizer
in proceedings of cvpr
cheng lin liu masashi koga and hiromichi fujisawa

lexicon driven segmentation and recognition of handwritten character strings for japanese address reading
ieee trans
pattern anal
mach
intell
fei liu jeffrey flanigan sam thomson norman sadeh and noah a smith

toward abstractive summarization using semantic representations
corr

hu liu sheng jin and changshui zhang

connectionist temporal classification with maximum entropy regularization
in proceedings of nips

wei liu chaofeng chen and kwan yee k wong

char net a character aware neural network for distorted scene text recognition

in proceedings of aaai

wei liu chaofeng chen kwan yee k wong zhizhong su and junyu han

star net a spatial attention residue network for scene text recognition
in proceedings of bmvc

xu liu

a camera phone based currency reader for the visually impaired
in proceedings of acm sigaccess international conference on computers and accessibility

xiaojing liu feiyu gao qiong zhang and huasha zhao

graph convolution for multimodal information extraction from visually rich documents
in proceedings of naacl

xinhao liu takahito kawanishi xiaomeng wu and kunio kashino

scene text recognition with cnn classifier and wfst based word labeling
in proceedings of icpr

xuebo liu ding liang shi yan dagui chen yu qiao and junjie yan

fots fast oriented text spotting with a unified network
in proceedings of cvpr

j
acm vol
no
article
publication date december
chen and jin al
xiaoqian liu and weiqiang wang

robustly extracting captions in videos based on stroke like edges and spatio temporal analysis
ieee transactions on multimedia
xi liu rui zhang yongsheng zhou qianyi jiang qi song nan li kai zhou lei wang dong wang minghui liao et al

icdar robust reading challenge on reading chinese text on signboard
in proceedings of icdar

yuliang liu hao chen chunhua shen tong he lianwen jin and liangwei wang

abcnet real time scene text spotting with adaptive bezier curve network
in proceedings of cvpr
yuliang liu and lianwen jin

deep matching prior network toward tighter multi oriented text detection
in proceedings of cvpr

yuliang liu lianwen jin and chuanming fang

arbitrarily shaped scene text detection with a mask tightness text detector
ieee transactions on image processing
yuliang liu lianwen jin zecheng xie canjie luo shuaitao zhang and lele xie

tightness aware evaluation protocol for scene text detection
in proceedings of cvpr

yuliang liu lianwen jin shuaitao zhang canjie luo and sheng zhang

curved scene text detection via transverse and longitudinal sequence connection
pattern recognition
yang liu zhaowen wang hailin jin and ian wassell

synthetically supervised feature learning for scene text recognition
in proceedings of eccv

zichuan liu yixing li fengbo ren wang ling goh and hao yu

squeezedtext a real time scene text recognition by binary convolutional encoder decoder network
in proceedings of aaai

shangbang long xin he and cong ya

scene text detection and recognition the deep learning era
corr shangbang long and cong yao

unrealtext synthesizing realistic scene text images from the unreal world
fang lu corey s mccaffrey and elaine i kuo

foreign language abbreviation translation in an instant messaging

in proceedings of cvpr
system
us patent
simon m lucas

icdar text locating competition results
in proceedings of icdar

simon m lucas alex panaretos luis sosa anthony tang shirley wong and robert young

icdar robust canjie luo lianwen jin and zenghui sun

moran a multi object rectified attention network for scene reading competitions
in proceedings of icdar

text recognition
pattern recognition
canjie luo qingxiang lin yuliang liu jin lianwen and shen chunhua

separating content from style using adversarial learning for recognizing text in the wild
corr

pengyuan lyu minghui liao cong yao wenhao wu and xiang bai

mask textspotter an end to end trainable neural network for spotting text with arbitrary shapes
in proceedings of eccv

jieru mei luo dai baoguang shi and xiang bai

scene text script identification with convolutional recurrent neural networks
in proceedings of icpr

yajie miao mohammad gowayyed and florian metze

eesen end to end speech recognition using deep rnn models and wfst based decoding
in ieee workshop on automatic speech recognition and understanding asru

anand mishra karteek alahari and cv jawahar

scene text recognition using higher order language priors
in anand mishra karteek alahari and cv jawahar

top down and bottom up cues for scene text recognition
in proceedings of bmvc

proceedings of cvpr

anand mishra karteek alahari and cv jawahar

enhancing energy minimization framework for scene text recognition with top down cues
computer vision and image understanding
mehryar mohri fernando pereira and michael riley

weighted finite state transducers in speech recognition
ali mosleh nizar bouguila and a ben hamza

image text detection using a bandlet based edge detector and computer speech and language
stroke width transform

in proceedings of bmvc

george nagy

twenty years of document image analysis in pami
ieee trans
pattern anal
mach
intell
nibal nayef yash patel michal busta pinaki nath chowdhury dimosthenis karatzas wafa khlif jiri matas umapada pal jean christophe burie cheng lin liu al

robust reading challenge on multi lingual scene text detection and recognition rrc
in proceedings of icdar

yuval netzer tao wang adam coates alessandro bissacco bo wu and andrew y ng

reading digits in natural images with unsupervised feature learning
in proceedings of nips
j
acm vol
no
article
publication date december
text recognition in the wild a survey lukas neumann and jiri matas

a method for text localization and recognition in real world images
in luk neumann and ji matas

real time scene text localization and recognition
in proceedings of cvpr
luk neumann and ji matas

efficient scene text localization and recognition with local character refinement
proceedings of accv


in proceedings of icdar

luk neumann and ji matas

real time lexicon free scene text localization and recognition
ieee trans
pattern anal
mach
intell
shigueo nomura keiji yamanaka osamu katai hiroshi kawakami and takayuki shiose

a novel adaptive morphological approach for degraded character image segmentation
pattern recognition
yi feng pan xinwen hou and cheng lin liu

a hybrid approach to detect and localize texts in natural scene images
ieee transactions on image processing
clment peyrard moez baccouche franck mamalet and christophe garcia

competition on text image super resolution
in proceedings of icdar

xianbiao qi yihao chen rong xiao chun guang li qin zou and shuguang cui

a novel joint character categorization and localization approach for character level scene text recognition
in proceedings of icdar workshops

liang qiao sanli tang zhanzhan cheng yunlu xu yi niu shiliang pu and fei wu

text perceptron towards end to end arbitrary shaped text spotting
in proceedings of aaai
zhi qiao yu zhou dongbao yang yucan zhou and weiping wang

seed semantics enhanced decoder framework for scene text recognition
in proceedings of cvpr
siyang qin alessandro bissacco michalis raptis yasuhisa fujii and ying xiao

towards unconstrained end to end text spotting
in proceedings of iccv

weichao qiu and alan l
yuille

unrealcv connecting computer vision to unreal engine
in proceedings of eccv

trung quy phan palaiahnakote shivakumara shangxuan tian and chew lim tan

recognizing text with perspective distortion in natural scenes
in proceedings of iccv

anhar risnumawan palaiahankote shivakumara chee seng chan and chew lim tan

a robust arbitrary text detection system for natural scene images
expert systems with applications
jose a rodriguez serrano albert gordo and florent perronnin

label embedding a frugal baseline for text alain rouh and jean beaudet

method and a device for tracking characters that appear on a plurality of images recognition
int
j
comput
vis
of a video stream of a text
us patent app

joan andreu sanchez vernica romero alejandro h toselli mauricio villegas and enrique vidal

competition on handwritten text recognition on the read dataset
in proceedings of icdar

pierre sermanet soumith chintala and yann lecun

convolutional neural networks applied to house numbers asif shahab faisal shafait and andreas dengel

icdar robust reading competition challenge reading digit classification
in proceedings of icpr

text in scene images
in proceedings of icdar

fenfen sheng zhineng chen and bo xu

nrtr a no recurrence sequence to sequence model for scene baoguang shi xiang bai and cong yao

script identification in the wild via discriminative convolutional neural text recognition
in proceedings of icdar

network
pattern recognition
baoguang shi xiang bai and cong yao

an end to end trainable neural network for image based sequence recognition and its application to scene text recognition
ieee trans
pattern anal
mach
intell
baoguang shi xinggang wang pengyuan lyu cong yao and xiang bai

robust scene text recognition with automatic rectification
in proceedings of cvpr

baoguang shi mingkun yang xinggang wang pengyuan lyu cong yao and xiang bai

aster an attentional scene text recognizer with flexible rectification
ieee trans
pattern anal
mach
intell
baoguang shi cong yao minghui liao mingkun yang pei xu linyan cui serge belongie shijian lu and xiang bai

competition on reading chinese text in the wild
in proceedings of icdar

baoguang shi cong yao chengquan zhang xiaowei guo feiyue huang and xiang bai

automatic script identification in the wild
in proceedings of icdar

cunzhao shi chunheng wang baihua xiao yang zhang song gao and zhong zhang

scene text recognition using part based tree structured character detection
in proceedings of cvpr

palaiahnakote shivakumara souvik bhowmick bolan su chew lim tan and umapada pal

a new gradient based character segmentation method for video text recognition
in proceedings of icdar

j
acm vol
no
article
publication date december
chen and jin al
palaiahnakote shivakumara weihua huang trung quy phan and chew lim tan

accurate video text detection through classification of low and high contrast images
pattern recognition
palaiahnakote shivakumara trung quy phan and chew lim tan

a gradient difference based technique for video text detection
in proceedings of icdar

karen simonyan and andrew zisserman

very deep convolutional networks for large scale image recognition
in proceedings of iclr
amanpreet singh vivek natarajan meet shah yu jiang xinlei chen dhruv batra devi parikh and marcus rohrbach

towards vqa models that can read
in proceedings of cvpr

ajeet kumar singh anand mishra pranav dabral and cv jawahar

a simple and effective solution for script identification in the wild
in iapr workshop on document analysis systems das

bolan su and shijian lu

accurate scene text recognition based on recurrent neural network
in proceedings of accv

bolan su and shijian lu

accurate recognition of words in scenes without character segmentation using recurrent neural network
pattern recognition
yipeng sun jiaming liu wei liu junyu han errui ding and jingtuo liu

chinese street view text large scale chinese text reading with partially supervised learning
in proceedings of iccv

yipeng sun zihan ni chee kheng chng yuliang liu canjie luo chun chet ng junyu han errui ding jingtuo icdar competition on large scale street view text with partial liu dimosthenis karatzas al

labeling rrc lsvt
in proceedings of icdar

youbao tang and xiangqian wu

scene text detection using superpixel based stroke feature transform and deep learning based region classification
ieee transactions on multimedia
shu tian xu cheng yin ya su and hong wei hao

a unified framework for tracking based text detection and recognition from web videos
ieee trans
pattern anal
mach
intell
sam s tsai huizhong chen david chen georg schroth radek grzeszczuk and bernd girod

mobile visual search on printed documents using text and low bit rate features
in proceedings of icip

seiichi uchida

text localization and recognition in images and video
handbook of document image processing and recognition
ranjith unnikrishnan and ray smith

combined script and page orientation estimation using the tesseract ocr engine
in proceedings of the international workshop on multilingual ocr

ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser and illia polosukhin

attention is all you need
in proceedings of nips

andreas veit tomas matera lukas neumann jiri matas and serge belongie

coco text dataset and benchmark for text detection and recognition in natural images
corr

luis von ahn benjamin maurer colin mcmillen david abraham and manuel blum

recaptcha human based character recognition via web security measures
science
zhaoyi wan mingling he haoran chen xiang bai and cong yao

textscanner reading characters in order for robust scene text recognition
in proceedings of aaai
zhaoyi wan fengming xie yibo liu xiang bai and cong yao

ctc for scene text recognition
corr cong wang fei yin and cheng lin liu

memory augmented attention model for scene text recognition
in hao wang pu lu hui zhang mingkun yang xiang bai yongchao xu mengchao he yongpan wang and wenyu liu

all you need is boundary toward arbitrary shaped text spotting
in proceedings of aaai
jianfeng wang and xiaolin hu

gated recurrent convolution neural network for ocr
in proceedings of nips
kai wang boris babenko and serge belongie

end to end scene text recognition
in proceedings of iccv


proceedings of icfhr



kai wang and serge belongie

word spotting in the wild
in proceedings of eccv

peng wang lu yang hui li yuyan deng chunhua shen and yanning zhang

a simple and robust convolutional attention network for irregular text recognition
corr

qingqing wang wenjing jia xiangjian he yue lu michael blumenstein ye huang and shujing lyu

reelfa a scene text recognizer with encoded location and focused attention
in proceedings of icdar workshops

qi wang shaoteng liu jocelyn chanussot and xuelong li

scene classification with recurrent attention of vhr remote sensing images
ieee transactions on geoscience and remote sensing
siwei wang yongtao wang xiaoran qin qijie zhao and zhi tang

scene text recognition via gated cascade attention
in proceedings of icme

j
acm vol
no
article
publication date december
text recognition in the wild a survey tao wang david j wu adam coates and andrew y ng

end to end text recognition with convolutional neural networks
in proceedings of icpr

tianwei wang yuanzhi zhu lianwen jin canjie luo xiaoxue chen yaqiang wu qianying wang and mingxiang cai

decoupled attention network for text recognition
in proceedings of aaai
wenjia wang enze xie peize sun wenhai wang lixun tian chunhua shen and ping luo

textsr aware text super resolution guided by recognition
corr

xinyu wang yuliang liu chunhua shen chun chet ng canjie luo lianwen jin chee seng chan anton van den hengel and liangwei wang

on the general value of evidence and bilingual scene text visual question answering
in proceedings of cvpr
yuyang wang feng su and ye qian

text attentional conditional generative adversarial network for super resolution of text images
in proceedings of icme

yuxin wang hongtao xie zheng jun zha youliang tian zilong fu and yongdong zhang

r net a relationship network for efficient and accurate scene text detection
ieee transactions on multimedia
fred l bookstein principal warps

thin plate splines and the decompositions of deformations
ieee trans
pattern anal
mach
intell
liang wu chengquan zhang jiaming liu junyu han jingtuo liu errui ding and xiang bai

editing text in the wild
in proceedings of acm international conference on multimedia

yue wu and prem natarajan

self organized text detection with minimal post processing via border learning
in proceedings of iccv

hongtao xie shancheng fang zheng jun zha yating yang yan li and yongdong zhang

convolutional attention networks for scene text recognition
acm transactions on multimedia computing communications and applications tomm
lele xie tasweer ahmad lianwen jin yuliang liu and sheng zhang

a new cnn based method for directional car license plate detection
ieee transactions on intelligent transportation systems
lele xie yuliang liu lianwen jin and zecheng xie

derpn taking a further step toward more general object detection
in proceedings of aaai

zecheng xie yaoxiong huang yuanzhi zhu lianwen jin yuliang liu and lele xie

aggregation cross entropy for sequence recognition
in proceedings of cvpr

zecheng xie zenghui sun lianwen jin hao ni and terry lyons

learning spatial semantic context with fully convolutional recurrent network for online handwritten chinese text recognition
ieee trans
pattern anal
mach
intell
linjie xing zhi tian weilin huang and matthew r
scott

convolutional character networks
in proceedings of iccv

wenhui xing junsheng qi xiaohui yuan lin li xiaoyu zhang yuhua fu shengwu xiong lun hu and jing peng

a gene phenotype relationship extraction pipeline from the biomedical literature using a representation learning approach
bioinformatics
li xu and jiaya jia

two phase kernel estimation for robust motion deblurring
in proceedings of eccv

yongchao xu yukang wang wei zhou yongpan wang zhibo yang and xiang bai

textfield learning a deep direction field for irregular scene text detection
ieee transactions on image processing
chenggang yan hongtao xie jianjun chen zhengjun zha xinhong hao yongdong zhang and qionghai dai

a fast uyghur text detector for complex background images
ieee transactions on multimedia
fan yang lianwen jin songxuan lai xue gao and zhaohai li

fully convolutional sequence recognition network for water meter number reading
ieee access
mingkun yang yushuo guan minghui liao xin he kaigui bian song bai cong yao and xiang bai

constrained rectification network for scene text recognition
in proceedings of iccv

xiao yang dafang he zihan zhou daniel kifer and c lee giles

learning to read irregular text with attention mechanisms
in proceedings of ijcai

cong yao xiang bai and wenyu liu

a unified framework for multioriented text detection and recognition
ieee transactions on image processing
cong yao xiang bai wenyu liu yi ma and zhuowen tu

detecting texts of arbitrary orientations in natural cong yao xiang bai baoguang shi and wenyu liu

strokelets a learned multi scale representation for scene images
in proceedings of cvpr

text recognition
in proceedings of cvpr

cong yao xin zhang xiang bai wenyu liu yi ma and zhuowen tu

rotation invariant features for oriented text detection in natural images
plos one
j
acm vol
no
article
publication date december
chen and jin al
qixiang ye and david doermann

text detection and recognition in imagery a survey
ieee trans
pattern anal
mach
intell
qixiang ye wen gao weiqiang wang and wei zeng

a robust text detection algorithm in images and video frames
in proceedings of joint conf
inf
commun
signal process
pac
rim conf
multimedia
ieee
qixiang ye qingming huang wen gao and debin zhao

fast and robust text detection in images and video frames
image and vision computing
chucai yi and yingli tian

text string detection from natural scenes by structure based partition and grouping
ieee transactions on image processing
fang yin rui wu xiaoyang yu and guanglu sun

video text localization based on adaboost
multimedia tools fei yin yi chao wu xu yao zhang and cheng lin liu

scene text recognition with sliding convolutional and applications
character models
in proceedings of iccv
xu cheng yin ze yu zuo shu tian and cheng lin liu

text detection tracking and recognition in video a comprehensive survey
ieee transactions on image processing
deli yu xuan li chengquan zhang junyu han jingtuo liu and errui ding

towards accurate scene text recognition with semantic reasoning networks
in proceedings of cvpr
tai ling yuan zhe zhu kun xu cheng jun li and shi min hu

chinese text in the wild
corr
liu yuliang jin lianwen zhang shuaitao and zhang sheng

detecting curve text in the wild new dataset and
new solution
corr

razieh nokhbeh zaeem rachel l german and k suzanne barber

privacycheck automatic summarization of privacy policies using data mining
acm transactions on internet technology toit
fangneng zhan and shijian lu

esir end to end scene text recognition via iterative image rectification
in fangneng zhan shijian lu and chuhui xue

verisimilar image synthesis for accurate detection and recognition fangneng zhan hongyuan zhu and shijian lu

spatial fusion gan for image synthesis
in proceedings of cvpr
honggang zhang kaili zhao yi zhe song and jun guo

text extraction from natural scene image a survey
proceedings of cvpr

of texts in scenes
in proceedings of eccv


neurocomputing
detector
in proceedings of aaai

sheng zhang yuliang liu lianwen jin and canjie luo

feature enhancement network a refined scene text yaping zhang shuai nie wenju liu xing xu dongxiang zhang and heng tao shen

sequence to sequence domain adaptation network for robust text image recognition
in proceedings of cvpr

xu zhao kai hsiang lin yun fu yuxiao hu yuncai liu and thomas s huang

text from corners a novel approach to detect text and caption in videos
ieee transactions on image processing
yu zhong hongjiang zhang and anil k jain

automatic caption localization in compressed video
ieee trans
pattern anal
mach
intell
yu zhou shuang liu yongzheng zhang yipeng wang and weiyao lin

perspective scene text recognition with feature compression and ranking
in proceedings of accv

yiwei zhu shilin wang zheng huang and kai chen

text recognition in images based on transformer with yingying zhu cong yao and xiang bai

scene text detection and recognition recent advances and future hierarchical attention
in proceedings of icip

trends
frontiers of computer science
j
acm vol
no
article
publication date december

