a m l c
s c v
v i x r a an improved phrase based approach to annotating and summarizing student course responses wencan luo university of pittsburgh pittsburgh pa university of central florida orlando fl fei liu diane litman wencan
pitt
edu
ucf
edu abstract teaching large classes remains a great challenge primarily because it is difcult to attend to all the student needs in a timely manner
automatic text summarization systems can be leveraged to summarize the student feedback submitted immediately after each lecture but it is left to be discovered what makes a good summary for student responses
in this work we explore a new methodology that effectively extracts summary phrases from the student responses
each phrase is tagged with the number of students who raise the issue
the phrases are evaluated along two mensions with respect to text content they should be informative and well formed measured by the rouge metric additionally they shall attend to the most pressing student needs measured by a newly proposed metric
this work is enabled by a phrase based annotation and ing scheme which is new to the summarization task
the phrase based framework allows us to summarize the student responses into a set of bullet points and present to the instructor promptly
introduction effective teachers use student feedback to adjust their teaching strategies
nowadays in large classes there is far too much feedback for a single teacher to manage and attend to
if different perspectives in the student feedback could be summarized and pressing issues identied it would greatly enhance the teachers ability to make informed choices
in this work we seek to automatically summarize the student course feedback into a set of bullet points
each bullet point corresponds to a phrase tagged with the number of students who raise the issue
our emphasis is on the textual feedback submitted by students after each lecture in response to two reective prompts boud et al
describe what you found most interesting in today s class and describe what was confusing or needed more detail
education researchers have demonstrated that asking students to respond to reection prompts can improve both teaching and learning van den boom et al
menekse et al

however summarizing these responses for large classes e

introductory stem moocs remains costly time consuming and an onerous task for humans mosteller
in our prior work luo and litman henceforth introduced the task of automatic rization of student responses
the challenges of this task include high lexical variety because students tend to use different word expressions to communicate the same or similar meanings e

bike ments vs
bicycle parts and high length variety as the student responses range from a single word to multiple sentences
to tackle the challenges proposed a phrase summarization framework sisting of three stages phrase extraction phrase clustering and phrase ranking
the approach extracts noun phrases from student responses groups the phrases using a greedy clustering algorithm and nally selects representative phrases from the clusters using lexrank erkan and radev
there are three limitations in the phrase summarization framework
first noun phrases do not sufce
other types of phrases such as how condence intervals linked with previous topics are useful and should be allowed
second clustering is based on similarity but similarity of phrases that do not appear in a background corpus i
e
the corpus used to learn the similarities can not be captured in the previous this work is licensed under a creative commons attribution
international license
license details creativecommons
org licenses
reective prompt describe what was confusing or needed more detail
student responses in the age of distributions example application of qq plot g was confusing last problem about normalization m central limit teorem y and a and b events example formulas were different
i did not understand that part well sampling distribution r was a little bit abstract q q plot g central limit thm y clt y normal approximation to binomial bernaulli random variables the central limit y and normal approximations


human summary central limit theorem q q plot g sampling distribution r normal approximation normalization last example m human summary central limit theorem q q plots general more explanations details better handwriting move slower sampling distributions nothing table example prompt student responses and two human summaries
are student ids
the summary phrases are each tagged with the number of students who raise the issue i
e
student supporters
the summary and phrase highlights are manually created by annotators
phrases that bear the same color belong to the same issue
each annotator is free to choose his her color palette
we have only demonstrated the highlights of human summary to avoid overlaying of two sets of colors on student responses
the superscripts of the phrase highlights are imposed by the authors of this paper to differentiate colors when printed in grayscale y yellow g green r red b blue and m magenta
setting
lastly a greedy clustering algorithm k medoids kaufman and rousseeuw was ously used to group candidate phrases
it ignores global information and may suffer from a collapsing effect which leads to the generation of a large cluster with unrelated items basu et al

the goal of this work is to explore a phrase based highlighting scheme which is new to the rization task
we aim to improve the phrase summarization framework by exploiting new capabilities that are enabled by the highlighting scheme
in the new scheme human annotators are instructed to create summary phrases from the student responses associate a number with each summary phrase which indicates the number of students who raise the issue henceforth student supporters and highlight the corresponding phrases in both the human summary and student responses
table trates the highlighting scheme and more details are presented in
the new highlighting scheme makes it possible to develop a supervised candidate phrase extraction model
and estimate pairwise phrase similarity with supervision

to solve the third limitation we explore a community detection gorithm oslom lancichinetti et al
that optimizes the statistical signicance of clusters with respect to a global null model

experimental results show that the newly developed phrase traction model is better than noun phrases only in terms of both intrinsic and extrinsic measures phrase similarity learning appears to produce marginal improvement and the community detection approach yields better phrase summaries with more accurate estimation of the number of student supporters
in summary the contribution of this work is threefold
we introduce a new phrase based highlighting scheme for automatic summarization a departure from prior work
it highlights the phrases in the human summary and also the semantically similar phrases in student responses
we create a new dataset annotated with this highlighting
we push the boundary of a phrase based summarization framework by using our highlighting scheme to enable identication of candidate phrases as well as estimation of phrase similarities with supervision and by using community detection to group phrases into clusters
we conduct comprehensive evaluations in terms of both summary text quality measured by rouge lin and how well phrase summaries capture the most pressing student needs measured by a new evaluation metric based on color matching
data set is publicly available at
coursemirror
com download related work work on automatic text summarization involves multiple granularities ranging from keywords phrases to sentences
traditional approaches have largely focused on sentence extraction martins and smith berg kirkpatrick et al
li et al
and document abstraction liu et al
rush et al
durrett et al
nallapati et al

in both cases the produced summary is expected to be cohesive and coherent
we deviate from this path and seek to directly generate a set of bullet points as a summary
phrases are easy to search and browse like words but more meaningful and t better on the small screen of a mobile device compared to sentences ueda et al
luo et al

our task setting differs from those of keyphrase extraction wu et al
liu et al
medelyan et al
hasan and ng kan
of key importance is that each summary phrase is ated with a numerical value indicating the number of students who raise the issue
this information is critical to course instructors for making informed choices
intuitively our task setting bears similarity to word phrase cloud yatani et al
brooks et al
where the cloud gives greater prominence to words or phrases that appear frequently in the source text
the downside is that they do not take lexical variety into account or considering semantically equivalent words phrases
a summarization system is expected to produce high quality summary phrases and accurate estimates of the number of student supporters for each phrase
luo and litman focus on extracting noun phrases from student responses however there lacks a comprehensive evaluation of the results taking the number of student supporters into account
other related work on student responses includes collecting student responses using a mobile application named coursemirror luo et al
fan et al
determining the quality of a student reective response and providing feedback luo and litman and extracting informative sentences from the student feedback luo et al

traditional approaches to summary annotation have been based on either sentence extracts or ment abstracts loza et al
xiong and litman wang and ling
an effective linkage between the document content and human summary on the micro level have been largely absent
barker et al
partially address this challenge by linking a summary back to a group of sentences that port the summary
however this linkage is weak since it tells only that there is one sentence or more supporting the summary within the group without explicitly telling which
approaches such as pyramid nenkova and passonneau have exploited creating summary content units scus to establish such links and alleviate the challenge
the new highlighting scheme described in this work holds promise for establishing direct links between the phrases in student responses and those in the human summary allowing us to develop a new evaluation metric based on color matching
new data and annotation when reviewing the student feedback we observe that not all issues are equally important
some ing problems are more prominent than others
summary phrases should naturally reect the number of students who raise the issue
but until now a reasonable sized dataset has been missing for this type of summarization setting
in this work we create a new dataset for this purpose
this allows us to develop a class of summarization approaches that learn to extract summary phrases from the student responses and estimate the number of student supporters for each summary phrase
our dataset consists of two statistics courses offered in a research university for industrial engineers
after each lecture the students were asked to respond to two carefully designed reection prompts using a mobile application named describe what you found most interesting in today s class and describe what was confusing or needed more detail
for each course two independent human annotators native english speakers with a statistics mathematics background were recruited to create summaries for each lecture and prompt
the instructions we provide to the annotators include create a summary using phrases and mark how many students semantically mentioned each phrase
we limit the number of summary phrases to per lecture and prompt in order to provide a concise summary to the instructor
note that the summary phrases are not limited to extracts while abstracts
google
com store apps edu
pitt
cs
mips
coursemirror and fusion of phrases are also possible they are rare
we further ask the annotators to highlight the corresponding phrases in the student responses which are semantically the same to the summary phrases using the same highlight colors
the number of highlights in student responses should match the number of students who semantically mentioned the phrase
an example is illustrated in table
note that attempt to annotate the number of student supporters for summary phrases on a small dataset but without the highlighting scheme
we argue that the new highlighting scheme can provide many unique benets
first it allows us to track the source phrases that humans use to create the summary phrase
for example the rst summary phrase in human summary of table is central limit theorem
it is created from a collection of phrases in the student responses including the tral limit central limit teorem a typo by the student clt its abbreviation and central limit thm another abbreviation
naturally the highlighted source phrases lend themselves to a supervised approach to candidate phrase extraction
second the highlights inform us about the similarity and similarity of phrases
for example the source phrases that bear the same color are semantically similar to each other whereas those with different colors are semantically dissimilar
in a similar vein we develop a supervised approach that learns to predict the phrase similarity using highlights as guidance
third we are now able to accurately match the phrases in a system summary to those in a human summary allowing the development of a novel summarization evaluation metric
for instance assuming the tem summary contains the phrase last problem about normalization from table using the color highlights we know that this phrase matches the human summary phrase normalization last ple
such semantic matching between system and human summaries remains an elusive challenge for traditional summarization evaluation but highlights make it an easy decision
finally the highlights on source texts indicate to what extent the information has been retained in the human summary
specic to our task we are interested to know the percentage of students whose responses are covered by the human summary
we dene a student coverage score where a student is covered if and only if part of his her response is highlighted
for example in table is considered not covered by human summary
basic statistics of the dataset are presented in table
the student coverage scores
for course a and
for course b highlight the effectiveness of the current annotation scheme with a majority of students covered by the human summaries
course students lectures a b responses

words words per res




highlights

student coverage

averaged by lecture prompt table basic statistics of the dataset
because the student responses and human summaries are created for each lecture and prompt we take the average of the corresponding statistics
improved phrase summarization so far we have motivated the need for a new dataset with a highlighting scheme for phrase based rization
we proceed by describing three improvements to the phrase based summmarization framework
our rst improvement involves a supervised approach to candidate phrase extraction

next we learn to predict the pairwise phrase similarity

further we explore a community detection rithm to group the phrases into clusters

we use the cluster size as an approximation to the number of student supporters for all the phrases within the cluster
adopt lexrank erkan and radev to nally choose one representative phrase from each cluster
we follow the convention in this study
note that our focus of this paper is not on developing new algorithms but to explore new ities that are enabled by the highlighting scheme
we thus perform direct comparisons with approaches described in and leave comparisons to other approaches to future work
we present an intrinsic evaluation of each improvement in this section followed by a comprehensive extrinsic evaluation in
there are lectures in total for course a unfortunately only of them have phrase highlighting

candidate phrase extraction the phrase based highlighting scheme lends itself to a supervised phrase extraction approach
in trast used heuristics to extract noun phrases nps only
this limitation has meant that informative non np phrases such as how condence intervals linked with previous topics will be excluded from the summary whereas uninformative np phrases such as the most interesting point may be included
we attempt to resolve this issue by formulating candidate phrase extraction as a word level quence labeling task
concretely we aim to assign a label to each word in the student responses
we choose to use the bio labeling scheme where b stands for the beginning of a phrase i for continuation of a phrase o for outside of a phrase
for example the b central i limit i and o normal b approximations i illustrates the tagging of individual words where the the central limit and normal approximations are two phrases highlighted by our annotators
local features global features word trigram within a word window part of speech tag trigram within a word window chunk tag trigram within a word window whether the word is in the prompt whether the word is a stopword label bigrams
total number of word occurrences stemmed rank of the word s term frequency table local and global features for supervised phrase extraction
local features are extracted within one student s response
global features are extracted using all student responses to a prompt in one lecture
we choose to use the conditional random fields crf lafferty et al
as our sequence and develop a number of features table based on sentence syntactic structure and word importance to signal the likelihood of a word being included in the candidate phrase
during training we merge the phrase highlights produced by two annotators in order to form a large pool of training instances
when two highlights overlap completely e

normal approximations are marked by both annotators using different colors we keep only one instance of the phrase resulting in and instances for course a and course b respectively
when the highlights partially overlap we use each phrase highlight as a separate training instance
in this and all the following experiments we perform one lecture out cross validation on all the lectures and report results averaged across folds
table presents the intrinsic evaluation results on the phrase extraction task
we calculate precision p recall r and f measure f scores based on the exact match of system phrases to gold standard phrases
while the sequence labeling approach and the features presented here are straightforward they do produce a collection of candidate phrases with higher precision
it removes noun phrases that are commonly used by students but uninformative e

a little bit abstract a problem with today s topic as they were not highlighted by annotators
phrase well formedness is highly important to the summary quality as evaluated in
candidate phrase extraction nps only sequence labeling with highlights p

course a r

f

course b r

p

f

table results of phrase extraction intrinsically evaluated by comparing the system phrases to gold standard phrases using exact match
the highest score in each column is shown in bold
means the difference is signicant with p


similarity learning accurately estimating pairwise phrase similarity plays an essential role in phrase based summarization
better similarity learning helps produce better phrase clusters which in turn leads to more accurate estimation of the number of student supporters for each summary phrase
while a human annotator use the implementation of wapiti lavergne et al
with default parameters
could distinguish the semantic similarity or dissimilarity of the phrase highlights it remains unclear if a single similarity metric could fulll this goal or if we may need an ensemble of different metrics
calculate the pairwise phrase similarity using semilar rus et al
with the latent mantic analysis lsa trained on the touchstone tefanescu et al

one drawback of this approach is that the similarity of phrases that do not appear in a background corpus can not be captured
in this work we develop an ensemble of similarity metrics by feeding them into a supervised classication framework
we use the phrase highlights as supervision where phrases of the same color are positive examples and those of different colors are negative examples
we experiment with a range of metrics for measuring lexical similarity including lexical overlap rus et al
cosine similarity lin ilarity miller bleu papineni et al
simsum lin word embedding goldberg and levy and lsa deerwester et al

lin similarity is based on wordnet denitions
lexical overlap cosine similarity bleu and simsum are related to how many words the two phrases have in common while word embedding and lsa both capture the phrase similarity in a low sional semantic space
therefore we use an ensemble of the above similarity metrics by feeding them as features in a svm classication model assuming it will be better suited for this task than the lsa alone
table presents the intrinsic evaluation results
lsa has a poor degree of coverage low recall with many phrase similarities not being picked up by the metric
pairwise phrase similarity lsa similarity learning with highlights p

course a r

f

p

course b r

f

table results of predicting pairwise phrase similarity measured using classication p r f

phrase clustering use k medoids for phrase clustering
it is a greedy iterative clustering algorithm kaufman and rousseeuw which may suffer from local minimal
we instead treat phrase clustering as a munity detection problem
we dene a community as a set of phrases that are semantically similar to each other as compared to the rest of the phrases in student responses malliaros and vazirgiannis
in our formulation we consider each candidate phrase as a node in the network graph
we create an edge between two nodes if the two phrases are considered semantically similar to each other using the above similarity learning approach
our goal is to identify tightly connected phrase communities in the network structure
the community size is used as a proxy for the number of students who tically mention the phrase
community detection has seen considerable success in tasks such as word sense disambiguation jurgens medical query analysis campbell et al
and automatic summarization qazvinian and radev mehdad et al

phrase clustering k medoids community detection with oslom course a

course b

table results of phrase clustering measured by purity ratio of number of phrases agreeing with the majority color in clusters
we use oslom order statistics local optimization method lancichinetti et al
in this work
it is a widely used community detection algorithm that detects community structures i
e
clusters of vertices from a weighted directed network
it optimizes locally the statistical signicance of clusters with respect to a global null model during community expansion
we use an undirected version of oslom and set the value as
to encourage more communities to be since the number of vertices in the constructed graph is relatively small compared to large complex networks
the key feature of oslom is that it supports nding overlapped community structures and orphaned vertices offering more exibility in the clustering process than k medoids
we want to investigate if the unique characteristics of oslom allow it to produce better phrase clusters hence more accurate estimation of set the number of clusters is to be the square root of the number of extracted phrases
the number of student supporters
we conduct an intrinsic evaluation using purity corresponding to the percentage of phrases in the cluster that agree with the majority color
results are presented in table
while this metric by itself is not thorough enough it does highlight the strength of the community detection approach in generating cohesive clusters
one advantage of oslom we found is that it will treat a phrase different from any other phrase as a singleton while this phrase must be assigned to one of the clusters in k medoids resulting in a noisy cluster
summary evaluation the previous section described three improvements to the phrase summarization framework
next we evaluate them on the end task of summarizing student course responses
the phrase summaries are evaluated along two dimensions we expect rouge lin to measure the informativeness of the summary text content
we further propose a new metric to quantify to what extent the most pressing student needs have been captured in the summary


rouge rouge measures the n gram overlap between system and human summaries
in this work we report and r scores which respectively measure the overlap of unigrams bigrams and unigrams plus skip bigrams with a maximum distance of words
these are metrics commonly used in the duc and tac competitions dang and owczarzak
we implement the phrase summarization work described in luo and litman named as phrasesum
further we include lexrank erkan and radev as a competitive baseline
lexrank is a graph based summarization approach based on eigenvector centrality
it has demonstrated highly competitive performance against the phrasesum on a prior dataset luo and litman
the summary is limited to phrases or less in all experiments
note that the summary length is set independently of the number of clusters
if the number of clusters produced in
is less than the phrase number is equal to the cluster number
a b course system p
lexrank
phrasesum sequencesum

simsum
cdsum
lexrank phrasesum
sequencesum

simsum
cdsum r









f









p









r









f









r r









p









f









table summarization performance
sequencesum means replacing the syntax phrase extraction in the phrasesum baseline with the supervised sequence labeling phrase extraction
simsum means replacing not only the phrase extraction but also the similarity scores using the supervised models
cdsum means using all three proposed techniques including the community detection
indicates that the difference is statistically signicant compared to phrasesum with p

means that the improvement over sequencesum is statistically signicant with p

the summarization performance is shown in table the caption explains the system names
the phrasesum baseline compared to lexrank gets better p and f scores for all three rouge metrics for both courses and the improvement of p is signicant
this is the same as the ndings in luo and litman and veries our implementation of their model
for our enhancements of phrasesum the proposed supervised phrase extraction sequencesum signicantly improves p and thus improves mostly signicantly f as well
simsum is slightly better than sequencesum for r and f however it is not signicant using a two tailed paired t test
it suggests that a supervised method is not necessarily better than an unsupervised model in terms of the end task performance and its improvement over the phrasesum baseline is mainly due to the supervised phrase extraction step
in fact the predicted larity scores using the similarity learning model and the lsa model are highly correlated to each other r
p
although it has a better classication performance table
although cdsum is not signicantly different from sequencesum for the course a it does improve p signicantly for all three rouge metrics for course b
one possible explanation is that the latter course has a larger number of student responses and thus benets more from the community detection as the graph is larger

a new metric based on color matching our goal is to create a comprehensive evaluation metric that takes into account the following two factors
phrase matching
while rouge is a classic summarization evaluation metric it trivially pares the system vs
human summaries based on surface text form
in contrast the phrase highlights allow us to accurately match the phrases in the system summary to those in the human summary based on color matching
this is due to two facts rst our methods are extractive based and all candidate phrases are extracted from the student responses in the new highlighting scheme the annotators are asked to highlight both the human summary phrase and any phrases in the student responses that are semantically the same with the summary phrase using the same color
it thus comes easy to track the colors of the extracted phrases and verify if they match any of those in the human summary
student supporters
each summary phrase is tagged with the number of students who raise the issue
for human summary this number is created by human annotators
for system summary we approximate this number using the size of the cluster from which the summary phrase is extracted
our proposed new metric resembles precision recall and f measure
we dene the true positive tp as the number of shared colors between system and human summaries
each color is weighted by the number of student supporters taken as the smaller value between system and human estimates
the precision is dened as tp over the total number of colors in the system summary each weighted by system estimates while recall is dened as tp over the total number of colors in the human summary each weighted by human estimates
for example assuming the phrases in the human summary are colored and tagged with estimates on student support similarly the phrases in the system summary are colored and tagged
there are two phrases in the system summary that bear the same color we thus add up the system estimates into see human summary in table and sequencesum in table
there are shared colors between system and human summaries
the true positive is calculated as
the precision is
and recall is

the f measure is calculated as the harmonic mean of precision and recall scores
the performance is shown in table
similar to the rouge evaluation sequencesum improves the p and f signicantly
now cdsum not only signicantly improves p but also f for course b
p phrasesum
sequencesum

simsum
cdsum course a r



f



course b r



f



p



table evaluation based on the new metric of color matching
p r and f are averaged by the annotators

example summaries the automatic summaries generated by different systems for the same example in table are shown in table
the phrasesum baseline extracts unnecessary content which could be eliminated by the supervised phrase extraction model
for example including the example after before central limit theorem makes it too specic
the collapse effect with a large cluster with unrelated items basu et al
can also be illustrated e

the quantitative numbers for the phrase i in phrasesum and q q plot in sequencesum are much larger than the gold standard
this is solved by the community detection algorithm where such bigger clusters will not be considered as a single community
phrasesum i the example after central limit theorem y q q plot g the fact that we can sample as many sequencesum q q plot g central limit theorem y normal approximation to binomial cdsum central limit theorem y q q plot g sampling distributions r normal approximation to as we want last problem about normalization m sampling distributions r clt y binomial nothing table example system summaries for the example in table
note the highlights in these summaries are not annotated by human after they are generated
instead they are automatically extracted from the dataset

conclusion and future work in this work we introduce a new phrase based highlighting scheme for automatic summarization
it highlights the phrases in the human summary and also the corresponding phrases in student responses
enabled by the highlighting scheme we improved the phrase based summarization framework proposed by luo and litman by developing a supervised candidate phrase extraction learning to estimate the phrase similarities and experimenting with different clustering algorithms to group phrases into clusters
we further introduced a new metric that offers a promising direction for making progress on developing automatic summarization evaluation metrics
experimental results show that our proposed methods not only yield better summarization performance evaluated using rouge but also produce summaries that capture the pressing student needs
future work includes thorough comparison with other approaches and extending the current research to multiple courses and other summary lengths in order to test the generalizability
we also plan to supplement our rouge scores with human evaluations of system summaries
acknowledgements this research is supported by an internal grant from the learning research and development center at the university of pittsburgh
we thank jingtao wang and xiangmin fan for developing the ror mobile system
we thank fan zhang and huy nguyen for valuable suggestions about the proposed summarization algorithm
we also thank anonymous reviewers for insightful comments and suggestions
references emma barker monica lestari paramita ahmet aker emina kurtic mark hepple and robert gaizauskas

the sensei annotated corpus human summaries of reader comment conversations in on line news
in ings of the annual meeting of the special interest group on discourse and dialogue pages los angeles september
association for computational linguistics
sumit basu chuck jacobs and lucy vanderwende

powergrading a clustering approach to amplify human effort for short answer grading
transactions of the association for computational linguistics
taylor berg kirkpatrick dan gillick and dan klein

jointly learning to extract and compress
in ings of acl pages portland oregon usa
david boud rosemary keogh david walker al

reection turning experience into learning
ledge
bill j brooks debra m gilbuena stephen krause and milo d koretsky

using word clouds for fast formative assessment of students short written responses
chemical engineering education
william campbell elisabeth baseman and kara greeneld

classication examining the roles of social interactions and linguist content in twitter user classication
in proceedings of the second workshop on natural language processing for social media pages dublin ireland
dan s tefanescu rajendra banjade and vasile rus

latent semantic analysis models on wikipedia and tasa
in proceedings of lrec pages reykjavik iceland
hoa trang dang and karolina owczarzak

overview of the tac update summarization task
in proceedings of tac pages
scott deerwester susan t dumais george w furnas thomas k landauer and richard harshman

ing by latent semantic analysis
journal of the american society for information science
greg durrett taylor berg kirkpatrick and dan klein

learning based single document summarization with compression and anaphoricity constraints
in proceedings of acl pages berlin germany
gunes erkan and dragomir r
radev

lexrank graph based lexical centrality as salience in text rization
journal of articial intelligence research
xiangmin fan wencan luo muhsin menekse diane litman and jingtao wang

coursemirror hancing large classroom instructor student interactions via mobile interfaces and natural language processing
in works in progress of acm conference on human factors in computing systems
acm
yoav goldberg and omer levy

explained deriving mikolov et al
s negative sampling embedding method
arxiv preprint

kazi saidul hasan and vincent ng

automatic keyphrase extraction a survey of the state of the art
in proceedings of acl pages baltimore maryland
david jurgens

word sense induction by community detection
in proceedings of workshop pages portland oregon
min yen kan

keywords phrases clauses and sentences topicality indicativeness and informativeness at scales
in proceedings of the acl workshop on novel computational approaches to keyphrase tion page beijing china
leonard kaufman and peter rousseeuw

clustering by means of medoids
statistical data analysis based on the norm and related method pages
john d
lafferty andrew mccallum and fernando c
n
pereira

conditional random elds probabilistic models for segmenting and labeling sequence data
in proceedings of icml pages san francisco ca usa
andrea lancichinetti filippo radicchi jose j ramasco and santo fortunato

finding statistically ca nt communities in networks
plos one
thomas lavergne olivier cappe and francois yvon

practical very large scale crfs
in proceedings the annual meeting of the association for computational linguistics acl pages
association for computational linguistics july
chen li fei liu fuliang weng and yang liu

document summarization via guided sentence compression
in proceedings of emnlp pages seattle washington usa
chin yew lin

rouge a package for automatic evaluation of summaries
in proceedings of the workshop on text summarization branches out volume
barcelona spain
zhiyuan liu peng li yabin zheng and maosong sun

clustering to nd exemplar terms for keyphrase extraction
in proceedings of emnlp pages stroudsburg pa usa
fei liu jeffrey flanigan sam thomson norman sadeh and noah a
smith

toward abstractive rization using semantic representations
in proceedings of naacl pages denver colorado
vanessa loza shibamouli lahiri rada mihalcea and po hsiang lai

building a dataset for summarization and keyword extraction from emails
in proceedings of lrec pages reykjavik iceland
wencan luo and diane litman

summarizing student responses to reection prompts
in proceedings of emnlp pages lisbon portugal
wencan luo and diane litman

determining the quality of a student reective response
in proceedings international flairs conference key largo fl
wencan luo xiangmin fan muhsin menekse jingtao wang and diane litman

enhancing student and student student interactions with mobile interfaces and summarization
in proceedings of naacl demonstrations pages denver colorado
wencan luo fei liu zitao liu and diane litman

automatic summarization of student course back
in proceedings of the north american chapter of the association for computational linguistics human language technologies naacl
fragkiskos d
malliaros and michalis vazirgiannis

clustering and community detection in directed works a survey
corr

andre martins and noah a
smith

summarization with a joint model for sentence extraction and sion
in proceedings of the workshop on integer linear programming for nlp pages boulder colorado
olena medelyan eibe frank and ian h
witten

human competitive tagging using automatic keyphrase extraction
in proceedings of emnlp pages stroudsburg pa usa
yashar mehdad giuseppe carenini frank tompa and raymond t
ng

abstractive meeting in proceedings of the european workshop on natural language rization with entailment and fusion
generation pages soa bulgaria
muhsin menekse glenda stump stephen j
krause and michelene t
h
chi

the effectiveness of students daily reections on learning in engineering context
in proceedings of the american society for engineering education annual conference vancouver canada
george a miller

wordnet a lexical database for english
communications of the acm
frederick mosteller

the muddiest point in the lecture as a feedback device
on teaching and learning the journal of the harvard danforth center
ramesh nallapati bing xiang and bowen zhou

sequence to sequence rnns for text summarization
corr

ani nenkova and rebecca passonneau

evaluating content selection in summarization the pyramid method
in daniel marcu susan dumais and salim roukos editors proceedings of naacl pages boston massachusetts usa
kishore papineni salim roukos todd ward and wei jing zhu

bleu a method for automatic evaluation of machine translation
in proceedings of acl pages philadelphia pennsylvania usa
vahed qazvinian and dragomir r
radev

learning from collective human behavior to introduce diversity in lexical choice
in proceedings of acl pages portland oregon usa
vasile rus mihai lintean rajendra banjade nobal niraula and dan stefanescu

semilar the semantic similarity toolkit
in proceedings of acl system demonstrations pages soa bulgaria
alexander m
rush sumit chopra and jason weston

a neural attention model for abstractive sentence summarization
in proceedings of emnlp pages lisbon portugal
yoshihiro ueda mamiko oka takahiro koyama and tadanobu miyauchi

toward the at a glance mary phrase representation summarization method
in proceedings of coling pages stroudsburg pa usa
gerard van den boom fred paas jeroen jg van merrienboer and tamara van gog

reection prompts and tutor feedback in a web based learning environment effects on students self regulated learning competence
computers in human behavior
lu wang and wang ling

neural network based abstract generation for opinions and arguments
in proceedings of naacl pages san diego california
yi fang brook wu quanzhi li razvan stefan bot and xin chen

domain specic keyphrase extraction
in proceedings of cikm pages new york ny usa
wenting xiong and diane litman

empirical analysis of exploiting review helpfulness for extractive marization of online reviews
in proceedings of coling pages dublin ireland
koji yatani michael novati andrew trusty and khai n
truong

review spotlight a user interface for summarizing user generated reviews using adjective noun word pairs
in proceedings of chi pages new york ny usa

