topic modelling and event identification from twitter textual data marina kanyi joshua vera renee chris sidney nanjira sambuli of ottawa ottawa on canada sokolova joshua

ca for big data analytics dalhousie university halifax ns canada of computer science polish academy of sciences warsaw poland
dal
ca vancouver bc canada
org nairobi kenya chris
co
ke corresponding author marina sokolova institute for big data analytics dalhousie university and university of ottawa rgn smyth rd ottawa on canada email
ca abstract the tremendous growth of social media content on the internet has inspired the development of the text analytics to understand and solve real life problems
leveraging statistical topic modelling helps researchers and practitioners in better comprehension of textual content as well as provides useful information for further analysis
statistical topic modelling becomes especially important when we work with large volumes of dynamic text e

facebook or twitter datasets
in this study we summarize the message content of four data sets of twitter messages relating to challenging social events in kenya
we use latent dirichlet allocation lda topic modelling to analyse the content
our study uses two evaluation measures normalized mutual information nmi and topic coherence analysis to select the best lda models
the obtained lda results show that the tool can be effectively used to extract discussion topics and summarize them for further manual analysis
keywords twitter statistical topic modelling model evaluation
introduction in recent years social media has increasingly come under the microscope in the context of political events in order to enhance understanding of current and emerging issues
while there are a wide variety of areas of focus and implications for such study topics related to peace and security are of particular interest
communications and propaganda have played particularly important roles in the most violent episodes of our history such as during the rwandan genocide where radio was used to spread violent hateful and dehumanizing messages that led to the massacre of more than rwandans crimes which implicated more than one million perpetrators
social create both new risks in exacerbating tension but can also create opportunities for responding to violence and incitement towards the prevention of violence and the escalation and toward building more peaceful open and democratic societies
while practitioners have been looking at more small data examples of how messaging can manifest and with what implications big data and sentiment analysis tools offer an incredible opportunity to understand commentary and behavior in online spaces towards better understanding their implications offline
the goal of such study is to help relevant actors notably governments and society actors to develop meaningful understanding and responses to these emerging trends towards reducing the risk of violence and towards using social media in more proactive ways to build trust between conflicting communities
kenyans are among the most active and avid users of social media tools in facebook is estimated to have over million users and twitter over
users as of meaning that effective use abuse and regulation of social media can play an important role in affecting the outcome of future conflicts
we are only at the beginning of understanding the potential for such research
this paper explores what we can learn from specific events in kenya towards considering how to further develop a broader research agenda moving forward

background with a large number of people embarking on a trend of actively voicing their opinion online on social networks and forums social media has become a major source for social data mining matwin
starting from humble beginnings in twitter has grown exponentially from
in the media daily posted up to million of messages figure
emergence of twitter as a leading social media has
html
dotsavvyafrica
com biggest social media platforms in
businessdailyafrica
com corporate news africa kenya is second most active made it a useful resource in development of social oriented text analysis as in analysis of commentary disseminated via twitter on the riots in london and other british cities in august tonkin pfeiffer tourte figure
growth of posted tweets worldwide per day m million adapted from twitter outreach and growth is a worldwide phenomenon both in the number of twitter users and posted tweets
according to a survey conducted by portland communications and tweetminster twitter has become an important source of information in africa
in kenya had the second most active population on twitter in africa
at the end of nairobi was the most active city in east africa with geo located tweets
according to mobile phone operator airtel there is constant increase in the number of people following other kenyan users accounts figure
each follower potentially amplifies the impact of posted messages
this online community known collectively by the acronym kot kenyans on twitter is now acknowledged as in important and ever growing force in kenyan social and political
with community based learning prominently contributing to many aspects of kenyan life ramisch et al twitter plays a transformative role in the society
it is also acquiring an important role in both generating but also curtailing dangerous speech related to domestic political events from major events like s general election and the westgate terror attack to more localized acts of corruption and political

internetlivestats
com twitter
portland communications
com publications how africa
socialbakers
com resources client stories airtel
nation
co
ke lifestyle showbiz is kot the most powerful group in
html
bbc
com news figure
kenya s follower growth on the project emerged out of recognition that mobile and digital technologies played a catalyzing role in kenya s post election violence
this project seeks to better understand the use of dangerous speech in the kenyan online space
the project monitors particular blogs forums online newspapers facebook and twitter
online content monitored includes tweets status updates and comments posts and blog entries
set up in september ahead of kenya s general elections the umati project sought to identify the use and role of social media in propagating dangerous hate speech online something that at the time no other monitoring group was looking into
in order to understand the changes in online inflammatory speech used over time the umati project developed a contextualized methodology for identifying collecting and categorizing inflammatory speech in the kenyan online space
the media s near unlimited growth rapidly changing content linguistic complexity and often implicit context presents considerable challenges for data analytics
meaningful analysis of the data can be achieved by collaboration of social science computer science especially machine learning and text data mining and quantitative analysis
the current work demonstrates how state of the art statistical topic modelling methods can be used in analysis of twitter data
topic models are mostly unsupervised data driven means of capturing main discussions happening in collections of texts
each topic is represented through a probability distribution over words occurring in the collection such that words that co occur frequently are each assigned high probability in a given topic aletras baldwin lau stevenson
statistical topic modelling is commonly based on automated generation of terms and term phrases associated with a given topic lau newman karimi baldwin
it has been shown that terms provide for more relevant document retrieval than term phrases aletras baldwin lau stevenson
we apply latent dirichlet allocation lda blei ng jordan
to evaluate the lda results we applied normalized mutual information nmi and topic coherence analysis
the two measures are complementary by design nmi rates representativeness of the constructed topics in the data set whereas topic coherence
socialbakers
com resources client stories airtel kiswahili word that means crowd
measures each topic individually
we worked with four sets of twitter texts provided by the umati
data collection was done utilising twitter streaming api
each data set represents a collective response to a significant social event in early e

assassination of a controversial cleric explosions in a major market and attacks in two different communities

data sets we worked with four sets of texts collected from twitter each of which had generated online controversy but with varying sample sizes
the data were collected by the umati through twitter s streaming api
the gikomba twitter data mainly covers a bombing incident in a nairobi market called gikomba
the tweets talk about explosions blasts i
e
what happened in the market speculate on suspected perpetrators and discuss how people feel about the bombing incident and how social organizations and the government reacted and responded to the incident

the mandera twitter data contains tweets mainly talking about so called tribal clashes in mandera region a kenyan town located near the border with somalia and ethiopia
the data has tweets in total

the makaburi dataset contains tweets
in those tweets people are talking about the violent death of sheikh makaburi a controversial muslim preacher
as a result of the controversy of the late cleric and his public assassination two opposite opinions exist towards the incident some people think that killing is justified while others think makaburi was innocent

the mpeketoni data set is the largest with tweets
in that data people mainly discuss an attack that happened in mpeketoni town in the coastal region of kenya as well as social and political problems behind that attack
in the present study we worked with tweets written in english tweets written in other languages were left for future work
our choice is not unreasonable
we know from other studies that automated language identification showed of tweets in kenya were in
only tweets were in kiswahili
the rest were in an array of other languages including hindi kikuyu somali luo the sheng dialect and other languages
many of these were mixed with
the twitter data is considered to be more challenging than other social data due to a character limit and misspellings slang and informal capitalization eisenstein
all the four sets exhibit misspelling slang a large number of urls informal capitalization typical for twitter data
those characteristics can significantly diminish capacity of the text analytics tools
thus a considerable normalization effort is required to prepare the data for meaningful topic modelling
we performed data pre processing with the aim to make the text suitable for application of automated natural language processing techniques
the first step was to identify and delete duplicate text
since www
ihub
co
ke umati
co
ke research
economist
com blogs twitter kenya
what twitter can tell us about african this part of the study aims to analyze english text on the next step we identified and filtered out messages in other languages
finally we deleted urls stop words the and of short words characters and tokenized each sentence
traditional syntactic and semantic text analysis methods i
e
technology and science known as natural language processing nlp were developed to process contrived well edited text
twitter messages however are often spontaneously written and unaltered after posting
to exemplify challenges faced by traditional nlp tools in analysis of twitter data we report part of speech pos tagging results by lingpipe a commonly used nlp
in many cases the assigned pos tags are questionable and can not be relied upon in further analysis of the data e

mall was incorrectly identified as an adjective
in further steps of data analysis we employ latent dirichlet allocation lda statistical topic modelling technique blei ng jordan
this unsupervised algorithm has been proved to be an effective probabilistic model for topic modelling of twitter data

empirical analysis
lda application latent dirichlet allocation lda is a topic modelling algorithm used for extracting topics from a given collection of documents blei ng jordan
it builds models in unsupervised mode i
e
does not need labelled training data
based on the assumption that a document contains a mixture of n underlying different topics and the document is generated by these topics with different proportions or probabilities lda is able to find out the topics and their relative proportions which are distributed as a latent dirichlet random variable
the algorithm s performance can be managed though assumptions on the word and topic distributions
table reports on the adjustable parameters of the lda model table lda adjustable parameters
variables n mintokencount minimum token count i
e
if one word appears less than definition required topic number dirichlet prior on the per document topic distributions dirichlet prior on the per topic word distributions numtokens numdocs mintokencount ignore that word in the document number of tokens of a data number of documents in our experiment which is number of records of a data given a pre set of parameters such as which is the parameter of the dirichlet prior on the per document topic distributions and which is the parameter of the dirichlet prior on the per topic word distribution the only required input is the documents and fixed topic number n
the output of lda contains two parts
part one is n topics with a list of words and count numbers for each word
part two for each document indicates lingpipe website i
com which topics it might belong to and the relative probability
the general processing procedure using lda is as follows
setting parameters
the default parameters are

mintokencount
choose a topic number n and input data file

tokenize for the text data

run lda algorithm to get the latent structure behind the text and print out the result
for the gikomba data we started with default parameters

and input parameter topic number n which means desired topics
by comparing the gikomba lda result above we choose topic number n as a basic group for further comparison since when n most topics have enough words to reveal information about the topic while without too much words to make the topics messy
in the next step of our experiment we set n and tuning parameter and by setting


while


to see if the results show any difference
for the mandera data we also start with default parameters

and topic number n
also we continue the experiment with tuning parameter


and



mandera lda results with topic number n and both show good results
however for the larger datasets i
e
makaburi and mpeketoni data fifteen topic numbers is not enough to capture sufficient information about the data
as a result we tried topic number n and for makaburi and mpeketoni data respectively
since we have tried lda algorithm with different parameters in the following analysis we use lda topics to denote lda with different topic number dirichlet prior on the per document topic distributions and dirichlet prior on the per topic word distributions
for example lda

means that we applied lda with topics
and


manual analysis of the lda topics from the manual analysis of the extracted topics we confirmed that the lda results are able to identify the event and reveal some relevant information about the said event
for example in gikomba lda

topic blast bomb give us an idea of what happened there kenya indicates the location of the incident
in topic the outliers are security ban background ban refers to restricting access to the place in question
in topic terror gikomba nairobi market indicate the location details
in topic and topic there are clothes and in topic there are nguo which is also clothes in swahili both words show how the bomb was hidden that is in clothes background the section of gikomba market that was attacked primarily deals with open air trading of clothes
although we considered the pre processed gikomba data to be our benchmark section we also applied lda on other versions of the gikomba data one dataset keeps short words while removing stop words another dataset keeps stop words and short words
comparing the obtained lda results the found commonalities are as follows
all results reveal background information about the incident including the location by words gikomba nairobi market
the nature of the incident by words fire bomb attack blast
actors in the attack and how the attack happened by words suspect terror clothes nguo


all results contain a topic with word security which means people care and talking about security issues after the attack

all results contain topic with references to people s names such as kimaiyo inspector general of the kenya police robertalai a prominent investigative blogger kidero governor of nairobi
at the same time there exist notable differences between the results
when the data contains short words security often appears in a topic which also lists no we assume this joint occurrence indicates the phase no security
as expected in the data with short words filtered out the word no disappeared from the resulting topics

some high frequency words appear in lda results obtained on one data but not in others
for example according to our preliminary words frequency analysis reconstruction and donate have high frequency
however they only appear in the lda results obtained on the data version containing stop words and short words both words appear together with word kidero background evans kidero the nairobi county governor donated money to reconstruct gikomba market after the attack
in the lda results obtained on the other two data versions only kidero appears

the lda results on the benchmark data i
e
stop and short words removed contain more references to politicians and government officials such as kimaiyo robertalai a prominent blogger robert alia who was often the first to break stories on twitter and railaodinga these references are absent in the other results
regarding the mandera lda results outliers in the topics are shown as following in mandera lda

topic fighting somalis as well as in topic clashes tribal killing indicate the situation in mandera background there exists serious conflict between different clans in mandera
in topic we found that a word sad appears together with killing
this joint occurrence may indicate people s feeling towards the conflict
topic lists security insecurity need government violence end
this implies that people hope for government to do something to ensure their security and end the conflict situation
topic lists muslim which indicates religion as an important factor in the discussion
topic and topic list somalis
we found it interesting that somalis and muslim never appear in the same topic in this dataset
perhaps tweets do not mention them together when discussing events in mandera
in topic we assume from words solution peace leaders that the topic is about ways to achieve peace
the extracted topics also contain references to people e

johnallannamu a renowned journalist uhuru president of kenya duale a prominent politician and abdulazizhoa an al shabaab terrorist group follower
comparing the benchmark mandera lda results i
e
stop words and short words are deleted with the results obtained on other data versions we found that all lda results can reveal the situation in mandera
all the results contain description of clashes killings and violence
at the same time the results contain topics referring to peace and finding solutions for the situation
the most noteworthy difference between the results is that sentiment bearing words such as great sad appear only when the stop words are deleted from original mandera data
for makaburi data a much larger dataset we chose makaburi

as the baseline result
in makaburi lda

words in topics also reveal information about what happened to sheikh makaburi
from topic death gun and in topic shoot we understand that makaburi was fatally shot
some topics also reveal background of makaburi s assassination for example in topic religion islam and in topic christians muslims indicate there might be some religious issues that have connections with makaburi s death
remarkably different topics contain words with opposite sentiments deserved vs sad
we can assume that when people talked about makaburi s death they may have had antagonistic opinions towards him
some antonyms even appear in the same topic
for example in topic we have good and bad
in topic there are heaven and hell
other examples including in topic there is deserved while in topic there is innocent
in topic there is happy while in topic there is sad
besides that we can see people s concern about security via topic which lists security situation and government
when we reduced the number of topics to and built makaburi lda

we found that almost every topic contains the word makaburi
as in previous results the extracted topics contain opposite sentiment words pairs good and bad heaven and hell innocent and deserve
due to the large volume of tweets in the mpeketoni dataset we chose mpeketoni lda

as a baseline result and found it shows more clear topics than the other datasets i
e
when looking through a topic it is easier for us to assume what the topic means
for example in topic since it contains mpeketoniattack lost families affected sad prayers peace we can conclude that in the topic people are mainly talking about the victims or families affected by the attack and express their condolences as well as their wish for peace
topic is about security issues since it contains safe and security but it may be that people are discussing more about solutions or policies rather than just expressing a wish for security since we found president never uhuru and need
in topic there are mpeketoniattack god country pray help peace sad from which we can feel people s emotion towards the attack and their call for help
in topic people are talking about government s reaction to the attack since we have police response officers military and deployed
topic shows that people are unsatisfied with government since in the topic the word blame has high frequency and also there are politics insecurity government need and instead
similarly in topic which contains government security citizens protect innocent failed and die and sad the high frequency of these words likely indicates a strong expectation for the government as well as sadness for some failure and death
in the mpeketoni data people also talking about politicians but unlike in other datasets names of those politicians tend to appear in the same topic
one example is topic which contains ukenyatta president uhuru kenyatta joelenku cabinet secretary of the interior joseph ole lenku railaodinga opposition politician raila odinga and president william samoei ruto
we can assume that topic identifies suspects in the attack since shabaab alshabaab responsibility claim are the highest frequency words in that topic
topic focuses on media since there are ktnkenya citizentvkenya ntvkenya media and citizentvnews appear together
topic reveals information to describe the attack incident in mpeketoni via words such as lamu police station hotels gunmen and fire background gunmen attacked hotels and a police station in mpeketoni near lamu town and set fire to several buildings
topic talks about conflict between different communities since it is represented through killed kikuyu ethnic tribe and community
another interesting topic is topic which contains consulate british closed west info and know
mpeketoni attacks happened soon after the british consulate at the coastal city of mombasa was closed as a result people may discuss whether this happened by chance or was pre meditated
the number of topics is critical to the quality of analysis
when we reduced the number of topics to mpeketoni lda

did not extract as well identified topics as mpeketoni lda

had done
when we increased the number of topics to the model mpeketoni lda

faulted to improve the quality of the topic extraction it replicated many of the topics found in the output of the models with a smaller number of topics
for example topic of mpeketoni lda

is similar to topic of mpeketoni lda


in that topic people speculate on the coincidence of the mpeketoni attacks being preceded by the closure of the british consulate in mombasa city citing security concerns
topic of mpeketoni lda

is similar to topic of mpeketoni lda

in that topic people express their condolences and sadness for the lives lost in the attacks
in mpeketoni lda

there also exists some topics showcasing similar information
for example topic is similar as topic topic is similar to topic

normalized mutual information results in the experiment we used nmi normalized mutual information to evaluate overall documents tweets cluster quality
the following formula is used to calculate nmi mehrotra al where is mutual information between x and y where x


xn and y


yn
xi is the set of tweets in lda s topic i while yj is the set of tweets with the label j
in our experiments a tweet with the label j means that tweet has the highest probability of belonging to topic j n is the number of topics
is in the formula means probability of being classified to topic i means probability of labeled to topic j while yj means probability of being classified to cluster i but actually labeled to cluster j
is entropy of x as calculated by the following formula nmi means the clustering result is totally different from the label while nmi means clustering result and label result are identical
in our experiments we evaluated nmi of lda with different topic numbers
table reports the results nmi results











table nmi results for lda models
lda models























the results show that with fewer topics the nmi value tends to be higher
since nmi presents similarity of clustered tweets set and labelled tweets set the overall nmi results indicate that with fewer topics tweets set are more correctly clustered
the reason for this phenomenon could be the length of each document tweet is much shorter if compared to traditional documents
since the length for each tweet is limited usually no longer than characters information contained in a single tweet is also limited
hence when the number of topics increases many topics tend to contain the same words as a result it is hard to determine to which topic a document be assigned
in further experiments we can use different tweeter pooling schemes mehrotra sanner buntine xie and see whether they affect the nmi results

topic coherence analysis topic coherence measures each topic by scoring it based on calculating the degree of semantic similarity between words in the topic
it is often considered as a metric to evaluate the quality of a topic
in our experiment we use the following formula nugroho molla aliod yang zhong paris and nepal to implement topic coherence evaluation in the formula and w mean that in topic k the total words set is w
wl is the number of documents containing both word m and word l while is the number of documents containing word
topics with higher values are considered more coherent thus are better
since we have tried lda on different parameters including different with default topic number and different topic numbers with default we then evaluate those results by calculating the normalized average topic coherence value average coherence value between each topic as well as standard deviation between normalized coherence value for each topic average coherence value between each word in each topic
we use the following formula which evolves from the previous topic coherence formula to calculate normalized average topic coherence value in the formula n is number of words in topic
the following formula is used to calculate standard deviation is the topic coherence of topic
co

















in the formula n refers to topic number while topic coherence for the gikomba and mandera datasets is reported in the following tables and
the reported results show that lda with
provides for a slightly better coherence than other but still does not make a significant difference
we also varied the number of topics in the built models
we report assessment of the lda results with different topic numbers in table
table topic coherence for gikomba data with different and parameters gikomba lda

gikomba lda

gikomba lda

gikomba lda

gikomba lda

gikomba lda

gikomba lda

gikomba lda

gikomba lda

table topic coherence for mandera data with different and parameters mandera lda

mandera lda

mandera lda

mandera lda

mandera lda

mandera lda

mandera lda

mandera lda

mandera lda

co

















co























table topic coherence for the four data sets with different topic numbers parameters gikomba lda

gikomba lda

gikomba lda

mandera lda

mandera lda

mandera lda

makaburi lda

makaburi lda

makaburi lda

mpeketoni lda

mpeketoni lda

mpeketoni lda

manually assessing the results with different topic numbers we found that gikomba lda

provides for better results
most topics contain enough words to reveal information and not too many to make the topic unreadable
for mandera data mandera lda

also outputs comprehensible results
hence choosing topics worked well for small data sets
makaburi and mpeketoni lda models yield different results
since data volumes are considerably larger for both datasets increase in the topic number improves the modelling results
makaburi lda

mpeketoni lda

and mpeketoni lda

all output reasonably understandable topics
in topic coherence analysis however the lower topic number in mandera lda

seems to have better coherence performance than mandera lda


for makaburi and mpeketoni data coherence performance also seems better with a smaller topic number
by examining topic coherence values for each topic and the appearance count for each word in the topic we found that for fewer topic numbers each topic tends to have a higher score and words in each topic have larger appearance count numbers thus causing a higher total coherence value
this can be explained as for fewer topic numbers for each document probability of belonging to a particular topic increases
hence each topic has more words assigned to it and those words have a higher chance to appear in a document assigned to the same topic
when examining topics with higher coherence values we found those high value topics usually contain high frequency words
those words often reveal the event s essential information
for example in gikomba lda

the highest topic coherence value is
for topic
in topic words with the greatest contribution to its coherence value are gikomba and market
however in outlier topics for example in topic the word security reveals what people care about but the word only occurs once with gikomba attack and business
based on this and similar examples we conclude that lda is able to identify rare topics i
e
topics that exhibit a well defined content while appearing infrequently in the data
we consider this ability to be a significant advantage of the lda algorithm

related work unsupervised topic modelling can be defined as a search for patterns in the textual data
patterns can be difficult to be identified a thus making assessment of the built models challenging
using manual evaluation can introduce a human bias hence it is imperative to supplement it with evaluation measures sokolova and lapalme
when patterns do not need to have a semantic interpretation one evaluation approach is to fix a number of patterns and then separate different patterns tuytelaars lampert blaschko buntine
however many studies e

textual data social media studies expect semantic interpretation of the found topics
in those cases we can evaluate topic modelling by calculating topic coherence that scores a single topic by measuring the degree of semantic similarity between words in the topic
several studies compare topic coherence of different topic modelling algorithms
considerable research has been done to compare lda modelling quality with other methods e

non negative matrix factorization nmf lee seung
consider nugroho molla aliod yang zhong paris and nepal in this work after the topic extraction the authors calculate coherence for each topic which we also use in our experiment
besides that they also evaluates tweet topic accuracy by using the result of manually labelled training dataset to compare with the automated classified tweet and using f score to compute the harmonic mean of both precision p and recall r
their empirical results show that lda has better topic coherence performance over nmf lda has topic coherence values ranging from

while nmf results range from


however both lda and nmf are not comparable with intlda nmi range from

which the authors advocate in the article as an improved lda algorithm
uci and umass measures are used to evaluate topic coherence in stevens kegelmeyer andrzejewski and buttler
for uci measure which indicates average coherence score the result shows lda and nmf almost the same and stable at around

however as for entropy for the umass score nmf produces unstable results ranging from
to i
e
nmf learns topics with different levels of quality some with high and some with very low quality
besides nmi uci and umass wise mutual information pmi is also used to evaluate topic coherence mehrotra sanner buntine xie
work by chen and liu aims at addressing the topic coherence issue existing in unsupervised models
the authors propose an automatic process to learn prior knowledge from various domains and use that knowledge to generate more coherence topics
further the authors propose a new knowledge based topic model ltm to deal with possible incorrect knowledge
quality of twitter s topic modelling can be improved through various approaches
a commonly used method is pre processing data through tweet pooling schemes
for example in the work by mehrotra sanner buntine and xie the authors provide an automatic hashtag assignment scheme to improve lda topic quality which proved in the later experiment to be the best pooling scheme with pmi value increased from
to

however in our twitter data sets most tweets do not have a hashtag so it is infeasible for our experiment to verify the effect of hashtag pooling
in other work nugroho molla aliod yang zhong paris and nepal propose intlda as a variant of lda incorporating the tweet relationship to improve the tweet topic distributions
in the work by xie yang and the authors build a markov random field mrf regularized lda model which defines a mrf on the latent topic layer of lda in order to create better chance for similar words to appear in the same topic
besides lda there also some works targeting at other topic modeling methods such as the work by yan guo liu cheng and wang in which the authors improve nmf algorithm by directly estimating topics from term correlation data rather than the sparse term document matrix
twitter has become one of the major research sources in text mining field over the past years it differs from traditional media data sources due to large volumes and the short length of each document tweets
the work by zhao and jiang provides comprehensive comparison between twitter and traditional news media content analysis through lda topic modelling
eisenstein focuses on one of the most typical attributes of online data the high abundance of misspellings abbreviated phrases and internet slang or shorthand
the author analyzes different types of bad language and their possible causes and then provides suggestions on how to mitigate it such as normalization and preprocessing
twitter data has been used in some business applications
for example si mukherjee liu li li and deng use topic based sentiments from twitter to help predict the stock market
the authors first utilize a continuous dirichlet process mixture model to learn the daily topic set and then build a sentiment time series base on the opinion words distribution of each topic
finally the authors use the stock index and the twitter sentiment time series to predict the market

conclusions and future work with a large number of people participating on social networks and online forums social media has become a major source for social data mining
in the presented work we applied statistical topic modelling to extract and analyze content of twitter data
we worked with four sets of twitter messages collected in kenya for the umati project monitoring online dangerous speech
each dataset follows a specific event
for the topic modelling we applied latent dirichlet allocation
we varied the lda parameters to find a model that outputs more informative and coherent topics as evaluated by nmi and topic coherence analysis
performance of the lda models was not affected by changes in distribution parameters and
at the same time the results significantly changed with the change of topic numbers
as we expected the quality of lda results also depends on the amount of records in the data
manual analysis of the results revealed that lda is able to extract detailed information from the data
it extracts all the major event components including the geographic location people involved how the event unfolded
it is also important to note that all the extracted topics were related to the events covered by the collected data
our method does not confide to the analysis of kenya s data
it can be applied to the analysis of twitter data collected in similar settings
understanding the influence of social networks can help political scientists to better understand how such information can be used not only in the dissemination of online violent messaging but can also help to inform responses that could help to mitigate or prevent violence from starting and escalating
it can also act as an early warning mechanism for when incidents do occur
with a more real time understanding of emerging issues programs that aims to prevent and respond to conflict escalation can consider how to respond to current and emerging threats
relevant questions would include why and when do online tools get used to incite violence and hate how does the dissemination of information about violence in online spaces affect communities at risk what is the nature of online speech in these contexts is it different than offline content in terms of its impact and if so then how how can we devise and improve upon early warning mechanisms to prevent the escalation of conflict how can online tools and narratives be instead used to respond to violence constructive and promote understanding the answers to these questions can help civil society citizens and government to create more constructive policies and programs to help reduce the risk of violence
organizations like radio la benevolencija which helped rwandans to understand how hate speech enabled the genocide through radio soap operas can consider both how online spaces affect these risks and how they can be used to complement existing strategies
policy makers can consider responsible policies to monitor and regulate hate speech and violent speech in online spaces without infringing on civil rights
community leaders in online and offline spaces can create better strategies for responding to and leveraging social media tools narratives and strategies
in future the goal of improved text conceptualization can be achieved through improvement of the automated methods
topic modelling by mrf markov random field lda xie yang xing which defines a mrf on the latent topic layer of lda can create a better chance for similar words to appear in the same topic
we can also apply non negative matrix factorization and compare the resulting topics with lda s
also nmi and topic coherence together would help improve the quality of topic modelling since they enable us to evaluate different model from both overall and topic specific point of view
for example when comparing nmf and regular lda we can input the same topic number and try to find out which model get higher nmi and topic coherence values
when comparing regular lda and improved lda we can also apply nmi and topic coherence under the same lda parameters topic number
references aletras n
baldwin t
lau j
stevenson m
evaluating topic representations for exploring document collections journal of the association for information science and technology blei d
m
ng a
y
jordan m
i
latent dirichlet allocation
journal of machine learning research
chen z
b
liu topic modeling using topics from many domains lifelong learning and big data proceedings of the international conference on machine learning
eisenstein j
what to do about bad language on the internet hlt lau j
h
newman d
karimi s
baldwin t

best topic word selection for topic labelling
in proceedings of the international conference on computational linguistics coling pp

lee d
and h
sebastian seung
algorithms for non negative matrix factorization
advances in neural information processing systems

matwin s
institute for big data analytics message from the director
cs
dal
ca about retrieved july
mehrotra r
s
sanner w
buntine l
xie improving lda topic models for microblogs via tweet pooling and automatic labeling proceedings of the international acm sigir conference on research and development in information retrieval
nugroho r
d
molla aliod j
yang y
zhong c
paris and s
nepal incorporating tweet relationships into topic derivation proceedings of the conference of the pacific association for computational linguistics pacling
ramisch j
j
misiko m
t
ekise i
e
mukalama j
b
strengthening folk ecology community based learning for integrated soil fertility management western kenya
international journal of agricultural sustainability taylor francis si j
a
mukherjee b
liu q
li h
li x
deng exploiting topic based twitter sentiment for stock prediction emnlp pp
sokolova m
and g
lapalme a systematic analysis of performance measures for classification tasks information processing management p
stevens k
p
kegelmeyer d
andrzejewski d
buttler exploring topic coherence over many models and many topics proceedings of the joint conference on empirical methods in natural language processing and computational natural language learning pp


tonkin e
pfeiffer h
d
and tourte g
twitter information sharing and the london riots
bul
am
soc
info
sci
tech

tuytelaars t
lampert c
h
blaschko m
b
buntine w

unsupervised object discovery international journal of computer vision
yan x
j
guo s
liu x
cheng y
wang learning topics in short texts by non negative matrix factorization on term correlation matrix proceedings of the siam international conference on data mining xie p
d
yang e
xing incorporating word correlation knowledge into topic modeling conference of the north american chapter of the association for computational linguistics zhao x
j
jiang an empirical comparison of topics in twitter and traditional media singapore management university school of information systems technical paper series
retrieved november
