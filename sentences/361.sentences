bengali abstractive news summarization bans a neural attention approach prithwiraj avi md saiful and marium e department of computer science and engineering shahjalal university of science and technology bangladesh
sust
edu
com saiful cse jannat
edu abstract abstractive summarization is the process of generating novel sentences based on the information extracted from the original text ument while retaining the context
due to abstractive summarization s underlying complexities most of the past research work has been done on the extractive summarization approach
nevertheless with the umph of the sequence to sequence model abstractive rization becomes more viable
although a significant number of notable research has been done in the english language based on abstractive summarization only a couple of works have been done on bengali stractive news summarization bans
in this article we presented a based long short term memory lstm network model with attention at encoder decoder
our proposed system deploys a local attention based model that produces a long sequence of words with cid and human like generated sentences with noteworthy information of the original document
we also prepared a dataset of more than articles and corresponding human written summaries collected from bangla

which is till now the most extensive dataset for bengali news document summarization and publicly published in
we evaluated our model qualitatively and quantitatively and pared it with other published results
it showed significant improvement in terms of human evaluation scores with state of the art approaches for bans
keywords attention abstractive summarization bleu rouge dataset lstm encoder deocder bengali
introduction text or document summarization is the process of transforming a long ment or documents into one or more short sentences which contain the key


kaggle
com prithwirajsust bengali news summarization dataset p
bhattacharjee et al
points and main contents
automatic summarization became vital in our daily life in order to minimize the effort and time for finding the condensed and vant delineation of an input document that captures the necessary information of that document
despite different ways to write the summary of a document the summarization can be categorized into two classes based on the content lection and organization extractive and abstractive approach
extractive summarization basically finds out the most important sentences from the text using features and grouped to produce the summary
it is like highlighting a text through a highlighter
in contrast abstractive summarization is a technique that generates new sentences instead of selecting the essential sentences of the original document that contain the most critical information
like a human ing writing a summary from his thinking with a pen
machine learning based summarizing tools are available nowadays
but the language specific models are hard to find
although a notable number of works have been done on bengali extractive marization only a few abstractive summarizations are available
the majority of the available works are based on the basic machine learning ml techniques and the dataset was too small
due to the lack of standard datasets no ca nt work is available on encoder decoder based summarization systems
so the most challenging part for bans is to prepare a standard and clean dataset
to build a bengali news summarization dataset a crawler has been made to crawl data from online resources like a daily newspaper
we have collected more than data from bangla

online portal
the dataset represents the article and its corresponding summary
in this paper a sequence to sequence lstm encoder decoder architecture with figure illustration of our neural attention model for abstractive rization of bengali news incorporates a set of lstm encoder decoder on top of a standard word embedding
attention has been presented for bengali abstractive news summarization
bengali abstractive news summarization bans ure illustrates the proposed model
the source code and other details of the model already uploaded to
then the dataset of size has also been prepared which is till now the largest one and published it in
the word embedding layer has been used to represent the words in numbers and fed them into the encoder
moreover both the encoder and decoder parts are ciated with some attention mechanisms
we got a notable improvement in terms of human assessment compared to other available bengali abstractive rization methods
we also evaluated rouge and bleu scores
in short our contribution to this work is threefold
they are preparation of till now the largest bengali news summarization dataset of size documents with its summary and published it in
presenting the encoder decoder architecture with the attention mechanism for bengali abstractive news in an efficient way
evaluation of the model both qualitatively and quantitatively and the sented approach outperforms bengali state of the art approaches
related work there are different kinds of abstractive text summarization approaches that ist
we found that yeasmin et al
have described the different techniques regarding abstractive approaches
then as we decided to focus on abstractive text summarization approaches on the bengali language context we covered haque et al
where approaches of bengali text summarization regarding both extractive and abstractive approaches are described
in islam et al
first introduced bengali extractive summarization based on document indexing and keyword based information retrieval
then techniques of english extractive text summarization were applied for bengali by uddin et al

in das et al
used theme identification page rank algorithms
for extractive marization
sentence ranking and stemming process based bengali extractive summarization were first proposed by a researcher named kamal sarkar and later in a better way by efat et al

haque et al
respectively proposed a key phrase based extractive approach and a pronoun replacement based sentence ranking approach
in the heuristic approach proposed by abujar et al
k means clustering method of akther et al
and lsa latent semantic analysis method stated in chowdhury et al
became popular techniques for bengali extractive rization
the graph based sentence scoring feature for bengali summarization was first used by ghosh et al

moreover sarkar et al
and ullah et al
proposed term frequency and cosine similarity based extractive approach respectively
recently munzir et al
instigated a deep neural network based bengali tractive summarization
again abujar et al
introduced based word embedding for bengali text summarization
then talukder et al

com bengali deep news summarization p
bhattacharjee et al
proposed an abstractive approach for bengali where bi directional rnns with lstm are used at the encoder and attention at the decoder
we also used lstm rnn based attention model like but we applied attention to both the encoder and the decoder layer and did some comparative study with the responding result part and dataset part with the existing one
another rnn based text generation process is introduced by abujar et al
for bengali abstractive text summarization
we used the concept stated in lopyrev et al
for our system
the model and the lstm encoder decoder architecture we used was introduced by sutskever et al
and bahdanau et al
respectively
again the decoder and encoder part s attention technique is the concept stated in luong et al
and rush et al
respectively
furthermore the lstm concept based guage parsing method has been adopted from vinyals et al

dataset a standard dataset is a vital part of text summarization
we gathered a ceptual idea of preparing a standard dataset from hermann et al
and also observed some of the existing public english datasets like cnn daily dataset
we need a vast amount of data for training but no significant dard public dataset is available for bengali summarization
so we collected table statistics of the dataset total no of articles total no of summaries maximum no of words in an article maximum no of words in a summary minimum no of words in an article minimum no of words in a summary news and its summary from the online news portal bangla

as it had both the article and its summary
we made a crawler and crawled news articles and their summaries from different categories like sports politics economics
online news contains lots of garbage like advertisements bengali words different websites links
so we started preprocessing by making a data cleaning program that eliminates all kinds of garbage from the dataset
we uploaded data crawling cleaning and analysis source and their working details to github and publicly published our dataset in
a tabular representation of our processed data is shown in table
the cance and comparison of our dataset with only publicly available bangla natural
nyu
kcho
com data manipulation bengali abstractive news summarization bans language processing community summarization dataset has been shown in table
table comparison of our standard dataset with bnlpc dataset source dataset our total articles no of summary per article total summaries model architecture by observing the significant performance of lstm encoder decoder with the attention mechanism described in lopyrev et al
we ve used a similar ral attention model architecture
it has an lstm encoder part and an lstm decoder part
both of the parts are associated with some attention nisms
tensorflow s embedding layer has been used to represent the words in numbers to feed into encoders
after generating the decoder s output a comparison between the actual and predicted summary has been done using the softmax loss function and for minimizing the loss the network started back propagating
lastly a summary has been generated with minimal loss
the whole process works as a approach and can be alized by figure
let s describe the major two components of our model
firstly an input sequence is encoded to numbers via word embedding layer and fed into the lstm encoder in reverse order
sutskever et al
proposed that because of calculating short term dependencies the first few words of both the input sequence and output sequence must be closer to each other and it can be achieved by feeding input in reverse order and thus the result can be significant
that means bengali sentence like is fed into each encoder cell reversely as individual word and respectively
attention is also used to the encoder part as mentioned by rush et al

secondly we used a greedy lstm decoder which is different from a beam search decoder
firstly encoder output is fed into the first decoder cell
then the put of the current decoder cell is fed into the next decoder cell along with the attention as well as the information from the previous decoder cell and ued the process till the last decoder cell
that means if the first generated word in the decoder cell is then this word will help to predict the next word suppose for the next decoder cell combining with attention and ued the process till the end
the decoder attention mechanism is implemented as stated in
before training we made a vocabulary of the most frequent words both from
bnlpc
org research
php p
bhattacharjee et al
articles and summaries
the out of vocabulary words are denoted by unk ken
pad token is used for padding the article and its summary to the bucket sizes
a bucket is nothing but an array where we define how many words an article and its summary can hold while training
we used five encoder decoder lstm models for training
now the trained model also padded the words of the given input sentences to the bucket sizes
so the model can well summarize the articles containing the number of words in all sentences equal to the largest bucket size and in our case it was for article and summary respectively
result and discussion we assessed our model based on two types of evaluation matrices for analyzing the result they are quantitative evaluation and qualitative evaluation
both of the evaluation methods are mandatory for checking how much the mary system is suitable for generating a summary
of our data was used for training for validating and was used for testing
the system was trained three times with different parameter specifications
after the evaluation we found that the system has the best output when the vocabulary size was set to hidden unit to learning rate to
and steps per checkpoint to
table shows some generated examples of our best model
we showed two good quality as well as two poor quality predictions in table from our system
here the first two predictions are well summarised by our model and sometimes the new word has also been generated like in the second ample
on the other hand from the last two predictions on the table we found that repetition of words like in the third example and in the fourth example occurred twice
further from the third example we can see inaccurate reproduction of factual details
that means word has been produced by the model rather than predicting the word in the fourth example
moreover due to bucketing issues some summaries are forcefully stopped before hitting the end token of the sentence which can be shown in third predictions on table

quantitative evaluation quantitative evaluation is a system oriented evaluation
in this evaluation cess both the actual and predicted summaries are given as input to a gram and the program generates a score comparing how much the predicted summary deviates from the actual summary
we found that recall oriented understudy for gisting evaluation rouge and bilingual evaluation derstudy bleu are two standard quantitative evaluation matrices
as far as our knowledge quantitative evaluation of the existing bengali abstractive text summarization techniques is not mentioned or publicly available
so we could not compare our evaluation with them
but as per standard scoring tioned in the papers our achieved score was also significant
there are bengali abstractive news summarization bans table illustrates some predictions of our bans system showing the input news article actual summary and bans predicted summary


e r o c s e v i a t i n a u q



rouge l bleu figure illustrates the quantitative analysis of our proposed model based on rouge l and bleu scores new articleactual summarypredicted summarybengali english the miscreants set fire to a bus in steel mill area of chittagong city during the strike and blockade of the bnp alliance
bengali english fire on bus in chittagong
bengali fire on the buses of chittagongbengali english two children drowned at melandho in jamalpur
bengali two children drowned in jamalpurbengali the child drowned in the pondbengali english truck driver zahid ahmed died in a hospital after eight days being burnt by a petrol bomb in a blockade at polash in narsingdi
bengali truck driver killed in bomb blast in narsingdibengali more death from burns burns in the siegebengali english the body of a young man who went missing after falling into the river at thakurgaon sadar has been recovered
bengali english the dead body of a missing young boy was recovered in thakurgaon
bengali english the dead body dead bodyof a missing young boy was recovered in kushtia p
bhattacharjee et al
different variants of rouge calculation exist
l rouge n are some of them
here we computed the most adapted rouge l and measured the bleu score as well
firstly we took generated summaries and corresponding actual summaries and calculated the average bleu score
again for rouge calculation we first calculated the precision and recall
then using these two measurements calculated the average score for that examples
the bar diagram of figure denotes rouge and bleu scores of the best model

qualitative evaluation qualitative evaluation is the user oriented evaluation process
here some users of different ages take part in rating the generated summary on a scale of compared with the actual one
for the qualitative evaluation we took some examples from our system and some from the existing one
as far as our table qualitative evaluation of existing system and the proposed system system proposed system existing system average of

knowledge qualitative evaluation of the existing method is not publicly available
so for comparison we also had to calculate the rating for
we provided the examples of both the systems to the users via a google survey
a total of users participated in a rating on a scale of
among the users were female and were male
moreover all the users were from the educational background with an average age of
again were from linguistic faculty were from engineering faculty and were from other faculties
we calculated the average rating regarding each of the models and found that our system outperforms the existing system based on human assessment
the qualitative rating of the systems is shown in table
conclusion to recapitulate the development of the standard summarization dataset of bengali news has been one of our pioneering accomplishments cially since it is the largest publicly published dataset in this field
here a neural attention based encoder decoder model for abstractive summarization of bengali news has been presented which generates human like sentences with core mation of the original documents
along with that a large scale experiment was
gle bengali abstractive news summarization bans conducted to investigate the effectiveness of the proposed bans
from the itative evaluation we have found that the proposed system generates more manoid output than all other existing bans
indeed the lstm based decoder has been exceptionally successful nonetheless the model s performance can deteriorate quickly for long input sequences
repetition of summaries and inaccurate reproduction of factual details are two significant problems
to fix these issues we plan to drive our efforts on modeling hierarchical encoder based on structural attention or pointer generator architecture and developing ods for multi document summarization
acknowledgements we would like to thank shahjalal university of science and technology sust research center and sust nlp research group for their support
references
yeasmin s
tumpa p
b
nitu a
m
uddin m
p
ali e
afjal m
i
study of abstractive text summarization techniques
american journal of engineering research
haque m
m
pervin s
hossain a
begum z
approaches and trends of tomatic bangla text summarization challenges and opportunities
international journal of technology diffusion ijtd
islam m
t
al masum s
m
bhasa a corpus based information retrieval and summariser for bengali text
in proceedings of the international conference on computer and information technology
uddin m
n
khan s
a
a study on text summarization techniques and ment few of them for bangla language
in international conference on computer and information technology
pp

ieee
das a
bandyopadhyay s
topic based bengali opinion summarization
in ing posters
pp

sarkar k
bengali text summarization by sentence extraction
arxiv preprint

efat m
i
a
ibrahim m
kayesh h
automated bangla text summarization by sentence scoring and ranking
in international conference on informatics electronics and vision iciev
pp

ieee
haque m
m
pervin s
begum z
enhancement of keyphrase based approach of automatic bangla text summarization
in ieee region conference tencon
pp

ieee
haque m
pervin s
begum z
al
an innovative approach of bangla text summarization by introducing pronoun replacement and improved sentence ing
journal of information processing systems
abujar s
hasan m
shahin m
hossain s
a
a heuristic approach of text summarization for bengali documentation
in international conference on computing communication and networking technologies icccnt
pp

ieee
akter s
asa a
s
uddin m
p
hossain m
d
roy s
k
afjal m
i
an extractive text summarization technique for bengali document s using k means clustering algorithm
in ieee international conference on imaging vision pattern recognition icivpr
pp

ieee p
bhattacharjee et al

chowdhury s
r
sarkar k
dam s
an approach to generic bengali text marization using latent semantic analysis
in international conference on information technology icit
pp

ieee
ghosh p
p
shahariar r
khan m
a
h
a rule based extractive text rization technique for bangla news documents
international journal of modern education and computer science
sarkar a
hossen m
s
automatic bangla text summarization using term quency and semantic similarity approach
in international conference of computer and information technology iccit
pp

ieee
ullah s
hossain s
hasan k
a
opinion summarization of bangla texts using cosine simillarity based graph ranking and relevance based approach
in international conference on bangla speech and language processing icbslp
pp

ieee
al munzir a
rahman m
l
abujar s
hossain s
a
al
text analysis for bengali text summarization using deep learning
in international ference on computing communication and networking technologies icccnt
pp

ieee
abujar s
masum a
k
m
mohibullah m
hossain s
a
al
an approach for bengali text summarization using
in international ference on computing communication and networking technologies icccnt
pp

ieee
talukder m
a
i
abujar s
masum a
k
m
faisal f
hossain s
a
bengali abstractive text summarization using sequence to sequence rnns
in international conference on computing communication and networking nologies icccnt
pp

ieee
abujar s
masum a
k
m
islam m
s
faisal f
hossain s
a
a bengali text generation approach in context of abstractive text summarization using rnn
in innovations in computer science and engineering pp

springer
lopyrev k
generating news headlines with recurrent neural networks
arxiv preprint

sutskever i
vinyals o
le q
v
sequence to sequence learning with neural networks
in advances in neural information processing systems
pp

bahdanau d
cho k
bengio y
neural machine translation by jointly learning to align and translate
arxiv preprint

luong m
t
pham h
manning c
d
effective approaches to attention based neural machine translation
arxiv preprint

rush a
m
chopra s
weston j
a neural attention model for abstractive sentence summarization
arxiv preprint

vinyals o
kaiser
koo t
petrov s
sutskever i
hinton g
grammar as a foreign language
in advances in neural information processing systems
pp

hermann k
m
kocisky t
grefenstette e
espeholt l
kay w
suleyman m
blunsom p
teaching machines to read and comprehend
in advances in neural information processing systems
pp

lin c
y
rouge a package for automatic evaluation of summaries
in text summarization branches out
pp

pastra k
saggion h
colouring summaries bleu
in proceedings of the eacl workshop on evaluation initiatives in natural language processing are evaluation methods metrics and resources reusable pp

