relabeling and summarizing posterior distributions in signal decomposition problems when the number of components is unknown alireza roodaki julien bect and gilles fleury n a j o c
t a t s v
v i x r a abstract this paper addresses the problems of relabeling and summarizing posterior distributions that typically arise in a bayesian framework when dealing with signal tion problems with an unknown number of components
such posterior distributions are dened over union of subspaces of differing dimensionality and can be sampled from using modern monte carlo techniques for instance the increasingly popular rj mcmc method
no generic approach is available however to summarize the resulting variable dimensional samples and extract from them component specic parameters
we propose a novel approach named variable dimensional approximate posterior for relabeling and summarizing vapors to this problem which consists in approximating the rior distribution of interest by a simplebut still dimensional parametric distribution
the distance between the two distributions is measured using the kullback leibler vergence and a stochastic em type algorithm driven by the rj mcmc sampler is proposed to estimate the parameters
two signal decomposition problems are considered to show the capability of vapors both for relabeling and for summarizing variable dimensional posterior distributions the classical lem of detecting and estimating sinusoids in white gaussian noise on the one hand and a particle counting problem motivated by the pierre auger project in astrophysics on the other hand
index terms bayesian inference signal decomposition trans dimensional mcmc label switching stochastic em
i
introduction nowadays owing to the advent of markov chain monte carlo mcmc sampling methods bayesian data ysis is considered as a conventional approach in machine ing signal and image processing and data mining problems to name but a few
nevertheless in many applications tical challenges remain in the process of extracting from the generated samples quantities of interest to summarize the posterior distribution
summarization consists loosely speaking in providing a few simple yet interpretable parameters graphics to the end user of a statistical method
for instance in the case of a scalar parameter with a unimodal posterior distribution measures of location and dispersion e

the empirical mean and the standard deviation or the median and the tile range are typically provided in addition to a graphical alireza roodaki is with ltci cnrs tlcom paristech paris france
email al

com
julien bect and gilles fleury are with supelec systems sciences department of signal processing and electronic systems supelec gif yvette france
email rstname

fr the results presented here are also part of the ph
d
thesis of the rst author
summary of the distribution e

a histogram or a kernel density estimate
in the case of multimodal distributions summarization becomes more difcult but can be carried out using for instance the approximation of the posterior by a gaussian mixture model gmm
summarizing or approximating posterior distributions has also been used in designing proposal distributions of metropolis hastings mh samplers in an adaptive mcmc framework see e


this paper addresses the problem of summarizing posterior distributions in the case of some trans dimensional problems i
e
problems in which the number of things that we do nt know is one of the things that we do nt know
more specically we concentrate on the problem of signal position when the number of components is unknown which is an important case of trans dimensional problem
examples of such problems include the detection and estimation of sinusoids in white gaussian noise and the related problem of estimating directions of arrival in array processing the detection of objects in images and the detection of physical particles neutrons muons


using noisy data from various types of sensors for instance in spectroscopy or astrophysics
let y


be a vector of n observations where the superscript t stands for vector transposition
in signal decomposition problems the model space is a nite or countable set of models m mk k k where k denotes the number of components and k n the set of its possible values
it is assumed here that under mk there are components with vectors of component specic parameters qqq qqq


qqq k q
one feature that the problems we are considering have in common is the invariance of the likelihood y k qqq with respect to permutations relabeling of the components which is called the label switching issue in the literature see e


we will discuss this issue further in section i a
k where q rd and q in a bayesian framework a joint posterior density k qqq p k qqq y is obtained through bayes formula for the number of components and the vector of specic parameters after assigning prior distributions on them k qqq p y k qqq k p qqq p k where a variable dimensional space q of differing dimensionality i
e
q indicates proportionality
this density is dened over which is a union of subspaces q q
the posterior density completely describes the tion and the associated uncertainty provided by the data q q q psfrag replacements

















k


about the candidate models and the vector of unknown rameters
since it is only known up to a normalizing constant in most cases monte carlo simulation methods such as the reversible jump mcmc rj mcmc sampler have been widely used to approximate it
a
the label switching issue one of the most challenging issues when attempting at summarizing posterior distributions that even occurs in dimensional situations is the label switching phenomenon see e

which is caused by the invariance of both the likelihood and the prior distribution under permutations of the components
as a consequence the component specic marginal posterior distributions are all equal and therefore useless for the purpose of summarizing the information tained in the posterior distribution about individual nents
the simplest way of dealing with the label switching issue is to introduce an identiability constraint ic such as sorting the components with respect to one of their parameters see for more discussion concerning the use of ics in the problem of bayesian analysis of gmm
however in most practical examples choosing an appropriate ic manually is not feasible
many relabeling algorithms have therefore been developed to undo the label switching effect automatically but all of them are restricted to the case of xed dimensional posterior distributions see for recent advances and references
in variable dimensional posterior distributions there is an extra uncertainty about the presence of components in dition to their location
this challenging problem has hindered previous attempts to undo label switching in the dimensional scenario where according to the meaning of individual components is vacuous
this argument will be claried in the following illustrative example
b
illustrative example joint bayesian detection and tion of sinusoids in white gaussian noise in this example it is assumed that under mk the observed signal y is composed of k sinusoidal components observed in white gaussian noise
that is under mk ac ji as j ji k where ac and as j are the cosine and sine amplitudes and w j is the radial frequency of the jth sinusoidal component
moreover n is a white gaussian noise of variance s
j ac as w the unknown parameters are the number k of sinusoidal components the vectors qqq j of specic parameters j k and the noise variance s
thus q p and q
we use the hierarchical model prior distributions and the rj mcmc sampler proposed in for this problem the interested reader is thus referred to for more
q q k fact the birth or death moves acceptance ratio provided in the seminal paper is erroneous
see chapter or for justication and true expression of the acceptance ratio which is used in this paper


y

w figure posterior distributions of k left and sorted radial cies www given k right from output rj mcmc samples
the true number of components is three
the vertical dashed lines in the right gure locate the true radial frequencies
figure represents the posterior distributions of both the number of components and the sorted radial cies www w


w given k obtained using ples generated by the rj mcmc sampler
note that here we used sorting to mitigate the effect of label switching for ization
each row is dedicated to one value of k for k
observe that other models have negligible posterior ties since k y

in the experiment the served signal of length n consists of three sinusoids with energies
where a j c j s j phases fff k p p where j j ac j and true radial frequencies www



the snr t and kd d is the n design matrix of sines and cosines associated to www is set to the moderate value of db



ac as where ns roughly speaking two approaches co exist in the literature for summarizing variable dimensional posterior distributions bayesian model selection bms and bayesian model aging bma
the bms approach ranks models according to their posterior probabilities y selects one model denoted by k map here where map stands for maximum a riori and then summarizes the posterior distribution of the component specic parameters under the xed dimensional selected model
this is at the price of losing valuable tion provided by the other discarded models
for instance in the example of figure all information about the small and therefore harder to detect middle component is lost by selecting the most a posteriori probable model
on the other hand the bma approach consists in reporting results that are averaged over all possible models
although the bma approach is suitable for signal reconstruction and prediction purposes see e

and references therein it is not appropriate for studying component specic parameters the q number of which changes in each
more information concerning these two approaches can be found in and references therein
to the best of our knowledge no generic method is currently available that would allow to summarize the information that is so easily read on figure for this very simple example namely that there seem to be three sinusoidal components in the observed noisy signal the middle one having a smaller probability of presence than the others
c
outline of the paper in this paper we propose a novel approach named dimensional approximate posterior for relabeling and marizing vapors for relabeling and summarizing posterior distributions dened over variable dimensional subspaces that typically arise in signal decomposition problems when the number of components is unknown
it consists in mating the true posterior distribution with a parametric model of varying dimensionality by minimization of the leibler kl divergence between the two distributions
a stochastic expectation maximization algorithm driven by the output of an rj mcmc sampler is used to estimate the parameters of the approximate model
vapors shares some similarities with the relabeling rithms proposed in to solve the label switching problem and also with the em type algorithm used in in the context of adaptive mcmc algorithms both in a dimensional setting
the main contribution of this paper is the introduction of an original variable dimensional parametric model which allows to tackle directly the difcult problem of approximating a distribution dened over a union of subspaces of differing dimensionality and thus provides a rst solution to the trans dimensional label switching problem so to speak
perhaps the algorithm that we propose can be seen as a realization of the idea that m
stephens had in mind when he stated page this raises the question of whether we might be able to obtain an alternative view of the variable dimensional rior by combining the results for all different k and grouping together components which are similar in that they have similar predictive density estimates
however attempts to do this have failed to produce an easily interpretable results
the paper is organized as follows
section ii introduces the proposed model and stochastic algorithm for relabeling and summarizing variable dimensional posterior distributions
section iii illustrates the performance of vapors using two signal decomposition examples namely the problem of joint bayesian detection and estimation of sinusoids in white sian noise and the problem of joint bayesian detection and estimation of particles in the auger project in astrophysics
section iv conrms the performances of vapors using a monte carlo experiment
finally section v concludes the paper and gives directions for future work
ii
vapors we assume that the target posterior distribution dened on the variable dimensional space q k admits a probability density function pdf with respect to the dimensional lebesgue measure on each q kk q k k k
q s our objective is to approximate the true posterior density using a simple parametric model qhhh where hhh is the vector of parameters dening the model
the pdf qhhh will also be dened on the variable dimensional space q i
e
it is not a xed dimensional approximation as in the bms approach
we assume that a monte carlo sampling method e

an rj mcmc sampler available to generate m ples from f which we denote by qqq i for i


m
qqq i a
variable dimensional parametric model instead of trying to describe the proposed parametric family of densities qh directly let us now adopt a generative point of view i
e
valued random variable qqq k qqq from the corresponding probability distribution
we assume that a positive integer l is given which represents the number of components present in the posterior
let us describe how to sample an q first we generate independently for each of the l ponents a binary indicator variable drawn from the bernoulli distribution l where l indicates that the corresponding component is present otherwise it is absent in qqq
the actual number of components in the l
the parameter erated samples is thus dened as k l p l will be called the probability of presence of the lth component
second given the vector of indicator variables xxx


l a q random vector is generated for each component that is present i
e
for each l such that l
this random vector is generated according to some probability distribution associated to the component that will be assumed to be a q dimensional gaussian distribution with mean mmm l and covariance matrix s in this
in order to achieve the required invariance with respect to component relabeling the generated vectors are arranged in a vector qqq qqq


qqq k
l contemplating the posterior distributions of the sorted radial frequencies depicted in the right panel of figure particularly the plots related to the models with three and four sinusoidal components it can be observed that there are diffuse parts in the rj mcmc output samples resulting in the heavy metric tails of some components
it is clear that a model made of gaussian components only is not capable of describing these diffuse samples at least not in a parsimonious way
these abnormal observations with respect to the bulk of the observed data or simply outliers can adversely inuence the that any dimensional parametric family of distributions could be used at this point
as often in the literature the gaussian distribution is chosen here as a convenient mean of describing a compact and unimodal dimensional distribution nothing more
however the intensity plot provided in section iii figure as an precisely a permutation of the k components that are present is example of a bma summary related to a component specic parameter
drawn uniformly in the set of all permutations
q q q q q s s l p l mmm l l l l qqq figure proposed variable dimensional parametric model generative viewpoint
in a process of tting the approximate posterior to the true posterior distribution of interest and consequently lead to meaningless parameter estimates
to overcome this robustness issue we propose to include in the model a noise like poisson point process ppp see e

to account for the presence of outliers in the observed samples
we assume that the ppp is on q with intensity l
the number of components generated by the ppp thus follows a poisson distribution with mean l
to be consistent with our previous notations we denote by n this number note that


l still take their values in
the extended vector xxx thus follows the probability distribution p xxx ppp l el l l p l l p l
given xxx random samples are generated uniformly on q and inserted randomly among the samples drawn from the gaussian components
we denote by qhhh the pdf of the random variable qqq k qqq that is thus generated with l mmm l l and hhh hhh hhh l p l
figure provides the directed acyclic graph of the model



hhh l s b
distribution of the labeled samples a random variable qqq k qqq


qqq drawn from the density qhhh can be thought of as an unlabeled sample since l l


l of the component from the label which each qqq j j k originates can not be recovered from qqq itself
let us now introduce the variable dimensional allocation vector k


zk l k kk which provides the missing piece of information l indicates that qqq j originates from the lth gaussian component if l l while z l indicates that qqq j originates from the point process component
we will refer to the pair qqq z as a labeled sample
in the following we will derive its joint distribution qhhh qqq z qhhh qqq
the distribution of the allocation vector z is qhhh xxx xxx where qhhh xxx is given in
note that xxx is a deterministic function of with j l for l l
to compute the rst term of remember that the points generated by the components of the parametric model are randomly arranged in qqq
therefore for all n such that l k qhhh xxx since two arrangements that differ only by the position of the points corresponding to the ppp give rise to the same allocation vector
the conditional distribution qhhh qqq z reads qhhh qqq z qhhh qqq j z j k where qhhh qqq j z j mmm s qqq n if z l if z l
therefore from equations to we have qhhh qqq z l el jk z j l l p l l p n qqq j mmm s z z where


and z is the set of all allocation vectors i
e
the set of all z kk l k such that l for l l
c
estimating the model parameters we propose to t the parametric distribution qhhh to the posterior of interest by minimizing a divergence measure to qhhh
we use the kl divergence as a divergence from f measure in this paper though other divergence measures can be used as
denoting the kl divergence by dkl qqq kqhhh qqq we dene the criterion to be minimized as from to qhhh j hhh dkl qqq k qhhh qqq qqq log zq qqq qqq dqqq
using samples generated by the rj mcmc sampler criterion can be approximated as this j hhh m m log qhhh qqq i c is assumed here for the sake of simplicity but more elaborate non homogeneous models are easily accommodated by our approach if needed
chapter where another divergence measure proposed by has been used for this problem for robustness reasons
s s s s s s s s s q q at the r iteration do s step draw allocation vectors i m using an imh step with target q hhh r qqq i
e step construct the pseudo completed log likelihood m qhhh qqq i log
m step estimate hhh such that hhh argminhhh
figure proposed sem type algorithm where c is a constant that does not depend on hhh note that minimizing j hhh amounts to choosing
one should hhh argmaxhhh m log qhhh qqq i
to estimate the model parameters hhh n one of the extensively used algorithms for maximum likelihood ml parameter estimation in latent variable models is the em algorithm proposed by
however it turns out that the em algorithm which has been used in similar works is not appropriate for solving this problem as computing the expectation in the e step is intricate
more explicitly in our problem the computational burden of the summation in the e step over the set of all possible allocation vectors increases very rapidly with both l and k
in fact even for moderate values of l and k say l and k the summation is far too expensive to compute as it involves l
terms
in this paper we propose to use the sem algorithm a variation of the em algorithm in which the e step is substituted with stochastic simulation of the latent variables from their conditional posterior distributions given the vious estimates of the unknown parameters
in other words at the iteration r of the sem algorithm denoting the estimated parameters at iteration r by hhh r for i


m the allocation vectors are drawn from q hhh r qqq i
this step is called the stochastic
then these random samples are used to construct the so called pseudo completed log likelihood
exact sampling from q hhh r qqq i as required by the s step of the sem type algorithm is unfortunately not feasible not even using the accept reject algorithm due to the heavily binatorial expression of the normalizing constant q hhh r qqq i
instead since q hhh r qqq i q hhh r qqq i it would also be possible to assign prior remark
tributions over the unknown parameters hhh and study their posterior distributions for example using an mcmc sampler with the latent variable z added to the state of the chain in the spirit of the data augmentation algorithm
this would however leave the label switching issue unsolved because of the invariance of qhhh to permutations of its components
remark
convergence results of the sem algorithm in the general form are provided by and in the particular example of mixture analysis problems by
unfortunately the assumptions in do not hold in the problem we are dealing with as the observed samples qqq i are correlated owing to the fact that they are generated from the true posterior distribution using some mcmc methods e

the rj mcmc sampler an i mh sampler is used to draw from the conditional posterior distribution
nevertheless empirical evidence of the good convergence properties of the type algorithm we proposed will be provided in the next two sections
d
robustied algorithm preliminary experiments with the sem type algorithm scribed in figure were not satisfactory because the sample mean and estimates in the m step obtained from minimizing the kl divergence from the posterior tion to the parametric model qhhh still suffer from sensitivity to the outliers in the observed samples even after including the poisson point process component
as a workaround we propose to use robust estimates of the means and of gaussian distributions instead of the empirical means and in the m step
for example in the case of univariate gaussian distributions one can use the median and the interquartile range as robust estimators of the mean and variance respectively
see section
for more discussion of the robustness issue including an alternative solution using the robust divergence of
remark
similar robustness concerns are widespread in the clustering literature see e

and references therein
iii
illustrative examples in this section we will investigate the capability of vapors for summarizing variable dimensional posterior distributions using two signal decomposition examples joint bayesian detection and estimation of sinusoids in white gaussian noise and joint bayesian detection and estimation of astrophysical particles in the auger project see chapters and for more results and discussion
we phasize again that the output of the trans dimensional monte carlo sampler e
g the
rj mcmc sampler in this paper is considered as the observed data for vapors
can be computed up to a normalizing constant we choose to use an independent metropolis hasting imh step with q hhh r qqq i as its stationary distribution see rithm
for more details
the proposed sem type algorithm is summarized in figure
a
joint bayesian detection and estimation of sinusoids in white gaussian noise let us consider the problem of detection and estimation of sinusoidal components introduced in section i b where psfrag replacements
















psfrag replacements m p l

jm gaussian comp
m
s
p
gaussian comp
m
s
p


gaussian comp
m
s
p


point process comp
l
y t i s n e t n i sem iteration figure evolution of the model parameters along with the jm dened in using iterations of vapors with l rion on the rj mcmc output samples shown in figure
the unknown parameters are the number of components the component specic parameters ac j as w j j k and the noise variance s
since the amplitudes and the noise variance can be analytically integrated out we focus on summarizing the joint posterior distribution www y of the form illustrated in figure
therefore we assume that the proposed parametric model introduced in section ii a consists of univariate gaussian components with means m l l and probabilities of presence p l l l variances to be estimated
moreover the space of component specic parameters is q p r
before launching vapors we need rst to initialize the parametric model
it is natural to deduce the number l of gaussian components from the posterior distribution of k
here we set it to the percentile of y to keep all the probable models in the play
to initialize the gaussian nents parameters i
e
m l and l l l we used the robust estimates of the means and variances of the marginal posterior distributions of the sorted radial frequencies given k l
finally we set p l
for l l and l

we ran the robustied stochastic algorithm introduced in section ii on the specic example shown in figure for iterations with l gaussian components note that the posterior probability of k is approximately

to assess the convergence of vapors figure illustrates the evolution of the model parameters hhh together with the criterion j
two substantial facts showing the convergence of vapors can be deduced from this gure rst the decreasing jm which is almost constant after behavior of the criterion the iteration the convergence of the parameters of the parametric model particularly the means m l and bilities of presence p l l l even though we used a naive initialization procedure
indeed after the iteration there is no signicant move in the parameter estimates


w w figure histogram of the labeled samples that is the samples allocated to the gaussian and poisson point process components the pdf of estimated gaussian components in the model black solid line using vapors on the sinusoid detection example
the estimated parameters of each component are presented in the corresponding panel
a trans dimensional setting
figures shows the histograms of the labeled samples i
e
qqq i with i


m along with the pdf of the estimated gaussian components black solid line
moreover the summaries provided by vapors for each component are presented in its corresponding panel
we used the average of the last sem iterations as parameter estimates as recommended in the sem literature see for example
comparing the distributions of the labeled samples with the ones of the posterior distributions of the sorted radial frequencies given shown in figure which are highly multimodal reveals the capability of vapors in solving label switching in a variable dimensional setting
looking at the bottom right panel of figure the role of the point process component in capturing the outliers in the observed samples which can not be described by the gaussian components becomes clearer
note that without the point process component these outliers would be allocated to the gaussian components and would consequently induce a signicant deterioration of the parameter estimates
table i presents the summaries provided using vapors along with the ones obtained using the bms approach
trary to the bms approach vapors has enabled us to benet from the information of all probable models to give summaries about the middle harder to detect component
turning to the results of vapors it can be seen that the estimated means are compatible with the true radial frequencies
furthermore the estimated probabilities of presence are consistent with certainty of them in the variable dimensional posterior shown in figure
as discussed in section i one of the main objectives of the algorithm we proposed is to solve the label switching issue in to observe better the goodness of the estimated gaussian components the bottom panel of figure depicts psfrag replacements


























k
psfrag replacements








y t i s n e t n i
comp
m


s


p

m bms

sbms

psfrag replacements table i summaries of the variable dimensional posterior distribution shown in figure vs
the bms approach


w figure posterior distribution of the sorted radial frequencies www given k top and normalized pdf of the tted gaussian components bottom
their normalized under the posterior distributions of the sorted radial frequencies given
this gure can be used to validate the coherency of the estimated summaries with the information in the variable dimensional posterior distribution
it can be seen from the gures that the shape of the pdf of the estimated gaussian components are coherent in both the location and dispersion with the ones of the posterior of the sorted radial frequencies
it is also useful for validating the estimated summaries to compare the intensity of the estimated parametric model qhhh dened in general as p n mmm l s l l where we ignore the point process component with the histogram intensity of all radial frequencies obtained using the bma approach see chapter for more information
figure shows such a gure for the specic example of this section where the solid black line indicates the intensity of the estimated parametric model
these gures also indicate the goodness of the tted approximate posterior and the true one
finally to validate both the estimated probabilities of ence of the gaussian components and the mean parameter l of the poisson point process component figure illustrates the posterior distribution of the number of components together with its approximated versions using vapors
it can be seen from the gure that vapors well captured the information provided in the true posterior of the number of components
obtain the normalized densities rst we normalized the estimated pdf s to have their maximum equal to one
then we multiplied the estimated probability of presence of each gaussian component to its corresponding normalized estimated pdf
thus the maximum of each normalized density is equal to the corresponding estimated probability of presence


w figure histogram intensity of all radial frequencies samples using
the bma approach along with the intensity of the tted parametric
model obtained using vapors





y t i
l i b a
b o r p


k figure posterior distribution of the number of number of components black and its approximated version gray obtained from the tted model
b
joint bayesian detection and estimation of astrophysical particles in the auger project as the second illustrative example we show results on a signal decomposition problem encountered in the international astrophysics collaboration called auger
the auger project is aimed at studying ultra high energy cosmic rays with energies in order of the most energetic particles found so far in the universe
the long term objective of this project is to study the nature of those ultra high energy cles and determine their origin in the universe
nevertheless they are not observed directly
in fact when they collide the earth s atmosphere a host of secondary particles are generated some of which mostly muons nally reach the ground
to detect them the pierre auger cosmic ray observatory was built which consists of two independent detectors an array of surface detectors sd and a number of fluorescence detectors fd
the number of muons and their arrival times can be used as indications of both the chemical composition and the origin of the primary particles see for more information
here we concentrate on the signal decomposition problem where the goal is to count the number of muons and estimate their individual parameters from the signals observed by sd detectors
to show results we use the bayesian algorithm and the rj mcmc sampler developed in for the trans dimensional problem of joint detection and estimation of s s figure top observed signal n
bottom intensity of the model aaam ttt dened in
there are k muons in the signal with the true arrival times i
e
ttt m indicated by vertical dashed lines
psfrag replacements

















e p y t i s n e t n i










psfrag replacements muons
in this section we rst briey describe the problem and then use vapors to relabel and summarize dimensional output samples of the rj mcmc sampler oped by
when a muon crosses a sd tank it generates photoelectrons pe along its track that are then captured by detectors and create a discrete observed signal
we denote the vector of observed signal by n


nn nn where the element ni indicates the number of pe deposited by the muons in the time interval ti i itd where is the absolute starting time of the signal and td ns is the signal resolution length of one bin
each muon has two component specic parameters namely the arrival time tm and the signal amplitude am
the absorption process of the photons generated by a muon is modeled by a non homogeneous poisson point process with intensity section
am tm am pt td t tm where pt td t is the time response distribution td is the time and t is the exponential decay both measured in ns see figure bottom for such exponential shape intensities
then the expected number of pe in the bin i is obtained by integrating the intensity in the corresponding bin tm am pt td t tm
conditioning on the number of muons and the vector of parameters ttt m tm


tm k and aaam am


am k and assuming that the number of pe in each bin are independent the likelihood is written as k ttt m aaam aaam ttt m where aaam ttt m is a poisson distribution with the mean aaam ttt m
then assuming independence of the the expected number of pe in the ith bin muons i
e
aaam ttt m given k ttt m and aaam becomes ti z n k

nnn figure posterior distributions of the number of muons left and the sorted arrival times ttt given k right constructed using rj mcmc output samples after discarding the burn in period
the true number of components is ve
the vertical dashed lines in the right gure locate the arrival times
aaam ttt m j tm j
we will now illustrate the performance of vapors on a simulated pe counting signal see chapter for results on two other simulated experiments
the observed signal of the illustrative example considered here consists of ve muons located at ttt m see figure
the posterior distributions of the number of muons and sorted arrival in this times are shown in figure
note that example there are two muons with almost equal arrival times i
e
the third and fourth muons
using the bms approach the model with four muons would be selected n
although has an almost similar posterior probability of

moreover observe that the marginal posterior of the arrival time of the third component is bimodal under both and more signicantly so
we ran vapors with l gaussian components on the rj mcmc output samples shown in figure note that n

figure shows the histogram of the labeled samples and the estimated parameters of the components
from the gure it can be seen that the bimodality effects caused by label switching exhibited in figure is removed completely and the estimated gaussian components enjoy reasonable variances
in the presented summary there are four muons with high probabilities of presence corresponding to the ones shown in the bottom row of figure
there are also two other muons with comparatively low probabilities of presence
in fact the samples allocated to the point process component shown the bottom row of figure can be regarded as the residuals of the tted model that is the observed samples which the l gaussian components in qhhh have not been able psfrag replacements






















































p

y t i s n e t n i psfrag replacements psfrag replacements













































y t i s n e t n i

y t i s n e t n i

l y t i s n e t n i e z i l a m r o n
l
l
l gaussian comp
gaussian comp
m
s
p

m
s
p
l l
l l
gaussian comp
gaussian comp

m
s
p

m
s
p
l l
l l
gaussian comp
gaussian comp

m
s
p

m
s
p
figure histograms of the residuals of the tted model using vapors with different values of l




point process comp
l
figure histogram of the labeled samples along with the pdf of estimated gaussian components in the model black solid line using vapors with l on the variable dimensional postrior shown in figure
the estimated parameters of each component are presented in the corresponding panel
figure normalized pdf s of the tted gaussian components using vapors with different values of l
to describe
these residuals can be used as usual in statistics as a tool for goodness diagnostics and model choice
figure illustrates the histograms of the residuals of the tted model for different values of l
it can be seen from the top left panel of figure that the distribution of the residuals corresponding to the case where l contains a few signicant peaks
the peaks are gradually removed by adding gaussian components
when l a component is added at tm that captures samples distributed around the most signicant peak of the top left panel of figure
however there still exist a few peaks particularly around tm which are captured when l
however the distribution of residuals for the case of l and l do not differ signicantly
note the decrease of value of l by increasing l
figure compares the normalized intensities of the mated gaussian components for l
it can be seen from the gure that changing l in a reasonable range say l does not inuence signicantly the nal inference
in all cases the six gaussian components that were estimated in the case of l exist
by moving from l to l additional gaussian components are added in the obtained summary with very low probabilities of presence which improve the t but does not change much the nal inference
iv
monte carlo experiment the examples of section iii have illustrated the capability of vapors to relabel and summarize variable dimensional posterior distributions encountered in two signal sition problems
in order to conrm these ndings we will now investigate more systematically by means of a monte carlo simulation experiment how faithfully the approximate posterior distribution preserves certain features of the true posterior distribution
one hundred realizations of the sinusoid detection ment described in section i b see figure were simulated and analyzed using the same rj mcmc sampler as before
the number of rj mcmc iterations was set to and the rst samples were discarded as the burn in period
then the samples were thinned to one every fth
to initialize in a systematic fashion we set l to the parametric model qhhh the largest k such that its posterior probability is not less than

then during the process of the sem type algorithms if sufcient number of samples say is not allocated to a gaussian component or equivalently its probability of presence fades to zero we will remove it from the parametric model and decrease l by one
using this approach generally results in approximate posterior distributions which are richer than those provided by the bms in the sense that l k map where k map argmaxk
to initialize the gaussian components parameters i
e
the means m l and variances l we used as previously robust estimates of the mean and variances of the posterior distributions of sorted radial frequencies given k l
figure compares various features of the tted mate posterior distribution hhh obtained using iterations of vapors with the corresponding features of the true variable dimensional posterior distribution
these features are described in the rest of this section
the scatter plots shown in panels a and c compare the posterior distribution of the number of components i
e
with its approximated version denoted here by in runs
we only show the posterior probabilities of k and k in this comparison as the other probabilities were close to zero
the digits situated on the right of the points in the panel a indicate the number of occurrence of the corresponding event in runs and k map argmaxk
it can be seen from these three panels that the information in was well preserved by the approximated posterior distributions
next we compare the performance of vapors with the one of the direct bma in reconstructing the noiseless signal d
to this end the estimated reconstructed noiseless signal is dened as y zq kk k qqq y qqq y dqqq
in the direct bma approach using the samples generated with the rj mcmc sampler the above integral is approximated by ybma m m i and where is the design matrix of the ith vector of the sampled radial frequencies www is the posterior mean i of the amplitudes given www and its hyperparameters
to reconstruct the noiseless signal from the tted approximate posterior q hhh using vapors one can generate r pairs of r samples www as explained in section ii a
then we set yvapors r r
panel d compares the normalized reconstruction errors when using vapors with the ones of the direct bma approach in db dened as in a post processing step since each gaussian component has been endowed with a probability of presence p l with l l one can decide to discard the ones with p l smaller than a certain threshold see section

for more discussion about this idea
direct we mean that posterior means are approximated using the rj mcmc samples directly and not using the vapors posterior
where is the norm and we set ybma and yvapors when using the bma approach and vapors spectively
it can be seen from the gure that the normalized errors of the reconstructed noiseless signals using the compact summary obtained by vapors are quite comparable with the ones obtained using the bma approach
finally the scatter plots in the last two panels compare the expected number of components in the intervals p and p p using vapors with again the ones obtained using the direct bma approach
for the bma approach the expected number of components in an interval t p is given by y k y kk m m where is the number of radial frequencies observed in t on the ith sample
on the other hand from the summary provided by vapors the expected number of components in interval t is e hhh y p l n t hhh l l l where n t hhh l denotes the probability of t under the sian distribution with parameters hhh
the gures conrm that the expected number of components in the chosen intervals computed using both approaches are very similar
the results shown in this section conrmed that the proximate posterior distribution hhh obtained using vapors preserves faithfully several important features of the true posterior distribution see section
for more results in this vein including a numerical investigation comparison of the properties of estimators derived from vapors
v
conclusion in this paper we have proposed a novel algorithm to relabel and summarize variable dimensional posterior butions encountered in signal decomposition problems when the number of component is unknown
for this purpose a variable dimensional parametric model has been designed to approximate the posterior of interest
the parameters of the approximate model have been estimated by means of an sem type algorithm using samples from the true posterior distribution generated by a trans dimensional monte carlo sampler e

the rj mcmc sampler
modications of our initial sem type algorithm have been proposed in order to cope with the lack of robustness of maximum likelihood type estimates
the relevance of the proposed algorithm both for marizing and for relabeling variable dimensional posterior distributions has been illustrated on two signal decomposition examples namely the problem of detection and estimation of sinusoids in gaussian white noise and a particle counting problem motivated by the astrophysics project auger
most notably vapors has been shown to be the rst approach in the literature capable of solving the label switching issue in trans dimensional problems
we have shown that the proposed psfrag replacements y p
p a m k s r o p a v psfrag replacements k map map estimator of k posterior probability of k
psfrag replacements psfrag replacements
direct bma posterior probability of k reconstruction error db psfrag replacements psfrag replacements y p
s r o p a v s r o p a v
direct bma e p
direct bma p figure comparison of some features of the true posterior distribution with its vapors approximation
parametric model provides a good approximation for the teriors encountered in both applications
moreover vapors can provide the user with more insight concerning not only the component specic parameters but also the uncertainties about their presence
we believe that this algorithm can be useful in the vast domain of signal decomposition and mixture model analysis to enhance inference in trans dimensional problems
theoretical investigations are required in order to extend available existing convergence results for the sem algorithm to the sem type algorithm used in this paper with correlated input data and metropolis hastings updates
future work will focus on using vapors to design more efcient adaptive trans dimensional mcmc methods as a continuation of the ideas presented in
acknowledgment the authors would like to express their gratitude to b
kgl for his collaboration and providing them with data for the auger example
references a
roodaki signal decompositions using trans dimensional bayesian methods thesis cole suprieure dlectricit suplec gif sur yvette france
ph
d

n
metropolis a
w
rosenbluth m
n
rosenbluth a
h
teller and e
teller equation of state calculations by fast computing machines the journal of chemical physics vol
no
pp

w
k
hastings monte carlo sampling methods using markov chains and their m
stephens dealing with label switching in mixture models journal of the royal statistical society
series b statistical methodology pp

a
jasra c
c
holmes and d
a
stephens markov chain monte carlo methods and the label switching problem in bayesian mixture modeling statistical science vol
no
pp

g
celeux m
hurn and c
p
robert computational and inferential difculties with mixture posterior distributions journal of the american statistical tion pp

s
frhwirth schnatter dealing with label switching under model uncertainty in mixtures estimation and applications k
mengersen c
p
robert and d
terington eds
pp

wiley online library
m
sperrin t
jaki and e
wit probabilistic relabelling strategies for the label switching problem in bayesian mixture models statistics and computing vol
pp

w
yao model based labeling for mixture models statistics and computing pp

c
p
robert discussion of on bayesian analysis of mixtures with an unknown number of components by s
richardson and p
j
green journal of the royal statistical society
series b statistical methodology vol
no
pp

a
roodaki j
bect and g
fleury note on the computation of the hastings ratio for birth or death moves in trans dimensional mcmc algorithms for signal decomposition problems technical report
cole suprieure dlectricit suplec gif sur yvette france
m
a
clyde and e
i
george model uncertainty statistical science vol
no
pp

g
celeux and j
diebolt the sem algorithm a probabilistic teacher algorithm derived from the em algorithm for the mixture problem computational statistics quaterly vol
pp

g
celeux and j
diebolt a stochastic approximation type em algorithm for the mixture problem stochastics and stochastics reports vol
no
pp

s
f
nielsen the stochastic em algorithm estimation and asymptotic results bernoulli vol
no
pp

m
stephens bayesian methods for mixture of normal distributions ph
d
thesis d phill thesis
university of oxford oxford

applications biometrika vol
no
pp

a
f
karr point processes and their statistical inference second edition crc j
s
liu monte carlo strategies in scientic computing springer verlag
c
p
robert and g
casella monte carlo statistical methods second edition
springer verlag
a
basu i
r
harris n
l
hjort and m
c
jones robust and efcient estimation by minimising a density power divergence biometrika vol
no
pp

a
p
dempster n
b
laird and d
b
rubin maximum likelihood from incomplete data via the em algorithm journal of the royal statistical society series b statistical methodology
m
a
tanner and w
h
wong the calculation of posterior distributions by data augmentation journal of the american statistical association vol
no
pp

j
diebolt and g
celeux asymptotic properties of a stochastic em algorithm for estimating mixing proportions stochastic models vol
no
pp

p
j
huber and e
m
ronchetti robust statistics edition wiley

r
n
dav and r
krishnapuram robust clustering methods a unied view ieee transactions on fuzzy systems vol
no
pp

b
kgl bayesian estimation the metropolis hastings algorithm and a simple example technical report lal university of paris sud cnrs france
r
bardenet b
kgl and d
veberic single muon response the signal model technical report lal university of paris sud cnrs france
m
west approximating posterior distributions by mixture journal of the royal statistical society series b statistical methodology vol
no
pp

h
haario e
saksman and j
tamminen an adaptive metropolis algorithm bernoulli pp

y
bai r
v
craiu and a
f
di narzo divide and conquer a based approach to regional adaptation for mcmc journal of computational and graphical statistics vol
no
pp

r
bardenet o
capp g
fort and b
kgl an adaptive metropolis algorithm with online relabeling in the proceeding of the international conference on articial intelligence and statistics aistats
p
j
green reversible jump mcmc computation and bayesian model nation biometrika vol
no
pp

p
j
green trans dimensional markov chain monte carlo in highly structured stochastic systems p
j
green n
l
hjort and s
richardson eds
pp

o
u
p

c
andrieu and a
doucet joint bayesian model selection and estimation of noisy sinusoids via reversible jump mcmc ieee transactions on signal processing vol
no
pp

j
r
larocque and j
p
reilly reversible jump mcmc for joint detection and estimation of sources in coloured noise ieee transactions on signal processing vol
pp

h
rue and m
a
hurn bayesian object identication biometrika vol
no
pp

m
ortner x
descombes and j
zerubia building outline extraction from digital elevation models using marked point processes international journal of computer vision vol
pp

c
andrieu e
barat and a
doucet bayesian deconvolution of noisy ltered point processes ieee transactions on signal processing vol
no
pp

auger collaboration the pierre auger project design report second edition
auger
org
html
auger collaboration properties and performance of the prototype instrument for the pierre auger observatory nuclear instruments and methods in physics research a vol
pp

s
richardson and p
j
green on bayesian analysis of mixtures with an unknown number of components journal of the royal statistical society series b statistical methodology vol
no
pp


