an enhanced meansum method for generating hotel multi review summarizations author saibo geng supervisor diego antognini prof
boi faltings lab articial intelligence epfl switzerland abstract multi document summaritazion is the process of taking multiple texts as input and producing a short summary text based on the content of input texts
up until recently multi document summarizers are mostly supervised extractive
however supervised methods require datasets of large paired document summary examples which are rare and expensive to produce
in an unsupervised multi document abstractive summarization was proposed by chu and liu and demonstrated competitive performances comparing to extractive methods
despite good evaluation results on automatic metrics meansum has multiple limitations notably the inability of dealing with multiple aspects
the aim of this work was to use multi aspect as content selector to address the issue with multi aspect
moreover we propose a regularizer to control the length of the generated summaries
through a series of experiments on the hotel dataset from trip advisor we validate our assumption and show that our improved model achieves higher rouge sentiment accuracy than the original meansum method and also comprarable close to the supervised baseline
automatic summarization interpreatability of deep learning multi aspect masker meansum deep learning neural network abstractive summarization keywords i
introduction text automatic summarization is a challenging task in nlp and it s also among the most focused research topics recently
in industry text automatic summarization has various application in addition to the direct generation of text such as generating headlines it can also play an important role in other nlp tasks as intermediate step
for example in text sentiment analysis search engine and recommendation system comparing to use original text employ a summarized text could enhance the performance without losing much information
depending on the method of summarizing a summarizer can be either extractive abstractive
extrative method explictly uses text level or word level from input texts to construct the output summary while an abstractive method produces novel text which contains the essential information of input and avoid repeating the texts from input document
abstractive summarization has been studied using neural sequence transduction methods with datasets of large paired document summary examples
however such datasets are rare and expensive to produce recently some progress has been made in unsupervised abstrative leanring
meansum an unsupervised multi document abstractive summarization method proposed by chu and liu in demonstrated competitive performance on multiple metrics with extractive methods

meansum model takes the similarity between multiple input reviews and generated summary plus an encoder decoder as objective function
it does not rely on any specic features of given dataset
however meansum is highly abstractive but not takes into account any information on review s content
besides evluations on output summaries show that meansum is biased towards high precision and low recall
to address the rst issues we suggest to use masks instead of original reviews as input in order to reduce the unnecessary information and guide the summarizer
to address the second issue we suggest a regularizer to constraint the output summaries length
despite the fact that our masks help the meansum model to achive better performance our study shows it could increase the difculty of training
fig
meansum ii
methods a
meansum we chose meansum because it s the latest unsupervised highly abstrative multi reviews summarization model and demonstrates performance comparable to extractive methods on their validation dataset
meansum model is composed of two main conponents an auto encoder module that learns representations for each case of no pretrained language model and guarantees the uency of generated language and a summarization module that learns to generate summaries that are semantically similar to each of the input reviews
these two modules contribute a reconstruction loss and similarity loss respectively
both components contain an lstm encoder and decoder the two encoders weights and the two decoders weights are tied by default
the autoencoder reconstruction loss function is a cosinus similarity between the input texts and reconstructed can be reviews masks or rsar
the summary review similarity loss is dened as the average cross entropy between the generated summary and each input text
the summary review similarity loss is the key how meansum achieves unsupervised learning
b
masks of reviews the term mask or rationale is generally understood as a long word sequences from the input text which sufce for neural network system to make the prediction
we can consider masks as informative text within reviews and the non mask part of reviews are little informative
having masks enabled us to implement a content selection on reviews before feeding them to neural network
a rst usage of masks is to lter noises from original reviews
a second usage is to aggregate review information by categories this could help the summarizer we use the multi aspect to build masks on the hotel review
mam allocates to each review segment a most related aspect from ve candidates
service
cleanliness
value
location
room
masks were used in three different ways in this project maskconcatenate all masks as ltered review rsarsplit all reviews into single aspect segments and regroup them by the associated hotel
train a single summarizer for the regrouped summaries
fig
regrouped single aspect review rsar i v use the same regrouped reviews as in the previous case but classify them by aspect and for each aspect train an individual summarizer
it is critical to note that masks are not homogeneously distributed over different aspects
in particular far more reviews than any other than half of the whole rsar dataset which outlines that customers attach most importance to this aspect when evaluate a hotel
and have less than of the whole rsar dataset s reviews
dataset rsar rsar rsar rsar rsar rsar review quantity table i reviews distributions on aspects fig
rsar i v c
controlling summary length this capability of controlling generated text s length is crucial for various nlp applications notably text rization
in the context of text summarizaiton generation of headlines requires a concise summaries with a short length while in legal contract analysis a summary potentially longer and with high recall is targeted
length control method for extractive summarization has been investigated by
a recent review of the literature on this topic found that suggested methods of controlling text encoder decoder system s output length
in this work we suggest to control output summary length by adding a length loss term into the objective function of meansum
to this end we propose a concept of text shortness
intuitively the shortness of a summary is characterized by the length of the summary
but as the loss function built upon this denition is not differentiable it s not a good denition in deep learning
we use the average probability of giving as next token during the whole text generation process as the denition of shortness
in the extreme case where the text generated is very short shortness will be high and in the case where the text generated is very longshortness will necessarily be small as it s not sampled through the whole sampling processes
in particular we notice that shortness is for summaries reaching the maximal length
here we give an example of the generated summary for readers to better understand this concept i have stayed at the hotel before and it was a lovely experience
it is a very old hotel but the rooms are a little dated and could do with a bit of a facelift
the staff were all very helpful and friendly nothing was too much trouble
we did nt use the restaurant but the food was good value for money
pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad pad once we have dened the shortness we can use it to calculate the shortness of input reviews and the shortness of generated summary
the length loss function is dened as below llen si are two coefcient used to regularize the effect of length constraint
in case where the length constraint is set to be close to the mean length of input reviews
a larger will lead to a longer summary and a small to a shorter summary
d
supervised baseline we also designed a supervised model to compare with our model
as showed in the figure we replace the autoencoder reconstruction loss by a standard cross entropy loss between gold short summaries and generated summaries
the nal loss we optimize is simply lsupervised lautoencoder lcrossentropy
we use the summarizer trained on masks reviews and rsar to generate summary on our validataion set
no tuning was performed we used the exact same model as in the previous part
after that we train on each dataset a supervised model and test them on the same validation set as for unsupervised model to compare the performance
fig
supervised model iii
metrics and evaluation a
automated metrics without reference summaries here we use the same metrics as proposed in the meansum paper
rouge rouge is a common automated metrics in text summarization
as we want to evaluate our summarizer without reference summaries a variation of rouge score is adopted
instead of calculating rouge score between reference summary and generated summary we do the same calculations between each source review and generated called wordoverlap in meansum paper
finally we take the average of these score and dene it as rouge score
rou gei rou j n n where k is the number of reviews being in our experiments
in this paper we used and
sentiment accuracy a useful summary should reect and be consistent with the overall sentiment of the reviews
we rst separately train a cnn based classication model that given a review predicts the star rating of a review an integer from to
for each summary we check whether the classier s predicted rating is equal to the average rating of the reviews being summarized rounded to the nearest star rating
n n clf round k j log likelihood we use nll to measure the uency of generated text
a low nll reects high language uency in the generated text
b
automated metrics with reference summaries rouge to compare our model with supervised baseline we use the reference summary to caculate the rouge of generated summary
the rouge used here is identical as in the one widely used
a
datasets description iv
experimental setup to evaluate the performance of our model we crawled hotel reviews from tripadvisor
each review contains a ve star rating for each aspect service cleanliness value location and room
the average correlation between aspects is high
on average
dataset hotel review dataset number of reviews before ltering number of reviews after ltering number of hotels before ltering number of hotels after ltering maximal review length average of review length characters
characters table ii statistics on hotel review dataset it s benecial to compare our model with a supervised model
to enable the training of a supervised model we scraped hotel information including a short overall summary and multiple summaries on various aspects from trustyou
com
among the hotels of them are also present in our hotel review dataset
we take the intersection of the two dataset and use it for supervised learning
it is important to note that gold summaries are much shorter compared to reviews
a gold summary typically looks like beach hotel
close to the beach
great rooms and fantastic service
beautiful beach
while the review generated by meansum are in general much longer
b
experimental details in subword v
results dataset average short gold summary length average long gold summary length number of reviews before ltering number of reviews after ltering number of hotels before ltering number of hotels after ltering average of review length supervised dataset characters characters characters table iii statistics on hotel with ground true summary dataset input reviews rouge l sentiment accuracy nll mean summ comment review masks rsar















best overall repetitive highly repetitive too large highly repetitive






























table iv automated metric results with reviews being summarized a
main results the automated metrics for our model and the baselines are shown in table iii
using the test split of each input review dataset our experiments conrm that use rsar as input text provided a boost to meansum compared to feeding original reviews on automatic metric evaluations

as we mentioned in the dataset description sectionii b masks are not homogeneously distributed over different aspects
viii we nd empirically that the dataset size is correlated with the repetitiveness of generated summaries
in case of small training dataset such as and the output summaries are highly repetitive despite good rouge scores and nll
based on this consideration we only consider and as robust input review datasets
among all these datasets rsar outperforms in sentiment and gives second best result in and rouge l while outperforms on rouge l
although and other single aspect dataset fails to beat the performance of rsar on we believe this is due to the huge diffrence on size of dataset
it could be imagined that given similar size of data single aspect summarizer would outperform multi aspect on other metrics
the apparent repetitiveness on the summary of and is mostly due to the lack of data
we aware that the inhomogeneity of review number of different aspects is intrinsic and it reveals the priority that customers give while making reviews on the hotel
a direct solution to this would be shorten the output summary
a simple but brutal method that we tested was to trauncate the output summary after a given number of sentences
this method did solve the repetitiveness issue and the output summary are quite uent
unfortunately as the summary truncated are very short the metric on it has very low recall and a very high precision
thus brutal truncation is not satisfactory and needs to be improved in the future
b
issue with language uency the introduction of mask into summarization model aims to guide the summarizer model to focus on the important meaningful part of the input reviews
however one direct counter effect is the regrouped masks lack language rouge score used in this evaluation is different from the traditional one as meansum it s an unsupervised learning without true summary cf evaluations section highly biaised sentiment distribution in undermines its high sentiment accuracy uency
in contrary to reviews written by humans masks are generated by concatenating the selected segments of corresponding reviews
this direct concatenation leads to a fragmented language style
this counter effect is more signicant on rsar as reviews are split into more ne grained pieces and regrouped together
in the rst example below there two places where the mask lost language uency due to the sentences discarded
in the second example above the rst phrase is not semantically clear as we do not know who the he refers to
and this may confused language model as in real texts a undened he rarely appears as the beginning of the text
the and sentences have the same subject which are syntactically repetitive
this happens from time to time adding difculties for model to capture the right syntax and semantics
original review check in was quick and jessie spelling was very friendly
she explained everything and went out of her way to check on things for us
the room was nice but older
the beds were metal frames weight rating unknown


with nice mattresses
the headboards


interesting and had reading lights attached
the room was clean


until day when we had a roach wave hello from the side table
we killed it and forgot about it
then the last day we saw more
in all stages of growth from nymph to full adult
one had even gotten into the fridge
so we were happy to be leaving
the a c unit worked well
the pool hours were enforced and the place was quiet during quiet time
wi worked good enough
nice sized tv with an okay line up
parking was a pain in the butt


ataken from review in hotel test dataset hotelreview reviews qualityi nnf loridac ity f loridac ityf lorida
html masks concatenated check in was quick and jessie spelling was very friendly
she explained everything and went out of her way to check on things for us
the room was nice but older
the room was clean


until day when we had a roach wave hello from the side table
in all stages of growth from nymph to full adult
one had even gotten into the fridge
so we were happy to be leaving
the pool hours were enforced and the place was quiet during quiet time
wi worked good enough
nice sized tv with an okay line up
parking was a pain in the butt


rsar he was very friendly to the point of sleeping on our bed when we fell asleep
the young man who greeted us was friendly courteous helpful and very accommodating
the young man was not so pleased and mentioned that they had been looking for the cat all day
there were a lot of nice touches such as a happy hour with complimentary cheese and wine each day which we sampled on our rst night
in the afternoons there was complimentary cake a beverage available but we did not try it
ataken from entry from rsar test dataset aspect hotelreview reviews roxbroh ouse w arkworthamblen orthumberlande ngland
html further observations on the tensorboard for language models conrmed with our initial ndings
we notice that language model with the same conguration has higher loss on hotel masks after a given number of batches
contrary to expectations the language model loss function on rsar are lower than both hotels and masks which could be due to the fact that rsar texts are single aspect thus helps to reduce the difculty of predicting next word given previous words
lm loss function on hotel mask lm loss function on hotel review fig
loss function curve for reviews and masks c
unbalanced recall and precision interestingly for all input review datasets we nd that rouge score are always biased towards high recall and low precision
below is the example of rsar
as precision and recall are related to the summary length longer the summary is higher its recall could potentially be and lower its precision could be
this is not always true especially when the summary are just recopying its self then no matter how long the summary it s its recall and precision both remain the same
but if we can control the output summary length by not just repeating it may allow us to improve the the rouge score by balancing the precision and recall
rouge

rougel
precision recall





table v detailed rouge scores of rsar to address this issue we introduced length loss and tested it with different parameter values
model length loss mean summ



















comment baseline table vi effect of length loss parameter the results in particular the column of mean summary length conrmed our hypothesis upon the regularizer effect of length loss
both can regularize the output summary length
in addition to this we notice the recall and precision were balanced by the variation of summary length as in table vi and table vii recall keeps growing and precision keeps decreasing
this remarkable result shows that the effect of length loss is not simply repeating but generating new content
unfortunately we did not see any improvement on
this is due to the fact that the decreasing rate of precision is faster than the increasing speed of recall thus the gain on recall is model mean summ











comment table vii effect of length loss parameter not enough to ll the loss on precision
further ne tune of parameters such as learning rate might resolve this issue
besides the control on the generated summaries length is only in a qualitative manner
we could not constraint the length of generated summaries into a given interval
d
supervised baseline

summarizer meansum on review meansum on mask meansum on rsar supervised on review
supervised on mask supervised on rsar

in progress
in porgress in progress rl


table viii supervised vs meansum this part of experiement is still in progress
so far we have the results for meansum on review meansum on mask and supervised model on review
from current results we could say our model has comparable performance with supervised model and even higher
this is not trivial as we could generate comparable results without requirement on the reference summaries
we expect our model trained on rsar could surpass supervised model
vi
conclusion limitations and future work our work consists of improving the recent unsupervised abstractive multi review summarization meansum
as a highly abstractive summarizer model meansum lacks attention mechanism
to address this limitaion we introduced masks on original reviews to help summrizer focus on important points
our model demonstrates remarkable improvement on rouge scores
besides to address the unbalanced precision recall phenomenon on meansum we suggested a regularizer on the output summary length which has a notable effect
regularizer on output summary length did not lead to improvement on rouge scores this is probably due to the inappropriate parameters of training
further ne tune on parameters are necessary
the comparison of our model with supervised model is still in progress which would help us better position our model s performance
references diego antognini
multi dimensional explanation of reviews

maximin coavoux hady elsahar and matthias gall
unsupervised aspect based multi document abstractive summarization
in proceedings of the workshop on new frontiers in summarization pages hong kong china november
association for computational linguistics
eric chu and peter j
liu
unsupervised neural multi document abstractive summarization
corr eric chu and peter j
liu
unsupervised neural multi document abstractive summarization
corr



yuta kikuchi graham neubig ryohei sasano hiroya takamura and manabu okumura
controlling output length in neural encoder decoders
in proceedings of the conference on empirical methods in natural language processing pages austin texas november
association for computational linguistics
chin yew lin
rouge a package for automatic evaluation of summaries
in text summarization branches out pages barcelona spain july
association for computational linguistics
yashar mehdad amanda stent kapil thadani dragomir radev youssef billawala and karolina ner
extractive summarization under strict length constraints
in proceedings of the tenth international conference on language resources and evaluation pages portoro slovenia may
european language resources association elra

