t c o l c
s c v
v i x r a abstractive dialog summarization with semantic scaffolds lin yuan zhejiang university
com zhou yu university of california davis
edu abstract the demand for abstractive dialog summary is growing in real world applications
for example customer service center or hospitals would like to summarize tomer service interaction and doctor patient interaction
however few researchers explored abstractive summarization on dialogs due to the lack of suitable datasets
we propose an abstractive dialog summarization dataset based on multiwoz budzianowski et al

if we directly apply previous state of the art ument summarization methods on dialogs there are two signicant drawbacks the informative entities such as restaurant names are difcult to preserve and the contents from different dialog domains are sometimes mismatched
to address these two drawbacks we propose scaffold pointer network spnet to utilize the existing annotation on speaker role semantic slot and dialog domain
spnet incorporates these semantic scaffolds for dialog summarization
since rouge can not capture the two drawbacks mentioned we also propose a new evaluation metric that considers critical informative entities in the text
on multiwoz our proposed spnet outperforms state of the art abstractive summarization methods on all the automatic and human evaluation metrics
introduction summarization aims to condense a piece of text to a shorter version retaining the critical tion
on dialogs summarization has various promising applications in the real world
for instance the automatic doctor patient interaction summary can save doctors massive amount of time used for lling medical records
there is also a general demand for summarizing meetings in order to track project progress in the industry
generally multi party conversations with interactive tion are more difcult to summarize than single speaker documents
hence dialog summarization will be a potential eld in summarization track
there are two types of summarization extractive and abstractive
extractive summarization selects sentences or phrases directly from the source text and merges them to a summary while abstractive summarization attempts to generate novel expressions to condense information
previous dialog summarization research mostly study extractive summarization murray et al
maskey hirschberg
extractive methods merge selected important utterances from a dialog to form summary
because dialogs are highly dependant on their histories it is difcult to produce coherent discourses with a set of non consecutive conversation turns
therefore extractive summarization is not the best approach to summarize dialogs
however most modern abstractive methods focus on single speaker documents rather than dialogs due to the lack of dialog summarization corpora
popular abstractive summarization dataset like cnn daily mail hermann et al
is on news documents
ami meeting corpus mccowan et al
is the common benchmark but it only has extractive summary
in this work we introduce a dataset for abstractive dialog summarization based on multiwoz budzianowski et al

models such as pointer generator see et al
have achieved high quality summaries of news document
however directly applying a news summarizer to dialog results in two drawbacks informative entities such as place name are difcult to capture precisely and contents in different domains are summarized unequally
to address these problems we propose scaffold pointer network spnet
spnet incorporates three types of semantic scaffolds in dialog speaker role semantic slot and dialog domain
firstly spnet adapts separate encoder to attentional framework producing distinct semantic representations for different speaker roles
then our method inputs delexicalized utterances for producing delexicalized summary and lls in slot values to generate complete summary
finally we incorporate dialog domain scaffold by jointly optimizing dialog domain classication task along with the summarization task
we uate spnet with both automatic and human evaluation metrics on multiwoz
spnet outperforms pointer generator see et al
and transformer vaswani et al
on all the metrics
related work rush et al
rst applied modern neural models to abstractive summarization
their approach is based on framework sutskever et al
and attention mechanism bahdanau et al
achieving state of the art results on gigaword and dataset
gu et al
posed copy mechanism in summarization demonstrating its effectiveness by combining the tages of extractive and abstractive approach
see et al
applied pointing vinyals et al
as copy mechanism and use coverage mechanism tu et al
to discourage repetition
most recently reinforcement learning rl has been employed in abstractive summarization
rl based approaches directly optimize the objectives of summarization ranzato et al
celikyilmaz et al

however deep reinforcement learning approaches are difcult to train and more prone to exposure bias bahdanau et al

recently pre training methods are popular in nlp applications
bert devlin et al
and gpt radford et al
have achieved state of the art performance in many tasks including marization
for instance zhang et al
proposed a method to pre train hierarchical document encoder for extractive summarization
hoang et al
proposed two strategies to incorporate a pre trained model gpt to perform the abstractive summarizer and achieved a better performance
however there has not been much research on adapting pre trained models to dialog summarization
dialog summarization specically meeting summarization has been studied extensively
previous work generally focused on statistical machine learning methods in extractive dialog summarization galley used skip chain conditional random elds crfs lafferty et al
as a ing method in extractive meeting summarization
wang cardie compared support vector machines svms cortes vapnik with lda based topic models blei et al
for producing decision summaries
however abstractive dialog summarization was less explored due to the lack of a suitable benchmark
recent work wang cardie goo chen pan et al
created abstractive dialog summary benchmarks with existing dialog corpus
goo chen annotated topic descriptions in ami meeting corpus as the summary
however topics they dened are coarse such as industrial designer presentation
they also proposed a model with a sentence gated mechanism incorporating dialog acts to perform abstractive summarization
over li et al
rst built a model to summarize audio visual meeting data with an abstractive method
however previous work has not investigated the utilization of semantic patterns in dialog so we explore it in depth in our work
proposed method as discussed above state of the art document summarizers are not applicable in conversation tings
we propose scaffold pointer network spnet based on pointer generator see et al

spnet incorporates three types of semantic scaffolds to improve abstractive dialog summarization speaker role semantic slot and dialog domain

background we rst introduce pointer generator see et al

it is a hybrid model of the typical tention model nallapati et al
and pointer network vinyals et al

framework encodes source sequence and generates the target sequence with the decoder
the input sequence is fed into the encoder token by token producing the encoder hidden states hi in each encoding step
the decoder receives word embedding of the previous word and generates a distribution to decide the target element in this step retaining decoder hidden states st
in pointer generator attention distribution at is computed as in bahdanau et al
i vt tanh whhi wsst battn at softmax where wh ws v and battn are all learnable parameters
with the attention distribution at context vector h hidden states
context vector is regarded as the attentional information in the source text t is computed as the weighted sum of encoder s h t at ihi i pointer generator differs from typical attention model in the generation process
the ing mechanism combines copying words directly from the source text with generating words from a xed vocabulary
generation probability pgen is calculated as a soft switch to choose from copy and generation t wt where xt is the decoder input wh ws wx and bptr are all learnable parameters
is sigmoid function so the generation probability pgen has a range of
s st wt xt bptr h h pgen the ability to select from copy and generation corresponds to a dynamic vocabulary
pointer work forms an extended vocabulary for the copied tokens including all the out of words appeared in the source text
the nal probability distribution p w on extended vocabulary is computed as follows pvocab softmax v v st h p w pgen at i i wi w where pvocab is the distribution on the original vocabulary v v b and are learnable parameters used to calculate such distribution

scaffold pointer network spnet our scaffold pointer network depicted in figure is based on pointer generator see et al

the contribution of spnet is three fold separate encoding for different roles incorporating semantic slot scaffold and dialog domain scaffold


speaker role scaffold our encoder decoder framework employs separate encoding for different speakers in the dialog
and system utterances xsys user utterances xusr are fed into a user encoder and a system encoder t and hsys separately to obtain encoder hidden states husr
the attention distributions and context vectors are calculated as described in section

in order to merge these two encoders in our framework the decoder s hidden state is initialized as t i i the pointing mechanism in our model follows the equation and we obtain the context vector h t t hsys t h t concat ausrt i husr i asyst i hsys i i i

semantic slot scaffold we integrate semantic slot scaffold by performing delexicalization on original dialogs
tion is a common pre processing step in dialog modeling
specically delexicalization replaces the slot values with its semantic slot

replace with time
it is easier for the language modeling to process delexicalized texts as they have a reduced vocabulary size
but these generated sentences lack the semantic information due to the delexicalization
some previous dialog system figure spnet overview
the blue and yellow box is the user and system encoder respectively
the encoders take the delexicalized conversation as input
the slots values are aligned with their slots position
pointing mechanism merges attention distribution and vocabulary distribution to obtain the nal distribution
we then ll the slots values into the slot tokens to convert the template to a complete summary
spnet also performs domain classication to improve encoder representation
research ignored this issue wen et al
or completed single delexicalized utterance sharma et al
as generated response
we propose to perform delexicalization in dialog summary since delexicalized utterances can simplify dialog modeling
we ll the generated templates with slots with the copy and pointing mechanism
we rst train the model with the delexicalized utterance
attention distribution at over the source tokens instructs the decoder to ll up the slots with lexicalized values max at i note that wslot species the tokens that represents the slot name e

hotel place time
decoder directly copies lexicalized value conditioned on attention distribution at i
if w is not a slot token then the probability p w is calculated as equation


dialog domain scaffold we integrate dialog domain scaffold through a multi task framework
dialog domain indicates different conversation task content for example booking hotel restaurant and taxi in multiwoz dataset
generally the content in different domains varies so multi domain task summarization is more difcult than single domain
we include domain classication as the auxiliary task to rate the prior that different domains have different content
feedback from the domain classication task provides domain specic information for the encoder to learn better representations
for main classication we feed the concatenated encoder hidden state through a binary classier with two linear layers producing domain probability
the ith element di in d represents the probability of the ith domain u husr t hsys t bd d where u u bd and d are all trainable parameters in the classier
we denote the loss function of summarization as and domain classication as
assume target word at timestep t is w t is the arithmetic mean of the negative log likelihood of w t over the generated sequence log p w t t t the domain classication task is a multi label binary classication problem
we use binary cross entropy loss between the ith domain label di and predict probability for this task di log di log di where is the number of domains
finally we reweight the classication loss with ter and the objective function is loss experimental settings
dataset we validate spnet on
dataset budzianowski et al

multiwoz consists of multi domain conversations between a tourist and a information center clerk on varies booking tasks or domains such as booking restaurants hotels taxis
there are dialogs spanning over seven domains
of them are single domain
turns on average and are domain
turns on average
during multiwoz data collection instruction is provided for crowd workers to perform the task
we use the instructions as the dialog summary and an example data is shown in table
dialog domain label is extracted from existing multiwoz annotation
in the experiment we split the dataset into training validation and testing

evaluation metrics rouge lin is a standard metric for summarization designed to measure the surface word alignment between a generated summary and a human written summary
we evaluate our model with and rouge l
they measure the word overlap bigram overlap and longest common sequence between the reference summary and the generated summary respectively
we obtain rouge scores using the
however rouge is insufcient to measure summarization performance
the following example shows its limitations reference you are going to restaurant name at time
summary you are going to restaurant name at
in this case the summary has a high rouge score as it has a considerable proportion of word overlap with the reference summary
however it still has poor relevance and readability for leaving out one of the most critical information time
rouge treats each word equally in computing n gram overlap while the informativeness actually varies common words or phrases e

you are going to signicantly contribute to the rouge score and readability but they are almost irrelevant to essential contents
the semantic slot values e

restaurant name time are more essential compared to other words in the summary
however rouge did not take this into consideration
to address this drawback in rouge we propose a new evaluation metric critical information completeness cic
formally cic is a recall of semantic slot information between a candidate summary and a reference summary
cic is dened as follows vv cic m
com models base pointer gen see et al
transformer vaswani et al
base speaker role base speaker role semantic slot spnet base speaker role semantic slot dialog domain rouge l














cic




table automatic evaluation results on multiwoz
we use pointer generator as the base model and gradually add different semantic scaffolds
where v stands for a set of delexicalized values in the reference summary is the number of values co occurring in the candidate summary and reference summary and m is the number of values in set v
in our experiments cic is computed as the arithmetic mean over all the dialog domains to retain the overall performance
cic is a suitable complementary metric to rouge because it accounts for the most important mation within each dialog domain
cic can be applied to any summarization task with predened essential entities
for example in news summarization the proper nouns are the critical information to retain

implementation details we implemented our baselines with opennmt framework klein et al

we delexicalize utterances according to the belief span annotation
to maintain the generalizability of spnet we combine the slots that refer to the same information from different dialog domains into one slot e

time
instead of using pre trained word embeddings like glove pennington et al
we train word embeddings from scratch with a dimension embedding layer
we set the hidden states of the bidirectional lstm encoders to dimensions and the unidirectional lstm decoder to dimension
our model is optimized using adam kingma ba with a learning rate of



we reduce the learning rate to half to avoid overtting when the validation loss increases
we set the hyperparameter to
in the objective function and the batch size to eight
we use beam search with a beam size of three during decoding
we use the validation set to select the model parameter
our model with and without multi task takes about epochs and seven epochs to converge respectively
results and discussions
automatic evaluation results to demonstrate spnet s effectiveness we compare it with two state of the art methods generator see et al
and transformer vaswani et al

pointer generator is the of the art method in abstractive document summarization
in inference we use length penalty and coverage penalty mentioned in gehrmann et al

the hyperparameters in the original mentation see et al
were used
transformer uses attention mechanisms to replace recurrence for sequence transduction
transformer generalizes well to many sequence to sequence problems so we adapt it to our task following the implementation in the ofcial opennmt py documentation
we show all the models results in table
we observe that spnet reaches the highest score in both rouge and cic
both pointer generator and transformer achieve high rouge scores but a ative low cic scores
it suggests that the baselines have more room for improvement on preserving critical slot information
all the scaffolds we propose can be applied to different neural network models
in this work we select pointer generator as our base model in spnet because we observe that transformer only has a small improvement over pointer generator but is having a higher cost on training time and computing resources
we observe that spnet outperforms other methods in all the automatic evaluation metrics with a big margin as it incorporates all the three semantic scaffolds
semantic slot contributes the most to spnet s increased performance bringing the largest increase on all automatic evaluation metrics
conversation i just need it booked for people for a total of nights starting from sunday
client i m looking for a place to stay
it needs to be a guesthouse and include free wi
help desk there are hotels that meet your needs
would you like to narrow your search by area price range client i would like for it to be cheap and include free parking
help desk there are nine guesthouse hotels in various areas
what part of town are you hoping for client nothing in particular
reference number please
help desk sure we will book you in a hotel with stars
the reservation will be for people for nights
how many rooms would you like to reserve client well for six people i suppose i will be needing three rooms for four nights starting sunday
help desk you re booked at the alexander bed and breakfast coldham lane for people for four nights starting sunday
your reference number is
client thank you i m also looking for a restaurant
ideally an italian place in the same price range in the centre
help desk i found ask restaurant would you like to book that client is the name of the restaurant ask restaurant help desk yes the restaurant is called ask restaurant
would you like to book a table there client yes
book it for the same group of people on the same day at
can i get the reference number please help desk great your booking for people at the restaurant ask on sunday at was successful your reference number is
client i am all set
thank you
help desk thank you for using the cambridge towneinfo help desk i d also like the summaries pointer generator you are traveling to cambridge and looking forward to try local restaurants
you are looking for a place to stay
the hotel should include free wi and should be in the type of guesthouse
the hotel does nt need to include internet
if there is no such hotel how about one that has free wi
once you nd the hotel you want to book it for people and nights starting from sunday
if the booking fails how about nights
make sure you get the reference number
you are also looking for information particular restaurant
its name is called ask restaurant restaurant
make you you the price range and postcode
spnet you are looking for information in cambridge
you are looking for a place to stay
the hotel should be in the type of guest house and should include free wi
the hotel should be in the cheap price range
once you nd the hotel you want to book it for people and nights starting from sunday
make sure you get the reference number
you are also looking for a restaurant
the restaurant should be in the same price range as the hotel and should serve italian food
the restaurant should be in the same area as the hotel
once you nd the restaurant you want to book a table for the same group of people at on the same day
make sure you get the reference number
ground truth you are planning your trip in cambridge
you are looking for a place to stay
the hotel should include free wi and should be in the type of guest house
the hotel should be in the cheap price range and should include free parking
once you nd the hotel you want to book it for people and nights starting from sunday
make sure you get the reference number
you are also looking for a restaurant
the restaurant should be in the same price range as the hotel and should be in the centre
the restaurant should serve italian food
once you nd the restaurant you want to book a table for the same group of people at on the same day
make sure you get the reference number
table an example dialog and pointer generator spnet and ground truth summaries
we derline semantic slots in the conversation
red denotes incorrect slot values and green denotes the correct ones

human evaluation results we also perform human evaluation to verify if our method s increased performance on automatic evaluation metrics entails better human perceived quality
we randomly select test samples from multiwoz test set for evaluation
we recruit crowd workers from amazon mechanical turk
for each sample we show the conversation reference summary as well as summaries generated by pointer generator and spnet to three different participants
the participants are asked to score each summary on three indicators relevance conciseness and readability on a to scale and rank the summary pair tie allowed
we present human evaluation results in table
in the scoring part our model outperforms generator in all three evaluation metrics
spnet scored better than pointer generator on relevance and readability
all generated summaries are relatively concise therefore they score very similar in conciseness
ground truth is still perceived as more relevant and readable than spnet results
however ground truth does not get a high absolute score
from the feedback of the evaluators we found that they think that the ground truth has not covered all the necessary information in the versation and the description is not so natural
this motivates us to collect a dialog summarization dataset with high quality human written summaries in the future
results in the ranking evaluation show more differences between different summaries
spnet outperforms pointer generator with a large margin
its performance is relatively close to the ground truth summary
summary ground truth pointer et al
spnet rank pair spnet vs
pointer gen spnet vs
ground truth relevance conciseness readability


lose




win




tie

table the upper is the scoring part and the lower is the the ranking part
spnet outperforms pointer generator in all three human evaluation metrics and the differences are signicant with the condence over
in student t test
in the ranking part the percentage of each choice is shown in decimal
win lose and tie refer to the state of the former summary in ranking

case study table shows an example summary from all models along with ground truth summary
we observe that pointer generator ignores some essential fragments such as the restaurant booking information people sunday
missing information always belongs to the last several domains rant in this case in a multi domain dialog
we also observe that separately encoding two speakers reduces repetition and inconsistency
for instance pointer generator s summary mentions free wi several times and has conicting requirements on wi
this is because dialogs has tion redundancy but single speaker model ignores such dialog property
our method has limitations
in the example shown in table our summary does not mention the hotel name alexander bed and breakfast and its address coldham lane referred in the source
it occurs because the ground truth summary doe not cover it in the training data
as a supervised method spnet is hard to generate a summary containing additional information beyond the ground truth
however in some cases spnet can also correctly summarize the content not covered in the reference summary see table in appendix
furthermore although our spnet achieves a much improved performance the application of spnet still needs extra annotations for semantic scaffolds
for a dialog dataset speaker role scaffold is a natural pattern for modeling
most multi domain dialog corpus has the domain annotation
while for texts for example news its topic categorization such as sports or entertainment can be used as domain annotation
we nd that semantic slot scaffold brings the most signicant improvement but it is seldom explicitly annotated
however the semantic slot scaffold can be relaxed to any critical entities in the corpus such as team name in sports news or professional terminology in a technical meeting
conclusion and future work we adapt a dialog generation dataset multiwoz to an abstractive dialog summarization dataset
we propose spnet an end to end model that incorporates the speaker role semantic slot and dialog domain as the semantic scaffolds to improve abstractive summary quality
we also propose an automatic evaluation metric cic that considers semantic slot relevance to serve as a complementary metric to rouge
spnet outperforms baseline methods in both automatic and human evaluation metrics
it suggests that involving semantic scaffolds efciently improves abstractive summarization quality in the dialog scene
moreover we can easily extend spnet to other summarization tasks
we plan to apply semantic slot scaffold to news summarization
specically we can annotate the critical entities such as person names or location names to ensure that they are captured correctly in the generated summary
we also plan to collect a human human dialog dataset with more diverse human written summaries
references dzmitry bahdanau kyunghyun cho and yoshua bengio
neural machine translation by jointly learning to align and translate
in iclr international conference on learning tations
dzmitry bahdanau philemon brakel kelvin xu anirudh goyal ryan lowe joelle pineau aaron c
courville and yoshua bengio
an actor critic algorithm for sequence prediction
in iclr international conference on learning representations
david m
blei andrew y
ng and michael i
jordan
latent dirichlet allocation
journal of machine learning research
pawe budzianowski tsung hsien wen bo hsiang tseng iigo casanueva stefan ultes osman ramadan and milica gai
multiwoz a large scale multi domain wizard of oz dataset for oriented dialogue modelling
arxiv preprint

asli celikyilmaz antoine bosselut xiaodong he and yejin choi
deep communicating agents for abstractive summarization
in naacl hlt annual conference of the north can chapter of the association for computational linguistics human language technologies volume pp

corinna cortes and vladimir vapnik
support vector networks
machine learning
jacob devlin ming wei chang kenton lee and kristina toutanova
bert pre training of deep bidirectional transformers for language understanding
arxiv preprint

michel galley
a skip chain conditional random eld for ranking meeting utterances by importance
in proceedings of the conference on empirical methods in natural language processing pp

sebastian gehrmann yuntian deng and alexander m
rush
bottom up abstractive summarization
in emnlp conference on empirical methods in natural language processing pp

chih wen goo and yun nung chen
abstractive dialogue summarization with sentence gated eling optimized by dialogue acts
arxiv preprint

jiatao gu zhengdong lu hang li and victor o
k
li
incorporating copying mechanism in sequence to sequence learning
in proceedings of the annual meeting of the association for computational linguistics volume long papers volume pp

karl moritz hermann tom koisk edward grefenstette lasse espeholt will kay mustafa man and phil blunsom
teaching machines to read and comprehend
in proceedings of the international conference on neural information processing systems volume pp

andrew hoang antoine bosselut asli celikyilmaz and yejin choi
efcient adaptation of trained transformers for abstractive summarization
arxiv preprint

diederik p
kingma and jimmy ba
adam a method for stochastic optimization
arxiv preprint

guillaume klein yoon kim yuntian deng jean senellart and alexander m
rush
opennmt open source toolkit for neural machine translation
in proceedings of acl system strations pp

john d
lafferty andrew mccallum and fernando c
n
pereira
conditional random elds probabilistic models for segmenting and labeling sequence data
in icml proceedings of the eighteenth international conference on machine learning pp

manling li lingyu zhang heng ji and richard j
radke
keep meeting summaries on topic abstractive multi modal meeting summarization
in acl the annual meeting of the association for computational linguistics pp

chin yew lin
rouge a package for automatic evaluation of summaries
in text summarization branches out proceedings of the workshop pp

sameer maskey and julia hirschberg
comparing lexical acoustic prosodic structural and course features for speech summarization
in interspeech pp

i
mccowan j
carletta w
kraaij s
ashby s
bourban m
flynn m
guillemot t
hain j
kadlec v
karaiskos m
kronenthal g
lathoud m
lincoln a
lisowska w
post reidsma p
wellner l
p
j
j
noldus f grieco l
w
s
loijens and p
h
zimmerman
the ami meeting corpus
symposium on annotating and measuring meeting behavior pp

gabriel murray steve renals and jean carletta
extractive summarization of meeting recordings
in interspeech pp

ramesh nallapati bowen zhou ccero nogueira dos santos aglar glehre and bing xiang
stractive text summarization using sequence to sequence rnns and beyond
in proceedings of the signll conference on computational natural language learning pp

haojie pan junpei zhou zhou zhao yan liu deng cai and min yang
end to end dialogue description generation
arxiv preprint

jeffrey pennington richard socher and christopher d
manning
glove global vectors for word representation
in proceedings of the conference on empirical methods in natural guage processing emnlp pp

alec radford karthik narasimhan tim salimans and ilya sutskever
improving language derstanding by generative pre training
url us
amazonaws
com assets researchcovers languageunsupervised language understanding paper
pdf
marcaurelio ranzato sumit chopra michael auli and wojciech zaremba
sequence level ing with recurrent neural networks
in iclr international conference on learning resentations
alexander m
rush sumit chopra and jason weston
a neural attention model for abstractive sentence summarization
arxiv preprint

abigail see peter j
liu and christopher d
manning
get to the point summarization with pointer generator networks
in proceedings of the annual meeting of the association for computational linguistics volume long papers volume pp

shikhar sharma jing he kaheer suleman hannes schulz and philip bachman
natural language generation in dialogue using lexicalized and delexicalized data
in international conference on learning representations iclr workshop
ilya sutskever oriol vinyals and quoc v
le
sequence to sequence learning with neural networks
in advances in neural information processing systems pp

zhaopeng tu zhengdong lu yang liu xiaohua liu and hang li
modeling coverage for neural machine translation
arxiv preprint

ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n
gomez lukasz kaiser and illia polosukhin
attention is all you need
in advances in neural information processing systems pp

oriol vinyals meire fortunato and navdeep jaitly
pointer networks
in proceedings of the international conference on neural information processing systems volume pp

lu wang and claire cardie
domain independent abstract generation for focused meeting in proceedings of the annual meeting of the association for computational marization
linguistics volume long papers pp

lu wang and claire cardie


summarizing decisions in spoken meetings
arxiv preprint tsung hsien wen milica gasic dongho kim nikola mrksic pei hao su david vandyke and steve j
young
stochastic language generation in dialogue using recurrent neural networks with in proceedings of the annual meeting of the special convolutional sentence reranking
interest group on discourse and dialogue pp

xingxing zhang furu wei and ming zhou
hibert document level pre training of hierarchical bidirectional transformers for document summarization
in acl the annual meeting of the association for computational linguistics pp

a supplement to case study supplement summary transformer you are planning your trip in cambridge
you are looking for a place to stay
the hotel does nt need to include internet and should include free parking
the hotel should be in the type of house
if there is no such hotel how about one that is in the moderate price range once you nd the hotel you want to book it for people and nights starting from sunday
make sure you get the reference number
you are also looking forward to dine
the restaurant should be in the centre
make sure you get the reference number
human evaluation which one is better in your opinion summary pointer generator or summary spnet or tie evaluator summary spnet what is the reason for your rank we recommend you to talk about it from relevance conciseness and readability
evaluator summary is more coherent and relevant
it is just as concise but more readable
which one is better in your opinion summary spnet or summary ground truth or tie evaluator tie what is the reason for your rank we recommend you to talk about it from relevance conciseness and readability
evaluator summary and are almost identical
they are equally coherent relevant and readable
table supplement to the case in table
the summary generated by transformer is shown in supplement summary
red denotes incorrect slot values and green denotes the correct ones
human evaluation part provides the evaluator s choice and feedback in ranking summary pairs
content in the brackets is not shown to the evaluators
b dialog summarization cases conversation client i m looking for a moderately priced place to eat that in the centre of town
help desk what type of cuisine are you looking for there are restaurants in that area
client i do nt have a preference
help desk out of the restaurant choices one is the yippee noodle bar which is moderately priced in the centre of town
would you like to make a reservation client that sounds great what is the postcode help desk their postcode is and if you want a reservation just let me know the time party size and day and i ll make it for you
client not now thanks
here s a weird one though are there any expensive star hotels in the center of town help desk i m sorry but there are no expensive star hotels in the area
can i help you nd something else client do you have a hotel in the moderate price range help desk the cityroomz hotel is moderatly priced and has free internet and parking
would you like to make a reservation now client that sounds nice yes please book a room for guests staying for nights starting on sunday
help desk i m sorry those particular dates are lled if you d like i could try to make the trip shorter or maybe change days client how about just for the one night help desk alright i was able to book your hotel room at the cityroomz for people for one night
your reference number is
is there anything else i can do client i will also need a taxi to go from the restaurant to the hotel i want to leave the restaurant at
help desk i have booked your taxi
it will be a blue volvo and the contact number is
client great
thanks
that s all i need today
help desk you re welcome
have a wonderful visit
summaries pointer generator you are traveling to cambridge
you are looking for a restaurant
the restaurant should serve food and should be in the moderate price range
make sure you get postcode and address
you are also looking for information in the centre
the hotel should have a star of and should include free wi
the hotel does nt need to include internet
if there is no such hotel how about one that does nt have free parking once you nd the hotel you want to book it for people and nights starting from sunday
if the booking fails how about night make sure you get the reference number
spnet you are traveling to cambridge and looking forward to try local restaurants
you are looking for a place to dine
the restaurant should be in the moderate price range and should be in the centre
make sure you get postcode
you are also looking for a place to stay
the hotel should be in the type of hotel and should have star
the hotel should be in the same area as the restaurant and should be in the same price range as the restaurant
once you nd the hotel you want to book it for people and nights starting from sunday
if the booking fails how about night make sure you get the reference number
you also want to book a taxi to commute between the places
you want to leave the restaurant by
make sure you get contact number and car type
ground truth you are traveling to cambridge and looking forward to try local restaurants
the restaurant should be in the centre and should be in the moderate price range
make sure you get postcode
you are also looking for a place to stay
the hotel should be in the expensive price range and should have a star of
the hotel should be in the same area as the restaurant
if there is no such hotel how about one that is in the moderate price range once you nd the hotel you want to book it for people and nights starting from sunday
if the booking fails how about night
make sure you get the reference number
you also want to book a taxi to commute between the places
you want to leave the restaurant by
make sure you get contact number and car type
table an example dialog and pointer generator spnet and ground truth summaries
the dialog spans over three domains restaurant hotel and taxi
we underline semantic slots in the conversation
red denotes incorrect slot values and green denotes the correct ones
conversation client i would like a british food restaurant in the centre
help desk sure there are restaurants that meet your needs
are moderate and are expensive
do you have a preference client only the best for my family

we ll take the expensive one
book us a table for at on thursday
help desk i m sorry i am having difculty making a reservation for you
shall we try another time or restaurant type client let s try italian instead
help desk caffe uno is a very nice expensive italian restaurant in the center of town
would you like a table there client actually i change my mind
i think i want to stick with british food after all
can you suggest any one that s in the centre of town help desk fitzbillies restaurant the cambridge chop house and midsummer house are all centrally located british and very expensive but none have a table for available on thursday at
client can you try the cambridge chop house for thursday for people at instead help desk your reservation at the cambridge chop house for people at on thursday was ful
your reference number is
is there anything else i can help you with today client no that s all i need
thanks for your help help desk you re welcome thank you for using our system
client you re welcome it was great help desk have a good day pointer generator you are looking for a restaurant
the restaurant should serve british food and should be in the centre
once you nd the restaurant you want to book a table for people at on thursday
make sure you get the reference number
summaries spnet you are looking for a place to dine
the restaurant should serve british food and should be in the centre
the restaurant should be in the expensive price range
if there is no such restaurant how about one that serves british food once you nd the restaurant you want to book a table for people at on thursday
if the booking fails how about different restaurant in the same area and price range make sure you get the reference number
ground truth you are looking for a restaurant
the restaurant should serve british food and should be in the centre
once you nd the restaurant you want to book a table for people at on thursday
if the booking fails how about make sure you get the reference number
table an example dialog and pointer generator spnet and ground truth summaries
the dialog spans over one domain restaurant
we underline semantic slots in the conversation
red denotes incorrect slot values and green denotes the correct ones
blue denotes the content not covered by ground truth in spnet s summary

