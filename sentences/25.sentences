corpus based web document summarization using statistical and linguistic approach rushdi m
m
a
afrina suraiya rumana and monika department of computer science and engineering khulna university of engineering technology kuet khulna bangladesh
com abstract single document summarization generates summary by extracting the representative sentences from the document
in this paper we presented a novel technique for summarization of domain specific text from a single web document that uses statistical and linguistic analysis on the text in a reference corpus and the web document
the proposed summarizer uses the combinational function of sentence weight and subject weight to determine the rank of a sentence where is the function of number of terms and number of words in a sentence and term frequency in the corpus and is the function of and in a subject and in the
percent of the ranked sentences are considered to be the summary of the web document
we generated three web document summaries using our technique and compared each of them with the summaries developed manually from different human subjects
results showed that percent of the summaries produced by our approach satisfy the manual summaries
extraction web document summarization text summarization subject weight pos tagging
knowledge i
introduction the number of pages available on the internet almost doubles every year
in july the number of hosts advertised in the dns is
this bulk forces the search engines to provide numerous web pages for a single search
to find the desired information user often has to browse hundreds of pages where only a few of them are relevant
most of the users also have limited knowledge regarding the relevance and appropriateness of the information in the pages because of absence of contextual and discourse awareness in today s web
therefore summarizing all the information with contextual and discourse awareness is helpful for the user to find out relevant and appropriate information from the web
if the user searches the web with a keyword resistance the web may return him the pages containing the information of resistance of electricity and resistance of body against diseases
the key missing here the relevance and appropriateness of text according to the domain context and discourse of the keyword
therefore successful web text summarization depends on the measurement of relevance is between the text in the web and a reference that can be a structured and representative collection of text
this paper presents an approach to summarize specific text from single web document using both linguistic and statistical methods
to achieve this we introduced two novel sentence weight and subject weight to rank sentences and used a representative specific for the domain dc electrical circuits
here is the function of number of terms and number of words in a sentence and term frequency in the corpus and is the function of and in a subject and in the
we considered percent of the ranked sentences as the summary of the document
experimental results showed that percent of the summaries produced by our approach satisfy the manual summaries produced by different human subjects
the organization of the paper is as follows
section ii discusses the leading techniques of document summarization
in section iii we discuss the proposed approach of text summarization
experimental results and related discussions are depicted in section iv
section v concludes the paper
ii
related work in this section we discuss about a summarization tool from the royal institute of technology sweden
we also refer a public domain multi lingual multi document summarization system developed by the research group of dragomir radev
lastly we discuss a summarizer toolkit that provides the summary with its own search engine
a
swesum swesum an online summarizer was first constructed by hercules dalianis in and further developed by martin hassel
it is a traditional extraction based domain specific text summarizer that works on sentences from news text using html tags
it utilizes a lexicon for mapping inflected forms of content words for each language
for topic identification swesum applies the hypothesis where the high frequent content words are keys to the topic of the text
in news paper text the most relevant information is often presented at the top
frequencies are modified by a set of heuristics e

the position of the sentence in the text and its formatting
sentences that contain keywords are scored high
a keyword is an open class word with a high term frequency
sentences containing numerical data are also considered carrying important information
these parameters are put into a combination function with modifiable weights to obtain the total score of each sentence
for swedish swesum also features anaphora resolution as well as named entity tagging
complete user dependency and absence of generic summary makes it difficult for inexpert user to set the parameter of the swesum
b
mead mead is a centroid based extractive domain specific summarizer that scores sentences based on sentence level and inter sentence features which indicate the quality of the sentence as a summary sentence
it chooses the top ranked sentences for inclusion in the output summary
mead extractive summaries score sentences according to certain sentence centroid position and length
it only works with the news text not with the web which are significantly different in nature structure and presentation
c
lemur lemur is a toolkit which not only searches the web but also makes summary of both single and multi documents
it utilizes ad retrieval tfidf vector model okapi probabilistic model for multi document and structured query takes newswire language as relevance feedback
lemur document individual into files and breaks each one documents based on the doc formatting tags in the files
also lemur provides a standard tokenizer e

a parser that has options for stemming and stop words
iii
proposed text summarization approach summary is mainly concerned with judging the importance or the indicative power of each sentence in a given document
there are two common approaches used in the statistical approach and the linguistic approach
statistical approaches derive weights of key terms and determine the importance of sentence by the total weight contained by the sentence whereas linguistics based approaches identify term relationships in the document through part of speech pos tagging grammar analysis thesaurus usage and extract meaningful sentences
statistical approaches maybe efficient in computation but term linguistic approaches semantics which may yield better summary results in these our proposed summarization we used both of approaches
we used a representative multimodal for the domain dc electrical circuits that contains over sentences from web resources
we selected three web documents containing text for the domain and named them as document document and document
look into the proposed summarization technique works in three steps
first it selects web documents that are resourceful with respect to the domain
second the summarizer extracts text from these web documents
lastly it summarizes the extracted text
a
identifying the resourceful document we calculate the mean of each document to determine their resourcefulness
thereafter the mean of each document is compared with the mean of the corpus
in this case the mean where sentence weight and number of sentence in the document both the corpus and the documents use to calculate their respective means
on the other hand sentence weight is calculated using following where number of terms noun in a sentence number of words in the sentence frequency of term in the sentence
the sentence weight is equal to the summation of term frequency multiplied by probability of the sentence to be representative
this probability is a ratio of in order to get the effect of the length of the sentence on
document with mean distant from the mean of the in a positive direction is more informative in the domain and is chosen for summarization
from fig
we see that documents and have mean



and
respectively where corpus is denoted as document
comparison of means of corpus and documents n a e m document number figure
comparison of mean of and documents from the documents document is more informative than the others as the distance of its mean from the mean of the corpus is the highest







here number of terms number of words in a b
extracting text from web document sentence types and advantages
we converted web documents have defined structures and they consist of some sections and subsections like abstract introduction application this structured text into flat text where we preserved the paragraph only
first we selected an html document and removed all of its tags except p to collect flat text
thereafter we collected text that is separated by the tag means the text is divided into paragraphs
within a paragraph sentences are separated by period

c
summarization of text the proposed approach uses natural language processing techniques for summarization purposes as well as the statistical methods on term frequency
any text summary can be either query relevant summary or generic summary
a query relevant summary presents the contents of the document that are closely related to the initial search query
creating a query relevant summary is essentially a process of retrieving the query relevant sentences from the document
on the other hand a generic summary provides an overall sense of the contents of documents and it should contain the main topics of the documents
our proposed method utilizes both types of text summarization
from we find the sentence weight

then is normalized with the maximum weight of a sentence in the document in the following geng et al
proposed a summarization system which is based on the subject information from term co occurrence graph and linkage information of different subjects
in this research the term co occurrence graph of the document is generated after term co occurrences are calculated
thereafter the graph is sub divided into many connected which are most significant linguistic information in a sentence
in our approach the subject is determined from the sentence structure and then weight of each subject is summed up with the sentence weight
we considered four properties of a sentence weight subject weight correlation between two sentences and their positions
we considered another property called sentence a combination of and
in this regard first pos tagging is performed for each sentence
we used stanford pos tagger to tag a sentence
for example after tagging the sentence we determined its sentence structure from the corpus we calculated term frequency of the nouns
table i shows the of the nouns that are present most frequently in the corpus
the dc solution np of an electric circuit pp is vbz the solution np where wrb all voltages np and cc currents nns are vbp constant vbn table i
term frequency in the corpus term noun term frequency term noun current charge circuit voltage power resistance energy term frequency






electric ohm unit series law wire battery






here the noun phrase np is np dt jj nn where nn is nnp or nns and preposition phrase is combination of pp in np
the nns nnp np or left to the verb are considered as the subject
in this sentence the subject is the dc solution of an electric circuit
then subject weight is calculated from the of as for example we can consider the following the dc solution of an electric circuit is the solution where all voltages and currents are constant for the example we found of the sentence is

then the weight of each subject is divided by the maximum subject weight
the summation of term frequency the rank of a sentence is the combination of the and for the generic summary
we get the rank of a sentence from and as sentence overlap in summary for document for the whole document and the corpus our example sentence has of
and of
and the rank of the sentence is

we ranked each sentence in every document using and the sorted ranks of the sentences of document are depicted in table ii
table ii
sentence ranks and rank values for document rank rank value rank rank value































we take percent of every document as its summary
document contains sentences and therefore of these sentences will be included in its summary
so the weight of the sentence with rank becomes the lower bound to justify a sentence to be in summary in this case which is

if the rank of any sentence is greater than
we selected that sentence for summary otherwise not
since sentences are chosen sequentially and as we preserved the paragraphs by keeping the tag p in a sequential order the information flow was completely preserved
the correlation among sentences is very important for the summary as a sentence often refers to the previous or next sentence
in our approach we only concentrated with the relation of a sentence with its previous sentence
we observed that the sentence starting with connectives like such beyond although however moreover also this these those and that are related with preceding sentence
so in such case the sentence prior to the selected sentence for summary is considered to be included in the summary
if the rank of the referred sentence is greater than or equal to the percent of the rank of the selected sentence then it is included in the summary
iv
experimental results the comparison of our summary with the manual summaries is shown in fig

s e c n e t n e s r e b m u n s e c n e t n e s r e b m u n reviewers figure
sentence overlap between the summary of document and human summaries if we consider the summary of document from fig
we can see that the sentence overlap between the summary of our summarizer and the summary of reviewer is means that the summary of the reviewer contains five of the sentences of our summary
the maximum number of sentence overlap for the document is seven out of sentences and has been chosen by four reviewers
fig
shows the comparison of our summary of document with the manual summaries
the summary of document contains sentences and the maximum number of sentence overlap between the summaries is nine
sentence overlap in summary for document reviewers figure
sentence overlap between the summary of document and and human summaries similarly fig
shows that the summary of document contains six sentences and maximum number of sentence overlap between the summaries is means five sentences from the summary developed by our summarizer are also chosen by the human subjects in their summaries
sentence overlap in summary for document reviewers figure
sentence overlap between the summary of document and human summaries in precision and recall generated summary is compared against an ideal reference summary to find sentence which is the performance of the prior
to construct the reference summary a group of human subjects are asked to extract sentences
then the sentences chosen by a majority of humans are included in the reference summary
from the manual summaries we created a reference summary for each document and compared our summary with the reference summary
the comparison is described in fig
comparison of reference summaries


s e c n e t n e s r e b m u n g a t n e c r e p l l a c e r d n a n o i s i c e r p mean and ssd due to the similarity of sentence of the document and top ranked sentences in the
therefore we can evaluate the resourcefulness of a web document based on its mean and ssd
table iii
result of mean and standard deviation between summaries document mean difference in mean ssd difference in ssd reference

summarizer

reference

summarizer

reference

summarizer

the language technologies research centre ltrc iiit provides an online generic summarizer
we fed the three web documents to the summarizer and its performance was percent
we also used swesum and pertinence with the three documents and their performances were less than percent in summarizing the documents
the performance evaluation of these summarizers is depicted in fig

performance evaluations of summarizers e c n a m r o r e p documents ltrc iiit swesum pertinence figure
sentence overlaps between our summary and the reference summary using precision and recall in fig
the horizontal line indicates the document numbers and the vertical line indicates the precision and recall sentences present both in the reference summary and the summary of our summarizer
this is the performance of our summarizer and it shows its efficiency in summarizing document is
percent document is
percent and document is
percent producing the average of
percent
we calculate the sample standard deviation ssd for both summaries to measure the deviation between them
for the most resourceful document almost every line of it is important
from table iii we see that document the most resourceful document has the lowest difference between the summarizers prposed summarizer figure
performance evaluations of web document summarizers v
conclusions in this paper we proposed an approach to summarize domain specific text from single document using linguistic and statistical methods and a representative as a reference
the novelty of this approach is to rank sentences based on sentence and subject weight and to extract sentences from web documents measuring textual information in the
we compared the means of web documents and the mean of the to choose three representative web documents and summarized them with the relevance with their the proposed summarizer
different human subjects also produced summaries of the documents and we produced a reference summary from them
we compared these summaries and showed that our proposed summarizer performs better than other web document summarizers
references d
r
radev and w
fan automatic summarization of search engine hit lists proceedings of the workshop on recent advances in natural language processing and information retrieval hong kong pp

internet isc
isc
org www survey reports
at available december survey domain isc r
shams and a
elsayed a corpus based evaluation of lexical components of a domain specific text to knowledge mapping prototype ieee international conference on computer and information technology iccit khulna bangladesh pp

h
dalianis swesum a text summarizer for swedish technical report trita na kth nada sweden
h
dalianis and e
strm swenam a swedish named entity recognizer technical report kth nada sweden
d
r
radev h
jing m
sty and d
tam centroid based summarization of multiple documents international journal on information processing and management vol
no
pp

n
mccracken ir experiments with lemur available at
cs
cmu
december
a
kiani and m
r
akbarzadeh automatic text summarization using hybrid fuzzy ga gp proceedings of the ieee international conference on fuzzy systems canada
t
chang and w
hybrid approach to automatic text summarization ieee international conference on computer and information technology cit sydney australia
r
shams a
elsayed and q
m
akter a corpus based evaluation of a domain specific text to knowledge mapping prototype special issue of journal of computers academy publisher in press
h
geng p
zhao e
chen and q
cai a novel automatic text summarization study based on term co occurrence proceedings of the ieee international conference on cognitive informatics canada
d
r
radev s
teufel h
saggion
w
lam j
blitzer a
elebi d
liu and e
drabek evaluation challenges in large scale document summarization the mead project proceedings of association of computational linguistics acl japan
r
shams and a
elsayed development of a conceptual structure of a domain specific corpus international conference on concept maps cmc finland and estonia
wikipedia direct current available at msn
wikipedia
org wiki june electric at
encarta
msn
com
htm l june available encarta circuit play hookey introduction to dc circuits available at
play hookey
com june stanford nlp group stanford log linear part of speech tagger available at
stanford
edu software tagger
shtml june international institute of information technology current ongoing projects at siel available at
iiit
ac
june international technologies december institute information technology language research centre available at
iiit
ac
for pertinence mining online summarization for real time multilingual
pertinence
net
html at news available december
