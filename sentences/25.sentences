corpus based web document summarization using statistical and linguistic approach rushdi afrina suraiya rumana and monika department of computer science and engineering khulna university of engineering technology kuet
khulna bangladesh abstract single document summarization generates summary by extracting the representative sentences from the document
in this paper we presented a novel technique for summarization of domain specific text from a single web document that uses statistical and linguistic analysis on the text in a reference corpus and the web document

the proposed summarizer uses the combinational function of sentence
weight and subject weight to determine the rank of a sentence where is the function of number of terms and number of words in a sentence and term frequency in the corpus and is the function of and in a subject and in the corpus
percent of the ranked sentences are considered to be the summary of the web document

we generated three web document summaries using our technique and compared each of them with the summaries developed manually from different human subjects
results showed that percent of the summaries produced by our approach satisfy the manual summaries

extraction web document summarization text summarization subject weight pos tagging
knowledge
introduction
the number of pages available on the internet almost doubles every year


in july the number of hosts advertised in the dns is

this bulk forces the search engines to provide numerous web pages for a single search

to find the desired information user often has to browse hundreds of pages where only a few of them are relevant
most of the users also have limited knowledge regarding the relevance and appropriateness of the information in the pages because of absence of contextual and discourse awareness in today s web
therefore summarizing all the information with contextual and discourse awareness is helpful for the user to find out relevant and appropriate information from the web
if the user searches the web with a keyword resistance the web may return
him the pages containing the information of resistance of electricity and resistance of body against diseases

the key missing here the relevance and appropriateness of text according to the domain context and discourse of the keyword

therefore successful web text summarization depends on the measurement of relevance is between the text in the web and a reference that can be a structured and representative collection of text
this paper presents an approach to
summarize specific text from single web document using both linguistic and statistical methods

to achieve this we introduced two novel
sentence weight
and
subject
weight to
rank sentences and used a representative specific for the domain dc electrical circuits



here is the function of number of terms and number of words in a sentence and term frequency in the corpus and is the function of and in a subject and in the corpus
we considered percent of the ranked sentences as the summary of the document
experimental results showed that percent of the summaries produced by our approach satisfy the manual summaries produced by different human subjects
the organization of the paper is as follows
section ii discusses the leading techniques of document summarization

in section iii we discuss the proposed approach of text summarization

experimental results and related discussions are depicted in section iv
section v concludes the paper
ii

related work
in this section we discuss about a summarization tool from the royal institute of technology sweden
we also refer a public domain multi lingual multi document summarization system developed by the research group of dragomir radev
lastly we discuss a summarizer toolkit that provides the summary with its own search engine
swesum swesum
an online summarizer was first constructed by hercules dalianis in and further developed by martin hassel
it is a traditional extraction based domain specific text summarizer that works on sentences from news text using html tags
it utilizes a lexicon for mapping inflected forms of content words for each language

for topic identification swesum applies the hypothesis where the high frequent content words are keys to the topic of the text
in news paper text the most relevant information is often presented at the top
frequencies are modified by a set of heuristics
the position of the sentence in the text and its formatting
sentences that contain keywords are scored high
a keyword is an open class word with a high term frequency

sentences containing numerical data are also considered carrying important information

these parameters are put into a combination function with modifiable weights to obtain the total score of each sentence

for swedish swesum also features anaphora resolution as well as named entity tagging


complete user dependency and absence of generic summary makes it difficult for inexpert user to set the parameter of the swesum


mead
mead is a centroid based extractive domain specific summarizer that scores sentences based on sentence level and inter sentence features which indicate the quality of the sentence as a summary sentence
it chooses the top ranked sentences for inclusion in the output summary

mead extractive summaries score sentences according to certain sentence centroid position and length

it only works with the news text not with the web which are significantly different in nature structure and presentation
lemur
lemur is a toolkit which not only searches the web but also makes summary of both single and multi documents
it utilizes ad retrieval tfidf vector model
okapi probabilistic model for multi document and structured query takes newswire language as relevance feedback

lemur document individual into files and breaks each one documents based on the doc formatting tags in the files

also lemur provides a standard tokenizer a parser that has options for stemming and stop words
iii
proposed text summarization approach summary is mainly concerned with judging the importance or the indicative power of each sentence in a given document

there are two common approaches used in the statistical approach and the linguistic approach

statistical approaches derive weights of key terms and determine the importance of sentence by the total weight contained by
the sentence whereas linguistics based approaches identify term relationships in the document through
part of speech pos tagging grammar analysis thesaurus usage and extract meaningful sentences
statistical approaches maybe efficient in computation but term linguistic approaches semantics which may yield better summary results
in
these our proposed summarization we used both of approaches
we used a representative multimodal for the domain dc electrical
circuits that contains over sentences from web resources
we selected three web documents containing text for the domain and named them as document document and document

look into the proposed summarization technique works in three steps
first it selects web documents that are resourceful with respect to the domain

second the summarizer extracts text from these web documents
lastly it summarizes the extracted text

identifying the resourceful document we calculate the mean of each document to determine their resourcefulness
thereafter the mean of each document is compared with the mean of the corpus
in this case the mean


where sentence weight and

number of sentence in the document both the corpus and the documents use to calculate their respective means

on the other hand sentence weight is calculated using following






where number of terms
noun in a sentence
number of words in the sentence frequency of term in the sentence

the sentence weight is equal to the summation of term frequency multiplied by probability of the sentence to be representative
this probability is a ratio of in order to get the effect of the length of the sentence on
document with
mean distant from the mean of the in a positive direction is more informative in the domain and is chosen for summarization

from fig we see that documents and have mean and respectively where corpus is denoted as document

comparison of means of corpus and documents n a e m document number figure
comparison of mean of and documents
from the documents document is more informative than the others as the distance of its mean from the mean of the corpus is the highest
here number of terms number of words in a

extracting text from web document sentence
types and advantages

we converted web documents have defined structures and they consist of some sections and
subsections like abstract introduction application this structured text into flat text where we preserved the paragraph only
first we selected an html document and removed all of its tags except p to collect flat text

thereafter we collected text that is separated by the tag means the text is divided into paragraphs

within a paragraph sentences are separated by period
summarization of text
the proposed approach uses natural language processing techniques for summarization purposes as well as the statistical methods on term frequency

any text summary can be either query relevant summary or generic summary
a query relevant summary presents the contents of the document that are closely related to the initial search query

creating a query relevant summary is essentially a process of retrieving the query relevant sentences from the document

on the other hand a generic summary provides an overall sense of the contents of documents and it should contain the main topics of the documents
our proposed method utilizes both types of text summarization

from we find the sentence weight



then is normalized with the maximum weight of a sentence in the document in the following

geng et al
proposed a summarization system which is based on the subject information from term co occurrence graph and linkage information of different subjects
in this research the term co occurrence graph of the document is generated after term co occurrences are calculated
thereafter the graph is sub divided into many connected which are most significant linguistic information in a sentence
in our approach the subject is determined from the sentence structure and then weight of each subject is summed up with the sentence weight
we considered four properties of a sentence weight
subject weight correlation between two sentences and their positions

we considered another property called sentence a combination of and
in this regard first pos tagging is performed for each sentence
we used stanford pos tagger
to tag a sentence

for example after tagging the sentence we determined its sentence structure
from the corpus we calculated term frequency of the nouns
table i shows the of the nouns that are present most frequently in the corpus
the dc solution np of an electric circuit pp
is vbz the solution np where wrb all voltages np and cc currents nns are vbp constant vbn table term frequency in the corpus term
noun term frequency term
noun current charge circuit voltage power resistance energy term frequency


electric ohm unit series law wire
battery



here the noun phrase np is np dt jj
nn where nn is nnp or nns and preposition phrase is combination of pp in np
the nns nnp np or left to the verb are considered as the subject
in this sentence the subject is
the dc solution of an electric circuit
then subject weight is calculated from the of as

for example we can consider the following the dc solution of an electric circuit is the solution where all voltages and currents are constant for the example we found of the sentence is

then the weight of each subject is divided by
the maximum subject weight

the summation of term frequency


the rank of a sentence is the combination of the and for the generic summary
we get the rank of a sentence from and as sentence overlap in summary for
document
for the whole document and the corpus our example sentence has of and of and the rank of the sentence is
we ranked each sentence in every document using and the sorted ranks of the sentences of document are depicted in table ii
table ii
sentence ranks and rank values for document rank rank value rank rank value


we take percent of every document as its summary

document contains sentences and therefore of these sentences will be included in its summary
so the weight of the sentence with rank becomes the lower bound to justify a sentence to be in summary in this case which is
if the rank of any sentence is greater than we selected that sentence for summary otherwise not

since sentences are chosen sequentially and as we preserved the paragraphs by keeping the tag p in a sequential order the information flow was completely preserved
the correlation among sentences is very important for the summary as a sentence often refers to the previous or next sentence
in our approach we only concentrated with the relation of a sentence with its previous sentence
we observed that the sentence starting with connectives like such beyond although however moreover also this these those and that are related with preceding sentence
so in such case the sentence prior to the selected sentence for
summary is considered to be included in the summary

if the rank of the referred sentence is greater than or equal to the percent of the rank of the selected sentence then it is included in the summary
iv

experimental results
the comparison of our summary with the manual summaries is shown in fig

s e c n e t n e s r e b m u n
s e c n e t n e s r e b m u n reviewers figure
sentence overlap between the summary of document and human summaries
if we consider the summary of document from fig we can see that the sentence overlap between the summary of our summarizer and the summary of reviewer is means that the summary of the reviewer contains five of the sentences of our summary
the maximum number of sentence overlap for the document is seven out of sentences and has been chosen by four reviewers
fig
shows the comparison of our summary of document with the manual summaries
the summary of document contains sentences and the maximum number of sentence overlap between the summaries is nine
sentence overlap in summary for document
reviewers figure
sentence overlap between the summary of document and and human summaries
similarly fig
shows that the summary of document contains six sentences and maximum number of
sentence overlap between the summaries is means five sentences from the summary developed by our summarizer are also chosen by the human subjects in their summaries
sentence overlap in summary for
document reviewers figure
sentence overlap between the summary of document and human summaries in precision and recall generated summary is compared against an ideal reference summary to find sentence which is the performance of the prior

to construct the reference summary a group of human subjects are asked to extract sentences


then the sentences chosen by a majority of humans are included in the reference summary
from the manual summaries we created a reference summary for each document and compared our summary with the reference summary
the comparison is described in fig
comparison of reference summaries s e c n e t n e s r e b m u n g
a t n e c r e p l l a c e r d n a n o
i s
i c e r p mean and ssd due to the similarity of sentence of the document and top ranked sentences in the corpus
therefore we can evaluate the resourcefulness of a web document based on its mean and ssd
table iii

result of mean and standard deviation between summaries
document mean difference in mean ssd difference in ssd reference summarizer reference summarizer
reference summarizer the language technologies research centre ltrc iiit
provides an online generic summarizer
we fed the three web documents to the summarizer and its performance was percent
we also used swesum and
pertinence with the three documents and their performances were less than percent in summarizing the documents
the performance evaluation of these summarizers is depicted in fig

performance evaluations of summarizers e c
n a m r o
r e p documents ltrc iiit swesum pertinence figure
sentence overlaps between our summary and the reference summary using precision and recall
in fig the horizontal line indicates the document numbers and the vertical line indicates the precision and recall sentences present both in the reference summary and the summary of our summarizer
this is the performance of our summarizer and it shows its efficiency in summarizing
document is percent document is percent and document is percent producing the average of percent
we calculate the sample standard deviation ssd for both summaries to measure the deviation between them

for the most resourceful document almost every line of it is important
from table iii we see
that
document the most resourceful document has the lowest difference between the summarizers prposed summarizer figure
performance evaluations of web document summarizers conclusions in this paper we proposed an approach to summarize domain specific text from single document using linguistic and statistical methods and a representative as a reference

the novelty of this approach is to rank sentences based on sentence and subject weight and to extract sentences from web documents measuring textual information in the corpus
we compared the means of web documents and the mean of the to choose three representative web documents and summarized them with the relevance with their the proposed summarizer
different human subjects also produced summaries of the documents and we produced a reference summary from them
we compared these summaries and showed that our proposed summarizer performs better than other web document summarizers
references
radev and fan automatic summarization of
search engine hit lists proceedings of the workshop on recent advances in natural language processing and information retrieval hong kong pp


internet
isc
at available
december survey domain isc
shams and elsayed a corpus based evaluation of lexical components of a domain specific text to knowledge mapping prototype ieee international conference on computer and information
technology iccit khulna bangladesh pp

dalianis swesum a text summarizer for swedish technical report trita na kth nada sweden

dalianis and strm swenam
a
swedish named entity recognizer technical report

kth nada sweden

radev jing sty and
tam centroid based summarization of multiple documents international journal on information processing and management vol
no pp


mccracken ir experiments with lemur available at
december
kiani and akbarzadeh automatic text summarization
using hybrid
fuzzy ga gp
proceedings of the ieee international conference on fuzzy systems canada


chang and
hybrid approach to automatic text summarization ieee
international conference on computer and information technology cit sydney australia
shams elsayed and akter a corpus based evaluation of a domain specific text to knowledge mapping prototype special issue of journal of computers academy publisher in press


geng zhao
chen and

cai a novel automatic text summarization study based on term
co
occurrence
proceedings of the ieee
international conference on
cognitive informatics canada


radev
teufel saggion lam blitzer elebi liu and drabek evaluation challenges in large scale document summarization the mead project proceedings of association of computational linguistics acl japan
shams and elsayed development of a conceptual structure of a domain specific corpus international conference on concept maps
cmc finland and estonia

wikipedia direct current available at msn
june
electric at june available encarta circuit
play hookey introduction to dc circuits available at
june
stanford nlp group stanford log linear part of speech tagger available at
june
international institute of information technology current ongoing projects at siel available at
june international technologies
december institute information technology language research centre available at for
pertinence mining online summarization for real time multilingual
at news
available
december
