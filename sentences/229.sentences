p e s l c
s c v
v i x r a features in extractive supervised single document summarization case of persian news hosein rezaei department of electrical and computer engineering isfahan university of technology hosein

iut
ac
ir seyed amid moeinzadeh department of electrical and computer engineering isfahan university of technology amid

com azar shahgholian liverpool john moores university liverpool business school a

ac
mohamad saraee school of computing science engineering university of salford m

ac
a preprint september abstract text summarization has been one of the most challenging areas of research in nlp
much effort has been made to overcome this challenge by using either the abstractive or extractive methods
extractive methods are more popular due to their simplicity compared with the more elaborate abstractive methods
in extractive approaches the system will not generate sentences
instead it learns how to score sentences within the text by using some textual features and subsequently selecting those with the highest rank
therefore the core objective is ranking and it highly depends on the document
this dependency has been unnoticed by many state of the art solutions
in this work the features of the document are integrated into vectors of every sentence
in this way the system becomes informed about the context increases the precision of the learned model and consequently produces comprehensive and brief summaries
keywords supervised extractive summarization machine learning regression feature extraction natural language processing introduction from the early days of articial intelligence automatically summarizing a text was an interesting task for many researchers
followed by the advance of the world wide web and the advent of concepts such as social networks big data and cloud computing among others text summarization became a crucial task in many applications
for example it is essential in many search engines and text retrieval systems to display a portion of each result entry which is representative of the whole text
it is also becoming essential for managers and the general public to gain the gist of news and articles immediately in order to save time while being inundated with information on social media
researchers have approached this challenge from various perspectives and have obtained some promising results
however this area continues to present more research challenges and has a long path to maturity
one method of investigating this challenge is supervised extractive summarization
extractive implementations use a ranking mechanism and select top n ranked sentences as the summary
sentences of a document are represented as vectors of features
using summarization corpora a rank will be assigned to each sentence based on its presence in several human written summaries golden summaries
the system should then learn how to use those features to predict a preprint september the rank of sentences in any given text
various machine learning approaches such as regression and classication algorithms are used to perform the ranking task
as far as our knowledge goes in all current implementations sets of sentence vectors of every document are merged together to compose a larger set which is then passed to the learning model as a matrix
in this approach the locality of ranks is disregarded
in other words the rank of sentences is highly relative to the context and document
a sentence might be ranked high in one document while being ranked lower in another
as a result merging sentences of a whole dataset into a matrix removes document boundaries and a main source of information will be lost
we addressed this issue by taking certain features of documents into account such as its length topical category and so on in addition to some new sentence features that also reect document properties
thus more information will be provided to the model and ranking could be done with respect to local features of the document
our experiments show that this rectication leads to improvement in both the performance of the learned model and the quality of produced summaries
we also represent a new baseline for the evaluation of extractive text summarizers which can be used to measure the performance of any summarizing method more accurately
the remainder of this paper is organized as follows
section reviews related works
section presents the proposed method and evaluation measures
section discusses how the experiments are set up
the results are discussed in section and nally section concludes the paper
related works text summarization has been widely studied by both academic and enterprise disciplines
text summarization methods may be classied into different types
based on input type there are single document vs multi document summarization methods
based on language there are mono lingual bilingual and multi lingual methods
there are also query focused methods in which a summary relevant to a given query is produced
from the perspective of procedure however there are two main approaches abstractive vs extractive
abstractive approaches try to generate a new short text based on the concepts understood from the original text
this usually requires a full pass through nlp pipeline and is faced with many complexities and challenges
the abstractive approach relies on linguistic methods to examine and interpret the text in order to nd new concepts and expressions
the output is a new shorter text which consists of the most important information from the original text document
extractive approaches on the other hand select a few sentences from the document based on some measures in order to place them in a summary
a broad range of methods has been examined in this approach including graph based unsupervised and supervised based methods
in supervised methods training data is generally needed to select important content from the documents
in these methods usually the problem is reduced to a classication or regression problem and machine learning techniques applied to the dataset of documents and their gold summaries represented by some features
support vector machines svm and neural networks are more popular sentence classication algorithms
the key step in extractive summarization is to determine the importance of sentences in the document
previous studies examine the ordinal position of sentences length of sentences the ratio of nouns the ratio of verbs ratio of adjectives ratio of adverbs the ratio of numerical entities and cue words
gupta and lehal in their survey of text summarization techniques list the following groups of features content based title based location based length based proper noun and upper case word based font based specic phrase based and features based on sentence similarity to other sentences in a text
previous studies use different sentence features such as terms from keywords key phrases terms from user queries frequency of words and position of words sentences for text summarization
however in most cases selection and weighting of features are an important matter of debate
some works have been carried out with respect to this but none to the best of our knowledge has shown that target attribute is highly related to the scope of the document
it is occasionally mentioned but not included in practice
for instance ferreira et al studied various combinations of sentence scoring methods on three types of documents in and and concluded that the weight of features varies dependent on the properties of context the effectiveness of sentence scoring methods for automatic extractive text summarization algorithms depends on the kind of text one wants to summarize the length of documents the kind of language used and their structure

a preprint september jy yeh et al in utilized a genetic algorithm ga to nd the weight of features for calculating sentence scores
however their following statement implies that performance of weights is generally dependent to genre that could be seen as a feature of context it can not be guaranteed that the score function whose feature weights are obtained by ga denitely performs well for the test corpus nevertheless if the genre of the test corpus is close to that of the training corpus we can make a prediction that the score function will work well

berenjkoub et al studied the effectiveness of various subsets of features in summarization of distinct sections of scientic papers
they showed that some features work well only in some specic portion of text for example on the abstract section while others perform better on the methodology section
this could be considered to be a consequence of differences in the structure and context of each section
all the above studies imply the signicance of document context in ranking
nevertheless it has not been given enough attention in the nlp community and even sometimes is neglected
for instance authors in suggest the use of a wide range of various features
among these seventeen part of speech based sentences features have been introduced all of which are sentence normalized but not document normalized i
e
they count the ratio of a syntactic unit e

verbs divided by the number of words in a sentence
such features do not consider the total number of those units e

verbs in the whole document
our work contributes to this line of research and includes document features in the learning and ranking processes
incorporating document features as a way to investigate the need for document features in sentence ranking as explained in the introduction and related works we introduced several document level features and incorporated them in the summarization process
these features are listed under subsection


although stages of our method do not differ from general supervised extractive summarization the whole process is explained in order to clarify the method of investigation
every supervised summarization has two phases
the rst is the learning phase a corpus of ideal summaries is used to train the system how to rank sentences
the second is the summarization phase where the system applies its learning gained from the rst phase in order to rank the sentences of a new given text
a process of selection is then performed to form a summary
each of these phases has several intricacies which are briey described in the following sections

learning phase the input to this phase is a dataset of documents each of which is associated with several human written summaries
the output is a learned model with a good level of accuracy that is able to reliably predict the rank of sentences in almost the same way that a human may rank them
to accomplish this it is necessary to rst perform normalization and transform various forms of phrases into their canonical form
then every text should be tokenized to sentences and further tokenized to words
another prerequisite is to remove stop words
the following subtasks should be carried out next


feature extraction foremost it is necessary to represent each sentence with those features that have the most distinguishing effect on the prediction of the rank
many features have been examined in the literature
we entitle some as document aware because they do implicitly represent some information about a document
however other features have been used that say nothing about the document in which they appeared
we call them document unaware
in the previous sections we argued that this lack of information might be misleading for the system especially when we train it with sample sentences from different documents
thus we modied some document unaware features and derived new features that cover document properties
we also examined the effect of incorporating explicit features of a document into vectors of its sentences
the following sub sections describe the features mentioned above in more detail



document unaware features ordinal position it is shown that inclusion of sentence in summary is relevant to its position in the document or even in a paragraph
intuitively sentences at the beginning or the end of a text are more likely to be included in the summary
a preprint september for the rst sentence for the second and so on to depending on how it is dened this feature might be document unaware or not
for example in and it is dened as for fth and zero for remaining sentences
in another research conducted by wong et al
it is dened as sentence number
with such a denition we may have several sentences for example with in the training set these may not have the same sense of position
while a sentence means among the rsts in a document with sentences it has a totally different meaning of in the middle in another document containing sentences
thus a useful feature formula should involve differences of documents which may change the meaning of information within it
in our experiments we used the denition of
a document aware version of position will be introduced in



length of sentence the intuition behind this feature is that sentences of too long or too short length are less likely to be included in the summary
like sentence position this feature is also subject to the wrong denition that makes it document unaware
for example in it is dened as a number of words in a sentence
such a denition does not take into account that a sentence with say words may be considered long if all other sentences of document have fewer words
another sentence with the same number of words may be regarded as short because other sentences in that document have more than words
this might occur due to different writing styles
however we included this in our experiments to compare its effect with that of its document aware counterpart which will be listed in



the ratio of nouns is dened in as the number of nouns divided by total number of words in the sentence after stop words are removed
three other features ratio of verbs ratio of adjectives and ratio of adverbs are dened in the same manner and proved to have a positive effect on ranking performance
from our perspective however a sentence with a ratio of nouns
for example in a document containing many nouns must be discriminated in the training set from another sentence with the same ratio of nouns that appeared in another document having fewer nouns
this feature does not represent how many nouns are there in the document which is important in sentence ranking
the same discussion goes on to justify the need to consider the number of verbs adjectives and adverbs in the document
the impact of these features is examined in our experiments and compared to that of their document aware counterparts
the ratio of numerical entities assuming that sentences containing more numerical data are probably giving us more information this feature may help us in ranking
for calculation we count the occurrences of numbers and digits proportional to the length of sentence
this feature must be less weighted if almost all sentences of a document have numerical data
however it does not count numbers and digits in other sentences of the document
cue words if a sentence contains special phrases such as in conclusion overall to summarize in a nutshell and so forth its selection as a part of the summary is more probable than others
the number of these phrases is counted for this feature



document aware features cosine position as mentioned in


a good denition of position should take into account document length
a well known formula used in the literature is cos t in which index is an integer representing the order of sentences and t is the total number of sentences in document
this feature ranges from to the closer to the beginning or to the end the higher value this feature will take
is a tuning parameter
as it increases the value of this feature will be distributed more equally over sentences
in this manner equal values of this feature in the training set represent a uniform notion of position in a document so it becomes document aware
relative length the intuition behind this feature is explained in



a discussion went there that a simple count of words does not take into account that a sentence with a certain number of words may be considered long or short based on the other sentences appeared the document
taking this into consideration we divided the number of words in the sentence by the average length of sentences in the document
more formally the formula is in which n is number of sentences in the document and si is the ith sentence of it
values greater than could be interpreted as long and vice versa
relative n n a preprint september tf isf this feature counts the frequency of terms in a document and assigns higher values to sentences having more frequent terms
it also discounts terms which appear in more sentences
since it is well explained in the literature we have not included details and formula which are in references and
nonetheless the aspect that matters in our discussion is that both frequency and inverse sentence frequency are terms which involve properties of context and consequently are document aware
pos features here we introduce another way to include the ratio of part of speech pos units in features and keep them document normalized
to do this the number of occurrences of each pos unit should be divided by the number of them in the document instead of that occurring in a sentence
the formal denition of the new document aware features are as follows ratio of nouns in ratio of verbs in ratio of adjectives in ratio of adverbs in number of nouns in s number of nouns in document number of verbs in s number of verbs in document number of adjectives in s number of adjectives in document number of adverbs in s number of adverbs in document ratio of numbers in number of numerical entities in s number of numerical entities in document


explicit document features in order to further investigate how effective are document specic features in sentence ranking we dened several features for documents
these features are then calculated for each document and repeated in the feature vector of every sentence of that document
their formal denition is described below and their effect is examined in the result and discussion section document sentences an important property of a document that affects summarization is the total number of sentences participating in sentence ranking
as this number grows a summarizer should be more selective and precise
also some sentence features such as cue words maybe more weighted for longer documents
in addition the main contextual information is probably more distributed over sentences
in such a case even lower values of other features should be considered important
document words the number of words in the document is another notion of document length
since the number of sentences alone is not enough to represent document length this feature should also be considered
topical category different topics such as political economic
have different writing styles and this might affect sentence ranking
for instance numerical entities may appear more in economic or sport reports than in religious or social news
therefore the weight of this attribute should be more or less based on a document s category
so it needs to be included
an overview of our feature set is represented by example in gure
column id is just for enumeration and column target is explained in the next section


target assignment every feature vector needs a target value from which the system should learn how to rank sentences
the value of target is usually determined based on golden summaries
if a sentence is included in a majority of human written extracts its target is near to
in contrast it would be closer to if the sentence could not be found in any human made summaries
in some datasets like the one we used golden summaries are not absolutely extractive and they are not composed of exact copies of sentences in the original text
in such cases a measure of similarity between the sentence whose target we are looking for and each ideal summaries sentence will be calculated
this results in real values between and for this attribute
section includes more details about target assignment
a preprint september figure an excerpt of whole feature set
sc and sp under topical category stand for science and sport respectively


training model since target attribute values vary between zero and one we opted to use regression methods for the learning task
to build a training and a test set a global matrix is composed in which every row corresponds to a sentence in the corpus and each column corresponds to a feature
the last column is for target attribute which will be omitted in the test set
it might be required to perform scaling on certain columns depending on its corresponding feature and range of values
in cases where the dataset is large the total number of sentences which are not included in golden summaries and consequently have lower targets is many times larger than the number of included sentences
this might lead the regression bias toward lower target values
to avoid this dataset balancing is needed
that is to leave aside a portion of not included sentences and not to feed them to learner model
lastly in this phase the regression model should be tted on training set and be evaluated on a test set as described in sections and

summarization phase

feature extraction

sentence ranking having acquired a model that can precisely rank sentences we can apply it to any new given text and use ranked sentences in order to create a summary
this summarization process could also be executed on dataset texts in order to evaluate how precisely our method resembles human written summaries
in this section we briey describe the summarization process
the evaluation process is explained in section

initially sentence features need to be extracted
again normalization sentence tokenization word tokenization and stop words removal are preliminary steps
the same features used in the learning phase should be calculated
in comparison with learning phase in which a global matrix was used this time a local matrix is composed whose rows correspond with the sentences of the input text
if during learning any scaling was performed on features they should be carried out here in the same manner
the matrix is then fed to the regressor obtained in the previous phase and a rank value between zero and one will be predicted for each sentence
a preprint september

sentence selection by sorting sentences based on their ranks the most appropriate sentences for being included in summary will be determined
to preserve readability however it is important to place them in the summary in the same order they appeared in the input document
another consideration is the cut off length
how many of the top sentences should we select for summary the answer should be as simple as a constant number a percentage of total sentences or it could be determined by more advanced heuristics
we allowed cut off length to be an input parameter
this allows us in the evaluation phase to produce summaries of dataset documents in the same length as golden summaries
this makes the comparison more equitable

evaluation measures in this section some measures are described to evaluate the performance of both phases explained in the previous section the learning phase and summarization phase
the former is evaluated using common regression metrics such as mean square error mse and coefcient of determination
the latter is carried out using rouge which is a well known metric for evaluating summarization systems
mean square error mse is the average of squared errors in all estimated targets
an ideal regressor tends to make this measure as near as possible to zero
though an exact zero for mse is not desirable because it is suspected to be due to over tting
the coefcient of determination is another metric for evaluating how well a regression model is tted to data
it ranges from to
as it approaches goodness is increased while negative values show that the mean of data is a better estimator for target
rouge is proposed in as an evaluation metric for summaries
it matches n grams in both system produced summaries and reference summaries and returns the percentage of matching in terms of precision recall and measure
there is a variety of rouge family metrics namely and rouge l
in the overlap of grams each word is calculated
in the bigrams are considered as units of comparison
the rouge l uses the longest common subsequence lcs to measure resemblance
nevertheless we found that rouge assessments are always relatively high even for a summary that is produced perfunctorily
hence we also designed a random summarizer that selects random sentences for the summary and evaluated it by rouge
this could be used as a baseline for comparison
experiments two experiments were set up to verify our hypothesis sentence ranking is highly dependent to document and features must also represent context
the rst experiment involves document unaware features listed in section


alongside tf isf
in the second experiment document aware features were used instead of document unaware ones
we also set up a random summarizer based on a random regressor that acts as a baseline for comparisons
more details are recorded in section

a good experimental study should be as reproducible as possible
here we explain the technical details that are more specic to our dataset to allow the interested user to set up the same experiments for further research

dataset we used the pasokh dataset that contains persian news documents each of which is associated with summaries
each summary consists of several sentences of the original text selected by a human expert
some sentences are slightly modied and are not therefore an exact copy of any original sentences
documents are categorized into six categories such as political economic and so on
the length of documents ranges from to sentences
overall it has about sentences

extracting features and scaling all features introduced in section

are calculated
pre processing sentence and word tokenization stop words removal and part of speech tagging is performed using the hazm library
the majority of features have a range between zero and one
other features are passed to a min max scaler to transform into the same range
for the category feature which is nominal the one hot encoding method applied and six ag features used instead
a preprint september table quality of the regression model s predictions on the test set
mse experiment experiment experiment random regression






target assignment in assigning the target to a sentence as mentioned in section

the goal is to assign a number between and with higher values as an indicator that the sentence is present in the majority of golden summaries
because exact matching between sentences is not possible to resolve the question of presence in a single golden summary such as g we calculated the cosine similarity of the desired sentence with each sentence sj g
then the maximum value of these similarities is selected as an indicator of presence
this indicator is then calculated for other golden summaries and their average is assigned to the sentence as the target
t gig maxsj gi sj in which g is set of summaries written for the document containing s
this is an additional explicit evidence that target and subsequently ranking is related to the document

training model a vast collection of scikit learn tools were used for the learning phase
k fold cross validation is applied with and split size of

three different regression methods were applied including linear regression decision tree regression and epsilon support vector
overall results were the same with minor differences
thus only the svr result is reported
various values for parameters were examined but the best results were achieved by
kernel rbf and default values for other parameters
with the aim of evaluating summary qualities the tted regressor of each run was used to rank documents sentences in the test set
to compare with each standard summary a summary with the same count of sentences was produced and compared by rouge
averaging these rouge scores over each document and then over the dataset the overall quality of summaries produced by the model can be obtained
the same process was repeated with a random regressor that needed no training and which simply assigns a random number between zero and one to any given sample
apart from measuring the performance of this regressor on the test set the quality of summaries produced is evaluated and reported as a baseline
the juxtaposition of this baseline and our measured results will demonstrate how effective our feature set was and how intelligent our whole system worked
results and discussion in section
mse and rouge scores are remarked as evaluation measures
the results of our experiments are reported below in terms of these measures
for better comparison we also ran another experiment in which the random regressor was used for ranking sentences and producing summaries
table shows and compares mse and reported from these experiments
the results show that in experiment the mean squared error is reduced and the score is increased
this means that using document aware features leads to a more accurate learned model proving our hypothesis about the relationship between document features and target ranks
rouge scores are displayed separately in terms of precision recall and measure in figures to respectively
f measure scores are displayed in the gure comparing and rouge l
figures and allow comparison of precision and recall scores
the higher values gained in experiment conrm that document aware features perform better than unaware features
these results are also interpretable from viewpoint of entropy based decision tree methods
in learning phase impurity of features within the whole dataset will be measured and features having higher information gain will take place in upper levels of tree
but in summarization phase within which decisions have to be made within a single document impurity of those features may be low causing less effective decisions and precision
by incorporating document features we help model to use different features thus different trees for different documents
another insight gained from these charts is that a random summarizer resulted in scores more than in all measures and without using document aware features the model achieves a small improvement over a random summarizer
a preprint september figure rouge quality of produced summaries in terms of measure
figure rouge quality of produced summaries in term of precision
figure rouge quality of produced summaries in term of recall
a preprint september conclusion this paper has discussed that in supervised extractive summarization we can not learn to rank by considering dataset sentences as independent educational examples
the rank of sentences is dependent on each other within a document
to overcome this issue we suggested incorporating document features explicitly in the feature vector of sentences
we also suggested using features that take into account the properties of document
we named this kind of features as document aware
conducted experiments demonstrated the benet of adding explicit document features as well as document aware features both in model precision and summary quality
for future work more document aware features can be examined
it is also possible to run the same experiments on an english or any other language dataset if available
another clue for study is measuring degree of entropy difference between dataset and single documents in a standard dataset
our source code is hosted on and is published for later reference further experiments and reproducing results
a web and a telegram is also implemented as demo
references rashmi mishra jiantao bian marcelo fiszman charlene r weir siddhartha jonnalagadda javed mostafa and guilherme del fiol
text summarization in the biomedical domain a systematic review of recent research
journal of biomedical informatics
t sakai and k sparck jones
generic summaries for indexing in information retrieval
proceedings of the annual international acm sigir conference on research and development in information retrieval pp pages
m buenaga j hidalgo and acm
maa lpez m
gmez multidocument summarization an added value to clustering in interactive retrieval
on information systems
d roussinov and h chen
information navigation on the web by clustering and summarizing query results
information processing and management
a turpin y tsegay d hawking and h williams
fast generation of result snippets in web search
proceedings of the annual international acm sigir conference on research and development in information retrieval pp pages
kathleen mckeown rebecca j
passonneau david k
elson ani nenkova and julia hirschberg
do summaries help a task based evaluation of multi document summarization
in sigir proceedings of the annual international acm sigir conference on research and development in information retrieval
rafael ferreira frederico freitas luciano de souza cabral rafael dueire lins rinaldo lima gabriel frana steven j simske and luciano favaro
a context based text summarization system
in document analysis systems das iapr international workshop on pages
ieee
araly barrera and rakesh verma
combining syntax and semantics for automatic extractive single document summarization
in lecture notes in computer science including subseries lecture notes in articial intelligence and lecture notes in bioinformatics
vishal gupta computer science and gurpreet singh lehal
a survey of text summarization extractive techniques
journal of emerging technologies in web intelligence
kam fai wong mingli wu and wenjie li
extractive summarization using supervised and semi supervised learning
proceedings of the international conference on computational linguistics volume pages
t hirao h isozaki e maeda and y matsumoto
extracting important sentences with support vector machines
coling proceedings of the international conference on computational linguisticsvolume pp
juan manuel torres moreno
automatic text summarization
john wiley sons
a patil k pharande d nale and r agrawal
automatic text summarization
international journal of computer applications

com hrezaei summbot
ir summ form
me a preprint september janara christensen stephen soderland oren etzioni al
towards coherent multi document summarization
in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies pages
gunes erkan and dragomir r
radev
lexpagerank prestige in multi document text summarization
ings of the conference on empirical methods in natural language processing emnlp pages
a nenkova l vanderwende and k mckeown
a compositional context sensitive multi document summarizer exploring the factors that inuence summarization
proceedings of the annual international acm sigir conference on research and development in information retrieval pp pages
m gambhir and v gupta
recent automatic text summarization techniques a survey
articial intelligence review
ramakrishna varadarajan and vagelis hristidis
a system for query specic document summarization
international conference on information and knowledge management proceedings pages
udo hahn and inderjeet mani
the challenges of automatic summarization
computer
n moratanch and s chitrakala
a survey on abstractive text summarization
international conference on circuit in power and computing technologies iccpct pp pages
elena lloret and manuel palomar
text summarisation in progress a literature review
articial intelligence review
rada mihalcea and paul tarau
textrank bringing order into text
in proceedings of the conference on empirical methods in natural language processing pages
rasmita rautray and rakesh chandra balabantaray
an evolutionary framework for multi document tion using cuckoo search approach mdscsa
applied computing and informatics
g silva r ferreira r lins l cabral h oliveira s simske m riss and acm
automatic text document summarization based on machine learning
proceedings of the on document engineering pp pages
fatemeh shaee and mehrnoush shamsfard
similarity versus relatedness a novel approach in extractive persian document summarisation
journal of information science
y ouyang w li s li and q lu
applying regression models to query focused multi document summarization
information processing and management
m fattah
a hybrid machine learning model for multi document summarization
applied intelligence
c fang d mu z deng and z wu
word sentence co ranking for automatic extractive text summarization
expert systems with applications
h edmundson
new methods in automatic extracting
journal of the acm
m fattah f ren and technology international
automatic text summarization
world academy of science engineering and of computer electrical automation control and information engineering
a dlikman
using machine learning methods and linguistic features in single document extractive summarization
dmnlppkddecml pages
r ferreira l cabral r lins g silva f freitas g cavalcanti and l favaro
assessing sentence scoring techniques for extractive text summarization
expert systems with applications
c lin
y

training a selection function for extraction
proceedings of the eighth international conference on information and knowledge management pp pages
m ozsoy f alpaslan and i cicekli
text summarization using latent semantic analysis
journal of information science
joel larocca neto alex a freitas and celso aa kaestner
automatic text summarization using a machine learning approach
in brazilian symposium on articial intelligence pages
springer
j yeh h ke w yang and i meng
y


h

text summarization using a trainable summarizer and latent semantic analysis
information processing and management
m berenjkoub and m palhang
persian text summarization using a supervised machine learning approach
proceedings of the robocup iranopen symposium and irans joint conference of robotics and ai tehran iran
a preprint september l suanmali n salim and m binwahlan
fuzzy logic based method for improving text summarization
arxiv preprint
r verma f filozov cs technical and uh report
document map and wn sum a new framework for automatic text summarization and a rst implementation
university of houston computer science dept pages
jl neto ad santos and caa kaestner
document clustering and text summarization
proceedings of the international conference



n nagelkerke
a note on a general denition of the coefcient of determination
biometrika
c lin and a
y

rouge for automatic evaluation of summaries
text summarization branches out proceedings of the workshop pp pages
b moghaddas m kahani s toosi a pourmasoumi and a estiri
pasokh a standard corpus for the evaluation of persian text summarizers
iccke pp
sobhe
sobhe hazm python library for digesting persian text

com sobhe hazm aug

