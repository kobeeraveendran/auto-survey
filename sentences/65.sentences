e f l c
s
c
v
v
i x r a variations of the similarity function of textrank for automated summarization federico federico luis rosita facultad de ingeniera universidad de buenos aires ciudad autonoma de buenos aires argentina

universidad nacional tres de febrero caseros argentina

abstract
this article presents new alternatives to the similarity
tion for the textrank algorithm for automated summarization of texts

we describe the generalities of the algorithm and the dierent functions we propose
some of these variants achieve a signicative improvement using the same metrics and dataset as the original publication
keywords textrank variations automated summarization tion retrieval ranking functions introduction in the eld of natural language processing an extractive summarization task can be described as the selection of the most important sentences in a document

using dierent levels of compression a summarized version of the document of arbitrary length can be obtained

textrank is a graph based extractive summarization algorithm
it is domain and language independent since it does not require deep linguistic knowledge nor domain or language specic annotated corpora
these features makes the algorithm widely used it performs well summarizing structured text like news articles but it has also shown good results in other usages such as summarizing meeting transcriptions and assessing web content credibility
in this article we present dierent proposals for the construction of the graph and report the results obtained with them

the rst sections of this article describe previous work in the area and an overview of the textrank algorithm
then we present the variations and describe the dierent metrics and dataset used for the evaluation
finally we report the results obtained using the proposed changes
previous work the eld of automated summarization has attracted interest since the late s

traditional methods for text summarization analyze the frequency of words or sentences in the rst paragraphs of the text to identify the most important lexical elements
the mainstream research in this eld emphasizes extractive proaches to summarization using statistical methods
several statistical els have been developed based on training corpora to combine dierent heuristics using keywords position and length of sentences word frequency or titles
other methods are based in the representation of the text as a graph
the graph based ranking approaches consider the intrinsic structure of the texts stead of treating texts as simple aggregations of terms
thus it is able to capture and express richer information in determining important concepts
the selected text fragments to use in the graph construction can be phrases
sentences or paragraphs
currently many successful systems adopt the sentences considering the tradeo between content richness and grammar correctness
according to these approach the most important sentences are the most connected ones in the graph and are used for building a nal summary

to identify relations between sentences edges for the graph there are eral measures overlapping words cosine distance and query sensitive similarity

also some authors have proposed combinations of the previous with supervised learning functions
these algorithms use dierent information retrieval techniques to determine the most important sentences vertices and build the summary
the trank algorithm developed by mihalcea and tarau and the lexrank gorithm by erkan and radev are based in ranking the lexical units of the text sentences or words using variations of pagerank

other graph based ranking algorithms such as hits or positional function may be also applied
textrank
description
textrank is an unsupervised algorithm for the automated summarization of texts that can also be used to obtain the most important keywords in a document

it was introduced by rada mihalcea and paul tarau in

the algorithm applies a variation of pagerank
over a graph constructed specically for the task of summarization
this produces a ranking of the ements in the graph the most important elements are the ones that better describe the text
this approach allows textrank to build summaries without the need of a training corpus or labeling and allows the use of the algorithm with dierent languages
text as a graph for the task of automated summarization textrank models any document as a graph using sentences as nodes
a function to compute the similarity of sentences is needed to build edges in between
this function is used to weight the graph edges the higher the similarity between sentences the more important the edge between them will be in the graph
in the domain of a random walker as used frequently in pagerank we can say that we are more likely to go from one sentence to another if they are very similar
textrank determines the relation of similarity between two sentences based on the content that both share
this overlap is calculated simply as the number of common lexical tokens between them divided by the lenght of each to avoid promoting long sentences
the function featured in the original algorithm can be formalized as denition
given si sj two sentences represented by a set of n words that in si are represented as si wi wi

the similarity function for si sj can be dened as wi sj

the result of this process is a dense graph representing the document
from this graph pagerank is used to compute the importance of each vertex
the most signicative sentences are selected and presented in the same order as they appear in the document as the summary
experiments our variations
this section will describe the dierent modications that we propose over the original textrank algorithm
these ideas are based in changing the way in which distances between sentences are computed to weight the edges of the graph used for pagerank
these similarity measures are orthogonal to the textrank model thus they can be easily integrated into the algorithm
we found some of these variations to produce signicative improvements over the original algorithm

longest common substring from two sentences we identify the longest common substring and report the similarity to be its length
cosine distance
the cosine similarity is a metric widely used to compare texts represented as vectors
we used a classical tf idf model to represent the documents as vectors and computed the cosine between vectors as a measure of similarity
since the vectors are dened to be positive the cosine results in values in the range where a value of represents identical vectors and represents orthogonal vectors

okapi is a ranking function widely used as the state of the art for information retrieval tasks
is a variation of the tf idf model using a probabilistic model
denition
given two sentences r s is dened as bm s idf n r
r b avgdl where and b are parameters
we used k and
avgdl is the average length of the sentences in our collection
this function denition implies that if a word appears in more than half the documents of the collection it will have a negative value
since this can cause problems in the next stage of the algorithm we used the following correction formula idf avgidf if
if where takes a value between and and avgidf is the average idf for all terms
other corrective strategies were also tested setting and using simpler modications of the classic idf formula
we also used a variation of that changes the way long ments are penalized
evaluation for testing the proposed variations we used the database of the document understanding conference duc

the corpus has documents that are summarized to of their size and is the same corpus used in
to evaluate results we used version of the rouge package
the conguration settings were the same as those in duc where and rouge were used as metrics using a condence level of and applying stemming
the nal result is an average of these three scores
to check the correct behaviour of our test suite we implemented the ence method used in which extracts the rst sentences of each document

we found the resulting scores of the original algorithm to be identical to those reported in a improvement over the baseline
results we tested lcs cosine sim and as dierent ways to weight the edges for the textrank graph
the best results were obtained using and with the corrective formula shown in equation
we achieved table
evaluation results for the proposed textrank variations
method rouge improvement

cosine tf idf
idf

idf

longest common substring


textrank

duc baseline


fig
and scores comparison
an improvement of above the original textrank result using and
the following chart shows the results obtained for the dierent tions we proposed
the result of cosine similarity was also satisfactory with a

ment over the original method
the lcs variation also performed better than the original textrank algorithm with total improvement

the performance in time was also improved
we could process the uments from the database in of the time needed in the original version


costf

costf reference implementation and gensim contribution a reference implementation of our proposals was coded as a python and can be obtained for testing and to reproduce results
we also contributed the textrank algorithm to the gensim
conclusions
this work presented three dierent variations to the textrank algorithm for tomatic summarization
the three alternatives improved signicantly the results of the algorithm using the same test conguration as in the original publication
given that textrank performs over the baseline our improvement of over the textrank score is an important result

the combination of textrank with modern information retrieval ranking functions such as and creates a robust method for automatic summarization that performs better than the standard techniques used ously

based on these results we suggest the use of along with textrank for the task of unsupervised automatic summarization of texts
the results obtained and the examples analyzed show that this variation is better than the original textrank algorithm without a performance penalty

references
balcerzak jaworski wierzbicki application of textrank algorithm for credibility assessment
in proceedings of the ieee wic acm international joint conferences on web intelligence wi and intelligent agent technologies
iat volume
pp

wi iat ieee computer society washington dc usa
barzilay mckeown sentence fusion for multidocument news tion
computational linguistics trier
db journals coling
christopher manning prabhakar raghavan introduction to information retrieval
cambridge university press
das martins
a survey on automatic text summarization
tech rep carnegie mellon university language technologies institute
document understanding conference duc guidelines july
ercan cicekli using lexical chains for keyword extraction
inf
process

manage
nov
source code available at source code available at
erkan radev
lexrank graph based lexical centrality as salience in text summarization
artif
intell
res
jair

garg favre riedhammer hakkani tur clusterrank a graph based method for meeting summarization
in interspeech annual ference of the international speech communication association brighton united kingdom september
pp
speech
org archive
guseld algorithms on strings trees and sequences computer science and computational biology
cambridge university press new york ny usa
herings van der laan talman
measuring the power of nodes in digraphs
research memorandum maastricht university maastricht research school of economics of technology and organization meteor unm
kleinberg
authoritative sources in a hyperlinked environment
acm sep
lin
rouge a package for automatic evaluation of summaries
in proceedings of the workshop on text summarization branches out was barcelona spain
lin hovy
identifying topics by position
in proceedings of ference on applied natural language processing
washington march

luhn
the automatic creation of literature abstracts
ibm res
dev
apr
lv zhai lower bounding term frequency normalization
in proceedings of the acm conference on information and knowledge management cikm glasgow united kingdom october
pp

mihalcea graph based ranking algorithms for sentence extraction applied to text summarization
in proceedings of the acl on interactive poster and demonstration sessions
acldemo association for computational linguistics stroudsburg pa usa
mihalcea tarau textrank bringing order into texts
in lin wu eds
proceedings of emnlp
pp

association for computational
linguistics barcelona spain july
mitrat singhal buckleytt automatic text summarization by graph extraction
in intelligent scalable text summarization
pp

ouyang li wei lu
learning similarity functions in based document summarization
in li aliod eds
iccpol
ture notes in computer science vol
pp

springer db conf iccpol
page brin motwani winograd
the pagerank citation ranking bringing order to the web
in proceedings of the international world wide web conference
pp

brisbane australia
rehurek sojka software framework for topic modelling with large pora
in proceedings of the lrec workshop on new challenges for nlp frameworks
pp

elra valletta malta may en
robertson walker jones hancock beaulieu gatford okapi at
in proceedings of the third text retrieval conference trec gaithersburg maryland usa november
pp
pubs papers
salton singhal mitra buckley automatic text structuring and summarization
information processing and management

singhal modern information retrieval a brief overview
bulletin of the ieee computer society technical committee on data engineering
