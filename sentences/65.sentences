e f l c
s c v
v i x r a variations of the similarity function of textrank for automated summarization federico federico luis rosita facultad de ingeniera universidad de buenos aires ciudad autonoma de buenos aires argentina
universidad nacional tres de febrero caseros argentina
fbarrios
uba
ar abstract
this article presents new alternatives to the similarity tion for the textrank algorithm for automated summarization of texts
we describe the generalities of the algorithm and the dierent functions we propose
some of these variants achieve a signicative improvement using the same metrics and dataset as the original publication
keywords textrank variations automated summarization tion retrieval ranking functions introduction in the eld of natural language processing an extractive summarization task can be described as the selection of the most important sentences in a document
using dierent levels of compression a summarized version of the document of arbitrary length can be obtained
textrank is a graph based extractive summarization algorithm
it is domain and language independent since it does not require deep linguistic knowledge nor domain or language specic annotated corpora
these features makes the algorithm widely used it performs well summarizing structured text like news articles but it has also shown good results in other usages such as summarizing meeting transcriptions and assessing web content credibility
in this article we present dierent proposals for the construction of the graph and report the results obtained with them
the rst sections of this article describe previous work in the area and an overview of the textrank algorithm
then we present the variations and describe the dierent metrics and dataset used for the evaluation
finally we report the results obtained using the proposed changes
previous work the eld of automated summarization has attracted interest since the late s
traditional methods for text summarization analyze the frequency of words or sentences in the rst paragraphs of the text to identify the most important lexical elements
the mainstream research in this eld emphasizes extractive proaches to summarization using statistical methods
several statistical els have been developed based on training corpora to combine dierent heuristics using keywords position and length of sentences word frequency or titles
other methods are based in the representation of the text as a graph
the graph based ranking approaches consider the intrinsic structure of the texts stead of treating texts as simple aggregations of terms
thus it is able to capture and express richer information in determining important concepts
the selected text fragments to use in the graph construction can be phrases sentences or paragraphs
currently many successful systems adopt the sentences considering the tradeo between content richness and grammar correctness
according to these approach the most important sentences are the most connected ones in the graph and are used for building a nal summary
to identify relations between sentences edges for the graph there are eral measures overlapping words cosine distance and query sensitive similarity
also some authors have proposed combinations of the previous with supervised learning functions
these algorithms use dierent information retrieval techniques to determine the most important sentences vertices and build the summary
the trank algorithm developed by mihalcea and tarau and the lexrank gorithm by erkan and radev are based in ranking the lexical units of the text sentences or words using variations of pagerank
other graph based ranking algorithms such as hits or positional function may be also applied
textrank
description textrank is an unsupervised algorithm for the automated summarization of texts that can also be used to obtain the most important keywords in a document
it was introduced by rada mihalcea and paul tarau in
the algorithm applies a variation of pagerank over a graph constructed specically for the task of summarization
this produces a ranking of the ements in the graph the most important elements are the ones that better describe the text
this approach allows textrank to build summaries without the need of a training corpus or labeling and allows the use of the algorithm with dierent languages

text as a graph for the task of automated summarization textrank models any document as a graph using sentences as nodes
a function to compute the similarity of sentences is needed to build edges in between
this function is used to weight the graph edges the higher the similarity between sentences the more important the edge between them will be in the graph
in the domain of a random walker as used frequently in pagerank we can say that we are more likely to go from one sentence to another if they are very similar
textrank determines the relation of similarity between two sentences based on the content that both share
this overlap is calculated simply as the number of common lexical tokens between them divided by the lenght of each to avoid promoting long sentences
the function featured in the original algorithm can be formalized as denition
given si sj two sentences represented by a set of n words that in si are represented as si wi


wi n
the similarity function for si sj can be dened as wi sj the result of this process is a dense graph representing the document
from this graph pagerank is used to compute the importance of each vertex
the most signicative sentences are selected and presented in the same order as they appear in the document as the summary
experiments
our variations this section will describe the dierent modications that we propose over the original textrank algorithm
these ideas are based in changing the way in which distances between sentences are computed to weight the edges of the graph used for pagerank
these similarity measures are orthogonal to the textrank model thus they can be easily integrated into the algorithm
we found some of these variations to produce signicative improvements over the original algorithm
longest common substring from two sentences we identify the longest common substring and report the similarity to be its length
cosine distance the cosine similarity is a metric widely used to compare texts represented as vectors
we used a classical tf idf model to represent the documents as vectors and computed the cosine between vectors as a measure of similarity
since the vectors are dened to be positive the cosine results in values in the range where a value of represents identical vectors and represents orthogonal vectors
okapi is a ranking function widely used as the state of the art for information retrieval tasks
is a variation of the tf idf model using a probabilistic model
denition
given two sentences r s is dened as bm s idf n r r b avgdl where and b are parameters
we used k
and

avgdl is the average length of the sentences in our collection
this function denition implies that if a word appears in more than half the documents of the collection it will have a negative value
since this can cause problems in the next stage of the algorithm we used the following correction formula idf

avgidf if if where takes a value between
and
and avgidf is the average idf for all terms
other corrective strategies were also tested setting and using simpler modications of the classic idf formula
we also used a variation of that changes the way long ments are penalized

evaluation for testing the proposed variations we used the database of the document understanding conference duc
the corpus has documents that are summarized to of their size and is the same corpus used in
to evaluate results we used version

of the rouge package
the conguration settings were the same as those in duc where and rouge were used as metrics using a condence level of and applying stemming
the nal result is an average of these three scores
to check the correct behaviour of our test suite we implemented the ence method used in which extracts the rst sentences of each document
we found the resulting scores of the original algorithm to be identical to those reported in a
improvement over the baseline

results we tested lcs cosine sim and as dierent ways to weight the edges for the textrank graph
the best results were obtained using and with the corrective formula shown in equation
we achieved table
evaluation results for the proposed textrank variations
method rouge improvement

cosine tf idf idf idf longest common substring textrank duc baseline














































fig

and scores comparison
an improvement of
above the original textrank result using and

the following chart shows the results obtained for the dierent tions we proposed
the result of cosine similarity was also satisfactory with a
ment over the original method
the lcs variation also performed better than the original textrank algorithm with
total improvement
the performance in time was also improved
we could process the uments from the database in of the time needed in the original version


costf




costf




reference implementation and gensim contribution a reference implementation of our proposals was coded as a python and can be obtained for testing and to reproduce results
we also contributed the textrank algorithm to the gensim
conclusions this work presented three dierent variations to the textrank algorithm for tomatic summarization
the three alternatives improved signicantly the results of the algorithm using the same test conguration as in the original publication
given that textrank performs
over the baseline our improvement of
over the textrank score is an important result
the combination of textrank with modern information retrieval ranking functions such as and creates a robust method for automatic summarization that performs better than the standard techniques used ously
based on these results we suggest the use of along with textrank for the task of unsupervised automatic summarization of texts
the results obtained and the examples analyzed show that this variation is better than the original textrank algorithm without a performance penalty
references
balcerzak b
jaworski w
wierzbicki a
application of textrank algorithm for credibility assessment
in proceedings of the ieee wic acm international joint conferences on web intelligence wi and intelligent agent technologies iat volume
pp

wi iat ieee computer society washington dc usa


wi iat


barzilay r
mckeown k
sentence fusion for multidocument news tion
computational linguistics
uni trier
db journals coling

christopher d
manning prabhakar raghavan h
s
introduction to information retrieval
cambridge university press
das d
martins a
f
t
a survey on automatic text summarization
tech
rep
carnegie mellon university language technologies institute
document understanding conference duc guidelines july www nlpir
nist
gov projects duc
html
ercan g
cicekli i
using lexical chains for keyword extraction
inf
process
manage
nov


j
ipm


source code available at
com summanlp textrank source code available at
com summanlp gensim
erkan g
radev d
r
lexrank graph based lexical centrality as salience in text summarization
j
artif
intell
res
jair
uni trier
db journals jair

garg n
favre b
riedhammer k
hakkani tur d
clusterrank a graph based method for meeting summarization
in interspeech annual ference of the international speech communication association brighton united kingdom september
pp

isca speech
org archive
html
guseld d
algorithms on strings trees and sequences computer science and computational biology
cambridge university press new york ny usa
herings p
j
j
van der laan g
talman d
measuring the power of nodes in digraphs
research memorandum maastricht university maastricht research school of economics of technology and organization meteor
repec
org unm
kleinberg j
m
authoritative sources in a hyperlinked environment
j
acm sep
acm



lin c
y
rouge a package for automatic evaluation of summaries
in proceedings of the workshop on text summarization branches out was barcelona spain
lin c
y
hovy e
h
identifying topics by position
in proceedings of ference on applied natural language processing
washington d
c
march
luhn h
p
the automatic creation of literature abstracts
ibm j
res
dev
apr


rd


lv y
zhai c
lower bounding term frequency normalization
in proceedings of the acm conference on information and knowledge management cikm glasgow united kingdom october
pp

mihalcea r
graph based ranking algorithms for sentence extraction applied to text summarization
in proceedings of the acl on interactive poster and demonstration sessions
acldemo association for computational linguistics stroudsburg pa usa




mihalcea r
tarau p
textrank bringing order into texts
in lin d
wu d
eds
proceedings of emnlp
pp

association for computational linguistics barcelona spain july
mitrat m
singhal a
buckleytt c
automatic text summarization by graph extraction
in intelligent scalable text summarization
pp

aclweb
org anthology
ouyang y
li w
wei f
lu q
learning similarity functions in based document summarization
in li w
aliod d
m
eds
iccpol
ture notes in computer science vol
pp

springer
uni trier
db conf iccpol

page l
brin s
motwani r
winograd t
the pagerank citation ranking bringing order to the web
in proceedings of the international world wide web conference
pp

brisbane australia citeseer
nj
nec

html
rehurek r
sojka p
software framework for topic modelling with large pora
in proceedings of the lrec workshop on new challenges for nlp frameworks
pp

elra valletta malta may
muni

robertson s
walker s
jones s
hancock beaulieu m
gatford m
okapi at
in proceedings of the third text retrieval conference trec gaithersburg maryland usa november
pp

nist
gov pubs papers city
ps
gz
salton g
singhal a
mitra m
buckley c
automatic text structuring and summarization
information processing and management
singhal a
modern information retrieval a brief overview
bulletin of the ieee computer society technical committee on data engineering
info
pdf
