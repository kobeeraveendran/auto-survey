biclustering readings and manuscripts via non negative matrix factorization with application to the text of jude joey mccollum and stephen brown abstract
the text critical practice of grouping witnesses into families or texttypes often faces two obstacles contamination in the manuscript tion and co dependence in identifying characteristic readings and manuscripts
we introduce non negative matrix factorization nmf as a simple vised and efficient way to cluster large numbers of manuscripts and readings simultaneously while summarizing contamination using an easy to interpret mixture model
we apply this method to an extensive collation of the new testament epistle of jude and show that the resulting clusters correspond to human identified textual families from existing research

introduction genealogical analysis has had a prominent role in new testament nt critical theory even before it was popularized in the work of westcott and hort
indeed one of the steps in their approach that of classifying manuscripts mss into families and texttypes based on their shared readings goes back over a century and a half earlier to the works of mill bentley and bengel
in theory the rationale for this is that the more two mss agree in their readings the more likely they are to represent a close common ancestor or to have an exemplar copy relationship themselves the goal is that by grouping witnesses in this way the critic can then weigh them according to how purely they represent their group or how derivative they are from common sources
the theory is not without obstacles however
despite the emphasis they placed on the genealogical method westcott and hort misused the method by overlooking the effects of contamination or mixture of readings characteristic of different types on the genealogy they were attempting to derive
it turns out that such mixture is somewhat ubiquitous
indeed as more mss are discovered and studied placing them into families and texttypes by hard assignment only blurs the lines between these groups even more
an additional complication in the assignment of mss to groups is the dual problem of assigning readings to groups
any two witnesses will probably agree in a majority of their readings so simply counting places of agreement is insufficient
in order to classify texts into well defined well separated groups we must determine which readings are the most significant for this purpose
so we must first determine the readings that the most characteristic mss of a group share and that few or no other mss share
but in order for us to do this the mss must be assigned to groups already
this leaves us with a problem of co dependence characteristic mss of a given type are determined by which characteristic readings they have date february
mathematics subject classification

key words and phrases
textual criticism text analysis text mining text types classification machine learning nonnegative matrix factorization nmf new testament jude
j
mccollum and s
brown and characteristic readings of a given type are determined by which characteristic mss attest to them
these observations have spurred the increased use of approaches that exchange the assumptions of texttype theory for other assumptions
seeing the benefits of these methods some researchers have started to question the continued relevance of methods based on texttypes
others have proposed to abandon the underlying theory altogether
yet the idea of texttypes has not been rejected universally
epp for one has argued for its continued value
more generally the assumptions made by other methods introduce limitations of their own some of which the theory of texttypes can overcome
it is also important to recognize that texttype based methods and newer approaches are not mutually exclusive but can be used in conjunction to achieve more refined results
we will elaborate on these points briefly
the main implication of our work with regard to theory however is that contamination and co dependence are not truly insurmountable obstacles to texttype based methods as we will show both issues can in fact be handled
in this paper we present non negative matrix factorization nmf as a simple unsupervised and efficient computer based method for isolating clusters of mss and their most important readings simultaneously
it is a pre genealogical method only in the sense that it does not infer any directed relationships among readings texts or groups
as such it is not intended to replace more complex genealogical methods but to help researchers generate hypotheses that these methods can test and refine
in the first section we review known classification methods with their advantages and disadvantages
in the second section we show how nmf addresses the problems of contamination and co dependence and discuss its advantages over other methods
this section involves some mathematics but the more technical details can be found in the references
in the third section we describe our plication of nmf to tommy wasserman s full collation of mss of the epistle of jude
in the last section we show that the use of nmf in different settings yields results in the form of recognizable texttypes and families established in the literature

state of the art the history of textual criticism has seen the development of numerous cation methods
we will not attempt an exhaustive treatment here but instead focus our attention on the following generalizations base text this method used in nt textual criticism at its earliest stages classifies ms texts based on their deviations from a single base of readings
the base could be anything but historically it was the textus receptus tr
classes were formed based on their common agreements against the base text
quantitative this method introduced by colwell compares the text of each ms to that of every other ms
similarity is generally measured as a simple count or proportion of readings at which two texts agree
the set of pairwise similarity measures is then used to group texts according to a variety of algorithms
profile the claremont profile method cpm developed by mcreynolds and wisse improves the efficiency and classification power of ing methods by taking identified groups and determining which patterns of readings provide the best profile for each group
these profiles can then be used to determine the most likely group of an unclassified text and the strength of a classified text s group membership
biclustering readings and manuscripts factor analysis this method which has been developed and put to use extensively at andrews university first determines the factors or combinations of readings that are most correlated to one another among ms texts and then groups mss by their strongest factors
in this way it combines the text side approach of with the reading side approach of
stemmatic stemmatic methods aim for a more precise and structured classification of texts by examining changes in every variation unit between extant texts and nodes representing their potential ancestors
the goal is to construct an undirected stemma of maximum parsimony or the fewest changed readings along all links of the stemma
examples of these methods can be found in the recent work of spencer wachtel and howe
coherence based the coherence based genealogical method cbgm veloped by mink improves by producing directed stemmata that are robust to contamination
it starts by constructing a directed local stemma for the readings at each variation unit based on general agreement among readings witnesses and transcriptional probability so that readings have prior and posterior relationships
then it constructs a directed cal stemma for the texts at each unit based on their general agreement and their relative proportions of prior and posterior readings where they disagree
these first two steps are applied iteratively to account for the co dependent relationship of good readings and good texts
finally the local stemmata of texts are merged to form a global stemma that mizes the objective of simplicity i
e
as few ancestors to a text as possible under the constraint that the directed relationships of all readings are served
a useful introduction can be found in wachtel s recent feature on the method
we will summarize each method s advantages and disadvantages below
method is simple to understand but it has many shortcomings
it requires the assumption of a base text and it only defines groups in terms of their ments with this text when their agreements might also be informative
because it offers no procedure for deciding which readings are the most signficant in ing groups it also fails to address the problem of co dependence between readings and texts
typically the evaluation of which readings are important is done under human supervision and can be slow for a large number of readings
this method can account for contamination but only after groups have been determined
a brief discussion of this method can be found in ehrman s essay on classification methods
method presents easy to interpret results requires no human supervision and dispenses with the unnecessary assumption of a base text
its major tage is its computational cost building a table of pairwise similarity measures for n mss requires comparisons which becomes inconvenient for a large number of mss
because it counts readings rather than weighing them it fails to address the problem of co dependence
typical clustering algorithms do not accommodate contamination
method is much more efficient by design than produces results that are simple to understand and can identify and quantify contamination between groups in a ms s text
its greatest weakness is that it does not identify the groups to be profiled but assumes that they are known
it therefore does not even attempt has in fact been criticized on the basis of its application with poorly identified groups
because of this it is best used in conjunction with methods like or
j
mccollum and s
brown to address the problem of co dependence
finally despite its efficiency it is a supervised method so it will not be as fast as some computer based methods
method is extremely efficient is unsupervised and does not require the assumption of a base text
as such it could reasonably be said to supersede method as a quantitative method
furthermore the way the method fits readings and texts together in factors may be considered an adequate approach to the problem of co dependence
the drawback is that the results of factor analysis can be difficult to interpret the method often assigns a negative coefficient for one or more groups to a text and there is no obvious sense of what that means
the problem is that factor analysis does not provide a model that accounts for additive mixture between groups
naturally this becomes an obstacle to identifying contamination
for these reasons factor analysis is often refined using method p

method is unsupervised and it makes no assumptions about a base text
furthermore unlike methods it avoids controversy over the use of texttypes by focusing instead on transmissional details at the level of individual texts and readings
the price of this level of detail of course is complexity in implementation the construction of an optimal stemma is a computationally expensive task so one must sacrifice accuracy to complete it in an acceptable amount of time
the other major disadvantage is that simple stemmata can not account for contamination
in addition simple stemmatic approaches make no statements about good texts or readings until one has to orient the stemma
method accounts for the problems of contamination and co dependence tween texts and readings without requiring any assumptions about underlying types
in other areas however it is lacking
first it is a supervised method
ond between the initialization of a pairwise ms coherence table and the supervised construction of local stemmata the method is very time consuming
third and haps most importantly it requires the assumption of a working initial text which for all practical purposes is tantamount to the base text assumption of method
this assumption severely limits the scope of what can be achieved cbgm can help refine existing hypotheses but it can not compare significantly different hypotheses
cbgm has risen to prominence relatively recently having only been applied on a large scale to the catholic epistles and acts
during that time it has seen discussion as well as criticism
as we will show nmf combines many of best qualities of methods
it it is unsupervised and extremely fast even with does not rely on a base text
data as large as wasserman s jude collation
it performs biclustering on mss and readings at the same time so it does not need a profile method to be applied on top of it
most importantly nmf finds an equilibrium in the co dependent relationship of good witnesses and good readings and it does so in a way that is robust to contamination between groups
as nmf models mixture additively its results are easy to interpret
see table for a comparison of methods and nmf
of course nmf relies on the assumptions of texttype theory so it is subject to the criticisms of that theory
even so while a comprehensive discussion of texttype theory and its relevance is beyond the scope of this paper it should be noted that the results of nmf can still be used to benefit other methods in the pre processing stage
cbgm and other stemmatic methods for instance are often applied only to a sample of all available mss and readings for the sake of time and computational resources nmf can provide a smart selection of significant mss and readings in this situation
more information see houghton s survey wasserman s overview and tc featured articles on cbgm at rosetta
reltech
org tc index
html
biclustering readings and manuscripts table
comparison of textual classification methods
the text column label refers to the assumption of a base or working initial text the texttypes label to the assumption of ing texttypes the unsup
label to the question of whether the method is unsupervised the fast label to whether the method is efficient and the contam
and co dep
labels to whether the method is robust to contamination and co dependence tively
a text texttypes unsup
fast contam
co dep
base text quantitative profile factor analysis stemmatic coherence based nmf
theoretical basis nmf was popularized by daniel d
lee and h
sebastian seung in their paper
since then it has found use in a wide array of fields see for a detailed survey
with regard to fields most relevant to textual criticism it has found use in text mining for the purposes of document clustering and topic modeling and in computational biology for the purposes of classifying gene expressions in dna microarrays and more recently for determining biological admixture or ancestry coefficients
the following treatment of the mathematical basis of nmf is primarily a summary but the interested reader is encouraged to refer to for details
suppose that we have a collation consisting of m readings with readings in the same variation unit treated as distinct objects and n mss
a natural way to represent this collation is an m n matrix where the rows represent the readings and the columns represent mss
a cell at row i and column j contains a if ms j attests to reading i and a otherwise
we will call this collation matrix x
a small example of such a matrix is shown in fig

ms
ms
ms
ms
unit

reading
unit

reading
unit

reading
unit

reading
unit

reading
unit

reading
unit

reading
figure
matrix representation of part of a collation
as pected each column ms only has a nonzero value in a single reading in a given unit
we want to find k latent features underlying this data
in our case the features are texttypes or textual families the larger k is the finer the groupings are
for the purposes of this application we assume that the observed readings and mss j
mccollum and s
brown have been generated by these hidden features
fig
gives an illustration of this model
m n m k n figure
a graphical illustration of the latent feature model sumed by nmf using the data from fig
and k
notice how the post factorization model weighs readings by the information they provide about a cluster and accounts for a mixture of these clusters in ms

the corresponding equation for this generative process is x wh here w called the basis matrix is an m k matrix describing the makeup of each group in terms of linear combinations of readings and h called the coefficient or mixture matrix is a k n matrix describing the makeup of each mss s text in terms of linear combinations of groups
so our goal is to find group membership coefficients for readings and for texts that when combined explain the data as best as possible
since the data matrix x is obviously non negative and we want to describe it in terms of sums of parts we restrict w and h to be non negative as well
this model has several advantages over standard clustering models first it allows readings and texts to belong to more than one cluster which is critical for providing group profiles and dealing with contamination it assigns weights to readings so that the ones more characteristic of a single cluster have higher priority than those shared among several and third it assigns weights to mss so we can see which ones are the strongest and purest representatives of their groups
the closeness of the product wh to x can be measured in a variety of ways but in this paper we will use jjx f which is the squared frobenius norm or the total sum of squared differences between each cell of x and the corresponding cell of wh
so our goal in any factorization will be to minimize this quantity
how then do we find w and h we must first choose initial matrices and ourselves either with random positive values in each cell or with an educated guess
then we alternate between updating them using the following rules biclustering readings and manuscripts arg min jjx f arg min jjx f in other words for each matrix in the factorization we fix the values of the other matrix and choose new non negative values for this matrix that minimize the value of function
clearly this means that the value of function will never increase from one step to the next but can only decrease or remain the same
until we reach a point in the process where rules and no longer change anything we iteratively update w using the current h and then update h using the new w
our aim is that by repeating these alternating optimizations we will eventually reach a fixed point in the process where function is no longer improved by these updates
at this point the reader may recognize the lurking shadow of co dependence between readings w and witnesses h
how do we know that the loop of updates wo nt reach a stable point before the objective function does and what happens if the process never reaches a fixed point as it turns out such scenarios can never happen theorem
any limit point of the sequence fwt rules and is a stationary point of function
generated by from this theorem we are guaranteed that our update process will not reach a stable point without the objective function doing the same
if we add any upper bound it can be as large as we need to ensure accuracy to the entries of w and h then we can also guarantee that the update process has at least one limit point
so nmf with objective function update rules and and arbitrarily large upper bounds on the matrix entries will always converge to a factorization that is at a stationary point of the objective function
as this analysis has shown nmf provides a natural model for identifying textual families and more than adequately addresses the problems of contamination and co dependence
with regard to contamination it not only detects the degrees and sources of contamination in individual texts but also quantifies the importance of specific readings to textual clusters
with regard to co dependence we have shown that nmf s use of iterative refinement of group readings and group witnesses is guaranteed not only to stop but to stop at a critical point of the function it is trying to minimize

application

data
we applied nmf to tommy wasserman s comprehensive collation of the epistle of jude
we considered this a good testing ground for the method for several reasons the size of the collation which might be prohibitive for more complex supervised methods can be handled efficiently and automatically by nmf
should be noted however that the process and the objective function may have more than one stationary point meaning that one nmf run may reach a locally optimal but not globally optimal factorization
it is therefore important to run nmf with good initial guesses for w and h or to repeat it many times with different random guesses
j
mccollum and s
brown the collation is complete over nearly all readings and mss
we can fore avoid any biases associated with previous selections of genealogically significant readings and texts
moreover starting with virtually all able evidence we can discover new readings and texts of significance and add confidence to existing ones whose significance we re discover
to the best of our knowledge no other application of this scale has been done with wasserman s work
we hope that our work will spark continued research involving his collation and inspire work towards collations of equal scale elsewhere in the nt
the collation covers mss including papyri and lectionaries across variation units
in encoding the data we ignored lacunae partially lacunose or uncertain readings from non continuous text sources such as correctors and units contained within larger overlapping omissions
all readings that were not skipped including omissions were then represented by their own row in the collation matrix with mss represented in columns
see fig

the result was a matrix with non zero entries
after running nmf on this matrix in different settings we observed that highly lacunose mss and singular readings were being isolated in their own clusters
this likely occurred because these witnesses and readings constituted outliers with high influence on the objective function of the factorization
to account for this we removed all singular readings from consideration and treated all mss with fewer than readings as secondary non continuous texts
filtering these out we were left with a matrix with non zero entries
the excluded mss are listed on page


prior weights on readings
we applied nmf to our collation matrix with the entries being weighed uniformly on the one hand and using the inverse ment frequency idf scheme on the other hand
uniform weighting as its name suggests weighs all readings equally prior to nmf all entries of the matrix are therefore entries
idf weighting developed to facilitate information retrieval in the context of terms and documents is a heuristic that seeks to weigh dividual terms by their specificity
while a theoretical justification of its use has been elusive it has proven to be of great practical effectiveness in text mining tasks
the definition is simple
if a term t occurs nt times among n documents then we assign it a weight log n nt here log is a logarithm that can be taken to any base greater than
with this weighting function the more documents term t appears in the less information it provides about any specific document
the word the is an example of such a term
if it appears in all n documents then its idf weight would be n
notes that his apparatus does not record the most frequent orthographic variants such as instances of movable nu final vowel elisions in prepositions and conjunctions itacisms and other common vowel interchanges p

but this is actually good for our purposes since such readings are considered unimportant for ms classification p

readings contain underlying dots or brackets in wasserman s apparatus
continuous texts pose the same problems for nmf that they do for other methods like cbgm
nevertheless once clusters have been determined for the continuous text data we can make inferences about the non continuous texts on the basis of their readings
see appendix a for more details
way to handle units contained in larger omissions would be to treat them as omissions themselves
we did not attempt to encode the data in this way but the number of variation units in question is small enough that we do not expect significantly different results
biclustering readings and manuscripts meanwhile a word appearing in only a single document would have the larger weight
in our case we would take readings as terms
the highest specificity readings then would be those that occur more rarely with singular readings receiving the highest prior weight
balancing this out is the fact that singular readings are less informative about non trivial clusters i
e
those consisting of more than a single ms which will lead nmf to give these readings a lower final weight than it gives to readings with attestation from slightly larger groups
sometimes however singular readings will exert enough influence to bias the factorization towards outlying mss
this is what initially happened with our data as we showed in subsection

when this happens it is prudent to perform outlier detection and removal as we have done
ultimately in maximizing the cohesiveness of ms clusters non singular readings that are shared exclusively by the mss in a given cluster are likely to become the most important readings
meanwhile readings that are common to multiple clusters will be given less weight and therefore will play less of a role in nmf
each of these two weighting schemes is best suited for a different set of tasks
uniform weighting is better in the context of clustering on the whole picture of readings and explaining as much of the variance between mss as possible
this is applicable for example to the construction of a text critical apparatus where we want to group many mss under a few sigla for the purpose of succinctness while having to list as few exceptional cluster members as possible
idf weighting is more useful in producing weighted profiles of textual families based on their most exclusive readings
in general it is more aligned with human intuition in identifying textual groups as we will see


implementation
for ease of use we stored all apparatus matrices along with their row and column headers as microsoft excel spreadsheets
for all putational work we used release
of the python programming language
to read and write data from and to excel spreadsheets we used the python pandas package
for running nmf on our data we chose to use nimfa an open source python library
this library best fit our needs because it offered a variety of nmf versions including versions having the convergence guarantees summarized in section numerous factor initialization methods and factorization quality sures
for most of our data manipulation needs including linear algebra for matrix operations we used the scipy stack of open source python modules for scientific computing
to factor our collation data in nimfa we used the lsnmf method an implementation of the alternating least squares formulation of nmf proposed by lin
we ran this with values of k ranging from to and a maximum iteration limit of
we used a single run in each case seeding it with nndsvd initialization a non random initialization method that has been empirically shown to result in faster lower error factorizations
we found that single runs ized in this way matched the objective function values for hundreds to thousands of runs with random initialization and in fact tended to give sparser factors
this implementation of nmf was run separately on a platform with an intel quad core processor and gb of memory which we will denote and a platform with an intel duo dual core processor and gb of memory which we course the more contaminated the scribal tradition is the more exceptions one can expect to see in the apparatus
but even then the level of compression achieved for the average reading may still outweigh the number of exceptions


pydata

j
mccollum and s
brown will denote
the differences in performance between the two platforms will be detailed in the following sections

results

uniform weighted results
table gives summary statistics for the weight nmf runs and results for
in general nmf obtained tions that explained much of the variance in the observed data and it did so in a very short time
table
summary statistics for uniform weight nmf results
here gives the number of iterations before convergence
time and
time give the running time in seconds on both platforms dist gives the value of the objective function from tion evar gives the explained variance as a proportion between and and w
spar and h
spar give sparseness measures tween and according to hoyer s formula

time
time dist evar w
spar h
spar we will now examine the results for k in detail
table lists the mixture coefficients for consistently cited witnesses in the apparatus for jude
note that the coefficients have not been normalized
we have left them as is in order to preserve their absolute magnitude which we can interpret as a confidence score for classification
if we were to divide each coefficient in a given row by the row wise sum we could interpret the scaled coefficients as mixture proportions
under such normalization ms would be interpreted as cluster cluster cluster and cluster
in order to determine the textual groups represented by the clusters it is structive to look at their most representative witnesses
tables list the top mss in each cluster
for the purposes of profiling secondary witnesses we will also want to know the most important readings in each cluster
tables list these readings in order of their coefficients
the group behind cluster is perhaps the easiest to identify this cluster sents the alexandrian texttype
perhaps not surprisingly one of its best tatives is b with papyrus being another leading member
the remaining top representatives include a handful of s consistently cited witnesses
cials a and c also fall under this cluster but as table shows they all have strong enough elements of mixture with other clusters that they do not make it to the top of the cluster s list
the cluster contains mss in total
cluster appears to be a mixture of two textual families identified in and p

the former group ing literature has also been identified in peter p
and in the catholic epistles it shares important readings with the old georgian versions
its namesake is a consistently cited witness in
one of s scribes claimed to have copied it from an ancient codex and scholars conjecture that its exemplar dates back at least biclustering readings and manuscripts to the fourth or fifth century
further evidence for the family s antiquity has been found in its close similarity to the text used by origen
the connection with origen has led some to posit that represents the controversial caesarean texttype in the catholic epistles
the latter group has also been identified in peter p
and in james peter and john its core members have been shown to have a connection to the harklean syriac
so and both attest to early forms of several of the catholic epistles and the same situation likely holds in jude as well
the cluster is small at mss but the witnesses are generally cohesive
the fact that their readings overlap enough for their mss to be grouped together also suggests that and are closely related to each other in most variation units
cluster as its witnesses make clear represents the group of lectionaries
the existence of a distinct lectionary textual group has been recognized for some time but a thorough examination of this group in the catholic epistles was long delayed
the first and perhaps most extensive work in this area was done by junack
junack s work confirmed the existence of a large and cohesive textual family among the byzantine lectionaries
at least in the context of the epistle of jude our results based on wasserman s complete collation should give additional weight to these findings
our results also agree with junack s identification of as an exceptionally non byzantine lectionary in fact table lists it as a strong representative of the alexandrian texttype
the cluster does not consist exclusively of lectionaries as it contains mss total but the non lectionary mss are lower on the list due to mixture
cluster clearly represents the byzantine subgroup kr also known as as can be seen from the overlap between table and the list of collated mss for john jude in
this cluster is by far the largest with mss assigned to it and it exhibits great cohesion among its purest representatives
to its disadvantage however it contains no witnesses dating earlier than the tenth century
cluster appears to represent another byzantine subgroup but it is unclear if it corresponds to any previously known subgroup
while not as massive as cluster it is still large with mss
perhaps the most noticeable quality is that it appears to be the earliest byzantine subgroup
it contains the following five ninth century mss k and
cluster undoubtedly represents the textual family p

its earliest witness is the tenth century ms but this same ms is also a cited witness in see table
this group was independently identified in the catholic epistles through stemmatic methods by spencer wachtel and howe who noted that it contains states of text that are thought to be important for the formation of the byzantine text
the family is of moderate size containing mss
cluster also looks byzantine but like cluster its precise identity is unclear
like cluster it seems to represent a text earlier than that of cluster its earliest witnesses are dated to the tenth century but two prominent representatives of the group are uncials and and both of these possess alexandrian elements quantifiable as cluster mixture proportions of and respectively
the cluster is of moderate size consisting of mss
cluster appears to be von soden s kc byzantine subgroup p
as can be seen from the presence of the following kc mss in the cluster von soden s and
the cluster as established by nmf has no witnesses from earlier than the tenth century and of j
mccollum and s
brown its purest representatives the oldest is the eleventh century ms but the group is large enough with members and tight knit enough with generally strong mixture coefficients that its archetype is surely older than the tenth century
there are a few observations to make here
nmf on a uniform weight collation matrix reveals a number of distinct subgroups not only of the alexandrian texttype in particular the byzantine texttype splits but also of the byzantine texttype
into the lectionary group kr kc and two additional groups
it should be noted therefore that the byzantine mss do not form a monolithic group in jude
clusters and form two more large as yet unknown byzantine families
while we might expect one of these clusters to correspond to the larger more general k group the mss traditionally assigned to that group are divided between both clusters
it may be the case that the k mss are divided in jude with two thirds of the family siding with the oldest mss in the group and one third taking the other side
a cross reference from tables to wasserman s apparatus reveals that nmf in the uniform weight setting tends to assign higher basis coefficients to common widely divided readings than it does to rarer readings exclusive to groups
this is the result of nmf trying to minimize the number of misclassified readings when all readings are all equal in weight
to minimize unexplained variance readings are chosen on how cleanly they divide the entire body of mss into their assigned clusters
for these reasons an important reading in this setting will likely resent multiple clusters but a given cluster can be uniquely identified by patterns of readings
this in essence reflects the methodology of wisse and mcreynolds s original formulation of the claremont profile method
while this has the unfortunate side effect of not clustering readings as sparsely as we might like it is useful for certain purposes
in particular it allows us to identify widely split variant units which may represent early divisions in the scribal tradition and to determine where different families side in these splits
table gives a short list of widely divided readings and their support among uniform weight nmf groups
table
uniform weight nmf cluster support for highly divided readings
cluster wide support is determined not by manuscript count but by basis coefficient with a reading resp
group of ings being considered representative if its coefficient resp
sum of coefficients is a least twice the value of every alternative s cient resp
sum of coefficients in that variation unit
the readings are primarily split between and in and in and in and in and in and and in


alex

split om
om
split


om



split
om
split split kr


kc lect














split
om
om
om





om


om

split biclustering readings and manuscripts as an example the robinson pierpont greek nt lists and as divided byzantine readings and opts for and respectively as the original readings
while the cluster is split in both cases and offers no strong evidence either way has the support of alex and kc and has the support of and kc
the external evidence shows earlier and more diverse testimony in favor of with the same situation to a lesser degree in favor of
valuing diversity of testimony we therefore agree with robinson and pierpont s textual decisions on the divided readings in jude
the results of nmf may also reveal readings that have not yet been recognized as divided byzantine readings and are two candidates
of course in other applications we would want to identify readings that are individually more exclusive to their groups
in these cases we view less common readings as more valuable a priori
thus to get sparser results we must turn to nmf in the idf weight setting


idf weighted results
table gives summary statistics for the idf weight nmf runs and results for
because idf weighting assigns greater importance to less common readings nmf tends to find more exclusive bases for clusters in this setting
another positive effect of idf weighting is that it allows nmf to isolate more distinctive clusters often due to differences that weight nmf overlooks
a disadvantage as can be seen in table is that when the factorization sets aside especially rare readings for the sake of more common cohesive ones the high weight of the ignored readings reduces the explained variance of the model
for all k an nmf run in this setting took at most a couple seconds on both platforms
table
summary statistics for idf weight nmf results
here gives the number of iterations before convergence
time and
time give the running time in seconds on both platforms dist gives the value of the objective function from equation evar gives the explained variance as a proportion between and and w
spar and h
spar give sparseness measures between and according to hoyer s formula

time
time dist evar w
spar h
spar we will now examine the results for k in detail
table lists the mixture coefficients for consistently cited in the apparatus for jude
as in the would not consider the agreement of kr and lect to be especially diverse as they both are closely related to the byzantine texttype
the only non byzantine support comes from for and for the cluster s support there is essentially split between and
this relationship may be worth closer study in the future
these locations robinson pierpont gives only the readings and respectively
if we were to account for the readings of the other k groups here we would include the readings and respectively in the margin
subsection
for more details on the problem and how to address it
j
mccollum and s
brown uniform weight case no normalization has been applied to the coefficients
tables list the most representative mss in each cluster and tables list the most representative readings for each cluster
cluster clearly represents
we also note that now the cluster contains no representatives from and for this reason it now consists of only mss
an important observation in table is that uncial c has its highest mixture coefficient in this cluster which suggests that it shares many characteristic readings or at least some high weight characteristic readings with
the first few can be found in table and are the following


and

cluster appears to represent the majority of the byzantine texttype as mss are members of it
the group appears to be cohesive enough not to be split up when k but its mixture coefficients are also the lowest of any cluster by far which suggests that there is variance among the members of the cluster
this likely arises in splits between byzantine subgroups at common readings in the idf setting these readings will have low enough weight not to split the cluster but their total weight will suffice to produce noticeable variance within the group
ertheless the characteristic readings of the cluster have strong coefficients which indicates that uniquely byzantine readings are shared even by the texttype s ferent subgroups
cluster represents
the group is small consisting of only mss but this is the result of its being split apart from
uncial while not a member of this cluster still shares some significant readings with it
these readings include

and

cluster contains the alexandrian witnesses
the cluster which consists of mss is slightly smaller than its counterpart in the uniform weight setting
due to more exclusive readings being assigned prominent places in the cluster basis the order of the most representative witnesses has shifted somewhat
notably uncial a and are considered slightly more alexandrian than b in the idf setting
a glance at table will reveal that is relatively pure in its mixture coefficients while and all have at least some mixture with cluster
we will revisit this in a moment
cluster represents
the group consists of mss here which is a bit smaller than it was from uniform weight nmf
like the other clusters its readings should now be more exclusive to the group
little else has changed
cluster is obviously the lectionary group
it now consists of mss which means that it may have borrowed some mss placed elsewhere in the uniform weight clusters
its readings are now more exclusive to the group but little is different otherwise
cluster is a curious group consisting of only mss
most of its members were lumped under the alexandrian cluster in the uniform weight setting so it appears to have some relationship with the alexandrian text
the top two mss and demonstrate a high level of agreement in both the catholic and pauline epistles
in the catholics they and a few other members of this cluster and read in john
in corinthians and attest to an infamous variant that places at the end of the chapter with the only other greek ms support coming from western witnesses
their support for that reading has led to much debate over whether or not they have a common source in a localized western text and whether or not they support the theory that corinthians is an interpolation
despite the rarity of some of its other readings the cluster s characteristic readings are shared by the alexandrian uncials and and which suggests that the biclustering readings and manuscripts cluster preserves some ancient readings
as the cluster itself does not appear to have been identified in the literature we will designate it by here
cluster is another unusual group made up of mss
most of its members were mixtures of multiple byzantine subgroups in the uniform weight setting so it appears to represent a small and distinct branch of the byzantine texttype
its top representatives mss and are strong pure representatives of the family
some of the mss themselves are noteworthy
scrivener describes as valuable but with many errors p
he finds a similar text in and considers this ms an important copy p

apart from this the cluster itself does not seem to have received much study
lacking an existing name for it we will designate it in this paper
we observe one other connection between these mss outside the catholic epistles in the letter to the romans
there many of the family mss contain the subscription
in jude one of the group s most characteristic readings
is shared by which may indicate ancient roots for the reading and possibly for the family
on further examination however this is the only significant group reading that supports apart from the much lower weight reading in so the agreement is more likely coincidental
in this case the best explanation for the agreement is that the reading arose independently in and
we will make some observations to conclude this section
while nmf in the uniform weight setting succeeds at accounting for variance by giving more priority to common widely divisive readings nmf in the idf setting does better at locating readings more exclusive to specific clusters
this in turn allows it to identify sparser reading bases and smaller ms groups
for an illustration of this difference please refer to table which gives a short list of widely divided readings and their support among idf weighted nmf groups
compare this to table
notice how splits among the groups formed tend to be more common for widely divided readings in the idf setting while more distinctive group readings are identified in units with many readings such as
in general the re weighting of the observed data results in different clusters with sharper separation
while both weighting schemes isolate alexandrian and lectionary clusters idf weighted nmf compresses all previous subgroups of k into a single cluster separates and appropriately and identifies small subgroups of the alexandrian and byzantine texttypes with unique readings
for the purposes of identifying the most significant variation units and witnesses e

to provide more refined and manageable inputs to cbgm or other more complex methods this setting seems to be the most suitable
the mss with the romans subscription include which includes the subscription but reorders many words and includes a reference to tertius which omits which changes the begining to and omits and which appears to omit
unit concerns the inclusion or omission of the article and all but a few witnesses including most of include the article so this is probably an instance of independent errors producing agreement
evidence for coincidental agreement is that wasserman lists as having a defective text reading here with a corrector s hand supplying not the reading of but the reading shared by the majority of mss
besides this in the other high ranking variation units of either shares the majority reading or has a unique reading whose derivation from the reading would be difficult to explain e

in and
in other units alternatively adds to omits from or transposes the reading leaving us no indication that the scribe of deviated from the text in any consistent way
j
mccollum and s
brown table
idf weight nmf cluster support for highly divided readings
cluster wide support is determined as in table and the readings are split as they are in table






alex

split split




split split

lect byz split

split split om
om

split split

split om
om
split om

split om
om
split


om
split om
om

om
om


summary and conclusions in this paper we have shown how non negative matrix factorization or nmf can effectively classify mss and readings on texttype based principles
while as a pre genealogical method it can not make inferences regarding prior and rior textual relationships it can be used to facilitate more complex genealogical methods by providing better selections of readings and witnesses for input
we have demonstrated the suitability of nmf for these tasks on both theoretical and empirical grounds
on the theoretical side nmf is able to cluster both readings and mss by ing the best approximate factorization of the collation matrix
by alternatively optimizing the basis and coefficient factor matrices it keeps the problem of dependence between readings and mss under control
since for certain nmf update rules this process can be proven to stop only when the objective function of the factorization reaches a critical point we have a theoretical guarantee that co dependence wo nt cause an endless loop or result in arbitrarily bad clusters
ditionally nmf provides an easy to interpret model that allows us to determine reading profiles for clusters and account for mixture between different clusters in mss
on the practical side nmf provides fast human recognizable results for ces in various weighted settings
nmf is able to factor a complete collation matrix of jude for mss in less than minutes in the uniform weight setting and in a matter of seconds in the idf setting
as we have indicated the uniform weight ting provides good group classifications over widely divided variation units while the idf weight setting highlights the most distinctive readings of textual families
using nmf on wasserman s collation of jude we were able to classify many previously unclassified mss and verify several existing group classifications
in the uniform weight setting we identified a distinct textual family for lectionaries in jude we found further empirical justification for von soden s kr and kc groups in addition to a subdivision of his k group and we both verified the choices for the textual and marginal readings of jude in and proposed additional marginal readings based on the readings of the identified byzantine subgroups
meanwhile in the idf setting we isolated characteristic mss and readings for well known groups including the alexandrian texttype the byzantine texttype the lectionaries and we found two other groups which we identified as and and we demonstrated that both and have family ties outside of the catholic epistles suggesting that the classification made by nmf is legitimate
we feel that nmf has tremendous potential as a tool for automatic vised texttype based textual criticism and we wish to see it implemented in further studies
as we have attempted to show its results can be fruitful in a multitude references of applications from organizing known collation data to performing exploratory analysis on what is yet unknown
we hope to find the new textual groupings and ms classifications done with nmf examined further and perhaps used as starting points for new research on the complex text of the epistle of jude
it certainly deserves our greatest effort
references brooke foss westcott and fenton john anthony hort
the new testament in the original greek
vol

cambridge macmillan and company
url
google
com
eldon jay epp
textual clusters their past and future in new testament textual criticism
in the text of the new testament in contemporary search essays on the status quaestionis
ed
by bart d
ehrman and michael w
holmes
second
vol

new testament tools studies and documents
leiden brill pp

isbn
ernest cadman colwell
genealogical method its achievements and its limitations
in journal of biblical literature
pp

issn


gordon d
fee
the text of john in origen and cyril of alexandria a tribution to methodology in the recovery and analysis of patristic citations
in biblica
pp

issn
bart d
ehrman
the use of group profiles for the classification of new testament documentary evidence
in journal of biblical literature
pp

issn


klaus wachtel
towards a redefinition of external criteria the role of coherence in assessing the origin of variants
in textual variation logical and social tendencies ed
by h
a
g
houghton and david c
parker
vol

texts and studies
piscataway nj gorgias press pp

isbn
tommy wasserman
the epistle of jude its text and transmission
vol

coniectanea biblica new testament
stockholm almqvist and wiksell ternational
isbn
ernest cadman colwell
method in locating a newly discovered script
in studies in methodology in textual criticism of the new testament
vol

new testament tools and studies
leiden brill pp

j
c
thorpe
multivariate statistical analysis for manuscript tion
in tc a journal of biblical textual criticism
issn
url
reltech
org tc
html
timothy j
finney
mapping textual space
in tc a journal of biblical textual criticism
issn
url
reltech
org tc mapping index
html
paul robert mcreynolds
the claremont profile method and the grouping of byzantine new testament manuscripts
phd thesis
claremont graduate school
url www
cspmt
org pdf mcreynolds
pdf
frederik wisse
the profile method for the classification and evaluation of manuscript evidence as applied to the continuous greek text of the gospel of luke
vol

studies and documents
grand rapids mi wm
b
eerdmans publishing
isbn
references clinton s
baldwin
factor analysis a new method for classifying new testament greek manuscripts
in andrews university seminary studies
pp

url
auss
info
php
kenneth keumsang yoo
the classification of the greek manuscripts of peter with special emphasis on methodology
phd thesis
seventh day adventist theological seminary andrews university
url digitalcommons
andrews
edu
clinton s
baldwin
the so called mixed text an examination of the alexandrian and non byzantine text type in the catholic epistles
phd thesis
seventh day adventist theological seminary andrews university
url
andrews
edu
matthew spencer klaus wachtel and christopher j
howe
the greek lage of the syra harclensis a comparative study on method in exploring textual genealogy
in tc a journal of biblical textual criticism
issn
url rosetta
reltech
org tc index
html
matthew spencer klaus wachtel and christopher j
howe
representing multiple pathways of textual flow in the greek manuscripts of the letter of james using reduced median networks
in computers and the humanities pp

gerd mink
problems of a highly contaminated tradition the new ment
stemmata of variants as a source of a genealogy for witnesses
in studies in stemmatology
ed
by pieter van reenen august den hollander and margot van mulken
vol

amsterdam john benjamins publishing pp

isbn
klaus wachtel
the coherence method and history
in tc a journal of biblical textual criticism
issn
url
reltech
org tc cbgm history
pdf
w
larry richards
a critique of a new testament text critical ology the claremont profile method
in journal of biblical literature
pp

issn


h
a
g
houghton
recent developments in new testament textual icism
in early christianity
pp



url pure oai
bham
ac
ws files preprint
pdf
tommy wasserman
the coherence based genealogical method as a tool for explaining textual changes in the greek new testament
in novum tamentum
pp

issn


daniel d
lee and h
sebastian seung
learning the parts of objects by non negative matrix factorization
in nature pp

issn


suvrit sra and inderjit s
dhillon
nonnegative matrix approximation gorithms and applications
tech
rep

department of computer science university of texas at austin
url
ist
psu
edu viewdoc




wei xu xin liu and yihong gong
document clustering based on negative matrix factorization
in proceedings of the annual tional acm sigir conference on research and development in tion retrieval
sigir
new york ny acm pp

isbn



references karthik devarajan
nonnegative matrix factorization an analytical and interpretive tool in computational biology
in plos computational biology
pp


journal
pcbi

url journals

org ploscompbiol article i d
journal
pcbi

eric frichot et al
fast and efficient estimation of individual ancestry efficients
in genetics
pp


genetics


url
genetics
org
short
chih jen lin
projected gradient methods for nonnegative matrix ization
in neural computation
pp

url
ist
psu
edu viewdoc




l
grippo and s
sciandrone
on the convergence of the block nonlinear gauss seidel method under convex constraints
in operations research letters pp

w
larry richards
the classification of the greek manuscripts of the hannine epistles
missoula mt scholars press
isbn
karen sprk jones
a statistical interpretation of term specificity and its application in retrieval
in journal of documentation
pp

issn


url
ist
psu
edu viewdoc




stephen robertson
understanding inverse document frequency on oretical arguments for idf
in journal of documentation
pp

issn


url
ist
psu
edu viewdoc




marinka itnik and bla zupan
nimfa a python library for ative matrix factorization
in journal of machine learning research pp

issn
url citeseerx
ist
psu
edu viewdoc




christos boutsidis and efstratios gallopoulos
svd based initialization a head start for nonnegative matrix factorization
in pattern recognition
pp

issn

j
patcog



url
ist
psu
edu viewdoc




patrik o
hoyer
non negative matrix factorization with sparseness straints
in journal of machine learning research
ed
by peter dayan pp

issn
url
ist
psu
edu viewdoc




barbara aland et al
eds
nestle aland novum testamentum graece
eighth
stuttgart deutsche bibelgesellschaft
isbn
robert b
waltz
the encyclopedia of new testament textual criticism

url
google
com pefhaaaaqbaj
terry dwain robertson
relationships among the non byzantine manuscripts of peter
in andrews university seminary studies
pp

url
andrews
edu library
christian b
amphoux and dom b
outtier
les leons des versions ennes de jacques
in biblica
pp

issn
k
w
kim
codices and origen
in journal of biblical ature
pp

issn


christian b
amphoux
la parent textuelle du syh du groupe dans lptre de jacques
in biblica
pp

issn
references barbara aland and andreas juckel
das neue testament in syrischer lieferung
vol

berlin walter de gruyter
isbn
ernest cadman colwell
is there a lectionary text of the gospels in harvard theological review
pp

issn


klaus junack
zu den griechischen lektionaren und ihrer berlieferung der katholischen briefe
in die alten bersetzungen neuen testaments die kirchenvterzitate und lektionare der gegenwrtige stand ihrer erforschung und ihre bedeutung fr die griechische textgeschichte
ed
by matthew black and kurt aland
vol

arbeiten zur neutestamentlichen textforschung
berlin walter de gruyter pp

isbn
wilbur n
pickering
the greek new testament according to family
second
wilbur n
pickering
isbn
url www
cspmt
org pdf
pdf
hermann freiherr von soden
die schriften des neuen testaments in ihrer ltesten erreichbaren textgestalt hergestellt auf grund ihrer textgeschichte
vol

gttingen vandenhoeck und und ruprecht
url
cspmt
org pdf vonsoden gnt
pdf
maurice a
robinson and william g
pierpont eds
the new testament in the original greek byzantine textform
southborough ma chilton book publishing
isbn
url www
cspmt
org pdf rp mt
pdf
curt niccum
the voice of the manuscripts on the silence of women the external evidence for cor

in new testament studies
pp

issn


philip b
payne
ms
as evidence for a text without cor

in new testament studies
pp

issn
doi

jennifer shack
a text without corinthians
not according to the manuscript evidence
in journal of greco roman christianity and judaism pp

url jgrchj
net
pdf visited on
frederick henry ambrose scrivener
a plain introduction to the criticism of the new testament for the use of biblical students
ed
by edward miller
fourth
vol

london george bell sons
url
cspmt
org pdf
pdf
appendix a
classification of lacunose mss in section
we explained that in the process of data selection we regarded the texts of correctors and witnesses with fewer than readings as non continuous and therefore secondary
table lists the mss from wasserman s collation that were too lacunose to be included
because of their age most papyri and uncials are so lacunose that they must be excluded in this way
this leaves us with an unfortunate situation in which we have nothing to say about the mss in which we are most interested
fortunately we are not without a remedy
once nmf on the primary set of continuous text witnesses has produced a basis matrix w for cluster readings we can use this matrix to classify the secondary witnesses by whatever readings they do have
if we take x to be a vector representing the readings of a single secondary witness that we want to classify then the solution h to the least squares equation arg min jjx f references table
mss with fewer than readings excluded from the primary nmf run
will contain the mixture coefficients for the witness represented by x
because the entries of h are required to be non negative we can interepret h as we interpreted the mixture matrix h for the primary witnesses
to solve equation we used scipy s optimize
nnls method for each ms in table individually in both the uniform weight case and the idf weight case
for the sake of space we will not list the mixture coefficients of all mss but we will list the results for ms and the consistently cited witnesses and
these results can be found in tables and
table
uniform weight mixture coefficients for selected ondary mss
table
idf weight mixture coefficients for selected secondary mss
as table shows and are too lacunose to be classified with much dence in the uniform weight case
uncial p fares slightly better exhibiting a moderate alexandrian element and weaker lectionary and kr elements
mss and on the other hand clearly belong to the cluster
the situation is not too different in the idf weighted setting as table shows
as in the uniform weight case s extant readings do not commend it to any cluster
the situation is nearly the same for it has a slightly higher mixture coefficient for the cluster because it shares the group reading at but it is otherwise too lacunose for us to determine any closer relationship
uncial like is inconclusive
ms shares characteristic readings of both and the alexandrian cluster
finally as we would expect ms clearly belongs to the family bearing its name
references appendix b
nmf results table consistently cited mss

uniform weight mixture coefficients for references table
uniform weight cluster mss sorted by
table
uniform weight cluster mss sorted by
table
uniform weight cluster mss sorted by
table
uniform weight cluster mss sorted by
ms ms ms ms references table
uniform weight cluster mss sorted by
table
uniform weight cluster mss sorted by
table
uniform weight cluster mss sorted by
table
uniform weight cluster mss sorted by
ms ms ms ms references table
uniform weight cluster readings sorted by
table
uniform weight cluster readings sorted by
reading














reading














reading














reading














table
uniform weight cluster readings sorted by
table
uniform weight cluster readings sorted by
references table
uniform weight cluster readings sorted by
table
uniform weight cluster readings sorted by
reading














reading














reading














reading














table
uniform weight cluster readings sorted by
table
uniform weight cluster readings sorted by
references table
idf weight mixture coefficients for cited mss
references table
idf weight mss sorted by
cluster table
idf weight mss sorted by
cluster table
idf weight mss sorted by
cluster table
idf weight mss sorted by
cluster ms ms ms ms references table
idf weight mss sorted by
cluster table
idf weight mss sorted by
cluster table
idf weight mss sorted by
cluster table
idf weight mss sorted by
cluster ms ms ms ms references table
idf weight readings sorted by
cluster table
idf weight readings sorted by
cluster reading














reading














reading


inscriptio


subscriptio



inscriptio




reading














table
idf weight readings sorted by
cluster table
idf weight readings sorted by
cluster references table
idf weight readings sorted by
cluster table
idf weight readings sorted by
cluster reading














reading








subscriptio





reading














reading







inscriptio

subscriptio




table
idf weight readings sorted by
cluster table
idf weight readings sorted by
cluster
