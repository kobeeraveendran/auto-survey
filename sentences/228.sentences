moverscore text generation evaluating with contextualized embeddings and earth mover distance wei zhao maxime peyrard fei liu yang gao christian m
meyer steffen eger computer science department technische universitat darmstadt germany computer science department university of central florida us
tu darmstadt
maxime


ucf
edu yang

ac

informatik
tu darmstadt

tu darmstadt
abstract a robust evaluation metric has a profound pact on the development of text generation tems
a desirable metric compares system put against references based on their tics rather than surface forms
in this paper we investigate strategies to encode system and reference texts to devise a metric that shows a high correlation with human judgment of text quality
we validate our new metric namely moverscore on a number of text generation tasks including summarization machine lation image captioning and data to text eration where the outputs are produced by a variety of neural and non neural systems
our ndings suggest that metrics combining contextualized representations with a distance measure perform the best
such metrics also demonstrate strong generalization capability across tasks
for ease of use we make our metrics available as web service
introduction the choice of evaluation metric has a signicant impact on the assessed quality of natural language outputs generated by a system
a desirable ric assigns a single real valued score to the tem output by comparing it with one or more erence texts for content matching
many natural language generation nlg tasks can benet from robust and unbiased evaluation including to text machine translation and summarization data to text response generation and image text captioning gatt and krahmer
out proper evaluation it can be difcult to judge on system competitiveness hindering the ment of advanced algorithms for text generation
it is an increasingly pressing priority to develop better evaluation metrics given the recent advances in neural text generation
neural models provide code is publicly available at
cc vsqtbz the exibility to copy content from source text as well as generating unseen words see et al

this aspect is hardly covered by existing metrics
with greater exibility comes increased demand for unbiased evaluation
diversity promoting jectives make it possible to generate diverse ural language descriptions li et al
man et al

but standard evaluation rics including bleu papineni et al
and rouge lin compute the scores based marily on n gram co occurrence statistics which are originally proposed for diagnostic evaluation of systems but not capable of evaluating text ity reiter as they are not designed to sure if and to what extent the system and ence texts with distinct surface forms have veyed the same meaning
recent effort on the plicability of these metrics reveals that while pelling text generation system ascend on standard metrics the text quality of system output is still hard to be improved bohm et al

our goal in this paper is to devise an mated evaluation metric assigning a single holistic score to any system generated text by comparing it against human references for content matching
we posit that it is crucial to provide a holistic sure attaining high correlation with human ments so that various neural and non neural text generation systems can be compared directly
tuitively the metric assigns a perfect score to the system text if it conveys the same meaning as the reference text
any deviation from the reference content can then lead to a reduced score e

the system text contains more or less content than the reference or the system produces ill formed text that fails to deliver the intended meaning
we investigate the effectiveness of a spectrum of distributional semantic representations to code system and reference texts allowing them to be compared for semantic similarity across p e s l c
s c v
v i x r a multiple natural language generation tasks
our new metric quanties the semantic distance tween system and reference texts by harnessing the power of contextualized representations ters et al
devlin et al
and a ful distance metric rubner et al
for better content matching
our contributions can be marized as follows we formulate the problem of evaluating tion systems as measuring the semantic distance between system and reference texts assuming powerful continuous representations can encode any type of semantic and syntactic deviations
we investigate the effectiveness of existing textualized representations and earth mover s distance rubner et al
for comparing system predictions and reference texts ing to our new automated evaluation metric that achieves high correlation with human ments of text quality
our metric outperforms or performs bly to strong baselines on four text generation tasks including summarization machine lation image captioning and data to text eration suggesting this is a promising direction moving forward
related work it is of fundamental importance to design tion metrics that can be applied to natural language generation tasks of similar nature including marization machine translation data to text eration image captioning and many others
all these tasks involve generating texts of sentence or paragraph length
the system texts are then pared with one or more reference texts of similar length for semantic matching whose scores cate how well the systems perform on each task
in the past decades however evaluation of these natural language generation tasks has largely been carried out independently within each area
summarization a dominant metric for rization evaluation is rouge lin which measures the degree of lexical overlap between a system summary and a set of reference summaries
its variants consider overlap of unigrams grams unigrams and skip bigrams with a imum gap of words longest common sequences and its weighted version
among others
metrics such as pyramid nenkova and passonneau and be hovy et al
tratz and hovy further compute matches of content units e

head word modier ples that often need to be manually extracted from reference summaries
these metrics achieve good correlations with human judgments in the past
however they are not general enough to count for the relatedness between abstractive maries and their references as a system abstract can convey the same meaning using different face forms
furthermore large scale tion datasets such as cnn daily mail hermann et al
and newsroom grusky et al
use a single reference summary making it harder to obtain unbiased results when only lexical lap is considered during summary evaluation
machine translation a number of metrics are commonly used in mt evaluation
most of these metrics compare system and reference translations based on surface forms such as word character n gram overlaps and edit distance but not the meanings they convey
bleu papineni et al
is a precision metric measuring how well a system translation overlaps with human reference translations using n gram co occurrence statistics
other metrics include sentbleu nist chrf ter wer per cder and meteor lavie and agarwal that are used and described in the wmt metrics shared task bojar et al
ma et al

ruse shimanaka et al
is a recent effort to improve mt evaluation by ing sentence embeddings on large scale data tained in other tasks
additionally preprocessing reference texts is crucial in mt evaluation e

normalization tokenization compound splitting
if not handled properly different ing strategies can lead to inconsistent results using word based metrics post
data to text generation bleu can be poorly suited to evaluating data to text systems such as dialogue response generation and image ing
these systems are designed to generate texts with lexical and syntactic variation ing the same information in many different ways
bleu and similar metrics tend to reward systems that use the same wording as reference texts ing repetitive word usage that is deemed able to humans liu et al

in a similar vein evaluating the quality of image captions can be challenging
cider vedantam et al
uses tf idf weighted n grams for similarity estimation and spice anderson et al
incorporates synonym matching over scene graphs
novikova et al
examine a large number of and grammar based metrics and demonstrate that they only weakly reect human judgments of system outputs generated by data driven end to end ural language generation systems
metrics based on continuous representations moving beyond traditional metrics we envision a new generation of automated evaluation metrics comparing system and reference texts based on mantics rather than surface forms to achieve better correlation with human judgments
a number of previous studies exploit static word embeddings ng and abrecht lo and trained classifers peyrard et al
shimanaka et al
to improve semantic similarity estimation replacing lexical overlaps
in contemporaneous work zhang et al
describe a method comparing system and ence texts for semantic similarity leveraging the bert representations devlin et al
which can be viewed as a special case of our metrics and will be discussed in more depth later
more cently clark et al
present a semantic ric relying on sentence mover s similarity and the elmo representations peters et al
and apply them to summarization and essay scoring
mathur et al
introduce unsupervised and supervised metrics based on the bert tations to improve mt evaluation while peyrard provides a composite score combining dundancy relevance and informativeness to prove summary evaluation
in this paper we seek to accurately measure the between system and reference texts drawing inspiration from contextualized tations and word mover s distance wmd ner et al

wmd nds the traveling tance of moving from the word frequency bution of the system text to that of the reference which is essential to capture the tween two texts
our metrics differ from the temporaneous work in several facets we plore the granularity of embeddings leading to two variants of our metric word mover and tence mover we investigate the effectiveness of diverse pretrained embeddings and netuning tasks we study the approach to consolidate layer wise information within contextualized beddings our metrics demonstrate strong eralization capability across four tasks oftentimes outperforming the supervised ones
we now scribe our method in detail
our moverscore meric we have motivated the need for better metrics pable of evaluating disparate nlg tasks
we now describe our metric namely moverscore built upon a combination of i contextualized sentations of system and reference texts and a distance between these representations ing the semantic distance between system outputs and references
it is particularly important for a metric to not only capture the amount of shared content between two texts i
e
b as is the case with many semantic textual similarity measures peters et al
devlin et al
but also to accurately reect to what extent the system text has deviated from the reference i
e
b b which is the intuition hind using a distance metric

measuring semantic distance let


xm be a sentence viewed as a sequence of words
we denote by xn the sequence of n grams of i
e
is the sequence of words and is the sequence of bigrams
thermore let xn be a vector of weights one weight for each n gram of xn
we can sume f t making f xn a distribution over n grams
intuitively the effect of some n grams like those including function words can be played by giving them lower weights e

using inverse document frequency idf
word mover s distance wmd kusner et al
a special case of earth mover s tance rubner et al
measures semantic distance between texts by aligning semantically similar words and nding the amount of ow eling between these words
it was shown ful for text classication and textual similarity tasks kusner et al

here we formulate a generalization operating on n grams
let and y be two sentences viewed as sequences of grams xn and yn
if we have a distance metric between n grams then we can dene the i portation cost matrix c such that cij j is the distance between the i n gram of and the j n gram of y
the wmd between the two sequences of n grams xn and with associated n gram weights f xn and is then given by yn min f s
t
f xn f
f in xn to the j n gram where f is the transportation ow matrix with fij denoting the amount of ow traveling from the n gram xn j in yn
i here f denotes the sum of all matrix entries of the matrix c f where denotes wise multiplication
then yn is the minimal transportation cost between xn and where n grams are weighted by f xn and
i in practice we compute the euclidean tance between the embedding representations of n grams j j where e is the embedding function which maps an gram to its vector representation
usually static word embeddings like are used to pute e but these can not capture word order or compositionality
alternatively we investigate contextualized embeddings like elmo and bert because they encode information about the whole sentence into each word vector
we compute the n gram embeddings as the weighted sum over its word embeddings
mally if xn i xi


is the i n gram from sentence its embedding is given by i i where is the idf of word xk computed from all sentences in the corpus and is its word vector
furthermore the weight associated to the n gram xn i is given by xn i z i where z is a normalizing constant s
t
f t in the limiting case where n is larger than the sentence s size xn contains only one n gram the whole sentence
then yn reduces to computing the distance between the two sentence embeddings namely sentence mover s distance smd denoted as yn where lx and ly are the size of sentences
hard and soft alignments in neous work bertscore zhang et al
also models the semantic distance between system and reference texts for evaluating text generation tems
as shown in figure bertscore cision recall can be intuitively viewed as hard figure an illustration of moverscore and bertscore
alignments one to one for words in a sentence pair where each word in one sequence travels to the most semantically similar word in the other sequence
in contrast moverscore goes beyond bertscore as it relies on soft alignments to one and allows to map semantically related words in one sequence to the respective word in the other sequence by solving a constrained mization problem nding the minimum effort to transform between two texts
the formulation of word mover s distance vides an important possibility to bias the metric towards precision or recall by using an ric transportation cost matrix which bridges a gap between moverscore and bertscore proposition bertscore precision recall can be represented as a non optimized mover tance f where c is a transportation cost matrix based on bert and f is a uniform portation ow matrix

contextualized representations the task formulation naturally lends itself to deep contextualized representations for inducing word vectors
despite the recent success of layer attentive neural architectures devlin et al
peters et al
consolidating layer wise information remains an open problem as different layers capture information at disparate scales and task specic layer selection methods may be ited liu et al

tenney et al
found that a scalar mix of output layers trained from task dependent supervisions would be tive in a deep transformer based model
instead we investigate aggregation functions to idate layer wise information forming stationary representations of words without supervision
consider a sentence passed through alized encoders such as elmo and bert with l layers
each layer of the encoders produces a the proof in the appendix
system a guywith a redjacketis standingon a boatguymanwearinglifevestsittingcanoeredjacketstandingboatguymanwearinglifevestsittingcanoeredjacketstandingboatword embeddingsword embeddingsref y a manwearinga lifevestis sittingin a tor representation for each word xi in
we note by zi l rd the representation given by layer l a dimensional vector
overall xi receives l different vectors


zi l
an aggregation maps these l vectors to one nal vector


zi l where is the aggregated representation of the word xi
we study two alternatives for i the catenation of power means al
as a generalized pooling mechanism and a routing mechanism for aggregation zhao et al

we relegate the routing method to appendix as it does not yield better results than power means
power means power means is an effective eralization of pooling techniques for aggregating information
it computes a non linear average of a set of values with an exponent eq

ing ruckle et al
we exploit power means to aggregate vector representations zi taining to the i th word from all layers of a deep neural architecture
let p r the mean of


zi l is zp zp l i l p rd where exponentiation is applied elementwise
this generalized form can induce common named means such as arithmetic mean p and metric mean p
in extreme cases a power mean reduces to the minimum value of the set when and the maximum value when
the concatenation of p mean vectors we use in this paper is denoted by i i where is vector concatenation


pk are exponent values and we use k with p in this work

summary of moverscore variations we investigate our moverscore along four sions i the granularity of embeddings i
e
the size of n for n grams the choice of pretrained embedding mechanism the ne tuning task used for iv the aggregation technique means or routing when applicable
usually requires heavy layers on the top which restricts the power of ne tuning tasks for elmo
granularity we used n and n as well as full sentences n size of the sentence
embedding mechanism we obtained word beddings from three different methods static bedding with as well as contextualized embedding with elmo and bert
if n gram embeddings are calculated by eq

note that they represent sentence embeddings when n size of the sentence
fine tuning tasks natural language inference nli and paraphrasing pose high demands in this understanding sentence meaning
vated us to ne tune bert representations on two nli datasets multinli and qanli and one paraphrase dataset qqp the largest datasets in glue wang et al

we ne tune bert on each of these yielding different contextualized embeddings for our general evaluation metrics
aggregation for elmo we aggregate word representations given by all three elmo layers using p means or routing see the appendix
word representations in bert are aggregated from the last ve layers using p means or routing since the representations in the initial layers are less suited for use in downstream tasks liu et al

empirical evaluation in this section we measure the quality of ferent metrics on four tasks machine tion text summarization image captioning and alogue generation
our major focus is to study the correlation between different metrics and human judgment
we employ two text encoders to embed n grams bertbase which uses a layer former and elmooriginal which uses a layer bilstm
we use pearson s r and spearman s to measure the correlation
we consider two variants of moverscore word mover and sentence mover described below
word mover we denote our word mover notation containing four ingredients as
for example represents the semantic metric using word mover distance where unigram based word embeddings ne tuned on mnli are aggregated by p means
sentence mover we denote our sentence as mover notation with three
for example represents the semantic ingredients metric using sentence mover distance where two sentence embeddings are computed as the weighted sum over their embeddings by eq

baselines we select multiple strong baselines for each task for comparison sentbleu guo et al
and a supervised metric ruse for machine translation and and a supervised metric best peyrard et al
for text summarization bleu and meteor for dialogue response eration cider spice meteor and a vised metric leic cui et al
for image tioning
we also report bertscore zhang et al
for all tasks see
due to the page limit we only compare with the strongest baselines the rest can be found in the appendix

machine translation data we obtain the source language sentences their system and reference translations from the wmt news translation shared task bojar et al

we consider language pairs from german chinese zh czech cs latvian lv finnish russian ru and turkish tr resp
to english
each language pair has mately sentences and each sentence has one reference translation and multiple system tions generated by participating systems
for each system translation at least human assessments are independently rated for quality
results table in all language pairs the best correlation is achieved by our word mover rics that use a bert pretrained on mnli as the embedding generator and pmeans to aggregate the embeddings from different bert layers i
e

note that our unsupervised word mover metrics even forms ruse a supervised metric
we also nd that our word mover metrics outperforms the tence mover
we conjecture that important mation is lost in such a sentence representation while transforming the whole sequence of word vectors into one sentence embedding by eq


text summarization we use two summarization datasets from the text analysis conference and which contain and clusters spectively
each cluster includes news articles
nist
gov on the same topic four reference summaries and in or in tem summaries generated by the participating tems
each summary either reference or system has fewer than words and receives two human judgment scores the pyramid score nenkova and passonneau and the responsiveness score
pyramid measures how many important semantic content units in the reference summaries are ered by the system summary while ness measures how well a summary responds to the overall quality combining both content and guistic quality
results tables we observe that lexical rics like rouge correlate above moderate on in contrast these tac and datasets
metrics perform poorly on other tasks like alogue generation novikova et al
and image captioning anderson et al

parently strict matches on surface forms seems reasonable for extractive summarization datasets
however we still see that our word mover rics i
e
form better than or come close to even the vised metric best

data to text generation we use two task oriented dialogue datasets bagel mairesse et al
and sfhotel wen et al
which contains and instances of meaning representation mr
each mr instance includes multiple references and roughly two system utterances generated by ferent neural systems
each system utterance ceives three human judgment scores tiveness naturalness and quality score novikova et al

informativeness measures how much information a system utterance provides with spect to an mr
naturalness measures how likely a system utterance is generated by native ers
quality measures how well a system utterance captures uency and grammar
results tables interestingly no metric duces an even moderate correlation with human judgments including our own
we speculate that current contextualizers are poor at representing named entities like hotels and place names as well as numbers appearing in system and reference texts
however best correlation is still achieved by our word mover metrics combining ized representations
direct assessment setting metrics cs lv en ru en tr zh en average baselines ruse bertscore




















sent mover word mover smd smd elmo pmeans smd bert pmeans smd bert mnli pmeans









































elmo pmeans bert pmeans






bert mnli pmeans






bert mnli pmeans


















table absolute pearson correlations with segment level human judgments in language pairs on dataset
setting metrics best bertscore baselines sent mover word mover smd smd elmo pmeans smd bert pmeans smd bert mnli pmeans

elmo pmeans bert pmeans
bert mnli pmeans
bert mnli pmeans
responsiveness r pyramid r responsiveness r pyramid r


































































































table pearson r and spearman correlations with summary level human judgments on tac and

image captioning we use a popular image captioning dataset coco lin et al
which contains images
each image includes roughly ve ence captions and system captions generated by the participating systems from coco captioning challenge
for the system level man correlation each system receives ve human judgment scores son et al

the and scores sure overall quality of the captions while and scores measure correctness detailedness and saliency of the captions
following cui et al
we compare the pearson correlation with two system level scores and since we cus on studying metrics for the overall quality of the captions leaving metrics understanding tions in different aspects correctness detailedness and saliency to future work
results table word mover metrics form all baselines except for the supervised metric leic which uses more information by ing both images and texts

further analysis hard and soft alignments bertscore is the harmonic mean of bertscore precision and bertscore recall where both two can be composed as a combination of hard mover tance hmd and bert see prop

we use the representations in the th bert layer for fair comparison of bertscore and moverscore and show results on the machine translation task in table
moverscore forms both asymmetric hmd factors while if they are combined via harmonic mean bertscore is on par with moverscore
we conjecture that bert softens hard alignments of bertscore as contextualized embeddings encode information about the whole sentence into each word tor
we also observe that wmd bigrams slightly outperforms wmd unigrams on out of guage pairs
setting metrics baselines sent mover word mover meteor bertscore smd smd elmo pmeans smd bert pmeans smd bert mnli pmeans elmo pmeans bert pmeans bert mnli pmeans bert mnli pmeans inf












bagel nat qual inf sfhotel nat



















































qual












table spearman correlation with utterance level human judgments for bagel and sfhotel datasets
setting metric baselines sent mover word mover leic meteor spice bertscore recall smd smd elmo p smd bert p smd bert m p



















elmo p bert p

bert m p

bert m p

table pearson correlation with system level human ments on mscoco dataset
m and p are short names
metrics ruse cs de lv



hmd bert hmd recall bert hmd prec bert


wmd unigram bert

wmd bigram bert














table comparison on hard and soft alignments
distribution of scores in figure we take a closer look at sentence level correlation in mt
results reveal that the lexical metric sentbleu can correctly assign lower scores to system lations of low quality while it struggles in ing system translations of high quality by ing them lower scores
our nding agrees with the observations found in chaganty et al
novikova et al
lexical metrics correlate better with human judgments on texts of low ity than high quality
peyrard further show that lexical metrics can not be trusted because figure score distribution in german to english pair
figure correlation in similar language and distant language zh en pair where bordered area shows tions between human assessment and metrics the rest shows inter correlations across metrics and da is direct assessment rated by language experts
they strongly disagree on high scoring system puts
importantly we observe that our word mover metric combining bert can clearly distinguish texts of two polar qualities
correlation analysis in figure we serve existing metrics for mt evaluation attaining medium correlations

with human ments but high inter correlations between selves
in contrast our metrics can attain high correlations

with human judgments forming robust across different language pairs
we believe that our improvements come from clearly distinguishing translations that fall on two tremes
impact of fine tuning tasks figure badgoodhuman



























translation translation translation





















translation translation translation zh en demonstrated strong generalization ability across four text generation tasks oftentimes even forming supervised metrics
our metric provides a promising direction towards a holistic metric for text generation and a direction towards more human like eger et al
evaluation of text generation systems
in future work we plan to avoid the need for costly human references in the evaluation of text generation systems and instead base tion scores on source texts and system predictions only which would allow for next level vised in a double sense and unlimited evaluation louis and nenkova bohm et al

acknowledgments we thank the anonymous reviewers for their ments which greatly improved the nal version of the paper
this work has been supported by the german research foundation as part of the search training group adaptive preparation of formation from heterogeneous sources aiphes at the technische universitat darmstadt under grant no
grk
fei liu is supported in part by nsf grant
references peter anderson basura fernando mark johnson and stephen gould

spice semantic tional image caption evaluation
in computer vision eccv european conference dam the netherlands october ceedings part v pages
florian bohm yang gao christian m
meyer ori shapira ido dagan and iryna gurevych

ter rewards yield better summaries learning to in proceedings of summarise without references
the conference on empirical methods in ural language processing hong kong china
ondrej bojar yvette graham and amir kamran

results of the metrics shared task
in proceedings of the conference on machine lation wmt
arun chaganty stephen mussmann and percy liang

the price of debiasing automatic metrics in natural language evalaution
in proceedings of the annual meeting of the association for tational linguistics volume long papers pages
elizabeth clark asli celikyilmaz and noah a
smith

sentence mover s similarity automatic in proceedings of uation for multi sentence texts
figure correlation is averaged over language pairs
pares pearson correlations with our word mover metrics combining bert ne tuned on three ferent tasks
we observe that ne tuning on closely related tasks improves correlations cially ne tuning on mnli leads to an impressive improvement by
points on average

discussions we showed that our metric combining ized embeddings and earth mover s distance performs strong unsupervised metrics on out of tasks i
e
on machine translation by
points spice on image captioning by
points and meteor on dialogue response eration by
points
the best correlation we achieved is combining contextualized word beddings and wmd which even rivals or exceeds sota task dependent supervised metrics across different tasks
especially in machine translation our word mover metric pushes correlations in chine translation to
on average
points over the sota supervised metric and
points over contemporaneous bertscore
the major improvements come from contextualized bert embeddings rather than and elmo and from ne tuning bert on large nli datasets
however we also observed that soft alignments moverscore marginally outperforms hard ments bertscore
regarding the effect of grams in word mover metrics unigrams slightly outperforms bigrams on average
for the effect of aggregation functions we suggested effective techniques for layer wise consolidations namely p means and routing both of which are close to the performance of the best layer and on par with each other see the appendix
conclusion we investigated new unsupervised evaluation rics for text generation systems combining tualized embeddings with earth mover s distance
we experimented with two variants of our metric sentence mover and word mover
the latter has


correlation the annual meeting of the association for putational linguistics pages florence italy
association for computational linguistics
dorin comaniciu and peter meer

mean shift a robust approach toward feature space analysis
ieee transactions on pattern analysis machine intelligence
yin cui guandao yang andreas veit xun huang and serge belongie

learning to evaluate age captioning
in proceedings of the ieee ence on computer vision and pattern recognition pages
jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language standing


steffen eger gul s ahin andreas ruckle ung lee claudia schulz mohsen mesgar ishnkant swarnkar edwin simpson and iryna gurevych

text processing like humans do visually attacking and shielding nlp systems
in proceedings of the conference of the north american chapter of the association for tational linguistics human language gies volume long and short papers pages minneapolis minnesota
association for computational linguistics
albert gatt and emiel krahmer

survey of the state of the art in natural language generation core tasks applications and evaluation
journal of cial intelligence research jair
max grusky mor naaman and yoav artzi

newsroom a dataset of
million summaries with diverse extractive strategies
in proceedings of the conference of the north american ter of the association for computational linguistics human language technologies naacl hlt
yinuo guo chong ruan and junfeng hu

incorporating copy knowledge into machine translation evaluation
in proceedings of the third conference on machine translation shared task papers pages
karl moritz hermann tomas kocisky edward grefenstette lasse espeholt will kay mustafa leyman and phil blunsom

teaching chines to read and comprehend
in proceedings of neural information processing systems nips
eduard hovy chin yew lin liang zhou and junichi fukumoto

automated summarization in proceedings of the uation with basic elements
fifth conference on language resources and uation lrec pages
matt j
kusner yu sun nicholas i
kolkin and ian q
weinberger

from word embeddings to document distances
in proceedings of the tional conference on machine learning icml
alon lavie and abhaya agarwal

meteor an automatic metric for mt evaluation with high levels of correlation with human judgments
in proceedings of the second workshop on statistical machine translation statmt pages stroudsburg pa usa
association for tional linguistics
jiwei li michel galley chris brockett jianfeng gao and bill dolan

a diversity promoting tive function for neural conversation models
in ceedings of the north american chapter of the sociation for computational linguistics naacl
chin yew lin

rouge a package for in proceedings tomatic evaluation of summaries
of acl workshop on text summarization branches out pages barcelona spain
tsung yi lin michael maire serge belongie james hays pietro perona deva ramanan piotr dollar and c lawrence zitnick

microsoft coco in european common objects in context
ence on computer vision pages
springer
chia wei liu ryan lowe iulian v
serban michael noseworthy laurent charlin and joelle pineau

how not to evaluate your dialogue system an empirical study of unsupervised evaluation rics for dialogue response generation
in ings of the conference on empirical methods in ural language processing emnlp
liyuan liu xiang ren jingbo shang xiaotao gu jian peng and jiawei han

efcient textualized representation language model pruning for sequence labeling
in proceedings of the ference on empirical methods in natural language processing emnlp
nelson f liu matt gardner yonatan belinkov matthew peters and noah a smith

tic knowledge and transferability of contextual resentations
arxiv preprint

chi kiu lo

meant
accurate semantic mt evaluation for any output language
in ings of the second conference on machine tion wmt copenhagen denmark september pages
annie louis and ani nenkova

automatically assessing machine summary content without a gold standard
computational linguistics
qingsong ma ondrej bojar and yvette graham

results of the metrics shared task
in ceedings of the third conference on machine lation wmt
francois mairesse milica gasic filip jurccek simon keizer blaise thomson kai yu and steve young

phrase based statistical language generation using graphical models and active learning
in ceedings of the annual meeting of the ciation for computational linguistics pages
association for computational linguistics
nitika mathur timothy baldwin and trevor cohn

putting evaluation in context contextual beddings improve machine translation evaluation
in proceedings of the annual meeting of the association for computational linguistics pages florence italy
association for tational linguistics
ani nenkova and rebecca j
passonneau

ating content selection in summarization the in proceedings of the mid method
ence of the north american chapter of the ation for computational linguistics human guage technologies pages
association for computational linguistics
jun ping ng and viktoria abrecht

better marization evaluation with word embeddings for in proceedings of the conference on rouge
empirical methods in natural language ing pages lisbon portugal
tion for computational linguistics
jekaterina novikova ondrej dusek amanda cas curry and verena rieser

why we need new evaluation metrics for nlg
in proceedings of the conference on empirical methods in natural language processing pages copenhagen denmark
association for tional linguistics
kishore papineni salim roukos todd ward and jing zhu

bleu a method for automatic evaluation of machine translation
in proceedings of the annual meeting on association for putational linguistics acl pages stroudsburg pa usa
association for tional linguistics
matthew e
peters mark neumann mohit iyyer matt gardner christopher clark kenton lee and luke zettlemoyer

deep contextualized word resentations
in proceedings of the north american chapter of the association for computational guistics naacl
maxime peyrard

a simple theoretical model of importance for summarization
in proceedings of the annual meeting of the association for putational linguistics pages florence italy
association for computational linguistics
maxime peyrard

studying summarization evaluation metrics in the appropriate scoring range
in proceedings of the annual meeting of the association for computational linguistics pages florence italy
association for tational linguistics
maxime peyrard teresa botschen and iryna learning to score system gurevych

summaries for better content selection evaluation
in proceedings of the workshop on new frontiers in summarization
matt post

a call for clarity in reporting bleu scores
in proceedings of the third conference on machine translation wmt
ehud reiter

a structured review of the validity of bleu
computational linguistics
yossi rubner carlo tomasi and leonidas j
guibas

the earth mover s distance as a metric for image retrieval
international journal of computer vision
andreas ruckle steffen eger maxime peyrard and iryna gurevych

concatenated power mean word embeddings as universal cross lingual tence representations
corr

abigail see peter j
liu and christopher d
manning

get to the point summarization with in proceedings of the annual generator networks
meeting of the association for computational guistics acl
hiroki shimanaka tomoyuki kajiwara and mamoru komachi

ruse regressor using sentence embeddings for automatic machine translation uation
in proceedings of the third conference on machine translation wmt
ian tenney patrick xia berlin chen alex wang adam poliak r thomas mccoy najoung kim benjamin van durme samuel r bowman jan das al

what do you learn from probing for sentence structure in context arxiv preprint textualized word representations


stephen tratz and eduard h hovy

rization evaluation using transformed basic ments
in proceedings of the text analysing ence tac
ramakrishna vedantam c
lawrence zitnick and devi parikh

cider consensus based in ieee conference age description evaluation
on computer vision and pattern recognition cvpr boston ma usa june pages
matt p wand and m chris jones

kernel ing
chapman and hall crc
alex wang amapreet singh julian michael felix hill omer levy and samuel r bowman

glue a multi task benchmark and analysis platform for natural language understanding
arxiv preprint

tsung hsien wen milica gasic nikola mrksic hao su david vandyke and steve young

semantically conditioned lstm based natural guage generation for spoken dialogue systems
arxiv preprint

sam wiseman stuart m
shieber and alexander m
rush

learning neural templates for text in proceedings of the conference on eration
pirical methods in natural language processing emnlp
suofei zhang wei zhao xiaofu wu and quan zhou

fast dynamic routing based on weighted nel density estimation
corr

tianyi zhang varsha kishore felix wu kilian q
bertscore corr weinberger and yoav artzi

evaluating text generation with bert


wei zhao haiyun peng steffen eger erik cambria and min yang

towards scalable and able capsule networks for challenging nlp in proceedings of the annual cations
ing of the association for computational tics pages florence italy
association for computational linguistics
wei zhao jianbo ye min yang zeyang lei suofei zhang and zhou zhao

investigating sule networks with dynamic routing for text in proceedings of the conference on cation
empirical methods in natural language ing
association for computational linguistics
a supplemental material a
proof of prop
in this section we prove prop
in the paper about viewing bertscore precision recall as a optimized mover distance
as a reminder the wmd formulation is and f n y
here n and n y denote vectors of weights for each n gram of xn and where f n
bertscore is dened as yn min f i j cij fij s
t

rbert pbert fbert i i j i i j i j j j pbert rbert pbert rbert
j then rbert can be formulated in a quasi wmd form cij fij i j fij cij m if xj arg m z otherwise i j j if arg otherwise j j where z i and m is the size of n grams in
similarly we can have pbert in a quasi wmd form omitted
then fbert can be formulated as harmonic mean of two wmd forms of pbert and rbert
i a
routing in this section we study the aggregation function with a routing scheme which has achieved good results in other nlp tasks zhao et al

specically we introduce a nonparametric clustering with kernel density estimation kde for routing since kde bridges a family of kernel functions with underlying empirical distributions which often leads to computational efciency zhang et al
dened as min v zi j s
t
i j ij ij
l t l where is a distance function ij denotes the underlying closeness between the aggregated vector vj and vector zi in the i th layer and k is a kernel function
some instantiations of k wand and jones are gaussian exp epanechnikov
one typical solution for kde clustering to minimize z is taking mean shift comaniciu and meer dened as f zi j zi j v firstly v can be updated while is xed ij j i j v j i i j zi j j zi j ij ij zi j intuitively vj can be explained as a nal aggregated vector from l contextualized layers
then we adopt sgd to update ij where is a hyperparameter to control step size
the routing process is summarized in algorithm
algorithm aggregation by routing procedure initialize i j ij while true do return vj preloss loss break else vj foreach representation i and j in layer and do ij softmax ij foreach representation j in layer do i i zi foreach representation i and j in layer and do ij ij zi loss if then i j best layer and layer wise consolidation table compares our word mover based metric bining bert representations on different layers with stronger bert representations consolidated from these layers using p means and routing
we often see that which layer has best performance is dependent and our word mover based metrics wmd with p means or routing schema come close to the oracle performance obtained from the best layers
experiments table and show correlations between metrics all baseline metrics and word mover based metrics and human judgments on machine translation text summarization and dialogue response generation respectively
we nd that word mover based metrics combining bert ne tuned on mnli have highest correlations with humans outperforming all of the unsupervised metrics and even supervised metrics like ruse and ull
routing and p means perform roughly equally well
metrics bert layer bert layer bert layer bert layer bert layer bert routing bert pmeans cs






de






direct assessment lv en ru en




















tr






zh






table absolute pearson correlations with segment level human judgments on to english translations
setting metrics cs de lv en ru en tr zh en average direct assessment baselines blend ruse sentbleu bertscore word mover bert routing bert mnli routing bert mnli routing bert pmeans bert mnli pmeans bert mnli pmeans







































































































table absolute pearson correlations with segment level human judgments on to english translations
setting metrics baselines best ull we we rouge l bertscore responsiveness r pyramid r responsiveness r pyramid r
















































































































































word mover
bert routing
bert mnli routing
bert mnli routing

bert pmeans
bert mnli pmeans
bert mnli pmeans table correlation of automatic metrics with summary level human judgments for and
setting baselines metrics rouge l nist cider meteor bertscore word mover bert routing bert mnli routing bert mnli routing bert pmeans bert mnli pmeans bert mnli pmeans inf















bagel nat















qual















sfhotel nat















qual















inf















table spearman correlation with utterance level human judgments for bagel and sfhotel datasets

