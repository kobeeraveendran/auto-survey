bengali text summarization by sentence
extraction kamal sarkar computer science engineering department jadavpur university kolkata india
abstract text summarization is a process to produce an abstract or a summary by selecting significant portion of the information from one or more texts
in an automatic text summarization process a text is given to the computer and the computer returns a shorter less redundant extract or abstract of the original
many techniques have been developed for summarizing english
but a very few attempts have been made for bengali text summarization
this paper presents a method for bengali text summarization which extracts important sentences from a bengali document to produce a summary
keyword bengali text summarization sentence extraction indian languages introduction
now a days information overload on the world wide web www is becoming a problem for an increasingly large number of web users

to reduce this information overload problem automatic text summarization can be an indispensable tool
the abstracts or summaries can be used as the document surrogates in place of the original documents

in another way the summaries can help the reader to get a quick overview of an entire document
another important issue related to the information explosion on the internet is the problem that many documents with the same or similar topics are duplicated
this kind of data duplication problem increases the necessity for effective document summarization

in summary the following are the important reasons in support of automatic text summarization
a summary or abstract saves reading time
a summary or an abstract facilitate document selection and literature searches

it improves document indexing efficiency
machine generated summary is free from bias customized summaries can be useful in question answering systems where they provide personalized information

the use of automatic or semi automatic summarization by commercial abstract services may allow them to scale the number of published texts they can evaluate
input to a summarization process can be one or more text documents
when only one document is the input it is called single document text summarization and when the input is a group of related text documents it is called multi document summarization
we can also categorize the text summarization based on the type of users the summary is intended for
user focused query focused summaries are tailored to the requirements of a particular user or group of users and generic summaries are aimed at a broad readership community mani
depending on the nature of summary a summary can be categorized as an abstract and an extract
an extract is a summary consisting of a number of salient text units selected from the input

an abstract is a summary which represents the subject matter of an article with the text units which are generated by reformulating the salient units selected from an input
an abstract may contain some text units which are not present into the input text

based on information content of the summary it can be categorized as informative and indicative summary

the indicative summary presents an indication about an article s purpose and approach to the user for selecting the article for in depth reading informative summary covers all salient information in the document at some level of detail that is it will contain information about
all the different aspects such as article s purpose scope approach results and conclusions
for example an abstract of a research article is more informative than its headline

the main objective of the work presented in this paper is to generate an extract from a bengali document
we have followed a simple and easy to implement approach to bengali single document text summarization because the sophisticated summarization system requires resources for deeper semantic analysis
bengali is a resource constrained language and nlp natural language processing research activities on bengali have recently been started

in our work presented in this paper we have investigated the impact of thematic term feature and position feature on bengali text summarization
to our knowledge no generic text summarization system for bengali is available for comparison to our system
so we have compared the proposed method to the lead baseline which was defined for single document text summarization task in past two duc conferences duc and duc
lead baseline considers the first n words of an input article as a summary where n is a predefined summary length
our work is different from the work on bengali opinion summarization presented in das and bandyopadhyay because we mainly focus on generic text summarization for bengali

in section we present a brief survey on single document text summarization in english domain
the proposed summarization method has been presented in section
in section we describe the summary evaluation method and experimental results


a survey on single document text summarization in english domain
in this section we present a brief survey on single document text summarization for english
although new research on text summarization in english domain has been started many years ago most works on text summarization today still rely on sentence extraction to form summary
many previous works on extractive summarization use two major steps
ranking the sentences based on their scores which are computed by combining few or all of the features such as term frequency tf
positional information and cue phrases baxendale edmundson luhn lin and hovy and selecting few top ranked sentences to form an extract
the very first work on automatic text summarization by
luhn computes salient sentences based on word frequency number of times a word occurs in a document and phrase frequency

although subsequent research has developed sophisticated summarization methods based on various new features the work presented by
edmundson is still followed today as the foundation for extraction based summarization
baxendale presented a straightforward method of sentence extraction using document title first and last sentences of the document each paragraph
lin and hovy claimed that as the discourse structures change over the domains and the genres the position method can not be as simple as in baxendale
they defined an optimal policy of locating the likely positions of topic bearing sentences in the text
mead
radev et

al
computes the score of a sentence based on many features such as similarity to the centroid similarity to the first sentence of the document position of the sentence in the document sentence length
kupiec et
el
applied a machine learning approach to text summarization
they developed a summarizer using a bayesian classifier to combine features from a corpus of scientific articles and their abstracts

salton et
al
presented a sentence extraction method that exploits the semantic links between sentences in the text

the feature they used in this work may be considered as a cohesion feature
text cohesion halliday and hasan refers to the relations semantic links between words word senses or referring expressions which determine how tightly connected the text is
in this approach text is represented by a graph in which each node represents a paragraph in a document and the edges are labeled with the similarity score between two paragraphs
the paragraph that is connected to many other paragraphs with a similarity above a predefined threshold is considered as the bushy node

the paragraph representing the bushy node is considered as a salient one
barzilay and
elhadad described a summarization approach that used lexical chaining method to compute the salience of a sentence
cohesion halliday and
hasan is a method for sticking together different parts of the text
lexical cohesion is the simplest form of cohesion
lexical cohesion links the different parts of the text through semantically related terms co reference ellipsis and conjunctions
lexical cohesion also involves relations such as reiteration synonymy hypernymy
is a relations such as dog is a kind of animal wrist is a part of hand

the concept of lexical chain was introduced in morris and hirst
they characterized lexical chain as a sequence of related words that spans a topical unit of text
in other words lexical chain is basically lexical cohesion that occurs between two terms and among sequences of related words
barzilay and
elhadad used a wordnet
miller to construct the lexical chains

the work in conroy and oleary considered the fact that the probability of inclusion of a sentence in an extract depends on whether the previous sentence had been included as well and applied hidden markov models hmms in sentence extraction task

osborne applied maximum entropy log linear model to decide whether a sentence will be included in a summary or not
he assumed no feature independence
the features he considered are word pairs sentence length sentence position discourse features whether sentence follows the introduction
compared to creating an extract automatic generation of abstract is harder and the latter requires deeper approaches which exploit semantic properties in the text

generation of an abstract from a document is relatively harder since it requires semantic representation of text units sentences or paragraphs in a text reformulation of two or more text units and rendering the new representation in natural language

abstractive approaches have used template based information extraction information fusion and compression
in information extraction based approach predefined template slots are filled with the desired pieces of information extracted by the summarization engine paice and

an automated technique has been presented in jing and mckeown to build a representing the cut and paste process used by humans so that such a corpus can then be used to train an automated summarizer
true abstraction needs more sophisticated process that requires large scale resources
headline generation can be viewed as generation of very short summary usually less than words that represents the relevant points contained in a document

a headline summary is a kind of the indicative summary
banko et
al
presented an approach that uses some statistical methods to generate headline like abstracts
hmm hidden markov model based headline generation has been presented in
zajic dorr and schwartz

dorr al
developed the hedge
trimmer that uses a parse and trim based approach to generate headlines
in this approach the first sentence of a document is parsed using a parser and then the parsed sentence is compressed to form a headline by eliminating the unimportant constituents of the sentence using a set of linguistically motivated rules
topiary zajic
al a headline generation system combines the compressed version of the lead sentence and a set of topic descriptors generated from the corpus to form a headline
the sentence is compressed using the approach similar to the approach in dorr al and the topic descriptors

a number of approaches for creating abstracts have been conceptualized without much emphasis on the issue that a true abstract may contain some information not contained in the document
creating such an abstract requires external information of some kind such as ontology knowledge base
since large scale resources of this kind are difficult to develop abstractive summarization has not progressed beyond the proof of concept stage
proposed summarization method
the proposed summarization method is extraction based
it has three major steps preprocessing sentence ranking summary generation

preprocessing the preprocessing step includes stop word removal stemming and breaking the input document in to a collection of sentences

for stop word removal we have used the bengali stop word list downloadable from the website of forum for information retrieval evaluation

stemming using stemming a word is split into its stem and affix
the design of a stemmer is language specific and requires some significant linguistic expertise in the language

a typical simple stemmer algorithm involves removing suffixes using a list of frequent suffixes while a more complex one would use morphological knowledge to derive a stem from the words

since bengali is a highly inflectional language stemming is necessary while computing frequency of a term

in our work we use a lightweight stemmer for bengali that strips the suffixes using a predefined suffix list on a longest match basis using the algorithm similar to that for hindi ramanathan and rao
sentence ranking
after an input document is formatted and stemmed the document is broken into a collection of sentences and the sentences are ranked based on two important features thematic term and position
thematic term the thematic terms are the terms which are related to the main theme of a document
we define the thematic terms are the terms whose tfidf values are greater than a predefined threshold

the tfidf value of a term is measured by the product of tf and idf where tf term frequency is the number of times a word occurs in a document and idf is inverse document frequency
the idf of a word is computed on a using the formula idf df where n number of documents in the and document frequency indicates the number of documents in which a word occurs
the score of a sentence k is computed based on the similarity of the sentence to the set of thematic terms in a document
the similarity of a sentence to the set of thematic terms in a document is computed as the sum of the tfidf values of the thematic terms contained in the sentence

s k w tfidf w k where tfidfw is a tfidf value of a thematic term w in a sentence and sk is the score of the sentence one crucial issue is to determine the tfidf threshold value based on which we can decide on whether a term is a thematic term or not
in experimental section we will discuss how this threshold value has been adjusted for the best results
positional value
the positional score of a sentence is computed in such a way that the first sentence of a document gets the highest score and the last sentence gets the lowest score
the positional value for the sentence k is computed using following formula kp
sentence length we consider length of a sentence as a feature because we observe that if a sentence is too short but it occurs in the beginning paragraph of a document it is sometimes selected due to its positional advantage
on the other hand if a sentence is too long it is sometimes selected due to the fact that it contains many words
so we eliminate the sentences which are too short or too long

combining parameters for sentence ranking we compute the score of a sentence using the linear combination of the normalized values of thematic term based score sk and positional score
pk if the sentence is not too long or too short
if a sentence is too short or too long it is assigned a score of
the final score of a sentence k is score s if l p

l l l l
u
the values of ll lower cutoff on the sentence length l and lu upper cutoff on the sentence length l are obtained by tuning them for the best results on a subset of documents randomly selected from our corpus
in the experimental section we will discuss in detail how the values of these parameters are tuned
summary generation a summary is produced after ranking the sentences based on their scores and selecting k top ranked sentences when the value of k is set by the user

to increase the readability of the summary the sentences in the summary are reordered based on their appearances in the original text for example the sentence which occurs first in the original text will appear first in the summary
evaluation experiments and results
to test our summarization system we collected bengali documents from the bengali daily newspaper ananda bazar patrika
the documents are typed and saved in the text files using format

for each document in our corpus we consider only one reference summary for evaluation
evaluation of a system generated summary is done by comparing it to the reference summary

evaluation it is very difficult to determine whether a summary is good or bad
the summary evaluation methods can be broadly categorized as human evaluation methods and automatic machine based evaluation methods
a human evaluation is done by comparing system generated summaries with reference model summaries by human judges

according to some predefined guidelines the judges assign a score in a predefined scale to each summary under evaluation
quantitative scores are given to the summaries based on the different qualitative features such as information content fluency
the main problems with human evaluation are the evaluation process is tedious it suffers from the lack of consistency
two human judges may not agree on each other s judgments
on the other hand automatic evaluation machine based is always consistent with a judgment
the automatic evaluations may lack the linguistic skills and emotional perspective that a human has

hence although automatic evaluation is not perfect compared to the human evaluation it is popular primarily because the evaluation process is quick even if summaries to be evaluated are large in number
since automatic evaluation is performed by a machine it follows a fixed logic and always produces the same result on a given summary
since automatic evaluation processes are free from human bias it provides a consistent way of comparing the various summarization systems

in several past
document understanding conferences duc organized by
nist
the national institute of standards and technology single document text summarization systems for english have been evaluated

in duc and duc single document summarization task was to generate a summary of fixed length such as words words
a baseline called lead baseline was defined in these s conferences
lead baseline considers the first n words of an input article as a summary where n is a predefined summary length
unlike duc single document text summarization task where there was a fixed summary length for each document we believe that a generic summary of a document may be longer or shorter than a summary of another document
so we assume that the size of a system generated summary should be equal to that of the corresponding model summary but the different model summaries may not be equal in size
we adopted an automatic summary evaluation metric for comparing system generated summaries to reference summaries
when we compare a system generated summary to a reference summary we ensure that they would be of the same length
we have used the unigram overlap method stated in radev for evaluating the system generated summaries
unigram overlap between a system generated summary and a reference summary is computed as follows unigram based recall
s ri r is the length of the reference summary and indicates the maximum number of unigrams co occurring in the system generated summary s and the reference summary creation of reference summaries is a laborious task
in our experiment we have used only one reference summary for evaluating each system generated summary
experiments and results tuning and choosing appropriate threshold value for the best results and used in equation would be set appropriately
at the same time an appropriate tfidf threshold value for selecting the thematic terms discussed in subsection should be chosen

for tuning these parameters we build a training data set by the collection of randomly selecting document summary pairs from document summary pairs in our corpus

initially we set the value of to since is the weight of the positional feature which is observed by us as a feature producing better results than the thematic term feature
we set the value of to for all the experimental cases presented in this paper

for tuning the value of we set the tfidf threshold value to and conduct experiments with the different values of that ranges from to
to obtain the different values of we step between to by
the figure shows summarization performance curve with respect to different values of on the training data

average recall score vs
when tfidf threshold value is set to and is set to

the figure shows that when the value of is set to which is a relatively smaller value the better result is obtained

since depending on tfidf threshold value we decide on whether a term is the thematic term or not an appropriate threshold value should be determined to improve the summarization performance
for this pupose after fixing the value of to we adjust the tfidf threshold value
the figure shows the summarization performance curve with different tfidf threshold values
figure
average recall score vs
tfidf threshold value when is set to and is set to

the figure shows that the best result is achieved when tfidf threshold value is set to any value between and
we set tfidf threshold value to because at this value average recall score transits from a lower value to the best value

after fixing the value of to and the tfidf threshold value to we adjust the lower cutoff and the upper cutoff on the sentence length
table shows the results on training set with different values of the upper cutoff on sentence length
lu average recall
score table
results on training set with different values of the upper cutoff lu on sentence length

the results on training set with different values of lower cutoff on sentence length are shown in table
ll average recall score table
results on training set with different values of lower cutoff ll on sentence length
table and table show that the best results are obtained when lu is set to any value between and and ll is set to
we set the value of lu to and the value of ll to when we run the system on the test data
from pairs randomly chose document summary results
we document summary pairs in our corpus and considered this subset as a training set for tuning the values of several parameters discussed above
after setting the parameters to the values learnt from the training set we test our system on the entire collection of documents
from each of documents a summary of n words is generated where n is the length of the reference summary of the corresponding document

a system generated summary is compared to a reference summary and the unigram based recall score is computed using the equation

the average recall score is obtained by averaging the recall scores obtained on all the documents in the collection
of table shows the performance of the proposed system on the test data set

to our knowledge no generic text summarization system for bengali is available for comparison to our system
so we have compared the proposed method to the lead baseline
lead baseline considers the first n words of an input article as a summary where n is a predefined summary length
table shows the comparisons of our system to the lead baseline

methods average unigram based recall score proposed system lead baseline
comparison of the proposed system to lead baseline table shows that the proposed method outperforms the lead baseline

the evaluation of generic summarization systems in the past duc conferences duc and duc proves that it is very hard to beat
lead baseline on the news documents

an
example
the following is an article taken from the bengali daily newspaper ananda bazar patrika k i m p n t m dn do
n s a

an o o
k n
ei p
n
p
p i


s sp st o
i
s




s l m e pnt


p o nt o

ei s

us n dn s ee eee a dk ps


e
i k
i n




u o
dn

o a

m p
i o t n



s a i t dn
i
e n i o nt e
o n a e d m
s a
k ps s a am ee
n u o p o s
m here is the reference summary for the article mentioned above


a
si m pnt
p

m st n
ki
s i
dn a an t
n the following is the summary generated by the proposed system for the news article
k i

m p n t
m dn do o
k n
ei p
n
p o p i
s sp st o
conclusion
this paper discusses a single document text summarization method for bengali
many techniques have been developed for summarizing english

but a very few attempts have been made for bengali text summarization
the performance of the proposed system may further be improved by improving stemming process exploring more number of features and applying learning algorithm for effective feature combination

traditionally more than one reference summaries are used for evaluating each system generated summary but in our work we have used only one reference summary for summary evaluation
in future we will consider more than one reference summaries for summary evaluation
das bandyopadhyay

topic based bengali opinion summarization
references
ramanathan rao

a
lightweight stemmer for hindi

in the coling posters

proceedings of eacl
dorr zajic
schwartz

hedge trimmer
a parse and trim approach to headline generation

in proceedings of the hlt naacl

text summarization workshop and
document understanding conference duc pp
edmonton alberta
paice jones

the identification of important concepts in highly structured technical papers

in the proceedings of the
international conference on research and development in information retrieval sigir
lin c y and hovy
identifying topics by position
in proceedings of the applied natural
language processing conference

new brunswick new jersey association for computational linguistics

radev jing sty
tam
centroid based summarization of multiple documents
journal of information
processing and management elsevier volume issue pp

radev allison blair goldensohn blitzer celebi drabek lam liu otterbacher qi saggion
teufel topper winkel zhang

mead
a platform for multidocument multilingual text summarization

in proceedings of the
international conference on language resources and evaluation lrec lisbon portugal
zajic
dorr schwartz
bbn umd at
topiary
in the association for the north american chapter of
proceedings of computational
linguistics workshop on
document understanding boston ma pp

zajic dorr schwartz
automatic headline
generation for newspaper stories in workshop on automatic summarization philadelphia pa pp

miller

wordnet
a lexical
database for english communications of the association for computing machinery cacm
salton singhal mitra buckley

automatic text structuring
information processing and management and summary
journal of
edmundson

new methods in automatic extracting

journal of the association for computing machinery

luhn

the automatic creation of literature abstracts

ibm journal of research development
mani
automatic summarization volume of natural language processing amsterdam philadelphia john benjamins publishing company
jing

using hidden
markov modeling to decompose human written summaries
computational linguistics
jing mckeown

the decomposition of human written summary sentences in the proceedings of international conference on
research and development in information retrieval university of california berkeley august pages
kupiec pedersen
chen

a trainable document summarizer

in proceedings of research and development in information retrieval pp
conroy
text summarization via hidden markov models and pivoted qr matrix decomposition

tech
university of maryland college park
morris hirst
lexical cohesion computed by thesaural relations as an indicator of the structure of text computational linguistics
halliday hasan
cohesion in text
longman london

halliday k hasan
cohesion in english
english language series longman london
banko mittal witbrock
headline generation based on statistical translation
in proceedings of the annual meeting of the association for comptational linguistics hong kong pp

osborne
using maximum entropy for sentence extraction
in proceedings of the workshop on automatic summarization volume philadelphia pennsylvania annual
meeting of the acl association for computational linguistics morristown
baxendale
man made index for technical literature an experiment
ibm journal of research and development pages
barzilay elhadad

using lexical chains for text summarization

in proceedings of the workshop on intelligent scalable text summarization
pp
madrid spain

