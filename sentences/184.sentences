n a j r i
s c v
v i x r a structuring an unordered text document shashank yadav tejas shimpi c
ravindranath chowdary prashant sharma deepansh agrawal shivang agarwal abstract segmenting an unordered text document into different sections is a very useful task in many text processing applications like multiple document summarization question answering
this paper proposes structuring of an unordered text document based on the keywords in the document
we test our approach on wikipedia documents using both statistical and predictive methods such as the textrank algorithm and google s use universal sentence encoder
from our experimental results we show that the proposed model can effectively structure an unordered document into sections
index terms ordering sentences text processing structuring document introduction t o structure an unordered document is an essential task in many applications
it is a post requisite for tions like multiple document extractive text summarization where we have to present a summary of multiple ments
it is a prerequisite for applications like question swering from multiple documents where we have to present an answer by processing multiple documents
in this paper we address the task of segmenting an unordered text ment into different sections
the input document summary that may have unordered sentences is processed so that it will have sentences clustered together
clustering is based on the similarity with the respective keyword as well as with the sentences belonging to the same cluster
keywords are identied and clusters are formed for each keyword
we use textrank algorithm to extract the keywords from a text document
textrank is a graph based ranking algorithm which decides the importance of a vertex within a graph by considering the global information recursively computed from the entire graph rather than focusing on local vertex specic information
the model uses knowledge acquired from the entire text to extract the keywords
a cluster is generated for every keyword
while generating clusters the similarity between a tence and a topic keyword is calculated using the cosine similarity of embeddings generated using google s use universal sentence encoder
use is claimed to have better performance of transfer learning when used with sentence level embeddings as compared to word level beddings alone
this model is claimed to have better formance even if there is less task specic training data available
we observed that the quality of clusters section is better if the similarity of a sentence with the keyword is considered along with the similarity of the sentence with the sentences already available in the respective section
to test our approach we jumble the ordering of department of computer science and engineering iit bhu
e mail jas
nitin

ac
in rchowdary

ac
in prashant
sharma

ac
in deepansh
agrawal

ac
in
shivanga
rs

ac
in shashank
yadav

ac
in tences in a document process the unordered document and compare the similarity of the output document with the original document
related work several models have been performed in the past to retrieve sentences of a document belonging to a particular topic
given a topic retrieving sentences that may belong to that topic should be considered as a different task than what we aim in this paper
a graph based approach for extracting information relevant to a query is presented in where subgraphs are built using the relatedness of the sentences to the query
an incremental integrated graph to represent the sentences in a collection of documents is presented in
sentences from the documents are merged into a master sequence to improve coherence and ow
the same ordering is used for sequencing the sentences in the extracted summary
ordering of sentences in a document is discussed in
in this paper we aim to generate the sections clusters from an unordered document
to the best of our knowledge this is a rst attempt to address this problem formally
proposed model our methodology is described in the figure
the process starts by taking an unordered document as an input
the next step is to extract the keywords from the input ument using textrank algorithm and store them in a list k
the keywords stored in k act as centroids for the clusters
note that the quality of keywords extracted will have a bearing on the nal results
in this paper we present a model that can be used for structuring an unstructured document
in the process we use a popular keyword traction algorithm
our model is not bound to textrank and if a better keyword extraction algorithm is available it can replace textrank
the next step is to nd the most relevant sentence for each keyword in k
the most relevant sentence is mapped to the keyword and assigned in the respective cluster
this similarity between the keyword and the sentence is lated by the cosine similarity of embeddings generated from google s use
now we have a list of keywords k and a sentence mapped to each keyword
the next step is to map the remaining sentences
in the next step we go through all the sentences in the document that have not been mapped yet and nd the relevant keywords that can be mapped with them
we do this by the following procedure y is the similarity between the current sentence and the keyword y
y is the maximum similarity between the current sentence and the sentences that are already mapped with the keyword y
if y has three tences mapped to it then the similarity between and the sentences mapped to y are computed and the maximum similarity among the three is assigned to
the overall similarity y is calculated as y t y t y we map every other sentence to the keyword with which they have maximum similarity m y
later we cluster the keywords along with the sentences mapped to them
the value of t signies the importance to be given to the keyword and its associated sentences respectively
in our experiments we empirically x the value of t to

input document find keywords using textrank store them in k for each keyword in k find the most relevant sentence and map it
map each sentence to the most appropriate cluster clusters with keword relevant sentences fig

proposed methodology
metrics to evaluate our algorithm to evaluate our algorithm we propose two similarity rics and
these metrics compute the similarity of each section of the original document with all the tions clusters keyword and the sentences mapped to it of the output document and assign the maximum similarity
between an input section and an output section is calculated as the number of sentences of the input section that are present in the output section divided by the total number of sentences in the input section
to calculate the nal similarity similarity of the entire output document we take the weighted mean of similarity calculated responding to each input section
between an input section and an output section is computed as the number of sentences of an input section that are present in an output set no
average





table results

















section divided by the sum of sentences in the input and output sections
the nal similarity is computed in a similar manner
experimental setup and results for our experiments we prepared ve sets of documents
each set has wiki documents randomly chosen
each document is restructured randomly sentences are ranged randomly
this restructured document is the input to our model and the output document is compared against the original input document
also we compare our results with the baseline being the results when we consider only the similarity between sentences and keywords
the results are shown in table
here both and are the mean of similarities of the entire set
and are computed similar to and respectively but with the t value as in equation
it is evident that the results are better if both similarities y and y are considered
we proposed an efcient model to structure an unordered document
we evaluated our model against the baseline and found that our proposed model has a signicant ment
we observed that while ordering an unordered ment the initial sentences associated with a keyword topic play a signicant role
references daniel cer yinfei yang sheng yi kong nan hua nicole limtiaco rhomni st
john noah constant mario guajardo cespedes steve yuan chris tar yun hsuan sung brian strope and ray kurzweil
universal sentence encoder
corr

c
ravindranath chowdary and p
sreenivasa kumar
sentence dering for coherent multi document summary generation
in ing data information and knowledge british national conference on databases bncod cardiff uk july
proceedings pages
c
ravindranath chowdary and p
sreenivasa kumar
esum an efcient system for query specic multi document summarization
in advances in information retrieval european conference on ir research ecir toulouse france april
proceedings pages
c
ravindranath chowdary m
sravanthi and p
sreenivasa mar
a system for query specic coherent text multi document international journal on articial intelligence tools summarization

lun wei ku li ying lee tung ho wu and hsin hsi chen
major topic detection and its application to opinion summarization
in proceedings of the annual international acm sigir conference on research and development in information retrieval sigir pages new york ny usa
acm
for each sentence that has not been mapped yet loop through all the keywords in k find similarity between the sentence and the cluster belonging to that keyword
conclusions rada mihalcea and paul tarau
textrank bringing order into text
in proceedings of the conference on empirical methods in natural language processing emnlp a meeting of sigdat a special interest group of the acl held in conjunction with acl july barcelona spain pages
m
sravanthi c
ravindranath chowdary and p
sreenivasa mar
quests a query specic text summarization system
in ceedings of the twenty first international florida articial intelligence research society conference may coconut grove florida usa pages
aaai press

