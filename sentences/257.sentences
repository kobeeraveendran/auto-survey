r a l c
s c v
v i x r a audio summarization with audio features and probability distribution divergence carlos emiliano gonzalez romain eric and juan manuel torres lia avignon universite chemin meinajaries avignon france carlos emiliano
gonzalez gallardo eric
sanjuan juan manuel
avignon
fr romain

com departement gigl polytechnique montreal c
p
succ
centre ville montreal quebec canada abstract
the automatic summarization of multimedia sources is an important task that facilitates the understanding of an individual by condensing the source while maintaining relevant information
in this paper we focus on audio summarization based on audio features and the probability of distribution divergence
our method based on an tive summarization approach aims to select the most relevant segments until a time threshold is reached
it takes into account the segment s length position and informativeness value
informativeness of each ment is obtained by mapping a set of audio features issued from its frequency cepstral coecients and their corresponding jensen shannon divergence score
results over a multi evaluator scheme shows that our approach provides understandable and informative summaries
keywords audio summarization js divergence informativeness human language understanding introduction multimedia summarization has become a major need since internet platforms like provide easy access to massive online resources
in general matic summarization intends to produce an abridged and informative version of its source
the type of automatic summarization we focus in this article is audio summarization which source corresponds to an audio signal
audio summarization can be performed with the following three approaches directing the summary using only audio features extracting the text inside the audio signal and directing the summarization process using textual methods and an hybrid approach which consists of a mixture of the rst two
each approach has advantages and disadvantages with regard to the others
using only audio features for creating a summary has the advantage of
youtube
c
e
gonzalez gallardo et al
being totally transcript independent however this may also be a problem given that the summary is based only on how things are said
by contrast directing the summary with textual methods benets from the information contained within the text dealing to more informative summaries nevertheless in some cases transcripts are not unavailable
finally using both audio features and textual methods can boost the summary quality yet disadvantages of both approaches are present
the method we propose in this paper consists of an hybrid approach ing training phase while text independent during summary creation
it resides on using textual information to learn an informativeness representation based on probability distribution divergences that standard audio summarization with audio features does not consider
during the summarization process this sentation is used to obtain an informativeness score without a textual tion of the audio signal to summarize
to our knowledge probability distribution divergences have not been used for audio summarization
the rest of this article is organized as follows
in section we give an overview of what audio summarization is we include its advantages and disadvantages comparing it with other summarization techniques
during section we explain how the probability distribution divergence may be used over an audio marization framework and we describe in detail our summarization proposal
in section we describe the dataset used during training and the summary generation phases as well as the evaluation metric that we adopted to measure the quality of the produced summaries and the results from the experimental evaluation of the proposed method
finally section concludes the article
audio summarization audio summarization without any textual representation aims to produce an abridged and informative version of an audio source using only the information contained in the audio signal
this kind of summarization is challenging because the available information corresponds to how things are said this is advantageous in terms of transcripts availability
hybrid audio summarization methods or text based audio summarization algorithms need automatic or manual speech transcripts to select the pertinent segments and produce an informative summary
nevertheless speech transcripts may be expensive non available or of low quality this creates repercussions over the summarization performance
duxans al
managed to generate audio based summaries of a soccer match using re transmissions that detect highlighted events
they based their detection algorithm on two acoustic features the block energy and the acoustic repetition indexes
the performance was measured in terms of goal recall and summary precision showing high rates for both categories
maskey et al
presented an audio based summarization method using a hidden markov model hmm framework
they used a set of dierent tic prosodic features to represent the hmm observation vectors speaking rate min max mean range and slope min max and mean rms energy rms audio summarization with audio features and p
d
d
slope and sentence duration
the hidden variables represented the inclusion or exclusion of a segment within the summary
they performed experiments over cnn shows and stories previously used in
evaluation was made with standard precision recall and f measures information retrieval measures
sults show us that the hmm framework had a very good coverage recall
but a very poor precision p recision
when selecting pertinent segments
zlatintsi et al
addressed the audio summarization task by exploring the potential of a modulation model for the detection of perceptually important audio events
they performed a saliency computation of audio streams based on a set of saliency models and various linear adaptive and nonlinear fusion schemes
experiments were performed over audio data extracted from six minute movie clips
results were reported in terms of frame level precision scores showing that nonlinear fusion schemes perform best
audio summarization based only on acoustic features like fundamental quencies energy volume change and speaker turn has the big advantage that no textual information is needed
this approach is especially useful when human transcripts are not available for the spoken documents and automatic speech recognition asr transcripts have a high word error rate
however for high informative contexts like broadcast news bulletins or reports most relevant formation resides on the things that are said while audio features are limited to how things are said
probability distribution divergence for audio summarization all presented methods in the previous section omit the informativity content of the audio streams
in order to overcome the lack of information we propose an extractive audio summarization method capable of representing the ness of a segment in terms of its audio features during training phase tiveness is mapped by a probability distribution divergence model
then when creating a summary textual independence is reached using only audio based features
divergence is dened by manning as a function which estimates the ence between two probability distributions
in the framework of automatic text summarization evaluation have used divergence based measures such as kullbackleibler and jensenshannon js to compare the probability bution of words between automatically produced summaries and their sources
extractive summarization based on the divergence of probability distributions has been discussed in and a method has been proposed in divtex
our proposal based on an extractive summarization approach aims to select the most pertinent audio segments until a time threshold is reached
a training phase is in charge of learning a model that maps a set of audio features to an informativeness value
a big dataset is used to compute the informativeness by obtaining the divergence between the dataset documents and their corresponding segments
during the summarization phase the method takes into account the c
e
gonzalez gallardo et al
segment s length position and the mapped informativeness of the audio features to rank the pertinence of each audio segment

audio signal pre processing during the pre processing step the audio signal is split into background and foreground channels
this process is normally used on music records for ing vocals and other sporadic signals from accompanying instrumentation
rai et
al achieved this separation for identifying recurrent elements by looking for similarities instead of periodicities
rai et
al approach is useful for those song records where repetitions happen intermittently or without a xed period however we found that applying the same method to newscasts and reports audio les made much easier to segment them using only the background signal
we assume this phenomena is due to the fact that newscasts and reports are heavily edited with a low volume of background music playing while the journalist speak and louder music noises for transitions foreground
following to suppress non repetitive deviations from the average trum and discard vocal elements audio frames are compared using the cosine similarity
similar frames separated by at least two seconds are aggregated by taking their per frequency median value to avoid being biased by local ity
next assuming that both signals are additive a pointwise minimum between the obtained frames and the original signal is applied to obtain a raw background lter
then a foreground and background time frequency mask is derived from the raw background lter and the input signal with a soft mask operation
nally foreground and background components are obtained by multiplying the time frequency masks with the input signal

informativeness model informativeness is learned from the transcripts of a big audio dataset such as newscasts and reports
a mapping between a set of audio features and an informativeness value is learned during the training phase
it corresponds to the jensen shannon divergence djs between the segmented transcripts and their source
the djs is based on the kullback leibler divergence with the main ference that is symmetric
the djs between a segment q and its source p is dened by as pw pw qw qw pw qw wp c p pw qw w w c q audio summarization with audio features and p
d
d
where c p w is the frequency of word w over p or q
to avoid shifting the probability mass to unseen events the scaling parameter is set to

and corresponds to the number of tokens on p and q
finally
where is the vocabulary size on p
each segment q has a length of seconds and is represented by dio features where corresponds to statistical values of mel frequency cepstral coecients mfcc and the other two correspond to the number of frames in the segment and its starting time
the statistical values can be seen in table where and corresponds to the rst and second mfcc derivative
feature mfcc min max median mean variance skewness kurtosis table
mfcc based statistical values a linear least squares regression model y is trained to map the audio features x into a informativeness score y
figure shows the whole training phase informativeness model
all audio processing and feature tion is performed with the librosa library

audio summary creation the summary creation of a document p follows the same audio signal processing steps described in section

during this phase only the audio signal is needed and informativeness of each candidate segment qi p is predicted with the yqi model
figure shows the full summarization pipeline to obtain a threshold length summary of an audio document p
after the background signal is isolated from the main signal a constrained agglomerative clustering routine is used to partition the audio stream into contiguous segments
plength being plength the length in seconds of p

github
io librosa index
html c
e
gonzalez gallardo et al
fig

informativeness model scheme to rank the pertinence of each segment


qk a score sqi is computed
audio summarization is performed by choosing those segments which contain higher sqi scores in order of appearance until is reached
sqi is dened as sqi ti e here ti tqi being the starting time of the segment qi and the starting time of
and corresponds to the length in seconds of the segment qi and p respectively
experimental evaluation we trained the informativeness model explained in section
with a set of audio broadcasts which corresponds to more than hours of audio in french english and arabic
transcripts were obtained with the asr system described on
during audio summary creation we focused on a small dataset of english audio samples
in this phase no asr system was used given the text dence our systems achieves once the informativeness model has been obtained
selected sample lengths vary between seconds and seconds with an average length of seconds
similar to rott et al
we implement a subjective scaled opinion ric to evaluate the quality of the generated summaries and their parts
during evaluation we provided a set of ve evaluators with the original audio the erated summary their corresponding segments and the scale shown in table
audio summarization with audio features and p
d
d
fig

summary creation scheme
results summary length was set to be the of the original audio length during perimentation
evaluation was performed over the complete audio summaries as well as over each summary segment
we are interested on measuring the tiveness of the generated summaries but also on measuring the informativeness of each one of its segments
score explanation full informative mostly informative half informative quite informative not informative table
evaluation scale table shows the length of each video and the number of segments that were selected during the summarization process
full score corresponds to the complete audio summaries evaluation while average score to the score of their corresponding summary segments
both metrics represent dierent things and seem to be quite correlated
full score quanties the informativeness of all the summary as a whole while average score represents the summary quality in terms of the information of each of its segments
to validate this observation we computed the linear correlation between these two metrics obtaining a pcc value equal to

c
e
gonzalez gallardo et al
the average scores of all evaluators can be seen in table
the lowest full score average value obtained during evaluation was
and the highest
meaning that the summarization algorithm generated at least half informative summaries
average score values oscillate between
and

an ing case is sample which according to its full score is mostly informative table but has the lowest average score of all samples
this dierence is given because of its summary segments has an informativity score but in general it achieves to communicate almost all the relevant information
figure plots the average score of each one of the segments for sample
sample length segments full score average score



















table
audio summarization performance over complete summaries and summary segments fig

audio summarization performance for sample a graphical representation of the audio summaries and their performance can be seen in figure
full audio streams are represented by white bars while audio summarization with audio features and p
d
d
mary segments are represented by the gray zones
the height of each summary segment corresponds to their informativeness score
fig

graphical representation of audio summarization performance from figure it can be seen that samples and have all their summary segments clustered to the left
this is due to the preference that the summarization technique is given to the rst part of the audio stream region whereby within a standard newscast is gathered the major part of the information
the problem is that in cases where dierent topics are covered over the newscast multi topic newscast interviews round tables reports
relevant information is distributed all over the video
if a big amount of relevant segments are grouped in this region the summarization algorithm uses all the space available for the summary very fast discarding a large region of the audio stream
this is the case of samples and which full scores are less to

concerning sample a well distribution of its summary segments is served
from its segments only had an informativeness score achieving the highest full score of all samples and a good average score
c
e
gonzalez gallardo et al
conclusions in this paper we presented an audio summarization method based on audio features and on the hypothesis that mapping the informativeness from a trained model using only audio features may help to select those segments which are more pertinent for the summary
informativeness of each segment was obtained by mapping a set of audio tures issued from its mel frequency cepstral coecients and their corresponding jensen shannon divergence score
summarization was performed over a sample of english newscasts demonstrating that the proposed method is able to ate at least half informative extractive summaries
we can deduce that there is not a clear correlation between the quality of a summary and the quality of its parts
however this behavior could be modeled as a recall based relation between both measures
as future work we will validate this hypothesis as well as expand the uation dataset from a multilingual perspective to consider french an arabic summarization
acknowledgments we would like to acknowledge the support of chist era for funding this work through the access multilingual information opinions amis france rope project
references
christensen h
gotoh y
renals s
a cascaded broadcast news highlighter
ieee transactions on audio speech and language processing
duxans h
anguera x
conejero d
audio based soccer game summarization
in broadband multimedia systems and broadcasting

ieee ternational symposium on
pp

ieee
jouvet d
langlois d
menacer m
fohr d
mella o
smali k
adaptation of speech recognition vocabularies for improved transcription of youtube videos
journal of the international science and general applications
kullback s
leibler r
a
on information and suciency
the annals of matical statistics
leszczuk m
grega m
a
gliwski j
wasieczko k
smali k
video summarization framework for newscasts and reports work in progress
in dziech a
czyzewski a
eds
multimedia communications services and security
pp

springer international publishing cham
louis a
nenkova a
automatic summary evaluation without human models
in tac
louis a
nenkova a
automatically evaluating content selection in tion without human models
in conference on empirical methods in natural language processing volume volume
pp

acl
manning c
d
schutze h
foundations of statistical natural language ing
mit press cambridge ma usa audio summarization with audio features and p
d
d

maskey s
hirschberg j
comparing lexical acoustic prosodic structural and discourse features for speech summarization
in ninth european conference on speech communication and technology
maskey s
hirschberg j
summarizing speech without text using hidden markov models
in proceedings of the human language technology conference of the naacl companion volume short papers
pp

association for tional linguistics
mcfee b
rael c
liang d
ellis d
p
mcvicar m
battenberg e
nieto o
librosa audio and music signal analysis in python
in python in science conference
pp

rai z
pardo b
music voice separation using the similarity matrix
in ismir
pp

rott m
cerva p
speech to text summarization using automatic phrase traction from recognized text
in sojka p
horak a
kopecek i
pala k
eds
text speech and dialogue
pp

springer international publishing cham
saggion h
torres moreno j
m
cunha i

sanjuan e
multilingual marization evaluation without human models
in proceedings of the national conference on computational linguistics posters
pp

ing association for computational linguistics stroudsburg pa usa
acm
org citation


szaszak g
tundik m
a
beke a
summarization of spontaneous speech using automatic speech recognition and a speech prosody based tokenizer
in kdir
pp

taskiran c
m
pizlo z
amir a
ponceleon d
delp e
j
automated video program summarization using speech transcripts
ieee transactions on dia aug


tmm


torres moreno j
m
automatic text summarization
john wiley sons i
sanjuan e

torres moreno j
saggion h
da cunha morales p
summary evaluation with and without references
polibits
cidetec
ipn
mx ojs index
php article
zechner k
spoken language condensation in the century
in eighth pean conference on speech communication and technology
zlatintsi a
iosif e
marago p
potamianos a
audio salient event detection and summarization using audio and text modalities
in signal processing ence eusipco european
pp

ieee
zlatintsi a
maragos p
potamianos a
evangelopoulos g
a saliency based approach to audio event detection and summarization
in signal processing ference eusipco proceedings of the european
pp

ieee
