on utilization and importance of perl status reporter srr in text mining sugam tzusheng and hari department of computer science iowa state usa center for bioinformatics jackson state usa sugam


com from the high quality abstract in bioinformatics text mining and text data mining sometimes interchangeably used is a process to derive high quality information text
perl status reporter srr is a data fetching tool from a flat text file and in this research paper we illustrate the use of srr in text data mining
srr needs a flat text input file where the mining process to be performed
srr reads input file and derives information from it
typically text mining tasks are text clustering text categorization concept and entity extraction and document summarization
srr can be utilized for any of these tasks with little or none customizing efforts
in our implementation we text categorization mining operation on input file
the input file has two parameters of interest firstkey and secondkey
the composition of these two parameters describes the uniqueness of entries in that file in the similar manner as done by composite key in database
srr reads the input file line by line and extracts the parameters of form a composite key by joining them together
it subsequently generates an output file consisting as
srr reads the input file and tracks the composite key
it further stores all that data lines having interest and perform name the of is stored regexpr file the same composite key in output file that generated by srr based on composite key
keywords perl handler

introduction labour intensive manual text mining approaches first came into picture in the for past decades but technological advances have dominated the field with fast pace
as most of the information text text mining is blowing with a high demand
text mining in is extracting knowledge from growing literature in different research areas such as bioinformatics
text mining techniques are used to extract useful information from unstructured text and different databases such as pubmed
we apply perl srr on traffic database for texting mining to analyze the traffic data
the input file is a flat file in textual format contains traffic data
the first column entry is the identification i d of the city where the traffic has been collected from
this i d is unique for a particular metro city
the second column entry is the name of that fundamental knowledge and in ijcsis international journal of computer science and information security vol
no

google
com site issn metro city
the third column entry is the name of the company responsible for data collection in the respective metro city area
next column entry is the date the traffic data has been collected on
rest of the column entries are self informative and are not much important in our development
column entries first and third are of our interest and we call them as parameters of interest
to try in this paper we call the first column enrty as firstkey and third column entry as secondkey
as text mining is somewhere concern with relate our database so we parameters of interest with composite key concept of database management system
in text mining there is a key factor which is the base for information retrieval
our likewise implementation firstkey and secondkey are the main factors in mining
srr joins these keys together and form a composite key
srr uses this composite key to segregate the data from the input data file
in srr reads the input text file one line at a time eradicates its separator and stores the contents of that line in an array
the filled array is further operated to extract firstkey and secondkey
srr joins these keys together and form a composite key subsequently
srr keeps tracking the input data and generates output files based on the composite key
the name of the file will be same as the composite key
the extracted data consisting of the same composite key will be stored in that generated output file
thus for an individual composite key srs generates a separate output file and fill it in the same fashion as stated above
the rest of the paper is organized as follows
section
is the mining process section
this section details about the recent mining in computer trends science and bioinformatics and mining operation srr performs on input text file
section
is the result section
this section consists of input sample file implementation and we use sample output produced
section
is the conclusion section and last the section
is the reference section
in our mining
mining process and srr text mining is utmost popular under bioinformatics umbrella and has a big range of text mining applications in the biomedical literature
mining can be described as discovery by computer of new previously unknown information by automatically extracting information from different written resources
in our development we use a flat file in textual format
a key element is to utilize the extracted information to form new facts or new hypotheses to be explored further by more conventional means of experimentation
text mining is different from web search
in search the user has a goal to search for something that is already written by some one and exists in the database
in text mining the target is to discover unknown information that is not yet known and could not have yet written down
text mining is a variation on a field called data mining that tries to find large interesting patterns from databases
there are many upcoming tools being developed every day for text is one more mining and perl srr development in the same direction and for the same purpose
the beauty of srr ijcsis international journal of computer science and information security vol
no

google
com site issn is tool that srr is over existing completely written in perl and is highly customizable
the scope of operation of srr is not only limited to text mining in bioinformatics but also text mining in other areas as well where srr is capable to perform mining process with more a than multipurpose in information extraction process
is accuracy
srr tool well efficient srr performs the mining process on flat text input file
the following code snippet describes how srr reads the input file and parses the sentences and categories the text
we write the sample code easy understanding
block wise to make in the following segment we declare the variables globally
to variable we assign the input file to be processed
in our implementation we use
txt as the input file and is a flat textual file
my
txt my my my my my my using in following block of code srr reads a file handler a inputhandler
if srr is unable to open the input file it throws a message
file open inputhandler die could not open file for reading
srr has performed the text mining operations on input file in the following segment srr reads the input flat file one line at a time splits the line based on the separator used and stores the contents in an array
while inputhandler split my now srr extracts the text from current line
we assign the parameters of interest in and variables respectively
the following block of code depicts this
shift shift shift the following segment is bit confusing but not a rocket science definitely
this part of srr just tracks the composite attributes generates the file based on those attributes and stores those data line containing the same composite attributes in that file
srr uses if els statement to separate out the generation of different files
the generated files are opened in append mode and any number of line can be added to it
srr uses a file handler outputhandler to write out the data to the file
eq



txt open outputhandler die could not open file for writing
print outputhandler eq ne



txt open outputhandler open file for writing
print outputhandler ne



txt open outputhandler die could not open file for writing
print outputhandler else



txt open outputhandler ijcsis international journal of computer science and information security vol
no

google
com site issn die could not open file for writing
print outputhandler
results
input file snippet in this section we show the curtailed sample input text file we use in our implementation
the data in the file is road traffic data in different metro cities in united states
the first column represents an i d of the city and second column represents the name of the city where the traffic belongs to
the third column represents the company name which collects the traffic data for that city
rests of are to understand
informative column first and third are of our interest and together they form a composite key which differentiates the line from other lines
columns enough the road road road road road no road w
no road center w
no road center w no road w no road e no road center e no road center e
no road e
no road e
no road e
no road w
n
n
n
s
s
s
n center n
e
e
w
w
ijcsis international journal of computer science and information security vol
no

google
com site issn n
n
n s s
e
e
w

output file snapshot in this section we collect the results
we capture snapshots of all output files
input file which has in first column and idot in third column and generates a file with name before storing the extracted text
figure shows the stored data in the file generated by srr
figure shows the contents of the file
srr generates a file named as
figure shows the contents of that file
figure shows the generated file and its contents
figures file and the data stored in that
figure is file showing its contents extracted from the input file and stored by srr
represents figure
srr status screen display figure
extracted text stored in generated file figure
extracted text stored in generated file figure
extracted text stored in generated file ijcsis international journal of computer science and information security vol
no

google
com site issn text file
figure is a screen shot depicting the progress of srr
figure
extracted text stored by in generated file the data figure shows the contents of the file generated by srr
the name of the file is
srr extracts that data from the
conclusion srr is a text mining tool performs mining operations on input text file and lines based on segregates composite attributes
we analyze the results generated by srr and found that each file has distinct data stored in it based on its composite attributes
in this research paper the mining operation has been performed on an input text file consisting of traffic data but functioning of srr is not confined till here
srr is a customizable tool and can be applied to other applications as well where one reads an input file
in this research paper we have applied srr on traffic data file and our next goal is to use srr on file consisting genomics data and sequence analyzing subsequently
it is a rare and noble work we have done that perl developed mining tool srr extracts the traffic data and segregates that for easy analyzing
we believe that our work will and help communities academia figure
extracted text stored in generated file figure
extracted text stored in generated file figure
extracted text stored in generated file first figure shows the progress of srr running and rest of the snapshots show the contents segregated from the input ijcsis international journal of computer science and information security vol
no

google
com site issn journal international industry and prove itself as a leader in text data mining

reference
sugam sharma hari cohly and tzusheng pei on generation of firewall log status reporter srr using perl submitted for review in international journal of computer science applications april

sugam sharma tzusheng pei and hhp cohly raphael isokpehi and n to access pubmed meghanathan to extract articles using database of computer science and network security ijcsns
ijcsis international journal of computer science and information security vol
no

google
com site issn
