simple qe better automatic quality estimation for text simplication reno kriz marianna and chris callison burch computer and information science department university of pennsylvania cnrs llf france and university of helsinki finland rekriz
upenn
edu marianna

fi c e d l c
s c v
v i x r a abstract text simplication systems generate versions of texts that are easier to understand for a the quality of broader audience
ed texts is generally estimated using metrics that compare to human references which can be difcult to obtain
we propose qe a bert based quality estimation qe model adapted from prior summarization qe work and show that it correlates well with man quality judgments
simple qe does not require human references which makes the model useful in a practical setting where users would need to be informed about the quality of generated simplications
we also show that we can adapt this approach to accurately dict the complexity of human written texts
specic pieces of information from the original and omit unimportant passages ed text typically expresses all the content present in the original text using simpler words and tures
both types of text however need to ll some linguistic quality constraints in order to be useful such as being grammatical and formed
we show that simple qe correlates well with human judgments of linguistic quality on tem output produced by simplication systems
in addition we adapt our model to make reasonable complexity predictions at both the sentence and document level
our models can be used to mize both simplication system development and the process of writing manual simplications
introduction related work simplication systems make texts easier to stand for people with reading disabilities and guage learners or for readers not yet familiar with a specic domain
they propose re writings using simpler meaning preserving words and structures
for automatically produced simplications to be useful in practical settings users should be able to easily assess their quality
traditional evaluation metrics papineni et al
xu et al
timate the quality of generated texts by comparing them to human written simplications which stricts their use to settings where such references are available
in addition comparing tions to a single reference is often too restrictive as most texts can be simplied in a variety of ways
we propose a model for measuring the quality of automatically generated simplications which does not require human references
our model simple quality estimation simple qe adapts the bert based summary qe model sum qe xenouleas et al
to the simplication ting
as opposed to summaries which contain quality estimation qe methods were rst troduced in the eld of machine translation to measure the quality of automatically translated text without need for reference translations jar et al
martins et al
specia et al

in the most recent qe task the best tems leveraged bert via pre training for specic language pairs and integrating a transfer learning approach fonseca et al

xenouleas et al
propose several sions to the bert ne tuning process devlin et al
to estimate summary quality
their proposed model sum qe predicts ve linguistic qualities of generated summaries using multi task training grammaticality non redundancy erential clarity focus and structure and ence
similar to state of the art results obtained by bert on many classication tasks xenouleas et al
show that bert can be successfully applied to qe
in our work we adapt sum qe to simplication qe estimating the fluency quacy and complexity of simplied text
figure the simple qe architecture with and without adding numeric features corresponding to the original complex sentence original features and the system output system features
r denotes a regressor layer
alva manchego et al
most recent simplication research uses both automatic metrics and human judgments during evaluation zhang and lapata kriz et al
mallinson and lapata
the metrics commonly used are bleu papineni et al
meteor banerjee and lavie and sari xu et al

contrary to simple qe these metrics require a reference sentence
furthermore bleu correlates poorly with deletion a core pect of simplication sulem et al

sari correlates well with human simplication ments at the lexical level but this does not transfer to the sentence level as shown in our experiments
recently ated a toolkit to calculate various standard tomatic simplication metrics including sari word level accuracy scores and qe features such as compression ratio and average number of added deleted words
recent work that addresses qe for simplication experiment with a variety of features including sentence length average token length and language model probabilities stajner et al
martin et al

however the best models from these works also use reliant features such as bleu and translation error rate as these have been shown to correlate with fluency and adequacy
note that these works were carried out before the rise of large scale trained models peters et al
devlin et al

sum qe and our adaptation simple qe explicitly leverage the ne tuning capabilities of bert for assessing the quality of generated text
methodology to estimate the quality of a simplication system output we focus on three linguistic aspects fluency how well formed it is
adequacy how well it preserves the meaning of the original text
complexity how much simpler it is than the original text
we adapt the architecture posed by xenouleas et al
in their sum qe model which extends the bert ne tuning cess devlin et al
to rate summaries with respect to ve linguistic qualities
we expect ency in our setting to align well with cality as addressed by sum qe
in the case of equacy and complexity since judgments are is the generated text simpler than the ative e

original text does it convey the same meaning we need to also consider the original complex text
xenouleas et al
use bert as the main encoder and ne tune it in three ways one task and two multi task approaches single task train k models on each annotation type where k is the number of guistic qualities here k
multi train one model with a single regressor to predict k annotations
multi task k train one model with k separate regressors
to adapt sum qe to simplication we extend the architecture to take into account the original complex sentence
we do so by passing the inal complex sentence and simplication system output through the bert architecture separately
we concatenate the resulting embedding tations and pass them through a nal dense linear regressor layer r to predict each linguistic quality score
our adaptation of the sum qe multi approach is described on the left side of figure
to further adapt the qe model to our task we also attempt to incorporate task specic features the average length of content words in a tence in characters and in syllables their gram the sentence length and the use the average log unigram frequency from the syntactic parse height
we pass these features extracted from the original complex sentence arately through a linear layer before ing them with the bert embeddings of the tence
we do the same for the system output
the right side of figure describes this architecture
qe experiments on system output
data and baselines our test data consists of human judgments lected by kriz et al
on generated cations for newsela sentences xu et al

for each sentence outputs from six simplication models were considered vanilla sequence to sequence nisioi et al
learning with reinforcement zhang and lapata memory augmented transformer zhao et al
and three ations of with post training re ranking kriz et al

annotators were asked to rate the fluency adequacy and complexity of each system output on a point likert scale
we compare the simple qe model to baselines that use the simplication specic features scribed in section quality estimates provided by bleu papineni et al
and sari xu et al
and three additional bert based baselines
bert as language model bert lm given a sentence we mask each token and predict the likelihood of the true word ring in this context this captures fluency
bert embedding similarity bert sim we convert the original and simplied texts into sentence level bert vector tions via mean pooling and compute their sine similarity this estimates adequacy
sum qe we apply sum qe directly tuning only on annotated system output
for sum qe and simple qe we perform fold cross validation combining the results to compute the overall correlation

results the results are shown in table
simple qe relates better with human judgments than the line models tested
the correlation of bleu and google n gram corpus brants and franz
do not use the qe dataset introduced by stajner et al
as it focuses on small scale lexical changes similar to the turk dataset xu et al
while current neural models adopt a more holistic approach

com xu song bert as language model model bleu sari bert lm bert sim sum qe sum qe sum qe simple qe simple qe simple qe f









simple qe ph
simple qe sl

simple qe all a












c












table pearson correlation with human fluency f adequacy a and complexity c judgments on plication system output
the last three rows rate three numeric feature sets sentence length sl parse tree height ph and all features from section
sari with human judgments is particularly low especially for complexity
this is not surprising given that sari mainly addresses lexical cation while recent models approach tion more holistically
the three versions of simple qe perform ilar to sum qe on fluency where the model does not need to access the original complex tence
the difference between the two models is more noticeable for adequacy and ity where accessing the original sentence ally helps simple qe make more reasonable timates
from the three versions of simple qe tested the multi task versions perform better than the single task on all three qualities tested
the bert lm and bert sim baselines perform well on fluency and adequacy as expected but fall short on the other aspects of simplication
as shown in table adding numeric features do not improve performance
this may be because the most predictive features e

sentence length are already implicitly learned by bert
complexity prediction on human written text
datasets as seen in the previous section simple qe makes reasonable estimates for fluency and adequacy syntax of a sentence can be extracted from tual word embeddings with reasonable accuracy hewitt and manning
but scores lower on complexity
to explore this further we test sum qe s capability to predict the complexity of hand written text
assuming this text is relatively well formed we can in this way focus on how the model deals with complexity
we perform this analysis on the entire newsela corpus xu et al
which contains glish news articles re written at four complexity levels
we explore how well ne tuning bert performs compared to incorporating features into a linear regression classier linreg
since we only address complexity we only consider the single task approach simple qe

sentence level complexity prediction we generate data by labelling sentences from newsela articles with the complexity level of the corresponding document to
when a tence is found at different complexity levels we label it with the level of the simplest article in which it appears this results in sentences
we measure the correlation between each feature and the sentence s complexity level and perform fold cross validation for linreg and qe
the results of this experiment are shown in the rst column of table
sentence length is the most predictive feature and combining all the features using a linear regression classier proves correlation but both are outperformed by our model

document level complexity prediction most recent work has focused on sentence cation but document level simplication might be more useful in practical settings
given that bert can only process sub word units at a time we break a document down into documents of up to sub word units
at test time to get a single document level complexity prediction we take a length based weighted age of the predictions for the sub documents
the results of this experiment are shown in the second column of table
we can see that while sentence length and our linear regression classier rating all features perform quite well our model improves correlation even further

out of domain evaluation finally we use pwkp zhu et al
to plore how well our complexity prediction model
com sentence document model word length syllables frequency sentence length parse height linreg simple qe













table pearson correlation of the ne tuned bert model and different feature based baselines on the complexity prediction task at the sentence and the document level
transfers to a different domain
we extract parallel texts from simple and standard english wikipedia aligning texts by their unique article id
we label each simple wikipedia document with simpler and each standard wikipedia document with more complex
the alignment dure results in parallel documents
ilar to our document level complexity prediction experiments we combine the sentence and document predictions into a single document level prediction
in this experiment our model reaches a pearson correlation of

while this is lower than our in domain newsela experiments it is still reasonably high showing that our model can be applied for complexity prediction on other mains
conclusion we present simple qe a quality estimation model for simplication
we have shown that ing sum qe xenouleas et al
to include the reference complex sentence sensibly improves predictions on adequacy and complexity
qe tems can be useful for evaluating the overall ity of model output without requiring expensive human annotations or references
future cation systems can incorporate simple qe into the optimization process similar to how sari was incorporated into a network zhang and lapata
as shown a ne tuned bert can also predict the complexity of human written text especially at the document level
this nding can be leveraged in future work as the simplication eld moves towards simplifying entire documents
wikipedia dumps
wikimedia
org used can at
wikimedia
org be found and references fernando alva manchego louis martin carolina scarton and lucia specia

easse ier automatic sentence simplication evaluation
in proceedings of the conference on ical methods in natural language processing and the international joint conference on natural language processing emnlp ijcnlp system demonstrations pages hong kong china
association for computational linguistics
satanjeev banerjee and alon lavie

meteor an automatic metric for mt evaluation with proved correlation with human judgments
in ceedings of the acl workshop on intrinsic and trinsic evaluation measures for machine tion summarization pages ann bor michigan
association for computational guistics
ondrej bojar rajen chatterjee christian federmann yvette graham barry haddow shujian huang matthias huck philipp koehn qun liu varvara logacheva christof monz matteo negri matt post raphael rubino lucia specia and marco turchi

findings of the conference on machine translation
in proceedings of the second conference on machine translation pages copenhagen denmark
association for computational linguistics
thorsten brants and alex franz

web t gram version
in philadelphia vania
linguistic data consortium
jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language derstanding
in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies volume long and short papers pages minneapolis minnesota
ation for computational linguistics
erick fonseca lisa yankovskaya andre f
t
martins mark fishel and christian federmann

ings of the wmt shared tasks on quality timation
in proceedings of the fourth conference on machine translation volume shared task pers day pages florence italy
tion for computational linguistics
john hewitt and christopher d
manning

a structural probe for finding syntax in word sentations
in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies volume long and short papers pages minneapolis minnesota
ation for computational linguistics
reno kriz joao sedoc marianna apidianaki carolina zheng gaurav kumar eleni miltsakaki and chris callison burch

complexity weighted loss and diverse reranking for sentence simplication
in proceedings of naacl human language technologies volume pages
jonathan mallinson and mirella lapata

trollable sentence simplication employing tactic and lexical constraints
arxiv
louis martin samuel humeau pierre emmanuel mazare eric de la clergerie antoine bordes and benot sagot

reference less quality tion of text simplication systems
in proceedings of the workshop on automatic text adaptation ata pages tilburg the netherlands
ciation for computational linguistics
andre f
t
martins marcin junczys dowmunt fabio n
kepler ramon astudillo chris hokamp and roman grundkiewicz

pushing the its of translation quality estimation
transactions of the association for computational linguistics
sergiu nisioi sanja stajner simone paolo ponzetto and liviu p
dinu

exploring neural text simplication models
in proceedings of the annual meeting of the association for tional linguistics volume short papers pages vancouver canada
association for tational linguistics
kishore papineni salim roukos todd ward and jing zhu

bleu a method for automatic in evaluation of machine translation
ings of the annual meeting of the tion for computational linguistics pages philadelphia pennsylvania usa
association for computational linguistics
matthew peters mark neumann mohit iyyer matt gardner christopher clark kenton lee and luke zettlemoyer

deep contextualized word in proceedings of the resentations
ence of the north american chapter of the ation for computational linguistics human guage technologies volume long papers pages new orleans louisiana
association for computational linguistics
lucia specia blain varvara logacheva ramon astudillo and andre f
t
martins

findings of the wmt shared task on quality estimation
in proceedings of the third conference on machine translation shared task papers pages belgium brussels
association for putational linguistics
elior sulem omri abend and ari rappoport

bleu is not suitable for the evaluation of text plication
in proceedings of the conference on empirical methods in natural language cessing pages brussels belgium
ciation for computational linguistics
stratos xenouleas prodromos malakasiotis marianna apidianaki and ion androutsopoulos

qe a bert based summary quality estimation model
in proceedings of the conference on empirical methods in natural language ing and the international joint conference on natural language processing emnlp ijcnlp pages hong kong china
association for computational linguistics
wei xu chris callison burch and courtney napoles

problems in current text simplication search new data can help
transactions of the association for computational linguistics
wei xu courtney napoles ellie pavlick quanze chen and chris callison burch

optimizing statistical machine translation for text tion
transactions of the association for tional linguistics
xingxing zhang and mirella lapata

sentence simplication with deep reinforcement learning
in proceedings of the conference on cal methods in natural language processing pages copenhagen denmark
association for computational linguistics
sanqiang zhao rui meng daqing he andi saptono and bambang parmanto

integrating former and paraphrase rules for sentence in proceedings of the conference on cation
empirical methods in natural language ing pages brussels belgium
ation for computational linguistics
zhemin zhu delphine bernhard and iryna gurevych

a monolingual tree based translation model for sentence simplication
in proceedings of the international conference on computational linguistics coling pages jing china
coling organizing committee
sanja stajner maja popovic and hanna bechara

quality estimation for text simplication
in proceedings of the lrec workshop on quality sessment for text simplication pages toroz slovenia

