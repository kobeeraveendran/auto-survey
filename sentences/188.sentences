keyphrase generation a text summarization struggle erion c ano institute of formal and applied linguistics charles university prague czech republic
mff
cuni
cz ondrej bojar institute of formal and applied linguistics charles university prague czech republic
mff
cuni
cz r a l c
s c v
v i x r a abstract authors keyphrases assigned to scientic ticles are essential for recognizing content and topic aspects
most of the proposed supervised and unsupervised methods for keyphrase eration are unable to produce terms that are valuable but do not appear in the text
in this paper we explore the possibility of ing the keyphrase string as an abstractive mary of the title and the abstract
first we collect process and release a large dataset of scientic paper metadata that contains
lion records
then we experiment with ular text summarization neural architectures
despite using advanced deep learning models large quantities of data and many days of putation our systematic evaluation on four test datasets reveals that the explored text marization methods could not produce ter keyphrases than the simpler unsupervised methods or the existing supervised ones
introduction a valuable concept for searching and libraries is the ing scientic papers in digital keyphrase we use keyphrase and keyword changeably a short set of one or few words that represent concepts
scientic articles are monly annotated with keyphrases based on onomies of concepts and the authors judgment
finding keyphrases that best describe the contents of a document is thus essential and rewarding
most of the proposed keyphrase extraction lutions tend to be unsupervised florescu and caragea nguyen and luong rose et al
bougouin et al
campos et al
and generate terms by selecting the most propriate candidates ranking the candidates based on several features and nally returning the top n
another way is to utilize datasets of texts and keywords for training supervised models with guistic or other features to predict if candidates are keywords or not witten et al
turney medelyan hulth
all above methods propose n keyphrases for each article which are joined together with or other separator like to form the keyphrase string of that article
they suffer from various problems or discrepancies
first they are unable to nd an optimal value for n and require it as a preset parameter
furthermore semantic and syntactic properties of article phrases are analyzed separately
the meaning of paragraphs sections or entire document is thus missed
lastly only phrases that do appear in the article are returned
meng et al
recently proposed a deep pervised keyphrase generation solution trained on it successfully solves the last two a big dataset
problems above but not the rst one
motivated by recent advances in neural chine translation and abstractive text tion vaswani et al
foster et al
rush et al
see et al
in this paper we explore the possibility of considering keyphrase generation as an abstractive text summarization task
instead of generating keywords one by one and linking them to form the keyphrase string we consider the later as an abstractive summary of the concatenated paper title and abstract
ent recently proposed text summarization tectures are tried on four test datasets of article keyphrases tanti et al
rush et al
see et al

we trained them with a newly created dataset of
million article titles stracts and keyphrase strings that we processed and released
the selected text summarization models are compared with popular unsupervised and vised methods using rouge lin and match metrics
the results show that though
handle
trained with large data quantities for many days the tried text summarization methods could not produce better keywords than the existing vised or deep supervised predictive models
in our opinion a possible explanation for this is the fact that the title and the abstract may not carry cient topical information about the article even when joined together
in contrast when assigning keywords annotations of their paper authors are highly inuenced by the topic aspects of it
this paper carries several contributions spite the fact that no progressive result scores it is the rst work that considers were reached
keyphrase generation as an abstractive text marization task
we produced a large dataset of article titles abstracts and keywords that can be used for keyword generation text summarization or similar purposes
finally we evaluated the formance of different neural network architectures on summarization of article keyword strings paring them with popular unsupervised methods
scientic paper datasets because of the open source and open data tives many public datasets from various domains can be found online c ano and morisio
among the several collections of scientic cles some of them have gained considerable larity in research literature
in meng et al
we found a recent and big collection of k per abstracts and keyphrases
these metadata long to articles of computer science from acm digital library sciencedirect and web of ence
in hulth we found a collection of for train val and for testing stracts in english together with titles and authors keywords
the corresponding articles were lished from to and belong to the cipline of information technology
furthermore krapivin et al
released a dataset of for train val and for testing full articles published by acm from to in puter science domain
more information about similar keyphrase data collections or other able resources can be found in hasan and ng and in online repositories
regarding text summarization some of the most popular datasets are mainly used for testing english gigaword napoles et al
cnn daily mail described in section

nist
gov attribute records keyphrases title tokens abstract tokens av
keyphrase av
title av
abstract val test train k k m m k k m
m
m m m m




fullset
m
m m m

table statistics of oagk dataset of nallapati et al
and newsroom a erogeneous bundle of news articles described in grusky et al

these datasets are frequently used for the task of predicting titles from abstracts or short stories
however no keyphrases are vided they do not serve to our purpose
miner is a recent attempt to crawl scientic paper data from academic networks tang et al

the system extracts proles of researchers from digital resources and integrates their data in a mon network
a spin off is the open academic graph oag data collection sinha et al

to produce a usable collection for our purpose we started from oag
we extracted title abstract and keywords
the list of keywords was formed into a comma separated string and a guage identier was used to remove records that were not in english
abstracts and titles were lowercased and stanford corenlp tokenizer was used for tokenizing
short records of fewer than tokens in the abstract tokens in the title and tokens in the keywords were removed
for the test portion we selected documents of at least and tokens in each eld
data preprocessing stopped here for the release version no symbol ltering given that many researchers want to ter text in their own way
this new dataset named oagk can be used for both text summarization predicting title from abstract and keyphrase traction unsupervised supervised or deep vised tasks
some rounded measures about each set of released data are presented in table
keyphrase extraction strategies
unsupervised and supervised methods topicrank is an extractive method that creates topic clusters using the graph of terms and phrases bougouin et al

obtained topics are then ranked according to their importance in the ment
finally keyphrases are extracted by ing one candidate from each of the most important topics
a more recent unsupervised and based method for keyphrase extraction is yake it heuristically combines campos et al

features like casing word position or word quency to generate an aggregate score for each phrase and uses it to select the best candidates
one of the rst supervised methods is kea described by witten et al

it extracts those candidate phrases from the document that have good chances to be keywords
several tures like tf idf are computed for each date phrase during training
in the end nave bayes algorithm is used to decide if a candidate is a keyword or not binary classication
an improvement and generalization of kea is maui medelyan
additional features are puted and bagged decision trees are used instead of nave bayes
the author reports signicant formance improvements in precision recall and scores
the above keyphrase extraction methods and others like florescu and caragea or nguyen and luong reveal various lems
first they are not able to nd an optimal value for n number of keywords to generate for an article based on article contents and require it as a preset parameter
second the semantic and syntactic properties of article phrases considered as candidate keywords are analyzed separately
the meaning of longer text units like paragraphs or entire abstract paper is missed
third only phrases that do appear in the paper are returned
in practice authors do often assign words that are not part of their article
meng et al
overcome the second and third problem using an encoder decoder model copyrnn with a bidirectional gated recurrent unit gru and a forward gru with attention
they train it on a datasets of hundred thousands of samples consisting of abstract keyword one keyword only pairs
the model is entirely driven and can produce terms that may not appear in the document
it still produces one keyword at a time requiring n rst problem as parameter to create the full keyphrase string

text summarization methods to overcome the three problems mentioned in tion
we explore abstractive text tion models proposed in the literature trained with article abstracts and titles as sources and keyword strings as targets
they are expected to learn and paraphrase over entire source text and produce a summary in the form of a keyphrase string with no need for extra parameters
they should also introduce new words that do not appear in the stract
two simple encoder decoder variants based on lstms are described in figure of tanti et al

merge figure
encodes input and the current summary independently and merges them in a joint representation which is later decoded to predict the next summary token
inject model figure
on the other hand injects the source document context representation to the encoding part of the current summary before the decoding operation is performed
abs is presented in figure
a of rush et al

the encoder figure
takes in the put text and a learned soft alignment between the input and the summary producing the context tor
this soft alignment is the attention mechanism bahdanau et al

to generate the summary words rush et al
apply a beam search decoder with a window of k candidate words in each sition of the summary
pointer generator network pointcov picted in figure of see et al
is similar to abs
it is composed of an attention based coder that produces the context vector
the coder is extended with a pointer generator model that computes a probability pgen from the context vector the decoder states and the decoder output
that probability is used as a switch to decide if the next word is to be generated or copied from the input
this model is thus a compromise between abstractive and extractive copying words from put models
another extension is the coverage mechanism for avoiding word repetitions in the summary a common problem of encoder decoder summarizers tu et al

results we performed experiments with the unsupervised and supervised methods of section on the rst three datasets of section and on oagk
all supervised methods were trained with the m records of oagk train part
an exception was maui which could be trained on k records at most memory limitation
in addition to the cessing steps of section we further replaced digit symbols with and limited source and get text lengths to and tokens respectively
vocabulary size was also limited to the k most method yake topicrank maui copyrnn merge inject abs pointcov hulth















krapivin















meng k















oagk k















table full match scores of predicted keyphrases by various methods method yake topicrank maui copyrnn merge inject abs pointcov hulth krapivin meng k oagk k































































table rouge scores of predicted keyphrases by various methods frequent words
the few parameters of the unsupervised ods length and windows of candidate keyphrases for yake ranking strategy for topicrank were tuned using the validation part of each dataset
for the evaluation we used score of full matches between predicted and authors words
given that the average number of words in the data is about we computed scores on top and top returned keywords
before each comparison both sets of terms were stemmed with porter stemmer and cates were removed
in the case of rization models keyphrases were extracted from their comma separated summaries
we also computed and rouge l scores that are suitable for evaluating short summaries lin
the keywords tained from the unsupervised methods were linked together to form the keyphrase string assumed summary
this was later compared with the inal keyphrase string of the authors
full match results on each dataset are reported in table
from the unsupervised models we see that yake is consistently better than crank
the next two supervised models perform even better with copyrnn being discretely perior than maui
results of the four summarization models seem disappointing
merge and inject are the worst on every dataset with highest score

ious predictions of these models are empty or very short and some others contain long word tions which are discarded during evaluation
as a result there are usually fewer than ve predicted keyphrases
this explains why and scores are very close to each other
abs works slightly better reaching scores from
to

pointcov is the best of the text summarizers producing keyphrase predictions that are usually clean and concise with few titions
this is probably the merit of the coverage mechanism
there is still a considerable gap tween pointcov and copyrnn
and rouge l scores are reported in table
rnn is still the best but pointcov is close
abs scores are also comparable to those of maui and yake
topicrank merge and inject are again the worst
regarding the test datasets the highest result scores are achieved on hulth and the lowest on krapivin
we checked some samples of the later and observed that each of them contains tion tags e

t a b figure
for cating different parts of text in the original paper
a more intelligent text cleaning step may be quired on those data
discussion the results show that the tried text tion models perform poorly on full match word predictions
their higher rouge scores further indicate that the problem is not entirely in the summarization process
observing a few ples we found differences between the two uation strategies
for example suppose we have the predicted keyword intelligent system pared against authors keyword system design
full match evaluation adds nothing to and scores
however in the case of rouge evaluation the prediction is partially right and a certain value is added to score
in follow up works one solution to this discrepancy could be to try partial match comparison scores like overlap coefcients
another detail that has some negative effect in full match scores is keyword separation
the dicted string health system human metabolism immunity produces health care immune system man metabolism immunity as the list of keywords after removing the extra separators
stead we expected health care immune tem human metabolism immunity
this again penalizes full match scores but not score
a more intelligent keyword separation mechanism could thus help for higher full match result scores
a third reason could be the fact that we used the title and abstract of papers only
this is ally what most researchers do as it is hard to nd high quantities of article full texts for free
article body is usually restricted
abstractive tion methods could still benet from longer source texts
using default hyperparameters for the els may have also inuenced the results
some rameter tuning could be benecial though
the main reason could be even more tal
we trained abstractive summarization els on abstracts and titles with authors keyphrases considered as golden ones
there might be two sues here
first when setting their keywords thors mostly consider the topical aspects of their work rather than paraphrasing over the contents
abstracts and titles we used may not carry enough topical information about the article even when joined together
second considering authors words as golden ones may not be reasonable
one solution is to employ human experts and ask them to annotate each article based on what they read
this is however prohibitive when hundred sands of samples are required
extensive ments on this issue may provide different facts and change the picture
for the moment a safe way to go seems developing deep supervised generative models like the one of meng et al
that dict one keyphrase at each step independently
conclusions in this paper we experimented with various supervised supervised deep supervised and stractive text summarization models for ing keyphrases of scientic articles
to the best of our knowledge this is the rst attempt that plores the possibility of conceiving article string of keywords as an abstractive summary of tle and abstract
we collected and produced a large dataset of
million abstracts titles and keyphrase strings from scientic papers available online
it can be used for future text tion and keyphrase generation experiments
tematic evaluation on four test datasets shows that the used summarization models could not duce better keywords than the supervised tive models
extensive experiments with more vanced summarizaiton methods and better eter optimization may still reveal a different view of the situation
acknowledgments this research work was supported by the project no
cz




national mobility of researchers at charles versity of the operational programme research development and education grant of the czech science foundation and elitr of the eu
references dzmitry bahdanau kyunghyun cho and yoshua neural machine translation by corr bengio

jointly learning to align and translate


adrien bougouin florian boudin and beatrice daille

topicrank graph based topic ranking for keyphrase extraction
in proceedings of the sixth ternational joint conference on natural language processing pages
asian federation of natural language processing
ricardo campos vtor mangaravite arian pasquali alpio mario jorge celia nunes and adam jatowt

yake collection independent automatic in advances in information word extractor
trieval pages
springer international lishing
erion c ano and maurizio morisio

tion of public datasets for recommender systems
in ieee international forum on research and technologies for society and industry leveraging a better tomorrow rtsi pages
corina florescu and cornelia caragea

rank an unsupervised approach to keyphrase traction from scholarly documents
in proceedings of the annual meeting of the association for computational linguistics pages
ciation for computational linguistics
george foster ashish vaswani jakob uszkoreit wolfgang macherey lukasz kaiser orhan firat llion jones noam shazeer yonghui wu ankur bapna melvin johnson mike schuster zhifeng chen macduff hughes niki parmar and mia xu chen

the best of both worlds ing recent advances in neural machine translation
in acl pages
association for tional linguistics
max grusky mor naaman and yoav artzi

newsroom a dataset of
million summaries with diverse extractive strategies
in proceedings of the conference of the north american chapter of the association for computational linguistics man language technologies pages
ciation for computational linguistics
kazi saidul hasan and vincent ng

automatic keyphrase extraction a survey of the state of the in proceedings of the annual meeting art
of the association for computational linguistics pages
anette hulth

improved automatic keyword in traction given more linguistic knowledge
ceedings of the conference on empirical ods in natural language processing pages
association for computational linguistics
mikalai krapivin aliaksandr autayeu maurizio marchese enrico blanzieri and nicola segata

keyphrases extraction from scientic ments
in the role of digital libraries in a time of global change
chin yew lin

rouge a package for automatic evaluation of summaries
in proc
acl workshop on text summarization branches out page
olena medelyan

human competitive automatic topic indexing
the university of waikato phd sis
rui meng sanqiang zhao shuguang han daqing he peter brusilovsky and yu chi

deep in proceedings of the keyphrase generation
annual meeting of the association for tional linguistics pages
association for computational linguistics
ramesh nallapati bowen zhou cicero dos santos caglar gulcehre and bing xiang

stractive text summarization using sequence to in proceedings of the quence rnns and beyond
signll conference on computational natural language learning pages
association for computational linguistics
courtney napoles matthew gormley and benjamin in van durme

annotated gigaword
ceedings of the joint workshop on automatic edge base construction and web scale knowledge extraction akbc wekex pages stroudsburg pa usa
association for tional linguistics
thuy dung nguyen and minh thang luong

wingnus keyphrase extraction utilizing document logical structure
in proceedings of the tional workshop on semantic evaluation semeval pages stroudsburg pa usa
ation for computational linguistics
stuart rose dave engel nick cramer and wendy cowley

automatic keyword extraction from individual documents
in michael w
berry and cob kogan editors text mining
applications and theory pages
john wiley and sons ltd
alexander m
rush sumit chopra and jason weston

a neural attention model for abstractive in proceedings of the tence summarization
conference on empirical methods in natural guage processing pages
association for computational linguistics
abigail see peter j
liu and christopher d
ning

get to the point summarization with in proceedings of the pointer generator networks
annual meeting of the association for tational linguistics pages
association for computational linguistics
arnab sinha zhihong shen yang song hao ma rin eide bo june paul hsu and kuansan wang

an overview of microsoft academic vice mas and applications
in proceedings of the international conference on world wide web www companion pages new york ny usa
acm
jie tang jing zhang limin yao juanzi li li zhang and zhong su

arnetminer extraction and mining of academic social networks
in proceedings of the acm sigkdd international conference on knowledge discovery and data mining kdd pages new york ny usa
acm
marc tanti albert gatt and kenneth p
camilleri

what is the role of recurrent neural works rnns in an image caption generator corr

zhaopeng tu zhengdong lu yang liu xiaohua liu and hang li

modeling coverage for neural machine translation
in proceedings of the nual meeting of the association for computational linguistics pages
association for tional linguistics
peter d
turney

learning algorithms for keyphrase extraction
inf
retr

ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser and illia polosukhin

attention is all you need
in i
guyon u
v
luxburg s
bengio h
wallach r
fergus s
vishwanathan and r
nett editors advances in neural information cessing systems pages
curran sociates inc
ian h
witten gordon w
paynter eibe frank carl gutwin and craig g
nevill manning

kea in practical automatic keyphrase extraction
ceedings of the fourth acm conference on digital libraries dl pages ny usa
acm

