proceedings of the international meeting on high dimensional data driven science december kyoto japan e f r i
s c v
v i x r a generalized minimum dominating set and application in automatic text summarization yi zhi xu and hai jun zhou state key laboratory of theoretical physics institute of theoretical physics chinese academy of sciences zhong guan cun east road beijing china e mail
ac
cn
ac
abstract
for a graph formed by vertices and weighted edges a generalized minimum dominating set mds is a vertex set of smallest cardinality such that the summed weight of edges from each outside vertex to vertices in this set is equal to or larger than certain threshold value
this generalized mds problem reduces to the conventional mds problem in the limiting case of all the edge weights being equal to the threshold value
we treat the generalized mds problem in the present paper by a replica symmetric spin glass theory and derive a set of propagation equations
as a practical application we consider the problem of extracting a set of sentences that best summarize a given input text document
we carry out a preliminary test of the statistical physics inspired method to this automatic text summarization problem

introduction minimum dominating set mds is a well known concept in the computer science community see review
for a given graph a mds is just a minimum sized vertex set such that either a vertex belongs to this set or at least one of its neighbors belongs to this set
in the last few years researchers from the statistical physics community also got quite interested in this concept as it is closely related to various network problems such as network monitoring network control infectious disease suppression and resource allocation see for example and review
constructing an exact mds for a large graph is generally speaking an extremely dicult task and it is very likely that no complete algorithm is capable of solving it in an ecient way
on the other hand by mapping the mds problem into a spin glass system with local many body constraints and then treating it by statistical physics methods one can estimate with high empirical condence the sizes of minimum dominating sets for single graph instances
one can also construct close to minimum dominating sets quickly through a physics inspired heuristic algorithm which might be important for many practical applications
in the present work we extend the statistical physics approach of to edge weighted graphs and study a generalized minimum dominating set problem
our work is motivated by a practical knowledge mining problem extracting a set of sentences to best summarize one or more input text documents
we consider a general graph of vertices and edges each edge connecting two dierent vertices and bearing one weight or a pair of weights see fig

in the context of text summarization a vertex represents a sentence of some text documents and an edge weight is the similarity between two sentences
various data clustering problems figure
an graph with n vertices and m weighted edges
in this example the two weights wi j and wj i of each edge i j are equal wi j wj i and the threshold value of each vertex is

the vertex set is a generalized minimum dominating set for this graph
the summed weight of edges from every vertex j to vertices in is equal to or greater than
can also be represented as weighted graphs
given such a weighted graph our task is then to construct a minimum cardinality set of vertices such that if a vertex i is not included in the summed weight of the edges from i to vertices in must reach at least certain threshold value
the set is referred to as a generalized mds
we introduce a spin glass model for this generalized mds problem in sec
and then describe a replica symmetric rs mean eld theory in sec

a message passing algorithm bpd propagation guided decimation is outlined in sec
and is then applied to the automatic text summarization problem in sec

we conclude this work in sec
and discuss a way of modifying the spin glass model for better treating the text summarization problem

constraints and a spin glass model we consider a generic graph g formed by n vertices with indices i j k





n and m edges between pairs of these vertices fig

the constant c is the mean vertex degree of the graph on average a vertex is attached with c edges
each edge i j is associated with a pair of non negative weights wi j and wj i which may or may not be equal
the meaning of the edge weights depend on the actual context
for example wi j may be interpreted as the extent that vertex i represents vertex j in the symmetric case of wi j wj i we may also interpret wi j as the similarity between i and j
two vertices i and j are referred to as mutual neighbors if they are connected by an edge i j
the set of neighbors of vertex i is denoted as i i
e
i j i j g
given a graph g we want to construct a vertex set that is as small as possible and at the same time is a good representation of all the other vertices not in this set
let us assign a state ci to each vertex i ci if i referred to as being occupied and ci if i referred to as being empty
for each vertex j we require that ciwi where is a xed threshold value
a vertex j is regarded as being satised if it is occupied cj or the condition ciwi j holds otherwise it is regarded as being unsatised
therefore there are n vertex constraints in the system
a conguration


cn for the whole graph is referred to as a satisfying conguration if and only if it makes all the vertices to be satised fig

constructing such a generalized mds i
e
a satisfying conguration with the smallest number of occupied vertices is a integer programming problem but as it belongs to the nondeterministic polynomial hard np hard computational complexity class no




















algorithm is guaranteed to solve it in polynomial time
we now seek to solve it approximately through a statistical physics approach
let us introduce a weighted sum of all the possible microscopic congurations


cn as n cj e cj ciwi


cn a is the kronecker symbol a if a and b where b a if a b and is the heaviside step function such that for and for
in the statistical physics community is known as the partition function and the non negative parameter is the inverse temperature
notice a conguration


cn has no contribution to if it is not a satisfying conguration
if a conguration satises all the vertex constraints it contributes a term to where ci is the total number of occupied vertices
as increases satisfying congurations with smaller values become more important for and at the partition function is contributed exclusively by the satisfying congurations with the smallest
for the purpose of constructing a minimum or close to minimum dominating set we are therefore interested in the large limit of

replica symmetric mean eld theory it is very dicult to compute the partition function exactly here we compute it approximately using the replica symmetric mean eld theory of statistical physics
this rs mean eld theory can be understood from the angle of bethe peierls approximation it can also be derived through loop expansion of the partition function


thermodynamic quantities we denote by qcj the marginal probability that vertex j is in state cj
due to the j constraints associated with vertex j and all its neighboring vertices the state cj is strongly correlated with those of the neighbors
to write down an approximate expression for qcj j let us assume that the states of all the vertices in set j are independent before the constraint of vertex j is enforced
under this bethe peierls approximation we then obtain that qcj j cj e ci e ij ij ciwi ij ij
ciwi ij in the above equation cj is the joint probability that vertex i has state ci and its neighboring vertex j has state when the constraint associated with vertex j is not enforced
the product is a direct consequence of neglecting the correlations among vertices in j in the absence of vertex j s constraint
the mean fraction n of occupied vertices is then obtained through cj ij n j n this fraction should be a decreasing function of
we can dene the free energy of the system as f ln
within the rs mean eld theory this free energy can be computed through f n fj n j i where f is the free energy density and fj and j are respectively the free energy contribution of a vertex j and an edge i j fj e ln ij ciwi ij j ln ci cj ij ci ji
ci the partition function is predominantly contributed by satisfying congurations with number of occupied vertices n namely en with being the total number of satisfying congurations at occupation density
then the entropy density n ln of the system is computed through s
the entropy density is required to be non negative by denition
if as decreases below certain value then en suggests that there is no satisfying congurations with
we therefore take the value as the fraction of vertices contained in a minimum dominating set


belief propagation equation we need to determine the probabilities cj s
following the bethe peierls approximation and similar to eq
cj determined through ij ij to compute the thermodynamic densities and is self consistently wj i ij zij zij zij ck ck e ij ki ki ckwk i ki ckwk i ki where is the subset of i with vertex j being deleted and zij is a normalization constant
equation is called a belief propagation bp equation in the literature
to nd a solution to eq
we iterate this equation on all the edges of the input graph g see for example or for implementing details
however convergence is not guaranteed to achieve
if the reweighting parameter is small this bp iteration quickly reaches a xed point while at large values of we notice that it usually fails to converge see next subsection


results on erdos renyi random graphs we rst apply the rs mean eld theory to erdos renyi er random graphs
to generate an er random graph we select m dierent pairs of edges uniformly at random from the whole set of n n vertex pairs and then connect each selected pair of vertices by an edge
for n suciently large there is no structural correlations in such a random graph and the typical length of a loop in the graph diverges with n in a logarithmic way
if the two edge weights of every edge i j are equal to the vertex threshold value wi j wj i the generalized mds problem reduces to the conventional mds problem on an undirected graph which has been successfully treated in
for example for er random figure
replica symmetric mean eld results on er random networks of mean vertex degree c

the symmetric edge weights are drawn from the set






and the vertex threshold value is
the cross symbols bp are results obtained by propagation on a single graph instance of size n while the solid lines rs are averaged results obtained by population dynamics simulations
occupation density inverse temperature free energy density versus c entropy density s versus entropy density s as a function of obtained by combining data of a and
graphs with mean vertex degree c
the mds relative size is

on the other hand if the two edge weights of every edge are strongly non symmetric such that either wi j and wj with probability or wi j and wj also with probability the generalized mds problem reduces to the conventional mds problem on a directed graph which again has been successfully treated in e

at c
the mds relative size is

in this paper as a particular example we consider a distribution of edge weights with the following properties the weights of every edge i j are symmetric so wi j wj i the edge weights of dierent edges are not correlated but completely independent for each edge i j its weight wi j is assigned the value
or
with probability each and assigned values in the set




with equal probability each
the bp results on the occupation density the free energy density and the entropy density s are shown in fig
for a single er random graph of n vertices and mean degree c

the bp iteration for this this graph instance is convergent for

the occupation density and the entropy density s both decrease with inverse temperature
the entropy density as a function of occupation density approaches zero at
indicating there is no satisfying congurations at occupation density
the bp results



















figure
the relative size of minimum dominating sets for er random graphs of mean vertex degree c
the edge weight distribution for these random graphs are the same as that of fig
and the vertex threshold value

the solid line connected plus symbols are the predictions of the rs mean eld theory while the results obtained by the bpd algorithm at
are drawn as cross symbols for graph size n circles n and squares n
each bpd data point is the result of a single run on one graph instance
therefore predict that a mds for this problem instance must contain at least
vertices
we can also obtain rs mean eld results on the thermodynamic densities by averaging over the whole ensemble of er random graphs with n and xed mean vertex degree c
this is achieved by population dynamics simulations
we store a population of probabilities cj and update this population using eq
and at the same time compute the densities of thermodynamic quantities
a detailed description on the implementation can be found in section
of
the ensemble averaged results for the er random network ensemble of
and n are also shown in fig

these results are in good agreement with the bp results obtained on the single graph instance
through the rs population dynamics simulations we can estimate the ensemble averaged value of the minimum fraction of occupied vertices by the equation
the value of obtained in such a way decreases with mean vertex degree c continuously see fig
solid line

belief propagation guided decimation algorithm for suciently large the marginal occupation probability qcj j obtained by eq
tells us the likelihood of each vertex j to belong to a minimum dominating set
this information can serve as a guide for constructing close to minimum dominating sets
based on the bp equation we implement a simple belief propagation guided decimation bpd algorithm as follows
starting from an input graph g and an empty vertex set at each step we iterate the bp equation for a number of repeats and then estimate the occupation probability j for all the vertices j not in and add a tiny fraction e

of those vertices with the highest values of j into the set and set their state to be cj then simplify the graph and repeat the operations on the simplied graph until becomes a dominating set
the detailed implementation of this bpd algorithm is the same as described in section of
here we only need to emphasize one new feature after a vertex i is newly occupied the



threshold value say of every neighboring vertex j should be updated as j j wi j and if this updated j is non positive then vertex j should be regarded as being satised
for the same graph of fig
a single trial of this bpd algorithm at
results in a dominating set of size which is very close to the predicted mds size by the rs mean eld theory
equally good performance of the bpd algorithm is also achieved on other er random graphs with mean vertex degree c ranging from c
to see fig
suggesting that the bpd algorithm is able to construct a dominating set which is very close to a mds
we emphasize that in the bpd algorithm we do not require the bp iteration to converge

application automatic text summarization automatic text summarization is an important issue in the research eld of natural language processing
one is faced with the dicult task of constructing a set of sentences to summarize a text document or a collection of text documents in a most informative and ecient way
here we extend the initial idea of shen and li and consider this information retrieval problem as a generalized minimum dominating set problem
we represent each sentence of an input text document as a vertex and connect two vertices say i and j by an weighted edge with the symmetric edge weight wi wj being equal to the similarity of the two corresponding sentences
before computing the edge weight a treatment is applied to all the sentences to remove stop words such as a an at do but of with and to transform words to their prototypes according to the wordnet dictionary e

airier airy eshier eshy are be children child looking look
there are dierent ways to measure sentence similarity here we consider a simple one the cosine similarity
to compute the cosine similarity we map each sentence i to a high dimensional vector the k th element of which is just the number of times the k th word of the text appears in this sentence
then the edge weight between vertices i and j is dened as wi j
to give a simple example let us consider a document with only two sentences tom is looking at his children with a smile
and these children are good at singing

the word set of this document is tom be look child smile good sing and the vectors for the two sentences are and respectively
the cosine similarity between these two sentences is then

we rst test the performance of the bpd algorithm on short english text documents of dierent lengths on average a document has
sentences
we compare the outputs from the bpd algorithm with the key sentences manually selected by the rst author
for each text document we denote by b and b the set of key sentences selected by human inspection and by the algorithm respectively
on average the set b of human inspection contains a fraction
of the sentences in the input text document
then we dene the coverage ratio rcov and the dierence ratio rdif between b and b as rcov rdif b where bb denotes the set of sentences belonging to b but not to b
the ratio rcov quanties the probability of a manually selected key sentence also being selected by the algorithm while the ratio rdif quanties the extent that a sentence selected by the algorithm does not belong to the set of manually selected key sentences
table
averaged performances of the bpd algorithm
the pr pagerank algorithm and the ap anity propagation algorithm on english text documents average number of sentences per document

for bpd the vertex threshold is set to



and


for pr the fraction of sentences selected is and
for ap the adjustable parameter is set to be wi

and wi


is the fraction of representative sentences chosen by the algorithm and rcov and rdif are two performance measures dened by eq

the average fraction of representative sentences constructed by human inspection is






























rcov rdif we also apply two other summarization algorithms to the same set of text documents one is the pagerank pr algorithm and the other is the anity propagation ap algorithm
pagerank is based on the idea of random walk on a graph and it oers an ecient way of measuring vertex signicance
the importance pi of a vertex i is determined by the following self consistent equation pi p p n ji pj wj i wj k where p is the probability to jump from one vertex to a neighboring vertex we set p
following
those vertices i with high values of pi are then selected as the representative vertices
on the other hand anity propagation is a clustering algorithm each vertex either selects a neighboring vertex as its exemplar or serves as an exemplar for some or all of its neighbors
for any pair of vertices i and j the responsibility ri j of j to i and the availability ai j of j to i are determined by the following set of iterative equations ri j wi j max k wi ai j rj j rk j aj j ri j j
in eq
wi j is the weight of edge i j for i j and wi i is an adjustable parameter which aects the nal number of examplars
we iterate the ap equation on the sentence graph starting from the initial condition of ri j ai j and after convergence is reached then consider all the vertices i with positive values of ri i ai as the examplar vertices
for the short text documents used in our preliminary test the comparative results of table do not distinguish much the three heuristic algorithms yet it appears that pagerank performs slightly better than bpd and ap
when the fraction of extracted sentences is
the coverage ratio reached by pr is rcov
and the dierence ratio is rdif
while rcov
and rdif
for bpd at
and rcov
and rdif
for ap at

we then continue to evaluate the performance of the belief propagation approach on a benchmark set of longer text documents namely the duc document understanding table
averaged performances of the bpd algorithms
or
and bpd
and the pagerank algorithm on the text documents of duc
the precision recall and f score values are obtained by averaging over the results of individual text documents
the inverse temperature of bpd is xed to be

recall precision fscore














conference data set used in
we examine a total number of text documents from the duc directory
the average number of sentences per document is about and the average number of words per sentence is about
the duc data set oers for each of these text documents two sets b of representative sentences chosen by two human experts the total number of words in such a set b being
the pagerank algorithm and one version of the bpd algorithm
or
also construct a set b of sentences for each of these documents under the constraint that the total number of words in b should be about
in another version of the bpd algorithm bpd the restriction on the words number in b is removed
we follow the duc convention and use the toolkit rouge to evaluate the agreement between b and b in terms of recall precision and f score recall wordb wordb precision fscore wordsnum precision recall precision recall
where is the total number of times a given word appears in the summary b and is the number of times this word appears in the summary b is the total number of words in the summary b and similarly for wordsnum
the comparative results for the duc data set are shown in table
we notice that

has the highest recall value of
namely the summary obtained by this algorithm contains most of contents in the summary of human experts but its precision value of
is much lower than that of the algorithm indicating that the bpd algorithm add more sentences into the summary than the human experts do
in terms of the f score which balances recall and precision the last row of table we conclude that pagerank also performs a little bit better than bpd for the duc benchmark
the generalized mds model for the text summarization problem aims at a complete coverage it is therefore natural that the summary constructed by bpd of an input text document
contains more sentences than the summary constructed by the human experts which may only choose the sentences that best summarize the key points of a text document
all the tested documents in the present work are rather short which may make the advantages of the bpd message passing algorithm dicult to be manifested
more work needs to be done to test the performance of the bpd algorithm on very long text documents
figure
the word sentence graph representation for a text document
the m words and n sentences of an input text document are denoted by squares and circles respectively and a link between a word a and a sentence i is drawn if and only if word a appears in sentence i
to get a set of representative sentences we may require that each word must be connected to at least n n sentences of the set

outlook in this paper we presented a replica symmetric mean eld theory for the generalized minimum dominating set problem and we considered the task of automatic text summarization as such a mds problem and applied the bpd message passing algorithm to construct a set of representative sentences for a text document
when tested on a set of short text documents the bpd algorithm has comparable performance as the pagerank and the anity propagation algorithms
we feel that the bpd approach will be most powerful for extracting sentences out of lengthy text documents e

scientic papers containing thousands of sentences
we hope that our work will stimulate further eorts on this important application
the belief propagation based method for the automatic text summarization problem might be improved in various ways
for example it may not be necessary to perform the decimation step rather one may run bp on the input sentence graph until convergence or for a sucient number of rounds and then return an adjustable fraction of the sentences i according to their estimated occupation probabilities i
one may also convert the text summarization problem to other generalized mds problems
a particularly simple but potentially useful one can be constructed as follows we rst construct a bi partite graph formed by words sentences and the links between words and sentences see fig
we then construct a minimum sized dominating set of sentences such that every word of the whole bipartite graph must appear in at least n n of the sentences of
such a generalized mds problem can be studied by slightly modifying the bp equation eq

we notice that this alternative construction has the advantage of encouraging diversity in the selected representative sentences
acknowledgments we thank jin hua zhao and yusupjan habibulla for helpful discussions
this research is partially supported by the national basic research program of china grant number and by the national natural science foundation of china grand numbers and












references haynes t w hedetniemi s t and slater p j fundamentals of domination in graphs new york echenique p gomez gardenes j moreno y and vazquez a distance d covering problems in scale free networks with degree correlations phys
rev
e dallasta l pin p and ramezanpour a statistical mechanics of maximal independent sets phys
rev
dallasta l pin p and ramezanpour a optimal equilibria of the best shot game j
public economic marcel dekker e theor
yang y wang j and motter a e network observability transitions phys
rev
lett
molnar jr
f sreenivasan s szymanski b k and korniss k minimum dominating sets in scale free network ensembles sci
rep
nacher j c and akutsu t analysis on critical nodes in controlling complex networks using dominating sets in international conference on signal image technology internet based systems kyoto takaguchi t hasegawa t and yoshida y suppressing epidemics on networks by exploiting observer nodes phys
rev
e wuchty s controllability in protein interaction networks proc
natl
acad
sci
usa wang h zheng h browne f and wang c minimum dominating sets in cell cycle specic protein in proceedings of international conference on bioinformatics and biomedicine interaction networks ieee liu y y and barabasi a l control principles of complex networks
zhao j h habibulla y and zhou h j statistical mechanics of the minimum dominating set problem j
stat
phys
habibulla y zhao j h and zhou h j the directed dominating set problem generalized leaf removal and belief propagation lect
notes comput
sci
mani i advances in automatic text summarization cambridge ma mit press shen c and li t multi document summarization via the minimum dominating set in proceedings of the international conference on computational linguistics beijing association for computational linguistics mezard m and parisi g the bethe lattice spin glass revisited eur
phys
j
b mezard m and montanari a information physics and computation new york oxford univ
press zhou h j and wang c region graph partition function expansion and approximate free energy landscapes theory and some numerical results j
stat
phys
zhou h j spin glass and message passing beijing science press fellbaum c wordnet an electronic lexical database cambridge ma mit press singhal a modern information retrieval a brief overview ieee data engineering bulletin brin s and page l the anatomy of a large scale hypertextual web search engine computer networks and isdn systems mihalcea r and tarau p textrank bringing order into texts in preceedings of the conference on empirical methods in natural language processing barcelona association for computational linguistics erkan g and radev d r lexrank graph based lexical centrality as salience in text summarization j
artical intelligence res
frey b j and dueck d clustering by passing messages between data points science document understanding conference nlpir
nist
gov projects duc lin c y rouge a package for automatic evaluation of summaries in preceedings of the workshop text summarization branches out barcelona association for computational linguistics
