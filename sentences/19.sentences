diversity in ranking using negative reinforcement rama badrinath department of computer science and automation indian institute of science bangalore india
iisc
ernet
in c e veni madhavan department of computer science and automation indian institute of science bangalore india
iisc
ernet
in l u j r i
s c v
v i x r a abstract in this paper we consider the problem of diversity in ranking of the nodes in a graph
the task is to pick the top k nodes in the graph which are both central and diverse
many graph based els of nlp like text summarization opinion summarization involve the concept of diversity in generating the summaries
we develop a novel method which works in an iterative fashion based on dom walks to achieve diversity
specically we use negative forcement as a main tool to introduce diversity in the personalized pagerank framework
experiments on two benchmark datasets show that our algorithm is competitive to the existing methods
categories and subject descriptors h

database applications data mining general terms algorithms keywords diversity ranking negative reinforcement personalized ank introduction
ranking of data items represented in the form of a graph has many applications
consider the example of a co author network
the goal is to pick the most inuential authors from different areas
a simple approach would be to use a centrality measure like ank and then to pick the top scoring vertices in the graph
ever top ranking authors might not cover all the different areas cause top ranking nodes would be very near to each other dancy
hence we have to consider both centrality and diversity in the ranking process
a straight forward approach to diversity is to rst cluster the graph and the pick the cluster centres
the main drawback is that we may not know the number of clusters prior to clustering
the concept of diversity is used in a variety of applications like text summarization recommendation systems query tions search results diversication
before senting the current approaches to diversity we will briey describe the two classic algorithms used to rank nodes in a graph
the pagerank algorithm tries to nd out the central nodes in the graph by using the concept of random walk with teleporting
the score of a node depends on the score of its neighbors
from a vertex s the walk either teleports to a random vertex in the graph with probability or with probability jumps to one of the neighbours of s
n vv v zv v the personalized pagerank algorithm goes one step ahead and uses the prior distribution for the nodes in the ranking process
hence nodes with a high prior value will be favored in case of random jump
zv vv v zv v where p is the prior distribution
top k nodes returned by both the algorithms will be central but not necessarily diverse

related work the current methods for diversity fall into two categories greedy selection methods iteratively selects one vertex at a time such that the next vertex is central and as diverse as possible from the set of ranked picked vertices
unied ranking methods both centrality and diversity are considered simultaneously in the ranking process which runs only once
maximum marginal relevance mmr works in a greedy fashion
the main idea is that the next vertex to be picked must be most prestigious
at the same time it must be least similar to the set of ranked nodes
m m r max max vj s vj where r denotes the set of all nodes and s is the set of already selected nodes
q denotes the query given to us and q is the similarity of node vi to query
since we dot not have the notion of query in the current problem we consider q to be the pagerank score of vi
hence the rst ranked node will be the node having highest pagerank score
the next set of nodes are picked according to equation
grasshopper is another greedy selection method which uses the concept of absorbing random walk
the rst ranked node will be the node having highest pagerank score
next the ranked nodes are considered as absorbing states and the time to absorption for each node is calculated
the node with the maximum number of visits is selected as the next ranked item
divrank is an unied ranking algorithm
it leverages vertex reinforced random walk to deploy the rich gets richer mechanism
the idea is to use time dependent transition probabilities such that the high ranked nodes absorb scores from neighboring nodes
nally cluster centres win in the process and get high score
pt u v zv v nt v dt u dt u v vv where v is the transition probability prior to any ment
nt v is the number of times the walk has visited the node v up to time t
in the next section we propose an algorithm named negative forcement ranking which is basically a greedy selection method
section discusses the experiments conducted on the benchmark datasets
after a discussion on running time analysis in section we conclude the paper in section with some future work

negative reinforcement ing we borrow the concept of negative reinforcement in random walks from
the full details of our algorithm are as follows
our algorithm is similar in structure to grasshopper and picks a diverse set of nodes one at a time
to nd the rst ranked item we run the standard personalized pagerank ppr on the graph and pick the top scoring node
let w denote a row normalized similarity matrix i
e
w i j
let r denote a ence vector prior distribution of the vertices
then the ppr vector p is given by p w be written as follows i w we solve this system of linear equations to nd the score vector
as described earlier we pick the top scoring vertex as the rst ranked item
now we are ready to select the next set of nodes
it is crucial that the next item must be very far from the rst ranked item
further it must be central in the remaining subgraph
hence we ip the preference value prior ranking of the ranked item from positive to negative value and run the ppr again
the effect of this is that the ranked item s negative score tries to pull down the score of its nearby vertices and so on
however the nodes which are very far from the ranked nodes will not affected
hence they still get positive reinforcement from their neighbors
the top scoring node denotes the central node in the remaining graph
therefore we pick the top scoring node as the next ranked item
due to negative reinforcement nodes which are near the ranked item are removed from the race
after picking the second item we set the prior ranking of both the ranked items to negative value and run ppr
the process is tinued till top k nodes are picked
in order to have a good control over the distribution of negative mass from the set of ranked nodes to the set of unranked nodes we augment the original graph with a new node having a self edge called absorbing node
it absorbs positive mass from the set of unranked nodes
this leads in a tive mass propagation to a larger portion of the graph
however an absorbing node is never picked into the set of ranked nodes
input w r output list of top k nodes g
a b

vn
augment the graph with a new node d absorbing node with a self edge

solve eqn with r as the prior distrubution
pick the rst ranked item argmaxi pi
a a b b
repeat till k r r normalize seperately
solve equation with r as the prior tion
pick the next ranked item gj argmaxi pi
a a gj b b gj where is the damping factor
usually the power method is used to solve the above equation to nd the ppr vector
however it can the negative reinforcement ranking algorithm let a denote the set of ranked nodes and b be the set of ranked nodes
similarly let denote the indices of ranked nodes and denote the indices of unranked nodes
the plete algorithm is described above
and are positive parameters to be chosen
step
makes sure that i ri and hence tion to equation always exists
we note that only the preference vector r changes in every tion
the term i w remains same throughout the process
therefore we use the lu decomposition method to solve tion
the advantage of this method is that the lu decomposition of the matrix i w maximum time taking operation is done only once
hence step
of the algorithm runs very

experiments
social network analysis we rst test our method on the actor social network introduced in
the dataset consists of actors from comedy movies collected from internet movie
an undirected graph is created by considering actors as nodes
edge weights are proportional to the number of movies the two actors have acted together in
self edges are added with unit weight
the task is to extract top k actors who are prominent in the graph taking diversity into account
we expect top actors to be ans from different countries
this forces diversity in the top actors
this is based on the fact that co star connections within same try are more likely thus creating communities within countries
the diversity quality is measured in terms of the number of unique countries covered country coverage and the number of unique movies covered movie coverage by the top k actors
a good versity based algorithm should maximize both country coverage and movie coverage since the top k actors come from different gions
we also use the density measure introduced in
density of a graph is dened as the number of edges present in the network divided by the maximal possible number of edges in the network
formally it is dened as uv vv v where is an indicator function which returns if the ment x is true and zero otherwise
intuitively density of the graph created by the top k actors must be very low because the top k vertices must be as independent as possible from one another
we compare our algorithm with the algorithms pagerank alized pagerank mmr grasshopper and divrank
in order to nd out the optimal parameters for all the algorithms we divided the actor social graph into two subgraphs
nodes are picked domly into two sets intra set edges are retained and inter set edges are discarded
the rst subgraph created had nodes and was used for training and the second subgraph having nodes was used for testing
matlab implementation of the algorithm is available at
google
com site iiscrama ranking
imdb
figure country coverage
figure movie coverage
figure density the lower the better
of countries coverednumber of actors k pagerankpersonalized of movies coverednumber of actors k pagerankpersonalized





of actors k pagerankpersonalized fig shows the performance of different algorithms
we see that performs very well in country coverage especially when k is small
this is a good property since in many cations only a few top results are considered
it is also important to note that the density of our algorithm is very less compared to grasshopper
the list of top actors returned by algorithm on the test set is shown in the table below
in our experiments we used duc to tune the eters and duc dataset to test the performance
duc and duc datasets consist of and document clusters tively with human written summaries for each cluster
the task is to generate a word summary for each cluster reecting the gist of input documents
to evaluate summaries we used rouge recall oriented understudy for gisting evaluation
rouge generates recall value based on overlapping n grams between man and system generated summary to evaluate its quality
eddie murphy anthony anderson johny knoxville luke wilson steve martin steve buscemi breckin meyer jackie chan brittany murphy til schweiger table top actors returned by algorithm in order to prove that negative reinforcement helps in increasing diversity we conducted experiments for various values of
fig shows the effect of negative reinforcement on density
as increases the density decreases i
e diversity increases
similarly fig show that the country coverage and movie coverage crease with increase in
this is because the negative mass from ranked nodes is propagated to a larger portion of the graph thus picking the next node which is very far from the ranked nodes
a similar behavior is observed in case of too as shown in fig
with increase in importance to an absorbing node positive energy is absorbed from unranked nodes thus indirectly helping the tive energy propagation

text summarization in this section we demonstrate the effectiveness of our algorithm on networks arising from text documents
the input is a set of related documents and the task is to extract the important sentences to form a summary with no redundancy
in this problem is solved as a graph centrality problem
first a similarity graph g is constructed using sentences in the document
stopwords are removed and all the words are reduced to their root form through stemming
sentences are considered as nodes and edges are set up based on cosine similarity
finally sentences are ranked based on pagerank technique and the top ranking sentences are picked to form the summary
the idea of the algorithm is that if a sentence is central then it should be connected to many other importance sentences in the graph and hence it must be important in the original document as well
though the algorithm succeeds in nding the important sentences it fails to avoid redundancy in the top ranking sentences
this mediately leads to the inclusion of diversity in the ranking process so that a diverse set of sentences are extracted from the similarity graph
we show that our algorithm can be successfully applied to text summarization problem
we followed the same graph construction procedure presented in
we feed the sentence position information as a prior distribution to personalized pagerank ppr grasshopper gh divrank dr and our algorithm
if a sentence s appears at lth position in a document then l where is a positive parameter
lowing we used pagerank score pr as the relevance score in mmr
for each algorithm parameters were chosen to maximize the performance on the training set
in our method we tuned and in
table shows the average score of different algorithms on the training set
table shows the average score of different algorithms on the test set
it is evident that our method works better than other greedy selection methods on the test set
further it is quite competitive to divrank
algorithm





c
i












table text summarization results on duc dataset algorithm





c
i












pr mmr ppr gh dr pr mmr ppr gh dr table text summarization results on duc dataset
running time analysis the running time of our algorithm is linear in k because of the iterative behavior of the method
our algorithm works particularly well when k is small compared to the number of nodes in the graph ex
this is because we return only top k nodes and do not compute the ordering for the rest of the nodes
on the other hand divrank computes the ranking for all the nodes in the graph in a single pass irrespective of k which is a very costly process if the graph contains millions of nodes
further divrank uses an approximation algorithm whose convergence is not guaranteed
understanding conference
nist
figure movie coverage v
s

figure country coverage v
s

figure density v
s
figure movie coverage v
s

figure country coverage v
s

figure density v
s

conclusion we have proposed a new diversity based ranking algorithm
tive reinforcement is the core idea behind picking the next diverse item
experiments on two benchmark datasets conclude that is competitive to the existing methods
as part of future work we are looking at how negative reinforcement can be utilized to turn our algorithm into a unied ranking one
the idea is to use both positive and negative reinforcement so that only the cluster centres benet from positive reinforcement

acknowledgement we acknowledge a partial support for the work from a project proved by the department of science and technology government of india
we thank the reviewers for helping us improve the sentation

references r
agrawal s
gollapudi a
halverson and s
ieong
diversifying search results
in proceedings of the second acm international conference on web search and data mining wsdm pages new york ny usa
acm
s
brin and l
page
the anatomy of a large scale hypertextual web search engine
comput
netw
isdn syst
april
j
carbonell and j
goldstein
the use of mmr diversity based reranking for reordering documents and producing summaries
in in research and development in information retrieval pages
g
erkan and d
r
radev
lexrank graph based lexical centrality as salience in text summarization
j
artif
int
res
december
s
gollapudi and a
sharma
an axiomatic approach for result diversication
in proceedings of the international conference on world wide web www pages new york ny usa
acm
t
h
haveliwala
topic sensitive pagerank
in proceedings of the international conference on world wide web www pages new york ny usa
acm
w
li f
wei q
lu and y
he
ranking sentences with positive and negative reinforcement for query oriented update summarization
in proceedings of the international conference on computational linguistics coling pages manchester uk august
c

lin
rouge a package for automatic evaluation of summaries
in proc
acl workshop on text summarization branches out page
h
ma m
r
lyu and i
king
diversifying query suggestion results
in pages
q
mei j
guo and d
radev
divrank the interplay of








of movies covered












of countries covered

























of movies covered













of countries covered
















prestige and diversity in information networks
in proceedings of the acm sigkdd international conference on knowledge discovery and data mining kdd pages new york ny usa
acm
r
mihalcea and p
tarau
textrank bringing order into texts
in proceedings of conference on empirical methods in natural language processing july
r
h
van leuken l
garcia x
olivares and r
van zwol
visual diversication of image search results
in proceedings of the international conference on world wide web www pages new york ny usa
acm
x
zhu a
goldberg j
v
gael and d
andrzejewski
improving diversity in ranking using absorbing random walks
in hlt naacl pages
the association for computational linguistics
c

ziegler s
m
mcnee j
a
konstan and g
lausen
improving recommendation lists through topic diversication
in proceedings of the international conference on world wide web www pages new york ny usa
acm

