a m l c
s c v
v i x r a from web crawled text to project descriptions automatic summarizing of social innovation projects nikola dimitar abdullah and goran school of computer science university of manchester manchester uk nikola

ac
uk dimitar

manchester
ac
uk hunter centre for entrepreneurship strathclyde business school university of stratclyde glasgow uk abstract
in the past decade social innovation projects have gained the attention of policy makers as they address important social issues in an innovative manner
a database of social innovation is an tant source of information that can expand collaboration between social innovators drive policy and serve as an important resource for research
such a database needs to have projects described and summarized
in this paper we propose and compare several methods e

svm based recurrent neural network based ensambled for describing projects based on the text that is available on project websites
we also address and propose a new metric for automated evaluation of summaries based on topic modelling
keywords summarization evaluation metrics text mining natural language processing social innovation svm neural networks introduction social innovations are projects or initiatives that address social issues and needs in an innovative manner
in the past decade social innovation has gained nicant attention from policy makers and funding agencies around the worlds especially in the eu usa and canada
policy makers and researchers are ticularly interested in monitoring social innovation projects the eects of policies on these projects and the eects of these projects for the society
in order to enable monitoring of social innovation projects a number of database creation projects were funded over time
in the knowmak project we aim to integrate and expand on previously collected information by ing automation approaches enabled by machine learning and natural language processing techniques
the existing data sources for social innovation are varied in their levels of depth and detail
therefore in knowmak we aim to normalize the tion providing the same wealth of information for each reported project
in the nal authenticated version is available online at
doi
n
milosevic et al
order to do this we utilize the data from original data sources as well as the data from the projects webpages and social media sites such as facebook and twitter
in order to provide relevant information to the researchers and policy makers the projects in the database need to be described
some of the original data sources have descriptions but many data sources do not have
additionally some of the descriptions in existing data sources may be too long e

over words or too short sentence and therefore need to be normalized
automated summarization can be used to automate and speed up the cess of summarizing texts about a project in the database
summarization is a well known task in natural language processing however solutions in ture do not address the domain specic issues
project description building using summarization has challenges that may not be present with a usual text rization task
in this task it is necessary to generate short cohesive description that best portrays the project which may be described over several web pages contain noisy text pages or portions of pages with irrelevant text and align project description to the theme of the database
in this paper we compare several methods for creating project descriptions and summaries in the semi automated system that takes texts about social vation projects from the web
we develop a method that makes human readable project descriptions from the scraped pages from the project web sources
this paper presents an automated project description method applied in the mak project that aims to create a tool for mapping knowledge creation in the european area
the project focuses on collecting information on publications patents eu projects and social innovation projects
as publications patents and eu projects would have abstracts or short descriptions this paper aims at the particular case of describing social innovation projects
background automatic summarization is a complex natural language processing task which has been approached from several perspectives
we will review the main proaches
on the whole it is challenging to evaluate automatic summarization
maries of text will look dierent depending on who is doing them and which approach is used
however it has to be ensured that the main points of the text that is analysed have been retained
over the years there have been a couple of evaluation metrics proposed
in this section we will also review the proposed metrics

summarization approaches summarization approaches can be classied into two main categories tractive and abstractive
extractive approaches try to nd snippets the nal authenticated version is available online at
doi
automatic summarization of social innovation sentences and paragraphs that are important while abstractive approaches tempt to paraphrase important information from the original text
the types of summarizers may also depend on how many documents are used as input document or multi document on the languages of input and output gual multilingual or cross lingual or purpose factors informative indicative user oriented generic or domain specic
summarization approaches can be both supervised and unsupervised
pervised methods usually use sentence or phrase scoring algorithms to extract the relevant parts of the original text
most of the extractive tion approaches model the problem as a classication task classifying whether certain sentences should be included in the summary or not
these proaches usually use graphs linguistic scoring or machine learning in order to classify sentences
standard machine learning classiers such as naive bayes or support vector machines svm using features such as the frequency of words as well as neural network based classiers have been posed
traditional machine learning classiers usually use features such as the frequency of phrases relational ranks positions of the sentences in the text or overlapping rate with the text title
neural network approaches utilize word sentence and document representations as vectors pre trained on large corpora word document or sentence embeddings
then these vectors are imputed into convolutional or recurrent neural networks for classication training
abstractive summarization is considered less traditional
approaches usually include neural network architectures trained on both original texts and human created summaries
approaches using sequence to sequence neural tectures but also attention mechanism have been proposed

evaluation measures for summarization a good summary should be a short version of the original text carrying the majority of relevant content and topics in condensed format
summarization of a text is a subjective problem for humans and it is hard to dene what a good summary would consist of
however a number of quantitative metrics have been proposed such as rouge or pyramid
recall oriented understudy for gisting evaluation rouge is a commonly used metric in summarization literature that is based on overlapping grams in summary and original text
there are several variants of rouge such as rouge n computing percentage of the overlapping n grams rouge l computing the longest overlapping n gram rouge s computing the lapping skip grams in the sentence
since rouge takes into account only overlapping n grams it often favors the summaries that are long where the summarizer did not suciently reduced the size of the original text
pyramid is another metric that is based on the assumption that there is no one best summary of the given original text
pyramid requires a number of human generated summaries for each text as well as human annotations for summarization content units scu
for each scu a weight is assigned based on the number of human generated summaries containing it
newly created the nal authenticated version is available online at
doi
n
milosevic et al
summaries are evaluated based on the overlapping scus and their weights
this method is expensive since it requires a lot of human labour for annotating and generating multiple summaries for evaluated texts
while rouge and pyramid metrics are the most used in current literature other approaches have been proposed
a latent semantic analysis based metric was proposed based on the hypothesis that the analysis of semantic elements of the original text and summary will provide a better metric about the portion of important information that is represented in the summary
as rouge metrics often do not correlate with human rankings the evidence was provided that lsa based metric correlates better than rouge and cosine similarity metric based on the most signicant terms or topics
human ranking and scoring is a measure that is often used for evaluation of summarization systems
human annotations are more expensive than tomatic annotations however they provide a good metric that accounts for all elements of a good summary denition main topics condensed length ity
method
method overview we present a comparison and implementation of four summarization or tion generation methods for social innovation
the input to all summarization methods is text crawled from the social innovation project websites while the expected output is a short and condensed description of the project summary
the method consists of data collection training data set generation data cleaning classication and evaluation steps
figure presents the methodology overview
fig

methodology overview the nal authenticated version is available online at
doi
automatic summarization of social innovation
data collection and data set generation the initial set of social innovation projects was collected using existing databases of social innovation such as mopact digital social innovation innovage si drive
the data was collected from a compiled list of about data sources
some of the data sources contained data that can be downloaded in csv json or xml format however many data sources contained data accessible only through the website and therefore needed to be crawled
as these data sources contained structured data with humanly created descriptions of the projects websites and social media a set of crawlers were created that were able to locate these structured data points on the page and store them in our database
only a small number of data sources already contained descriptions of the projects and they were used for the creation of the training set
we collected projects
out of these project had identiable sites
in order to provide data for describing the projects we created a crawler that collects text from the websites
we performed a set of annotation tasks in which annotators were annotating sentences that describe how each project satises some of the following social innovation criteria social objective project addresses certain often unmet societal needs cluding the needs of particular social groups or aims at social value creation
social actors and actor interactions involves actors who would not normally engage in innovation as an economic activity including formal e

ngos public sector organisations
and informal organisations e

grassroots movements citizen groups
or creates collaborations between social actors small and large businesses and the public sector in dierent nations social outputs creates socially oriented outputs outcomes
often these puts go beyond those created by conventional innovative activity e

ucts services new technologies patents and publications but conventional outputs outcomes might also be present
innovativeness there should be a form of implementation of a new or signicantly improved product good or service or process a new marketing method or a new organisational method
data annotation is further explained in
the data set contained ments of which were annotated by dierent annotators while the rest were mainly single annotated
the distribution of annotated sentences is presented in table
annotated data descriptions from the original data sources and crawled websites were used for training and evaluating summarization approaches

data cleaning the data from the websites may be quite noisy as the crawler was collecting all textual information including menus footers of the pages and at times tisements
additionally many pages contained events and blog posts that were the nal authenticated version is available online at
doi
n
milosevic et al
number of sentences criteria social innovation criteria objectives actors outputs innovativeness not satisfying any criteria binary inside outside summary inside outside table
number of sentences satisfying social innovation criteria not relevant for describing the core of the project
therefore we have performed some data cleaning before proceeding with training the summarizers
in order to reduce the amount of irrelevant text in form of menus and footers we have performed part of speech tagging and excluded sentences that did not contain verbs
for further summarization only main pages about pages and project scription pages were used
in case the page was not in english it was translated using google translate

svm based summarizer the rst summarization approach is based on the assumption that the task can be modelled as a classication task where sentences would be classied as part of a summary or not
it was hypothesized that words in a sentence would indicate whether it describes the project e

project aims to


the goal of the project is to




in order to create a training data set we utilized projects that had both project description in the original data sources and crawled websites
since the descriptions were created by humans they usually can not be matched with the sentences from the website
in order to overcome this issue we generated embedding vectors of the sentences in both the description and the crawled text
we then computed cosine similarities between the sentences from the description and the ones from the crawled text
if the cosine similarity is higher than
the sentence is labeled as part of the summary otherwise it is labeled as a sentence that should not be part of the summary
these sentences were used as training data for the svm classier
before training we balanced the number of positive sentences that should be part of the summary and negative sentences that should remain outside the summary instances
the bag of words transformed to tf idf scores the position of a sentence in the document normalized to the score between and keywords were used as features for the svm classier
the keywords are extracted using knowmak ontology api that for the given text returns grand societal the nal authenticated version is available online at
doi
automatic summarization of social innovation challenge topics and a set of keywords that were matched for the given topic and

social innovation criteria classier the social innovation criteria classier utilized an annotated data set
in this data set sentences that were marked as explaining why a project satises any of the social innovation criteria objectives actors outputs innovativeness were used as positive training instances for the svm classier
the classier used a bag of words transformed to tf idf scores

summarunner summarunner is an extractive summarization method developed by ibm watson that utilizes recurrent neural networks gru
if compared using rouge metrics the algorithm outperforms state of the art methods
the method visits sentences sequentially and classies each sentence by whether or not it should be part of the summary
the method is using a dimensional language model
the model was originally trained on a cnn dailymail data set
the social innovation data set that we have created was quite small and not sucient for training a neural network model about texts compared to over in dailymail data
however we performed a model tting on our social innovation data set

stacked svm based summarizer and summarunner our nal summarization method was developed as a combination of svm based method and summarunner
we have noticed that binary svm model produces quite long summaries and may be ecient for initial cleaning of the text
once the unimportant parts have been cleaned up by the svm based classier marunner shortens the text and generates the nal summary
evaluation methodology in order to evaluate our methodologies and select the best performing model we used rogue metrics human scoring and two topic based evaluation methods
rouge metrics are the most popular and widely used summarization scoring approaches which were presented back in
as such we are utilizing them as well
since a good summary should include the most important topics from the original text topic related metrics can be devised
we have used two topic based metrics one was based on knowmak ontology and the proportion of matched
ac
uk projects the nal authenticated version is available online at
doi
n
milosevic et al
topics related to eu dened grand societal and key enabling in the original and summarized text
the other method was based on latent dirichlet allocation lda
we have extracted topics using lda from merged corpus of original texts and summaries and then we have lated the proportion of topics that match
in order to prevent favouring long summaries we have normalized the scores assuming that the perfect summary should be no longer than of the length of the original text longer texts were penalized
evaluation and results the evaluation of summarization techniques is a challenging process therefore we have employed several techniques
since svms classiers are utilizing classication we have calculated their precision recall and scores
these are measures commonly used for ating classication tasks
these metrics are calculated on a test unseen data set containing documents sentences labeled as inside summary sentences as outside
the results can be seen in table
classier binary svm objectives svm actors svm innovativeness svm outputs svm precision recall score














table
evaluation based on classication metrics precision recall and score for classication based summarizers binary and social innovation criteria based the data set for training these classiers is quite small containing between sentences
it is interesting to note that the criteria classiers containing larger number of training sentences compare table and table perform with a better score objectives and outputs
this indicates that scores can be improved by creating a larger data set
the classiers perform with quite good precision which means there are few false positive sentences the majority of the sentences that end up in summary are correct
since rouge metrics are commonly used in summarization literature we have evaluated all our summarization approaches with rouge rouge and rouge l metrics
the evaluation was performed again on an unseen test set containing documents and their summaries
the results can be seen in table

europa
eu programmes en societal challenges
europa
eu growth industry policy key enabling the nal authenticated version is available online at
doi
automatic summarization of social innovation classier binary svm social innovation svm summarunner binary svm summarunner binary svm summarunner relative length rouge rouge rouge l














table
rouge scores for the developed summarization methodologies summarunner has the best performance based on unigram rouge score
however the social innovation svm based summarizer performs ter in terms of bigram rouge and rouge l score measuring longest common token sequence
based on these results it is possible to conclude that a specically crafted classier for the problem will outperform a generic summarizer even if it was trained only on a small data set
stacked binary svm and summarunner perform worse than single summarizers on their own in terms of rouge
in order to further evaluate the methodologies used we have used an based metric
the assumption behind using this approach was that a good marizer would have a high number of topics in the summary description and the original text matching
the results of the lda topic similarity evaluation can be seen in table
classier binary svm social innovation svm summarunner binary svm summarunner lda topic similarity



table
lda topic similarity scores for the developed summarization methodologies the most matching topics are found with the binary svm classier
however this classier is also producing the longest summaries
stacked svm and marunner are performing similar matches with much shorter summaries being generated
the second topic based approach utilizes topics about grand societal lenges and key enabling technologies retrieved from the knowmak modelling tool
the results can be seen in table
the binary svm summarizer followed by the social innovation summarizer are the best methodologies according to this metric
finally summaries were scored by human annotators
human scorers were presented with an interface containing the original text and a summary for each of the three methods binary svm social innovation svm and summarunner
for each of the summaries they could give a score between
in table are presented averaged scores made by the human scorers
we have also averaged the nal authenticated version is available online at
doi
n
milosevic et al
classier binary svm social innovation svm summarunner binary svm summarunner knowmak topic similarity



table
topic similarity evaluation using knowmak ontology topics the scores in order to account for document length
in order to do that we used the following formula lengthaveragedscore doclen summarylen doclen human score classier binary svm social innovation svm summarunner number of ratings human score length averaged human score





table
human scores for the developed summarization methodologies the best human scores were for binary svm
however this classier excluded only a few sentences from the original text and it was generally creating longer summaries
if the scores are normalized for length the best performing rizer was the one based on social innovation criteria followed by summarunner
at the time of the human scoring the stacked approach consisting of binary svm and summarunner was not yet developed so results for this approach are not available
we have used stacked and social innovation classier in order to generate summaries for our database
stacked model was used as fallback in case summary based on social innovation model was empty or tained only one sentence
the approach was summarizing and generating project descriptions where either the description was too long longer than words or was missing
the summarizer generated new summaries for projects
conclusion making project descriptions and summaries based on the textual data available on the internet is a challenging task
the text from the websites may be noisy dierent length and important parts may be presented in dierent pages of the website
in this paper we have presented and compared several approaches for a particular problem of summarizing social innovation projects based on the information that is available about them on the web
the presented approaches the nal authenticated version is available online at
doi
automatic summarization of social innovation are part of a wider information system including the esid and the tool
since these approaches make extractive summaries they may not have connected sentences in the best manner and therefore additional manual checks and corrections would be performed before nal publication of the data
however these approaches signicantly speed up the process of generating project descriptions
evaluating automatically generated summaries remains a challenge
a good summary should carry the most important content but also signicantly shorten the text
finding a balance between the content and meaning that was carried from original text to the summary and nal length can be quite challenging
most of the currently used measures in the literature do not account for the summary length which may lead to biases towards longer summaries
there are a number of measure that we have used and proposed in this work
often it is not easy to indicate strengths and weaknesses of summarization approaches using single measures and using multiple measures may be benecial
most of the current research presents summarization approaches for general use
even though these approaches can be used in specic domains and for specic cases such as social innovation our evaluation shows that approaches developed for a particular purpose perform better overall
our evaluation indicated that it may be useful to combine multiple rization approaches
certain approaches can be used to clear the text while the others may be used to further shorten the text by carrying the most important elements of the text
in the end we used a combined approach for the production of the summaries in our system
acknowledgments the work presented in this paper is part of the knowmak project that has ceived funding from the european union s horizon research and innovation programme under grant agreement no

references
bazrfkan m
radmanesh m
using machine learning methods to marize persian texts
indian j
sci
res
blei d
m
ng a
y
jordan m
i
latent dirichlet allocation
journal of machine learning research
bonifacio m
social innovation a novel policy stream or a policy compromise an eu perspective
european review
cheng j
lapata m
neural summarization by extracting sentences and words
arxiv preprint

dong y
a survey on neural network based summarization methods
arxiv preprint

manchester
ac

knowmak
the nal authenticated version is available online at
doi
n
milosevic et al

fattah m
a
ren f
ga mr nn pnn and gmm based models for automatic text summarization
computer speech language
lin c
y
rouge a package for automatic evaluation of summaries
text rization branches out
maynard d
lepori b
ontologies as bridges between data sources and user queries the knowmak project experience
in proceedings of science technology and innovation indicators
sti
mikolov t
sutskever i
chen k
corrado g
s
dean j
distributed sentations of words and phrases and their compositionality
in advances in neural information processing systems
pp

milosevic n
gok a
nenadic g
classication of intangible social innovation concepts
in international conference on applications of natural language to information systems
pp

springer
nallapati r
zhai f
zhou b
summarunner a recurrent neural network based sequence model for extractive summarization of documents
in thirty first aaai conference on articial intelligence
nallapati r
zhou b
gulcehre c
xiang b
al
abstractive text tion using sequence to sequence rnns and beyond
arxiv preprint

nenkova a
passonneau r
evaluating content selection in summarization the pyramid method
in proceedings of the human language technology conference of the north american chapter of the association for computational linguistics naacl
neto j
l
freitas a
a
kaestner c
a
automatic text summarization using a machine learning approach
in brazilian symposium on articial intelligence
pp

springer
pagliardini m
gupta p
jaggi m
unsupervised learning of sentence dings using compositional n gram features
in proceedings of the conference of the north american chapter of the association for computational tics human language technologies volume long papers
vol
pp

riedhammer k
favre b
hakkani tur d
long story short global vised models for keyphrase based meeting summarization
speech communication
rush a
m
chopra s
weston j
a neural attention model for abstractive sentence summarization
arxiv preprint

sarkar k
nasipuri m
ghose s
using machine learning for medical document summarization
international journal of database theory and application
sinha a
yadav a
gahlot a
extractive text summarization using neural works
arxiv preprint

steinberger j
jezek k
evaluation measures for text summarization
computing and informatics
young t
hazarika d
poria s
cambria e
recent trends in deep ing based natural language processing
ieee computational intelligence magazine
zhang z
petrak j
maynard d
adapted textrank for term extraction a generic method of improving automatic term extraction algorithms
procedia puter science the nal authenticated version is available online at
doi

