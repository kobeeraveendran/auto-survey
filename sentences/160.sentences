improving abstraction in text summarization wojciech krysci nski kth royal institute of technology
romain paulus salesforce research
com caiming xiong salesforce research
com richard socher salesforce research
com g u a l c
s c v
v i x r a abstract text summarization aims abstractive to shorten long text documents into a human readable form that contains the most important facts from the original document
however the level of actual abstraction as measured by novel phrases that do not appear in the remains low in existing source document approaches
we propose two techniques to improve the level of abstraction of generated summaries
first we decompose the decoder into a contextual network that retrieves relevant parts of the source document and a pretrained language model that incorporates prior knowledge about language generation
second we propose a novelty metric that is optimized directly through policy learning to encourage the generation of novel phrases
our model achieves results comparable to state of the art models as determined by rouge scores and human evaluations while achieving a signicantly higher level of abstraction as measured by n gram overlap with the source document
introduction text summarization concerns the task of pressing a long sequence of text into a more cise form
the two most common approaches to summarization are extractive dorr et al
nallapati et al
where the model extracts salient parts of the source document and tive paulus et al
see et al
where the model not only extracts but also concisely paraphrases the important parts of the document via generation
we focus on developing a marization model that produces an increased level of abstraction
that is the model produces cise summaries without only copying long sages from the source document
work performed while at salesforce research
a high quality summary is shorter than the inal document conveys only the most important and no extraneous information and is cally and syntactically correct
because it is cult to gauge the correctness of the summary evaluation metrics for summarization models use word overlap with the ground truth summary in the form of rouge lin scores
however word overlap metrics do not capture the tive nature of high quality human written maries the use of paraphrases with words that do not necessarily appear in the source document
the state of the art abstractive text tion models have high word overlap performance however they tend to copy long passages of the source document directly into the summary thereby producing summaries that are not tive see et al

we propose two general extensions to rization models that improve the level of tion of the summary while preserving word lap with the ground truth summary
our rst tribution decouples the extraction and generation responsibilities of the decoder by factoring it into a contextual network and a language model
the contextual network has the sole responsibility of extracting and compacting the source document whereas the language model is responsible for the generation of concise paraphrases
our second contribution is a mixed objective that jointly timizes the n gram overlap with the ground truth summary while encouraging abstraction
this is done by combining maximum likelihood tion with policy gradient
we reward the policy with the rouge metric which measures word overlap with the ground truth summary as well as a novel abstraction reward that encourages the generation of words not in the source document
we demonstrate the effectiveness of our tributions on a encoder decoder summarization article human written summary cnn to allay possible concerns boston prosecutors released video friday of the shooting of a police ofcer last month that resulted in the killing of the gunman
the ofcer wounded john moynihan is white
angelo west the gunman shot to death by ofcers was black
after the shooting community leaders in the predominantly african american neighborhood of


boston police ofcer john moynihan is released from the hospital
video shows that the man later shot dead by police in boston opened re rst
moynihan was shot in the face during a trafc stop
generated summary see et al
generated summary liu et al
boston prosecutors released video friday of the shooting of a police ofcer last month
the gunman shot to death by ofcers was black
one said the ofcers were forced to return re
he was placed in a medically induced coma at a boston hospital
boston prosecutors released video of the shooting of a police ofcer last month
boston marathon bombing
the video shows west sprang out and red a shot with a pistol at ofcer s face
the shooting occurred in the wake of the our summary with lm new boston police release video of shooting of ofcer john moynihan
new angelo west had several prior gun convictions police say
boston police ofcer john moynihan survived with a bullet wound
he was in a medically induced coma at a boston hospital a police ofcer says
table summaries generated by different models for the same cnn daily mail article
the highlighted spans indicate phrases of tokens or more that are copied word by word from the original article
our model obtains model
state of the art rouge l scores and and performance comparable to state of the art ods on the cnn dailymail dataset
moreover we signicantly outperform all previous tive approaches in our abstraction metrics
ble shows a comparison of summaries ated by our model and previous abstractive els showing less copying and more abstraction in our model
model
base model and training objective the base model follows the encoder decoder architecture with temporal attention and attention proposed by paulus et al

let e rndemb denote the matrix of demb sional word embeddings of the n words in the source document
the encoding of the source ument henc is computed via a bidirectional lstm hochreiter and schmidhuber whose put has dimension dhid
henc bilstm e rndhid the decoder uses temporal attention over the encoded sequence that penalizes input tokens that previously had high attention scores
let hdec note the decoder state at time t
the temporal t tention context at time t ctmp is computed as t stmp ti qtmp ti tmp ti ctmp t w tmphenc i r r ti hdec t qtmp ti qtmp ji tj r n tmp ti henc i rdhid ti for t
where we set qtmp to the decoder also attends to its previous states via intra attention over the decoded sequence
the intra attention context at time t cint is computed as ti t sint ti cint t hdec t w inthdec i r sint ti sint tj i rdhid hdec the decoder generates tokens by interpolating between selecting words from the source ment via a pointer network as well as selecting words from a xed output vocabulary
let zt note the ground truth label as to whether the tth figure the network architecture with the decoder factorized into separate contextual and language models
the reference vector composed of context vectors ctmp and the hidden state of the t textual model hdec is fused with the hidden state of the language model and then used to compute the distribution over the output vocabulary
cint t t output word should be generated by the selecting from the output vocabulary as opposed to from the source document
we compute the bility that the decoder generates from the output vocabulary as rt hdec ctmp t zrt bz r cint t t the probability of selecting the word yt from a xed vocabulary at time step t is dened as the likelihood of which is log yt log zt log zt log zt log zt log zt log p zt zt log log zt log log p zt the objective function combines maximum likelihood estimation with policy learning
let m denote the length of the ground truth summary the maximum likelihood loss lml is computed as softmax w genrt bgen lml log m we set the probability of copying the word yt from the source document to the temporal attention distribution tmp
the joint probability t of using the generator and generating the word yt at time step t is then yt policy learning uses rouge l as its reward function and a self critical baseline using the greedy decoding policy rennie et al

let ysam denote the summary obtained by sampling from the current policy p ygre and zgre the mary and generator choice obtained by ily choosing from the rouge l score of the summary y and the model ters
the policy learning loss is r r ysam r ygre lpg e zsam ysam where we use greedy predictions by the model according to eq
as a baseline for variance reduction
the policy gradient as per schulman et al
is lpg r log p zsam t ysam t m the nal loss is a mixture between the mum likelihood loss and the policy learning loss weighted by a hyperparameter
l lpg
language model fusion the decoder is an essential component of the base model
given the source document and the viously generated summary tokens the decoder both extracts relevant parts of the source document through the pointer network as well as composes paraphrases from the xed vocabulary
we ple these two responsibilities by augmenting the decoder with an external language model
the guage model assumes responsibility of generating from the xed vocabulary and allows the decoder to focus on attention and extraction
this position has the added benet of easily ing external knowledge about uency or domain specic styles via pre training the language model on a large scale text corpora
the architecture of our language model is based on merity et al

we use a layer tional lstm with weight dropped lstm units
let et denote the embedding of the word erated during time step t
the hidden state of the language model at the l th layer is l t lstmlm hlm hlm l at each time step t we combine the hidden state of the last language model lstm layer hlm with rt dened in eq
in a fashion similar to sriram et al

let denote element wise plication
we use a gating function whose output gt lters the content of the language model hidden state
ft gt w gt hlm w hlm bfuse hfuse t relu gt we then replace the output distribution of the language model pgen yt in eq
with pgen yt softmax w genhfuse t
abstractive reward in order to produce an abstractive summary the model can not exclusively copy from the source document
in particular the model needs to parse large chunks of the source document and create concise summaries using phrases not in the source document
to encourage this behavior we pose a novelty metric that promotes the generation of novel words
we dene a novel phrase in the summary as one that is not in the source document
let ng n denote the function that computes the set of unique n grams in a document xgen the generated mary xsrc the source document and the ber of words in s
the unnormalized novelty ric n is dened as the fraction of unique n grams in the summary that are novel
n xgen n xgen n ng xsrc xgen to prevent the model for receiving high elty rewards by outputting very short summaries we normalize the metric by the length ratio of the generated and ground truth summaries
let xgt denote the ground truth summary
we dene the novelty metric as rnov xgen n n xgen n we incorporate the novelty metric as a reward into the policy gradient objective in eq
alongside the original rouge l metric
in doing so we encourage the model to generate summaries that both overlap with human written ground truth summaries as well as incorporate novel words not in the source document r y rourrou ysam novrnov ysam where rou and nov are hyperparameters that control the weighting of each reward
experiments
datasets we train our model on the cnn daily mail dataset hermann et al
nallapati et al

vious works on abstractive summarization either use an anonymized version of this dataset or the original article and summary texts
due to these different formats it is difcult to compare the overall rouge scores and performance between each version
in order to compare against ous results we train and evaluate on both versions of this dataset
for the anonymized version we follow the pre processing steps described in lapati et al
and the pre processing steps of see et al
for the the full text version
we use named entities and the source document to supervise the model regarding when to use the pointer and when to use the generator e

zt in eq

namely during training we teach the model to point from the source document if the word in the ground truth summary is a named entity an out of vocabulary word or a numerical value that is in the source document
we obtain the list of named entities from hermann et al


training details the two lstms of our bidirectional encoder are dimensional and out decoder lstm is dimensional
we restrict the input vocabulary for the embedding matrix to tokens and the output decoding layer to tokens
we limit the size of input articles to the rst tokens and the summaries to tokens
we use scheduled sampling bengio et al
with a probability of
when calculating the maximum likelihood training loss
we also set n when computing our novelty reward n
for our nal training loss using reinforcement learning we set
rou
and nov

finally we use the trigram repetition avoidance heuristic dened by paulus et al
during beam search decoding to ensure that the model does not output twice the same trigram in a given summary ing the amount of repetitions

novelty baseline we also create a novelty baseline by taking the outputs of our base model without rl training and without the language model and inserting dom words not present in the article after each summary token with a probability r

this baseline will intuitively have a higher centage of novel n grams than our base model puts while being very similar to these original puts hence keeping the rouge score difference relatively small
results
language models
quantitative analysis for each dataset version we train a language model consisting of a dimensional word bedding layer and a layer lstm with each layer having a hidden size of dimensions except the last input layer which has an output size of
the nal decoding layer shares weights with the embedding layer inan et al
press and wolf
we also use dropconnect wan et al
in the hidden to hidden connections as well as the non monotonically triggered chronous gradient descent optimizer from merity et al

we train this language model on the cnn daily mail ground truth summaries only following the same training validation and test splits as our main experiments
we obtain a validation and test perplexity of
and
respectively on the anonymized dataset and
and
on the full text dataset with the language models described in section

the rouge scores and novelty scores of our nal summarization model on both versions of the cnn daily mail dataset are shown in table
we report the and l f scores as well as the percentage of novel grams marked nn n in the generated summaries with n from to
results are omitted in cases where they have not been made available by vious authors
we also include the novel n gram scores for the ground truth summaries as a parison to indicate the level of abstraction of man written summaries
model r l ground truth summaries intra attn paulus et al











with lm ours






anonymized full text ground truth summaries pointer gen coverage see et al
sumgan liu et al
rsal pasunuru and bansal rl pasunuru and bansal


























with lm ours






table comparison of rouge and novel n gram test results for our model and other abstractive summarization models on the cnn daily mail dataset
even though our model outputs signicantly fewer novel n grams than human written it has a much higher percentage of maries novel n grams than all the previous it also achieves state of the art tive approaches
rouge l performance on both dataset versions and obtains and scores close to state of the art results

ablation study in order to evaluate the relative impact of each of our individual contributions we run ablation ies comparing our model ablations against each other and against the novelty baseline
the sults of these different models on the validation set of the anonymized cnn daily mail dataset are shown in table
results show that our base model trained with the maximum likelihood loss only and using the language model in the coder ml with lm has higher rouge scores novel unigrams and novel bigrams scores than our base model without the language model ml
ml with lm also beats the novelty baseline for these metrics
when training these models with reinforcement learning using the rouge reward rouge and rouge with lm the model with language model obtains higher and scores
ever it also loses its novel unigrams and bigrams advantage
finally using the mixed rouge and novelty rewards duces both higher rouge scores and more novel unigrams with the language model than without it
this indicates that the combination of the guage model in the decoder and the novelty reward during training makes our model produce more novel unigrams while maintaining high rouge scores

rouge vs novelty trade off in order to understand the correlation between rouge and novel n gram scores across different architectures and to nd the model type that gives the best trade off between each of these metrics we plot the and novel unigram scores for the ve best iterations of each model type on the anonymized dataset as well as the and novel bigram scores on a separate plot
we also include the novelty baseline described in tion
for values of r between
and

for each model type we indicate the pareto tier by a line plot ben tal illustrating which models of a given type give the best nation of rouge and novelty scores
these plots are shown in figure
these plots show that there exist an inverse relation between rouge and novelty scores in all model types illustrating the challenge of choosing a model that performs well in both
given that our nal model with lm provides the best trade off of scores compared to novel unigrams indicated by the higher pareto frontier in the rst plot
similarly our nal model gives one of the best trade offs of scores to novel bigrams even though the same model without lm produces more novel model r l ml ml with nov
baseline r
ml with lm rouge rouge with lm
with lm















































table ablation study on the validation set of the anonymized cnn daily mail dataset
figure rouge and novel n grams results on the anonymized validation set for different runs of each model type
lines indicates the pareto frontier for each model type
bigrams with a lower score

qualitative evaluation in order to ensure the quality of our model outputs we ask human evaluators to rate randomly selected full text test summaries giving them two scores from to respectively for readability and relevance given the original article
we also include the full text test outputs from see et al
and liu et al
for comparison
uators are shown different summaries ing to the same article side by side without ing told which models have generated them
the mean score and condence interval at for each model and each evaluation criterion are ported in table
these results show that our model matches the relevance score of see et al
and liu et al
but is slightly rior to them in terms of readability
related work text summarization
existing summarization approaches are usually either extractive or tive
in extractive summarization the model lects passages from the input document and bines them to form a shorter summary times with a post processing step to ensure nal coherence of the output neto et al
dorr et al
filippova and altun menares et al
nallapati et al

while extractive models are usually robust and produce coherent summaries they can not create concise summaries that paraphrase the source document using new phrases
abstractive summarization allows the model to paraphrase the source document and create cise summaries with phrases not in the source document
the state of the art abstractive marization models are based on sequence sequence models with attention bahdanau et al

extensions to this model include a attention mechanism paulus et al
and an article coverage vector see et al
to prevent repeated phrases in the output summary
different training procedures have also been used improve the rouge score paulus et al
or textual model readability relevance pointer gen coverage see et al
sumgan liu et al








with lm



table mean and condence interval at of human evaluation scores on the full text test outputs
individual summaries are rated from to a higher score indicating higher quality for readability and relevance separately
entailment pasunuru and bansal with forcement learning as well as generative ial networks to generate more natural summaries liu et al

several datasets have been used to train and evaluate summarization models
the gigaword graff and cieri and some duc datasets over et al
have been used for headline generation models rush et al
nallapati et al
where the generated summary is shorter than characters
however generating longer summaries is a more challenging task pecially for abstractive models
nallapati et al
have proposed using the cnn daily mail dataset hermann et al
to train models for generating longer multi sentence summaries up to words
the new york times dataset haus has also been used as a benchmark for the generation of long summaries durrett et al
paulus et al

training strategies for sequential models
the common approach to training models for sequence generation is maximum likelihood estimation with teacher forcing
at each time step the model is given the previous ground truth output and dicts the current output
the sequence objective is the accumulation of cross entropy losses from each time step
despite its popularity this approach for quence generation is suboptimal due to exposure bias huszar and loss evaluation mismatch wiseman and rush
goyal et al
propose one way to reduce exposure bias by plicitly forcing the hidden representations of the model to be similar during training and ence
bengio et al
and wiseman and rush propose an alternate method that poses the network to the test dynamics during training
reinforcement learning methods sutton and barto such as policy learning sutton et al
mitigate the mismatch between the optimization objective and the evaluation metrics by directly optimizing evaluation metrics
this approach has led to consistent improvements in domains such as image captioning zhang et al
and abstractive text summarization paulus et al

a recent approach to training sequential models utilizes generative adversarial networks to ing the human perceived quality of generated puts fedus et al
guimaraes et al
liu et al

such models use an additional discriminator network that distinguishes between natural and generated output to guide the tive model towards outputs akin to human written text
conclusions we introduced a new abstractive summarization model which uses an external language model in the decoder as well as a new reinforcement ing reward to encourage summary abstraction
periments on the cnn daily mail dataset show that our model generates summaries that are much more abstractive that previous approaches while maintaining high rouge scores close to or above the state of the art
future work could be done on closing the gap to match human levels of tion which is still very far ahead from our model in terms of novel n grams
including mechanisms to promote paraphrase generation in the summary generator could be an interesting direction
references dzmitry bahdanau kyunghyun cho and yoshua gio

neural machine translation by jointly learning to align and translate
in iclr
aharon ben tal

characterization of pareto and lexicographic optimal solutions
in multiple ria decision making theory and application pages
springer
samy bengio oriol vinyals navdeep jaitly and noam shazeer

scheduled sampling for quence prediction with recurrent neural networks
in nips
linqing liu yao lu min yang qiang qu jia zhu and hongyan li

generative adversarial work for abstractive text summarization
in aaai
stephen merity nitish shirish keskar and richard socher

regularizing and optimizing lstm guage models
in iclr
carlos a colmenares marina litvak amin mantrach and fabrizio silvestri

heads headline eration as sequence prediction using an abstract feature rich space
in hlt naacl pages
ramesh nallapati feifei zhai and bowen zhou

summarunner a recurrent neural network based quence model for extractive summarization of ments
in aaai
bonnie dorr david zajic and richard schwartz

hedge trimmer a parse and trim approach to line generation
in hlt naacl
greg durrett taylor berg kirkpatrick and dan klein

learning based single document tion with compression and anaphoricity constraints
in acl
william fedus ian j
goodfellow and andrew m
dai

maskgan better text generation via lling in the
in iclr
katja filippova and yasemin altun

ing the lack of parallel data in sentence compression
in proceedings of emnlp pages
seer
anirudh goyal alex lamb ying zhang saizheng zhang aaron c
courville and yoshua bengio

professor forcing a new algorithm for ing recurrent networks
in nips
david graff and c cieri

english gigaword guistic data consortium
gabriel lima guimaraes benjamin lengeling pedro luis cunha farias and alan aspuru guzik

objective reinforced ative adversarial networks organ for sequence generation models
corr

karl moritz hermann tomas kocisky edward grefenstette lasse espeholt will kay mustafa leyman and phil blunsom

teaching chines to read and comprehend
in nips
sepp hochreiter and jurgen schmidhuber

long short term memory
neural computation
ferenc huszar

how not to train your tive model scheduled sampling likelihood sary corr

hakan inan khashayar khosravi and richard socher

tying word vectors and word classiers a loss framework for language modeling
in iclr
chin yew lin

rouge a package for automatic evaluation of summaries
in proc
acl workshop on text summarization branches out page
ramesh nallapati bowen zhou c aglar gulcehre bing xiang al

abstractive text rization using sequence to sequence rnns and yond
proceedings of signll conference on putational natural language learning
joel larocca neto alex a freitas and celso aa kaestner

automatic text summarization ing a machine learning approach
in brazilian posium on articial intelligence pages
springer
paul over hoa dang and donna harman

duc in context
inf
process
manage

ramakanth pasunuru and mohit bansal

reward reinforced summarization with saliency and entailment
corr

romain paulus caiming xiong and richard socher

a deep reinforced model for abstractive marization
in iclr
or press and lior wolf

using the output arxiv embedding to improve language models
preprint

steven j
rennie etienne marcheret youssef mroueh jarret ross and vaibhava goel

self critical sequence training for image captioning
corr

alexander m rush sumit chopra and jason weston

a neural attention model for abstractive tence summarization
proceedings of emnlp
evan sandhaus

the new york times annotated corpus
linguistic data consortium philadelphia
john schulman nicolas heess theophane weber and pieter abbeel

gradient estimation using stochastic computation graphs
in nips
abigail see peter j
liu and christopher d
manning

get to the point summarization with generator networks
in acl
anuroop sriram heewoo jun sanjeev satheesh and adam coates

cold fusion training models together with language models
corr

richard s
sutton and andrew g
barto

inforcement learning an introduction
adaptive computation and machine learning
mit press
richard s
sutton david a
mcallester satinder p
singh and yishay mansour

policy ent methods for reinforcement learning with tion approximation
in nips
li wan matthew zeiler sixin zhang yann le cun and rob fergus

regularization of neural works using dropconnect
in icml
sam wiseman and alexander m
rush

sequence to sequence learning as beam search timization
in emnlp
li zhang flood sung feng liu tao xiang shaogang gong yongxin yang and timothy m
hospedales

actor critic sequence training for image tioning
corr


