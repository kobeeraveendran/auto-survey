extractive multi document summarization using multilayer networks jorge v
tohalino diego r
amancio institute of mathematics and computer science university of sao paulo sao carlos sao paulo brazil v o n l c
s c v
v i x r a abstract huge volumes of textual information has been produced every single day
in order to organize and understand such large datasets in recent years summarization techniques have become popular
these techniques aims at nding relevant concise and non redundant content from such a big data
while network methods have been adopted to model texts in some scenarios a systematic evaluation of multilayer network models in the multi document summarization task has been limited to a few studies
here we evaluate the performance of a multilayer based method to select the most relevant sentences in the context of an extractive multi document summarization mds task
in the adopted model nodes represent sentences and edges are created based on the number of shared words between sentences
dierently from previous studies in document summarization we make a distinction between edges linking sentences from dierent documents inter layer and those connecting sentences from the same document intra layer
as a proof of principle our results reveal that such a discrimination between and inter layer in a multilayered representation is able to improve the quality of the generated summaries
this piece of information could be used to improve current statistical methods and related textual models
keywords complex networks multilayer networks structure and dynamics pagerank text analysis text summarization
introduction since textual information available on the internet has increased in recent years methods that sify understand and present the information in a clear and concise way have played a prominent role in data and text mining applications
automatic summarization question answering and information retrieval are some of the multi way proposed solutions to address the problem of managing large volumes of unstructured data such as written texts
automatic summarization is the process of creating a compressed version summary of one document summarization or more documents multi document summarization mds by extracting the most important content
automatic summarization techniques are traditionally divided into two groups extractive and abstractive summarization
the task of extractive summarization consists in concatenating several sentences which are selected without modication i
e
exactly as they appear in the original ment
on the other hand the creation of abstractive summaries is a more complex and dicult task because preprint submitted to journal of latex templates november it involves paraphrasing sections of the source document and for this reason it requires natural language generation tools
in addition abstractive methods may reuse clauses or phrases from original documents
in this work we target our analysis on extractive summarization applied to a set of documents mds
the most traditional employed methods to select relevant sentences for extractive summarization are divided into the following major classes methods based on word frequency sentence clustering and machine learning
in recent years a new class of methods based on network theory have been proposed to analyze texts
applications of network models in text analysis include the study of scientic documents stylometry sense discrimination and several other applications
the problem of creating single document extractive summaries has beneted from these previous network models of texts
it has been claimed that network features overcome other traditional statistical methods when they are used to identify the most central sentences
while most of the studies applying network concepts in summarization have been limited to the single document counterpart here we evaluate the usefulness of networks in the multi document scenario
in particular the main objective of this paper is to probe whether a discrimination between and inter layer edges is able to improve the characterization of documents modeled as multilayer complex networks
this is an important feature to be considered in the models because a sentence connected to many other sentences from other documents may indicate a high relevance of the approached topics
in the adopted method nodes represent sentences and edges are established according to the lexical similarity between two sentences
a multilayer network is created by considering each document as a layer
as such two types of links arises those connecting sentences from the same documents and the links connecting sentence from distinct sources
in addition to the traditional network measurements we also used dynamical measurements to improve the characterization of the obtained networks
an evaluation on three corpora english and portuguese revealed that a simple distinction between and inter layer edges yields better performance in comparison to network methods not relying upon multilayered representations
a complimentary analysis also revealed that in general traditional measurements such as degree and pagerank yields a good performance for the mds task
finally we also found that dierently from the single document case there is no strong correlation among the evaluated network measurements which suggests that they could be combined to improve the identication of relevant sentences
this paper is organized as follows in section we present a brief survey of works that used complex networks for extractive summarization
the description of the adopted network model and the network metrics we used to rank sentences are described in section
in section the results are presented and discussed
finally the conclusions and prospects for future work are discussed in section

related work several works have addressed the task of extractive summarization based on complex networks tools and methods
for example in the work of ribaldo et al
the mds task was applied for documents in brazilian portuguese
the authors rst extracted all sentences from the cluster of documents and then they modelled them as a single network
after the pre processing stage sentences were represented as nodes which were linked by traditional similarity measurements
in order to select the best ranked sentences the authors used simple network measurements including degree clustering coecient and average shortest path length
a simple heuristic to avoid redundant sentences in the generated summaries was also applied
the results showed that the proposed method yielded competitive results which were close to the best statistical systems available for the portuguese language
even though this work addressed the mds with a graph based approach no distinction between and inter layer edges was considered
antiqueira et al
represented sentences as nodes which are linked if they share signicant lemmatized nouns
the authors applied static complex network metrics to identify the relevant sentences to compose the extract
a summarization system based on voting system was used to combine the results of summaries generated by dierent measurements
some systems achieved good results which are comparable to the top single document summarizers for brazilian portuguese
leite and rino used multiple features to automatically select the best attributes from single layer complex networks and other linguistic features
more specically the authors combined linguistic features and features network based measurements
for extract generation leite and rino used machine learning to classify each sentence as present or not present in summary
an evaluation in a corpus portuguese texts conrmed that the proposed network methods can be combined with linguistic features so as to improve the characterization of textual documents
in the work of erkan and radev sentences are represented as nodes
the bag of words model is used to represent the sentences
a connection between two nodes is established if the cosine similarity between the vectors of sentences is higher than a predened threshold
to rank the sentences the authors used degree centrality and eigenvector based metrics
competitive results were reported even if when applied to noisy data
in the work of mihalcea similarly to other studies sentences are nodes and edges represent the lexical similarity between sentences
the authors used recommendation algorithms for web pages to select the most informative sentences
the proposed algorithms used both google s pagerank and hits
mihalcea considered three network types undirected forward edges reecting the natural reading ow and backward edges going from the current to the previous word
the systems were evaluated by using the english corpus
the best performance was achieved with the hits algorithm for english texts
conversely for the portuguese scenario the pagerank algorithm yielded the best performance

methodology in the current paper we propose a method based on complex network measurements for multi document summarization by modeling a set of documents as a multilayer network
we represent each document sentence by a node and edges are established based on the cosine similarity between two sentences
the adopted method to extract the most relevant sentences from the texts can be divided into the following steps document pre processing sentence vectorization network creation measurements extraction and summarization i
e
sentence selection
these steps are detailed in sections




datasets the datasets used in this work comprises texts originally written in portuguese and english
since in a multi document context texts are organized according to the subject approached each dataset is organized in a set of clusters of related texts
the details of the datasets are provided below cstnews for portuguese mds this corpus includes documents extracted from on line brazilian news agencies folha de sao paulo estadao o globo gazeta povo and jornal do brazil
this corpus comprises news items which are divided into clusters
each cluster contains or documents sharing the same topic
this corpus includes two reference manual multi document summaries for each cluster
each summary has a compression rate
for english mds this corpus comprises a set of texts divided into clusters from the following on line news journals wall street journal ap newswire san jose mercury news financial times la times and fbis
each cluster include two word reference summaries
for english mds this corpus contains clusters of documents each
four man reference summaries with characters length were produced for this corpus
the documents were extracted from the following sources associated press newswire new york times newswire and xinhua news agency


document pre processing in this step the following pre processing steps are applied text segmentation removal of unnecessary words and lemmatization
in text segmentation sentences boundaries are recognized
we dened a sentence as any text segment separated by a period exclamation or question mark
punctuation marks and stopwords such as articles and prepositions were also removed
finally we lemmatized the remaing words so as to map the remaining words to their canonical forms
as a consequence plural nouns and conjugated verbs are transformed to their singular and innitive forms
to illustrate this process we provide in table a small piece of text undergoing the aforementioned pre processing steps
table example of pre processing steps applied to a piece of text extracted from wikipedia
we rst show the original document divided into seven sentences g
the corresponding preprocessed sentences are shown in lines
original sentences a
arequipa is the capital and largest city of the arequipa region from peru
it is peru s second most populous city with habitants
arequipa is the second most industrialized and commercialized city in peru
its industrial activity includes manufactured goods and camelid wool products for export e
the city has close trade ties with chile bolivia and brazil
the city was founded on august by garc manuel de carbajal g
the historic center of arequipa spans an area of hectares and is a unesco world heritage site pre proccesed sentences
arequipa capital large city arequipa region peru
peru second populous city habitant
arequipa second industry commerce city peru
industry activity include manufacture good camelid wool product export
city trade tie chile bolivia brasil
city be found august garci manuel carbajal
history center arequipa span area unesco world heritage site

sentence vectorization the next step in mapping a text into a network is the sentence vectorization
the tf idf term inverse document frequency weighting is a widely used method for document representation
we used this method because it was employed with satisfactory results in several other nlp tasks
the term frequency tf of a term t in a document d is calculated as t where t d is the number of times the term t appears in the document d and is the total number of terms in d
the inverse document frequency idf of term t in the collection of documents d is calculated as d log df where d is the total number of documents and df is the number of documents in which the term t appears
finally the tf idf weight is computed as tf d d d
in order to get the representative vector of each sentence we calculate the tf idf value for each of its content words


network creation the multilayered representation of documents is created using the following steps
tf idf based network creation in this model we rst calculate the tf idf vector representations for each document sentences
next each node is represented by a sentence and edges between two sentences i and j are established based on the cosine similarity wi j between the corresponding tf idf vectors
figure shows an example of the tf idf network generated from the example in table
figure example of tf idf based network
each node number represents the sentences from the piece of text shown in table
edge weights are created according to the cosine similarity between sentences

edge type identication we dened two edge types i edges connecting sentences from the same document intra layer edges and edges connecting sentences from dierent documents inter layer edges
this dierentiation is essential to assign relevance to the sentences according to the types of links established

type based edge weighting in multi document summarization it is important to consider document relationships
here we emphasize the importance of multi document tionships by reinforcing inter layer edges
such a reinforcement is done using the a simple linear function i j i j where is a factor that reinforces inter layer connections if and i j is the original layer edge weight connecting nodes i and j
as we shall show reinforcing intra layer links may also be important to improve the characterization of the set of documents
such an eect is simulated by considering in the experiments

edge removal for non weighted measurements this step is required because some network ments are not dened for weighted networks
here we removed a fraction r of the weakest links
the remaining edges are considered as unweighted
to illustrate the creation of multilayer networks figure shows an example of a multilayer network generated from a cluster of three documents
figure network model adopted in this work
each layer represents a document
continuous lines are edges linking sentences from the same document intra layer while dashed lines link sentences from dierent documents inter layer


network measurements in the summarization context the goal of a centrality network measurement is to rank the nodes according to its relevance
the importance assigned by network measurements allows us to determine which are the best ranked sentences that could compose the nal summary
therefore in this stage we use a set of network measurements to rank each node network
every measurement is used individually thus each metric generates one summary
in this work we used not only traditional network measurements such as degree strength shortest paths and pagerank but also additional measurements to take into account both the topological structure of the networks and their dynamical behavior
the latter can be captured by considering dynamical processes occurring on the top of the networks
a well known dynamics used in the context of text analysis in the traditional random walk
here we also use the self avoiding random walk an exploratory dynamics used to dene measurements such as accessibility and symmetry
below we detail each of the measures used in this work
degree the degree of a node i is the number of edges linked to that node
a high degree value suggests that a sentence is related to several others in the document or collection
strength for weighted networks the strength of a node i is the sum of the weights of all its incident edges
in unweighted networks the strength corresponds to the node degree
shortest paths l a shortest path between two nodes i and j is one of the paths that connects these nodes with a minimum length
the length of such a path is henceforth denoted as dij
the average shortest path length is dened as li where n is the total number of words in the network
a sentence is considered relevant for a document or collection if its average distance to any other sentence takes low values
in textual networks the shortest path length has been useful to identify relevant textual concepts
pagerank this measurement considers that a node i is relevant if it is connected to other relevant nodes
it can be computed in a recursive way as i aij j j where and are damping factors taking values between and
in text analysis this measurement has been used to identify the most probable sense of ambiguous constructions
a similar ment based on the number of shortest paths has also been used to gauge similarity in texts modeled as complex networks
accessibility the accessibility quanties how many nodes are accessible from an initial node when a self avoiding random walk of length h is performed
this measurement has been employed to identify borders in geographical networks and to characterize the interplay between structure and dynamics in a wide range of complex networks
dierently from other traditional graph measurements the accessibility takes into consideration dierent levels of hierarchy which can be set by specifying the length h of the random walks
in textual analysis this measurement has proven useful to identify key concepts in stylometric applications
to calculate the accessibility let j represent the probability of reaching a node j from i through a self avoiding random walk of length h
the accessibility is dened as the exponential of the true diversity of j i exp j log j
j it can be shown that the accessibility can be interpreted as the eective number of accessed nodes in the considered dynamics
to illustrate the accessibility concept we show in figure a subgraph created around node a
two congurations of links are considered i continuous red links and ii scenario i two additional blue dotted links
note that in the rst scenario all nodes in the second hierarchical level are reached with the same probability p
this leads to the maximum accessibility value a
in the second scenario the access to the nodes becomes uneven because two additional paths are created see dashed blue lines
such an irregular distribution leads to a decreased value of accessibility

a generalized accessibility a the accessibility measurement depends on the parameter h for its culation
the new version of accessibility called generalized accessibility is an improvement of cessibility because this new version can be computed without any prior choice of length h
actually this metric is computed by considering all lenghts in the random walk dynamics
the generalized accessibility depends upon the stochastic matrix p whose element j represents the probability of a random walker to go from node i to j in the next step of the random walk
the transition probability considering all lengths can be computed as e j pj
the transition probabilities obtained in can then be used to compute the generalized accessibility figure example of computation of accessibility considering two conguration of edges i red continuous edges only and ii red continuous and blue dotted edges
in i the access to the nodes at the second hierarchical level is uniform
therefore the accessibility reaches its maximum value
in the access to the nodes becomes uneven as some nodes tend to be accessed more frequently than others
as a consequence the accessibility of a drops to

a a using the true diversity of i
e
exp j log j j where is an element of
this metric has been employed with success as a centrality surement applied in other text classication tasks
symmetry s the network symmetry is a normalized version of accessibility where the number of accessible nodes is used as normalization factor
the symmetry uses the concept of concentric level h of a node i see figure which is dened as the set of nodes h hops away from i
because the main objective of this metric is to quantify how diverse is the exploration of a neighborhood the symmetry measurement considers that at each step the random walker access the next concentric level
thus to compute probabilities transitions all links connecting nodes in the same concentric ap hierarchical hierarchical level level are disregarded
the symmetry is calculated as i i exp j log j where i is the set of accessible nodes that are at a distance h from the node i i
e
the number of nodes in the h th level
because this measurement has never been used for summarization in the current work we evaluated the performance of selecting the sentences with the highest and lowest values of symmetry
absorption time the absorption time is dened as the time it takes for a particle in an internal node to reach an output absorbent node through a random walk
this metric quanties how fast a randomly walking particle is absorbed by output vertices assuming that the particle starts the random walk at the input node
the stochastic transition matrix p is used to compute this metric
the absorption time is dened using the matrix i where i is the identity matrix and is a submatrix of p which represents the transitions between transient nodes i
e
non absorbent nodes
it can be shown that the time spent in transient nodes can be computed as for each pair i j of nodes we dene i as a starting node and j as an absorbent node to compute
thus here the absorption time of a node i is computed as ti j
j i n tk
by using this measurement we expect that sentences taking low values of absorption time are more semantically related to the other sentences in the text
thus to generate the summary we select the sentences with the lowest values of i


summary generation in this stage the nal summary is created by selecting the best ranked sentences according to some measurement and strategy selection
the selection can be made by choosing either the highest or the lowest values of the considered metrics
the strategy used for each measurement is summarized in table
for summary generation a compression rate must be specied
the size of the generated summaries in the current work is the same as the size of the available reference summaries for the corpora used
table adopted network measurements for mds
the weighted version of the networks was considered only with the most traditional measurements
selection strategy measurement degree strength pagerank accessibility symmetry gen
accessibility shortest paths symmetry absorption time abbr
dg stg pr pr w access sym gaccess sp sp w sym highest values lowest values an additional important issue in summarization is the so called redundancy treatment
in the context of automatic summarization redundancy arises when identical or similar sentences composes the nal summary
in network terms two sentences in the nal summary are considered redundant if they are connected by strong links
in this paper we adopted two anti redundancy detection methods
in both methods a similarity threshold is established to compare sentences
at each step if the current best ranked sentence is similar to any of the previously selected sentences in the summary then it is considered redundant
therefore the redundant piece of text is not used to compose the nal summary
in this case the summarization process resumes and the next candidate sentence is evaluated
in the rst anti redundancy method the threshold value is computed as where j is the cosine similarity between two sentences i and j
the second anti redundancy method considers the following similarity measurement j j j n k k k n where n is the number of n grams to be considered k is the set of k grams of sentence i and k is the weight associated with the k gram similarity of two sets
we chose as threshold for the value

the other parameters in equation were chosen in accordance with ref


results in this section we evaluate the performance of the multilayered approach considering dierent weighting schemes for inter layer edges
we also assess the relevance of each network metric for the adopted network representation
finally we analyze the correlation between the network metrics in order to identify possible correspondences equivalences between the adopted multilayer network measurements


performance analysis the systems were evaluated using the following corpora cstnews a corpus of portuguese journalistic texts and duc and which are corpora comprising english journalistic texts
the evaluation of the informativeness of our method was done by using the automatic evaluation method which compares automatically generated summaries and reference texts
this metric was used here because it has been claimed that there is a strong correlation between the rouge index and manual human judgment
an important parameter in the analyzed multilayer networks is the setup of relevance weights for layer edges see in equation
the parameter accounts for assigning a higher or lower relevance for inter document relationships
the values of varied in the range


for each value of we removed a xed amount r of the weakest links r





concerning the anti redundancy methods both strategies and considered in this article displayed similar performance result not shown
for this reason hereafter we only report the best results
figure shows the overall performance of the multilayer approach as a function of for the cstnews corpus
for each subplot we show the curves for dierent percentages of removed edges
remarkably apart from the simmetry measurement we observed an improvement in performance when
we note that the best results can be obtained in two distinct scenarios i where a higher relevance is given for intra document relationships and where a higher relevance is assigned for the inter document relationships
the second scenario seems to be more important for improving the performance of the system since holds just for the degree
we also note from the gures that the best value of r depends on the measurement being analyzed
figure shows the performance of the multilayer approach for the corpus
as observed in the cstnews figure a value of is able to improve the performance of the systems except for the symmetry measurement
dierently from the previous analysis here the intra document relationships seems to play an important role for a larger number of network measurements
optimized results were figure performance analysis recall of the adopted multilayer approach in the cstnews corpus for portuguese mds
each subgure shows the performance of each proposed network measurement as a function of the inter layer edge weight parameter
obtained for for the degree shortest path length pagerank and accessibility both a and a
a major improvement in performance for was observed for the absorption time measurement
similarly to the behavior observed for the portuguese corpus here the best value of r depends on the adopted network measurement
a similar result was obtained with the corpus see figure of the supplementary information si with the best results being obtained for except for the symmetry
tables and summarize the results obtained in both cstnews and
for the portuguese case the best results were obtained with degree and shortest paths both considering the strategy to address the anti redundancy problem
actually apart from the generalized accessibility the best results were always obtained with the technique
for the english corpus the pagerank strategy outperformed the other network measurements
a good performance was also observed when the generalized accessibility was used
here the technique for anti redundancy treatment achieved the best results
considering the measurements based on self avoiding random walks the best performance occurred for figure performance analysis of corpus for english mds
each sub gure shows the performance of each proposed network measurement considering the inter layer edge weight parameter and thresholds of edge removal
axis represents the inter layer edge weight parameter and y axis is the average recall
the generalized accessibility
this measurement outperformed its hierarchical version probably because the adopted generalization grasps more information about the network organization
note that the denition of the generalized accessibility dierently from the hierarchical version considers all hierarchical levels to estimate the eective number of accessed nodes see equation
consistently the symmetry measurement displayed low performance in all adopted datasets
this might be related to the fact that such measurement mainly quanties the diversity of links weights and not the proeminence of nodes
while such a diversity might be of interest to quantify particular textual phenomena see e

for an application on authorship recognition the obtained results suggests that the most important information to quantify relevance is not captured by the symmetry
the results obtained for see table also conrms that low values of optimizes the performance for particular several measurements
the results observed in the above experiments suggests that the multilayer representation is relevant to identify the most prominent nodes sentences in documents
the importance of the and table best results obtained for portuguese mds
the network measurements are ranked according to the obtained recall
for each metric we show the respective parameters for inter layer edge weight and the threshold r for edge remotion
the anti redundancy detection ard method that obtained the best result is also shown
table best results for english mds corpus
the network measurements are ranked according to the obtained recall
for each metric we show the respective parameters for inter layer edge weight and the threshold r for edge remotion
the anti redundancy detection ard method that obtained the best result is also shown
meas
dg sp w gaccess pr stg w sp sym access meas
w gaccess dg stg sp access sp w sym



















r





r





ard









ard









layer edges seems to be dependent on the dataset language and metric used to rank sentences
this was clear when we observed that both scenarios and are possible even when considering the same language
while such a multilayer representation has been implicitly used in some textual contexts no discrimination between and inter layer edges has been considered for summary generation
given the eectiveness of the adopted representation to optimize the performance obtained by network measurements we believe that it could be considered in other related applications where and relationships are relevant
this is the case e

of applications related to text mining and identication of key concepts in scientic areas
this study focused on the evaluation of multilayer based network approaches for mds
even though we aimed at studying the relevance of discriminating and inter layer edges in multilayer networks it is still interesting to compare the eciency of statistical approaches such as the one evaluated in the current study and other approaches dependent upon more informed linguistic data
for comparison purposes we show in table a set of other works that achieved the best results for the corpus we used
for portuguese mds the works are gistsumm bushypath and path systems and cstsumm which follows a strategy based on cross document structure theory
in the case of english mds we considered the following works duc best which is the system with highest rouge scores for duc conferences bstm which uses a bayesian sentence based topic model for summarization fgb which proposes a new language model to simultaneously cluster and summarize the documents and lexpr which constructs a sentence connectivity graph based on cosine similarity and selects important sentences based on the eigenvector centrality
considering the portuguese language the multilayer approach outperformed several other statistical methods
the best result was obtained however with the gistsumm technique which considers more linguistic and semantical information than the multilayer approach
for both english corpora linguistic dependent approaches outperformed the method based on multilayers
however in the dataset only a minor dierence between the multilayer and other methods was observed
table list of works for portuguese and english mds with the respective average recall scores
the best results of the multilayer approach evaluated in this work are highlighted
cstnews system gistsumm multilayer bushypath path cstsumm system
duc best
bstm


multilayer fgb lexpr system bstm

fgb
duc best
lexpr
multilayer






correlation analysis in figure we show the spearman rank correlation coecient observed for both cstnews left and right corpora
for the cstnews case in general the correlation are not strong which means that the metrics are not equivalent in the summarization task
the highest correlation however occurs for the pair weighted pagerank and absorption time
such a similarity might occur because both measurements are based on the behavior of a random walk dynamics
for the corpora the correlations are even lower conrming thus an absence of correspondence among the adopted network metrics
low values of spearman rank correlation coecient were also observed in the corpus see figure
the complimentary role played by the metrics in the adopted multilayer networks suggests that such metrics could be combined e

in a voting system to improve the performance of extractive summarizers
most importantly the dierentiation of edge types in characterizing collections of documents should be taken into account whenever semantical links are at the core of the target task or investigation
figure spearman rank correlation coecients for the considered network measurements considering both cstnews left and
note that in general there is a weak correlation between the adopted measurements
the strongest correlation occurs for the pair weighted pagerank and absorption time for the portuguese corpus

conclusion in this paper we evaluated the eciency of a multilayered approach for the extractive summarization problem
several interesting ndings were observed when applying such a simple model to a set of portuguese and english texts
we found that the performance observed is increased when and inter layer edges are considered with distinct relevance
for the portuguese case for most of the measurements the best performance was obtained when inter document relationships are strenghtened
conversely for the english case both and inter layer edges yielded the best results
concerning the metrics excellent performance was obtained for the degree portuguese weighted pagerank english and the generalized acessibility for both portuguese and english
dierently from previous results obtained for network based single document summarization we found no strong correlation among the adopted measurements
given the complimentary role played by the metrics this study could be extended in order to consider acombination of metrics to improve the performance of the systems
the adopted model could also be extended in future works by using the concept of word embeddings to enhance the representation of sentences
finally future works could combine traditional document summarization techniques and layered network representations
such a combination can be created e

by combining network concepts and linguistic features such as sentence length number of proper nouns and sentence location via machine







learning or hybrid classiers
acknowledgments j
v
t
acknowledges nancial support from cnpq brazil
d
r
a
thanks sao paulo research tion fapesp grant no
for the nancial support
references
c
d
manning h
schutze foundations of statistical natural language processing mit press cambridge ma usa z

gao y

yang p

fang y
zou c

xia m
du multiscale complex network for analyzing experimental multivariate time series epl europhysics letters
r
ferreira l
de souza cabral r
d
lins g
p
silva f
freitas g
d
c
cavalcanti r
lima s
j
simske l
favaro assessing sentence scoring techniques for extractive text summarization expert syst
appl

a
nenkova s
maskey y
liu automatic summarization in proceedings of the annual meeting of the association for computational linguistics tutorial abstracts of acl hlt association for computational linguistics d
yu w
wang s
zhang w
zhang r
liu hybrid self optimized clustering model based on citation links and textual features to detect research topics plos one
f
n
silva d
r
amancio m
bardosova l
f
costa o
n
oliveira jr
using network science and text analytics to produce surveys in a scientic topic journal of informetrics
m
p
viana d
r
amancio l
f
costa on time varying collaboration networks journal of informetrics pp


c
chen the centrality of pivotal points in the evolution of scientic networks in proceedings of the international conference on intelligent user interfaces iui acm new york ny usa pp

d
r
amancio o
n
oliveira jr
l
f
costa structure semantics interplay in complex networks and its eects on the predictability of similarity in texts physica a statistical mechanics and its applications
a
mehri a
h
darooneh a
shariati the complex networks approach for authorship attribution of books physica a statistical mechanics and its applications
d
r
amancio authorship recognition via uctuation analysis of network topology and word intermittency journal of statistical mechanics theory and experiment
d
r
amancio a complex network approach to stylometry plos one
e
agirre a
soroa personalizing pagerank for word sense disambiguation in proceedings of the conference of the european chapter of the association for computational linguistics eacl association for computational linguistics t
c
silva d
r
amancio word sense disambiguation via high order of learning in complex networks epl europhysics stroudsburg pa usa pp

letters
s
yu h
liu c
xu statistical properties of chinese phonemic networks physica a statistical mechanics and its h
liu the complexity of chinese syntactic dependency networks physica a statistical mechanics and its applications l
antiqueira o
n
oliveira jr
l
f
costa m
g
v
nunes a complex network approach to text summarization inf
applications

sci

r
ribaldo a
t
akabane l
h
m
rino t
a
s
pardo graph based methods for multi document summarization exploring relationship maps complex networks and discourse information in computational processing of the portuguese language vol
springer berlin heidelberg pp

d
r
amancio m
g
nunes o
n
oliveira jr
l
f
costa extractive summarization using complex networks and syntactic dependency physica a statistical mechanics and its applications
d
s
leite l
h
rino combining multiple features for automatic text summarization through machine learning in proceedings of the international conference on computational processing of the portuguese language g
erkan d
r
radev lexrank graph based lexical centrality as salience in text summarization j
artif
int
res
verlag pp


r
mihalcea language independent extractive summarization in proceedings of the acl on interactive poster and demonstration sessions association for computational linguistics pp

l
page s
brin r
motwani t
winograd the pagerank citation ranking bringing order to the web in proceedings of the international world wide web conference pp

j
m
kleinberg authoritative sources in a hyperlinked environment j
acm
p
over w
liggett introduction to duc an intrinsic evaluation of generic news text summarization systems
o
paul y
james an introduction to in proceedings of the document understanding conference duc

s
robertson understanding inverse document frequency on theoretical arguments for idf journal of documentation d
padmanabhan p
desikan j
srivastava k
riaz wicer a weighted inter cluster edge ranking for clustered graphs in proceedings of the ieee wic acm international conference on web intelligence wi ieee computer f
wei w
li q
lu y
he a document sensitive graph model for multi document summarization knowledge and society washington dc usa pp

information systems
d
ramage a
n
raerty c
d
manning random walks for text semantic similarity in proceedings of the workshop on graph based methods for natural language processing association for computational linguistics stroudsburg pa usa pp

n
masuda m
a
porter r
lambiotte random walks and diusion on networks physics reports
d
r
amancio e
g
altmann o
n
oliveira jr
l
f
costa comparing intermittency and network measurements of words and their dependence on authorship new journal of physics
b
travencolo l
f
costa accessibility in complex networks physics letters a
d
r
amancio f
n
silva l
f
costa concentric network symmetry grasps authors styles in word adjacency networks epl europhysics letters
d
r
amancio o
n
oliveira jr
l
f
costa on the concepts of complex networks to quantify the diculty in nding the way out of labyrinths physica a statistical mechanics and its applications
r
gaizauskas h
saggion multi document summarization by cluster prole relevance and redundancy removal in proceedings of the hlt naacl document understanding workshop pp

c

lin rouge a package for automatic evaluation of summaries in proc
acl workshop on text summarization branches out p

d
r
radev a common theory of information fusion from multiple text sources step one cross document structure in proceedings of the sigdial workshop on discourse and dialogue volume sigdial association for computational linguistics stroudsburg pa usa pp

d
wang s
zhu t
li y
gong multi document summarization using sentence based topic models in proceedings of the acl ijcnlp conference short papers association for computational linguistics pp

d
wang s
zhu t
li y
chi y
gong integrating clustering and multi document summarization to improve document understanding in proceedings of the acm conference on information and knowledge management acm pp

g
erkan d
r
radev lexpagerank prestige in multi document text summarization in d
lin d
wu eds
ceedings of emnlp association for computational linguistics barcelona spain pp

t
mikolov i
sutskever k
chen g
corrado j
dean distributed representations of words and phrases and their compositionality arxiv e prints

