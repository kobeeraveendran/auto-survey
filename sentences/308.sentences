understanding points of correspondence between sentences for abstractive summarization logan lebanoff john muchovej franck dernoncourt doo soon lidan wang walter chang fei liu university of central florida loganlebanoff john

ucf
edu adobe research
ucf
edu dernonco dkim lidwang
com abstract source sentences fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries
such a simple task for humans has remained ing for modern abstractive summarizers stantially restricting their applicability in world scenarios
in this paper we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence which are cohesive devices that tie any two sentences together into a herent text
the types of points of dence are delineated by text cohesion theory covering pronominal and nominal referencing repetition and beyond
we create a dataset taining the documents source and fusion tences and human annotations of points of respondence between sentences
our dataset bridges the gap between coreference tion and summarization
it is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems
introduction stitching portions of text together into a sentence is a crucial rst step in abstractive summarization
it involves choosing which sentences to fuse what content from each of them to retain and how best to present that information elsner and santhanam
a major challenge in fusing sentences is to establish correspondence between sentences
if there exists no correspondence it would be cult if not impossible to fuse sentences
in table we present example source and fusion sentences where the summarizer attempts to merge two tences into a summary sentence with improper use of points of correspondence
in this paper we seek to uncover hidden correspondences between
com points of correspondence robert downey jr
is making headlines for walking out of an interview with a british journalist who dared to veer away from the superhero movie downey was there to promote
the journalist instead started asking personal questions about the actor s political beliefs and dark periods of addiction and jail time
robert downey jr started asking personal questions about the actor s political beliefs
source sentences real housewives of beverly hills star and former child actress kim richards is accused of kicking a police ofcer after being arrested thursday morning
a police representative said richards was asked to leave but refused and then entered a restroom and would nt come out
kim richards is accused of kicking a police ofcer who refused to leave
source sentences the kind of horror represented by the blackwater case and others like it


may be largely absent from public memory in the west these days but it is being used by the islamic state in iraq and syria isis to support its sectarian narrative
in its propaganda isis has been using abu ghraib and other cases of western abuse to legitimize its current actions


in its propaganda isis is being used by the islamic state in iraq and syria
table unfaithful summary sentences generated by neural abstractive summarizers in house and pg see et al

they attempt to merge two sentences into one sentence with improper use of points of dence between sentences yielding nonsensical output
summaries are manually re cased for readability
tences which has a great potential for improving content selection and deep sentence fusion
sentence fusion or multi sentence compression plays a prominent role in automated summarization and its importance has long been recognized lay et al

early attempts to fuse sentences build a dependency graph from sentences then code a tree from the graph using integer linear gramming nally linearize the tree to generate a summary sentence barzilay and mckeown filippova and strube thadani and own
despite valuable insights gained from n u j l c
s c v
v i x r a poc type source sentences summary sentence pronominal referencing nominal referencing the bodies showed signs of torture
they were left on the side of a highway in chilpancingo about an hour north of the tourist resort of acapulco in the state of guerrero
bahamian singer johnny kemp best known for the party anthem just got paid died this week in jamaica
the singer is believed to have drowned at a beach in montego bay on thursday the jamaica constabulatory force said in a press release
the bodies of the men which showed signs of torture were left on the side of a highway in chilpancingo
johnny kemp is believed to have drowned at a beach in montego bay police say
repetition common noun a nurse confessed to killing ve women and one man at hospital
a former nurse in the czech republic murdered six of her elderly referencing patients with massive doses of potassium in order to ease her workload
stewart said that she and her husband joseph naaman booked felix on their ight from the united arab emirates to new york on april
the couple said they spent to ship felix on the hour ight
four employees of the store have been arrested but its manager was still at large said goa police superintendent kartik kashyap
if convicted they could spend up to three years in jail kashyap said
event triggers the nurse who has been dubbed nurse death locally has admitted killing the victims with massive doses of potassium
couple spends to ship their cat felix on a ight from the united arab emirates
the four store workers arrested could spend years each in prison if convicted
table types of sentence correspondences
text cohesion can manifest itself in different forms
these attempts experiments are often performed on small datasets and systems are designed to merge sentences conveying similar information
less humans do not restrict themselves to combine similar sentences but also disparate sentences taining fundamentally different content but remain related to make fusion sensible elsner and thanam
we focus specically on analyzing fusion of disparate sentences which is a distinct problem from fusing a set of similar sentences
while fusing disparate sentences is a seemingly simple task for humans to do it has remained lenging for modern abstractive summarizers see et al
celikyilmaz et al
chen and bansal liu and lapata
these tems learn to perform content selection and tion through end to end learning
however such a strategy is not consistently effective and they gle to reliably perform sentence fusion falke et al
kryscinski et al

e

only of summary sentences generated by pointer generator networks see et al
are fusion sentences the ratio for human abstracts is much higher
further lebanoff et al
report that of fusion sentences contain incorrect facts
there ists a pressing need for and this paper contributes to broadening the understanding of points of respondence used for sentence fusion
we present the rst attempt to construct a able sentence fusion dataset where an instance in the dataset consists of a pair of input sentences a fusion sentence and human annotated points of correspondence between sentences
distinguishing our work from previous efforts geva et al
our input contains disparate sentences and output is a fusion sentence containing important though not equivalent information of the input sentences
our investigation is inspired by halliday and hasan s theory of text cohesion that covers a broad range of points of correspondence including tity and event coreference ng lu and ng shared words concepts between sentences and more
our contributions are as follows
we describe the rst effort at establishing points of correspondence between disparate sentences
without a clear understanding of points of spondence sentence fusion remains a daunting challenge that is only sparsely and sometimes correctly performed by abstractive summarizers
we present a sizable dataset for sentence fusion containing human annotated corresponding gions between pairs of sentences
it can be used as a testbed for evaluating the ability of rization models to perform sentence fusion
we report on the insights gained from annotations to suggest important future directions for sentence fusion
our dataset is released publicly
annotating points of correspondence we cast sentence fusion as a constrained rization task where portions of text are selected from each source sentence and stitched together to form a fusion sentence rephrasing and reordering are allowed in this process
we propose guidelines for annotating points of correspondence poc tween sentences based on halliday and hasan s theory of cohesion
we consider points of correspondence as sive phrases that tie sentences together into a ent text
guided by text cohesion theory we gorize poc into ve types including pronominal referencing they nominal referencing johnny kemp common noun referencing ve women figure an illustration of the annotation interface
a human annotator is asked to highlight text spans ring to the same entity then choose one from the ve pre dened poc types
repetition and event trigger words that are related in meaning died and drowned
an illustration of poc types is provided in table
our rization emphasizes the lexical linking that holds a text together and gives it meaning
a human annotator is instructed to identify a text span from each of the source sentences and mary sentence thus establishing a point of spondence between source sentences and between source and summary sentences
as our goal is to understand the role of poc in sentence fusion we do not consider the case if poc is only found in source sentences but not summary sentence e

kashyap said and said goa police dent kartik kashyap in table
if multiple poc co exist in an example an annotator is expected to label them all a separate poc type will be signed to each poc occurrence
we are particularly interested in annotating inter sentence poc
if tity mentions john and he are found in the same sentence we do not explicitly label them but assume such intra sentence referencing can be tured by an existing coreference resolver
instances of source sentences and summary sentences are obtained from the test and validation splits of the cnn dailymail see et al
following the procedure described by lebanoff et al

we take a human summary sentence as an anchor point to nd two document sentences that are most similar to it based on rouge
it becomes an stance containing a pair of source sentences and their summary
the method allows us to identify a large quantity of candidate fusion instances
annotations are performed in two stages
stage one removes all spurious pairs that are generated by the heuristic i
e
a summary sentence that is not a valid fusion of the corresponding two source sentences
human annotators are given a pair of sentences and a summary sentence and are asked figure statistics of poc occurrences and types
whether it represents a valid fusion
the pairs tied as valid fusions by a majority of annotators move on to stage two
stage two identies the responding regions in the sentences
as shown in figure annotators are given a pair of sentences and their summary and are tasked with highlighting the corresponding regions between each sentence
they must also choose one of the ve poc types repetition pronominal nominal common noun referencing and event triggers for the set of sponding regions
we use amazon mechanical turk allowing only workers with approval rate and at least accepted tasks
to ensure high quality annotations we rst run a qualication round of tasks
ers performing sufciently on these tasks were lowed to annotate the whole dataset
for task one instances were evaluated and of them were ltered out
in total we annotate points of correspondence for instances taken from documents
similar to hardy et al
we report fleiss kappa judged on each word lighted or not yielding substantial inter annotator agreement
for annotating points of spondence
we include a reference to the original article that each instance was taken from thus viding context for each instance
figure shows statistics of poc occurrence quencies and the distribution of different poc types
a majority of sentence pairs have one or two points of correspondence
only a small percentage
do not share a poc
a qualitatively analysis shows that these sentences often have an implicit course relationship e

the two men speak
scott then gets out of the car again and runs away
in this example there is no clear portion of text that is shared between the sentences rather the tion lies in the fact that one event happens after the other
most of the poc are a avor of coreference pronominal nominal or common noun
few are exact repetition
further we nd that only of points of correspondence in the sentence pair share number of poc per fusion instance distribution of poc by type pronominal nominal common noun repetition event triggers coref resolver pronominal nominal comm
repetition event trig
spacy allennlp stanford corenlp























table results of various coreference resolvers on successfully identifying inter sentence points of dence poc and recall scores of these resolvers split by poc correspondence type
any words lemmatized
this makes identifying them automatically challenging requiring a deeper understanding of what connects the two sentences
resolving coreference coreference resolution ng is similar to the task of identifying points of correspondence
thus a natural question we ask is how well state of art coreference resolvers can be adapted to this task
if coreference resolvers can perform reasonably well on poc identication then these resolvers can be used to extract poc annotations to potentially enhance sentence fusion
if they perform poorly coreference performance results can indicate areas of improvement for future work on detecting points of correspondence
in this paper we compare three coreference resolvers on our dataset provided by open source libraries stanford corenlp ning et al
spacy honnibal and montani and allennlp gardner et al

we base our evaluation on the standard metric used for coreference resolution b cubed rithm bagga and baldwin with some ications
each resolver is run on an input pair of sentences to obtain multiple clusters each resenting an entity e

johnny kemp ing multiple mentions e

johnny kemp he the singer of that entity
more than one cluster can be detected by the coreference resolver as additional entities may exist in the given sentence pair e

johnny kemp and the police
similarly in tion human annotators identied multiple poc clusters each representing a point of dence containing one mention from each sentence
we evaluate how well the resolver detected ters compare to the human detected clusters i
e
pocs
if a resolver cluster overlaps both mentions for the gold standard poc then this resolver cluster is classied as a hit
any resolver cluster that does not overlap both poc mentions is a miss
using this metric we can calculate precision recall and scores based on correctly incorrectly identied tokens from the outputs of each resolver
the results are presented in table
the three solvers exhibit similar performance but the scores on identifying points of correspondence are less than satisfying
the spacy resolver has the highest precision
and stanford corenlp achieves the highest score

we observe that isting coreference resolvers can sometimes struggle to use the high level reasoning that humans use to determine what connects two sentences together
next we go deeper into understanding what poc types these resolvers struggle with
we present the recall scores of these resolvers split by poc spondence type
event coreference poses the most difculty by far which is understandable as ence resolution only focuses on entities rather than events
more work into detecting event coreference can bring signicant improvements in poc cation
common noun coreference also poses a challenge in part because names and pronouns give strong clues as to the relationships between tions while common noun relationships are more difcult to identify since they lack these clues
sentence fusion truly effective summarization will only be able when systems have the ability to fully nize points of correspondence between sentences
it remains to be seen whether such knowledge can be acquired implicitly by neural abstractive tems through joint content selection and generation
we next conduct an initial study to assess neural abstractive summarizers on their ability to perform sentence fusion to merge two sentences into a mary sentence
the task represents an important atomic unit of abstractive summarization because a long summary is still generated one sentence at a time lebanoff et al

we compare two best performing abstractive summarizers pointer generator uses an decoder architecture with attention and copy anism see et al
transformer adopts a decoder only transformer architecture similar to that of radford et al
where a summary is system r l fuse related work concat baseline pointer generator transformer











table rouge scores of neural abstractive rizers on the sentence fusion dataset
we also report the percentage of output sentences that are indeed sion sentences fuse decoded one word at a time conditioned on source sentences and the previously generated summary words
we use the same number of heads layers and units per layer as bert base devlin et al

in both cases the summarizer was trained on about instances derived from the train split of cnn dailymail using the same heuristic as described in without poc annotations
the summarizer is then tested on our dataset of fusion instances and evaluated using standard rics lin
we also report how often each summarizer actually draws content from both tences fuse rather than taking content from only one sentence
a generated sentence counts as a fusion if it contains at least two non stopword kens from each sentence not already present in the other sentence
additionally we include a baseline creating a fusion sentence by simply catenating the two source sentences
the results according to the rouge evaluation lin are presented in table
sentence sion appears to be a challenging task even for ern abstractive summarizers
pointer generator has been shown to perform strongly on abstractive marization but it is less so on sentence fusion and in other highly abstractive settings narayan et al

transformer signicantly outperforms other methods in line with previous ndings liu et al

we qualitatively examine system outputs
table presents fusions generated by these els and exemplies the need for infusing models with knowledge of points of correspondence
in the rst example pointer generator incorrectly ates robert downey jr
with the journalist asking questions
similarly in the second example former states the police ofcer refused to leave when it was actually richards
had the models explicitly recognized the points of correspondence in the sentences that the journalist is a separate entity from robert downey jr
and that richards is separate from police ofcer then a more accurate summary could have been generated
uncovering hidden correspondences between tences is essential for producing proper summary sentences
a number of recent efforts select tant words and sentences from a given document then let the summarizer attend to selected content to generate a summary gehrmann et al
hsu et al
chen and bansal putra et al
lebanoff et al
liu and lapata
these systems are largely agnostic to sentence respondences which can have two undesirable sequences
if only a single sentence is selected it can be impossible for the summarizer to produce a fusion sentence from it
moreover if non fusible textual units are selected the summarizer is forced to fuse them into a summary sentence yielding put summaries that often fail to keep the original meaning intact
therefore in this paper we had vestigated the correspondences between sentences to gain an understanding of sentence fusion
establishing correspondence between sentences goes beyond nding common words
humans can fuse sentences sharing few or no common words if they can nd other types of correspondence
fusing such disparate sentences poses a serious challenge for automated fusion systems marsi and krahmer filippova and strube mckeown et al
elsner and santhanam thadani and mckeown mehdad et al
nayeem et al

these systems rely on common words to derive a connected graph from input sentences or subject verb object triples moryossef et al

when there are no common words in sentences systems tend to break apart
there has been a lack of annotated datasets and guidelines for sentence fusion
few studies have vestigated the types of correspondence between sentences such as entity and event coreference
evaluating sentence fusion systems requires not only novel metrics zhao et al
zhang et al
durmus et al
wang et al
but also high quality ground truth annotations
it is therefore necessary to conduct a rst study to look into cues humans use to establish correspondence between disparate sentences
we envision sentence correspondence to be lated to text cohesion and coherence which help tablish correspondences between two pieces of text
halliday and hasan describe text cohesion as cohesive devices that tie two textual elements together
they identify ve categories of cohesion mckeown et al
palin actually turned against the bridge project only after it became a national symbol of wasteful spending
ms
palin supported the bridge project while running for governor and abandoned it after it became a national scandal
fusion palin turned against the bridge project after it became a tional scandal
discofuse geva et al
melvyn douglas originally was signed to play sam bailey
the role ultimately went to walter pidgeon
fusion melvyn douglas originally was signed to play sam bailey but the role ultimately went to walter pidgeon
points of correspondence dataset our work the bodies showed signs of torture
they were left on the side of a highway in chilpancingo about an hour north of the tourist resort of acapulco in the state of guerrero
fusion the bodies of the men which showed signs of torture were left on the side of a highway in chilpancingo
human annotations of points of correspondence tween sentences
the dataset lls a notable gap of coreference resolution and summarization research
our ndings shed light on the importance of ing points of correspondence suggesting important future directions for sentence fusion
acknowledgments we are grateful to the anonymous reviewers for their helpful comments and suggestions
this search was supported in part by the national ence foundation grant
table comparison of sentence fusion datasets
references reference lexical cohesion ellipsis substitution and conjunction
in contrast coherence is dened in terms of discourse relations between textual ments such as elaboration cause or explanation
previous work studied discourse relations geva et al
this paper instead focuses on text hesion which plays a crucial role in generating proper fusion sentences
our dataset contains pairs of source and fusion sentences collected from news editors in a natural environment
the work is ticularly meaningful to text to text and data to text generation gatt and krahmer that demand robust modules to merge disparate content
we contrast our dataset with previous sentence fusion datasets
mckeown et al
compile a corpus of sentence fusions as a rst step toward a supervised fusion system
however the input sentences have very similar meaning though they often present lexical variations and different details
in contrast our proposed dataset seeks to fuse signicantly different meanings together into a single sentence
a large scale dataset of sentence fusions has been recently collected geva et al
where each sentence has disparate content and are connected by various discourse connectives
this paper instead focuses on text cohesion and on fusing only the salient information which are both vital for abstractive summarization
examples are presented in table
conclusion in this paper we describe a rst effort at annotating points of correspondence between disparate tences
we present a benchmark dataset comprised of the documents source and fusion sentences and amit bagga and breck baldwin

algorithms for scoring coreference chains
in the rst tional conference on language resources and tion workshop on linguistics coreference volume pages
granada
regina barzilay and kathleen r
mckeown

sentence fusion for multidocument news rization
computational linguistics
regina barzilay kathleen r
mckeown and michael elhadad

information fusion in the context of multi document summarization
in proceedings of the annual meeting of the association for tional linguistics acl
asli celikyilmaz antoine bosselut xiaodong he and yejin choi

deep communicating agents for in proceedings of the abstractive summarization
north american chapter of the association for putational linguistics naacl
yen chun chen and mohit bansal

fast stractive summarization with reinforce selected tence rewriting
in proceedings of the annual ing of the association for computational linguistics acl
jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language standing


esin durmus he he and mona diab

feqa a question answering evaluation framework for fulness assessment in abstractive summarization
in proceedings of the annual conference of the ation for computational linguistics acl
micha elsner and deepak santhanam

learning to fuse disparate sentences
in proceedings of acl workshop on monolingual text to text generation
tobias falke leonardo f
r
ribeiro prasetya ajie ido dagan and iryna gurevych

utama ranking generated summaries by correctness an teresting but challenging application for natural guage inference
in proceedings of the annual ing of the association for computational linguistics acl
katja filippova and michael strube

sentence fusion via dependency graph compression
in ceedings of the conference on empirical methods in natural language processing emnlp
matt gardner joel grus mark neumann oyvind tafjord pradeep dasigi nelson f
liu matthew peters michael schmitz and luke s
zettlemoyer

allennlp a deep semantic natural language processing platform
albert gatt and emiel krahmer

survey of the state of the art in natural language generation core tasks applications and evaluation
journal of cial intelligence research
sebastian gehrmann yuntian deng and alexander m
rush

bottom up abstractive tion
in proceedings of the conference on empirical methods in natural language processing emnlp
mor geva eric malmi idan szpektor and jonathan berant

discofuse a large scale dataset for discourse based sentence fusion
in proceedings of the north american chapter of the association for computational linguistics naacl
michael a
k
halliday and ruqaiya hasan

hesion in english
english language series
man group ltd
emnlp workshop on new frontiers in marization
logan lebanoff kaiqiang song franck dernoncourt doo soon kim seokhwan kim walter chang and fei liu

scoring sentence singletons and pairs for abstractive summarization
in proceedings of the annual meeting of the association for tational linguistics acl
logan lebanoff kaiqiang song and fei liu

adapting the neural encoder decoder framework from single to multi document summarization
in proceedings of the conference on empirical ods in natural language processing emnlp
chin yew lin

rouge a package for in proceedings tomatic evaluation of summaries
of acl workshop on text summarization branches out
peter j liu mohammad saleh etienne pot ben goodrich ryan sepassi ukasz kaiser and noam shazeer

generating wikipedia by in sixth international ing long sequences
ence on learning representations iclr
yang liu and mirella lapata

hierarchical formers for multi document summarization
in ceedings of the annual meeting of the association for computational linguistics acl
jing lu and vincent ng

event coreference lution a survey of two decades of research
in ceedings of the international joint conference on articial intelligence ijcai
hardy hardy shashi narayan and andreas vlachos

highres highlight based reference less evaluation of summarization
in proceedings of the annual meeting of the association for putational linguistics pages florence italy
association for computational linguistics
christopher d
manning mihai surdeanu john bauer jenny finkel steven j
bethard and david closky

the stanford corenlp natural guage processing toolkit
in association for tational linguistics acl system demonstrations pages
matthew honnibal and ines montani

natural language understanding with bloom dings convolutional neural networks and tal parsing
to appear
erwin marsi and emiel krahmer

explorations in sentence fusion
in proceedings of the acl shop on computational approaches to semitic guages
wan ting hsu chieh kai lin ming ying lee kerui min jing tang and min sun

a unied model for extractive and abstractive summarization using inconsistency loss
in proceedings of the nual meeting of the association for computational linguistics acl
wojciech kryscinski nitish shirish keskar bryan cann caiming xiong and richard socher

neural text summarization a critical evaluation
in proceedings of the conference on empirical ods in natural language processing emnlp
logan lebanoff john muchovej franck dernoncourt doo soon kim seokhwan kim walter chang and fei liu

analyzing sentence fusion in in proceedings fo the stractive summarization
kathleen mckeown sara rosenthal kapil thadani and coleman moore

time efcient creation of an accurate sentence fusion
in ings of the north american chapter of the tion for computational linguistics naacl
yashar mehdad giuseppe carenini frank w
tompa and raymond t
ng

abstractive meeting summarization with entailment and fusion
in ceedings of the european workshop on natural language generation
amit moryossef yoav goldberg and ido dagan

step by step separating planning from realization in neural data to text generation
in proceedings of the north american chapter of the association for computational linguistics naacl
shashi narayan shay b
cohen and mirella lapata

do nt give me the details just the summary topic aware convolutional neural networks for in proceedings of the treme summarization
conference on empirical methods in natural guage processing pages brussels gium
association for computational linguistics
mir tafseer nayeem tanvir ahmed fuad and lias chali

abstractive unsupervised document summarization using paraphrastic in proceedings of the international tence fusion
conference on computational linguistics ing
vincent ng

machine learning for entity ence resolution a retrospective look at two decades of research
in proceedngs of the thirty first aaai conference on articial intelligence aaai
jan wira gotama putra hayato kobayashi and incorporating topic nobuyuki shimizu

tence on neural news headline generation
alec radford jeffrey wu rewon child david luan dario amodei and ilya sutskever

language models are unsupervised multitask learners
abigail see peter j
liu and christopher d
manning

get to the point summarization with in proceedings of the annual generator networks
meeting of the association for computational guistics acl
kapil thadani and kathleen mckeown

tence compression with joint structural inference
in proceedings of conll
kapil thadani and kathleen mckeown

vised sentence fusion with single stage inference
in proceedings of the international joint conference on natural language processing ijcnlp
alex wang kyunghyun cho and mike lewis

asking and answering questions to evaluate the in proceedings of tual consistency of summaries
the annual conference of the association for putational linguistics acl
tianyi zhang varsha kishore felix wu kilian q
weinberger and yoav artzi

bertscore in international uating text generation with bert
conference on learning representations
wei zhao maxime peyrard fei liu yang gao tian m
meyer and steffen eger

moverscore text generation evaluating with contextualized beddings and earth mover distance
in proceedings of the conference on empirical methods in natural language processing and the tional joint conference on natural language cessing emnlp ijcnlp pages hong kong china
association for computational guistics

