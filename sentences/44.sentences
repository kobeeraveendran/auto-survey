international journal of computer applications volume no
may keyphrase based evaluation of automatic text summarization fatma elghannam electronics research institute cairo egypt tarek el shishtawy faculty of computers and information benha university benha egypt abstract the development of methods to deal with the informative contents of the text units in the matching process is a major challenge in automatic summary evaluation systems that use fixed n gram matching
the limitation causes inaccurate matching between units in a peer and reference summaries
the present study introduces a new keyphrase based summary evaluator kpeval for evaluating automatic summaries
the kpeval relies on the keyphrases since they convey the most important concepts of a text
in the evaluation process the keyphrases are used in their lemma form as the matching text unit
the system was applied to evaluate different summaries of arabic multi document data set presented at
the results showed that the new evaluation the known technique correlates well with evaluation systems rouge and autosummeng memog
kpeval strongest correlation with memog pearson and spearman correlation coefficient measures are

respectively
has the general terms automatic summary evaluation automatic summarization processing language extraction natural keyphrase computational linguistics information retrieval
keywords evaluating automatic text summarization keyphrase based summary evaluation summarization keyphrase extraction arabic summary evaluation

introduction evaluation of automatic text summarization systems using human evaluators requires expensive human efforts
this hard expensive effort has held up researchers looking for methods to evaluate summaries automatically
current automated methods compare fragments of the summary to be assessed against one or more reference summaries typically produced by humans measuring how much fragments in the reference summary is present in the generated summary
one method is to consider the sentence as the fragment text unit in the evaluation process but the problem is those sentences contain many individual pieces of information which may not be used by humans for reference summaries
choosing an appropriate fragment length and comparing it appropriately is a critical problem in the evaluation process
the problem is to extract the matching units that express the informative contents of a text
the misleading in choosing the informative content of a text leads to unfortunate matching between two pieces of text in a peer and reference summaries
based on the intuition that the keyphrases represent the most important concepts of the text we propose a keyphrase based summary evaluator kpeval for evaluating document summarization systems considering the keyphrase as the matching text unit for the evaluation process
ii keyphrase extractor kpeval idea is to count the matches between the peer summary and reference summaries for the essential parts of the summary text
kpeval have three main modules lemma extractor module that breaks the text into words and extracts their lemma forms and the associated lexical and syntactic features that extracts important keyphrases in their lemma forms and iii the evaluator that scoring the summary based on counting the matched keyphrases occur between the peer summary and one or more reference summaries
the remaining of this paper is organized as follows section reviews the previous works section the proposed keyphrase based summary evaluator section discusses the performance evaluation and section is the conclusion

previous works evaluating summaries and automatic text summarization systems is not a straightforward process
evaluation of automatic text summarization systems can be extrinsic or intrinsic evaluation methods
in extrinsic evaluation the summary quality is judged on the basis of how helpful summaries are for a given task
intrinsic evaluation has mainly focused on the informativeness and coherence of summaries
this is often done by comparing the peer summary to reference human summary
many systems have been developed for automatic evaluation of the summary systems
bleu bilingual evaluation understudy is an gram precision based evaluator metric initially designed for the evaluation of machine translation
the main idea of bleu is to measure the translation closeness between a candidate translation and a set of reference translations with a numerical metric
they use a weighted average of variable length gram matches between system translations and a set of human reference translations
lin al
have applied the same idea of bleu to the evaluation of summaries
they used automatically computed accumulative n gram matching scores between peer summaries and reference summaries as a performance indicator
rouge stands for oriented understudy for gisting evaluation is a recall measure that counts the number of overlapping n gram units between the peer summary generated by computer and several reference summaries
rouge has proved to be a successful algorithm
several variants of the measure were introduced such as rouge n rouge s and rouge su
rouge n is an n gram recall between a candidate summary and a set of reference summaries
rouge s is skip bigram occurrence statistics
skip bigram is any pair of words in their sentence order allowing for arbitrary gaps
rouge s measures the overlap ratio of skip bigrams between a candidate summary and a set of reference summaries
one potential problem for rouge s is that it does not give any credit to a candidate sentence if the sentence does not have any word pair co occurring with its references
the problem is solved by extending rouge s with the addition of unigram as counting unit
the extended version is called rouge su
memog memog is a summarization evaluation method that evaluates summaries by extracting and comparing graphs of character n grams between the generated and model summaries
hovy al
developed be method be is a very small syntactic unit of content
they defined be as the head of a major syntactic constituent noun verb adjective or adverbial phrases expressed as a single item or ii a relation between a head be and a single dependent expressed as a triple head modifier relation
their idea is to decompose reference and system summaries to lists of bes units and then compare the two lists to obtain a similarity score
they include a syntactic parser to produce a parse tree and a set of cutting rules to extract just the valid bes from the tree
a modified version of be is bewt e uses a set of transformations to match lexically different bes that convey similar semantic content

keyphrase based summary evaluator a problem with methods using fixed n gram matching is that they rely only on surface level features and the nonexistence of deep features that express the informative contents of the matching units
neglecting the linguistic features in the matching units misleads the matching process
we define two major types of errors that can occur between the matched units in a peer and reference summaries under matching where non identical form units that cover the same concept are considered as unmatched units
this problem can occur at any of the nlp levels lexical syntactic and semantic
for example the units stages of education education stages education levels convey the same concepts but with different synonyms
recognizing this problem needs different nlp analysis levels
structure or syntactic over matching where the matched units does not reflect a real agreement in the concept between the peer summary and reference summary
for example matching the word big that exists in two different phrases in peer and reference summary like big factories and big fish is unfair as there is no real concept agreement
the most that keyphrases represent regarding this problem attention must be paid to the informative content in the matching units
based on the intuition important concepts of the text in the proposed kpeval keyphrases are considered as the matching units for the evaluation process
kpeval idea is to count the matches that occur between the peer summary and one or more reference summaries for the essential parts of the summary text keyphrases
we adopted the existing lemma based keyphrase extractor lbake module which is based on statistical techniques in addition to linguistic knowledge to extract the candidate keyphrases
kpeval technique starts by extracting the keyphrases for both the peer and reference summaries
for a peer summary the number of matched keyphrases that occur with those existing in the reference summaries are counted
precision recall and f measure are calculated to measure the peer summary performance

features of the keyphrase based summary evaluator kpeval is based on counting the matched keyphrases that occur between the peer and reference summaries
the important keyphrases are extracted based on statistical and linguistic features
the existing lbake module is adopted for this purpose
international journal of computer applications volume no
may syntactic rules are used to identify the most informative phrases in a summary
the matching process is applied to keyphrases represented in their lemma form
so different word forms that have the same meaning in a peer and reference summaries can be considered the same
this can be useful to overcome the lexical phase of the problem
for example a word can have different plural forms in arabic
so the lemma forms of the two phrases will be matched
to the best of our knowledge none of the existing summary evaluation systems support an arabic lemmatizer
hovy et al
extracts the basic elements be which are used in the matching based on the words syntactic feature
precision recall and f measure are used to evaluate the summary performance

steps of the keyphrase based summary evaluator kpeval process has the following steps
extract the indicative keyphrases at lemma level using lbake module for both of peer and reference human summaries

count the matched keyphrases lemma forms that occur between the peer summary and each one of the reference summaries

calculate precision recall and f measure to measure the peer summary performance


keyphrase extraction the first step is to pass the peer and reference summaries to the keyphrase extractor lbake module to extract the indicative keyphrases at lemma level
lbake is a supervised learning module for extracting keyphrases of single arabic document
it is based on three main steps linguistic processing candidate phrase extraction and feature vector calculation
it starts by breaking the text into words and extracting their lemma forms and the associated lexical and syntactic features using the arabic lemmatizer
and then the extractor extracts the keyphrases in their lemma form for both of the peer and reference summaries
the extractor is supplied with linguistic knowledge as well as statistical information
all possible phrases of one two or three consecutive words that appear in a given document are generated as n gram terms
these n gram words are accepted as a candidate keyphrases if they follow the following syntactic rules
the candidate phrase can start only with some sort of nouns provided that not to be an adjective like general noun defined noun undefined noun copulative noun and noun
the candidate phrase can end only with general noun place noun time noun augmented noun and adjective
declined noun proper noun for three words phrase the second word is allowed only to be a preposition in addition to those cited in rule
it is worthwhile to note that the rules applied are dependent and the given rules are applicable only to arabic language
the importance of a keyphrase within a document is evaluated based on eight features number of words in each phrase
frequency of the candidate phrase
frequency of the most frequent single word in a candidate phrase
location of document
location of the candidate phrase within its sentence
the phrase sentence within relative phrase length to its containing sentence
assessment of the phrase sentence verb content
assessment as to whether the phrase sentence is in the the form of a question
weights of these features were learned during building the classifier
the output of lbake is a set of keyphrases in their lemma form representing the input document
the following example shows the generated keyphrases for two phrases a and b that exist in a peer and reference summary the high institutions in the the high towers in the villages after applying the filtering syntactic rules the system will produce the n gram keyphrases as illustrated in table
table extracted keyphrases for the two phrases a
a villages kp kp accordingly only one matched keyphrase lemma form village occurs between the two phrases
we mentioned here that according to the previous syntactic rules units such as high high in the villages that occur on both of the two phrases are not extracted as keyphrases and consequently does not considered as an equivalent matched units
note that the word sequence in the adjective phrase in arabic is different from the english the noun comes first then followed by the adjective
on the other hand for an evaluation system that relies only on n gram matching the system would count as two extra matched units regardless the different tenor speech in the two phrases
using such syntactic in extracting keyphrases contributes well in assigning the most informative units and at the same time reduces improper matching that can be occur in the evaluation process
rules

precision recall and f measure calculation kpeval technique is based on evaluating precision recall and f measure between the peer and reference summaries using the extracted keyphrases
for a peer summary the number of overlapping keyphrases with each one of the reference summaries is calculated
precision p recall r and f measure are then evaluated using the following formulas international journal of computer applications volume no
may where is the number of keyphrases in their lemma form in the reference summaries and peer system summary respectively
is the maximum number of keyphrases co occurring in a peer summaries
summary reference and in is the number of reference summaries

performance evaluation to evaluate the performance of the proposed system we compared it against other standard systems
we apply kpeval to evaluate a set of different participating systems at tac multiling pilot and compare the evaluation results against the existing results of rouge and autosummeng memog evaluation scores

data set the well known tac multiling pilot is used the package contains all the dataset files related to the multiling pilot
the data includes the peer summaries human summaries and results of and autosummeng memog evaluation scores
the data set available in languages including arabic
we apply our test on the arabic documents
for the arabic language there were seven participants peers in addition to the two baseline systems for a total of nine results
the source texts contain ten collections of related newswire and newspaper articles
each collection contains ten of related articles
the multiling task requires the participant to generate a single summary for each collection
the human summaries include three human reference summaries for each collection

evaluation results table illustrates kpeval average evaluation scores for the set of summarization systems participated at tac
we compared our summary performance results against four other systems and autosummeng memog
pearson correlation coefficient is used to measure agreement with the scores and the spearman coefficient to measure correlation with the rankings
the results showed that kpeval correlates with the other four techniques memog has the strongest correlation with kpeval in both measures
and
as illustrated in table
rouge table average scores by kpeval sysid kpeval







nist
gov

shows the participating systems superiority ranking assessed by the different four evaluation techniques
the experiment shows that kpeval has almost agreement with different evaluation techniques for assessing the participating systems superiority ranking
table pearson and spearman correlation coefficient between kpeval and other systems r memog pearson



spearman



rouge memog kp eval participating summarization systems superiority ranking by different evaluation techniques
conclusion and future work in this paper we introduced a keyphrase based evaluation system kpeval for assessing automatic summaries
kpeval is based on counting the matched keyphrases lemma form of the summary to be assessed against reference summaries
kpeval has three main steps i extract the keyphrases for both peer and reference summaries ii count the matched keyphrases occurring between the peer and each one of the reference summaries and calculate precision recall and f measure
to measure the validity of the new system pearson and spearman correlation coefficient measures were tested between the results of kpeval against other evaluation systems rouge and memog using international journal of computer applications volume no
may the four tac dataset
the results showed that kpeval correlates with the strongest techniques
memog has correlation with kpeval pearson and spearman measures are
and
respectively
feature work includes testing the proposed technique for documents in other languages especially semitic languages
references el shishtawy t
el ghannam f

an accurate arabic root based lemmatizer information retrieval purposes
international journal of computer science issues ijcsi
for el shishtawy t
el ghannam f
may
kpas
based arabic keyphrase and systems informatics international conference
pp

ieee
summarizer infos giannakopoulos g
karkaletsis v
vouros g
stamatopoulos p

summarization system evaluation revisited n gram graphs
acm transactions on speech and language processing tslp
hovy e
lin c
y
zhou l

evaluating duc using basic elements
in proceedings of duc vol

hovy e
lin c
y
zhou l
fukumoto j
may
automated summarization evaluation with basic elements
in proceedings of the fifth conference on language resources and evaluation lrec pp

jones k
s
galliers j
r
eds


evaluating natural language processing systems an analysis and review vol

springer
lin c
y
july
rouge a package for automatic evaluation of summaries
in text summarization branches out proceedings of the workshop pp

lin c
y
hovy e
may
automatic evaluation of summaries using n gram co occurrence statistics
in proceedings of the conference of the north american chapter of the association for computational linguistics on human language technology volume pp

association for computational linguistics
papineni k
roukos s
ward t
zhu w
j
july
bleu a method for automatic evaluation of machine translation
in proceedings of the annual meeting on association for computational linguistics pp

association for computational linguistics
tratz s
hovy e

summarization evaluation using transformed basic elements
in proceedings of the text analysis conference
ijcatm www
ijcaonline
org
