quantifying the informativeness for biomedical literature summarization an itemset mining method milad moradi nasser department of electrical and computer engineering isfahan university of technology isfahan iran e mail milad

iut
ac
ir
iut
ac
ir abstract objective automatic text summarization tools can help users in the biomedical domain to access information efficiently from a large volume of scientific literature and other sources of text documents
in this paper we propose a summarization method that combines itemset mining and domain knowledge to construct a concept based model and to extract the main subtopics from an input document
our summarizer quantifies the informativeness of each sentence using the support values of itemsets appearing in the sentence
methods to address the concept level analysis of text our method initially maps the original document to biomedical concepts using the unified medical language system umls
then it discovers the essential subtopics of the text using a data mining technique namely itemset mining and constructs the summarization model
the employed itemset mining algorithm extracts a set corresponding author
address department of electrical and computer engineering isfahan university of technology isfahan iran
phone fax alternate email
com manuscript april of frequent itemsets containing correlated and recurrent concepts of the input document
the summarizer selects the most related and informative sentences and generates the final summary
results we evaluate the performance of our itemset based summarizer using the recall oriented understudy for gisting evaluation rouge metrics performing a set of experiments
we compare the proposed method with graphsum texlexan swesum summa autosummarize the term based version of the itemset based summarizer and two baselines
the results show that the itemset based summarizer performs better than the compared methods
the itemset based summarizer achieves the best scores for all the assessed rouge metrics

r

and r

we also perform a set of preliminary experiments to specify the best value for the minimum support threshold used in the itemset mining algorithm
the results demonstrate that the value of this threshold directly affects the accuracy of the summarization model such that a significant decrease can be observed in the performance of summarization due to assigning extreme thresholds
conclusion compared to the statistical similarity and word frequency methods the proposed method demonstrates that the summarization model obtained from the concept extraction and itemset mining provides the summarizer with an effective metric for measuring the informative content of sentences
this can lead to an improvement in the performance of biomedical literature keywords biomedical text mining data mining frequent itemset mining informativeness concept based text analysis domain knowledge summarization

introduction with the fast growth in producing digital text content in the biomedical domain much effort has been made toward developing automatic tools to alleviate the difficulties of finding relevant information
notably clinicians and researchers are often faced with a common problem i
e
acquiring the intended information from the vast sources of available text documents
the information is obtained from various resources such as scientific literature databases clinical trials electronic health record ehr systems multimedia documents mailed reports and web documents
review of the biomedical literature is an essential prerequisite to manuscript april conducting the main steps of research and experiment such as getting to know the state of art collecting the required information making new hypotheses and interpreting the results of experiments
however identifying useful information within the large volume of biomedical literature is an exhausting and time consuming process
automatic text summarization makes the task easier by condensing the source text while preserving the content that refers to the essential points of text
reeve et al
have cited five reasons for generating summaries of full text papers even with the presence of the abstracts there are variants of an ideal summary in addition to the abstract some content of the full text may be missed in the abstract question answering systems can make use of customized summaries to provide personalized information automatic summaries allow the abstract services to scale the number of documents they can evaluate and investigating the quality of sentence selection methods can be helpful in the development of multi document summarization systems
in a typical summarization system the source text is first analyzed and modeled by a particular method then the final summary is generated
the majority of summarization systems deal with the source text through constructing a model from the words
however in the biomedical domain it seems that the term level analysis of text may not yield adequate summarization performance regarding informative content conveyed by summaries
the biomedical literature similar to the scientific literature of many other fields has some properties such as the variety of synonyms and homonyms elisions and abbreviations
more specifically text documents related to each subdomain of biomedical sciences have their particular singularities that should be taken into account
for example in the genome sciences each distinct gene may have multiple synonyms
when a text document from the genome domain is analyzed at term level multiple synonymous names of a unique gene may be considered as different entities and their relations are overlooked
on the other hand in the concept level analysis of text multiple terms that share the same meaning are considered as a single entity and will be referred to as a single concept
therefore the accuracy of the model improves enhancing the quality of summarization
to address the properties of biomedical literature the concept level analysis of text is performed exploiting domain specific biomedical knowledge sources such as ontologies vocabularies and taxonomies
a summarization system decides which sentences are relevant and informative and selects them to be included in the summary according to the model produced from the source text
using an appropriate metric for measuring the informativeness of sentences a summarization system can generate a useful summary that covers the main points of the original text
several summarization methods measure the quality of sentences based on some statistical and general manuscript april metrics
typical metrics include the position of sentences the frequency of words the presence of positive and negative keywords the length of sentences the similarity of sentences to the document title the existence of numerical data and the presence of proper nouns
although these methods have achieved a desirable summarization quality compared with their counterparts they may not suit the specific requirements of text modeling and sentence selection in biomedical summarization
we show that it is required to construct an accurate concept based model from the source text so that it can be effectively used to measure the relatedness and informativeness of sentences in this type of summarization
in this paper we propose a novel biomedical text summarization method employing the concept level analysis of text together with a data mining approach namely itemset mining
the goal of our proposed itemset based summarizer is to generate an accurate concept based model from the source text
the produced model represents the main subtopics of text and a measure of their importance in the form of extracted frequent itemsets
the itemset based summarizer first maps the input text document to biomedical concepts contained in the unified medical language system umls a popular knowledge source in the biomedical domain
then it generates a transactional data representation from the source text and the extracted concepts
afterward it discovers the main subtopics of the document using a well established data mining technique namely itemset mining
to this aim we utilize the apriori algorithm
each extracted frequent itemset is a set of correlated concepts that frequently occur in the source text and the summarizer uses them to quantify the informativeness of the sentences
eventually the based summarizer assigns a score to each sentence
the assigned scores measure the informative content of the sentences
the summarizer selects the most relevant and informative sentences and puts them together to form the final summary
to evaluate the performance of the proposed itemset based summarizer we perform a set of experiments on a corpus of biomedical scientific papers
the experimental results show that our proposed biomedical summarization method performs better than the statistical and similarity feature based word frequency and baseline methods regarding the recall oriented understudy for gisting evaluation rouge metrics
the remainder of this paper is organized as follows
a background of text summarization and previous works in biomedical summarization is given in section
in section we explain our proposed biomedical text summarization method as well as the evaluation methodology
the results of experiments and assessments are presented in section and are discussed in section
finally we draw some conclusions and point out the potential future work in section
manuscript april
background first research efforts in automatic text summarization were commenced in the late and by the early works of luhn and edmundson
during the last two decades various summarization methods have been proposed using statistical natural language processing nlp machine learning graph theoretic artificial intelligence and mathematical approaches
automatic text summarization systems are designed to generate a short form of text that conveys the main ideas of the original document
automatic text summarizers are classified into abstractive and extractive systems
an abstractive summarizer generates a new content that conveys the implications of the source text by employing nlp and linguistic methods
an extractive summarizer produces a shorter version of the input text through selecting the most representative sentences from the original wording and putting them together
regarding the number of documents that a summarization system receives as input to produce a unified summary summarization methods are divided into single document and multi document methods
generic versus query focused is another categorization for text summarization
a generic summary gives a general implication of the information provided by the source text while a query focused summary provides a summary that contains the content related to a given query
summaries can be styled as indicative or informative outputs
indicative summaries provide information about the topics of the input document pointing to some parts of the text
users still need to read the original text to acquire sufficient information
informative summaries provide complete and adequate content about the topics of text so that it is not necessary to retrieve the primary document
our proposed method is extractive informative generic and document
several summarization methods like swesum and summa employ statistical based similarity and word frequency features
we show that in biomedical literature summarization the use of traditional statistical and word frequency features should be replaced by another metric that can adequately measure the extent of informative content of each sentence
such a parameter can improve the accuracy of summarization because it evaluates the quality of sentences according to their approximated meaning rather than their position length and contained terms
we address this problem by introducing a concept based summarization model that can be useful for assessing the informative content of sentences in biomedical literature summarization
manuscript april various domain independent text summarization methods have been proposed using clustering methods genetic algorithms graph based methods latent semantic analysis lsa complex networks optimization methods topic based approaches statistical approaches
however as noted earlier the biomedical domain has some singularities that require specialized summarization methods
domain knowledge resources can be used in text analysis process to build a rich representation of the source text and improve the performance of biomedical summarization
one of the useful sources of knowledge in the biomedical domain is the umls developed by the us national library of medicine
the umls is a reputable biomedical knowledge source that unifies over controlled vocabularies classification systems and additional sources of knowledge
it has been employed by some summarization systems
the umls contains three main components the specialist lexicon the metathesaurus and the semantic network
the specialist lexicon is considered as a lexicographic information database and includes english and biomedical vocabularies
the metathesaurus is a large multi purpose and multi lingual thesaurus that includes a large number of biomedical and health related concepts along with their synonyms and relationships
the semantic network contains a set of broad subject categories called semantic types to divide the concepts of the metathesaurus into stable categorizations
it also defines a set of valuable relationships between the semantic types
plaza investigated the impact of a set of knowledge sources on the performance of biomedical summarization
she tested different combinations of particular sources in the umls for retrieving biomedical domain concepts
the results showed that the quality of produced summaries could be significantly improved by using an appropriate source of knowledge
in the last two decades various biomedical text summarization methods have been proposed using different approaches
some methods have addressed this type of summarization using concept based methods
plaza et al
performed biomedical summarization using a semantic graph based approach
their summarization method used the concepts and semantic relations of the umls to construct a graph
then it applied a degree based clustering algorithm to identify different themes within the document
the authors evaluated three different sentence selection heuristics to investigate the impact of various selection strategies on the quality of summarization
another concept based biomedical summarization system made use of genetic clustering approach in combination with graph connectivity information
it employed genetic graph clustering to identify the topics of the document according to its concepts
it also used the connectivity information of the graph to assess the relevance of different subjects
chainfreq is a hybrid biomedical summarization method that combined biochain and freqdist manuscript april summarizers
chainfreq method used biochain to identify thematic sentences
in the hybrid method freqdist was responsible for removing information redundancy
both biochain and freqdist methods utilized the umls concepts to improve their topic and frequency modeling approaches
sarkar identified a vocabulary of cue terms and phrases from the biomedical domain and incorporated the vocabulary as a source of domain knowledge in his feature based summarization method
the method used two new additional features namely the presence of cue medical terms and the existence of new terms along with a set of traditional features such as word frequency sentence length sentence position and the similarity with the title
the summarizer assigned a score to each sentence and selected the high scoring sentences to form the summary
as reported by the above methods when an appropriate summarization approach was combined with domain knowledge the biomedical summarizers could perform better than their domain independent counterparts
our proposed method employs the umls knowledge source to improve its itemset mining model
the impact of both concept based and term based approaches on the performance of the itemset based summarizer will be discussed in section
recently a few domain independent summarization methods have addressed the challenges of selecting the most relevant and non redundant sentences in multi document and multilingual summarization using frequent itemsets
frequent itemset mining is a data mining technique that can be used to discover frequent patterns in a dataset
it has already been used in summarization of transactional and medical data
however so far it has not been used for biomedical text summarization
in our proposed biomedical summarization method we employ frequent itemset mining to extract the subtopics of an input document
in the sentence scoring stage we use the extracted itemsets to measure the informative content of sentences

methods in this section we explain our itemset based biomedical text summarization method
we also describe the evaluation methodology in this section


itemset based summarizer the itemset based summarizer performs the summarization task in four steps including preprocessing data preparation for itemset mining extracting main subtopics and manuscript april sentence scoring and summary creation
fig
illustrates the architecture of the itemset based summarizer
in the following subsections we give the detailed description of each step
fig

the architecture of the itemset based biomedical text summarizer



preprocessing before performing the task of summarization the itemset based summarizer must prepare the input document for the subsequent steps
at first it removes those parts of the text unlikely to be of any value for the final summary
we can specify these parts according to the input text and its logical structure
since our evaluation corpus consists of a set of biomedical scientific papers the summarizer removes the figures and tables of the input document as they are not included in the text summarization steps
it will add the figures and tables to the summary in the last step if required
every other section of the paper that seems to be unnecessary can be removed from the text
note that the preprocessing step is not merely limited to scientific articles
this action is customizable regarding the logical structure of the input text and the requirements of users
after removing the unnecessary parts the summarizer maps the plain text to biomedical concepts contained in the umls metathesaurus to ease the creation of the concept based manuscript april summarization model
for this purpose we use the metamap program developed by the national library of medicine
each extracted concept belongs to a subject category called semantic type
the semantic types divide the concepts into broader categories such as biologic function cell disease or syndrome finding sign or symptom mental process or genetic function
the umls defines over semantic types and a set of semantic relations among them in its semantic network
metamap uses nlp and computational linguistic methods to match phrases and concepts
it assigns a score to each mapping between a noun phrase and its paired concepts returning the highest scoring concept along with its semantic type
we use metamap with its word sense disambiguation wsd feature i
e
y flag
using this option when multiple mappings with similar scores are returned for a concept metamap tries to resolve the ambiguity and utilizes the journal descriptor indexing jdi algorithm
this algorithm attempts to select a single mapping according to the context in which the phrase appears
however in some cases it fails to select a single mapping and metamap returns multiple candidate concepts with equal scores
in this case our method considers all the mappings returned for a phrase
plaza al
have shown that the all mapping strategy can perform well in wsd for concept based biomedical summarization as it obtains results comparable to those reported by the best evaluated wsd methods
for the itemset based summarizer we use the version of the metamap program for the mapping step and the release of umls as the knowledge base
we use metamap by the following list of options usabase e
fig
shows a sample sentence and its extracted concepts from the umls metathesaurus
plaza al
have identified nine excessively broad semantic types whose concepts can be discarded because they are considered as very generic
these semantic types include functional concept quantitative concept qualitative concept spatial concept temporal concept language idea or concept intellectual product and mental process
after mapping the text to the concepts the itemset based summarizer discards concepts belonging to these nine semantic types
therefore the following concepts are discarded in the sentence represented in fig
widening analysis aspect further relationships and etiology aspects
manuscript april fig

a sample sentence and its extracted concepts from the umls metathesaurus



data preparation for itemset mining after the mapping phase and concept extraction we should represent the input document in an appropriate format for the itemset mining step
the most common data format to represent the input data in itemset and association rule mining is transactional data format
a transactional dataset consists of a set of transactions where each transaction contains a set of items
we should convert the input dataset to the transactional format using a proper approach according to the context in which itemset mining is used
at this step we have a set of sentences sk where each sentence si contains a number of concepts extracted in the previous step
the summarizer converts the set of sentences and their concepts to the transactional data format by considering each sentence sk as a transaction trk
it also considers the distinct concepts appearing in sk as the items of trk
a more formal definition is given below
definition transactional representation of a document
let d be an input document
the transactional representation t of d includes a set of transactions where each transaction trk corresponds to a sentence sk such that sk d and trk consists of distinct items ij where ij is jth concept in sk
based on the above definition we convert the input document d to transactional representation t
for example table represents three sentences of a sample
table gives the transactional representation of these sentences
we assign a transaction number to each transaction that refers to the corresponding sentence
the distinct concepts extracted from the sentences make the items
in the itemset mining step the summarizer will use the transactional representation of the input document to generate a concept based model based on latent correlations among the concepts items
available at
biomedcentral
com
manuscript april table three sentences of the sample document before preparation for itemset mining
sentence number content genetic epidemiological studies of autism bipolar disorder and schizophrenia show that the risk of developing one of these specific psychiatric illnesses is proportional to the amount of genetic material shared with an affected individual
the distinction between schizophrenia and bipolar disorder has been justified for many years by reference to family studies showing that these disorders seem to breed true
genome wide analyses have also implicated further related and interacting synaptic protein coding genes in the etiology of asds
table three transactions corresponding to the three sentences represented in table after preprocessing mapping and preparation steps
the non essential concepts are discarded and the remaining concepts make the items
transaction number items study of epidemiology autistic disorder bipolar disorder schizophrenia mental disorders genetic materials persons schizophrenia bipolar disorder reference object family investigation family disease breeding genome protein coding gene autism spectrum disorders


extracting main subtopics at this stage the itemset based summarizer discovers the recurrent combinations of concepts from the transactional representation of the input document
the output of this step is a set of frequent k itemsets that demonstrate the themes of the text
a k itemset is an itemset with length of k that contains a set of k distinct items
if all items of an itemset appear in a given transaction trk i
e
the transaction corresponding to sentence sk it can be said that the itemset covers trk
in itemset mining there is a property that measures the frequency of each itemset in proportion to the total number of transactions in the dataset
this property is called support and for each itemset is defined as follows manuscript april definition itemset support
given the transactional representation t corresponding to document d and an itemset i the value of support property for itemset i in t is determined as the number of transactions in t that are covered by i divided by the total number of transactions in t
for example in the sample document with sentences proteins is a itemset whose corresponding concept appears in seven sentences
therefore the proteins covers seven transactions in t and its support value is
the deletion mutation gene is a itemset and the autistic disorder bipolar disorder schizophrenia is a itemset
these two sets cover six and nine transactions in t respectively
hence their support values are and
the based summarizer considers the support values of itemsets as a metric to measure their significance
in the itemset mining step the algorithm produces a large number of itemsets
however just the frequent itemsets are useful for the subsequent steps
in the following we present a formal definition of a frequent itemset
definition frequent itemset
itemset i is said to be frequent in the transactional representation t of document d if its support value in t is greater than or equal to a given minimum support threshold
for example let the value for the sample document be equal to
based on this value the early mentioned itemsets proteins and autistic disorder bipolar disorder schizophrenia are frequent itemsets and the itemset deletion mutation gene is not frequent
given a transactional representation t of document d and a minimum support threshold the summarizer executes the frequent itemset mining process to discover all the frequent itemsets in t
to perform the frequent itemset mining task we employ the apriori a basic algorithm in data mining
the apriori algorithm is basically used for association rule mining
in our proposed method we utilize it just to extract the frequent itemsets
we do not use its ability to generate association rules
the itemset based summarizer considers the extracted frequent itemsets as the main themes of the input text and utilizes them to select the most related and informative sentences
the inputs of the algorithm are the transactional representation t of document d and the minimum support threshold
the output is a set of discovered manuscript april frequent itemsets fi where each itemset demonstrates a subtopic of text and contains a set of correlated and recurrent concepts
table the frequent itemsets extracted from the transactional representation of the sample document related to the genetic overlap between autism schizophrenia and bipolar disorders
the itemsets are sorted based on their support values
itemset support itemset support schizophrenia
study bipolar disorder
tryptophanase bipolar disorder schizophrenia
disease autism spectrum disorders
binding molecular function
autistic disorder
scientific study neuroligin
reporting deletion mutation
proteins autistic disorder schizophrenia
neuroligin binding molecular deletion mutation function gene schizophrenia autism spectrum disorders

autistic disorder bipolar disorder schizophrenia
mental retardation autistic disorder bipolar disorder
procedure findings copy number polymorphism
staphylococcal protein a

encode action genome wide association
study
diagnosis













genes gene genome persons alleles table represents the frequent itemsets extracted from the sample document
the sample document is about the genetic overlap between autism schizophrenia and bipolar disorders
in this example the itemset mining algorithm extracts a total number of frequent itemsets of which are itemsets six of which are itemsets and one is itemset
in this example the value manuscript april of minimum support threshold is
i
e
an itemset is frequent if it covers at least of the transactions
in other words a set of correlated concepts is a central subtopic of the text if the concepts appear together in at least of the sentences
it is shown in table that the average number of sentences of a document in our evaluation corpus is
according to this average number it can be said for a minimum support threshold of
in average an itemset must appear at least in sentences to be discovered as a frequent itemset
this value of
used in the above example is not the optimum value for this threshold
the optimum value of threshold is specified by a set of preliminary experiments in section

and is discussed in section




sentence scoring and summary creation after performing the itemset mining step that discovers the main subtopics we should rank the sentences of the input text based on how much they are informative and cover the main subtopics
hence we require a scoring strategy to quantify the informativeness of the sentences
the support value of each itemset indicates that how much the itemset is significant
it means that in the comparison between two itemsets extracted from a given document an itemset is assumed to be more valuable and informative if it has a higher support value
therefore we hypothesize that the support value of the itemsets that cover a sentence is an appropriate measure to quantify the importance of the sentence
the itemset based summarizer assigns a score to each sentence by adding the support value of the itemsets that cover the sentence
the score of each sentence is calculated as follows where is ith sentence in document d and is the transaction corresponding to
is the set of all frequent itemsets extracted from the transactional representation t of document d and is jth itemset in
after scoring all the sentences of the input document the summarizer can decide which sentences should be selected to be included in the final summary
two factors contribute to a higher score the number of frequent itemsets that cover the sentence and the support value of the frequent itemsets that cover the sentence
therefore the sentences that contain more frequent itemsets and are covered by high supporting frequent itemsets produce higher scores
the summarizer considers the high scoring sentences to be highly informative and more related to the main topics manuscript april of the input text
after the sentence scoring task the summarizer sorts the sentences based on their scores
it selects the top n sentences to build the final summary where n is the number of sentences that must be chosen for the summary and is determined by the compression rate
if two sentences have the same score the method assigns a higher priority to the sentence having shorter length
the summarizer arranges the selected sentences according to their appearance order in the input text
finally if the summary refers to a figure or a table of the primary document removed in the preprocessing step the method adds the figure or the table to the summary
fig
shows the summary of the sample document produced by the itemset based summarizer
in this example for brevity reasons the compression rate is
that is the size of the summary must be of the input document
fig

the summary of the sample document generated by the itemset based summarizer compression


evaluation method the performance of text summarization systems can be evaluated using two methods extrinsic and intrinsic
the extrinsic method evaluates the impact of summarization on the quality of specific tasks that use produced summaries
as some of these specific tasks we can manuscript april point out those performed by question answering systems or search engines
the intrinsic method evaluates the performance of summarization regarding the measures that assess the quality of summaries
the most common measures used for intrinsic evaluation are informativeness accuracy relevancy comprehensiveness and readability
since we intend to assess the competency of the itemset based summarizer regarding the informative content of produced summaries we evaluate its performance through intrinsic evaluation
table the statistics of the evaluation corpus containing biomedical scientific papers and their abstracts
the minimum maximum and average number of sentences and words of a document are presented for the full texts and the abstracts
number of sentences number of words min
max
average min
max
average full texts abstracts


evaluation dataset and metrics to assess the performance of the proposed summarization method we need to summarize a of biomedical text documents that have model summaries available to serve as a reference standard
the model summary is used to measure the similarity between its content and the system generated summary
to the authors knowledge such a corpus has not been developed for the evaluation of single document biomedical text summarization methods
however a common approach is summarizing a collection of biomedical articles and using the abstract of each article as the model summary
to evaluate the performance of the itemset based summarizer we employ a collection of biomedical articles randomly selected from biomed central s for text mining
we use the abstracts of the papers as the model summaries
this dataset is large enough for the results of the evaluations to be significant
table presents the statistics of the evaluation corpus
to evaluate the performance of the itemset based summarizer in terms of its ability to improve the informativeness of automatic summaries we use the rouge package
rouge estimates the shared content by comparing a system generated summary with single or multiple
biomedcentral
com about datamining manuscript april model summaries
the estimation is performed by calculating the proportion of shared n grams between the system and model summaries
for the evaluations we use four rouge metrics it computes the number of shared unigrams between the system and model it computes the number of shared bigrams between the system and model summaries
summaries
rouge
r
it compares the consecutive matches between the system and model summaries and computes the union of the longest common subsequences
rouge r it calculates the overlap of skip bigrams pairs of words having intervening word gaps between the system and model summaries and allows a skip distance of four between the bigrams
the rouge metrics compute scores between and
a higher score indicates greater content overlap between the system and model summaries
therefore a summarizer is assumed to be better if its produced summaries obtain higher rouge scores because they contain more shared content with the model summaries and are considered to be more informative
it is worth mentioning that the rouge scores showed high correlation with the human judges of the document understanding conference duc evaluation data and duc conference adopted it as the official evaluation metric for text summarization



the value of minimum support threshold we conduct two sets of experiments to evaluate the performance of our itemset based method for biomedical text summarization
to tune the parameter of the system the first part of experiments is described in this subsection
afterward the second part of experiments will be described in the next subsection that evaluates the itemset based summarizer against other summarization methods
we design and perform a set of preliminary experiments in order to determine the best value for the threshold involved in discovering frequent itemsets section


the apriori algorithm finds the frequent itemsets whose support value is greater than or equal to the threshold
then the itemset based summarizer considers the extracted frequent itemsets to be the main themes of the document
it assigns a score to each sentence based on the frequent itemsets that cover the sentence
therefore the higher the value of threshold the fewer the frequent itemsets to be discovered and the fewer the number of itemsets participating in the sentence scoring step
in contrast the lower value of threshold the more the frequent manuscript april itemsets to be extracted and the more the itemsets getting involved in the sentence scoring phase
we assess the impact of lower and higher values of the threshold on the performance of the proposed itemset based summarizer
we choose the threshold value reporting the highest rouge scores as the best value for the
we use the optimum value in the subsequent experiments to evaluate the itemset based summarizer against other summarization methods
to specify the best value for the threshold as well as for parameterization of the comparison methods we use a separate evaluation consisting of biomedical articles randomly selected from biomed central s corpus for text mining research
we use the abstracts of the articles as the model summaries



comparing with other summarizers we compare our proposed summarization method against other research oriented publicly available commercial and baseline summarizers to assess its appropriateness for biomedical literature summarization
the other summarizers used in the evaluations include graphsum texlexan swesum summa microsoft autosummarize the term based version of the itemset based summarizer lead baseline and random baseline
the rationale for the selection of these comparison methods is the utilized term based methods and generic measures
since the challenges we address in this study are not related to previous biomedical summarizers we do not use any biomedical summarization methods mentioned in section in our evaluations and comparisons
for example the semantic graph based approach proposed by plaza et al
is one of the few methods concerning biomedical literature summarization
it addresses the challenges related to the previous graph based methods by considering concepts and their relations as the nodes and edges of the graph
if we include this method in our evaluations no matter which system would obtain better scores the difference between the semantic graph based system and our summarizer could not be discussed to address the challenges introduced in section
in the following the comparison methods are described
graphsum is a domain independent summarizer that uses a graph based approach in combination with association rule mining
it creates a correlation graph where the nodes represent sets of recurrent terms extracted regarding frequent itemsets and the edges indicate positive and negative correlations among multiple terms in pairs of nodes
it generates the summary using a greedy strategy selecting the most representative subset of sentences that best cover the correlation graph
manuscript april texlexan is a widely used and open source automatic summarizer that uses keywords extracted from the input text and the cue expressions to assess the relevancy of sentences and extract the most relevant ones for the final summary
swesum is a research oriented summarizer whose online version is available for public usage and is considered to be state the art for english danish norwegian and swedish text summarization
for sentence scoring it uses a set of features such as presence in the first line of the text presence of numerical values in the sentence and the presence of keywords in the sentence
swesum provides an option to choose between academic and newspaper as the type of text
for this option we use the academic text type
summa is another research oriented summarizer for both single and document summarization
it selects the sentences to be included in the summary based on several statistical and similarity based features
each feature has a weight that specifies its importance
for the evaluations we use these features for summa i
e
the frequency of terms contained in the sentence the position of the sentence in the document the similarity of the sentence to the first sentence of the document and the overlap between the sentence and the title of the document
autosummarize is a commercial application and a feature of the microsoft word software
it performs the sentence scoring and summarization tasks based on a word frequency algorithm
higher scores are assigned to the sentences that contain more frequent words
we use these four summarizers to assess the competency of statistical and similarity feature based keyword based and word frequency summarization methods for biomedical literature summarization
the term based version of the itemset based summarizer uses terms instead of concepts to build an itemset based model
in the term based version of our method the stage of mapping text to biomedical concepts is no longer needed but two additional steps are added for extracting appropriate terms that can be used in the itemset mining stage
the first step is stop word elimination that removes highly frequent words that have little lexical content
to this aim we employ the natural language toolkit nltk stop word
the second step is stemming reducing all the words contained in the sentences to their corresponding stem
for this purpose we adopt the porter stemming algorithm
after applying these two steps the remaining terms form the items
the summarizer performs the remaining steps similar to the original concept based version
the goal of using the term based version for the evaluations is to investigate the impact of concept level analysis of text on the accuracy of the itemset based text modeling against term level analysis
we also use two baseline methods in the experiments
the lead baseline method returns the first n sentences of the input text as the summary and the random baseline randomly selects n sentences and generates the summary
manuscript april we also perform a set of preliminary experiments to parameterize the comparison methods containing tunable parameters on the same development set employed for the parameterization of the itemset based summarizer
the aim of parameterization of all the methods on the same development set is to validate the results of the final evaluations where the performance of the methods is investigated for biomedical literature summarization
the results of the parameter tuning will be presented in section


in our evaluations we set the compression rate to for all the summarizers
that is the size of the generated summary is equal to of the input document
this choice is based on a widely accepted standard of a compression rate between and
we assess the statistical significance of the results using a wilcoxon signed rank test with a confidence interval

results will be presented


parameterization results in this section first we present the results of the preliminary experiments and the parameterization of the itemset based summarizer and the comparison methods
then the results of evaluations comparing the itemset based summarizer with the other summarization methods we perform the first set of parameter tuning experiments on the development corpus mentioned in section

to assess the impact of the threshold on the performance of the itemset based summarizer
we also devote the second set of preliminary experiments to the parameterization of the competitor methods
in the following we separately present the results of these two sets of experiments



itemset based summarizer the apriori algorithm decides whether the extracted itemsets are frequent according to the threshold
as mentioned in section

the number of discovered frequent itemsets has an inverse relationship with the value of the support threshold
in fact the higher the value of the minimum support threshold the fewer the number of frequent itemsets to be discovered and vice versa
fig
presents the results of the experiments
for brevity reasons only and scores are reported
the best value for the threshold is
i
e
that provides the best scores for the rouge metrics
and r

for the final manuscript april evaluations according to the average number of sentences of a document in the evaluation corpus table it can be said that an itemset must approximately appear at least in sentences to be discovered as a frequent itemset for a minimum support threshold of

it can be observed from fig
that according to the rouge scores the value of threshold has a significant impact on the quality of the generated summaries
table reports the average number of all discovered frequent itemsets and the average number of k itemsets where k is equal to and
the average numbers are given for each tested support threshold
we perform similar experiments to specify the best value of the min sup threshold for the term based version of the itemset based summarizer
the threshold value of
reports the highest rouge scores
and r
and we use this value for the subsequent experiments
rouge r o c s e g u o r



























threshold fig

and rouge scores for different values of the minimum support threshold
table the average number of all extracted frequent itemsets and the average number of k itemsets for the preliminary experiments evaluation corpus
the average numbers are given for each tested minimum support threshold in the preliminary experiments
the numbers are rounded off to one decimal digit
threshold average number of all frequent itemsets average number of frequent itemsets average number of frequent itemsets average number of frequent itemsets average number of frequent itemsets manuscript april




















































































































comparison methods in this section we present the results of parameterization of those competitor summarizers containing tunable parameters
graphsum method contains three parameters that can affect the quality of produced summaries
these parameters include the minimum support threshold to extract frequent itemsets the minimum lift threshold to identify positive correlations between terms and the maximum lift threshold to identify negative correlations between terms
we experiment graphsum by varying the minimum support threshold in the range

the minimum lift threshold in the range and the maximum lift threshold in the range


the minimum support threshold of
the minimum lift threshold of and the maximum lift threshold of
are the optimum configuration
using these parameter values graphsum reports its best scores
and r

summa method scores the sentences of an input document using a set of features and their weights
we tune the parameters of summa varying the weight of each feature and assessing the obtained rouge scores under each configuration
the best scores
and r
are reported when the weights of the term frequency feature the position feature the manuscript april similarity to the first sentence feature and the overlap with the title feature are


and
respectively
we perform another set of parameterization experiments to find the optimal weights used by swesum to score the sentences of an input document
the best scores
and r
are reported when the weights of the first line feature the numerical values feature and the keywords feature are

and
respectively
for the final evaluations we run graphsum summa and swesum using the optimal parameter values specified in the above experiments


evaluation results to evaluate the performance of our proposed itemset based biomedical summarizer we compare the rouge scores assigned to our method with the scores assigned to the other summarizers including graphsum texlexan swesum summa microsoft autosummarize itemset based summarizer term based version lead baseline and random baseline
the rouge toolkit assigns four different scores to each summarizer while comparing the generated summaries with the model summaries
table shows the rouge scores obtained by all the summarizers
as can be observed our proposed itemset based biomedical summarizer reports higher rouge scores than the other summarizers and the baseline methods
compared with graphsum the improvement in the scores obtained by the itemset based summarizer is significant for score according to wilcoxon signed rank test p

compared with the other summarizers the itemset based summarizer significantly improves all the reported rouge metrics p

the term based version of the itemset based summarizer substantially performs better than autosummarize lead baseline and random baseline for all the reported rouge scores p

its improvement in the scores compared with summa is significant for and r p

it also greatly improves and r scores with respect to swesum and texlexan although its improvement is not significant for r
score p

its obtained rouge scores are lower than those of graphsum and the difference is significant for and scores p

table rouge scores obtained by the itemset based summarizer and the comparison methods
the best score for each metric is shown in bold type
the summarizers are sorted based on their scores
rouge
rouge manuscript april



































itemset based summarizer itemset based summarizer term based graphsum summa swesum texlexan lead baseline autosummarize random baseline
discussion evaluations presented in section


parameterization in this section we discuss the results of the parameterization experiments and the final as reported in table and shown in fig
when we select a relatively small value e


or
the itemset mining algorithm returns a large number of frequent itemsets
these itemsets participate in the sentence scoring step whereas only a small number of them contain useful information to assess the informative content of the sentences
as a result the summarizer performs the sentence scoring step using numerous redundant itemsets
this negatively affects the quality of the produced summaries
for example when the value of threshold is
the method extracts a total number of frequent itemsets from the sample document mentioned in section
the number of k itemsets for k and is equal to and respectively
the results show that the produced summary tends to cover a range of concepts including reproductive history study of epidemiology population group sharing application procedure comparison social role when such a large number of itemsets participate in sentence scoring
it seems that such concepts are weakly relevant to the main subtopics as they appear less frequently in the text
in this particular example the itemset based summarizer reaches
and r
scores
as another extreme threshold when we choose a relatively high value e


or
for the value of the number of discovered frequent itemsets is remarkably reduced
in this case the summarizer quantifies the informativeness of the sentences according to a low number of manuscript april itemsets whereas this number of itemsets is not enough to decide to what extent the sentences are informative
in fact the summarizer assigns scores to the sentences based on a limited number of main subtopics while there are other important subtopics disregarded by an extreme value of the support threshold
consequently the summarizer can not accurately assign scores to the sentences based on their actual informativeness
hence the quality of the produced summaries is lowered
for example when the value of threshold is
the method extracts a total number of five frequent itemsets from the sample document
there are four frequent itemsets and one frequent itemset
the results show that the summary extremely tends to cover the most frequent concepts like autism spectrum disorders bipolar disorder and schizophrenia when this limited number of itemsets are used for sentence scoring
in this particular example the itemset based summarizer receives
and r
scores
on the other hand the itemset mining algorithm extracts a total number of frequent itemsets from the sample document when the value of threshold is

there are frequent itemsets three frequent itemsets and one frequent itemset
the results show that the summary covers both the most important concepts demonstrating the primary subtopics and other relevant concepts including genome proteins deletion mutation alleles neuroligin binding molecular function and gene using these extracted itemsets for sentence scoring
in this case compared to the summary generated by a small threshold of
the concepts that seem to be weakly relevant to the main subtopics appear less frequently in the summary
moreover compared to the summary generated by a high threshold of
the extreme tendency of the summary to cover the main subtopics is lowered and other relevant subtopics appear more frequently
in this particular example the itemset based summarizer obtains
and
scores
for graphsum which also employs itemset mining it also has been shown that an optimum support threshold plays an important role in balancing model specialization and generality


comparing with other summarizers investigating the summaries produced by different methods we can point out the following observations and discuss the evaluation results presented in table
the results show that the random baseline performs worse than the other summarizers
as expected sentences randomly selected from the documents do not lead to producing useful summaries
the lead baseline performs better than the random baseline because a portion of valuable information of a scientific article is presented when beginning with the introduction
manuscript april however the summarization performance of the lead baseline is not satisfying and it is required all the relevant information throughout the document be contained in the final summary
moreover other types of biomedical text documents may not have the same structure as the scientific articles and the lead baseline may give worse summarization performance when other types of text documents are used
the word frequency algorithm of autosummarize produces the summaries based on the highly frequent words contained in the input texts
in comparison with the top ranked summarizers the summaries generated by this method show a narrower topic coverage
moreover the presence of irrelevant and low informative sentences lowers the quality of the summaries
with the development of more intelligent methods utilizing a variety of features of text it can be argued that the term frequency feature can not solely be used to produce informative summaries particularly in biomedical literature summarization
in the summaries produced by swesum the sentences containing numerical values appear more frequently
these sentences are mostly extracted from the results section of the documents
many important sentences concerning the main subtopics of the documents are missing from the summaries
so this summarization method may be more useful when the user prefers to know about the results reported in a biomedical article
since the model summaries used for the evaluations the abstract of the articles address different parts of the articles background methods results
swesum reports lower scores compared to the other summarizers which do not differentiate between numerical and other content
however when the weights of swesum s features are tuned the performance of swesum increases and its tendency to select the sentences containing numerical values decreases
it has been shown that in biomedical literature summarization produced summaries convey more informative content when important sentences are selected from different sections of an input document
texlexan uses the keywords extracted from the input text to score the sentences
looking at the summaries generated by this method we can find out that the extracted keywords are the frequency terms in each document
there are some similarities between the summaries of texlexan swesum summa and autosummarize
the reason for this similarity can be the dependency of these methods on the high frequent terms as the keywords of the text
assessing the documents and summaries we observe that some keywords extracted by these methods are essentially meaningless or unrelated to the topics of the documents
for example the following terms are among the keywords extracted from a number of documents investigated by the four summarizers those which other their after number using there during could significant
manuscript april the above summarizers utilize such generic terms to measure the relatedness and informativeness of the sentences
despite their high frequency the itemset based summarizer discards such terms from the produced model since their semantic types are excessively broad as explained in section

or they are mapped to no concept in the preprocessing step
we can regard this improvement in selection as a key reason for the better rouge scores reported by the based summarizer
it seems that the investigation of more complicated keyword extraction methods employed in other fields like text classification could improve the performance of the available summarizers
summa employs a word frequency method as well as similarity based and positional features
it obtains better rouge scores compared to texlexan swesum and autosummarize
this better summarization quality could be due to utilizing additional features
the summaries produced by summa show that the similarity of sentences with the title of the document can be a useful feature in selecting more related sentences
this feature has also been investigated for the selection of informative sentences and segments in biomedical text summarization
however some issues may reduce the effectiveness of this feature
first all type of input texts may not have a title
second a sentence may convey similar information to the title of text but contains different terms
the produced summaries suggest that this feature could lead to some degree of redundancy because the relatedness of the sentences should be measured by a broader range of topics not only by the terms appearing in the title
another feature implemented by summa is the position of the sentence in the document
looking at the output summaries we observe that the first sentences of the paragraphs of a document are more likely to be selected for the summary although they may convey no informative content
the summaries show that this feature may not work efficiently for this type of documents where there are numerous paragraphs and the beginning sentences may not necessarily be related to the main topics
however this sentence selection strategy has shown its usefulness for summarization of newswire articles
another feature used by summa is the similarity of the sentence to the first sentence of document
the produced summaries show that the sentences having more than five terms in common with the first sentence of the respective document are more likely to be included in the final summary
in the documents with an appropriate first sentence this feature helps to extract more informative sentences
on the other hand for the documents with an irrelevant first sentence this feature leads to some unrelated sentences to be included in the summaries
regarding the evaluation results it seems that the methods and features used by summa texlexan swesum and autosummarize may not be manuscript april utilized as adequate measures to quantify the informative content of sentences in this type of summarization
graphsum reports the highest rouge scores among the term based summarizers
in comparison with the summaries produced by summa texlexan swesum and autosummarize the output summaries of graphsum cover a broader range of topics discussed in the input documents
this better coverage of topics could be due to its sentence selection strategy where it tries to select those sentences that best cover the correlation graph of the input text
however for the relatively large documents usually more than sentences graphsum reports lower rouge scores than for the smaller documents
it seems that the accuracy of its hybrid graph itemset model or its sentence selection method could negatively be affected by complex term distributions and abundant number of positive and negative correlations among terms in large documents
the term based version of the itemset based summarizer reports lower scores than graphsum
nevertheless it performs better than the other term based competitors
it covers a relatively broader range of topics in its produced summaries
however low informative and unrelated sentences still appear in the output summaries of the two methods
based on these observations it is essential to select the sentences according to their approximated meaning and the subtopics that each sentence covers
the itemset based summarizer analyzes documents using a based approach to cope with the issues raised by other methods
the itemset based summarizer reports the best rouge scores
following the trend of knowledge rich methods in biomedical text summarization the itemset based summarizer benefits from the combination of domain knowledge and itemset mining based summarization
it can improve the performance of biomedical text summarization by dealing with concepts rather than terms
through the use of itemset mining the method extracts correlated concepts in the form of frequent itemsets and considers them as important subtopics
it uses the main subtopics to measure the informative content of the sentences
when the summarizer maps the input text to biomedical concepts a single concept may be representative of multiple words or phrases sharing a common meaning
this operation can increase the accuracy of the produced model
moreover in term based modeling the summarizers deal with a sequence of terms indicating a unique concept as separate unit items
on the other hand using concept based modeling our summarizer can deal with a sequence of terms indicating a concept as an unit item
for example the based summarizer considers the phrase genome wide association study as a unique concept manuscript april while graphsum deals with this phrase as three or four separate terms
in this way the number of items increases and the accuracy of the model generated by graphsum is reduced
in our preliminary experiments we evaluated the comparison methods using the parameter values suggested by the respective authors or their default configurations
for brevity reasons we present only the rouge scores obtained by the optimum parameter values in section


comparing the scores reported for the default and the tuned parameter values we observe that when we parameterize the comparison methods on the development set they obtain higher scores on the final evaluation corpus
this shows that the optimum values of these parameters are dependent on the context in which we use the summarizers
all the parameterized systems report higher scores using their optimum parameter values however only one system swesum reaches a higher rank after parameter tuning
despite the improvement in the obtained scores the ranks of other systems do not change compared to their ranks before parameterization


limitations this study has some limitations
first it seems that four systems of the comparison methods i
e
swesum summa texlexan and autosummarize do not benefit from common preprocessing procedures stop word removal and stemming
this suggests that if they had been provided with the output of such preprocessing steps their performance could be increased
however if they had been evaluated with preprocessed documents the obtained rouge scores would not have been indicative of their actual performance
in real applications the majority of users may give these systems text documents without applying any preprocessing procedure
second there may be some similarities between concepts within an input document and this is not considered by the itemset based summarizer
dealing with these similarities may require to gain access to additional resources that contain the similarity information and might increase the complexity of the system

conclusion in this paper we propose a novel biomedical text summarization method employing a known data mining technique namely itemset mining and concept based modeling of the text
the summarizer maps the input document to the concepts contained in the umls to facilitate the concept level analysis of the source text
with the use of concept level analysis rather than traditional term based approaches the itemset based summarizer is better equipped to address the inherent ambiguities of biomedical text
the summarizer utilizes frequent itemset mining to manuscript april discover recurrent and correlated concepts appearing together in the source text
the discovered frequent itemsets demonstrate the important themes of the input document
the itemset based summarizer quantifies the relatedness and informativeness of each sentence using the support values of the frequent itemsets covering the sentence
eventually it produces the final summary by putting the most informative sentences together
we evaluate the itemset based summarizer on a collection of biomedical scientific articles
compared with other summarization methods that utilize statistical and similarity features or word frequency algorithms the itemset based summarizer shows better summarization performance
the evaluation results confirm that the use of itemset mining in combination with domain knowledge provides an useful method to generate an accurate concept based model for this type of summarization
we also investigate the role of the minimum support threshold involved in the itemset mining algorithm on the quality of produced summaries
the support values less than the optimum threshold value generate a large number of itemsets that mislead the summarizer and reduce its accuracy by redundant information
moreover the support values greater than the optimum threshold value produce fewer itemsets
in this case the summarizer s knowledge is not sufficient and its accuracy decreases due to incomplete information concerning the essential subtopics
although the itemset based summarizer show its efficiency and usefulness for document biomedical text summarization it may encounter the redundancy problem in document summarization
we intend to concentrate on this issue by incorporating a redundancy reduction strategy into the summarization method and proposing a multi document summarization method
our future work will also include extending the itemset based summarization modeling for query focused biomedical text summarization
as another topic for future research graphsum could be extended for biomedical text summarization dealing with concepts rather than terms

mode of availability the java source code of the itemset based biomedical text summarizer and its documentation are accessible at
iut
ac
ir content code itemset based summarizer
manuscript april references r
mishra j
bian m
fiszman c
r
weir s
jonnalagadda j
mostafa al
text summarization in the biomedical domain a systematic review of recent research journal of biomedical informatics vol
pp

s
afantenos v
karkaletsis and p
stamatopoulos summarization from medical documents a survey artificial intelligence in medicine vol
pp

w
w
fleuren and w
alkema application of text mining in the biomedical domain methods vol
pp

l
h
reeve h
han and a
d
brooks the use of domain specific concepts in biomedical text summarization information processing management vol
pp

l
plaza a
daz and p
gervs a semantic graph based approach to biomedical summarisation artificial intelligence in medicine vol
pp

r
a
erhardt r
schneider and c
blaschke status of text mining techniques applied to biomedical text drug discovery today vol
pp

p
chen and r
verma a query based medical information summarization system using ontology knowledge in ieee symposium on computer based medical systems pp

l
plaza and j
carrillo de albornoz evaluating the use of different positional strategies for sentence selection in biomedical literature summarization bmc bioinformatics vol
p

h
saggion summa a robust and adaptable summarization tool traitement automatique langues vol

m
a
fattah and f
ren ga mr ffnn pnn and gmm based models for automatic text summarization computer speech language vol
pp

r
m
alguliev and r
m
aliguliyev effective summarization method of text documents in the ieee wic acm international conference on web intelligence pp

s
j
nelson t
powell and b
humphreys the unified medical language system umls project encyclopedia of library and information science pp

r
agrawal t
imieliski and a
swami mining association rules between sets of items in large databases acm sigmod record vol
pp

r
agrawal h
mannila r
srikant h
toivonen and a
i
verkamo fast discovery of association rules advances in knowledge discovery and data mining vol
pp

c

lin rouge a package for automatic evaluation of summaries in text summarization branches out proceedings of the workshop
h
p
luhn the automatic creation of literature abstracts ibm journal of research and development vol
pp

h
p
edmundson new methods in automatic extracting journal of the acm jacm vol
pp

m
gambhir and v
gupta recent automatic text summarization techniques a survey artificial intelligence review pp

v
gupta and g
s
lehal a survey of text summarization extractive techniques journal of emerging technologies in web intelligence vol
pp

e
lloret and m
palomar text summarisation in progress a literature review artificial intelligence review vol
pp

manuscript april swesum


accessed
nada
kth
index eng adv
html
l
yang x
cai y
zhang and p
shi enhancing sentence level clustering with based clustering framework for theme based summarization information sciences vol
pp

summarizer
automatic text m
mendoza s
bonilla c
noguera c
cobos and e
len extractive single document summarization based on genetic operators and guided local search expert systems with applications vol
pp

g
erkan and d
r
radev lexrank graph based lexical centrality as salience in text summarization journal of artificial intelligence research pp

j

yeh h

ke w

yang and i

meng text summarization using a trainable summarizer and latent semantic analysis information processing management vol
pp

l
antiqueira o
n
oliveira l
da fontoura costa and m
d
g
v
nunes a complex network approach to text summarization information sciences vol
pp

r
m
alguliev r
m
aliguliyev m
s
hajirahimova and c
a
mehdiyev mcmr maximum coverage and minimum redundant text summarization model expert systems with applications vol
pp

s
harabagiu and f
lacatusu using topic themes for multi document summarization acm transactions on information systems tois vol
p

j

lee s
park c

ahn and d
kim automatic generic document summarization based on non negative matrix factorization information processing management vol
pp

h
d
menndez l
plaza and d
camacho combining graph connectivity and genetic clustering to improve biomedical summarization in ieee congress on evolutionary computation cec pp

l
reeve h
han and a
d
brooks biochain lexical chaining methods for biomedical text summarization in proceedings of the acm symposium on applied computing pp

l
h
reeve h
han s
v
nagori j
c
yang t
a
schwimmer and a
d
brooks concept frequency distribution in biomedical text summarization in proceedings of the acm international conference on information and knowledge management pp

accessed


national library of medicine
umls specialist lexicon fact sheet

nlm
nih
gov pubs factsheets umlslex
html
accessed


national library of medicine
umls metathesaurus fact sheet

nlm
nih
gov pubs factsheets umlsmeta
html
accessed


national library of medicine
umls semantic network fact sheet

nlm
nih
gov pubs factsheets umlssemn
html
l
plaza comparing different knowledge sources for the automatic summarization of biomedical literature journal of biomedical informatics vol
pp

k
sarkar using domain knowledge for text summarization in medical domain international journal of recent trends in engineering vol
pp

e
baralis l
cagliero s
jabeen and a
fiori multi document summarization exploiting frequent itemsets in proceedings of the annual acm symposium on applied computing pp

manuscript april e
baralis l
cagliero n
mahoto and a
fiori graphsum discovering correlations among multiple terms for graph based summarization information sciences vol
pp

e
baralis l
cagliero a
fiori and p
garza mwi sum a multilingual summarizer based on frequent weighted itemsets acm transactions on information systems tois vol
p

library of medicine
metamap portal
m
mampaey n
tatti and j
vreeken tell me what i need to know succinctly summarizing data with itemsets in proceedings of the acm sigkdd international conference on knowledge discovery and data mining pp

c
ordonez n
ezquerra and c
a
santana constraining and summarizing association rules in medical data knowledge and information systems vol
pp

accessed


national
nlm
nih

s
m
humphrey w
j
rogers h
kilicoglu d
demner fushman and t
c
rindflesch word sense disambiguation by selecting the best semantic type based on journal descriptor indexing preliminary experiment journal of the american society for information science and technology vol
pp

l
plaza m
stevenson and a
daz resolving ambiguity in biomedical text to improve summarization information processing management vol
pp

l
s
carroll and m
j
owen genetic overlap between autism schizophrenia and bipolar disorder genome medicine vol
p

k
s
jones and j
r
galliers evaluating natural language processing systems an analysis and review vol
springer science business media
c

lin looking for a few good metrics automatic summarization evaluation how many samples are enough in ntcir
accessed
sourceforge

microsoft word ed microsoft coporation
e
loper and s
bird nltk the natural language toolkit in proceedings of the workshop on effective tools and methodologies for teaching natural language processing and computational linguistics volume pp

the porter stemming algorithm

org martin
r
mitkov the oxford handbook of computational linguistics oxford university press
a
onan s
korukolu and h
bulut ensemble of keyword extraction methods and classifiers in text classification expert systems with applications vol
pp

d
d
a
bui g
del fiol j
f
hurdle and s
jonnalagadda extractive text summarization system to aid data extraction from full text in systematic review development journal of biomedical informatics vol
pp

texlexan an open


summarizer source text manuscript april
