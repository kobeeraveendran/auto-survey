a summarization system for scientic documents shai michal shmueli guy ora peled odellia haggai doron bar yosi or guy achiya jonathan yufang charles martin francesca debasis david research cloud
ibm
com abstract we present a novel system providing maries for computer science publications
through a qualitative user study we ed the most valuable scenarios for ery exploration and understanding of tic documents
based on these ndings we built a system that retrieves and summarizes scientic documents for a given information need either in form of a free text query or by choosing categorized values such as scientic tasks datasets and more
our system ingested papers and its summarization ule aims to generate concise yet detailed maries
we validated our approach with man experts
introduction the publication rate of scientic papers is ever creasing and many tools such as google scholar microsoft academic and more provide search pabilities and allow researchers to nd papers of interest
in computer science and specically natural language processing machine learning and articial intelligence new tools that go yond search capabilities are used to plore singh et al
discuss and publications
yet there is still a high information load on researchers that seek to keep up to date
summarization of scientic papers can mitigate this issue and expose researchers with adequate amount of information in order to reduce the load
many tools for text summarization are
however such tools target mainly news or simple documents not taking into account the characteristics of scientic papers i
e
their length and complexity
sanity
com

com miso belica sumy ivypanda
com online text summarizer a summarization system for scientic tions requires many underlying technologies rst extracting structure tables and gures from pdf documents then identifying important entities and nally generating a useful summary
we chose to provide summarization as part of a search system as it is the most common interface to sume scientic content regardless of the task
use cases
we identied the most valuable narios for scientic paper usage through a tive user study
we interviewed six potential users a phd student two young researchers two senior researchers and a research strategist all in the nlp domain
users were asked to describe when do they access scientic papers how often does it happens how do they explore content and nally what are their pain points with current tools
top scenarios were by order of frequency keeping updated on current work preparing a research project grant request preparing related works when writing a paper checking the novelty of an idea and learning a new domain or ogy
while and are important it seems that they happen only a few times a year whereas scenario happens on a daily weekly basis
all users mentioned information overload as their main problem and foremost the efforts incurred by reading papers
thus we decided to focus on scenario
we further asked the users to describe how do they search and the strategy they use to decide whether they want to read a paper
for a users mentioned searching by using either keywords entities e

task name dataset name benchmark name or citation
in this scenario users are familiar with their research topic and hence can be very focused
some amples queries were state of the art results for squad or using bert in abstractive rization
for users rst read the title and if g u a l c
s c v
v i x r a relevant continue to the abstract
here users tioned that in many cases they nd the abstract not informative enough in order to determine evance
hence the importance of summarization for helping researchers understand the gist of a paper without the need to read it entirely or even opening the pdf le
approach and contribution
we present a novel summarization system for computer ence publications named ibm science rizer which can be useful foremost to the acl it community and to researchers at large
duces summaries focused around an information need provided by the user a natural language query scientic tasks e

machine tion datasets or academic venues
ibm science summarizer summarizes the various sections of a paper independently allowing users to focus on the relevant sections for the task at hand
in ing so the system exploits the various entities and the user s interactions like the user query in order to provide a relevant summary
we validated our approach with human experts
the system is able at
biz sciencesum
related work numerous tools support the domain of scientic publications including search monitoring ing and more
for automatic summarization forts mostly concentrated on automated generation of survey papers jha et al
jie et al

surveyor jha et al
considers both content and discourse of source papers when generating survey papers
citationas jie et al
tomatically generates survey papers using citation content for the medical domain
the main ences between these systems and ours is that they create summaries from multi documents while our tool summarizes individual papers and ports query focused summaries
for supporting the acl community cl scholar singh et al
presents a graph ing tool on top of the acl anthology and ables exploration of research progress
albank fabbri et al
helps researchers to learn or stay up to date in the nlp eld
recently is an open resource for ml pers code and leaderboards
our work is mentary to these approaches and provide the rst
figure ibm science summarizer framework
tool for automatic summarization and exploration of scientic documents
system overview ibm science summarizer s main purpose is to support discovery exploration and ing of scientic papers by providing summaries
the system has two parts
first an ingestion pipeline parses and indexes papers content from arxiv
com and acl anthology as depicted in ure
second a search engine backed up by a ui supports search and exploration coupled with summarization as shown in figure
figure shows the user interface for ibm ence summarizer
users interact with the tem by posing natural language queries or by using lters on the metadata elds such as ference venue year and author or entities e

tasks
user experience is an tant usability factor
thus our ui provides dicators to help users explore and understand sults
specically associating a comprehensive structure with each result allows users to navigate inside content in a controlled manner each tion shows clearly the elements that are computed by the system section summary detected entities
and the elements that are directly extracted from the original paper
this clear distinction lows users to have visibility into the systems tributions flavian et al

ingestion pipeline our from system contains papers arxiv
org computer science subset and the clarity more related works are referred to in the ious sections of this paper
this case there is no user query
documents entities queryqueryanalysis enrichmentquery querysummarypdfjsontext tables figures extractionmetadata enrichmententity figure ibm science summarizer ui
acl
the ingestion pipeline consists of paper acquisition extracting the paper s text tables and gures and enriching the paper s data with various annotations and entities
paper parsing
we use science to tract the pdf text tables and gures
parse outputs a json record for each pdf which among other elds contains the title abstract text metadata such as authors and year and a list of the sections of the paper where each record holds the section s title and text
we have merged sub sections into their containing sections and this resulted in about merged sections per article e

see fig

science parse also supports tracting gures and tables into an image le as well as caption text
in addition we detect gure and table ences in the extracted text
we extract tasks datasets and metric see details below
finally we use to index the papers where for each paper we index its title abstract text tions text and some metadata
removed duplication between the two by using card similarity on the titles and authors

com allenai science parse
elastic
co entities extraction
entities in our system are of three types task e

question answering e


and metric e


we utilize both a dictionary based proach and learning based approach as follows
first we adopted the manual curated dictionaries of
since those dictionaries may not cover all evolving topics we further developed a module that automatically extracts entities
ferently from previous work on information traction from scientic literature which mainly cused on the abstract section gabor et al
luan et al
we analyze the entire paper and extract the above three types of entities that are related to the paper s main research ndings
we cast this problem as a textual entailment task we treat paper contents as text and the targeting dataset metric tdm triples as hypothesis
the textual entailment approach forces our model to focus on learning the similarity patterns between text and various triples
we trained our ule on a dataset consisting of papers in the nlp domain and it achieves a macro score of
and a micro score of
for predicting tdm triples on a testing dataset containing papers hou et al

in total our system dexed tasks datasets and metrics from the entire corpus
summarization this module generates a concise coherent mative summary for a given scientic paper that covers the main content conveyed in the text
the summary can either be focused around a query or query agnostic a generic
tic papers are complex they are long structured cover various subjects and the language may be quite different between sections e

the duction is quite different than the experiments tion
to ensure our summarizer assigns sufcient attention to each of these aspects we have opted to generate a standalone summary for each section
this way we summarize a shorter more focused text and the users can navigate more easily as they are given the structure of the paper
each of these section based summaries are eventually composed together into one paper summary
scientic papers summarization goes back more than thirty years
some of these works cus on summarizing content paice paice and jones while others focused on citation sentences citation aware summarization elkiss et al
qazvinian and radev jbara and radev
recently yasunaga et al
released a large scale dataset net including summaries produced by humans for over scientic papers using solely the pers abstract and citations
while citations data encompasses the impact of the paper and views from the research community it is not available for newly published papers and tends to lead to high level and shorter summaries scisumm net average summary length is words
we opted to focus on more extensive detailed summaries which do not rely on citations data
as mentioned above the inputs to the summarization module are an optional query and entities task dataset metric and the relevant papers returned by the see fig

given a retrieved per and the optional query q or entity we scribe next how a summary is produced for each section d in the paper
if present q can either be query handling
short and focused or verbose
if short it is panded using query expansion xu et al

this pseudo relevance feedback transforms q into a prole of unigram terms obtained from alyzing the top papers that are returned from our corpus as a response to the given query
tively in the case of a verbose query a fixed point term weighting schema paik and oard is applied in order to rank the terms of the query
alternatively if only ltering is applied and there is no query the keyphrases of the paper are extracted and used as a surrogate for the query
in this case all keywords in the generated query are given the same weight
pre processing
sentences are segmented ing the nltk library and each sentence is enized lower cased and stop words are removed
then each sentence is transformed into a grams and bi grams bag of words representations where each n gram is associated with its relative frequency in the text
summarization algorithm
in general maries can either be extractive or an abstractive
in the extractive case a summary is generated by selecting a subset of sentences from the original input
abstractive summarizers on the other hand can also paraphrase input text
in many cases tractive summarization generates grammatical and focused summaries while abstractive techniques require heavy supervision are limited to short documents and may transform meaning gambhir and gupta
in our system summarization is applied on d using a state of the art unsupervised tive query focused summarization algorithm spired by feigenblat et al
whose details are briey described as follows
the algorithm gets a paper section a natural language query q a desired summary length in our case and a set of entities associated with the query eq
the output s is a subset of sentences from d selected through an unsupervised mization scheme
to this end the sentence subset selection problem is posed as a multi criteria mization problem where several summary quality objectives are be considered
the selection is tained using the cross entropy ce method binstein and kroese
optimization starts by assigning a uniform importance probability to each sentence in d
then ce works iteratively and at each iteration it samples summaries ing a learnt distribution over the sentences and that in order to optimize the response time the leave the study of variable length section summaries duction system currently offers query agnostic summaries
for future work
evaluates the quality of these summaries by ing a target function
this function takes into count several quality prediction objectives which for simplicity are multiplied together
the ing process employs an exploration exploitation trade off in which the importance of a sentence is a fusion between its importance in previous tions and its importance in the current one
the following ve summary quality tors are used by feigenblat et al
query saliency entities coverage diversity text coverage and sentence length
query saliency measures to what extent the summary contains query related terms as expressed by the cosine similarity tween the unigrams bag of words representation of the summary and the query terms
entities erage measures to what extent the set of entities identied in a summary shares the same set of tities with eq measured by the jaccard ity between the sets
the aim of this objective is to produce a summary that is more aligned with the information need provided explicitly as a lter specied by the user or implicitly learnt from the query terms
diversity lays towards summaries with a diverse language model using the entropy of the unigrams bag of words representation of the summary
text coverage measures the summary coverage of d as measured by cosine similarity between the bi gram bag of words representation of a summary and d
finally the length tive biases towards summaries that include longer sentences which tend to be more informative
human evaluation ibm science summarizer summarization paradigm is section based i
e
each section is summarized independently and then all sections summaries are combined into the paper s mary
in order to evaluate this paradigm we approached authors from the nlp community and asked them to evaluate summaries of two papers that they have co authored preferably as the rst author
for each paper we generated the section based two summaries of two types summary as described above and a second summary generated using the same algorithm but ignoring sections i
e
treating the paper content as at text a section agnostic summary
for the section based summary each section s summary length was xed to sentences
the length of the section agnostic summary was dened as the length of the section based summary
in total papers and summaries were evaluated
tasks
the authors evaluated summaries of each summary type section agnostic and section based in random order by performing the following tasks per summary for each sentence in the summary we asked them to indicate whether they would consider it as a part of a summary of their paper i
e
precision oriented measure we asked them to evaluate how well each of the tions of the paper is covered in the summary i
e
coverage recall and we asked them to ally evaluate the quality of the summary
for tasks and we used a scale ranging from very bad to excellent means good
analysis
the objective of the analysis is to nd quantitative scores for each summary type to cilitate a comparison between them
for task for each paper we calculated the precision scores of the two summary types and then computed the average score for each summary type across all papers
for task we calculated an average score for each paper and summary type by aging over the sections scores
then we obtained the average of these scores for each summary type across all papers
finally for task we simply averaged the scores given by the authors to each summary type
to further quantify the evaluation we analyzed how well each summary type did for each of the tasks
for that we counted the ber of times that each summary type scored better than the other and then divided by the total ber of papers to obtain the wins
results
table summarizes the results across the tasks
for example for task for of the papers the section based summary was scored higher while for the section agnostic mary was scored higher for of the papers the summaries were scored equally
the average score for section based summaries was
with standard deviation of

notably the quality of the section based summaries signicantly performs the section agnostic summaries on all tasks supporting our proposed paradigm
conclusion we presented ibm science summarizer the rst system that provides researchers a tool to tematically explore and consume summaries of scientic papers
as future work we plan to add task section agnostic section based wins avg
score std wins avg
score std











table tasks results for section agnostic and based
the results were signicant with p

the results were signicant with p

support for additional entities e

methods and to increase our corpus to include more papers
nally we plan to provide this tool to the nity as an open service and conduct an extensive user study about the usage and quality of the tem including automatic evaluation of the maries
references amjad abu jbara and dragomir radev

herent citation based summarization of scientic pers
in proceedings of the annual hlt hlt pages
association for computational linguistics
aaron elkiss siwei shen anthony fader gunes erkan david states and dragomir radev

blind men and elephants what do citation maries tell us about a research article j
am
soc
inf
sci
technol

alexander fabbri irene li prawat trairatvorakul jiao he weitai ting robert tung caitlin ereld and dragomir radev

tutorialbank a manually collected corpus for prerequisite chains survey extraction and resource recommendation
in proceedings of the acl pages
guy feigenblat haggai roitman odellia boni and david konopnicki

unsupervised focused multi document summarization using the in proceedings of the cross entropy method
international acm sigir pages
carlos flavian raquel gurrea and carlos orus

web design a key factor for the website success
journal of systems and information technology
kata gabor davide buscaldi anne kathrin mann behrang qasemizadeh hafa zargayouna and thierry charnois

task semantic relation extraction and classication in in proceedings entic papers
hlt pages
mahak gambhir and vishal gupta

recent matic text summarization techniques a survey
tif
intell
rev

yufang hou charles jochim martin gleize francesca identication bonin and debasis ganguly

of tasks datasets evaluation metrics and numeric scores for scientic leaderboards construction
ume

rahul jha reed coke and dragomir radev

surveyor a system for generating coherent survey articles for scientic topics
in proceedings of the twenty ninth aaai pages
wang jie zhang chengzhi zhang mengying and deng sanhong

citationas a tool of matic survey generation based on citation content
journal of data and information science
yi luan luheng he mari ostendorf and hannaneh hajishirzi

multi task identication of ties relations and coreference for scientic edge graph construction
in proceedings of emnlp pages
c
d
paice

the automatic generation of ture abstracts an approach based on the tion of self indicating phrases
in proceedings of the annual acm sigir sigir pages
chris d
paice and paul a
jones

the cation of important concepts in highly structured technical papers
in proceedings of the annual international acm sigir sigir pages new york ny usa
acm
jiaul h
paik and douglas w
oard

a point method for weighting terms in verbose mational queries
cikm pages new york ny usa
acm
vahed qazvinian and dragomir r
radev

entic paper summarization using citation summary networks
in proceedings of the international conference on computational linguistics volume coling pages
reuven y
rubinstein and dirk p
kroese

the cross entropy method a unied approach to combinatorial optimization monte carlo tion
springer verlag berlin heidelberg
mayank singh pradeep dogga sohan patro raj barnwal ritam dutt rajarshi haldar pawan goyal and animesh mukherjee

cl scholar the acl anthology knowledge graph miner
in ceedings of the naacl
yang xu gareth j
f
jones and bin wang

query dependent pseudo relevance feedback based on wikipedia
in proceedings of the tional acm sigir pages
michihiro yasunaga jungo kasai rui zhang der richard fabbri irene li dan friedman and dragomir r
radev

scisummnet a large notated corpus and content impact models for tic paper summarization with citation networks
in aaai

