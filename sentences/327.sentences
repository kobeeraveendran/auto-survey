p e s l c
s c v
v i x r a podsumm podcast audio summarization aneesh vartakavi and amanmeet garg gracenote inc
the diverse nature scale and specificity of podcasts present a unique challenge to content discovery systems
listeners often rely on text descriptions of episodes provided by the podcast creators to discover new content
some factors like the presentation style of the narrator and production quality are significant indicators of subjective user preference but are difficult to quantify and not reflected in the text descriptions provided by the podcast creators
we propose the automated creation of podcast audio summaries to aid in content discovery and help listeners to quickly preview podcast content before investing time in listening to an entire episode
in this paper we present a method to automatically construct a podcast summary via guidance from the text domain
our method performs two key steps namely audio to text transcription and text summary generation
motivated by a lack of datasets for this task we curate an internal dataset find an effective scheme for data augmentation and design a protocol to gather summaries from annotators
we fine tune a model with our augmented dataset and perform an ablation study
our method achieves rouge l scores of


on our dataset
we hope these results may inspire future research in this direction
ccs concepts information systems speech audio search computing methodologies cross validation applied computing sound and music computing
additional key words and phrases podcasts speech summarization neural networks introduction the recent surge in popularity of podcasts presents a big opportunity and a unique set of challenges to existing content discovery and recommendation systems
podcasts usually require active attention from a listener for extended periods unlike listening to music
subjective attributes such as the speaker s presentation style type of humor or the production quality could influence the listener s preference but are hard to discern from a text description
in the video domain movie trailers allow a viewer to preview some content and make a subjective decision to watch a film
the frequent release schedule for podcasts would make the production of such trailers for each episode impractical
audio summaries have shown promise in improving the performance of spoken document search algorithms
we propose a method to create short podcast audio summaries in an automated manner
such summaries could inform the listener about the topics of the podcast as well as subjective attributes like presentation style and production quality
podcasts present a unique set of challenges for an audio based summarization algorithm
for example podcasts usually focus on spoken word content and often contain overlapping speech from multiple speakers free form speech audio effects background music and advertisements
a supervised learning algorithm operating in the audio domain would have to identify the nature of an audio segment before being able to judge its importance
this would require a large amount of training data manually annotated by listening to the audio in multiple passes which is a difficult and time consuming process
however as podcasts largely contain spoken word content summarization can also be performed in the text domain on the transcript of an episode
in this work we present our summarization podsumm method to obtain podcast audio summaries guided by the text domain
podsumm works by first transcribing the spoken content of a podcast then identifying important sentences in the transcript and finally stitching together the respective audio segments
we introduce a protocol and create an internal dataset specific to this task
in summary we introduce the both authors contributed equally to this research
concept of podcast audio summaries to aid in content discovery
these summaries allow a listener to rapidly preview an episode before investing time in listening to the entire episode
vartakavi and garg related work
text summarization neural models consider this task as a classification problem where a neural encoder creates a latent representation of the sentences followed by a classifier scoring the sentences on their importance towards creating a summary
with the rising popularity of deep neural networks and transformers pre trained language models particularly transformer models such as bert have shown promise in a wide range of nlp tasks
bert can express the semantics of a document and obtain a sentence level representation
recent approaches to text summarization like presumm and matchsum leverage bert and achieve state of the art performance on many benchmark datasets
these present a promising avenue for further development and expansion to other application domains

speech summarization speech summarization requires directly processing audio streams and providing snippets to create a combined audio summary
prior solutions to this task have modelled this problem as a feature classification problem speech text co training problem and graph clustering problem
neural extractive summarization such as reinforcement learning hierarchical modeling and sequence to sequence modeling have shown promising results though on a limited variety of data
automated speech summarization has many open research problems such as multi party speech spontaneous speech handling disfluencies and more

podcast summarization there has been limited research on automated methods for podcast audio summarization
the diversity and narrative nature of podcasts with spontaneous speech music audio effects and advertisements may present challenges for existing speech summarization methods
to address this issue we pose the podcast audio summarization problem as multi modal data summarization where we create an audio summary of a podcast with guidance from the text domain
our method
podsumm architecture the podsumm method comprises a sequence of steps starting with the original audio stream and resulting in an audio summary obtained as an output figure
the first stage of the process is automatic speech recognition asr which generates a transcript
we then process the text to segment each podcast transcript into sentences
subsequently we use a fine tuned text summarization model to select important sentences for inclusion in the final summary
we discuss each stage in detail below


automatic speech recognition
asr methods perform the task of speech to text transcription
they handle complexities related to varied accents prosody and acoustic features and speaker demographics
the quality of asr transcriptions varies significantly and depends on the underlying training data
we leveraged a publicly available podsumm podcast audio summarization fig

block diagram of the podsumm method and its modules
off the shelf solution aws transcribe which allowed us to limit errors and focus on other core modules our pipeline


text processing
the audio transcripts obtained in section

above contain tuples of text for individual words or punctuation marks the start and end timestamps from the audio and a confidence score for the text prediction
we use spacy to segment the text into sentences and their corresponding start and end times in the audio
additionally we force a sentence break where a pause of over seconds between words occurs
this helps us to better handle the cases where the asr method missed a punctuation mark which frequently occurs when music is played between speech segments


text summary generation
we then build text summaries by selecting appropriate sentences from the transcript by leveraging advances in the field of extractive text summarization
we choose the presumm model which builds upon bert to obtain a sentence level encoding and stacks inter sentence transformer layers to capture document level features for summarization
we find that a presumm model pre trained on the cnn dailymail dataset does not produce adequate summaries for podcasts
motivated by the lack of research datasets for this task we created a dataset to further fine tune the model for podcasts described in section

the extractive presumm model performs summarization on a document with sentences


sentm by assigning a score yi to each senti indicating exclusion from or inclusion in the summary
the model is trained using a binary classification entropy loss to capture difference in prediction yi and ground truth label yi

amazon
com
io usage linguistic

audio generation
the predictions of the text summarization model include the sentence indices and respective scores
using the stored sentence offsets the audio representing the selected sentences are stitched together to obtain vartakavi and garg an audio summary

dataset creation to address the lack of datasets for the task of podcast summarization we curate a dataset to support the development and evaluation of our method
we selected unique podcast series from different genres selecting on average

episodes per series
the dataset contains a total of hours of podcasts with an average duration of

minutes per episode
we built an annotation tool that presented the annotator with a sequence of sentences from the transcript of the episode as well as the metadata from the podcast feed including the original audio of the episode
each sentence was paired with the respective audio segment derived using the offsets of each segment
additionally the annotation tool dynamically generated audio and text summaries based on annotator s selection enabling them to verify their choices
the annotator was instructed to follow the protocol outlined below
read the provider submitted description if available or listen to the audio of the podcast episode to understand the context and core message
select the set of sentences that represent the summary of the podcast
the raters were requested to select continuous sequences of sentences where possible to minimize cuts in the audio while keeping the total summary listen to the newly created sentence summary and repeat the above steps if necessary
submit the annotations length within seconds
when a satisfactory summary is obtained
the resulting annotations include a set of sentence indices selected by the annotator as the most suitable candidates to create a summary
due to resource limitations each episode was annotated by a single annotator due to which we are unable to compute the inter annotator agreement
discarding some outliers we find that it took minutes seconds minutes seconds to annotate a single episode
we collected a total of episodes with an average of

selected sentences per summary

model training we begin with a presumm model pre trained on the cnn dailymail dataset for steps provided by the authors who report strong performance l


we then fine tune the model on our podcast dataset for steps as described in beyond we noticed overfitting on our training set
the pre trained model allows position embeddings of length which we deemed sufficient for our application as the annotations in our dataset were contained within the first tokens even for longer episodes
model checkpoints were saved and evaluated on the test set for every steps
the best performing model checkpoint was used for ablation experiments and to report system performance
for predicting summaries on new unseen data we obtain the predicted scores for each sentence
subsequently top n sentences are selected from the rank ordered candidates to create the final summary

com nlpyang presumm podsumm podcast audio summarization
evaluation metrics n l

cross validation experiment was repeated for each fold

data augmentation we report the precision recall and f measure for the rouge l scores
the metrics were selected to measure the ability of the model to produce summaries with overlapping words in comparison to the reference recall the prediction precision and average f measure
the n in the rouge n metric signifies the unigram word overlap bigram consecutive word overlap and longest common sequence overlap our current dataset consists of a total of podcast episodes
this number is small in comparison to datasets such as cnn dailymail data label pairs
to mitigate the effect of sampling bias we report the mean and standard deviation of the rouge metrics from a k fold cross validation experiment
the model was trained on the training split or samples and performance reported on the test split or episodes and the process we perform data augmentation to compensate for the relatively small size of our dataset and increase the generalization ability of the model
we observe that most previews and advertisements which should not be included in a summary are similar across podcasts episodes
we here describe a method to automatically find segments of repetitive content and our augmentation procedure
we first find the indices of the sentences in the transcript that also occur in other episodes across our dataset e


we then clean up the indices to merge any near by indices with into one large set and to remove any outliers
all such repetitive content segments are stored for use in augmentations
to generate an augmented output if an episode has repetitive content we replace else we prepend the transcript with a randomly selected repetitive segment to create a new data sample
for each transcript we add new samples for the total augmented data size of samples for the training set for each fold

ablation studies

effect of number of candidate sentences
similar to presumm we select the top n sentences with the highest scores as our predictions
we study the effect of varying the number of sentences selected to represent the summary from the rank ordered candidates in the model prediction
in our experiment n was varied and the l scores are reported


effect of data augmentation
the data augmentation applied during training alters the repetitive content preceding the sentences relevant to the summary
to test the effect of the data augmentation scheme on the model performance we performed a fine tuning experiment with and without data augmentation and report the system performance metrics
results we summarize our results and ablation studies in table
as outlined in section
we report the mean and standard deviation of the f measure for the metrics over the fold cross validation experiment
similar to prior work we use a simple baseline lead n where we select the n leading sentences from the document as a summary

com abisee cnn dailymail vartakavi and garg metric baseline fine tuning presumm no ft k presumm ft k presumm ft aug k ablation k sentences presumm presumm presumm presumm rouge l

































































table
results for the baseline fold cross validation experiment and ablation experiments for the presumm method
the f measure for l metrics for pre trained presumm model and the model fine tuned with podsumm dataset reported on the test set for each fold
summary statistics for each metric reported as mean std
dev
over the folds
we find that performs well only slightly worse than a presumm model pre trained on the cnn dailymail dataset with no fine tuning
after fine tuning on our dataset presumm ft k we find significant improvements in f measure for all l metrics over the baseline and the model with no fine tuning
the model with augmentation presumm ft aug k further improves performance demonstrating that model performance on this task improves with even a small amount of task specific data augmentation
in the ablation study we find that selecting the top sentences produced the best results compared to or
we display the distribution of sentence indices in figure
the ground truth data distribution indicates that the initial sentences with less related to the podcast summary task which is corroborated by the relatively high performance of the baseline relative to other lead or scores
we also see that the model without fine tuning ft is biased to select sentences from the beginning of the document which is likely a property of the cnn dailymail dataset
the distributions after fine tuning ft ft aug are closer to the ground truth distributions which are reflected in the metrics
however the tails of these models still appear to follow the distribution model without fine tuning
this highlights the need for further analysis and model development on a large dataset to account for all possible variations of the underlying data
we present an example transcript along with the model predictions for presumm no ft k in table and presumm ft aug k in table
the former model with no fine tuning selects a lot of sentences that are not relevant to the episode
in table we see true positive sentences in green false positive sentences in blue and false negative in red sentences repeated content sentences in magenta of which were falsely predicted by the model in cyan
this demonstrates that our method is able to correctly identify important sentences from the podcast transcription
the transcript also shows some errors that have accumulated through the system eg
variations in spoken words
org mistranscribed as dot org incorrect sentence segmentation between it is p
m
and on
errors like these can complicate any downstream text processing for example a reader may only identify false positive sentences in the above example whereas the system identified due to incorrect sentence segmentation
podsumm podcast audio summarization fig

selected sentence index vs
the normalized count over all sentences in dataset in the ground truth predictions from presumm no ft fine tuned presumm ft and fine tuned presumm with aug hey there real quick before we start the show
california
we are coming your way for a live show next month on february we are super excited to finally get to come to southern california
we will be in oaks with k c
l
you talking about the race and more to get your tickets head over to npr prisons dot org
oh and if you re in iowa we have a show there tomorrow night friday night and there are still a few tickets available
okay here s the show
hey there it s the npr politics podcast
it is p
m
on january
i m tamara keith
i cover the white house
i m aisha roscoe
i also cover the white house and i m susan davis
i cover congress
senate will convene as a court of impeachment today
the senate impeachment trial is continuing with more questions and answers senators asking questions the house managers and the president s legal team answering those questions
and in fact as we take this the q and a is still going on so things could happen
that s why we do a time stamp
um aisha i m wondering what stood out to you about today well a lot of what the questions seem to be about was getting at this idea of
is there a limit to what a president can do to get re elected because one of the president s lawyers representing him alan dershowitz made this argument that most presidents think their re election is in the public interest
and therefore if they take actions to kind of help their reelection as long as it s not illegal it s ok
and it really seemed like the senators were probing the limits of how far that argument can go on
table
presumm no ft k output with correct predictions in green false negatives in red and false positive sentences in blue
sentences detected as repetitive content magenta and also falsely predicted by the model cyan discussion in this work we proposed podsumm a method to automatically generate audio summaries of podcasts via guidance from the text domain
the method involves transcribing the audio followed by some text processing and text summarization
an audio summary is then generated by stitching the audio segments that correspond to the sentences selected by the text summarization
the resulting model fine tuned on our dataset performed better than a lead n baseline and a model trained on the cnn dailymail dataset
as our method contains a sequence of steps the performance of each module directly influences the final produced audio summaries
in this paper we heavily leverage prior work in different fields we believe custom modules would bring significant advantages
for example a sentence segmentation model that is robust to transcription errors or missing punctuation due to background music would allow us to leverage cheaper less accurate asr solutions
further research is needed to develop and understand the effects of the individual modules specific to podcasts








truthno ftftft aug vartakavi and garg hey there real quick before we start the show
california
we are coming your way for a live show next month on february we are super excited to finally get to come to southern california
we will be in oaks with k c
l
you talking about the race and more to get your tickets head over to npr prisons dot org
oh and if you re in iowa we have a show there tomorrow night friday night and there are still a few tickets available
okay here s the show
hey there it s the npr politics podcast
it is p
m
on january
i m tamara keith
i cover the white house
i m aisha roscoe
i also cover the white house and i m susan davis
i cover congress
senate will convene as a court of impeachment today
the senate impeachment trial is continuing with more questions and answers senators asking questions the house managers and the president s legal team answering those questions
and in fact as we take this the q and a is still going on so things could happen
that s why we do a time stamp
um aisha i m wondering what stood out to you about today well a lot of what the questions seem to be about was getting at this idea of
is there a limit to what a president can do to get re elected because one of the president s lawyers representing him alan dershowitz made this argument that most presidents think their re election is in the public interest
and therefore if they take actions to kind of help their reelection as long as it s not illegal it s ok
and it really seemed like the senators were probing the limits of how far that argument can go on
at one point there was a question from senator susan collins from maine a republican and and a few other republicans including senators crepeau blunt and rubio
and remember all of the questions are submitted in writing to the chief justice who then reads them aloud
table
presumm ft aug k output with correct predictions in green false negatives in red and false positive sentences in blue
sentences detected as repetitive content magenta and also falsely predicted by the model cyan although our proposed method showed improved performance after fine tuning on our dataset we recognize that its smaller size may restrict the generalization ability of the model on unseen data
manual annotation of a large corpus of podcast data for this task is prohibitively expensive but techniques like data augmentation could alleviate these to some extent
conclusion acknowledgments media technology lab at gracenote
references we present a novel method to create audio summaries for podcasts via guidance from the text domain and discuss the strengths and limitations
this work establishes the proof of working principle and sets direction for future development into a fully learned and automated method for podcast speech summarization
we look forward to newer methods emerging from the research community leading to an improved listener experience
the authors thank josh morris for his counsel chinting ko for his guidance on asr joseph renner jeff scott gannon gesiriech and zafar rafi for their feedback on the manuscript and the contributions of the our team members at the jacob devlin ming wei chang kenton lee and kristina toutanova

bert pre training of deep bidirectional transformers for language understanding
in proceedings of the conference of the north american chapter of the association for computational linguistics human language technologies volume long and short papers

mattia antonino di gangi robert enyedi alessandra brusadin and marcello federico

robust neural machine translation for clean and noisy speech transcripts
arxiv preprint

sadaoki furui t kikuichi yousuke shinnaka and chiori hori

speech to speech and speech to text summarization
in first international workshop on language understanding and agents for real world interaction
citeseer
nikhil garg benoit favre korbinian reidhammer and dilek hakkani tr

clusterrank a graph based method for meeting summarization
in tenth annual conference of the international speech communication association

podsumm podcast audio summarization awni y
hannun carl case jared casper bryan catanzaro greg diamos erich elsen ryan prenger sanjeev satheesh shubho sengupta adam coates and andrew y
ng

deep speech scaling up end to end speech recognition
arxiv

karl moritz hermann tom koisk edward grefenstette lasse espeholt will kay mustafa suleyman and phil blunsom

teaching machines to read and comprehend
in proceedings of the international conference on neural information processing systems volume montreal canada
mit press cambridge ma usa
yaser keneshloo tian shi naren ramakrishnan and chandan k reddy

deep reinforcement learning for sequence to sequence models
ieee transactions on neural networks and learning systems
chin yew lin

rouge a package for automatic evaluation of summaries
in text summarization branches out
association for computational linguistics barcelona spain

aclweb
org anthology tzu en liu shih hung liu and berlin chen

a hierarchical neural summarization framework for spoken documents
in icassp ieee international conference on acoustics speech and signal processing icassp
ieee
yang liu and mirella lapata

text summarization with pretrained encoders
in proceedings of the conference on empirical methods in natural language processing and the international joint conference on natural language processing emnlp ijcnlp

ramesh nallapati feifei zhai and bowen zhou

summarunner a recurrent neural network based sequence model for extractive summarization of documents
in proceedings of the thirty first aaai conference on artificial intelligence san francisco california usa
aaai press
abigail see peter j
liu and christopher d
manning

get to the point summarization with pointer generator networks
corr



org
damiano spina johanne r trippas lawrence cavedon and mark sanderson

extracting audio summaries to support effective spoken document search
journal of the association for information science and technology
ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser and illia polosukhin

attention is all you need
in advances in neural information processing systems

yuxiang wu and baotian hu

learning to extract coherent summary via deep reinforcement learning
in thirty second aaai conference on shasha xie hui lin and yang liu

semi supervised extractive speech summarization via co training algorithm
in eleventh annual conference artificial intelligence
of the international speech communication association
xingxing zhang mirella lapata furu wei and ming zhou

neural latent extractive document summarization
in proceedings of the conference on empirical methods in natural language processing

ming zhong pengfei liu yiran chen danqing wang xipeng qiu and xuanjing huang

extractive summarization as text matching
arxiv preprint


