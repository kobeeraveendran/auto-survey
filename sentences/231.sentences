efciency metrics for data driven models a text summarization case study erion ano institute of formal and applied linguistics charles university prague czech republic
mff
cuni
cz ondrej bojar institute of formal and applied linguistics charles university prague czech republic
mff
cuni
cz p e s l c
s c v
v i x r a abstract using data driven models for solving text summarization or similar tasks has become very common in the last years
yet most of the studies report basic accuracy scores only and nothing is known about the ability of the proposed models to improve when trained on more data
in this paper we dene and pose three data efciency metrics data score efciency data time deciency and overall data efciency
we also propose a simple scheme that uses those metrics and apply it for a more comprehensive evaluation of ular methods on text summarization and title generation tasks
for the latter task we cess and release a huge collection of million abstract title pairs from scientic articles
our results reveal that among the tested models the transformer is the most efcient on both tasks
introduction text summarization is the process of distilling the most noteworthy information in a document to produce an abridged version of it
this task is earning considerable interest since shorter sions of long documents are easier to read and save us time
there are two basic ways to marize texts
extractive summarization selects the most relevant parts of the source document and combines them to generate the summary
in this case the summary contains exact copies of words or phrases picked from the source
abstractive summarization on the other hand paraphrases the information required for the summary instead of copying it verbatim
this is usually better but also more complex and harder to achieve
there has been a rapid progress in ats stractive text summarization over the last years
the vanilla encoder decoder with bidirectional lstms hochreiter and schmidhuber is now enhanced with advanced mechanisms like tention bahdanau et al
which has been it allows the model to focus widely embraced
on various parts of the input during the ation phase and was successfully used by rush et al
to summarize news articles
pointing copying is another mechanism that helps to leviate the problem of unknown words gulcehre et al
gu et al

moreover coverage tu et al
and intra attention paulus et al
were proposed and utilized to avoid word repetitions producing more readable summaries
rl reinforcement learning concepts like policy gradient rennie et al
were recently bined into the encoder decoder architecture viating other problems like train test inconsistency and exposure bias paulus et al
chen and bansal
all these developments helped to boost the ats rouge lin scores from about in rush et al
to about in paulus et al

this is an increase of roughly in the last three years
yet all the studies evaluate the methods using datasets of a xed size
ing so they tell us nothing about the expected of the models when trained with more data
moreover training time is rarely reported
we believe that this evaluation practice of driven models is incomplete and data efciency metrics should be computed and reported
in this paper we propose three data efciency metrics namely data score efciency data time deciency and overall data efciency
the rst two represent the output quality gain and the ing time delay of the model per additional data samples
the third is the ratio between them and reects the overall efciency of the models w

the training data
we also suggest a simple scheme that considers several values for each of the above metrics together with the basic accuracy score use performance solely for the output quality not the time needed to train the model or obtain the output
stead of reporting only the latter
the proposed scheme and the metrics can be used for a more tailed evaluation of supervised learning models
using them we examine various recently text posed methods in two tasks tion using the popular cnndm cnn daily mail nallapati et al
dataset and title tion of scientic articles using oags a novel dataset of abstract title pairs that we processed and released
according to our results the performing and fastest methods in the two datasets are those of paulus et al
and chen and bansal
regarding score and time ciency transformer vaswani et al
is tinctly superior
in the future we will examine the transformer model on more data with different rameter setups
applying our evaluation scheme to related tasks such as mt machine translation could also be benecial
overall this work brings the following main contributions we dene and propose three data efciency metrics and a simple evaluation scheme that uses them for a more comprehensive tion of data driven learning methods
we use the scheme and metrics to benchmark some of the most recently proposed ats methods and discuss their training times rouge and data efciency scores
finally a huge collection of about million scientic paper abstracts and titles is pared and released to the community
to our best knowledge this is the largest data collection pared for title generation experiments
data efciency metrics
related work training data efciency of the data driven ing models is little considered in the literature
an early work is that of lawrence et al
who investigate the generalization ability of neural works with respect to the complexity of the proximation function the size of the network and in the the degree of noise in the training data
case of latter factor they vary the size of the ing data and the levels of gaussian noise added to those data concluding that ensemble techniques are more immune to the increased noise levels
performance variations w

t the training data sizes are not considered though
al jarrah et al
review the research erature focusing in the computational and energy
handle
efciency of the data driven methods
they ticularly consider data intensive application areas e

big data computing and how sustainable data models can help for a maximal learning curacy with minimal computational cost and cient processing of large volumes of data
boom et al
examine a character level rnn recurrent neural network used to predict the next character of a text given the previous put characters
they assess the evolution of the network performance in terms of perplexity in four train and prediction scenarios as a function of the training time and input training sequences
cording to their results the efciency of the model is considerably inuenced by the chosen scenario
a similar experiment is conducted by riou et al
who explore reinforcement learning cepts on the task of neural language generation
they compare different implementations reporting not only performance scores but also their tion as a function of the cumulated learning cost and the training data size
the most relevant work we found is the one by hlynsson
al
who propose an mental protocol for comparing the data efciency of a cnn convolution neural network with that of higsfa hierarchical information preserving graph based slow feature analysis
they give an informal denition of data efciency ering it as performance as a function of training set size
three character recognition challenges are dened and the two methods are trained on increasing amounts of data samples reporting the corresponding accuracy scores

proposed data efciency metrics despite the experimental results and insights they bring the above studies are still task and method specic
moreover their computation schemes are not generic or transferable and no formalization of the data efciency is given
in this section we ne three novel and useful data efciency metrics
suppose we train a data driven method m on dataset d to solve task t and we test it based on performance score s
we also assume that the quality of the data samples in different intervals of d is homogeneous
in practice this could be achieved by shufing d before starting the iments
for a certain training data size d it takes t seconds to train the model until convergence i
e
until no further gains are observed with more training time and the score obtained by testing it on a standard and independent test dataset of a xed size is s
we expect that for a certain crease d of training samples fed to m it will quire an extra time t to converge and the ing model will attain an extra s score
we can thus dene and compute data score ciency score gain per additional data samples of method m as s d it is a measure of how smartly or effectively m terprets the extra data samples or how well its formance score scales w

t the training data
larly data time deciency the inverse of data time efciency of m will be t d this measures how slowly or lazily m interprets the additional samples
given two train and test runs original and enlarged datasets characterized by the above measures training data d d training times t t t achieved scores s s we dene the overall data efciency e as e s t it is a measure of how smartly and quickly the models of m utilizes the data of d on task t
in practice using the absolute increments s t and d may produce small values of which are hard to interpret and work with
more and e use training times which depend on the computing conditions e

hardware setups
as a result they are hardly reproducible across different computing environments
to overcome these limitations we can instead use the relative increments s s t t and d d computing the corresponding relative data efciency metrics as s s d d t t d d s s t t data time efciency d t should not be fused with the training throughput as dened by popel and bojar for machine translation which reects the time required for one model update given the additional data
our t is the increase in the overall training time till convergence on the enlarged dataset in comparison with the original one
these relative metrics and their values are cally easier to interpret and work with
more they are transferable or reproducible in ferent computing setups which is important for cross interpretation of the experimental results
we can express and values in percent and values as their ratio

assorted remarks the metrics presented above can be used to ate different data driven methods or compare eral parameter congurations of the same basic method algorithm neural network
and help us nd the optimal one
in this sense they are generic and task independent
however it is portant to note that they do not represent sal or global attributes of method m
they are stead linear approximations that can give us local characterizations of m in certain intervals of d
in other words high or values of m in some intervals of d do not necessarily assure a decent generalization of m
it is also important not to confuse the data ciency with performance or quality
in our daily intuition we often tend to consider highly cient machines techniques or methods as performing ones
instead according to the above denitions a model can perform poorly but still be highly efcient w

t the training data
this happens if its performance scores on increasing training data cuts are all very low but grow very quickly from one assessment to the next
a model can also yield high scores which grow very slowly on increasing data sizes thus relatively small and values
in this case it is a well performing maybe even the best model on those data but not a data efcient one
from the data efciency viewpoint the best models would obviously be those of higher data score efciency and lower data time deciency or higher overall data efciency
in practice mance is generally the most desired characteristic
as a result data score efciency values or both should be more important and worthy to port in most of the cases
since models are trained only once and should be less relevant
ertheless they might be useful from a technical or theoretical perspective
they can be used for paring different methods comparing different rameter congurations of a method or for trying run time optimizations
a comprehensive evaluation scheme since the sizes of the predictive models and the utilized datasets are consistently growing it comes more difcult and costly to use human pertise for the evaluation
the typical approach is to test automatically by means of standard datasets and scoring metrics which are popular
for ample in the case of text summarization task it is very common to nd evaluations of proposed methods using the full set of cnndm only ble in paulus et al
table in lin et al
table in see et al
and more
we believe there are serious shortcomings in this evaluation practice
testing only one model of a method trained on a xed size data split does not reveal anything about its score trend when fed with more data
it thus becomes hard to discern the overall best method out of a few that are pared in a fair and objective way especially if the achieved scores are similar
moreover ing time is rarely reported and nothing is known about the time efciency of the models
to overcome the above limitations we propose a more detailed evaluation scheme that considers accuracy scores together with the data efciency metrics dened in section

again suppose we have a dataset d of size d with homogeneous ing samples a standard performance score s and two methods a and b that we want to compare
the typical practice trains two single models a and b from a and b on entire d and reports accuracy scores and sb from the standard test set



instead we suggest to split d in n equal parts of


dn of


n n



an bn on


dn sa n and n from the same test set
from a of models ai


from size d n and form n intervals increasing sizes d n n this way we can train models and and compute their scores sb sb equation we also compute a i and sa using each two scores sa and together with b the b models






a


n and sb we can now report up to score values and relative data score efciency values
for conciseness we can limit in n of the two biggest models
also given the local nature of the efciency metrics it make sense to report values from dispersed data intervals like the leftmost a and and the most a
the rightmost values the middle a and b and b figure illustration of the schema application are probably more relevant for predicting the score trend on bigger training sizes
we can also pute and report the respective values or even the and values in a similar fashion using the other equations of section

getting back to a vs
b we can rst check n and sb if one of them is distinctly higher than n
the other comparing the values may not be sential
the real worth comes when sa n by contrasting the rightmost corresponding values a
a signicant difference of one against the other could suggest which of them will reach higher scores on a bigger training set
vs
n sb to illustrate we can see in figure two pothetical graphs that approximate the variations of sa and sb over d
we have n training size d and very similar performance scores sa
obviously sb grows faster than sa till but then the situation is reversed since
we can thus expect sa sb a for d which is what actually happens in this example sa and a sb b sb
using the traditional practice computing and sb only our verdict would be a and b form almost the same on d
instead using the above scheme we can conclude that a and b form almost the same on d but a will probably perform better than b if trained on more data
the scheme can be used to evaluate data driven ods with different scores on different tasks
in section we show the results we obtained by plying it to assess several advanced ats methods
text summarization datasets the tendency towards data driven methods based on neural networks has encouraged experiments with large text collections for various tasks
in the case of ats one of the rst big datasets was the annotated english gigaword napoles et al
rush et al
with over nine million news ticles and headlines processed using corenlp of m d n n c s g a o split valid test valid test rec k k k k k k srcl m
m k k tgtl k k k voc used k k k
m k
m k
m k table statistics of used datasets
for each split it shows the number of records rec average length of source and target texts in tokens srcl tgtl total cabulary size voc and the number of most frequent words that were used used
manning et al

each headline was paired with the rst sentence of the corresponding cle to create the training base for the experiments
is another mostly used as an evaluation baseline given its small size
it sists of document summary pairs curated by human experts
newsroom is a recent and geneous bundle of about
million news articles grusky et al

cnndm has become the most popular dataset for text summarization nallapati et al

it provides a large set of news articles and the responding multi sentence summaries unlike the three above that contain one sentence summaries only
it is thus more suitable for training and ing summarization models of longer texts
title generation task on the other hand requires data samples of shorter texts and one sentence tles
collections of abstracts and titles from tic articles are well suited for exploring it
is a collection of k records of scientic paper metadata title abstract and keywords presented by meng et al

the metadata belong to ticles of computer science from acm digital brary sciencedirect and web of science
the demand for more and more data has tivated initiatives that mine research articles from academic networks
one of them is arnetminer a system that extracts researcher proles from the web and integrates the data into a unied network tang et al

a byproduct of that work is the oag open academic graph collection sinha et al

to produce a big title generation dataset for our experiments we started from oag
first abstract
nist
gov title and language elds were extracted from each record where they were available
in many cases abstract language did not match the language eld
we ignored the latter and used a language er to remove records that were not in english
duplicates were dropped and the texts were ercased
finally stanford corenlp tokenizer was used to split title and abstract texts
the ing dataset oags released with this paper tains about million abstract title pairs and can be used for title generation experiments
we had a quick look at the content of oags and observed that most of the papers are from medicine
there are also many papers about cial sciences psychology economics or ing disciplines
given its huge size and the ical richness the value of oags is twofold it can be used to supplement existing datasets on title generation tasks when more training data are needed
it can be used for creating byproducts of specic scientic disciplines or domains
text summarization evaluation in this section we apply the relative metrics of section
and the evaluation scheme of section to benchmark several advanced methods on text summarization of news articles and title tion of scientic papers
we rst introduce the methods and their parameters together with the experimental data
later we present and discuss the achieved accuracy and data efciency scores

tested summarization methods the ability of recurrent neural networks to resent and process variable length sequences has created a tradition of applying them on to sequence tasks such as ats or mt
in the case of ats the goal is to process the source text ducing a target text that is shorter but still ingful and easy to read
rush et al
were probably the rst to plement attention in a network dedicated to ats
their model abs in the following uses an coder that learns a soft alignment attention tween the source and the target sequences ing the context vector
in the decoding phase it uses a beam search decoder dahlmeier and ng with a window of candidate words in each target position
there are and mensions in the hidden layer and word embedding layer respectively
the authors reported state the art results in the testing dataset
see et al
proposed pointer generator pcov a model that implements an based encoder for producing the context vector
the decoder is extended with a pointing copying mechanism gulcehre et al
gu et al
that is used in each step to compute a generation probability pgen from the context vector the coder states and the decoder output in that step
this generation probability is used as a switch to decide if the next word should be predicted or copied from the input
another extension is the coverage mechanism keeping track of decoder outputs for avoiding word repetitions in the mary a chronic problem of encoder decoder marizers tu et al

the method was mented with word embeddings and hidden layer of sizes and respectively
lin et al
tried a partial use of lutions in their model globen to avoid word repetitions and semantic irrelevance in the maries
they couple the encoder with a tional gated unit which performs global encoding of the source context and uses it to lter certain gram features and rene the output of the encoder in each time step
globen is a very big network about m parameters on cnndm with three layers in the encoder and other three in the coder each of dimensions
a taxonomy of the above and more to sequence methods and added mechanisms can be found in shi et al

authors present a detailed review of problems and proposed tions based on network structures training gies and generation algorithms
furthermore they develop and release a library nats that plements combinations of mechanisms like tion pointing and coverage analyzing their fects in text summarization quality
nats was plemented with the same network parameters as pcov
intra decoder attention and weight sharing of embeddings were added in the decoder
the introduction of the transformer trans architecture that removes all recurrent or lutional structures reduced computation cost and training time vaswani et al

totally based on attention mechanism and primarily designed for mt transformer can also work for text marization since all it needs to do is to learn the alignments between the input source texts and the output target summaries
positional ing is added to word embeddings to preserve the order of the input and output sequences
trans is the biggest model we tried with four layers in both encoder and decoder dimensions in each layer including the embedding layers k ing steps and warm up steps
two observed problems in the encoder decoder framework are the exposure bias and train test consistency keneshloo et al

to overcome them rl ideas have been recently applied
paulus et al
use intra attention to focus on ent parts of the encoded sequence
this way it is less likely for their model pgrl to attend to the same parts of input in different decoding steps and thus fewer word repetitions should appear in the summaries
to optimize for rouge or similar discrete evaluation metrics they implement critical policy gradient training with reward tion a rl mechanism introduced by rennie et al

pgrl was used with encoder and decoder of dimensions and word embeddings of dimensions
aiming for speed chen and bansal veloped an extractive abstractive text summarizer fastrl with policy based reinforcement
it rst uses an extractor agent to pick the most salient sentences or phrases instead of encoding the tire input sequence which can be long
it then uses an encoder decoder abstractor to rewrite press the sentences in parallel
actor critic icy gradient with reward function bahdanau et al
joins together the extractor and abstractor networks
same as most models above fastrl uses and dimensions for the recurrent layer and the word embeddings
in every experiment no pretraining of word embeddings was performed
they were learned during the training of each model
adam timizer kingma and ba was used with


and
we chose mini batches of size in most of the cases for globen and trans to avoid ory errors
all experiments were conducted on two nvidia gtx gpus

used data to cope with limited computing resources we used up to
m records in our oags ments
we also picked n for the scheme of section and created three splits of k m and
m samples each together with the three authors rush et al
see et al
shi et al
lin et al
vaswani et al
chen et al
paulus et al
model p m
m
m
m
m
m
m
m
m
m
m
m
m
m
m






cnndm rl




















tt




















p m
m
m
m
m
m
m
m
m



oags











rl











tt table parameters rouge scores and training times for each method on the splits of the two datasets e r o c s r abs pcov nats globen trans fastrl pgrl figure score trends of the three models of each method on cnndm left and oags right splits one third two thirds and full of cnndm
some statistics of the experimental data are shown in table
vocabulary sizes used in each ment are shown in its last column
the higher vocabulary sizes of oags splits cause a signicant difference in parameters tween the two corresponding models of each method
as we can see table transformer models grows from m in cnndm to m in oags
another difference between the two sets of experiments is in the maximal number of ing and decoding steps words in source and target texts
for cnndm we used and tively
for oags we chose and since per abstracts and titles should not be longer

summarization results rouge scores and training times in seconds on cnndm experiments are shown in the dle part of table
the most accurate models are pgrl and fastrl
they both implement policy based training and optimize w

rouge scores
the worst performer is abs and the other four fall somewhere in between reaching similar scores with each other
the score differences between each third model and rst one are usually small for all methods
we believe this has to do with the way rouge scores authors rush et al
see et al
shi et al
lin et al
vaswani et al
chen et al
paulus et al
models



























cnndm













l























































table data efciency scores of the models on cnndm experiments
x is computed based on the ing rx score
similarly is computed based on x and
authors rush et al
see et al
vaswani et al
paulus et al
models















l







oags































table data efciency scores of the models on oags experiments
x is computed based on the corresponding rx score
similarly is computed based on x and
are computed
a graphical representation of the trends for each method is depicted in figure left
and rl not shown behave similarly
results on oags are listed on the right side of table
we could not run some of the models on oags data
the extractive part of fastrl could not be easily adapted to perform word level extraction of oags abstracts
furthermore nats and globen ran out of memory very frequently
from the remaining four pgrl is again the most accurate
trans follows and abs is the weakest
score trends are shown in the figure right
regarding training speed on cnndm we can see that fastrl is absolutely the best with a siderable difference from the second pgrl
the slowest is globen with training times at least higher than those of fastrl
in fact it took more than ten days to train globen on the full cnndm data
oags training times are lower than cnndm ones although oags data splits are
times ger in number of training samples
this happens because oags source and target samples are ally much shorter
we see that pcov is the fastest and trans is the slowest

efciency results using equations and of section
we computed the relative efciency metrics for every method
the values for cnndm experiments are shown in table
we see that trans is clearly the most efcient with highest lowest and highest
its scores grow quickly despite being relatively low and training times grow slowly despite being high in both data intervals
pcov and globen manifest the slowest racy score gains lowest but globen comes second in time efciency
nats on the other hand is very time inefcient with highest and lowest
oags scores of table reect a similar tion
trans leads and pcov is again the worst
the values of the other two models appear where in between
it is not easy to explain the high score and time efciency of trans
globen is also time cient but not score efcient
both of them are the biggest highest number of parameters and est many layers networks we tried
the sive feature of trans is the lack of any recurrent structure
globen and the other ve make use of at least one rnn in a certain phase
it is still hasty to infer that recurrent networks hinder score efciency or that more attention boosts it
an intuitive explanation could be the fact that in general performance of deeper networks scales better with more data
it could also be that capacity networks are faster in interpreting large additions of training samples thus low
in fact using more layers and bigger training datasets is what has driven the progress of deep learning lutions in many application areas
we plan to investigate this issue further in the future
one step could be to run more experiments on even bigger data sizes and smaller data vals for checking at what point do accuracy scores keep growing
transformer implementations with varying number of layers and other parameter tups can be further examined
investigating data efciency of similar tions to tasks like qa question answering reia et al
with standard datasets such as squad rajpurkar et al
could also be valuable
conclusions in this paper we dened three data efciency rics for a better evaluation of data driven learning models
we also proposed a simple scheme for computing and reporting them in addition to the basic accuracy scores
text summarization and tle generation tasks were chosen as a case study to see what insights the proposed scheme and rics could reveal
for title generation we also cessed a dataset of about million scientic titles and abstracts released with this paper
we applied seven recent ats methods on the two tasks
according to our results the two ods that mix rl concepts into the encoder decoder framework are the fastest and the most accurate
a surprising result is the excellent efciency of the popular transformer model
as future work we want to perform similar studies in analogous tasks like mt or qa
we would also like to investigate more in depth the transformer model
acknowledgments this research work was supported by the project no
cz




national mobility of researchers at charles versity of the operational programme research development and education the project no
of the czech science dation and elitr of the eu
references o
y
al jarrah paul d
yoo sami muhaidat george k
karagiannidis and kamal taha

efcient machine learning for big data a review
corr

dzmitry bahdanau philemon brakel kelvin xu anirudh goyal ryan lowe joelle pineau aaron courville and yoshua bengio

an actor critic algorithm for sequence prediction
arxiv e prints

dzmitry bahdanau kyunghyun cho and yoshua neural machine translation by corr bengio

jointly learning to align and translate


cedric de boom sam leroux steven bohez pieter simoens thomas demeester and bart dhoedt

efciency evaluation of character level rnn training schedules
corr

yen chun chen and mohit bansal

fast tive summarization with reinforce selected sentence rewriting
in proceedings of the annual ing of the association for computational linguistics volume long papers pages
tion for computational linguistics
alvaro henrique chaim correia jorge luiz eira silva thiago castro martins and fbio gagliardi cozman

a fully based information retriever
corr

daniel dahlmeier and hwee tou ng

a search decoder for grammatical error correction
in proceedings of the joint conference on empirical methods in natural language ing and computational natural language learning emnlp conll pages stroudsburg pa usa
association for computational tics
max grusky mor naaman and yoav artzi

newsroom a dataset of
million summaries with diverse extractive strategies
in proceedings of the conference of the north american chapter of the association for computational linguistics man language technologies pages
ciation for computational linguistics
jiatao gu zhengdong lu hang li and victor o
k
incorporating copying mechanism in li

in proceedings of sequence to sequence learning
the annual meeting of the association for putational linguistics volume long papers pages berlin germany
association for computational linguistics
ramesh nallapati bowen zhou cicero dos santos caglar gulcehre and bing xiang

stractive text summarization using sequence sequence rnns and beyond
in proceedings of the signll conference on computational natural language learning pages
association for computational linguistics
caglar gulcehre sungjin ahn ramesh nallapati bowen zhou and yoshua bengio

pointing in proceedings of the the unknown words
annual meeting of the association for tional linguistics volume long papers pages berlin germany
association for tational linguistics
hlynur dav hlynsson
alberto n
escalante b

and laurenz wiskott

measuring the data in ciency of deep learning methods
ings of the international conference on pattern recognition applications and methods volume icpram pages
insticc scitepress
sepp hochreiter and jrgen schmidhuber

long short term memory
neural computation
yaser keneshloo tian shi naren ramakrishnan and chandan k
reddy

deep reinforcement learning for sequence to sequence models
corr

diederik p
kingma and jimmy ba

adam a method for stochastic optimization
cite
comment published as a ence paper at the international conference for learning representations san diego
steve lawrence c lee giles and ah chung tsoi

what size neural network gives optimal eralization convergence properties of tion
technical report
chin yew lin

rouge a package for automatic evaluation of summaries
in proc
acl workshop on text summarization branches out page
junyang lin xu sun shuming ma and qi su

global encoding for abstractive tion
in proceedings of the annual meeting of the association for computational linguistics ume short papers pages
association for computational linguistics
christopher d
manning mihai surdeanu john bauer jenny finkel steven j
bethard and david closky

the stanford corenlp natural guage processing toolkit
in association for tational linguistics acl system demonstrations pages
rui meng sanqiang zhao shuguang han daqing he peter brusilovsky and yu chi

deep in proceedings of the keyphrase generation
annual meeting of the association for tional linguistics pages
association for computational linguistics
courtney napoles matthew gormley and benjamin in van durme

annotated gigaword
ceedings of the joint workshop on automatic edge base construction and web scale knowledge extraction akbc wekex pages stroudsburg pa usa
association for tional linguistics
romain paulus caiming xiong and richard socher

a deep reinforced model for abstractive marization
corr

martin popel and ond zej bojar

training tips for the transformer model
the prague bulletin of mathematical linguistics
pranav rajpurkar robin jia and percy liang

know what you do nt know unanswerable in proceedings of the tions for squad
nual meeting of the association for computational linguistics volume short papers pages melbourne australia
association for tational linguistics
steven j
rennie etienne marcheret youssef mroueh jarret ross and vaibhava goel

self critical sequence training for image captioning
ieee conference on computer vision and pattern nition cvpr pages
matthieu riou bassam jabaian stphane huet and fabrice lefvre

reinforcement adaptation of an attention based neural natural language tor for spoken dialogue systems
dialogue course
alexander m
rush sumit chopra and jason weston

a neural attention model for abstractive in proceedings of the tence summarization
conference on empirical methods in natural guage processing pages
association for computational linguistics
abigail see peter j
liu and christopher d
manning

get to the point summarization with generator networks
in proceedings of the nual meeting of the association for computational linguistics pages
association for putational linguistics
tian shi yaser keneshloo naren ramakrishnan and chandan k
reddy

neural abstractive text summarization with sequence to sequence models
corr

arnab sinha zhihong shen yang song hao ma rin eide bo june paul hsu and kuansan wang

an overview of microsoft academic vice mas and applications
in proceedings of the international conference on world wide web www companion pages new york ny usa
acm
jie tang jing zhang limin yao juanzi li li zhang and zhong su

arnetminer extraction and mining of academic social networks
in proceedings of the acm sigkdd international conference on knowledge discovery and data mining kdd pages new york ny usa
acm
zhaopeng tu zhengdong lu yang liu xiaohua liu and hang li

modeling coverage for neural machine translation
in proceedings of the nual meeting of the association for computational linguistics pages
association for tional linguistics
ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez ukasz kaiser and illia polosukhin

attention is all you need
in i
guyon u
v
luxburg s
bengio h
wallach r
fergus s
vishwanathan and r
nett editors advances in neural information cessing systems pages
curran sociates inc

