bengali text summarization by sentence sarkar science engineering 
 jukamal2001@yahoo.com summarization is a process to produce an abstract or a summary by selecting portion of the information from one or more texts in an automatic text a text is given to the computer and the computer returns a less redundant extract or abstract of the original text(s many techniques have developed for summarizing english text(s a very few attempts have been for bengali text summarization this paper presents a method for bengali text which extracts important sentences from a bengali document to a summary bengali text sentence indian languages introduction information overload on the world wide web is becoming a for an increasingly large number of web users to reduce this information automatic text summarization can be an indispensable tool the or summaries can be used as the document surrogates in place of the original 
 documents in another the summaries can help the reader to get a quick overview an entire document another important issue related to the information explosion on internet is the problem that many documents with the same or similar topics are 
 duplicated this kind of data duplication problem increases the necessity for effective summarization in the following are the important reasons in of automatic text a summary or abstract saves reading time a summary or an abstract facilitate document selection and literature searches improves document indexing efficiency machine generated summary is free from bias customized summaries can be useful in systems where they personalized information the use of automatic or summarization by commercial abstract may allow them to scale the number of published texts they can evaluate to a summarization process can be one or more text documents when only one is the it is called single document text summarization and when the is a group of related text it is called summarization can also categorize the text summarization based on the type of users the summary intended user focused summaries are tailored to the of a particular user or group of users and generic summaries are aimed at broad readership community 2001 on the nature of a summary can be categorized as an abstract and extract an extract is a summary consisting of a number of salient text units selected the input an abstract is a which represents the subject matter of an with the text which are generated by reformulating the salient units from an input an abstract may contain some text which are not present the input text on information content of the it can be categorized as informative indicative summary the indicative summary presents an indication about an purpose and approach to the user for selecting the article for summary covers all salient information in the document at some level of that it will contain information about all the different aspects such as results and conclusions etc for an of a research article is more informative than its headline main objective of the work presented in this paper is to generate an extract from a document we have followed a simple and approach to single document text summarization because the sophisticated summarization requires resources for deeper semantic analysis bengali is a resource language and nlp language research activities on have recently been started in our work presented in this we have the impact of thematic term feature and position feature on bengali text 
 summarization to our no generic text summarization system for bengali available for comparison to our system we have compared the proposed to the lead baseline which was defined for single document text task in past two duc conferences duc and duc 2002 lead considers the first n words of an input article as a where n is a summary length work is different from the work on bengali opinion summarization presented in and because we mainly focus on generic text for bengali section we present a brief survey on single document text summarization in domain the proposed summarization method has been presented in section 3 . section we describe the summary evaluation method and experimental results a survey on single document text summarization in domain this we present a brief survey on single document text summarization for 
 english although new research on text summarization in english domain has been many years most works on text summarization today still rely on sentence to form summary previous works on extractive summarization use two major ranking sentences based on their scores which are computed by combining few or all of features such as term frequency positional information and cue phrases lin and hovy and few top ranked sentences to form an extract the very first work on text summarization by luhn computes salient sentences based on frequency of times a word occurs in a and phrase frequency subsequent research has developed sophisticated summarization methods on various new the work presented by edmundson is still today as the foundation for extraction based summarization presented a straightforward method of sentence extraction using first and last sentences of the document each paragraph lin hovy claimed that as the discourse structures change over the domains the the position method can not be as simple as in 1958 defined an optimal policy of locating the likely positions of in the text et al computes the score of a sentence based on many such as similarity to the similarity to the first sentence of the position of the sentence in the sentence length etc et el applied a machine learning approach to text summarization they a summarizer using a bayesian classifier to combine features from a corpus scientific articles and their abstracts et al presented a sentence extraction method that exploits the semantic between sentences in the text the feature they used in this work may be as a cohesion feature text cohesion and hasan refers to relations between word or referring determine how tightly connected the text is in this text is by a graph in which each node represents a paragraph in a document and edges are labeled with the similarity score between two paragraphs the paragraph is connected to many other paragraphs with a similarity above a predefined is considered as the bushy node the paragraph representing the is considered as a salient one and elhadad described a summarization approach that used lexical method to compute the salience of a sentence cohesion and is a method for sticking together different parts of the text lexical is the simplest form of cohesion lexical cohesion links the different parts of text through semantically related ellipsis and conjunctions cohesion also involves relations such as hypernymy relations such as wrist is a part of hand the of lexical chain was introduced in and 1991 they characterized chain as a sequence of related words that spans a topical unit of text in other lexical chain is basically lexical cohesion that occurs between two terms and sequences of related words barzilay and elhadad used a wordnet to construct the lexical chains work in and considered the fact that the probability of of a sentence in an extract depends on whether the previous sentence had been as well and applied hidden markov models in sentence extraction 

 task applied maximum entropy model to decide whether a will be included in a summary or not he assumed no feature independence features he considered word sentence sentence features e.g. whether sentence follows the etc to creating an automatic generation of abstract is harder and the requires deeper approaches which exploit semantic properties in the text of an abstract from a document is relatively harder since it representation of text units or in a reformulation two or more text units and rendering the new representation in natural language approaches have used template based information information and compression in information extraction based predefined template are filled with the desired pieces of information extracted by the summarization and jones,1993 an automated technique has been presented in to build a corpus representing the used by humans so that such a corpus can then be used to train an automated 

 summarizer true abstraction needs more sophisticated process that requires resources generation can be viewed as generation of very short summary less that represents the relevant points contained in a document a summary is a kind of the indicative summary banko et al presented approach that uses some statistical methods to generate headline like abstracts markov based headline generation has been presented in dorr and 2002 et al developed the hedge trimmer that uses a based to generate headlines in this the first sentence of a document is using a parser and then the parsed sentence is compressed to form a headline eliminating the unimportant constituents of the sentence using a set of motivated rules et al . a headline generation combines the version of the lead sentence and a set of topic descriptors generated from corpus to form a headline the sentence is compressed using the approach similar the approach in et al and the topic descriptors a number of for creating abstracts have been conceptualized without much emphasis the issue that a true abstract may contain some information not contained in the 
 document creating such an abstract requires external information of some kind such knowledge base etc since resources of this kind are difficult abstractive summarization has not progressed beyond the 
 stage proposed summarization method proposed summarization method is extraction based it has three major sentence ranking summary generation 

 3.1 preprocessing preprocessing step includes stemming and breaking the input in to a collection of sentences for stop word we have used the list downloadable from the website of forum for information evaluation fire)(http://www.isical.ac.in/~fire stopwords_list_ben.txt 

 3.2 stemming a word is split into its stem and affix the design of a stemmer is and requires some significant linguistic expertise in the language typical simple stemmer algorithm involves removing suffixes using a list of while a more complex one would use morphological knowledge to a stem from the words since bengali is a highly inflectional is necessary while computing frequency of a term our we use a lightweight stemmer for bengali that strips the suffixes using a suffix on a using the algorithm similar to that hindi and 2003 

 3.3 sentence ranking an input document is formatted and the document is broken into a of sentences and the sentences are ranked based on two important term and position the thematic terms are the terms which are related to the main theme a document we define the thematic terms are the terms whose tfidf values are than a predefined threshold the tfidf value of a term is measured by the of tf and where tf is the number of times a word in a document and idf is inverse document frequency the idf of a word is on a corpus using the where of in the corpus and df indicates the number of in which a word occurs the score of a sentence k is computed based on the of the sentence to the set of thematic terms in a document the similarity of a k to the set of thematic terms in a document is computed as the sum of the values of the thematic terms contained in the sentence k. is a tfidf value of a thematic term w in a sentence k and sk is the of the sentence k. crucial issue is to determine the tfidf threshold value based on which we can on whether a term is a thematic term or not in experimental we will how this threshold value has been adjusted for the best results the positional score of a sentence is computed in such a way that the sentence of a document gets the highest score and the last sentence gets the lowest 

 score the positional value for the sentence k is computed using following we consider length of a sentence as a feature because we observe that a sentence is too but it occurs in the beginning paragraph of a document it is selected due to its positional advantage on the other if a sentence is it is sometimes selected due to the fact that it contains many words we the sentences which are too short or too long parameters for sentence we compute the score of a sentence the linear combination of the normalized values of thematic term based score sk positional score pk if the sentence is not too long or too short if a sentence is too or too it is assigned a score of 0 the final score of a sentence k values of   ll cutoff on the sentence length and lu cutoff the sentence length are obtained by tuning them for the best results on a subset documents randomly selected from our corpus in the experimental we will in detail how the values of these parameters are tuned 

 3.4 summary generation summary is produced after ranking the sentences based on their scores and selecting ranked when the value of k is set by the user to increase the of the the sentences in the summary are reordered based on their in the original for the sentence which occurs first in the text will appear first in the summary experiments and results test our summarization we collected bengali documents from the daily ananda bazar patrika the documents are typed and saved in text files using format for each document in our we consider only reference summary for evaluation evaluation of a system generated summary is by comparing it to the reference summary 

 4.1 evaluation is very difficult to determine whether a summary is good or bad the summary methods can be broadly categorized as human evaluation methods and evaluation methods a human evaluation is done by summaries with summaries by human 
 judges according to some predefined the judges assign a score in a scale to each summary under evaluation quantitative scores are given to the based on the different qualitative features such as information etc the main problems with human evaluation the evaluation process tedious it suffers from the lack of consistency two human judges may not agree each judgments on the other automatic evaluation is consistent with a judgment the automatic evaluations may lack the linguistic and emotional perspective that a human has hence although automatic is not perfect compared to the human it is popular primarily the evaluation process is quick even if summaries to be evaluated are large in 
 number since automatic evaluation is performed by a it follows a fixed logic always produces the same result on a given summary since automatic evaluation are free from human it provides a consistent way of comparing the summarization systems several past document understanding conferences organized by nist national institute of standards and single document text systems for english have been evaluated in duc and duc single document summarization task was to generate a summary of fixed length as words etc a baseline called lead baseline was defined in conferences lead baseline considers the first n words of an input article as a where n is a predefined summary length duc single document text summarization task where there was a fixed length for each we believe that a generic summary of a document be longer or shorter than a summary of another document we assume that the of a system generated summary should be equal to that of the corresponding but the different model summaries may not be equal in size adopted an automatic summary evaluation metric for comparing to reference summaries when we compare a system generated summary to reference we ensure that they would be of the same length we have used unigram overlap method stated in et.al for evaluating the system summaries unigram overlap between a system generated summary and a summary is computed as based recall is the length of the reference summary and indicates the maximum number of unigrams in the system summary s and the reference summary r. of reference summaries is a laborious task in our we have only one reference summary for evaluating each system generated summary 

 4.2 experiments and results   and choosing appropriate threshold for the best    used in equation would be set appropriately at the same an appropriate threshold value for selecting the thematic terms in subsection 3.3 be chosen for tuning these we build a training data set by collection of selecting pairs from pairs in our corpus we set the value of   to since   is the weight of the positional feature which observed by us as a feature producing better results than the thematic term feature set the value of   to for all the experimental cases presented in this paper tuning the value of we set the tfidf threshold value to and conduct with the different values of   that ranges from to 1 to obtain the values of we step between to by 0.1 the figure shows summarization curve with respect to different values of   on the training data 

 figure1 average recall score vs. when tfidf threshold value is set to and   is to 1 figure shows that when the value of   is set to 0.1 which is a relatively smaller the better result is obtained depending on tfidf threshold value we decide on whether a term is the term or an appropriate threshold value should be determined to improve summarization performance for this after fixing the value of   to 0.10 we the tfidf threshold value figure shows the summarization performance curve with different tfidf values 2 average recall score vs. tfidf threshold when   is set to 0.10 and is set to 1 figure shows that the best result is achieved when tfidf threshold value is set any value between 3.8 and 4.6 we set tfidf threshold value to 3.8 because at this average recall score transits from a lower value to the best value fixing the value of   to 0.10 and the tfidf threshold value to 3.8 we adjust the cutoff and the upper cutoff on the sentence length . table shows the results on set with different values of the upper cutoff on sentence length recall 

 0.3752 

 0.3752 

 0.3752 

 0.3627 1 results on training set with different values of the upper cutoff on length results on training set with different values of lower cutoff on sentence length shown in table 2 recall score 

 0.3752 

 0.3770 

 0.3749 

 0.3660 2 results on training set with different values of lower cutoff on sentence 
 length and table show that the best results are obtained when lu is set to any value and and ll is set to 3 we set the value of lu to and the value of ll when we run the system on the test data we pairs in our corpus and considered this subset as a training set for the values of several parameters discussed above after setting the parameters the values learnt from the training we test our system on the entire collection of documents from each of a summary of n words is where is the length of the reference summary of the corresponding document a system summary is compared to a reference summary and the unigram based recall is computed using the equation 4 the average recall score is obtained by the recall scores obtained on all the documents in the collection of shows the performance of the proposed system on the test data set our no generic text summarization system for bengali is available for to our system we have compared the proposed method to the lead 
 baseline lead baseline considers the first n words of an input article as a n is a predefined summary length . table shows the comparisons of our to the lead baseline unigram based recall score system 

 0.4122 baseline 

 0.3991 

 table3 comparison of the proposed system to lead baseline shows that the proposed method outperforms the lead baseline the of generic summarization systems in the past duc conferences duc duc proves that it is very hard to beat lead baseline on the news 
 documents the following is an article taken from the bengali daily newspaper bazar patrika p t m o    o   ei p   o   sp st o   e o nt ei      i   u o   m o t    a   t   eo e   o nt e d m   ei ps    o o is the reference summary for the article mentioned above    p st following is the summary generated by the proposed system for the news 

 article p t m o    ei p   o   sp st conclusion paper discusses a single document text summarization method for bengali many have been developed for summarizing english text(s a very few have been made for bengali text summarization performance of the proposed system may further be improved by improving exploring more number of features and applying learning for effective feature combination more than one reference summaries are used for evaluating each system but in our we have used only one reference summary for evaluation in we will consider more than one reference summaries summary evaluation a. s. 2010 bengali opinion summarization a. d. d. 2003 a lightweight stemmer for hindi in the 232 240 . of eacl 2003 b. j. d. r. 2003 hedge a to headline generation in proceedings of the summarization workshop and document understanding conference pp alberta c. d. 1993 the identification of important concepts in highly technical papers in the proceedings of the international on research and development in information retrieval 69 78 c y and e. 1997 identifying topics by position in proceedings of the applied natural language processing 290 new new association for computational linguistics d. r. h. m. d. 2004 summarization of documents journal of information processing and volume issue pp 919 938 d. t. s. j. a. e. 

 w. d. j. h. h. s. m. a. z. 2004 mead a platform for multidocument text summarization in proceedings of the international on language resources and evaluation 

 portugal d. b. j. r. 2004 at topiary in association for north american chapter of of linguistics workshop on document pp 112119 d. b. r. 2002 automatic headline generation for in workshop on automatic pp 78 85 g. 1995 a lexical database for communications of the for computing machinery 38(11):39 41 g. a. m. c. 1997 automatic text structuring processing and management summary journal of 
 33(2):193207 h. p. 1969 new methods in automatic extracting journal of the for computing 16(2):264285 h. p. 1958 the automatic creation of literature abstracts ibm journal of 2(2):159165 i. 2001 automatic volume of natural language john benjamins publishing company 

 jing h. 2002 using hidden markov modeling to decompose 

 summaries computational 527543 h. k. 1999 the decomposition of summary in the proceedings of international conference on and development in information university of pages 129136 j. j. o. f. 1995 a trainable document summarizer in of research and development in information pp 6873 j. m. d. p. 2001 text summarization via hidden markov models pivoted qr matrix decomposition tech rep university of 2001 j. g. 1991 lexical cohesion computed by thesaural relations as an of the structure of computational 17(1):21 43 m. a. k. r. 1996 cohesion in text london m. a. k r. 1976 cohesion in english english language london m. v. witbrock m. 2000 headline generation based on statistical 
 translation in proceedings of the annual meeting of the association for linguistics hong pp 318325 m. 2002 using maximum entropy for sentence extraction in proceedings of workshop on automatic volume annual meeting of the association for computational morristown p. 1958 index for technical literature an experiment ibm of research and pages 354361 r. elhadad m. 1997 using lexical chains for text summarization in of the workshop on intelligent scalable text summarization pp spain